<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS190634</article-id><article-id pub-id-type="doi">10.1101/2023.11.05.565662</article-id><article-id pub-id-type="archive">PPR753343</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">2</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>On prefrontal working memory and hippocampal episodic memory: Unifying memories stored in weights and activity slots</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Whittington</surname><given-names>James C.R.</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><contrib contrib-type="author"><name><surname>Dorrell</surname><given-names>William</given-names></name><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Behrens</surname><given-names>Timothy E.J.</given-names></name><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A4">4</xref></contrib><contrib contrib-type="author"><name><surname>Ganguli</surname><given-names>Surya</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>El-Gaby</surname><given-names>Mohamady</given-names></name><xref ref-type="aff" rid="A2">2</xref></contrib></contrib-group><aff id="A1"><label>1</label>Department of Applied Physics, Stanford University, Palo Alto, USA</aff><aff id="A2"><label>2</label>Wellcome Centre for Integrative Neuroimaging, University of Oxford, Oxford, UK</aff><aff id="A3"><label>3</label>Gatsby Computational Neuroscience Unit, University College London, London, UK</aff><aff id="A4"><label>4</label>Sainsbury Wellcome Centre for Neural Circuits and Behaviour, University College London, London, UK</aff><author-notes><corresp id="CR1">
<label>*</label>corresponding author(s): Correspondence to James CR Whittington <email>jcrwhittington@gmail.com</email></corresp></author-notes><pub-date pub-type="nihms-submitted"><day>06</day><month>11</month><year>2023</year></pub-date><pub-date pub-type="preprint"><day>05</day><month>11</month><year>2023</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Remembering events in the past is crucial to intelligent behaviour. Flexible memory retrieval, beyond simple recall, requires a cognitive map, or model of how sensations, actions, and latent environmental or task states are all related to one another. Two key brain systems are implicated in this process: the hippocampal episodic memory (EM) system and the prefrontal working memory (WM) system. While an understanding of the hippocampal system, from computation to algorithm and representation, is emerging, less is understood about how the prefrontal WM system can give rise to flexible computations beyond simple memory retrieval, and even less is understood about how the two systems relate to each other. Here we develop a mathematical theory relating the algorithms and representations of EM and WM by unveiling a duality between storing memories in synapses versus neural activity. In doing so, we develop a formal theory of the algorithms and representations of prefrontal WM in terms of structured, and controllable, neural subspaces (termed activity slots) that together can represent a dynamic cognitive map without any need for synaptic plasticity. By building models using this formalism, we elucidate the differences, similarities, and trade-offs between the hippocampal and prefrontal algorithms. Lastly, we show that several prefrontal representations in tasks ranging from list learning to cue dependent recall are unified as controllable activity slots. Our results unify frontal and temporal representations of memory, and offer a new basis for understanding dynamic prefrontal representations of WM.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">Being able to predict what will happen next in novel structured environments constitutes a fundamental feature of intelligent cognition. However, due to the one dimensional and irreversible nature of time itself, we can only learn about structured environments, and the consequences of our actions in them, through a spatiotemporally local sequence of transient sensorimotor experiences. Thus, to learn to predict the future, both brains<sup><xref ref-type="bibr" rid="R1">1</xref>–<xref ref-type="bibr" rid="R3">3</xref></sup> and machines<sup><xref ref-type="bibr" rid="R4">4</xref>–<xref ref-type="bibr" rid="R6">6</xref></sup> must convert this transient sequence of sensorimotor experience into internal models of the world that remember and exploit structured relationships between actions, sensations, and environmental features. When such an internal model, or cognitive map, emerges it can allow additional flexibility beyond next step prediction, such as inferring new routes to goals<sup><xref ref-type="bibr" rid="R7">7</xref></sup> or simulating counterfactual scenarios<sup><xref ref-type="bibr" rid="R8">8</xref></sup>. An algorithmic understanding of how local sequential sensorimotor experience is converted into a rich cognitive map capable of predicting the future counterfactual consequences of diverse potential actions remains a major aim of cognitive neuroscience.</p><p id="P3">Two key brain regions are proposed to build cognitive maps from sequential experience: the episodic memory (EM) system in the medial temporal lobe and the working memory (WM) system in the prefrontal cortex (PFC)<sup><xref ref-type="bibr" rid="R9">9</xref>–<xref ref-type="bibr" rid="R11">11</xref></sup>. However it is not clear why two systems are employed to solve the same problem nor how these brain systems are related in either underlying algorithms or representations.</p><p id="P4">For sequential episodic memory in the hippocampal formation, ideas are beginning to emerge on underlying algorithms and representations<sup><xref ref-type="bibr" rid="R4">4</xref>,<xref ref-type="bibr" rid="R12">12</xref>–<xref ref-type="bibr" rid="R14">14</xref></sup>. In these models, memories are stored in hippocampus (HPC) by updating synaptic connections via Hebbian learning<sup><xref ref-type="bibr" rid="R15">15</xref></sup> (like a Hopfield network<sup><xref ref-type="bibr" rid="R16">16</xref></sup>), with cortical recurrent neural networks (RNNs) controlling which memory to store or retrieve by tracking position (ordinal, spatial, or otherwise) within the sequence. These models are able to explain many cellular recordings in the hippocampal formation for both spatial and non-spatial tasks; hippocampal cells such as place cells<sup><xref ref-type="bibr" rid="R17">17</xref></sup>, landmark cells<sup><xref ref-type="bibr" rid="R18">18</xref></sup>, and splitter cells<sup><xref ref-type="bibr" rid="R19">19</xref></sup> are explained as memory representations, while entorhinal cells such as grid cells<sup><xref ref-type="bibr" rid="R20">20</xref></sup>, object-vector cells<sup><xref ref-type="bibr" rid="R21">21</xref></sup>, border-vector cells<sup><xref ref-type="bibr" rid="R22">22</xref></sup>, non-spatial grid cells<sup><xref ref-type="bibr" rid="R23">23</xref>,<xref ref-type="bibr" rid="R24">24</xref></sup>, non-spatial sound frequency cells<sup><xref ref-type="bibr" rid="R25">25</xref></sup> are explained as representing position, so that the right memory is retrieved at the right position. Importantly, the hippocampal literature shows us that sequence memory is not just remembering sequences exactly as they were presented, but rather using structured knowledge (e.g., where you are in space) to recall the right memory at the right time. Thus even in this case, successful sequence memory goes beyond mere rote memorisation of sensory experience, but rather reflects a more sophisticated cognitive map building process that learns systematic relationships between sensations and actions induced by latent spatial or task structure<sup><xref ref-type="bibr" rid="R4">4</xref>,<xref ref-type="bibr" rid="R5">5</xref>,<xref ref-type="bibr" rid="R12">12</xref>–<xref ref-type="bibr" rid="R14">14</xref></sup>.</p><p id="P5">For sequence working memory in PFC, our understanding is limited to tasks of repeating sequences exactly as they were presented. Here, findings from both artificial<sup><xref ref-type="bibr" rid="R26">26</xref>–<xref ref-type="bibr" rid="R28">28</xref></sup> and biological<sup><xref ref-type="bibr" rid="R29">29</xref>,<xref ref-type="bibr" rid="R30">30</xref></sup> networks suggest memories of items are organised into neural subspaces according to their ordinal position. Crucially, unlike HPC, storing these memories requires no additional synaptic plasticity since recurrent connections in PFC update and maintain memories stored in neural activity. While this has revealed mechanisms of sequential memory retrieval, PFC is implicated in tasks requiring flexible control of memory retrieval<sup><xref ref-type="bibr" rid="R31">31</xref>–<xref ref-type="bibr" rid="R33">33</xref></sup>, i.e., not just repeating sequences exactly as they were presented. While we don’t understand how PFC working memory models allow such flexible control, we do for HPC episodic memory models. Thus, if we could relate PFC working memory and HPC episodic memory then we could understand how the PFC working memory system flexibly controls its memories to tackle sequence memory and prediction tasks that go beyond simple repetitive sequences and instead require cognitive map-like knowledge of structured relationships between, sensations, actions, and latent spatial or non-spatial variables.</p><p id="P6">Unfortunately no relationships currently exist between PFC working memory and HPC episodic memory. Excitingly, though, recent results from the machine learning literature suggest there may be a relationship. In particular, simplified (linear) versions of transformer neural networks<sup><xref ref-type="bibr" rid="R6">6</xref></sup>, which are closely related to Hopfield networks<sup><xref ref-type="bibr" rid="R34">34</xref>–<xref ref-type="bibr" rid="R36">36</xref></sup>, have a recurrent reformulation<sup><xref ref-type="bibr" rid="R37">37</xref>,<xref ref-type="bibr" rid="R38">38</xref></sup> which is suggestive of a relationship between episodic and working memory models.</p><p id="P7">In this work we provide an understanding of sequence working memory in PFC and how it relates, in representation and algorithm, to HPC episodic memory. In particular we 1) develop a unifying theory of storing sequence memories in synapses (EM) and neural activity (WM); 2) demonstrate that the two algorithms differ in their ability to scale to larger task sizes; 3) demonstrate how the different algorithms utilise different neural representations, with EM using abstract positions, while WM uses slots (distinct neural subspaces) in neural activity; 4) demonstrate that the WM slot representation affords scene algebra; 5) recover single neuron slot coding under certain constraints; 6) demonstrate how internally computed velocity signals can control the contents of PFC slots; 7) show that our theory of controllable activity slots provides a common explanation for PFC data from several disparate studies. Overall, a main dividend of our derived duality between episodic HPC memory and PFC working memory is a new, unifying theoretical framework for how PFC working memory networks could, in principle, implement and control dynamic cognitive maps of the environment or task through recurrent updates of neural activity alone, without any synaptic plasticity.</p><sec id="S2"><title>Theory: Unifying memories stored in synapses and neural activity</title><sec id="S3"><title>Sequence memory and prediction is a structure learning problem</title><p id="P8">Sequence memory and prediction tasks involve recalling previous observations, but where correct recall depends on an underlying task structure. For example, in Immediate Serial Recall<sup><xref ref-type="bibr" rid="R39">39</xref></sup> (ISR), a series of observations are presented in order, and then they must be recalled in order. Here the underlying structure is a ordinal line, but other sequences can be drawn from other underlying structures. For example if a sequence is drawn from navigating in 2D space, then including this structural knowledge in an internal representation will dramatically facilitate recall and prediction, as some transitions are possible in 2D space, but others are not. For example, in a 2D navigation task, it is possible to predict what one will see next when traversing a closed loop for the first time, but this requires not only remembering one’s past sequence of observations, but also combining this sequence memory with knowledge of the structure of 2D space, and how actions move us within the space (i.e. if the integral of your recent velocity will become 0 then you will return to a previously experienced location). This facilitation of sequence memory and prediction by exploiting knowledge of task structure is possible in all problems where there is a common structural constraint. Even when each problem consists of sequences with different observations (so one problem’s sequence cannot be memorised and used for another problem), knowledge of the common task structure across problems facilitates recall and prediction within each problem. In machine learning terminology, the underlying task structure must be meta-learned across problems (learning to learn; <xref ref-type="fig" rid="F1">Figure 1A</xref> left for example ISR task).</p></sec><sec id="S4"><title>Task and problem formalism</title><p id="P9">Formally, for each task, we consider a dataset 𝒟 = {𝒟<sub>0</sub>, 𝒟<sub>1</sub>, ⋯, 𝒟<sub>N</sub>} Each 𝒟<sub>i</sub> is one of <italic>N</italic> problem instances of the common task, and is simply a sequence consisting of vectors of sensory observations, <bold><italic>o</italic></bold>, of dimension <italic>d</italic><sub><italic>o</italic></sub> (termed <bold><italic>o</italic></bold> ∈ ℝ<sup><italic>d<sub>o</sub></italic></sup>), sensory targets, <bold><italic>t</italic></bold> ∈ ℝ<sup><italic>d<sub>o</sub></italic></sup>, and (allocentric) velocities, <bold><italic>v</italic></bold> ∈ ℝ<sup><italic>d<sub>v</sub></italic></sup>, i.e., 𝒟<sub>i</sub> = {(<bold><italic>o</italic></bold><sub>0</sub>,<bold><italic>t</italic></bold><sub>0</sub>,<bold><italic>v</italic></bold><sub>0</sub>), (<bold><italic>o</italic></bold><sub>1</sub>,<bold><italic>t</italic></bold><sub>1</sub>,<bold><italic>v</italic></bold><sub>1</sub> ⋯, (<bold><italic>o</italic></bold><sub><italic>k</italic></sub>,<bold><italic>t</italic></bold><sub><italic>k</italic></sub>,<bold><italic>v</italic></bold><sub><italic>k</italic></sub>)} if the sequence is of length <italic>K</italic>. These velocities reflect actions taken by agents, but in this case we provide them externally. Importantly, the underlying structure of the task is determined by how successive actions cumulatively change latent states within the task, which themselves are never <italic>directly</italic> observed by the agent.</p><p id="P10">Concretely, we assume there is an underlying latent variable, <bold><italic>z</italic></bold> ∈ ℝ<sup><italic>d<sub>z</sub></italic></sup>, which we can think of as corresponding to a latent agent or task state. In spatial contexts we can think of the agent’s latent state as its position. Furthermore, we assume each latent state, or position <bold><italic>z</italic></bold>, is associated with a visible observation <bold><italic>o</italic></bold>, corresponding to what the agent would sense if it had the latent state, or position <bold><italic>z</italic></bold>. Also, we assume that for any ordered pair of neighbouring source and target latent states, there is a unique action, or velocity <bold><italic>v</italic></bold> that modifies the agent’s latent state from the source to the target (see <xref ref-type="fig" rid="F1">Figure 1A</xref> left for a simple loop structure with one action). The task structure is encoded by how actions, or velocities, change the latent state, or position. For example, in the case of navigation in a 2D grid, there are 4 elementary actions, or velocities, corresponding to moving one step <monospace>North, South, West</monospace> or <monospace>East</monospace>, and each step moves the latent 2D grid position <bold><italic>z</italic></bold> by one step in the corresponding direction. In our formulation, successive actions correspond to the addition of velocities, and so when a sequence of velocities additively cancel (i.e. <monospace>North</monospace> + <monospace>East</monospace> + <monospace>South</monospace> + <monospace>West</monospace> = 0 for a 2D grid), the then the agent necessarily returns to the same latent position and encounters the same observation at the beginning and end of the action sequence.</p><p id="P11">Now, returning to the data for a single task 𝒟 = {𝒟<sub>0</sub>, 𝒟<sub>1</sub>, ⋯, 𝒟<sub>N</sub>} each individual problem instance 𝒟<sub><italic>i</italic></sub> assumes a different and random pairing of observations <bold><italic>o</italic></bold>, to latent states <bold><italic>z</italic></bold>. However, all <italic>N</italic> problem instances share the <italic>same</italic> underlying task structure, specified by how actions, or velocities <bold><italic>v</italic></bold> change latent states. The aim of the task is to predict a target, <bold><italic>t</italic></bold>, at each timestep which is either an upcoming observation (i.e., what you will see after going <monospace>North</monospace>), or a past observation (i.e., what you saw 5 steps ago). Importantly, neither latent states, nor how actions affect latent states, are directly observed by the agent. Instead the agent only experiences a spatiotemporally local sequence of transient sensations and actions. To successfully solve the prediction or recall task across all problems, the agent must build a cognitive map of the common task structure that captures how actions affect latent states, and how latent states are bound to observations. Only then, for example can the agent predict what it will see next upon the first traversal of a closed loop in a 2D grid. Finally, we note that while the task formalism (and subsequent model formalism) is general to tasks with discrete and continuous positions, we primarily consider the discrete setting here (with <italic>n</italic><sub><italic>p</italic></sub> total positions).</p><p id="P12">Next we will develop a theory for a very simple network realisation of an EM solution, and from that derive a very simple network realisation of a WM solution. But crucially, we will show below that many of the features of these simple solutions hold in more general scenarios, both in generic artificial networks of machines, and in biological networks of animals, that successfully solve structured sequence memory and prediction tasks.</p></sec><sec id="S5"><title>Solving sequence memory tasks with EM</title><p id="P13">The hippocampal literature has developed EM models that solve these tasks<sup><xref ref-type="bibr" rid="R4">4</xref>,<xref ref-type="bibr" rid="R14">14</xref></sup>. These models are built from two components (1A top-middle). The first component is an RNN that learns to <italic>explicitly</italic> represent position in a manner that generalises across tasks. The second component is a memory system that binds observation representations to position representations and stores this memory in synaptic weights. Critically these weights change in every problem so different problems from a common task can be solved with a common position code. In its simplest form, the RNN has a single neuron active for each position (<xref ref-type="fig" rid="F1">Figure 1A</xref> middle; full theory in <xref ref-type="supplementary-material" rid="SD1">Appendix A.1</xref>). Sensory memories for each position are encoded in synaptic weights between each RNN neuron (corresponding to that position) and the observation representation, with memories added (weights updated) via Hebbian learning. The role of the RNN is to track the underlying latent variable, <bold><italic>z</italic></bold>, so that the correct position cell is activated at the right time to retrieve the right memory (<xref ref-type="fig" rid="F1">Figure 1A</xref> middle; the leftmost position cell activates to recall the observation at position A). Tracking position means the RNN integrates velocity signals, <bold><italic>v</italic></bold>, to update its representation from <bold><italic>h</italic></bold>(<bold><italic>z</italic></bold> − <bold><italic>v</italic></bold>) to <bold><italic>h</italic></bold>(<bold><italic>z</italic></bold>) (i.e. from position <bold><italic>z</italic></bold> − <bold><italic>v</italic></bold> to position <bold><italic>z</italic></bold>). This can be done with velocity dependent matrices, <bold><italic>W</italic></bold> <sub><bold><italic>v</italic></bold></sub>, that follow the transition rules of <bold><italic>z</italic></bold> (e.g., <bold><italic>W</italic></bold><sub><bold><italic>v</italic></bold></sub><bold><italic>W</italic></bold> <sub>−<bold><italic>v</italic></bold></sub> = <bold><italic>I</italic></bold>; going <monospace>North</monospace> then <monospace>South</monospace> takes you to the same position). Mathematically, the RNN update is <bold><italic>h</italic></bold>(<bold><italic>z</italic></bold>) = <bold><italic>W</italic></bold> <sub><bold><italic>v</italic></bold></sub> <bold><italic>h</italic></bold>(<bold><italic>z</italic></bold>− <bold><italic>v</italic></bold>) (<xref ref-type="fig" rid="F1">Figure 1C</xref>). The overall process of generating target predictions (assuming all observations have already been seen and added as memories - the <bold><italic>o</italic></bold> terms in the below equation) is succinctly described in the following equation:</p><disp-formula id="FD1"><label>(1)</label><mml:math id="M1"><mml:msub><mml:mstyle mathvariant="bold-italic" mathsize="normal"><mml:mover accent="true"><mml:mi>t</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mstyle><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:munder><mml:mrow><mml:mo>[</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mstyle><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mstyle><mml:mrow><mml:mi>z</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mstyle><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mstyle><mml:mrow><mml:mi>z</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mo stretchy="true">︸</mml:mo></mml:munder><mml:mrow><mml:mtext>EM</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>slots</mml:mtext><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:munder><mml:munder><mml:mrow><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mi>t</mml:mi></mml:munderover><mml:munder><mml:munder><mml:mrow><mml:msub><mml:mstyle><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mstyle><mml:mrow><mml:msub><mml:mstyle><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mstyle><mml:mi>τ</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">︸</mml:mo></mml:munder><mml:mrow><mml:mtext>Recurrent</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>matrix</mml:mtext><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:munder><mml:munder><mml:mrow><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mo stretchy="true">︸</mml:mo></mml:munder><mml:mrow><mml:mtext>Initial</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>RNN</mml:mtext><mml:mo>,</mml:mo><mml:msub><mml:mstyle><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mstyle><mml:mn>0</mml:mn></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:munder></mml:mrow><mml:mo stretchy="true">︸</mml:mo></mml:munder><mml:mrow><mml:mtext>RNN</mml:mtext><mml:mo>,</mml:mo><mml:msub><mml:mstyle><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mstyle><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:munder></mml:math></disp-formula><p id="P14">We see that, an initial RNN representation, <bold><italic>h</italic></bold><sub>0</sub>, is successively updated by velocity dependent matrices, <bold><italic>W</italic></bold> <sub><bold><italic>v</italic></bold></sub>, to code for position at timestep <italic>t</italic> + 1: <bold><italic>h</italic></bold><sub><italic>t</italic>+1</sub>. To make predictions, <bold><italic>h</italic></bold><sub><italic>t</italic>+1</sub> selects (like an attention vector) one of the <italic>n</italic><sub><italic>p</italic></sub> observations stored in memory <bold>slots</bold> in synaptic weights (<xref ref-type="fig" rid="F1">Figure 1B</xref>; synaptic memory slots are non-overlapping sets of synaptic connections that can be rapidly updated to store arbitrary memories; each slot corresponds to a position <bold><italic>z</italic></bold> and stores the observation at position <bold><italic>z</italic></bold>; <bold><italic>o</italic></bold><sub><bold><italic>z</italic></bold></sub>). For clarity of presentation, we chose a basis in which the RNN vector is one-hot (has one cell active at any time) and the matrices <bold><italic>W</italic></bold> <sub><bold><italic>v</italic></bold></sub> have columns that are all zeros except for a single 1 (e.g., <xref ref-type="fig" rid="F1">Figure 1C</xref>), though the above solutions works in any basis, i.e., <bold><italic>h</italic></bold> ← <bold><italic>O</italic></bold><sup><italic>T</italic></sup> <bold><italic>h, W</italic></bold> <sub><bold><italic>v</italic></bold></sub> ← <bold><italic>O</italic></bold><sup><italic>T</italic></sup> <bold><italic>W</italic></bold> <sub><bold><italic>v</italic></bold></sub> <bold><italic>O</italic></bold>, etc. Indeed, under simple constraints, the optimal solution to this basis is a grid cell basis<sup><xref ref-type="bibr" rid="R4">4</xref>,<xref ref-type="bibr" rid="R40">40</xref></sup>.</p></sec><sec id="S6"><title>Solving sequence memory tasks with WM</title><p id="P15">The above solution stores memories in synaptic connections, and is thus relatable to the hippocampal formation. However, the PFC is thought to store sequence memories in the dynamics of neural activity as opposed to synaptic connections<sup><xref ref-type="bibr" rid="R27">27</xref>,<xref ref-type="bibr" rid="R30">30</xref></sup> (1A top-right; although see<sup><xref ref-type="bibr" rid="R41">41</xref></sup>). Here we show that reshaping and rearranging the above equation produces an alternative, but equivalent, solution where memories are stored in RNN activity rather than synaptic connections (<xref ref-type="fig" rid="F1">Figure 1A</xref> right): <disp-formula id="FD2"><label>(2)</label><mml:math id="M2"><mml:msub><mml:mstyle><mml:mover accent="true"><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mstyle><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:munder><mml:mrow><mml:mo>[</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mstyle><mml:mi mathvariant="bold-italic">I</mml:mi></mml:mstyle><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mo stretchy="true">︸</mml:mo></mml:munder><mml:mrow><mml:mtext>Readout</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>weights</mml:mtext><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:msub><mml:mi>n</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:munder><mml:munder><mml:mrow><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mi>t</mml:mi></mml:munderover><mml:munder><mml:munder><mml:mrow><mml:msubsup><mml:mstyle><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mstyle><mml:mrow><mml:msub><mml:mstyle><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mstyle><mml:mi>τ</mml:mi></mml:msub></mml:mrow><mml:mo>*</mml:mo></mml:msubsup></mml:mrow><mml:mo stretchy="true">︸</mml:mo></mml:munder><mml:mrow><mml:mtext>Recurrent</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>matrix</mml:mtext><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:msub><mml:mi>n</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:msub><mml:mi>n</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:munder><mml:munder><mml:mrow><mml:mo>[</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mstyle><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mstyle><mml:mrow><mml:mi>z</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mstyle><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mstyle><mml:mrow><mml:mi>z</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mo stretchy="true">︸</mml:mo></mml:munder><mml:mrow><mml:mtext>Initial</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>WM</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>slots</mml:mtext><mml:mspace width="0.2em"/><mml:msub><mml:mstyle><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mstyle><mml:mn>0</mml:mn></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:msub><mml:mi>n</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:munder></mml:mrow><mml:mo stretchy="true">︸</mml:mo></mml:munder><mml:mrow><mml:mtext>RNN</mml:mtext><mml:mo>,</mml:mo><mml:msub><mml:mstyle><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mstyle><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:munder></mml:math></disp-formula></p><p id="P16">This equation performs the exact same computation as the previous equation, though its terms, while similar, have important differences (see <xref ref-type="supplementary-material" rid="SD1">Table 1</xref> for relationships between terms). In particular, what was a matrix of memories stored in synaptic weights, [<bold><italic>o</italic></bold><sub><italic>z</italic>0</sub> ⋯ <bold><italic>o</italic></bold><sub><italic>znp</italic></sub>], is now a vector of memories stored in RNN activity, <inline-formula><mml:math id="M3"><mml:mo>[</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mstyle><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mstyle><mml:mrow><mml:mi>z</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mstyle><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mstyle><mml:mrow><mml:mi>z</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo><mml:mo>.</mml:mo></mml:math></inline-formula> Thus the total neural activity pattern can be decomposed into a collection of non-overlapping subspaces which we term <bold>activity slots</bold>, and each such slot can store a memory of an arbitrary observation (<xref ref-type="fig" rid="F1">Figure 1A</xref> right). Readout weights are now fixed and attend to a single slot (<xref ref-type="fig" rid="F1">Figure 1D</xref>). Thus, to readout a memory, the contents of each slot must be copied and shifted to other slots via recurrent weights <inline-formula><mml:math id="M4"><mml:msubsup><mml:mstyle><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mstyle><mml:mstyle><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mstyle><mml:mo>*</mml:mo></mml:msubsup><mml:mo>,</mml:mo></mml:math></inline-formula> so that the correct observation can be readout (in the above equation the first slot is the readout slot, but in general it could be any slot - this is set by the structure of the task, e.g., <xref ref-type="supplementary-material" rid="SD1">Figure 8</xref>). To copy and shift the contents of activity slots, the WM velocity dependent matrices, <inline-formula><mml:math id="M5"><mml:msubsup><mml:mstyle><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mstyle><mml:mstyle><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mstyle><mml:mo>*</mml:mo></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:msub><mml:mi>n</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:msub><mml:mi>n</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:math></inline-formula> are expanded (and transposed) versions of the EM velocity-dependent matrices, <bold><italic>W<sub>v</sub></italic></bold>: where there was a 1 or a 0, there is now an identity matrix (<italic><bold>I</bold></italic> ∈ ℝ<sup><italic>d<sub>o</sub></italic>×<italic>d<sub>o</sub></italic></sup>) or a matrix of zeros (<bold>0</bold> ∈ ℝ<sup><italic>d<sub>o</sub></italic>×<italic>d<sub>o</sub></italic></sup>) (See <xref ref-type="fig" rid="F1">Figure 1E</xref> for a schematic of the structure of <bold><italic>W<sub>v</sub></italic></bold>). Intuitively, the matrix is bigger (by a factor of <italic>n</italic><sub><italic>o</italic></sub> in both dimensions) as we are now simultaneously tracking relative position to each observation, rather than abstract task position. Adding a memory to a slot is simple. Feed-forward weights can direct observations directly to the input slot (e.g., <xref ref-type="fig" rid="F1">Figure 1A</xref> right). The memory is then passed from slot to slot, controlled by velocity. When memories reach the output slot, it can influence immediate behaviour. Thus, once learned, this solution requires no synaptic plasticity. Lastly, similar to the EM solution, the WM solution works in any basis (not just the one presented above).</p></sec><sec id="S7"><title>Memory slots unify episodic and working memory and yield a rich neural basis for WM cognitive maps</title><p id="P17">While both solutions use memory slots, they do so in conceptually and functionally different ways. In the WM solution, memory slots are structured neural subspaces, with memories for different observations stored in each neural subspace, and the contents of each subspace can be copied and shifted to other subspaces. In the EM solution, memory slots are in synaptic connections (each memory is stored in a subspace of the weights), with each memory statically remaining in its slot (subspace). The memory slots are also accessed differently. The EM solution uses flexible attention (via an RNN) to index ‘fixed’ memory slots (the weights don’t move), while the WM solution uses fixed attention (the readout weights) but has flexible memory slots (the contents can be copied and shifted by the RNN)<sup><xref ref-type="fn" rid="FN3">i</xref></sup>.</p><p id="P18">Interestingly, there is a striking representational difference between the WM and EM solutions. This difference arises because the RNN in the EM solution represents latent position alone (relative to some initial position), independent of sensory observations attached to any position in any problem or task. However, RNN neurons in the WM solution represent relative position <italic>from</italic> individual observations - a type of conjunctive representation of relative position <italic>and</italic> observations for every problem. In particular, the slot identity corresponds to a particular relative position from the agent’s current position (or more generally a particular sequence of action/velocities one could take in a structured environment), and the contents of that slot is the observation at that relative position. In other words, the contents of each slot indicates the correct counterfactual answer to the task <italic>if</italic> the slot’s corresponding action <italic>were</italic> taken. For example, in the simple case of <xref ref-type="fig" rid="F1">Figure 1A</xref>, third column, Slot 1, aligned with the input/readout weights, contains the correct answer to the prediction task if no action were taken. And Slot 2 and 3 contain the correct counterfactual predictions if the agent <italic>were</italic> to go back one or two positions respectively. Every time the agent takes an actual action, the correct counterfactual prediction associated with each slot necessarily changes, and so the WM RNN must update the contents of very slot by appropriately copying and shifting their contents through the recurrent weights. Because of this dynamic update, at any given time, the entire WM representation acts like a cognitive map that can <italic>simultaneously</italic> answer 3 counterfactual questions (what observation would I predict if went back 0, 1, or 2 positions) using decoders that attend to slots 1, 2, and 3, respectively. As the agent moves forward in position, the slot activity is shifted backwards correspondingly so that <italic>each</italic> slot always contains the correct answer its <italic>own</italic> action specific counterfactual question.</p><p id="P19">Moreover, in the simple case of <xref ref-type="fig" rid="F1">Figure 1A</xref>, third column, since each neuron in each slot is selective for a single observation, from a single neuron perspective, the neural code will consist of a collection of neurons that fire selectively for particular observations, at particular times since the observations were most recently encountered (or more generally for particular observations and particular relative positions / action sequences taken since the observation). Any single neuron’s relative position / action selectivity elegantly derives from the <italic>identity</italic> of the slot it is a part of, while that same neuron’s object selectivity derives from its functional role <italic>within</italic> its slot.</p><p id="P20">This fundamental difference between EM and WM solutions implies that single neurons behave very differently across tasks. In particular, any two EM position neurons that fire next to each other in one task, will fire next to each other in another task: they maintain their phase relationship (<xref ref-type="fig" rid="F1">Figure 1F</xref>; just like grid cells do). On the other hand, two activity slot neurons with a particular phase relationship in one task (<xref ref-type="fig" rid="F1">Figure 1G</xref>, top), may not have the same phase relationship in another task (<xref ref-type="fig" rid="F1">Figure 1G</xref>, bottom). This is because WM cells code for relative position (as defined by the slot’s intrinsic relative position to the input/readout slot) to a particular observation (as defined by the identity of the neuron within a slot). Since the pairing between positions and observations are shuffled between different problem realisations of a given common task, the relative phase between WM cells will also appear shuffled. Interestingly, as we will see below, this slot derived conjunctive coding of observations and actions, reflecting a cognitive map that can simultaneously answer many counterfactual questions contingent on different actions, can elegantly and succinctly account for a wide range of otherwise perplexing properties of rich prefrontal cortical representational dynamics, both <italic>in silico</italic> and <italic>in vivo</italic>.</p></sec></sec><sec id="S8"><title>Model architectures and task specifics</title><p id="P21">To experimentally test the predictions of the theory, namely that the EM system uses position representations whereas WM systems use activity slots, we use a variety of tasks and model architectures (full details in <xref ref-type="supplementary-material" rid="SD1">Appendix A.2</xref>).</p><sec id="S9"><title>Model architectures</title><p id="P22">We build both EM and WM neural network models (<xref ref-type="fig" rid="F2">Figure 2A,B</xref>). The key difference between the two models is that the EM model makes predictions by retrieving memories from an external memory system, whereas the WM model makes predictions with a learned readout matrix. For the EM external memory, we use a modern Hopfield network<sup><xref ref-type="bibr" rid="R35">35</xref></sup>, which our above theoretical results are derived from (<xref ref-type="supplementary-material" rid="SD1">Appendix A.1</xref>). Both models use an RNN to control memories. To be general, we use two RNN variants (<xref ref-type="fig" rid="F2">Figure 2C,D</xref>); one directly inspired by our theory that uses velocity dependent transition matrices (GroupRNN; related to selective state-space models<sup><xref ref-type="bibr" rid="R42">42</xref></sup>), and the other is a conventional RNN which receives velocity signals as input (RegularRNN). All model parameters are initialised randomly, and trained using backpropagation.</p></sec><sec id="S10"><title>Tasks</title><p id="P23">We consider four main tasks (<xref ref-type="supplementary-material" rid="SD1">Figure 8A</xref>) that are all related to the neuroscience and cognitive science literature (further neuroscience tasks are introduced later): Immediate Serial Recall (ISR), N-Back, 1D Navigation, and 2D Navigation. These tasks range in complexity from simple sequence repetition that requires no velocity integration to tasks where correct recall relies upon integration of progressively more complex velocity signals. In all tasks, observations, <bold><italic>o</italic></bold>, and velocity signals, <bold><italic>v</italic></bold> are provided at each timestep and the models are trained to predict a target, <bold><italic>t</italic></bold>, at each timestep. After observing the observation and velocity at timestep <italic>t</italic>, the model is asked to predict the target at timestep <italic>t</italic> + 1. An example problem sequence for the 1D Navigation task (a random walk on a loop; e.g., a 3-loop with observations 1, 3, and 2 at the three positions) is: <bold><italic>o</italic></bold> = {1, 3, 2, 2, 3, 1, 2, …}, <bold><italic>v</italic></bold> = {+1, +1, 0, − 1, −1, − 1, …} and <bold><italic>t</italic></bold> ={ −, −, −, 2, 3, 1, 2, …}. Here, ‘−’ means a target that we do not train on since it has not been observed before and therefore is not possible to predict. The ISR task is like 1D navigation but with constant forward velocity, the 2D navigation task is a 2D version of the 1D navigation task, and the N-Back task is a random observation sequence (with constant velocity signal) and the targets are observations N timesteps ago. For each task we train on multiple problem realisations corresponding to multiple sequences where position-observation pairings are randomised, but the underlying task structure of how actions affect positions (e.g., 1D Navigation) is fixed. See <xref ref-type="supplementary-material" rid="SD1">Appendix A.3</xref> for details on all tasks. It is important to note that the 1D and 2D navigation tasks (as well as some tasks later in this paper) involve more than just repeating the sequence exactly as it was presented and so cannot be solved without learning a cognitive map and correctly integrating velocity signals.</p></sec></sec></sec><sec id="S11" sec-type="results"><title>Results</title><sec id="S12"><title>Differences in EM and WM algorithm performance and representation</title><sec id="S13"><title>EM scales more favourably than WM</title><p id="P24">Our theory demonstrates that EM and WM systems implement the same computation (solve the same task) but use different underlying algorithms (their neural mechanism is different). These algorithms have different trade-offs. Most notably, the WM solution requires many more neurons than the EM solution (a factor of <italic>n</italic><sub><italic>o</italic></sub> more since each observation must be stored in neural activity). Thus we predict that, for a fixed neuron budget, the WM model performance will degrade when the number of memories needed to be stored, which we refer to as the task size, increases, while the EM model will continue to perform well. We demonstrate this phenomenon for the 1D navigation task (<xref ref-type="fig" rid="F2">Figure 2E</xref>) as well as the other tasks (GroupRNN: <xref ref-type="supplementary-material" rid="SD1">Figure 11A</xref>, RegularRNN: <xref ref-type="supplementary-material" rid="SD1">Figure 12A</xref>). Additionally, we observe performance improves when the WM RNN has more neurons, as predicted. Also, in both EM and WM models, we observe reduced performance in tasks with more action dimensions (e.g. 2D navigation versus ISR; <xref ref-type="supplementary-material" rid="SD1">Figures 11A, 12A</xref>), likely because more weights need to be precisely tuned with more action dimensions.</p></sec><sec id="S14"><title>EM uses position representations while WM uses activity slots</title><p id="P25">Our simple theory above predicts that even more potentially complex trained EM models should use position-like representations to index memories stored in synaptic weight slots (<xref ref-type="disp-formula" rid="FD1">equation 1</xref>), whereas trained WM models should store and manipulate memories in RNN activity slots (<xref ref-type="disp-formula" rid="FD2">equation 2</xref>). To test these predictions, we train linear decoders to decode positions and observations from the neural activity of trained models’ RNNs. Crucially, we avoid task over-fitting by training each decoder on many example tasks, rather than just one, demonstrating that the activity slots, or position representations, are generalisable across tasks.</p><p id="P26">First, our theory says abstract position (independent of object identity) should be decodeable from EM models, but not WM models, since EM models use position to index memories (<xref ref-type="fig" rid="F2">Figure 2F</xref>). We confirm this prediction in all tasks and for all RNN types (<xref ref-type="fig" rid="F2">Figures 2G</xref>, <xref ref-type="supplementary-material" rid="SD1">11B, 12B</xref>). This is consistent with existing EM models<sup><xref ref-type="bibr" rid="R4">4</xref>,<xref ref-type="bibr" rid="R14">14</xref></sup> that learn position codes to index hippocampal memories, as well as entorhinal data such as grid cells that code for position. We note, however, that position is often not decodable for large or small task sizes. For large sizes, it is easy to understand: the models were unable to learn the task and thus learned no sensible representation (<xref ref-type="fig" rid="F2">Figure 2E</xref>, <xref ref-type="supplementary-material" rid="SD1">11A, 12A</xref>). For small task sizes, the RNN in the EM model has learned to use another memory indexing representation, namely the WM solution. We discuss this case further in a later paragraph.</p><p id="P27">Second, our theory predicts that previous observations should be decodeable from the RNN in WM models, but not the EM models, since the RNN in WM models store memories of previous observations in neural activity (<xref ref-type="fig" rid="F2">Figure 2H</xref>) while RNN activity in EM models only tracks position, with memories of previous observations stored in synaptic connections. More precisely, our theory prescribes exactly which past observation is stored in which neural activity slot at any given time since it details how slot contents are copied and shifted (or more generally rotated) by the trained RNN connectivity in a manner that reflects the underlying structure of the task (i.e. how velocity signals change position) (<xref ref-type="supplementary-material" rid="SD1">Figure 8B,C</xref>). Thus, over time, the neural activity within each activity slot will encode a particular sequence of observations. Moreover, for tasks with varying velocity signals, this sequence will not be a simple temporally shifted copy of the input observations (<xref ref-type="fig" rid="F2">Figure 2H</xref>). We refer to this sequence, defined purely by the task structure, velocity signals and observations, as the slot-sequence for each predicted activity slot. We find that these specific slot-sequences can indeed be successfully decoded from RNN activity in all tasks for WM models (<xref ref-type="fig" rid="F2">Figures 2I</xref> left, 11C, 12C), whereas other highly natural past-sequences (e.g., the observation <italic>N</italic> steps ago) cannot be decoded (apart from the ISR and N-Back task where past-sequences and slot-sequences are identical; <xref ref-type="supplementary-material" rid="SD1">Figures 11C, 12C</xref>). Slot-sequence decoding performance degrades for larger task sizes, as the RNN fails to learn the task. Furthermore, for an example task size on each of our four tasks, we show high individual slot-sequence decoding for WM models (<xref ref-type="fig" rid="F2">Figures 2I</xref> right, <xref ref-type="supplementary-material" rid="SD1">11D, 12D</xref>). These results demonstrate that WM models learn activity slots, and they use velocity signals to copy and shift previous observations between slots: velocity signals control activity slots.</p><p id="P28">Interestingly, while the EM models have, as predicted, poor slot-sequence decoding and high abstract position decoding in most situations, for small task sizes the converse can be true (<xref ref-type="supplementary-material" rid="SD1">Figure 11G,I</xref>). This is because an activity slot representation can also be effective at indexing memories; like a position representation, activity slots uniquely code for each position in each task (however it does not code position the same way across tasks, hence we cannot decode <italic>abstract</italic> position from activity slots). We posit the WM solution is easier to learn and hence preferred when possible (i.e., when not limited by number of neurons), which intuitively makes sense as slot representations are a direct function of input data, while position representations are abstract.</p></sec></sec><sec id="S15"><title>Visualising slots &amp; slot algebra</title><sec id="S16"><title>Visualising slots without decoding</title><p id="P29">We have so far provided evidence, through decoding analyses, that WM models learn activity slots, as predicted by our theory. We focused on decoding analyses because learned activity slots will in general correspond to different neural activity subspaces, that are not necessarily aligned to single neuron axes; i.e. single neurons could exhibit mixed selectivity for multiple slots. To more directly visualise learned activity slots in an even simpler setting, we leverage a recent regularization technique<sup><xref ref-type="bibr" rid="R43">43</xref></sup> that encourages demixed representations in which single neurons code for single independent factors (e.g., in our case slots). In particular, we train models while enforcing RNN activity to be nonnegative (i.e., a ReLU activation function rather than linear or tanh) and energy efficient (i.e., minimum norm weights and activities).</p><p id="P30">With these constraints, single neurons do indeed participate only in a single slot (<xref ref-type="fig" rid="F3">Figure 3A</xref>). We quantify the degree to which single neurons code for individual slots, using the metric ‘mutual information ratio’ (MIR), a well grounded metric<sup><xref ref-type="bibr" rid="R43">43</xref>,<xref ref-type="bibr" rid="R44">44</xref></sup> where high values indicate demixed single neuron slot coding. We demonstrate MIR improves with the additional constraints across all four tasks and for both RNNs types (<xref ref-type="supplementary-material" rid="SD1">Figure 13</xref>; GroupRNN and RegularRNN; blue and orange colours).</p></sec><sec id="S17"><title>Slot algebra predicts relations between neural representations of different problems from a common task</title><p id="P31">To further demonstrate that RNNs learn activity slots, as well as show that activity slots permit compositional computations, we test another prediction of our theory: activity slot representations should obey a slot algebra, which predicts remarkable and simple linear relationships between WM representations corresponding to <italic>different</italic> problem realisations of the same underlying task. As an example, consider a task with 3 latent positions and 4 possible observations (<xref ref-type="fig" rid="F3">Figure 3B</xref>). Let <italic>Rep</italic><sub><italic>i</italic></sub>([<italic>a, b, c</italic>]) denote the entire WM RNN representation while the agent is at position <italic>i</italic> in a problem realisation with observations <italic>a, b, c</italic> paired at each of the 3 positions respectively<sup><xref ref-type="fn" rid="FN4">ii</xref></sup>. Now consider the neural representations for two problems, <italic>Rep</italic><sub><italic>i</italic></sub>([<xref ref-type="bibr" rid="R1">1</xref>, <xref ref-type="bibr" rid="R4">4</xref>, <xref ref-type="bibr" rid="R2">2</xref>]) and <italic>Rep</italic><sub><italic>i</italic></sub>([<xref ref-type="bibr" rid="R1">1</xref>, <xref ref-type="bibr" rid="R2">2</xref>, <xref ref-type="bibr" rid="R2">2</xref>]). These two problems differ only in that the observation 4 at position 2 is replaced with the observation 2. The replacement of one observation with another induces an action on neural representations yielding the slot algebra relation <italic>Rep</italic><sub><italic>i</italic></sub>([<xref ref-type="bibr" rid="R1">1</xref>, <xref ref-type="bibr" rid="R2">2</xref>, <xref ref-type="bibr" rid="R2">2</xref>]) = <italic>Rep</italic><sub><italic>i</italic></sub>([<xref ref-type="bibr" rid="R1">1</xref>, <xref ref-type="bibr" rid="R4">4</xref>, <xref ref-type="bibr" rid="R2">2</xref>]) − <italic>Rep</italic><sub><italic>i</italic></sub>([<italic>a</italic>, 4, <italic>c</italic>]) + <italic>Rep</italic><sub><italic>i</italic></sub>([<italic>a</italic>, 2, <italic>c</italic>]) (<xref ref-type="fig" rid="F3">Figure 3B</xref> illustrates this relation when the agent is at position <italic>i</italic> = 0). Here <italic>a</italic> and <italic>c</italic> in the middle two terms can be any observations; the key is that the algebraic relation corresponds to taking away observation 4 at position 2 via subtraction of neural representation <italic>Rep</italic><sub><italic>i</italic></sub>([<italic>a</italic>, 4, <italic>c</italic>], for any <italic>a</italic> and <italic>c</italic>, and replacing it with observation 2 via the addition of another representation <italic>Rep</italic><sub><italic>i</italic></sub>([<italic>a</italic>, 2, <italic>c</italic>]) with the <italic>same a</italic> and <italic>c</italic>. Critically, this equality should be true independent of the particular sequence/trajectory taken to position <italic>i</italic>.</p><p id="P32">To test whether our model representations obey slot algebra, we examine the WM RNN in situations that satisfy the equality relation above. Each relation involves neural representations from 4 separate runs of the RNN in 4 <italic>different</italic> problems. We sum the 3 representations according to the right hand side of the relation, and compare the sum to the measured representation on the left hand side using a squared difference measure (<italic>d</italic><sub>1−2+3−4</sub>). We then compare this measure to the squared difference of the first term on the left and the first term on the right (<italic>d</italic><sub>1−2</sub>) via the ratio <inline-formula><mml:math id="M6"><mml:mi>S</mml:mi><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:mn>3</mml:mn><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:mn>3</mml:mn><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:math></inline-formula> Low <italic>SA</italic> values indicate the representation obeys slot algebra.</p><p id="P33">The correctness of slot-algebra requires trajectory independent representations, that depend only on the current agent position independent of how the agent arrived at the position. However, not all methods of integrating velocity in neural networks are trajectory independent, with some attractor networks, both in biology<sup><xref ref-type="bibr" rid="R45">45</xref></sup> and models<sup><xref ref-type="bibr" rid="R46">46</xref></sup>, having velocity modulated neurons. Indeed it is possible to have a slot-based representation where slots are conjunctive with velocity. Thus, understanding whether neural representations obey slot-algebra, not only assesses compositionality, but is also informative of how the RNN integrates velocity. Here we test which RNNs obey slot-algebra<sup><xref ref-type="fn" rid="FN5">iii</xref></sup>. We test the GroupRNN which modulates synapses with velocity signals (and is the model analogue of our theory), the RegularRNN which adds velocity signals to its RNN activities, and, additionally, the BioRNN which integrates velocity signals in a separate neural population, but not the RNN activities themselves. As predicted, the GroupRNN has low <italic>SA</italic> for all datasets (<xref ref-type="fig" rid="F3">Figure 3C</xref>) since velocity does not directly modulate RNN activity. <italic>SA</italic> further improves with additional regularisation (KL) that further encourages representations to be consistent across timesteps, i.e., trajectory independent (see <xref ref-type="supplementary-material" rid="SD1">Appendix</xref> for details). Conversely, as predicted, the RegularRNN only achieves low <italic>SA</italic> on the ISR dataset which requires no velocity signal (see <xref ref-type="supplementary-material" rid="SD1">Figure 10</xref> for another RegularRNN variant which exhibits the same phenomena). Lastly, the BioRNN achieves low <italic>SA</italic> for all datasets. Intriguingly the architecture of the BioRNN is closely related to the neural circuit discovered in the fly head direction system<sup><xref ref-type="bibr" rid="R47">47</xref>–<xref ref-type="bibr" rid="R49">49</xref></sup> (<xref ref-type="supplementary-material" rid="SD1">Figure 7E,F</xref>; details in <xref ref-type="supplementary-material" rid="SD1">Appendix A.2</xref>).</p></sec></sec><sec id="S18"><title>Activity slots controlled by velocity signals provide a unifying framework for diverse PFC representational dynamics</title><p id="P34">We have shown that our theory of controllable WM activity slots explains representations that emerge in artificial RNNs trained on structured sequence memory and prediction tasks. The implication of this is that any task where latent positions are linked through action induced transitions can be optimally navigated using WM controllable activity slots. This, however, relies on the appropriate integration of velocity signals. A key question that remains is what are these velocity signals, and how are they represented in neurons? In this section, we demonstrate that PFC-dependent sequential memory tasks and cued memory tasks can be unified through activity slots, but where the distinguishing feature is the velocity signal that controls activity slots.</p><sec id="S19"><title>PFC and RNNs compute and represent velocity signals</title><p id="P35">In previous tasks, we directly provided velocity signals to the model (thus specifying its representation). However, actual brains do not have this luxury; they must compute velocity signals from lower level sensory inputs and choose how to represent them. In spatial tasks, self-movement vectors are thought to be computed from vestibular or other sensory inputs and represented using head direction cells<sup><xref ref-type="bibr" rid="R50">50</xref></sup> and speed cells<sup><xref ref-type="bibr" rid="R45">45</xref></sup>. For complex PFC tasks, where behaviour may be non-spatial, it is unknown what the velocity signals are, or how they are represented.</p><p id="P36">Recent neural data however, while not demonstrating velocity signals, have found neurons that track progress to goals, invariant to the actual distance to the goal<sup><xref ref-type="bibr" rid="R30">30</xref>,<xref ref-type="bibr" rid="R51">51</xref></sup>. For example a 50% ‘progress cell’ fires at the midpoint between two goals whether they are 3 steps apart or 20. In order to update progress, we contend ‘progress-velocity’ signals must be computed and represented. To test for this, we train WM models on analogous tasks, but to be general and illustrate the principles of working memory, we remove the spatial component to these tasks.</p><p id="P37">In particular, Basu et al.<sup><xref ref-type="bibr" rid="R51">51</xref></sup> trained rodents to run back and forth between two (of 9) reward ports, and El-Gaby et al.<sup><xref ref-type="bibr" rid="R30">30</xref></sup> trained rodents to repeatedly visit 4 (of 9) spatially located reward ports in sequence. In both studies, the animals are trained on many problem realisations with random goal positions. We model these tasks (modulo the spatial component), as a 2-ISR and a 4-ISR task, but with delays between each observation (<xref ref-type="fig" rid="F4">Figure 4A,E</xref> left; just like the ‘delay’ of travelling between two spatial goals). Critically, while the delays are random across different problem realisations of each task, the delays are the <italic>same</italic> on each loop on every problem. In a spatial context, this is analogous to how distances between goals are the same on a particular task, but change for different goal positions on new problem realisations of the task. For example, possible 2-ISR delay sequences for different problem realisations are [4, *, *, 2, *, *, 4, *, *, 2, …] or [1, *, 3, *, 1, *, 3, …] where is the common delay observation (that also must be predicted), and possible 4-ISR delay sequences are [4, *, 2, *, *, 2, *, 6, 4, *, 2, *, *, 2, *, 6, 4, …] or [1, 3, *, 8, *, 2, 1, 3, *, 8, *, 2, 1, …]. We provide no explicit velocity signal, and so the model will have to utilise the sparse inputs to compute an appropriate progress-velocity for each delay period, and remember it on returning to that same delay (i.e., after0020one full loop of experience).</p><p id="P38">Indeed, after training WM models on these tasks, we are able to decode progress, as well as progress-velocity (<xref ref-type="fig" rid="F4">Figures 4A,E</xref> right). Furthermore, we observe progress tuning at the single neuron level (<xref ref-type="fig" rid="F4">Figure 4B,F</xref>), as well as progress-velocity tuned neurons (<xref ref-type="supplementary-material" rid="SD1">Figures 15A</xref>, <xref ref-type="supplementary-material" rid="SD1">16A</xref>). This means the network internally computed progress-velocity, on the basis of sparse inputs, to overcome the different delays. The question remains; how does this relate to activity slots?</p></sec><sec id="S20"><title>Controlling activity slots with progress-velocity</title><p id="P39">We posit that activity slots get structured by both task and progress (examples for the 2-ISR delay task shown in <xref ref-type="fig" rid="F4">Figures 4C</xref>, <xref ref-type="bibr" rid="R9">9</xref>), in that the slots are organised by task-progress on a loop. This means a slot will now code for 25% since observation, or 150% since observation (up to 200/400% since for the 2/4-ISR delay task). We refer to this as ‘task-progress’ structured (<xref ref-type="fig" rid="F4">Figure 4C</xref>). The contents of these slots are copied and shifted to subsequent slots by the progress-velocity signal<sup><xref ref-type="fn" rid="FN6">iv</xref></sup>. Indeed, in trained WM models, we are able to decode task-progress activity slots (<xref ref-type="fig" rid="F4">Figure 4A,E</xref> right), and we observe ‘task-progress slot’ neurons in <xref ref-type="fig" rid="F4">Figure 4D,G</xref>; these neurons always fire at the same task progress after a preferred observation (e.g., 375% after observation 5; <xref ref-type="fig" rid="F4">Figure 4G</xref> bottom). Further cellular examples are shown in <xref ref-type="supplementary-material" rid="SD1">Figures 15</xref>, <xref ref-type="supplementary-material" rid="SD1">16</xref>. It is of particular note that both ‘progress’ and ‘task-progress slot’ neurons were recently recorded in rodent mPFC<sup><xref ref-type="bibr" rid="R30">30</xref></sup>, exactly as our model predicts.</p><p id="P40">While representing progress and progress-velocity seems an esoteric choice of representation, it is not clear how activity slot representations could solve this task without representing progress-velocity. For example, it is not possible to have an activity slot for each step of the delay period as this cannot be placed in a consistent loop structure different problem realisations of a task. In general, when behaviour (e.g., navigating to goals or waiting for delays) is structured in different coordinates to the underlying space where actions are taken (e.g., physical space or a loop), a coordinate transformation is required to match the two spaces. This is exactly what the progress, and progress-velocity, neurons are doing: transforming from spatial coordinates to task coordinates.</p></sec><sec id="S21"><title>PFC activity slots in a task with constant velocity</title><p id="P41">Our activity slot theory also accounts for PFC representations in standard sequence memory tasks where only a constant velocity is required. For example, Xie et al.<sup><xref ref-type="bibr" rid="R29">29</xref></sup> recorded PFC neurons in an ISR task. Here, monkeys were shown a sequence of three spatial positions on a screen (out of 6 positions), and, were trained to saccade to the same objects in order (<xref ref-type="fig" rid="F5">Figure 5A</xref>). Importantly, the monkeys were trained on many such sequences (i.e., just like our ISR task). Neural activity in the delay period decomposed into three successive orthogonal subspaces. Each of the 6 possible spatial saccade locations could be represented in each of the 3 subspaces, with the first/second/third saccade location encoded in the first/second/third subspace (<xref ref-type="fig" rid="F5">Figure 5B-C</xref>). These 3 sequential subspaces therefore directly correspond to our activity slots, with a different slot for the first, second and third ordinal points in the sequence (<xref ref-type="fig" rid="F5">Figure 5D</xref> bottom is after delay period). Indeed, a WM RegularRNN on trained the task, exhibits exactly the same subspace decomposition (<xref ref-type="fig" rid="F5">Figure 5E-F</xref>).</p></sec><sec id="S22"><title>Controlling PFC activity slots in a cue-dependent memory retrieval task</title><p id="P42">So far we have considered either external or internally generated velocity signals. But sensory observations themselves can also serve as velocity signals. Here we show that sensory cues can be understood as velocity signals controlling PFC activity slots, in a particular study of cue-dependent memory retrieval<sup><xref ref-type="bibr" rid="R33">33</xref></sup>. In this study, Panichello &amp; Buschman<sup><xref ref-type="bibr" rid="R33">33</xref></sup> recorded PFC neurons in monkeys performing a working memory task where two colours are presented on a screen, one at the top and one at the bottom. Then, after a delay with a blank screen, a cue informs the monkey whether to report the colour of the top or bottom colour (<xref ref-type="fig" rid="F6">Figure 6A</xref>). Importantly, each problem realisation is a random combination of two colours and cue. Neural activity in the delay period decomposed into two orthogonal subspaces, one for the top colour and one for the bottom (<xref ref-type="fig" rid="F6">Figure 6B</xref>, left). Thus, each colour can be represented in one of two subspaces, depending on whether it was presented at the top or bottom. After the cue, the subspaces rotate so that top (when correct) and bottom (when correct) subspaces are parallel to one another (<xref ref-type="fig" rid="F6">Figure 6B</xref>, right; <xref ref-type="fig" rid="F6">Figure 6C</xref>). This is easily understood with our theory (<xref ref-type="fig" rid="F6">Figure 6D</xref>); the initial two subspaces are two different activity slots, one for the top colour and one for the bottom colour. Since only one slot can be readout from, the cue can be understood as a velocity signal that controls how slot contents are shifted to the readout slot. Because either the top or bottom colour is moved (controlled by the cue (e.g. velocity) signal) to the same readout slot on correct trials, the subspaces become parallel to one another after the cue on correct trials (<xref ref-type="fig" rid="F6">Figure 6D</xref>, bottom). Indeed, a WM RegularRNN trained on the task, exhibits exactly the same subspace decomposition and dynamics (<xref ref-type="fig" rid="F6">Figure 6E-G</xref>).</p></sec></sec></sec><sec id="S23" sec-type="discussion"><title>Discussion</title><p id="P43">In this work, we derived a formal relationship between the algorithms and representations of episodic and working sequence memory, and empirically validated theoretical predictions that EM utilises more abstract position-like representations while WM uses activity slot representations with a particular and systematic conjunctive coding of observations and (counterfactual) actions. Furthermore, we show that, like the HPC EM system, the PFC WM system can be updated and controlled by velocity signals, which can be flexibly computed from sparse input data. We used our theory of controllable activity slots to show that recordings from several different PFC studies - from serial recall to cue dependent recall and spatial working memory - are all explained in a unified framework of activity slots controlled by velocity signals.</p><p id="P44">Intriguingly, our activity slot theory may also explain PFC data from non-explicit working memory tasks. For example, human mPFC (fMRI) activity obeys rules of ‘scene algebra’ when humans perform scene construction tasks involving one object above another<sup><xref ref-type="bibr" rid="R52">52</xref></sup>, i.e., <inline-formula><mml:math id="M7"><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:math></inline-formula> where <inline-formula><mml:math id="M8"><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:math></inline-formula> denotes the representation of object <italic>a</italic> above object <italic>b</italic>. This suggests that the objects are stored in different neural subspaces depending on their spatial location, analogous to our theory of activity slots which organise objects depending on their (e.g. spatial) relationships. This is perhaps no surprise since both our and their task require a compositional understanding (objects can be in any sequence or spatial configuration respectively). We anticipate a slot based understanding will offer further insights into representations in frontal cortex, beyond just working memory. For example, activity slots could represent sub-goals for sequential goal directed planning<sup><xref ref-type="bibr" rid="R30">30</xref></sup>. Each slot would hold a sub-goal, with the sub-goals cycled forward when the previous sub-goal is achieved. This could offer an explanation as to why the same brain region involved in working memory, is also implicated in value based decision making and goal directed planning<sup><xref ref-type="bibr" rid="R31">31</xref>,<xref ref-type="bibr" rid="R53">53</xref></sup>, and why there are goal predictive representations in PFC (recall neurons in activity slots conjunctively encode different degrees of distance/progress to various observations/goals). In this vein, it is of note that slot based models are used in machine learning in diverse settings from natural language<sup><xref ref-type="bibr" rid="R6">6</xref></sup>, to planning<sup><xref ref-type="bibr" rid="R54">54</xref></sup> and scene construction<sup><xref ref-type="bibr" rid="R55">55</xref>,<xref ref-type="bibr" rid="R56">56</xref></sup>.</p><p id="P45">We related the two algorithms to HPC and PFC, however the key distinction between the algorithms is whether memories are stored in synaptic strengths or neural activity patterns. It is plausible that PFC could utilise short term plasticity to store memories in synapses as well as neurons. Indeed, recent modelling work suggests short term plasticity may better explain PFC activity as compared to recurrent dynamics<sup><xref ref-type="bibr" rid="R57">57</xref></sup>. Conversely, because of the intimate connectivity between entorhinal cortex and hippocampus (compared to the more distant connectivity between PFC and hippocampus), it makes sense for entorhinal cortex to control hippocampal synaptic memories using position-like representations as opposed to activity slots.</p><p id="P46">We do not claim to have solved the representations of RNNs on all working memory tasks. Indeed there are WM tasks in which activity slots are not learned (e.g., <xref ref-type="supplementary-material" rid="SD1">Figure 14A-B</xref>). However, we suggest that activity slots are a general solution to sequence working memory tasks, but in some circumstances there may be other bespoke RNN solutions that get learned instead. Lastly, we note that our formalism, as well as the GroupRNN, is a state-space model (these models have gained considerable attention recently<sup><xref ref-type="bibr" rid="R42">42</xref></sup>), thus, on the machine learning side, our work offers a relationship between the learned representations of state-space models, RNNs, and transformer neural networks.</p><p id="P47">The hippocampal and frontal systems are thought to be essential in mediating higher order cognition, with patients exhibiting profound deficits in behavioural flexibility if these structures are damaged<sup><xref ref-type="bibr" rid="R10">10</xref>,<xref ref-type="bibr" rid="R11">11</xref></sup>. While these systems have been the subject of intense study over the last several decades - both experimentally and theoretically - the systems have been largely treated independently and their respective cellular representations are hard to reconcile. Our work brings together these systems by showing that the algorithms and representations of frontal working memory and temporal episodic memory are two sides of the same coin.</p></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Appendix</label><media xlink:href="EMS190634-supplement-Appendix.pdf" mimetype="application" mime-subtype="pdf" id="d32aAdDbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S24"><title>Acknowledgements</title><p>We thank Kris Jensen and Jo Warren for helpful feedback on the manuscript. We thank the following funding sources: Sir Henry Wellcome Postdoctoral Fellowship (222817/Z/21/Z) to JCRW.; the Gatsby Charitable Foundation to WD.; Wellcome Principal Research Fellowship (219525/Z/19/Z), Wellcome Collaborator award (214314/Z/18/Z), and Jean-François and Marie-Laure de Clermont-Tonnerre Foundation award (JSMF220020372) to TEJB.; the Wellcome Centre for Integrative Neuroimaging is supported by core funding from the Wellcome Trust (203139/Z/16/Z); the James S. McDonnell, Simons Foundations, NTT Research, and an NSF CAREER Award to SG.</p></ack><sec id="S25" sec-type="data-availability"><title>Data availability</title><p id="P48">No data was generated in this paper..</p></sec><sec id="S26" sec-type="data-availability"><title>Code availability</title><p id="P49">Python and Pytorch code will be made available on publication.</p></sec><fn-group><fn id="FN1" fn-type="con"><p id="P50"><bold>Author Contributions</bold></p><p id="P51">JCRW conceptualised the study in conversations with WD, TEJB, SG, ME. JCRW developed theory and performed simulations. JCRW wrote the manuscript with input from WD, TEJB, SG, ME.</p></fn><fn id="FN2" fn-type="conflict"><p id="P52"><bold>Competing interests</bold></p><p id="P53">The authors declare no competing interests.</p></fn><fn id="FN3"><label>i</label><p id="P54">We note that our proposed WM activity slot solution may not the universal solution to all WM tasks. However we contend that for tasks involving non-trivial velocity signals, it is the solution neural networks learn, as evidenced by our subsequent simulations. See Discussion for further consideration.</p></fn><fn id="FN4"><label>ii</label><p id="P55">It is important to consider each agent position <italic>i</italic> individually, since activity slot representations change from agent position to position.</p></fn><fn id="FN5"><label>iii</label><p id="P56">We do not use the n-back dataset as there is no repetition of veridical position.</p></fn><fn id="FN6"><label>iv</label><p id="P57">While these task-progress slots will now be continuous rather than discrete, with bumps of activity on continuous attractor manifolds now defining an observation within a ‘slot’, for consistency we still speak about them as if they were discrete.</p></fn></fn-group><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stachenfeld</surname><given-names>KL</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name></person-group><article-title>The hippocampus as a predictive map</article-title><source>Nat Neurosci</source><year>2017</year><volume>20</volume><fpage>1643</fpage><lpage>1653</lpage><comment>ISBN: 9788578110796 _eprint: arXiv:1011.1669v3</comment><pub-id pub-id-type="pmid">28967910</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Buzsáki</surname><given-names>G</given-names></name><name><surname>Tingley</surname><given-names>D</given-names></name></person-group><article-title>Space and Time: The Hippocampus as a Sequence Generator</article-title><source>Trends Cogn Sci</source><publisher-name>Elsevier Ltd</publisher-name><year>2018</year><volume>22</volume><fpage>853</fpage><lpage>869</lpage><comment>ISBN: 0471140864</comment><pub-id pub-id-type="pmcid">PMC6166479</pub-id><pub-id pub-id-type="pmid">30266146</pub-id><pub-id pub-id-type="doi">10.1016/j.tics.2018.07.006</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><article-title>Improving Generalization for Temporal Difference Learning: The Successor Representation</article-title><source>Neural Comput</source><year>1993</year><volume>5</volume><fpage>613</fpage><lpage>624</lpage><pub-id pub-id-type="doi">10.1162/neco.1993.5.4.613</pub-id></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Whittington</surname><given-names>JCR</given-names></name><etal/></person-group><article-title>The Tolman-Eichenbaum Machine: Unifying Space and Relational Memory through Generalization in the Hippocampal Formation</article-title><source>Cell</source><publisher-name>Elsevier Inc</publisher-name><year>2020</year><volume>183</volume><fpage>1249</fpage><lpage>1263</lpage><elocation-id>e23</elocation-id><pub-id pub-id-type="pmcid">PMC7707106</pub-id><pub-id pub-id-type="pmid">33181068</pub-id><pub-id pub-id-type="doi">10.1016/j.cell.2020.10.024</pub-id></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raju</surname><given-names>RV</given-names></name><name><surname>Guntupalli</surname><given-names>JS</given-names></name><name><surname>Zhou</surname><given-names>G</given-names></name><name><surname>Lázaro-Gredilla</surname><given-names>M</given-names></name><name><surname>George</surname><given-names>D</given-names></name></person-group><article-title>Space is a latent sequence: Structured sequence learning as a unified theory of representation in the hippocampus</article-title><year>2022</year></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vaswani</surname><given-names>A</given-names></name><etal/></person-group><article-title>Attention is all you need</article-title><source>Adv Neural Inf Process Syst</source><year>2017</year><volume>2017-Decem</volume><fpage>5999</fpage><lpage>6009</lpage><comment>_eprint: 1706.03762</comment></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tolman</surname><given-names>EC</given-names></name></person-group><article-title>Cognitive maps in rats and men</article-title><source>Psychol Rev</source><year>1948</year><volume>55</volume><fpage>189</fpage><lpage>208</lpage><comment>_eprint: h0054651</comment><pub-id pub-id-type="pmid">18870876</pub-id></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Kumaran</surname><given-names>D</given-names></name><name><surname>Vann</surname><given-names>SD</given-names></name><name><surname>Maguire</surname><given-names>EA</given-names></name></person-group><article-title>Patients with hippocampal amnesia cannot imagine new experiences</article-title><source>Proc Natl Acad Sci</source><year>2007</year><volume>104</volume><fpage>1726</fpage><lpage>1731</lpage><comment>_eprint: 1011.1669.v3</comment><pub-id pub-id-type="pmcid">PMC1773058</pub-id><pub-id pub-id-type="pmid">17229836</pub-id><pub-id pub-id-type="doi">10.1073/pnas.0610561104</pub-id></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fuster</surname><given-names>JM</given-names></name><name><surname>Alexander</surname><given-names>GE</given-names></name></person-group><article-title>Neuron activity related to short-term memory</article-title><source>Sci (New York, NY)</source><year>1971</year><volume>173</volume><fpage>652</fpage><lpage>654</lpage><pub-id pub-id-type="pmid">4998337</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bauer</surname><given-names>RH</given-names></name><name><surname>Fuster</surname><given-names>JM</given-names></name></person-group><article-title>Delayed-matching and delayed-response deficit from cooling dorsolateral prefrontal cortex in monkeys</article-title><source>J Comp Physiol Psychol</source><year>1976</year><volume>90</volume><fpage>293</fpage><lpage>302</lpage><pub-id pub-id-type="pmid">819472</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Funahashi</surname><given-names>S</given-names></name><name><surname>Chafee</surname><given-names>MV</given-names></name><name><surname>Goldman-Rakic</surname><given-names>PS</given-names></name></person-group><article-title>Prefrontal neuronal activity in rhesus monkeys performing a delayed anti-saccade task</article-title><source>Nature</source><year>1993</year><volume>365</volume><fpage>753</fpage><lpage>756</lpage><pub-id pub-id-type="pmid">8413653</pub-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Behrens</surname><given-names>TEJ</given-names></name><etal/></person-group><article-title>What Is a Cognitive Map? Organizing Knowledge for Flexible Behavior</article-title><source>Neuron</source><publisher-name>Elsevier Inc</publisher-name><year>2018</year><volume>100</volume><fpage>490</fpage><lpage>509</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.10.002</pub-id></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Whittington</surname><given-names>JCR</given-names></name><name><surname>McCaffary</surname><given-names>D</given-names></name><name><surname>Bakermans</surname><given-names>JJW</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name></person-group><article-title>How to build a cognitive map</article-title><source>Nat Neurosci</source><publisher-name>Nature Publishing Group</publisher-name><year>2022</year><fpage>1</fpage><lpage>16</lpage><pub-id pub-id-type="pmid">36163284</pub-id></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uria</surname><given-names>B</given-names></name><etal/></person-group><article-title>A model of egocentric to allocentric understanding in mammalian brains Tech Rep</article-title><source>bioRxiv</source><year>2022</year><comment>Section: New Results Type: article</comment><pub-id pub-id-type="doi">10.1101/2020.11.11.378141</pub-id></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hebb</surname><given-names>DO</given-names></name></person-group><source>The Organization of Behavior; A Neuropsychological Theory</source><publisher-name>Wiley and Sons</publisher-name><publisher-loc>New York</publisher-loc><year>1949</year></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hopfield</surname><given-names>JJ</given-names></name></person-group><article-title>Neural networks and physical systems with emergent collective computational abilities (associative memory/parallel processing/categorization/content-addressable memory/fail-soft devices)</article-title><source>Biophysics</source><year>1982</year><volume>79</volume><fpage>2554</fpage><lpage>2558</lpage><pub-id pub-id-type="pmcid">PMC346238</pub-id><pub-id pub-id-type="pmid">6953413</pub-id><pub-id pub-id-type="doi">10.1073/pnas.79.8.2554</pub-id></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Nadel</surname><given-names>L</given-names></name></person-group><source>The Hippocampus as a Cognitive Map</source><publisher-name>Oxford University Press</publisher-name><year>1978</year><comment>ISSN: 0946-2716</comment></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deshmukh</surname><given-names>SS</given-names></name><name><surname>Knierim</surname><given-names>JJ</given-names></name></person-group><article-title>Influence of local objects on hippocampal representations: Landmark vectors and memory</article-title><source>Hippocampus</source><year>2013</year><volume>23</volume><fpage>253</fpage><lpage>67</lpage><pub-id pub-id-type="pmcid">PMC3869706</pub-id><pub-id pub-id-type="pmid">23447419</pub-id><pub-id pub-id-type="doi">10.1002/hipo.22101</pub-id></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wood</surname><given-names>ER</given-names></name><name><surname>Dudchenko</surname><given-names>PA</given-names></name><name><surname>Robitsek</surname><given-names>RJ</given-names></name><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><article-title>Hippocampal neurons encode information about different types of memory episodes occurring in the same location</article-title><source>Neuron</source><year>2000</year><volume>27</volume><fpage>623</fpage><lpage>633</lpage><pub-id pub-id-type="pmid">11055443</pub-id></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hafting</surname><given-names>T</given-names></name><name><surname>Fyhn</surname><given-names>M</given-names></name><name><surname>Molden</surname><given-names>S</given-names></name><name><surname>Moser</surname><given-names>M-bB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><article-title>Microstructure of a spatial map in the entorhinal cortex</article-title><source>Nature</source><year>2005</year><volume>436</volume><fpage>801</fpage><lpage>806</lpage><pub-id pub-id-type="pmid">15965463</pub-id></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Høydal</surname><given-names>A</given-names></name><name><surname>Skytøen</surname><given-names>ER</given-names></name><name><surname>Andersson</surname><given-names>SO</given-names></name><name><surname>Moser</surname><given-names>M-B</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><article-title>Object-vector coding in the medial ntorhinal cortex</article-title><source>Nature</source><year>2019</year><volume>568</volume><fpage>400</fpage><lpage>404</lpage><pub-id pub-id-type="pmid">30944479</pub-id></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Solstad</surname><given-names>T</given-names></name><name><surname>Boccara</surname><given-names>CN</given-names></name><name><surname>Kropff</surname><given-names>E</given-names></name><name><surname>Moser</surname><given-names>M-B</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><article-title>Representation of Geometric Borders in the Entorhinal Cortex</article-title><source>Science</source><year>2008</year><volume>322</volume><fpage>1865</fpage><lpage>1868</lpage><comment>_eprint: NIHMS150003</comment><pub-id pub-id-type="pmid">19095945</pub-id></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Constantinescu</surname><given-names>AO</given-names></name></person-group><source>Neural mechanisms underlying advanced cognition in humans</source><publisher-name>PhD Thesis, Oxford University</publisher-name><year>2017</year></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bongioanni</surname><given-names>A</given-names></name><etal/></person-group><article-title>Activation and disruption of a neural mechanism for novel choice in monkeys</article-title><source>Nature</source><publisher-name>Springer US</publisher-name><year>2021</year><volume>591</volume><fpage>270</fpage><lpage>274</lpage><pub-id pub-id-type="pmcid">PMC7116896</pub-id><pub-id pub-id-type="pmid">33408410</pub-id><pub-id pub-id-type="doi">10.1038/s41586-020-03115-5</pub-id></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Aronov</surname><given-names>D</given-names></name><name><surname>Nevers</surname><given-names>R</given-names></name><name><surname>Tank</surname><given-names>DW</given-names></name></person-group><article-title>Mapping of a non-spatial dimension by the hippocampal–entorhinal circuit</article-title><source>Nature</source><publisher-name>Nature Publishing Group</publisher-name><year>2017</year><volume>543</volume><fpage>719</fpage><lpage>722</lpage><pub-id pub-id-type="pmcid">PMC5492514</pub-id><pub-id pub-id-type="pmid">28358077</pub-id><pub-id pub-id-type="doi">10.1038/nature21692</pub-id></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burgess</surname><given-names>N</given-names></name><name><surname>Hitch</surname><given-names>GJ</given-names></name></person-group><article-title>Memory for serial order: A network model of the phonological loop and its timing</article-title><source>Psychol Rev</source><year>1999</year><volume>106</volume><fpage>551</fpage><lpage>581</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.106.3.551</pub-id></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Botvinick</surname><given-names>MM</given-names></name><name><surname>Plaut</surname><given-names>DC</given-names></name></person-group><article-title>Short-term memory for serial order: A recurrent neural network model</article-title><source>Psychol Rev</source><year>2006</year><volume>113</volume><fpage>201</fpage><lpage>233</lpage><pub-id pub-id-type="pmid">16637760</pub-id></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ganguli</surname><given-names>S</given-names></name><name><surname>Huh</surname><given-names>D</given-names></name><name><surname>Sompolinsky</surname><given-names>H</given-names></name></person-group><article-title>Memory traces in dynamical systems</article-title><source>Proc Natl Acad Sci</source><publisher-name>Proceedings of the National Academy of Sciences</publisher-name><year>2008</year><volume>105</volume><fpage>18970</fpage><lpage>18975</lpage><pub-id pub-id-type="pmcid">PMC2596211</pub-id><pub-id pub-id-type="pmid">19020074</pub-id><pub-id pub-id-type="doi">10.1073/pnas.0804451105</pub-id></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xie</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Geometry of sequence working memory in macaque prefrontal cortex</article-title><source>Science</source><year>2022</year><volume>375</volume><fpage>632</fpage><lpage>639</lpage><pub-id pub-id-type="pmid">35143322</pub-id></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>El-Gaby</surname><given-names>M</given-names></name><etal/></person-group><article-title>A Cellular Basis for Mapping Behavioural Structure</article-title><year>2023</year><elocation-id>2023.11.04.565609</elocation-id><comment>Section: New Results</comment><pub-id pub-id-type="doi">10.1101/2023.11.04.565609</pub-id></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><article-title>An Integrative Theory of Prefrontal Cortex Function</article-title><source>Annu Rev Neurosci</source><year>2001</year><volume>24</volume><fpage>167</fpage><lpage>202</lpage><pub-id pub-id-type="pmid">11283309</pub-id></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Postle</surname><given-names>BR</given-names></name></person-group><article-title>Working Memory as an Emergent Property of the Mind and Brain</article-title><source>Neuroscience</source><year>2006</year><volume>139</volume><fpage>23</fpage><lpage>38</lpage><pub-id pub-id-type="pmcid">PMC1428794</pub-id><pub-id pub-id-type="pmid">16324795</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroscience.2005.06.005</pub-id></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Panichello</surname><given-names>MF</given-names></name><name><surname>Buschman</surname><given-names>TJ</given-names></name></person-group><article-title>Shared mechanisms underlie the control of working memory and attention</article-title><source>Nature</source><publisher-name>Springer US</publisher-name><year>2021</year><volume>4</volume><pub-id pub-id-type="pmcid">PMC8223505</pub-id><pub-id pub-id-type="pmid">33790467</pub-id><pub-id pub-id-type="doi">10.1038/s41586-021-03390-w</pub-id></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krotov</surname><given-names>D</given-names></name><name><surname>Hopfield</surname><given-names>J</given-names></name></person-group><article-title>Large Associative Memory Problem in Neurobiology and Machine Learning</article-title><source>arXiv preprint</source><year>2020</year><fpage>1</fpage><lpage>12</lpage><comment>_eprint: 2008.06996</comment></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramsauer</surname><given-names>H</given-names></name><etal/></person-group><article-title>Hopfield networks is all you need</article-title><source>arXiv preprint</source><year>2020</year><comment>_eprint: 2008.02217</comment></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Whittington</surname><given-names>JCR</given-names></name><name><surname>Warren</surname><given-names>J</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name></person-group><source>Relating transformers to models and neural representations of the hippocampal formation</source><conf-name>Int Conf on Learn Represent</conf-name><year>2021</year></element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Katharopoulos</surname><given-names>A</given-names></name><name><surname>Vyas</surname><given-names>A</given-names></name><name><surname>Pappas</surname><given-names>N</given-names></name><name><surname>Fleuret</surname><given-names>F</given-names></name></person-group><article-title>Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention</article-title><source>ArXiv:2006.16236 [cs, stat]</source><year>2020</year></element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Retentive Network: A Successor to Transformer for Large Language Models</article-title><source>ArXiv:2307.08621 [cs]</source><year>2023</year></element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Baddeley</surname><given-names>AD</given-names></name><name><surname>Hitch</surname><given-names>G</given-names></name></person-group><chapter-title>Working Memory</chapter-title><person-group person-group-type="editor"><name><surname>Bower</surname><given-names>GH</given-names></name></person-group><source>Psychology of Learning and Motivation</source><publisher-name>Academic Press</publisher-name><year>1974</year><volume>8</volume><fpage>47</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1016/S0079-7421(08)60452-1</pub-id></element-citation></ref><ref id="R40"><label>40</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Dorrell</surname><given-names>W</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Whittington</surname><given-names>JCR</given-names></name></person-group><source>Actionable Neural Representations: Grid Cells from Minimal Constraints</source><conf-name>Int Conf on Learn Represent</conf-name><year>2023</year></element-citation></ref><ref id="R41"><label>41</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Stokes</surname><given-names>MG</given-names></name></person-group><article-title>‘Activity-silent’ working memory in prefrontal cortex: a dynamic coding framework</article-title><source>Trends Cogn Sci</source><publisher-name>Elsevier</publisher-name><year>2015</year><volume>19</volume><fpage>394</fpage><lpage>405</lpage><pub-id pub-id-type="pmcid">PMC4509720</pub-id><pub-id pub-id-type="pmid">26051384</pub-id><pub-id pub-id-type="doi">10.1016/j.tics.2015.05.004</pub-id></element-citation></ref><ref id="R42"><label>42</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gu</surname><given-names>A</given-names></name><name><surname>Dao</surname><given-names>T</given-names></name></person-group><article-title>Mamba: Linear-Time Sequence Modeling with Selective State Spaces</article-title><source>ArXiv:2312.00752 [cs]</source><year>2023</year><pub-id pub-id-type="doi">10.48550/arXiv.2312.00752</pub-id></element-citation></ref><ref id="R43"><label>43</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Whittington</surname><given-names>JCR</given-names></name><name><surname>Dorrell</surname><given-names>W</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name></person-group><source>Disentanglement with Biological Constraints: A Theory of Functional Cell Types</source><conf-name>Int Conf on Learn Represent</conf-name><year>2023</year><elocation-id>ArXiv:2210.01768 [cs, q-bio]</elocation-id><pub-id pub-id-type="doi">10.48550/arXiv.2210.01768</pub-id></element-citation></ref><ref id="R44"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hsu</surname><given-names>K</given-names></name><name><surname>Dorrell</surname><given-names>W</given-names></name><name><surname>Whittington</surname><given-names>JCR</given-names></name><name><surname>Wu</surname><given-names>J</given-names></name><name><surname>Finn</surname><given-names>C</given-names></name></person-group><article-title>Disentanglement via Latent Quantization</article-title><source>Adv In Neural Inf Process Syst</source><year>2023</year><comment>ArXiv:2305.18378 [cs, stat]</comment></element-citation></ref><ref id="R45"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sargolini</surname><given-names>F</given-names></name><etal/></person-group><article-title>Conjunctive representation of position, direction, and velocity in entorhinal cortex</article-title><source>Science</source><year>2006</year><volume>312</volume><fpage>758</fpage><lpage>62</lpage><pub-id pub-id-type="pmid">16675704</pub-id></element-citation></ref><ref id="R46"><label>46</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Khona</surname><given-names>M</given-names></name><name><surname>Fiete</surname><given-names>IR</given-names></name></person-group><chapter-title>Attractor and integrator networks in the brain</chapter-title><source>Nat Rev Neurosci</source><publisher-name>Nature Publishing Group</publisher-name><year>2022</year><fpage>1</fpage><lpage>23</lpage><pub-id pub-id-type="pmid">36329249</pub-id></element-citation></ref><ref id="R47"><label>47</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>SS</given-names></name><name><surname>Rouault</surname><given-names>H</given-names></name><name><surname>Druckmann</surname><given-names>S</given-names></name><name><surname>Jayaraman</surname><given-names>V</given-names></name></person-group><article-title>Ring attractor dynamics in the Drosophila central brain</article-title><source>Science</source><year>2017</year><volume>356</volume><fpage>849</fpage><lpage>853</lpage><pub-id pub-id-type="pmid">28473639</pub-id></element-citation></ref><ref id="R48"><label>48</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Green</surname><given-names>J</given-names></name><etal/></person-group><article-title>A neuronal circuit architecture for angular integration in Drosophila</article-title><source>Nature</source><year>2017</year><volume>546</volume><fpage>101</fpage><lpage>106</lpage><pub-id pub-id-type="pmcid">PMC6320684</pub-id><pub-id pub-id-type="pmid">28538731</pub-id><pub-id pub-id-type="doi">10.1038/nature22343</pub-id></element-citation></ref><ref id="R49"><label>49</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Turner-Evans</surname><given-names>D</given-names></name><etal/></person-group><article-title>Angular velocity integration in a fly heading circuit</article-title><source>eLife</source><publisher-name>eLife Sciences Publications, Ltd</publisher-name><year>2017</year><volume>6</volume><elocation-id>e23496</elocation-id><pub-id pub-id-type="pmcid">PMC5440168</pub-id><pub-id pub-id-type="pmid">28530551</pub-id><pub-id pub-id-type="doi">10.7554/eLife.23496</pub-id></element-citation></ref><ref id="R50"><label>50</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taube</surname><given-names>J</given-names></name><name><surname>Muller</surname><given-names>R</given-names></name><name><surname>Ranck</surname><given-names>J</given-names></name></person-group><article-title>Head-direction cells recorded from the postsubiculum in freely moving rats. I. Description and quantitative analysis</article-title><source>The J Neurosci</source><year>1990</year><volume>10</volume><fpage>420</fpage><lpage>435</lpage><comment>ISBN: 0270-6474 (Print)</comment><pub-id pub-id-type="pmcid">PMC6570151</pub-id><pub-id pub-id-type="pmid">2303851</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.10-02-00420.1990</pub-id></element-citation></ref><ref id="R51"><label>51</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Basu</surname><given-names>R</given-names></name><etal/></person-group><article-title>The orbitofrontal cortex maps future navigational goals</article-title><source>Nature</source><publisher-name>Nature Publishing Group</publisher-name><year>2021</year><volume>599</volume><issue>7885</issue><fpage>449</fpage><lpage>452</lpage><pub-id pub-id-type="pmcid">PMC8599015</pub-id><pub-id pub-id-type="pmid">34707289</pub-id><pub-id pub-id-type="doi">10.1038/s41586-021-04042-9</pub-id></element-citation></ref><ref id="R52"><label>52</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwartenbeck</surname><given-names>P</given-names></name><etal/></person-group><article-title>Generative replay underlies compositional inference in the hippocampal-prefrontal circuit</article-title><source>Cell</source><year>2023</year><volume>186</volume><fpage>4885</fpage><lpage>4897</lpage><elocation-id>e14</elocation-id><pub-id pub-id-type="pmcid">PMC10914680</pub-id><pub-id pub-id-type="pmid">37804832</pub-id><pub-id pub-id-type="doi">10.1016/j.cell.2023.09.004</pub-id></element-citation></ref><ref id="R53"><label>53</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Balleine</surname><given-names>BW</given-names></name><name><surname>Dickinson</surname><given-names>A</given-names></name></person-group><article-title>Goal-directed instrumental action: contingency and incentive learning and their cortical substrates</article-title><source>Neuropharmacology</source><year>1998</year><volume>37</volume><fpage>407</fpage><lpage>419</lpage><pub-id pub-id-type="pmid">9704982</pub-id></element-citation></ref><ref id="R54"><label>54</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watters</surname><given-names>N</given-names></name><name><surname>Matthey</surname><given-names>L</given-names></name><name><surname>Bosnjak</surname><given-names>M</given-names></name><name><surname>Burgess</surname><given-names>CP</given-names></name><name><surname>Lerchner</surname><given-names>A</given-names></name></person-group><article-title>COBRA: Data-Efficient Model-Based RL through Unsupervised Object Discovery and Curiosity-Driven Exploration</article-title><source>ArXiv:1905.09275 [cs]</source><year>2019</year></element-citation></ref><ref id="R55"><label>55</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burgess</surname><given-names>CP</given-names></name><etal/></person-group><article-title>MONet: Unsupervised Scene Decomposition and Representation</article-title><source>arXiv preprint</source><year>2019</year><fpage>1</fpage><lpage>22</lpage><comment>_eprint: 1901.11390</comment></element-citation></ref><ref id="R56"><label>56</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whittington</surname><given-names>JCR</given-names></name><name><surname>Kabra</surname><given-names>R</given-names></name><name><surname>Matthey</surname><given-names>L</given-names></name><name><surname>Burgess</surname><given-names>CP</given-names></name><name><surname>Lerchner</surname><given-names>A</given-names></name></person-group><article-title>Constellation: Learning relational abstractions over objects for compositional imagination</article-title><source>arXiv preprint</source><year>2021</year><comment>_eprint: 2107.11153</comment></element-citation></ref><ref id="R57"><label>57</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kozachkov</surname><given-names>L</given-names></name><etal/></person-group><article-title>Robust and brain-like working memory through short-term synaptic plasticity</article-title><source>PLOS Comput Biol</source><publisher-name>Public Library of Science</publisher-name><year>2022</year><volume>18</volume><elocation-id>e1010776</elocation-id><pub-id pub-id-type="pmcid">PMC9829165</pub-id><pub-id pub-id-type="pmid">36574424</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1010776</pub-id></element-citation></ref><ref id="R58"><label>58</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pritzel</surname><given-names>A</given-names></name><etal/></person-group><article-title>Neural Episodic Control</article-title><source>arXiv preprint</source><year>2017</year><comment>_eprint: 1703.01988</comment><pub-id pub-id-type="doi">10.1038/nature20101</pub-id></element-citation></ref><ref id="R59"><label>59</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Cho</surname><given-names>K</given-names></name><etal/></person-group><source>Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation</source><conf-name>Proc 2014 Conf on Empir Methods Nat Lang Process (EMNLP)</conf-name><year>2014</year><fpage>1724</fpage><lpage>1734</lpage><comment>ISBN: 9781937284961 _eprint: 1406.1078</comment><pub-id pub-id-type="doi">10.3115/v1/D14-1179</pub-id></element-citation></ref><ref id="R60"><label>60</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ba</surname><given-names>JL</given-names></name><name><surname>Kiros</surname><given-names>JR</given-names></name><name><surname>Hinton</surname><given-names>GE</given-names></name></person-group><article-title>Layer Normalization</article-title><source>arXiv preprint</source><year>2016</year><comment>ISBN: 978-3-642-04273-7 _eprint: 1607.06450</comment><pub-id pub-id-type="doi">10.1038/nature14236</pub-id></element-citation></ref><ref id="R61"><label>61</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hulse</surname><given-names>BK</given-names></name><etal/></person-group><article-title>A connectome of the Drosophila central complex reveals network motifs suitable for flexible navigation and context-dependent action selection</article-title><source>eLife</source><publisher-name>eLife Sciences Publications, Ltd</publisher-name><year>2021</year><volume>10</volume><elocation-id>e66039</elocation-id><pub-id pub-id-type="pmcid">PMC9477501</pub-id><pub-id pub-id-type="pmid">34696823</pub-id><pub-id pub-id-type="doi">10.7554/eLife.66039</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>Relationship between episodic memory and working memory models.</title><p><bold>A)</bold> Schematic of how a task can be solved by episodic and working memory solutions. Solid/empty circles are active/inactive neurons. Black/teal/grey arrows are recurrent/input/output connections. Left/Center/Right: Task/EM solution/ WM solution. Top/Middle/Bottom: General example/ Specific example 1/ Specific example 2. <bold>Left:</bold> Example task of Immediate Serial Recall (ISR) of length 3, with specific instances below. The task input is a sequence of 3 random observations, <bold><italic>o</italic></bold>, that repeat, and a constant ‘forward’ velocity, <bold><italic>v</italic></bold>. The task is to predict the upcoming target, <bold><italic>t</italic></bold>. Blue/orange segments highlight the timesteps described in EM/WM solution schematic (center/right). For the purposes of the schematic, we assume each observation has a one-hot encoding. <bold>Center:</bold> Top: EM models involve an RNN that indexes memories stored in synaptic weights. Middle/Bottom: Schematic of EM solution. This is a simplified version of the top figure (e.g., the RNN is one-hot, and memories are stored in synapses between the RNN and observation neurons; full model and derivation of simplification in <xref ref-type="supplementary-material" rid="SD1">Appendix A.1</xref>), but it maintains all the key elements. Past observations are stored in synaptic memory slots (here we show synaptic memory slots as non-overlapping sets of neural weights), and recurrent position representations index memory slots to retrieve a memory for predicting the upcoming target. Red neurons one-hot encode observations (each neuron represents one observation: 1, 2, 3, or 4). Blue neurons one-hot encode position (each neuron represents one position: A, B, or C). Blue/orange segment highlights present the network at two different timesteps of the task. <bold>Right:</bold> Top: WM models involve just an RNN. Middle/Bottom: Schematic of WM solution. Past observations are stored in activity slots within the RNN (we show activity slots as non-overlapping sets of neurons, but they could be non-overlapping neural subspaces more generally), with the content of each slot copied and shifted by the RNN (at every timestep) to successfully predict targets using fixed readout weights. This example RNN has three activity slots (Green/yellow/purple) each consisting of 4 neurons that can one-hot encode 4 possible observations (1,2,3,4). Blue/orange segment highlights present the network at two different timesteps of the task. <bold>B-E)</bold> Mathematics of the EM and WM solutions. <bold>B)</bold> The EM solution makes predictions via an RNN position code (blue vector) that indexes memories stored in synaptic weight slots (matrix columns). <bold>C)</bold> The RNN position code is updated by recurrent connections. <bold>D)</bold> The WM solution makes predictions using fixed readout weights that attend to a single RNN activity slot (slot 1). <bold>E)</bold> Contents of RNN activity slots are copied and shifted by a recurrent matrix. Note the recurrent matrices will be different depending on the task structure. <bold>F)</bold> The activity of two example position neurons (cells #1 and #2 are the left/middle blue neurons in panel A middle). Cell #1 / #2 is active at position A/B. Thus the two neurons have similar activity patterns in both tasks (top/bottom), up to a possible global shift in their firing fields across tasks, as absolute position could be unknown. However, the neurons preserve their <italic>relative</italic> phase relationship across tasks; i.e. the phase lag between the activity peaks of cell #1 and #2 is preserved across all tasks. <bold>G)</bold> The activity of two example activity slot neurons (cell #4 is rightmost green neuron, and cell #1 is leftmost yellow neuron in panel A right). Cell #4 always fires 2 steps after observation 4. Cell #1 always fires one step after observation 1. In task 1, these neurons have the same activity as the above position neurons, but do not in task 2: they do not keep their phase relationships between tasks as they each code for specific distance/lag from specific observations.</p></caption><graphic xlink:href="EMS190634-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>EM models scale better and learn position representations, while WM models learn activity slots.</title><p><bold>A)</bold> We train EM models consisting of an RNN that can store and retrieve memories. At each timestep, the RNN receives an observation, <bold><italic>o</italic></bold><sub><italic>t</italic></sub>, and velocity signal <bold><italic>v</italic></bold><sub><italic>t</italic></sub>, and must predict target <bold><italic>t</italic></bold><sub><italic>t</italic>+1</sub>. <bold>B)</bold> We train WM models that are just an RNN. We use two types of RNN (for both EM and WM models): <bold>C)</bold> Like our theory we use an RNN with learnable velocity dependent matrices (GroupRNN); <bold>D)</bold> We also use a conventional RNN which receives velocity as input (RegularRNN). <bold>E)</bold> Performance of the EM (solid) and WM (dashed) models on 1D navigation tasks (using GroupRNN). Black dashed line denote chance performance. EM models perform better that WM as task size increases. Larger sized RNN perform better for both EM and WM models. For each combination of task, task size, model type, and RNN size (32, 64, 128), we train five randomly initialised models. Results are mean <italic>±</italic> standard error. All subsequent panels are for RNNs of size 128. <bold>F)</bold> Our theory says EM models should learn position representations that generalise over task instantiations (i.e., in sequences with different sensory observations but same underlying structure). <bold>G)</bold> EM models, but not WM models, learn position like representations. <bold>H)</bold> Left: The WM activity slot theory says the RNN organises past observations into slots (structured according to underlying task structure). Right: Thus a particular sequence of observations should be decodeable for each slot (we call this the ‘slot-sequence’ for each slot). This sequence is different to the sequence of time-lagged past observations (we call this the ‘past-sequence’ for each time lag). <bold>I)</bold> Left: Average decoding of ‘slot-sequences’ (what observation should be in each slot according to our theory) and ‘past-sequences’ (what observation occurred <italic>i</italic> timesteps ago, up to the total number of slot). WM models have high slot-sequence decoding, but not past-sequence decoding, indicating they have learned activity slots. The EM models have not learned activity slots, apart from those trained on small task sizes. Right: Slot- and past-sequence decoding for individual slots or time lags for 1D navigation on an 8-loop. Slot-sequence decoding is consistently higher than past-sequence decoding for WM models, but not EM models, for all slots/time-lags. Similar results shown for all tasks with GroupRNN in <xref ref-type="supplementary-material" rid="SD1">Figure 11</xref>, and for all tasks with RegularRNN in <xref ref-type="supplementary-material" rid="SD1">Figure 12</xref>.</p></caption><graphic xlink:href="EMS190634-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Visualising WM slots without decoding, WM models afford slot algebra.</title><p><bold>A)</bold> To visualise WM activity slots we train models while enforcing non-negative RNN activity (using a ReLU) as well as regularising RNN activity (BC: a technique shown to encourage single neurons to code for single factors of variation<sup><xref ref-type="bibr" rid="R43">43</xref></sup>). We show the mutual information matrices between neurons (horizontal) and slots (vertical). We only show neurons with non-negligible activity, and only present slots 2-4 for clarity since slot 1 tends to have many more neurons than slots 2-4. Top: Without the technique, single neurons code for multiple slots. Middle/Bottom: With the technique single neurons code for single slots. <bold>B)</bold> Slot algebra means representations from three different tasks can be combined to give the representation of a fourth task, e.g., <italic>Rep</italic><sub><italic>i</italic></sub>([1, 4, 2]) − <italic>Rep</italic><sub><italic>i</italic></sub>([4, 4, 3]) + <italic>Rep</italic><sub><italic>i</italic></sub>([4, 2, 3]) = <italic>Rep</italic><sub><italic>i</italic></sub>([1, 2, 2]), where <italic>Rep</italic><sub><italic>i</italic></sub>([<italic>a, b, c</italic>]) denotes the RNN representation at position <italic>i</italic> in a task with observations <italic>a, b, c</italic> at each position. The slot algebra score is a measure of this property, with lower values indicating more accurate implementations of this property. <bold>C)</bold> WM models display ‘slot algebra’ with slot algebra scores low for all GroupRNN models (blue) after training, and are low for RegularRNN models when using the BioRNN variant. For each task and model type, we train three randomly initialised models. Results are mean <italic>±</italic> standard error.</p></caption><graphic xlink:href="EMS190634-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>WM-RNNs computes velocity to control activity slots.</title><p><bold>A)</bold> We train an RNN on a 2-ISR task, but with delays between observations. Delays are sampled randomly from {3, 4, 5, 6, 7} for each problem realisation of each task, and are fixed for the duration of the individual problem. An example delay of 5 steps shown in the schematic. An RNN is trained on multiple problems simultaneously, and so, after training, must be able to learn about and exploit the random delay in each new problem directly through experience, without any plasticity. Decoding analyses reveal that progress-velocity (reciprocal of delay duration) and progress (% of delay length completed) are represented, i.e., the models maps varying delay lengths across problems into a common progress representation. We can also decode observations at the predicted ‘task-progress’ lag (e.g., ‘3’ was 125% progress lengths ago) according to our model of task-progress activity slots. Red/green points correspond to before/after training. <bold>B)</bold> The RNN learn progress cells, i.e., cells that fire at a consistent progress post observation (regardless of observation type). Angle of circle represents fraction of progress from goal A at 0 degrees top to goal B at 180 degrees bottom, and then back. Radius of blue curve indicates firing rate of cell as a function of fractional progress. The bimodal firing rate indicates the cell fires at a fixed fraction of progress to the next goal, independent of goal identity A or B. These cells transform the variable delay periods for each problem into a common representation. <bold>C)</bold> Schematic of task-progress activity slots. Rather than two slots for this 2-ISR task with delays, there are multiple intermediate slots corresponding to progress through the task. This allows the variable length problems to be mapped to a common slot representation. Here 3 additional slots are shown between slot 1 to 2 (as well between slot 2 to 1) corresponding to 25%, 50%, and 75% progress. This models says that RNN neurons will be tuned to ‘task-progress’ since a preferred observation, e.g., a neuron will fire when ‘3’ was 125% progress lengths ago. <bold>D)</bold> The RNN learns task-progress slot cells, i.e., cells that fire at a consistent task-progress post an observation, as predicted by our model (panel C). Top: RNN neuron that fires at 0% after observation ‘7’. Left/Middle/Right: Average neural firing in all problems without a ‘7’ observation / problems with observation ‘7’ in ‘A’ position / problems with observation ‘7’ in ‘B’ position. Bottom: RNN neuron that fires at 175% after observation 5. Left/Middle/Right: Average neural firing in all problems without a ‘5’ observation / problems with observation ‘5’ in ‘A’ position / problems with observation ‘7’ in ‘5’ position. <bold>E-G)</bold> Same as A,B,D but for a 4-ISR task where delays between observations can be different for different problems (but still fixed within each problem; example delays of 3, 0, 1, and 4 steps shown in schematic; delays sampled from {3, 4, 5}).</p></caption><graphic xlink:href="EMS190634-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>Explaining PFC representations in an ISR task as activity slots.</title><p><bold>A)</bold> Xie et al.<sup><xref ref-type="bibr" rid="R29">29</xref></sup>, recorded PFC neurons while monkeys performed an ISR like task. Monkeys were presented, on a screen, three (out of six) spatial positions in sequence, then, after a delay, tasked with repeating the sequence (via saccades). <bold>B)</bold> During the delay, PFC recordings revealed observation coding in three neural subspaces; one for each ordered position. Darker dots are projections of the <italic>i</italic><sup>th</sup> observations in the <italic>i</italic><sup>th</sup> subspace, lighter dots are projections of <italic>j</italic><sup>th</sup> observations in the <italic>i</italic><sup>th</sup> subspace (<italic>j</italic> ≠ <italic>i</italic>). Lighter dots have close to zero projection, thus suggesting the subspaces are orthogonal, which <bold>C)</bold> is confirmed in analysis. <bold>D)</bold> For this ISR task, the activity slots model adds the current observation memory to slot 1, and rotates the contents of the slots unidirectionally, so that after observing all observations, slot <italic>i</italic> contains the observation <italic>i</italic> − 1 timesteps ago. In this schematic, the readout slot is also slot 1. <bold>E-F)</bold> Training a RegularRNN on the same task recovered the same three orthogonal subspaces, and is consistent with an activity slot model. A-C) reproduced from Xie et al.<sup><xref ref-type="bibr" rid="R29">29</xref></sup>.</p></caption><graphic xlink:href="EMS190634-f005"/></fig><fig id="F6" position="float"><label>Figure 6</label><caption><title>Explaining PFC representations in a cue-dependent memory retrieval task as velocity controlled activity slots.</title><p>Panichello &amp; Buschman<sup><xref ref-type="bibr" rid="R33">33</xref></sup> recorded PFC neurons while monkeys were cued to recall one of two colours previously presented at the top and bottom of a screen. <bold>B-C)</bold> Before the cue, PFC neurons represented two orthogonal subspaces - one for the top colour and one for the bottom colour. After the cue the subspaces became parallel. <bold>D)</bold> For this task, the activity slots model adds observation memories to slot 1, and copies and shifts the contents of slots according to velocity control signals (direction of shift denoted by solid as opposed to dashed arrow). In this schematic, the readout slot is also slot 1. <bold>E)</bold> We modelled this task by sequentially presenting the top colour, the bottom colour, then the cue, and trained the RNN to predict the target colour. <bold>F-G)</bold> A trained RegularRNN recovered the same orthogonal subspaces, which became parallel after the cue. This is consistent with the activity slot model. A-C) reproduced from Panichello et al.<sup><xref ref-type="bibr" rid="R33">33</xref></sup></p></caption><graphic xlink:href="EMS190634-f006"/></fig></floats-group></article>