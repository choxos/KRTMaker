<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS189889</article-id><article-id pub-id-type="doi">10.1101/2023.10.18.562859</article-id><article-id pub-id-type="archive">PPR744736</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">3</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Theta and alpha oscillations in human hippocampus and medial parietal cortex support the formation of location-based representations</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Satish</surname><given-names>Akul</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><contrib contrib-type="author"><name><surname>Keller</surname><given-names>Vanessa G.</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Raza</surname><given-names>Sumaiyah</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Fitzpatrick</surname><given-names>Shona</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Horner</surname><given-names>Aidan J.</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A3">3</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib></contrib-group><aff id="A1"><label>1</label>Department of Psychology, University of York, UK</aff><aff id="A2"><label>2</label>MRC Cognition and Brain Sciences Unit, University of Cambridge, UK</aff><aff id="A3"><label>3</label>York Biomedical Research Institute, University of York, UK</aff><author-notes><corresp id="CR1"><bold>Contact information for corresponding authors:</bold> Aidan Horner; Department of Psychology, University of York, York, UK, YO10 5DD, <email>aidan.horner@york.ac.uk</email>; Telephone: +44 (0) 1904 324603; Akul Satish; MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, UK, CB2 7EF. <email>Akul.Satish@mrc-cbu.cam.ac.uk</email>; Telephone: +44 (0) 12237 69441</corresp></author-notes><pub-date pub-type="nihms-submitted"><day>21</day><month>10</month><year>2023</year></pub-date><pub-date pub-type="preprint"><day>19</day><month>10</month><year>2023</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Our ability to navigate in a new environment depends on learning new locations. Mental representations of locations are quickly accessible during navigation and allow us to know where we are regardless of our current viewpoint. Recent fMRI research using pattern classification has shown that these location-based representations emerge in the retrosplenial cortex and parahippocampal gyrus, regions theorised to be critically involved in spatial navigation. However, little is currently known about the oscillatory dynamics that support the formation of location-based representations. We used MEG to investigate region-specific oscillatory activity in a task where participants could form location-based representations. Participants viewed videos showing that two perceptually distinct scenes (180° apart) belonged to the same location. This “overlap” video allowed participants to bind the two distinct scenes together into a more coherent location-based representation. Participants also viewed control “non-overlap” videos where two distinct scenes from two different locations were shown, where no location-based representation could be formed. In a post-video behavioural task, participants successfully matched the two viewpoints shown in the overlap videos, but not the non-overlap videos, indicating they successfully learned the locations in the overlap condition. Comparing oscillatory activity between the overlap and non-overlap videos, we found greater theta and alpha/beta power during the overlap relative to non-overlap videos, specifically at time-points when we expected scene integration to occur. These oscillations localised to regions in the medial parietal cortex (precuneus and retrosplenial cortex) and the medial temporal lobe, including the hippocampus. Therefore, we find that theta and alpha/beta oscillations in the hippocampus and medial parietal cortex are likely involved in the formation of location-based representations.</p></abstract><kwd-group><kwd>Spatial Memory</kwd><kwd>Scene Integration</kwd><kwd>Associative Memory</kwd><kwd>Environmental Encoding</kwd><kwd>Neural Oscillations</kwd><kwd>Beamforming</kwd></kwd-group></article-meta></front><body><p id="P2">Our ability to navigate in a new environment relies on learning its spatial layout by forming location-based representations. Location-based representations allow us to locate ourselves in space irrespective of the current heading direction and are thought to be formed by binding distinct viewpoints of a single location into a more coherent viewpoint-independent representation. Recent research using pattern classification on fMRI data has found that specific regions within a spatial navigation network support location-based representations (<xref ref-type="bibr" rid="R7">Baumann &amp; Mattingley, 2021</xref>; <xref ref-type="bibr" rid="R57">Marchette et al., 2014</xref>; <xref ref-type="bibr" rid="R77">Robertson et al., 2016</xref>; <xref ref-type="bibr" rid="R88">Vass &amp; Epstein, 2013</xref>). In particular, these representations can emerge in medial temporal and medial parietal regions following a single learning session (<xref ref-type="bibr" rid="R8">Berens et al., 2021</xref>). Despite evidence for the emergence of location-based representations, we know less about their formation. Specifically, we do not know the oscillatory dynamics that support their formation. Despite the known role of theta and alpha/beta oscillations in memory and spatial navigation (<xref ref-type="bibr" rid="R12">Buzsáki &amp; Moser, 2013</xref>; <xref ref-type="bibr" rid="R39">Hanslmayr et al., 2016</xref>; <xref ref-type="bibr" rid="R63">Nyhus &amp; Curran, 2010</xref>; <xref ref-type="bibr" rid="R70">Parish et al., 2018</xref>), they have yet to be specifically related to the formation of location-based representations in humans. As such, we assessed the role of region-specific oscillatory dynamics during at task that allowed for the formation of location-based representations.</p><p id="P3">Spatial navigation is supported by a network of brain regions, including the medial temporal lobes (and hippocampus) and medial parietal regions (<xref ref-type="bibr" rid="R7">Baumann &amp; Mattingley, 2021</xref>; <xref ref-type="bibr" rid="R9">Bicanski &amp; Burgess, 2018</xref>; <xref ref-type="bibr" rid="R21">Epstein, 2008</xref>; <xref ref-type="bibr" rid="R22">Epstein &amp; Baker, 2019</xref>). In the medial temporal lobes, a wide range of neurons have been found in rodents that respond to specific features of the spatial environment during navigation. The archetypal spatial neuron in the hippocampus is the <italic>place cell</italic>, a neuron that fires when the animal is in a specific location, irrespective of the heading direction of the animal (<xref ref-type="bibr" rid="R65">O’Keefe &amp; Dostrovsky, 1971</xref>). Thus, place cells are an example of a location-based viewpoint-independent representation in the hippocampus. Other neurons that respond to the animal’s heading direction (<xref ref-type="bibr" rid="R86">Taube et al., 1990</xref>), proximity to spatial boundaries (boundary vector cells; (<xref ref-type="bibr" rid="R54">Lever et al., 2009</xref>; <xref ref-type="bibr" rid="R64">O’Keefe &amp; Burgess, 1996</xref>; <xref ref-type="bibr" rid="R81">Solstad et al., 2008</xref>), and to multiple locations in a regular hexagonal pattern (grid cells; <xref ref-type="bibr" rid="R36">Hafting et al., 2005</xref>), as well as other spatially-tuned neurons, have also been shown (see e.g., <xref ref-type="bibr" rid="R42">Hartley et al., 2014</xref> for a review). This range of spatially tuned neurons in the medial temporal lobes is thought to support a ‘cognitive map’ of the environment, allowing the organism to effectively navigate in a flexible manner (<xref ref-type="bibr" rid="R66">O’Keefe &amp; Nadel, 1978</xref>). Computational models propose that the allocentric representations in the medial temporal lobe are translated into more egocentric navigationally-relevant representations in the parietal lobes, and precuneus in particular, with the retrosplenial cortex acting as a key region in this translation process (<xref ref-type="bibr" rid="R1">Alexander et al., 2023</xref>; <xref ref-type="bibr" rid="R9">Bicanski &amp; Burgess, 2018</xref>). Thus, the learning of location-based representations is likely to involve both parietal and medial temporal regions, translating more egocentric ‘viewpoints’ into more coherent location-based representations.</p><p id="P4">Location-based representations have also been observed in the wider spatial navigation network. Using fMRI representational similarity analysis (RSA), representations for known real-world locations have been shown in the parahippocampal gyrus and retrosplenial cortex (<xref ref-type="bibr" rid="R57">Marchette et al., 2014</xref>; <xref ref-type="bibr" rid="R84">Steel et al., 2023</xref>; <xref ref-type="bibr" rid="R88">Vass &amp; Epstein, 2013</xref>). Two recent studies used a novel paradigm to study the formation of these location-based representations using panoramic 2D images of real-world locations (<xref ref-type="bibr" rid="R8">Berens et al., 2021</xref>; <xref ref-type="bibr" rid="R77">Robertson et al., 2016</xref>). The panorama was cropped to derive scenes that were 180° apart, resulting in two viewpoints of the same location that were perceptually distinct, such that a naïve viewer would not be able to determine if they were from the same location or from two different locations. Participants watched videos panning across the whole panorama, providing an opportunity for the participants to sample shared information between the viewpoints (for overlap videos) and integrate them to form a coherent location-based representation of that panorama. In <xref ref-type="bibr" rid="R8">Berens et al. (2021)</xref> participants also watched videos that panned between two viewpoints from different locations (non-overlap videos), where they were not able to form a location-based representation. Participants were able to behaviourally match endpoints in the overlap condition, importantly only after watching the videos, but they were unable to match endpoints in the non-overlap condition. Using this manipulation, they found neural evidence of location-learning in the parahippocampal and retrosplenial cortex. Multivariate patterns of BOLD activity related to viewing two viewpoints from the same location were more similar after, relative to before, watching the overlap videos (no increase in similarity was seen for viewpoints presented in non-overlap videos).</p><p id="P5"><xref ref-type="bibr" rid="R8">Berens et al. (2021)</xref> also assessed univariate BOLD differences between the overlap and non-overlap conditions during the video watching period. This revealed a significantly greater BOLD response to the overlap relative to the non-overlap condition in medial prefrontal regions, and reduced activity in the overlap relative to the non-overlap condition in parahippocampal and retrosplenial cortex (<ext-link ext-link-type="uri" xlink:href="https://neurovault.org/images/115016/">https://neurovault.org/images/115016/</ext-link>). These results are somewhat difficult to interpret, and do not provide satisfactory insight into the neural processes involved in the formation of location-based representations. In particular, given the key role that oscillatory dynamics play in both memory and spatial navigation (<xref ref-type="bibr" rid="R11">Buzsáki, 2002</xref>; <xref ref-type="bibr" rid="R12">Buzsáki &amp; Moser, 2013</xref>), they do not provide any information about the region-specific oscillations that support the formation of location-based representations.</p><p id="P6">Both theta (4-8Hz) and alpha/beta (8-20Hz) oscillations have been broadly implicated in spatial navigation and memory (<xref ref-type="bibr" rid="R12">Buzsáki &amp; Moser, 2013</xref>). Theta oscillations are theorised to facilitate long-range communication between the hippocampus and neocortex via the striatum and septal nuclei (<xref ref-type="bibr" rid="R2">Arnulfo et al., 2015</xref>; <xref ref-type="bibr" rid="R14">Bzymek &amp; Kloosterman, 2023</xref>; <xref ref-type="bibr" rid="R30">Gloveli et al., 2005</xref>; <xref ref-type="bibr" rid="R37">Hangya et al., 2009</xref>; <xref ref-type="bibr" rid="R63">Nyhus &amp; Curran, 2010</xref>) in the service of navigation and memory. Neurons in the rodent hippocampus fire in theta frequencies during translational movement (<xref ref-type="bibr" rid="R87">Vanderwolf, 1969</xref>) and hippocampal place cells fire at different phases of the theta oscillation, known as theta phase precession (<xref ref-type="bibr" rid="R80">Skaggs et al., 1996</xref>). Hippocampal theta phase is also considered important for encoding and retrieval states of episodic memory (<xref ref-type="bibr" rid="R43">Hasselmo et al., 2002</xref>). Disrupting the theta rhythm in the rodent hippocampus was found to cause poor performance in spatial memory tasks, while reviving hippocampal theta improved performance (<xref ref-type="bibr" rid="R58">McNaughton et al., 2006</xref>). Therefore, there is causal evidence that rodent hippocampal theta oscillations are critical for spatial navigation and memory.</p><p id="P7">In humans, both invasive (iEEG/ECoG) and non-invasive (EEG/MEG) measurements of electrophysiological activity have implicated the theta rhythm in episodic memory and spatial navigation (<xref ref-type="bibr" rid="R45">Herweg et al., 2020</xref>; <xref ref-type="bibr" rid="R63">Nyhus &amp; Curran, 2010</xref>). Specifically, changes in theta oscillatory power have been observed on the scalp during learning of specific items (words/pictures/scenes; <xref ref-type="bibr" rid="R26">Fellner et al., 2013</xref>, <xref ref-type="bibr" rid="R27">2019</xref>; <xref ref-type="bibr" rid="R34">Guderian et al., 2009</xref>; <xref ref-type="bibr" rid="R38">Hanslmayr et al., 2009</xref>, <xref ref-type="bibr" rid="R41">2011</xref>; <xref ref-type="bibr" rid="R50">Khader et al., 2010</xref>; <xref ref-type="bibr" rid="R69">Osipova et al., 2006</xref>), lists of items (<xref ref-type="bibr" rid="R28">Fellner et al., 2016</xref>; <xref ref-type="bibr" rid="R33">Griffiths et al., 2016</xref>; <xref ref-type="bibr" rid="R59">Meeuwissen et al., 2011</xref>; <xref ref-type="bibr" rid="R79">Sederberg et al., 2006</xref>), and during associative learning (<xref ref-type="bibr" rid="R6">Backus et al., 2016</xref>; <xref ref-type="bibr" rid="R15">Caplan &amp; Glaholt, 2007</xref>; <xref ref-type="bibr" rid="R18">Crespo-García et al., 2016</xref>; <xref ref-type="bibr" rid="R33">Griffiths et al., 2016</xref>; <xref ref-type="bibr" rid="R48">Joensen et al., 2023</xref>; <xref ref-type="bibr" rid="R82">Staudigl &amp; Hanslmayr, 2013</xref>; <xref ref-type="bibr" rid="R85">Summerfield &amp; Mangels, 2005</xref>). Theta power changes have also been found when participants learn spatial layouts as they combine sensory input in new environments compared to when they freely explore a new spatial layout in the absence of an overt task (<xref ref-type="bibr" rid="R17">Chrastil et al., 2022</xref>; <xref ref-type="bibr" rid="R20">Du et al., 2023</xref>; <xref ref-type="bibr" rid="R49">Kaplan et al., 2012</xref>; <xref ref-type="bibr" rid="R76">Pu et al., 2017</xref>). Therefore, a large body of evidence indicates that theta power changes observed on the scalp are important for both non-spatial (episodic) and spatial memory formation.</p><p id="P8">Theta power changes during memory encoding often localise to the medial temporal lobes (among other structures), including the hippocampus and parahippocampal regions (<xref ref-type="bibr" rid="R6">Backus et al., 2016</xref>; <xref ref-type="bibr" rid="R18">Crespo-García et al., 2016</xref>; <xref ref-type="bibr" rid="R28">Fellner et al., 2016</xref>, <xref ref-type="bibr" rid="R27">2019</xref>; <xref ref-type="bibr" rid="R33">Griffiths et al., 2016</xref>; <xref ref-type="bibr" rid="R41">Hanslmayr et al., 2011</xref>; <xref ref-type="bibr" rid="R82">Staudigl &amp; Hanslmayr, 2013</xref>). Note, this theta effect is likely distinct from frontal mid-line theta, found during cognitive control and working memory tasks, which typically localises to medial prefrontal regions (<xref ref-type="bibr" rid="R17">Chrastil et al., 2022</xref>; <xref ref-type="bibr" rid="R20">Du et al., 2023</xref>; <xref ref-type="bibr" rid="R85">Summerfield &amp; Mangels, 2005</xref>; <xref ref-type="bibr" rid="R90">Zuure et al., 2020</xref>). Thus, a large body of evidence exists for the role of theta in forming associations between information in both spatial and non-spatial contexts. We therefore predicted that theta rhythms would be implicated in the formation of location-based representations that involves associating different viewpoints from the same location.</p><p id="P9">Oscillations at alpha and low beta frequencies (~8-20Hz) are also implicated in memory formation and are found in posterior sites that localise to parieto-occipital regions when scenes/objects are encoded (<xref ref-type="bibr" rid="R47">Jensen &amp; Mazaheri, 2010</xref>). Changes in alpha/beta oscillatory power are often thought to reflect functional inhibition, where increases in alpha power are observed in task-irrelevant brain regions, and are thought to reflect inhibition of these regions, and decreases in alpha power are found in task-relevant regions, and are thought to reflect release from inhibition. The oscillatory sync/de-sync model of memory formation (<xref ref-type="bibr" rid="R39">Hanslmayr et al., 2016</xref>; <xref ref-type="bibr" rid="R70">Parish et al., 2018</xref>) argues that stimulus-specific information is represented by reductions in alpha/beta power in the neocortex, such as visual information represented in parieto-occipital regions (<xref ref-type="bibr" rid="R32">Griffiths et al., 2019</xref>; <xref ref-type="bibr" rid="R47">Jensen &amp; Mazaheri, 2010</xref>; <xref ref-type="bibr" rid="R51">Klimesch, 2012</xref>). This stimulus information then travels to the hippocampus, where hippocampal theta power increases allow for mnemonic information to be integrated into a coherent memory trace via long-term potentiation. More recently, alpha oscillations have also been associated with micro-saccades and gaze towards to-be-encoded stimuli indicating that changes in alpha/beta power, especially in the visual cortex, could also be involved in memory formation (<xref ref-type="bibr" rid="R73">Popov &amp; Staudigl, 2023</xref>; <xref ref-type="bibr" rid="R83">Staudigl et al., 2017</xref>). Therefore, there are theoretical and computational models backed by empirical evidence that indicate changes in theta and alpha/beta oscillations (~4-30Hz) are involved in associative memory formation.</p><p id="P10">Despite the wealth of data implicating theta and alpha/beta in spatial navigation and memory, no study to date has focussed on these oscillations specifically during the formation of location-based representations. Further, no study has attempted to source-localise the oscillations supporting the formation of location-based representations. We therefore used MEG to measure electrophysiological activity related to the formation of location-based representations because it is temporally precise and provides a direct measure of changes in neural oscillations. Further, we aimed to estimate neural activity arising from the hippocampus and medial parietal structures, which are traditionally considered to be challenging to record from because of the depth of these regions relative to the scalp, and because the complex gyri folds in these regions could cancel out any signals before they emerge at the scalp (<xref ref-type="bibr" rid="R75">Pu et al., 2018</xref>). Although these problems do exist, mounting evidence indicates that hippocampal activity can be localised using advanced beamforming algorithms, especially with MEG data (<xref ref-type="bibr" rid="R35">Guitart-Masip et al., 2013</xref>; <xref ref-type="bibr" rid="R53">Korczyn et al., 2013</xref>; <xref ref-type="bibr" rid="R72">Pizzo et al., 2019</xref>; <xref ref-type="bibr" rid="R75">Pu et al., 2018</xref>; <xref ref-type="bibr" rid="R78">Ruzich et al., 2019</xref>). Therefore, using beamformers on MEG data, we predicted changes in theta (4-8Hz) (and potentially higher frequency alpha/beta (8-30Hz)) oscillatory activity from the hippocampus and medial parietal structures during the formation of location-based representations.</p><p id="P11">To test this, we adapted <xref ref-type="bibr" rid="R8">Berens et al.’s (2021)</xref> paradigm for MEG. Participants watched the overlap and non-overlap videos while we recorded neural activity. We tracked the formation of location-based representations behaviourally by assessing their ability to match viewpoints from the same location before and after watching the videos. We use the term “location-based representation” in this task as a short-hand for a mnemonic representation that allows participants to infer which viewpoints are from the same location after watching the panoramic videos, without making explicit claims about the precise nature of the representation (i.e., whether they relate to true allocentric representations of location such as place cells). We predicted that neural oscillatory power in the theta band would be greater when participants watched overlap videos, when location-based representations can be formed (<xref ref-type="bibr" rid="R8">Berens et al., 2021</xref>; <xref ref-type="bibr" rid="R77">Robertson et al., 2016</xref>), compared to non-overlap videos, when location-based representations cannot be formed. Given evidence for alpha/beta oscillations in memory (<xref ref-type="bibr" rid="R39">Hanslmayr et al., 2016</xref>; <xref ref-type="bibr" rid="R70">Parish et al., 2018</xref>), we also assessed power in frequency bands other than theta in a more exploratory manner. We also attempted to find evidence for the successful formation of location-based representations by comparing neural activity at encoding (watching overlap videos) based on whether they were subsequently remembered vs. forgotten (subsequent memory effect). This subsequent memory effect is often characterised by changes in hippocampal theta oscillations (<xref ref-type="bibr" rid="R39">Hanslmayr et al., 2016</xref>; <xref ref-type="bibr" rid="R48">Joensen et al., 2023</xref>; <xref ref-type="bibr" rid="R70">Parish et al., 2018</xref>; <xref ref-type="bibr" rid="R89">Voss et al., 2017</xref>), although the specific direction (increase or decrease) of change is dependent on several factors (<xref ref-type="bibr" rid="R45">Herweg et al., 2020</xref>). Thus, we predicted hippocampal theta power changes while participants watched overlap videos that were subsequently remembered compared to forgotten.</p><sec id="S1" sec-type="methods"><title>Methods</title><sec id="S2" sec-type="subjects"><title>Participants</title><p id="P12">Thirty-eight University of York students aged 18 to 34 years (<italic>M</italic> = 23.33 years, <italic>SD</italic> = 4.24, 32 females) participated in this study in exchange for course credits or £20. All participants indicated that they were right-handed, had normal or corrected-to-normal vision, had no prior or existing neurological or psychological illnesses, and were not on any psycho-active drugs. A total of eight participants were excluded due to issues during MEG acquisition (3), and extremely noisy MEG recordings (5). The final sample size was 30. Ethics approval was granted by the York Neuroimaging Centre’s (YNiC) ethics committee. Informed consent was obtained from all individual participants included in the study. Participants consented for anonymised data to be available on online repositories and to be published in peer-reviewed journals.</p></sec><sec id="S3"><title>Stimuli and Design</title><p id="P13">Our experimental paradigm was based on <xref ref-type="bibr" rid="R8">Berens et al., (2021)</xref>. The stimuli were created from twelve panoramic images of locations in different UK cities. Each panorama spanned a 210° horizontal field-of-view. The two endpoints of each panorama were extracted and displayed 30° of extreme ends of the panoramas. As such, naïve participants would not be able to accurately match two endpoints from the same location (see <xref ref-type="bibr" rid="R8">Berens et al., 2021</xref>). These endpoints were used in the endpoint-matching tasks conducted both before and after a learning task. See <xref ref-type="fig" rid="F1">Figure 1.A-B</xref> for an illustration of the stimuli used in the study.</p><p id="P14">In the learning task, participants viewed videos panning from one endpoint to the midpoint of a panorama, then switching to another endpoint and panning to the midpoint. In the overlap condition, participants viewed camera pans of the same panoramic scene, whereas in the non-overlap condition, participants viewed camera pans from two different panoramas. For instance, in the overlap condition, the left-to-centre sweep would be from the left endpoint of a location panorama and the right-to-centre sweep would be from the right endpoint from the same panorama. Therefore, there was clear visual overlap between both sweeps and participants could infer that the two endpoints belonged to the same location. However, in the non-overlap condition, the left-to-centre sweep would be from the left endpoint from one location and the right-to-centre sweep would be from a different location. Therefore, there was no visual overlap in non-overlap videos and participants could not infer which location the two endpoints belonged to - they could only infer that the two endpoints did not belong to the same location. The overlap condition was our key manipulation, where participants could form more coherent location-based representations. Non-overlap videos were the control condition, where participants could form associations between the two endpoints but critically were not able to form a more coherent location-based representation.</p><p id="P15">Eight panoramic scenes (from a total of 12) were used in the videos: Four in the overlap and four in the non-overlap condition. Endpoints from the other four panoramas were unseen in the video task but were used as behavioural controls in the pre- and post-learning tasks. The assignment of endpoints to each condition was fully counterbalanced. The starting location of the video pan (left or right endpoint of the panorama) was counterbalanced both across and within participants using the following rules: The 12 panoramic images were divided into 4 factions (sets) that had 3 panoramas (A, B, C) and 6 sets of endpoints (A1, A2, B1, B2, C1, C2) in each faction. The 6 endpoints were matched in the video-watching task such that A1-A2 were in the overlap videos, and belonged to the same panorama, B1-C2 were in the non-overlap videos, and C1 and B2 were unseen in the video-watching task (for one of the counterbalancing sets).</p><p id="P16">Both end-to-centre pans were repeated twice in each video to ensure that the visual overlap was easily detectable, in line with <xref ref-type="bibr" rid="R8">Berens et al., (2021)</xref>. Each end-to-centre pan lasted for 5s: The endpoint was shown for 1s, the pan from the endpoint to the centre took 3s, and the midpoint was shown for 1s. Each video had four pans. The first pan was from left-to-centre, the second was from right-to-centre, third was again from left-to-centre of the same panorama, and the final pan from right-to-centre of the same panorama. Therefore, there were 4 total pans lasting 5s each equating to 20s for each video. For counterbalancing purposes, half of the videos started with a left-to-centre pan and the other half of the videos started with a right-to-centre pan (see <xref ref-type="fig" rid="F2">Figure 2</xref> for an illustration).</p></sec><sec id="S4" sec-type="methods"><title>Procedure</title><p id="P17">We adapted <xref ref-type="bibr" rid="R8">Berens et al.’s (2021)</xref> experimental paradigm for MEG data acquisition. Similar to <xref ref-type="bibr" rid="R8">Berens et al. (2021)</xref>, participants first completed a behavioural task that assessed their ability to match endpoints from the same location (outside the MEG scanner). Then, participants entered the MEG scanner, where they were presented with each endpoint before and after the learning phase (oddball detection task). In the learning phase they watched the overlap and non-overlap videos (video-watching learning task). Outside the MEG scanner, participants then completed the same endpoint matching task they completed before entering the scanner, to assess learning.</p><sec id="S5"><title>Behavioural pre- and post-scanner tasks</title><p id="P18">This task was conducted both pre- and post-video-watching to assess if participants were able to accurately match two endpoints from the same location after (but not before) watching the panoramic videos. On each trial, participants first viewed one endpoint for 3s that was surrounded by a red box. Then, five other endpoints were sequentially presented with a number alongside (i.e., 1-5; 2s per endpoint; 500ms ISI). Out of the five images, one image was from the same location as the cue (red bordered endpoint), and the other four endpoints were from different locations, but from the same counterbalancing set (faction). The presentation order of the five endpoints was random. Participants had to indicate the endpoint that belonged to the same location as the cue (red bordered endpoint) via button press. See <xref ref-type="fig" rid="F1">Figure 1.C</xref> for an illustration of this task.</p><p id="P19">A secondary endpoint-matching task was conducted after the post-scanning task described above. The trial structure was identical, but the instructions were different. Participants were asked to match endpoints that were shown in the same video, rather than match endpoints from the same location (as they did in the previous task). Unseen endpoints were not presented in this task as targets but were presented as foils. Only endpoints that belonged to overlap and non-overlap videos were presented as cues in this task. Note that this is different because participants could still match endpoints from non-overlap videos in this task as they appeared in the same video but would still not know which endpoints belong to those respective locations.</p></sec><sec id="S6"><title>Oddball detection task</title><p id="P20">Participants completed an oddball detection task where they viewed presentations of endpoints in the scanner both before and after the video-watching learning task. On one trial, a fixation cross appeared for a jittered duration centred on 2s (2.25s to 1.75s), followed by a scene that lasted for 3s. Eight blocks of 24 endpoints were presented and the order of endpoint-presentation was pseudo-randomised both within and across blocks. Therefore, each endpoint was presented 8 times. Three trials were randomly chosen in each block to be oddball trials. Participants pressed a button to indicate that they saw an oddball image. The oddball stimulus was an endpoint with three small red dots (3-pixel radius) superimposed in random locations on the image.</p><p id="P21">This task was used to run multivariate pattern analyses to identify representations of individual endpoints. However, we were not able to identify patterns for individual scenes reliably, and as such were not able to perform analyses to assess changes in patterns as a function of learning (as in <xref ref-type="bibr" rid="R8">Berens et al., 2021</xref>). We report these analyses in the Supporting Information for completeness.</p></sec><sec id="S7"><title>Video-watching learning task</title><p id="P22">The video-watching task was our main task of interest, as we were interested in the oscillations that underpinned learning of location-based representations. See <xref ref-type="fig" rid="F2">Figure 2</xref> for an illustration of one trial in the video-watching task. We collected MEG recordings as participants viewed the overlap and non-overlap videos. On one trial, a fixation cross first appeared for 2s (jittered between 1.75s to 2.25s), followed by a video that lasted 20s. After a 2s interval, participants were asked to indicate whether the videos were from the same location or from different locations to ensure that they were paying attention to the visual overlap across segments. Participants used the left/right keys on a response box to make these decisions and had 3s to respond. Then, a 2s inter-trial-interval was followed by the next trial. Importantly, participants were asked to only respond when the text appeared on the screen asking for a response, to avoid motor-related neural activity during video-watching. Each video was repeated three times across the task. Each video was presented a single time within 3 blocks, with presentation order randomised in each block.</p></sec></sec><sec id="S8"><title>MEG data acquisition and processing</title><p id="P23">We measured neural activity with a 4D Neuroimaging Magnes 3600 whole-head 248-sensor magnetometer-based MEG. Four sensors were permanently offline, so we acquired data from 244 sensors for all participants at a 1000Hz sampling rate. Participants’ head-shape for source-localisation was attained using a Polhemus Fastrak Digitisation System. MEG data were pre-processed and analysed using a combination of the FieldTrip toolbox (<xref ref-type="bibr" rid="R68">Oostenveld et al., 2011</xref>) and self-written MATLAB code.</p><p id="P24">Raw MEG recordings were first band-pass filtered between 0.1Hz and 70Hz using two-pass butterworth filters. Notch filters were applied at 50Hz (UK mains frequency) and 60Hz (projector refresh rate). Further details of analyses and results of the oddball detection task are detailed in the Supporting Information. We focus on the video-watching task as we were primarily interested in neural oscillations during learning. Further, no reliable multivariate patterns were found in the oddball detection task.</p><p id="P25">The filtered continuous data from the video-watching task were segmented into epochs of 24s, from - 2s pre- to +20s post-stimulus onset. Trial-by-trial information about stimulus type and participant responses was then added to the FieldTrip data structure. Noisy epochs were rejected by visual inspection: As a first pass, experimenters looked for any specifically noisy trials including scanner drifts/jumps and extreme movements. Remaining epochs were concatenated and submitted to an Independent Component Analysis (ICA) using <italic>runica</italic> in FieldTrip with default parameters. Note that ICA was conducted by band-pass filtering the dataset between 1 to 40Hz and resampling to 200Hz, which is argued to improve ICA performance (<xref ref-type="bibr" rid="R29">Ferrante et al., 2022</xref>). Importantly, artefact-rejection occurred on the original data set, which was filtered between 0.1 to 70Hz. Components reflecting eye-movements and heartbeats were identified by visual inspection of component scalp topographies and time-courses. These components were discarded by back-projecting all but these components to the data space. Corrected data were low-pass filtered to 40Hz (two-way butterworth). Finally, any remaining noisy epochs were removed based on visual inspection and were baseline-corrected against the -200 to 0ms prestimulus period. The data were downsampled to 250Hz before further analysis.</p><p id="P26">After pre-processing, an average of 11.30 trials (<italic>SD</italic> = 1.24, range 7 to 12) in the overlap condition and 11.06 trials in the non-overlap condition (<italic>SD</italic> = 1.17, range 8 to 12) remained and were used for further analyses.</p><sec id="S9"><title>Source reconstruction of MEG activity</title><p id="P27">Observed sensor-level data was reconstructed in source-space using Linear Constrained Minimum Variance (LCMV) beamformers. A standard MNI structural T1 image from the FieldTrip toolbox was aligned to each individual’s headshape obtained immediately before participants entered the MEG scanner. The template structural scan was first co-registered to the fiducials and transformed to fit the headshape automatically. The experimenter then visually verified fit and manually resized each co-registered image to ensure good fit between the scan and the digitised headshape. The co-registered image was resliced to align voxel positions in 3D space to the individual’s headshape and segmented to isolate brain tissue from skull and skin. The segmented image was used to create positions of 3294 grid points spaced 10mm inside the brain. The lead-field matrix (forward model) was then computed, which included information about the forward projections from each grid point to scalp sensors. The sensor level data, source model, and forward model were input into the beamforming algorithm, with fixed dipole orientations and 5% lambda regularisation. The beamformer output resulted in time-series signals from -2s to +20s centred around video onset in each of the 3294 voxels. These signals were then decomposed into time and frequency dimensions to derive oscillatory power using aforementioned parameters.</p></sec><sec id="S10"><title>Time-frequency decomposition</title><p id="P28">Single-trial epochs were convolved with complex Morlet wavelets to derive oscillatory power of the MEG signal across time and frequency, using MATLAB code adapted from <xref ref-type="bibr" rid="R19">Denis et al. (2021)</xref>. Twenty-seven wavelets with centre frequencies ranging between 4-30Hz were used. Both the wavelet width and frequency steps were logarithmically spaced in order to distribute power equally across all theoretically important frequency bands (Theta: 4-8Hz, Alpha: 8-12Hz, and Beta: 8-30Hz). Linear spacing of frequencies would have prioritised higher frequency bands (Beta; 13 steps) rather than lower frequency theta (4 steps) and alpha (4 steps) bands. To remove edge artefacts, epochs were truncated to -1.75 to 19.5s. A pre-stimulus baseline period of -1 to -0.5s was used to normalise the oscillatory power to decibels (dB), because using baselines close to stimulus-onset could lead to bleeding of stimulus-related activity into the baseline period. The decomposition parameters were identical for both sensor-space and source-space data.</p></sec></sec><sec id="S11"><title>MEG data analysis</title><p id="P29">Our primary analysis was a pairwise comparison of oscillatory activity between overlap and non-overlap videos. Non-parametric cluster-based permutation tests (N<sub>perms</sub> = 1000, two-tail correction = ‘prob’ which multiples the uncorrected probability by a factor of two before setting the α = .05 threshold) as implemented in FieldTrip were used to detect statistically significant differences between these two conditions in both sensor and source-space, across time and frequency.</p><sec id="S12"><title>Sensor-level analysis</title><p id="P30">The cluster tests were first conducted in sensor-space (with a minimum of 3 neighbouring sensors required to form a cluster). We could not test for effects across all 20s of video watching in sensor-space because of RAM limitations (but this is addressed later). Therefore, we divided the 20s epoch into 1.5s long segments (the maximum time-window we could test with 1000 permutations) of interest around endpoint and midpoint onsets. We expected that participants would most likely be able to distinguish the endpoints were from same or different locations at these points in the videos. Hence, we expected oscillatory power involved in learning to be maximal between the overlap and non-overlap videos during the end- and mid-points of the videos.</p><p id="P31">We specified 3 time-segments starting at endpoint-onset (5 to 6.5s, 10 to 11.5s and 15 to 16.5s), and three segments around mid-point onset (8 to 9.5s, 13 to 14.5s, and 18 to 19.5s), see <xref ref-type="fig" rid="F2">Figure 2</xref> for an illustration of where these time-segments lie in the video. We specified these time-windows because they either represented the to-be-bound information (the endpoints) or depicted shared spatial information (mid-points) allowing binding between endpoints into a location-based representation. So, we expected the binding process that forms location-based representations to occur during these time-windows, which would be reflected by changes in neural oscillatory activity that we intended to find. The final 500ms of mid-point presentation could not be analysed in any situation. In the first two mid-point segments, evoked activity from the next endpoint-onset bled into preceding timepoints of mid-point-offset. The final 500ms included edge-artefacts arising from time-frequency decomposition.</p><p id="P32">Finally, we attempted to detect clusters across the whole 20s of video watching that we may have missed. We chose sensors that had the maximal t-value within significant clusters from the focal time-window analysis. Then, we ran cluster-based tests to detect significant clusters from 0 to 19.5s and 4 to 30Hz in each sensor. Note, this analysis can only be used to reveal significant effects at timepoints outside of our initial time-windows of interest, given the sensors were selected based on analyses from these time-windows.</p></sec><sec id="S13"><title>Whole brain analyses</title><p id="P33">We then assessed regions in the brain that contributed to any statistically significant sensor-space differences. Oscillatory power in each voxel in the brain was averaged over the time-frequency regions spanned by significant clusters found in sensor-space. We computed an averaged oscillatory power value for each voxel across the whole brain and used cluster-permutation pairwise tests to find differences in averaged oscillatory power between overlap and non-overlap videos across all voxels. The Brainnetome Atlas (<xref ref-type="bibr" rid="R24">Fan et al., 2016</xref>) was used to identify regions with statistically significant whole-brain clusters. This analysis therefore revealed the brain regions most likely to be producing the sensor-level power differences.</p></sec><sec id="S14"><title>ROI analysis</title><p id="P34">We ran targeted ROI analyses with two goals in mind. First, we wanted to reliably test for any clusters at time-points other than the segments chosen for sensor-space analyses. Second, although the whole-brain analyses revealed the brain regions involved in sensor-level effects, the distribution of these effects across time and frequency within specific brain regions was relatively unknown. Therefore, we tested for the extent of differences in oscillatory power across time-frequency ranges in each ROI and time-segments where we found sensor-level effects.</p><p id="P35">We chose regions of interest that were theorised to be critical for supporting location-based representations (see <xref ref-type="bibr" rid="R1">Alexander et al., 2023</xref>; <xref ref-type="bibr" rid="R9">Bicanski &amp; Burgess, 2018</xref>; <xref ref-type="bibr" rid="R13">Byrne et al., 2007</xref>): the precuneus, retrosplenial cortex, and right and left hippocampi. The hippocampus is also critical for integrating episodic and spatial information (e.g., <xref ref-type="bibr" rid="R6">Backus et al., 2016</xref>; <xref ref-type="bibr" rid="R12">Buzsáki &amp; Moser, 2013</xref>; <xref ref-type="bibr" rid="R46">Horner et al., 2015</xref>).</p><p id="P36">LCMV beamformers are more likely to generate illusory effects in either the right or left hippocampus as the algorithm fails to separate correlated sources (<xref ref-type="bibr" rid="R67">O’Neill et al., 2021</xref>). Therefore, any differences in power between conditions would likely be (falsely) lateralised in either the left or right hippocampus, and averaging over the two hippocampi could reduce our power to detect any true effects. Therefore, we ran our tests separately in the right and left hippocampus. Crucially, we did not make inferences about the lateralisation of any effects we found but were simply attempting to increase statistical power by running our analysis separately in the right/left hippocampus. Note that the precuneus and retrosplenial cortex were combined across left and right hemispheres as they were physically proximal and do not suffer from the illusory lateralisation found in the physically distant but functionally connected hippocampi.</p><p id="P37">Voxels belonging to each ROI were identified by interpolating grid-points with the Brainnetome atlas (<xref ref-type="bibr" rid="R24">Fan et al., 2016</xref>) using FieldTrip functions. We averaged oscillatory power across all voxels from each ROI for each data-point from 0 to 19.5s and 4 to 30Hz. Cluster-based permutation tests were conducted to detect differences in oscillatory power across time and frequency in each ROI across (i) 0 to 19.5s and (ii) in time-segments of interest from the sensor-level analysis where we found significant clusters (10 to 11.5s and 18 to 19.5s, see <xref ref-type="fig" rid="F2">Figure 2</xref>).</p></sec><sec id="S15"><title>Subsequent memory effect</title><p id="P38">In a complementary analysis, we tested for subsequent memory effects in each of the four ROIs. We split overlap videos based on whether participants were accurate or inaccurate in the subsequent behavioural scene-matching test. We then extracted average power from the subsequently accurate and inaccurate videos by defining time-frequency boundaries found in the overlap vs. non-overlap comparison in each ROI. Locations where participants could match only in one direction (endpoint B cued by endpoint A, or vice-versa) were considered to be subsequently remembered in order to increase trial numbers and statistical power (given the above chance but relatively poor performance post-learning in the overlap condition). A frequentist pairwise t-test was conducted between subsequently accurate and inaccurate videos from the video-watching task in each ROI that had significant overlap vs. non-overlap clusters. We had to exclude data from 6 participants from this analysis as they either remembered or forgot all the locations, and therefore did not have any trials in either one of the conditions. For the remaining 24 participants, 5.63 subsequently accurate (remembered) trials (SD = 2.32, range = 1 to 9) and 5.50 subsequently inaccurate (forgotten) trials (SD = 2.40, range = 1 to 9) remained on average, and were used for further analyses.</p></sec></sec></sec><sec id="S16" sec-type="results"><title>Results</title><sec id="S17"><title>Behavioural results</title><p id="P39">We tested our behavioural hypothesis that endpoint-matching accuracy would be greater post- vs. pre-video watching of overlap but not non-overlap videos or unseen endpoints (see <xref ref-type="fig" rid="F1">Figure 1.D</xref>).</p><p id="P40">Average endpoint-matching accuracy was submitted to a 2 (Session: pre-video, post-video) x 3 (Condition: overlap, non-overlap, unseen) within-subjects ANOVA. The main effect of Condition was not significant (<italic>F</italic>(1,29) = 1.78), but there was a significant main effect of Session: <italic>F</italic>(1,29) = 11.69, <italic>p</italic> = .002, <italic>η<sup>2</sup><sub>p</sub></italic> = .29), where endpoint-matching accuracy was greater post compared to pre-video watching. Importantly, a significant interaction between Condition and Session (<italic>F</italic>(1,29) = 5.91, <italic>p</italic> = .005, <italic>η<sup>2</sup><sub>p</sub></italic> = .17) was found. Follow up paired t-tests revealed that participants were able to match endpoints more successfully post- vs. pre-videos for overlap (<italic>t</italic>(29) = 4.15, <italic>p</italic> &lt; .001, <italic>BF<sub>10</sub></italic> = 96.43, <italic>d</italic> = .75) but not for non-overlap (<italic>t</italic>(29) = 0.72, <italic>p</italic> = .47, <italic>BF<sub>10</sub></italic> = 0.25) and unseen endpoints (<italic>t</italic>(29) = 1.22, <italic>p</italic> = .23, <italic>BF<sub>10</sub></italic> = 0.38). Furthermore, participants performed at chance level (20%) when matching endpoints from non-overlap videos (<italic>t</italic>(29) = 0.14, <italic>p</italic> = .89, <italic>BF<sub>10</sub></italic> = 0.196) and unseen endpoints (<italic>t</italic>(29) = 0.16, <italic>p</italic> = .88, <italic>BF<sub>10</sub></italic> = 0.197) but they performed significantly better than chance at matching endpoints from the same location post-videos (<italic>t</italic>(29) = 3.09, <italic>p</italic> = .003, <italic>BF<sub>10</sub></italic> = 9.08, <italic>d</italic> = .56). Therefore, participants learnt that two endpoints belonged to the same location after watching overlap compared to non-overlap videos and unseen locations, where they did not learn that two endpoints belonged to the same location. We also analysed the behavioural data using the same GLMMs as in <xref ref-type="bibr" rid="R8">Berens et al. (2021)</xref> and found a similar pattern of results (see <xref ref-type="supplementary-material" rid="SD1">Supporting Information</xref>).</p><p id="P41">Participants were at chance when matching two scenes from the same video for both overlap and non-overlap videos (<italic>M</italic><sub>overlap</sub> = 21.7%, <italic>SD</italic> = .17, <italic>BF<sub>10</sub></italic> = 0.22, <italic>t</italic>(29) = .53, <italic>p</italic> = .59; <italic>M</italic><sub>non-overlap</sub> = 21.7%, <italic>SD</italic> = .19, <italic>BF<sub>10</sub></italic> = 0.22, <italic>t</italic>(29) = .48, <italic>p</italic> = .63), and performance did not differ between both conditions (<italic>BF<sub>10</sub></italic> = 0.19, <italic>t</italic>(29) = 0.1, <italic>p</italic> = .99). Participants were hence unable to determine which endpoints were shown in the same video for both overlap and non-overlap videos. It is not clear why participants could not match endpoints for the overlap condition, given they were able to in the main task reported above. It is possible that they did not fully understand the task or were not motivated to perform given it occurred at the end of the experiment. Participants were above chance in the overlap condition in this task in <xref ref-type="bibr" rid="R8">Berens et al. (2021)</xref>, suggesting that participants can do this task if sufficiently motivated.</p></sec><sec id="S18"><title>MEG results</title><p id="P42">We next analysed MEG data collected during video-watching to determine the neural oscillations involved in forming location-based representations.</p><sec id="S19"><title>Sensor-level results</title><p id="P43">We first compared oscillatory power between overlap and non-overlap video-watching in sensor-space and estimated sources in the brain underlying the sensor-space effects (see <xref ref-type="fig" rid="F3">Figure 3</xref>).</p><p id="P44">We found significant clusters in the 10-11.5s and 18-19.5s time-windows. Oscillatory power was greater in theta, alpha, and low beta frequencies from 10.5-11.5s (4-20Hz, <italic>p</italic> = .023) and from 18-19s (4-11Hz, <italic>p</italic> = .03) post-video onset for overlap compared to non-overlap videos. These effects were maximal in posterior sensors but were spread across the whole scalp. No significant clusters were seen during the other time windows of interest (5-6.5s, 8-9.5s, 13-14.5s, 15-16.5s). Note, these effects are cluster corrected within each time-window but are not corrected for multiple comparisons across the 6 time-windows of interest. Neither the 10.5-11.5s or 18-19s effects survive a stringent Bonferroni correction (p&lt;0.05/6 time-windows of interest).</p><p id="P45">Then, we tested for differences in oscillatory power between overlap and non-overlap videos at time-points other than the a-priori chosen time-windows. To do this, we chose one sensor from the 10-11.5s and 18-19.5s each that had the maximal t-value from the statistically significant cluster showing power changes for the overlap compared to non-overlap condition. Then, we ran a cluster-based permutation test from 0 to 19.5s, which spans all time-points in the video-watching task, across 4 to 30Hz, in each of these sensors. We did not find any clusters that were statistically significant (all <italic>ps</italic> &gt; .34). Therefore, the differences in theta and alpha power seen between 10.5-11.5s and 18-19s in the theta and alpha band appear to be specific to those timepoints.</p><p id="P46">We next estimated sources in the brain that generated the effects we found on the scalp. To estimate the sources underlying the effect found in the 10-11.5s time window (<xref ref-type="fig" rid="F3">Fig 3.A</xref>), we averaged over 10.5-11.5s and 4-20Hz time-frequency data-points for each voxel in the brain. Similarly, we averaged over 18-19s and 4-11Hz for the second cluster (<xref ref-type="fig" rid="F3">Fig 3.C</xref>) for each voxel in the brain. Then, we ran cluster-based permutation tests to determine the extent of the effect across all voxels in the brain and used the Brainnetome atlas (<xref ref-type="bibr" rid="R24">Fan et al., 2016</xref>) to identify regions that belonged to the cluster.</p><p id="P47">Several brain regions, primarily belonging to the default-mode network and medial temporal lobe, contributed to the greater theta/alpha power for overlap compared to non-overlap videos observed on the scalp (cluster correction: 10.5-11.5s, <italic>p</italic> = .007; 18-19s, <italic>p</italic> = .002). Both effects survive a Bonferroni correction for the two time and frequency windows of interest (p&lt;0.05/2). Oscillatory power changes during 10.5-11.5s of video-watching were localised to bilateral superior, middle, and inferior temporal gyri, superior and inferior parietal cortices, and medial and lateral occipital cortices (<xref ref-type="fig" rid="F3">Fig 3.B</xref>). Notably, both the left and right hippocampus, retrosplenial cortices, preuneus, and vmPFC showed significant power differences between overlap and non-overlap videos. A subset of these same regions were involved in the theta/alpha changes found during 18 to 19s of overlap compared to non-overlap video-watching (<xref ref-type="fig" rid="F3">Fig 3.B</xref>), including the Inferior parietal lobe, hippocampus, retrosplenial cortex, and precuneus. Although the effect appears to be isolated to the right hemisphere, we do not make inferences about the lateralisation because the beamformer algorithm can output illusory lateralised effects (<xref ref-type="bibr" rid="R67">O’Neill et al., 2021</xref>).</p></sec><sec id="S20"><title>ROI analyses</title><p id="P48">We then investigated oscillatory power changes specifically in the right and left hippocampus, retrosplenial cortex, and precuneus, as these structures are thought to be important for location-based representations (<xref ref-type="bibr" rid="R9">Bicanski &amp; Burgess, 2018</xref>). Moreover, the hippocampus is particularly important for episodic and spatial memory formation (<xref ref-type="bibr" rid="R10">Burgess et al., 2002</xref>; <xref ref-type="bibr" rid="R45">Herweg et al., 2020</xref>). We determined the distribution of oscillatory power changes for overlap vs. non-overlap videos across time and frequency within our ROIs, within the time-windows of video-watching where we found sensor-level effects: 10 to 11.5s and 18 to 19.5s (see <xref ref-type="fig" rid="F4">Figure 4</xref>).</p><p id="P49">In the 10 to 11.5s time window, the power increase for overlap vs. non-overlap videos was in the theta and alpha (4 to 11Hz) bands from 10.5 to 11.5s in the right hippocampus (<italic>p</italic> = .004) and in theta, alpha, and early beta bands (12 to 18Hz) in the left hippocampus (<italic>p</italic> = .02). However, alpha/beta (8 to 28Hz) frequencies dominated in the precuneus (<italic>p</italic> = .045). There were no significant clusters in the retrosplenial cortex during this time window (though we note a cluster in the theta and alpha bands (4 to 11Hz) that was close to the cluster-corrected threshold (<italic>p</italic> = .053). In the 18 to 19.5s time window, in the right hippocampus, the oscillatory power increase for overlap vs. non-overlap videos was in the theta band (4 to 8.6Hz; <italic>p</italic> = .006). There were no significant clusters in the left hippocampus, retrosplenial cortex, or the precuneus in this later time window. Only the right hippocampal effects in the 10.5-11.5s and 18-19.5s time-window survive a stringent Bonferroni correction for multiple comparisons (p&lt;0.05/8, 4 ROIs and 2 time-windows of interest).</p><p id="P50">We then tested for significant effects across all time-points during video-watching (0 to 19.5s). We focused on the theta (4 to 8Hz) and alpha (8 to 12Hz) bands across 0 to 19.5s (see <xref ref-type="fig" rid="F5">Figure 5</xref>). There were no significant clusters in the alpha band. In the right hippocampus, we found 4 significant clusters indicating greater theta power for overlap vs. non-overlap videos. The two clusters found in previous analyses were also detected in this analysis (10.5 to 11.3s, <italic>p</italic> = .036; 18.5 to 19.1s; <italic>p</italic> = .02). We found two additional clusters from 15.2 to 16.2s (<italic>p</italic> = .047) and 17.11 to 17.55s (<italic>p</italic> = .043). The 15.2 to 16.2s time-window is 200ms post-onset of the second endpoint in time, after the camera pans from the first endpoint at 10s and ends at the central overlapping scene at 14.99s. The 17.11 to 17.55s time-window occurs during the camera pan from second endpoint in time to the final presentation of the central overlapping scene (around 18s). None of these effects survive a stringent Bonferroni correction for multiple comparisons (p&lt;0.05/8, 4 ROIs and 2 frequency-windows of interest). We also ran this analysis across all frequency-points (4 to 30Hz) however this did not reveal any effects in any ROI.</p><p id="P51">In sum, we found that oscillatory power in theta and alpha/beta bands was greater when participants watched overlap videos compared to non-overlap videos, especially during the second repetition of the video (10-20s). These effects were localised to the hippocampus, precuneus, and retrosplenial cortices among other default mode network regions.</p></sec><sec id="S21"><title>Subsequent memory effect</title><p id="P52">Finally, we ran paired-samples t-tests to detect potential differences in oscillatory power between subsequently remembered vs. forgotten locations, as measured in the endpoint-matching task. Oscillatory power was averaged over time-frequency points that belonged to the overlap vs. non-overlap clusters for each ROI (reported above) and compared between subsequently remembered and forgotten locations. We included trials where participants could successfully match both endpoints (A/B) when cued by the other, and trials where they remembered either endpoint B cued by endpoint A or vice versa but were incorrect on the other test (endpoint A cued by endpoint B). Note, we only performed these analyses in the ROIs where significant overlap vs non-overlap differences were seen.</p><p id="P53">In the 10 to 11.5s time-window, there was a significant effect in the left hippocampus, with subsequently remembered videos showing lower oscillatory power than subsequently forgotten videos (<italic>M<sub>remembered</sub></italic> = -0.94, <italic>SD</italic> = 1.09; <italic>M<sub>forgotten</sub></italic> = -.11, <italic>SD</italic> = 1.39; <italic>t</italic>(23) = -2.07, <italic>p</italic> = 0.049, <italic>d</italic> = .43). No significant differences in oscillatory power between subsequently remembered and forgotten locations were seen in the right hippocampus (<italic>M<sub>remembered</sub></italic> = -.32, <italic>SD</italic> = .78; <italic>M<sub>forgotten</sub></italic> = -.35, <italic>SD</italic> = 1.46; <italic>t</italic>(23) = .08, <italic>p</italic> = .96) or precuneus (<italic>M<sub>remembered</sub></italic> = -1.05, <italic>SD</italic> = 1.33; <italic>M<sub>forgotten</sub></italic> = -1.21, <italic>SD</italic> = 1.62; <italic>t</italic>(23) = .47, <italic>p</italic> = .63). There was no significant effect in the right hippocampus in the 18 to 19.5s window (<italic>M<sub>remembered</sub></italic> = -1.06, <italic>SD</italic> = 1.49; <italic>M<sub>forgotten</sub></italic> = -.43, <italic>SD</italic> = 1.21; <italic>t</italic>(23) = 1.47, <italic>p</italic> = .16). None of these effects survive Bonferroni correction for multiple comparisons (p&lt;0.05/4). Therefore, we found that oscillatory power from the theta and alpha bands in the left hippocampus was lower for subsequently remembered compared to subsequently forgotten videos (though we note the smaller sample size of 24 and marginal p-value). The left hippocampus was the only ROI to show a significant subsequent memory effect.</p></sec></sec></sec><sec id="S22" sec-type="discussion"><title>Discussion</title><p id="P54">We used a scene-integration paradigm to determine the region-specific neural oscillations involved in forming location-based representations that are critical for navigating new environments. We replicated previous behavioural findings that participants were able to infer which scenes came from the same location following exposure to panoramic videos depicting the spatial relationship between two perceptually distinct viewpoints of the same location. We found changes in neural oscillatory power in the theta (4-8Hz) and alpha and low beta (8-20Hz) frequencies in the overlap condition, where participants were able to infer which two viewpoints were from the same location, relative to the non-overlap condition, where participants were not able make the same location-based inference. These oscillatory power changes were localised to the hippocampus and to other scene-selective regions including the retrosplenial cortex and precuneus. Therefore, we have identified the region-specific oscillatory dynamics involved in participants ability to infer common locations from differing viewpoints.</p><p id="P55">We were unable to provide evidence, using pattern classification analyses, for changes in neural patterns as a function of watching the videos (indeed, we were not able to use pattern classification analyses to dissociated individual scenes). Thus, unlike in our previous fMRI study (<xref ref-type="bibr" rid="R8">Berens et al., 2021</xref>), we were not able to provide more direct evidence for the emergence of ‘location-based representations’. However, given our previous fMRI study provided evidence for these neural representations, and that their emergence was associated with participants ability to infer two viewpoints were from the same location, it is highly likely that such representations underpinned behaviour in the present experiment (given we saw the same behavioural pattern across the two independent experiments). Thus, we continue to refer to ‘location-based representations’ throughout the manuscript, with the caveat that we infer their presence with reference to our previous fMRI study.</p><p id="P56">MEG data collected when participants watched videos revealed greater theta power for overlap than non-overlap videos. Theta increases were maximal in parietal sensors and were estimated to arise from several regions in the brain including the hippocampus. Therefore, we find evidence that hippocampal theta increases were found when participants viewed videos that allowed them to integrate two perceptually distinct scenes into a location representation based on spatial context. Our findings are in line with a previous study that found hippocampal theta increases using MEG when participants learned a hidden location in a virtual Morris water maze compared to when they randomly moved around in the maze, when no location memories were formed (<xref ref-type="bibr" rid="R76">Pu et al., 2017</xref>). Theta increases were also found when participants formed associations in a spatial context compared to a baseline, pre-stimulus period, during fixation cross presentation (<xref ref-type="bibr" rid="R18">Crespo-García et al., 2016</xref>). We extend these findings by showing that theta power increases were involved when participants were attempting to integrate two scenes into one coherent location-based representation, in the absence of any overt navigation task. This evidence therefore adds to the literature implicating the hippocampal theta rhythm in memory formation and spatial navigation (<xref ref-type="bibr" rid="R6">Backus et al., 2016</xref>; <xref ref-type="bibr" rid="R15">Caplan &amp; Glaholt, 2007</xref>; <xref ref-type="bibr" rid="R18">Crespo-García et al., 2016</xref>; <xref ref-type="bibr" rid="R33">Griffiths et al., 2016</xref>; <xref ref-type="bibr" rid="R48">Joensen et al., 2023</xref>; <xref ref-type="bibr" rid="R82">Staudigl &amp; Hanslmayr, 2013</xref>; <xref ref-type="bibr" rid="R85">Summerfield &amp; Mangels, 2005</xref>).</p><p id="P57">Critically, this theta power difference occurred during the second repetition of the panoramic video within a trial. Theta power increased around 500ms following the start of the camera pan from the endpoint, and increased as the camera pan approached the central overlapping scene between the two endpoints. The timing of this theta power increase is likely important. First, its presence in the second repetition of the panoramic video suggests that a theta-mediated process is occurring only after participants have been presented with information that allows them to infer the two endpoints are from the same location (in the first repetition of the panorama). This perhaps suggests the theta power differences relate to the formation of a location representation as opposed to the simple awareness of a potential relationship. An online assessment of this awareness, tracking when participants become fully aware that the video is depicting a coherent location, would allow us to assess the timing of theta power increases relative to this awareness in future research.</p><p id="P58">Second, theta power changes occurred when participants saw the endpoints of the panorama. One possibility is that the viewpoint not currently presented is being actively retrieved and associated/integrated with the currently presented viewpoint and theta is tracking that retrieval and integration process. This would fit with evidence that theta is associated with not just associative memory (i.e., encoding A-B pairs presented at the same time; <xref ref-type="bibr" rid="R15">Caplan &amp; Glaholt, 2007</xref>; <xref ref-type="bibr" rid="R40">Hanslmayr &amp; Staudigl, 2014</xref>; <xref ref-type="bibr" rid="R82">Staudigl &amp; Hanslmayr, 2013</xref>; <xref ref-type="bibr" rid="R85">Summerfield &amp; Mangels, 2005</xref>) but also associative inference where participants integrate separately encoded A-B and A-C pairs (<xref ref-type="bibr" rid="R6">Backus et al., 2016</xref>). This integration process is thought to be underpinned by the retrieval of non-presented but associated information (i.e., retrieving B when learning A-C), resulting in the integration of the presented and retrieved information (<xref ref-type="bibr" rid="R61">Molitor et al., 2021</xref>; <xref ref-type="bibr" rid="R62">Morton et al., 2023</xref>). A similar process could be occurring when participants view each endpoint, but only once they realise the endpoints are from the same location. Using pattern classification to assess the reactivation of endpoints during video presentation could assess this possibility. We were unable to distinguish between scene endpoints in the present study, preventing us from running this analysis. Future research would likely need fewer scenes with more repetitions per scene and more repetitions per video to allow for this type of analysis.</p><p id="P59">The vMPFC is also considered to interact with the hippocampus during this inferential integration process (<xref ref-type="bibr" rid="R62">Morton et al., 2023</xref>; <xref ref-type="bibr" rid="R74">Preston &amp; Eichenbaum, 2013</xref>), possibly via the theta rhythm (<xref ref-type="bibr" rid="R6">Backus et al., 2016</xref>). We did find that increases in theta power for overlap videos compared to non-overlap videos were localised to the vMPFC, but the vMPFC – Hippocampus connectivity analyses proved inconclusive, possibly due to low statistical power (see <xref ref-type="supplementary-material" rid="SD1">Supporting Information</xref> for details regarding the connectivity analyses). Theta power increases that we found in the vMPFC and the hippocampus could thus reflect similar inferential learning between the two endpoints to form location-based representations.</p><p id="P60">Another possibility is that both endpoints A and B are integrated into a more abstract, allocentric representation of the location (A*) that is reactivated during the memory test and leads to successful matching of endpoints A and B (<xref ref-type="bibr" rid="R8">Berens et al., 2021</xref>). Previous theories and computational models predict that such spatial learning occurs via communication between medial parietal and temporal regions in the scene-selective network (<xref ref-type="bibr" rid="R7">Baumann &amp; Mattingley, 2021</xref>; <xref ref-type="bibr" rid="R9">Bicanski &amp; Burgess, 2018</xref>; <xref ref-type="bibr" rid="R13">Byrne et al., 2007</xref>; <xref ref-type="bibr" rid="R57">Marchette et al., 2014</xref>). In line with these theories, we find that changes in oscillatory power during the formation of location-based representations were localised to the hippocampus, retrosplenial cortex, precuneus, lateral parietal cortices (IPL and SPL) and early visual cortex. Previous studies using similar paradigms have used fMRI and have found that the retrosplenial and parahippocampal cortices are responsible for representing location-based information (<xref ref-type="bibr" rid="R8">Berens et al., 2021</xref>; <xref ref-type="bibr" rid="R77">Robertson et al., 2016</xref>). However, these studies were not able to conclude that these regions were involved in the formation of these representations. It is not clear whether participants formed a more abstract allocentric representation (i.e., A*), or whether they formed a simpler associative memory (i.e., A-B), or whether the integrative mechanisms discussed above are the mechanistic basis for forming either of these possible representations. However, our results point clearly to a role for hippocampal and medial parietal theta in forming a more location-based representation that can support behaviour in the scene-matching task.</p><p id="P61">We also investigated the neural oscillations involved in the successful formation of location-based representations by contrasting activity from overlap videos that were subsequently remembered vs. forgotten (Subsequent Memory Effect, SME). We found hippocampal theta decreases for remembered compared to forgotten locations, hence we found a negative SME. This effect was just below the significance threshold (<italic>α</italic> = .05), possibly due to low trial and participant numbers leading to a low signal-to-noise ratio and thus low statistical power to detect effects. As such, compared to our main analyses that are powered appropriately, we draw caution in relation to this result (i.e., this result could simply be a false positive).</p><p id="P62">Several studies have reported increases in theta power for subsequently remembered compared to subsequently forgotten stimuli, for both item (<xref ref-type="bibr" rid="R26">Fellner et al., 2013</xref>; <xref ref-type="bibr" rid="R34">Guderian et al., 2009</xref>; <xref ref-type="bibr" rid="R38">Hanslmayr et al., 2009</xref>, <xref ref-type="bibr" rid="R41">2011</xref>; <xref ref-type="bibr" rid="R50">Khader et al., 2010</xref>; <xref ref-type="bibr" rid="R59">Meeuwissen et al., 2011</xref>; <xref ref-type="bibr" rid="R69">Osipova et al., 2006</xref>; <xref ref-type="bibr" rid="R79">Sederberg et al., 2006</xref>) and associative memory (<xref ref-type="bibr" rid="R6">Backus et al., 2016</xref>; <xref ref-type="bibr" rid="R15">Caplan &amp; Glaholt, 2007</xref>; <xref ref-type="bibr" rid="R18">Crespo-García et al., 2016</xref>; <xref ref-type="bibr" rid="R33">Griffiths et al., 2016</xref>; <xref ref-type="bibr" rid="R48">Joensen et al., 2023</xref>; <xref ref-type="bibr" rid="R82">Staudigl &amp; Hanslmayr, 2013</xref>; <xref ref-type="bibr" rid="R85">Summerfield &amp; Mangels, 2005</xref>). However, studies that have investigated associative learning in a spatial context have observed decreases in theta power for subsequently remembered vs. forgotten items. For example, <xref ref-type="bibr" rid="R26">Fellner et al., (2013)</xref> conducted a study where participants memorised a list of items using the method of loci, which involves associating items together in a spatial context, vs. the pegword method, which involves associating items together in a non-spatial context of a rhyme. They found a negative subsequent memory effect for items associated together in a spatial context compared to a non-spatial context. Two other studies on theta changes during associative learning in a spatial context also found theta decreases (<xref ref-type="bibr" rid="R18">Crespo-García et al., 2016</xref>; <xref ref-type="bibr" rid="R33">Griffiths et al., 2016</xref>). They studied item and location binding as participants navigated around a specified path and found theta decreases for subsequently remembered locations, cued by the items, compared to subsequently forgotten locations. Therefore, it is possible that negative subsequent memory effects arise when encoding of information occurs in a spatial context.</p><p id="P63">If a greater decrease in theta does reflect better encoding (and therefore subsequent memory), it is unclear why we also saw even greater decreases in theta in the non-overlap condition, where no learning appeared to be occurring (i.e., participants couldn’t match the scenes presented in the non-overlap condition following video watching). Although speculative, one possibility is that the decrease in theta we observe reflects a form of ‘encoding effort’. In the overlap condition, more ‘effort’ results in better subsequent memory as a location-based representation can be formed. However, in the non-overlap condition, increased ‘effort’ does not result in the formation of a location-based representations (as the scenes are from different locations) resulting in poor behavioural performance.</p><p id="P64">As well as seeing theta differences between the overlap and non-overlap condition (and a theta SME), we also found that alpha and low beta power (12 to 20Hz) was greater during the overlap than non-overlap condition. A recent study found that alpha/beta power increased during active environmental encoding compared to guided encoding and attributed this increase to increased attention during active vs. passive exploration (<xref ref-type="bibr" rid="R17">Chrastil et al., 2022</xref>). Therefore, it is possible that participants paid more attention while watching overlap than non-overlap videos. However, the dominant finding in the literature is that stimulus-onset induces a decrease in alpha/beta power that is considered to reflect increased attention (<xref ref-type="bibr" rid="R51">Klimesch, 2012</xref>) and representing stimulus-information necessary for the formation of episodic memories (<xref ref-type="bibr" rid="R31">Griffiths et al., 2021</xref>, <xref ref-type="bibr" rid="R32">2019</xref>; <xref ref-type="bibr" rid="R39">Hanslmayr et al., 2016</xref>; <xref ref-type="bibr" rid="R70">Parish et al., 2018</xref>). Thus, increased alpha/beta in the overlap condition is unlikely to be driven by simple attentional differences, unless participants were paying greater attention to the non-overlap condition (perhaps because it is more difficult to associate two scenes from different locations). These alpha/beta changes source-localised to the same hippocampal and medial parietal regions that were revealed in the theta analyses, although the precuneus perhaps was driven more by alpha/beta than theta changes suggesting a potential dissociation.</p><p id="P65">Our results are also in line with previous theories implicating the hippocampus, retrosplenial cortex and precuneus as critical for maintaining and transforming location-based representations (<xref ref-type="bibr" rid="R1">Alexander et al., 2023</xref>; <xref ref-type="bibr" rid="R9">Bicanski &amp; Burgess, 2018</xref>; <xref ref-type="bibr" rid="R70">Parish et al., 2018</xref>). This model proposes that ego-centric representations are supported by the precuneus and allocentric representations are supported by the hippocampus, with the retrosplenial cortex acting as a transformation circuit between these two references frames. There is evidence for more allocentric place cells in the hippocampus (<xref ref-type="bibr" rid="R65">O’Keefe &amp; Dostrovsky, 1971</xref>) and a heterogeneity of neural representations in the retrosplenial cortex, including neurons that fire in relation to combinations of heading direction, location, and landmark information (<xref ref-type="bibr" rid="R16">Chen et al., 1994</xref>; <xref ref-type="bibr" rid="R52">Knight et al., 2014</xref>; <xref ref-type="bibr" rid="R55">Lozano et al., 2017</xref>; <xref ref-type="bibr" rid="R56">Mao et al., 2017</xref>). Other theories implicate the hippocampus in allocentric ‘scene construction’ that supports both spatial navigation and episodic memory (<xref ref-type="bibr" rid="R44">Hassabis &amp; Maguire, 2007</xref>) and the retrosplenial cortex in landmark learning (e.g, <xref ref-type="bibr" rid="R4">Auger et al., 2012</xref>, <xref ref-type="bibr" rid="R5">2015</xref>; <xref ref-type="bibr" rid="R3">Auger &amp; Maguire, 2018</xref>) and the learning of schematic spatial knowledge (<xref ref-type="bibr" rid="R25">Farzanfar et al., 2022</xref>; <xref ref-type="bibr" rid="R60">Mitchell et al., 2018</xref>; <xref ref-type="bibr" rid="R71">Peer &amp; Epstein, 2021</xref>). Despite their differences, all these theories implicate the hippocampus and retrosplenial cortex in the learning of spatial representations.</p><p id="P66">We found oscillatory changes during location-learning in these brain regions, broadly in support of these theories. We did not however see clear regional differences in relation to oscillatory frequency bands, nor did we track the information flow across these regions over time. Such analyses would provide more mechanistic evidence for these theories. Future research could focus on hippocampal theta vs. medial parietal alpha/beta in relation to how these regions communicate within these frequency bands during the learning of novel spatial environments (<xref ref-type="bibr" rid="R39">Hanslmayr et al., 2016</xref>; <xref ref-type="bibr" rid="R70">Parish et al., 2018</xref>). Additionally, future research could investigate how these regions communicate via oscillations using functional or effective connectivity measures to provide more concrete evidence for these theories.</p><p id="P67">Although our effects were significant after correcting for multiple comparisons within each time-window, some of the effects did not survive a more stringent Bonferroni correction across time-windows. Specifically, our sensor-level effects failed to survive Bonferroni correction across the 6 time-windows of interest, and the non-hippocampal source-level effects also did not survive this correction. We did find that the hippocampal source-level results are robust since they are present in every analysis that we conducted. Therefore, we interpret the theta/alpha oscillatory changes in the hippocampus during the formation of location memories as a robust effect. It is important to note that the Bonferonni correction is especially conservative in this analysis because the data across the time-windows are likely not entirely independent. <xref ref-type="fig" rid="F5">Figure 5</xref> suggests the possibility of a relatively sustained (but small) increase in theta/alpha from 10-20secs. As such, even though our time-windows are not temporally adjacent, we may be assessing oscillatory differences that are driven by the same underlying source. This is also the first study to investigate the neural oscillations related to the formation of location-based representations. Considering these two points, we present the effects that survive correction within each time-window but have made clear which of these effects do not survive more stringent corrections across time-windows.</p><p id="P68">In conclusion, participants were able to match perceptually distinct viewpoints from the same location after viewing videos that showed the spatial relationship between these endpoints, potentially driven by the formation of a coherent representation of that location. Using MEG, we found that hippocampal and medial parietal theta and alpha/beta power increased when participants watched these videos compared to videos that did not allow for location-based representations to be formed. This finding adds to the literature implicating the hippocampal theta rhythm in episodic memory formation and spatial navigation (<xref ref-type="bibr" rid="R12">Buzsáki &amp; Moser, 2013</xref>; <xref ref-type="bibr" rid="R63">Nyhus &amp; Curran, 2010</xref>) by showing that it is implicated in combining egocentric, viewpoint-dependent scene information into a potentially allocentric, viewpoint-independent representation. Thus, we provide evidence in favour of models that predict the involvement of hippocampal and medial parietal regions in the formation of location-based representations (<xref ref-type="bibr" rid="R9">Bicanski &amp; Burgess, 2018</xref>; <xref ref-type="bibr" rid="R13">Byrne et al., 2007</xref>), and implicate theta and alpha/beta oscillations in the formation of such representations.</p></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplemental Information</label><media xlink:href="EMS189889-supplement-Supplemental_Information.pdf" mimetype="application" mime-subtype="pdf" id="d17aAdNbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S23"><title>Acknowledgements</title><p>This work was funded by a Wellcome Trust Institutional Strategic Support Fund (ISSF) to The University of York (204829/Z/16/Z), through the Centre for Future Health (CFH). AJH is funded by the Economic and Social Research Council (ESRC; ES/X00791X/1) and The Leverhulme Trust (RPG-2023-003). The authors thank Benjamin Griffiths, Richard Aveyard, Dan Denis, and Pranay Yadav for their advice with data analysis and the York Neuroimaging Centre (YNiC) staff for their assistance during data collection. For the purposes of open access, the authors have applied a creative commons attribution (CC-BY) license to any author accepted manuscripts version arising henceforth.</p></ack><sec id="S24" sec-type="data-availability"><title>Data availability statement</title><p id="P69">The behavioural data and analysis code, and MEG analysis code that support the findings of this study are openly available in the Open Science Framework <ext-link ext-link-type="uri" xlink:href="https://osf.io/y4hev/?view_only=fce12d0877d4402ca54d61923ca3bf9e">here</ext-link>.</p></sec><fn-group><fn id="FN1" fn-type="conflict"><p id="P70"><bold>Conflict of Interest</bold></p><p id="P71">The authors declare no conflicts of interests.</p></fn></fn-group><ref-list><ref id="R1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alexander</surname><given-names>AS</given-names></name><name><surname>Robinson</surname><given-names>JC</given-names></name><name><surname>Stern</surname><given-names>CE</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group><article-title>Gated transformations from egocentric to allocentric reference frames involving retrosplenial cortex, entorhinal cortex, and hippocampus</article-title><source>Hippocampus</source><year>2023</year><volume>33</volume><issue>5</issue><fpage>465</fpage><lpage>487</lpage><pub-id pub-id-type="pmcid">PMC10403145</pub-id><pub-id pub-id-type="pmid">36861201</pub-id><pub-id pub-id-type="doi">10.1002/hipo.23513</pub-id></element-citation></ref><ref id="R2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arnulfo</surname><given-names>G</given-names></name><name><surname>Hirvonen</surname><given-names>J</given-names></name><name><surname>Nobili</surname><given-names>L</given-names></name><name><surname>Palva</surname><given-names>S</given-names></name><name><surname>Palva</surname><given-names>JM</given-names></name></person-group><article-title>Phase and amplitude correlations in resting-state activity in human stereotactical EEG recordings</article-title><source>NeuroImage</source><year>2015</year><volume>112</volume><fpage>114</fpage><lpage>127</lpage><pub-id pub-id-type="pmid">25721426</pub-id></element-citation></ref><ref id="R3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Auger</surname><given-names>SD</given-names></name><name><surname>Maguire</surname><given-names>EA</given-names></name></person-group><article-title>Dissociating Landmark Stability from Orienting Value Using Functional Magnetic Resonance Imaging</article-title><source>Journal of Cognitive Neuroscience</source><year>2018</year><volume>30</volume><issue>5</issue><fpage>698</fpage><lpage>713</lpage><pub-id pub-id-type="pmcid">PMC6118409</pub-id><pub-id pub-id-type="pmid">29308982</pub-id><pub-id pub-id-type="doi">10.1162/jocn_a_01231</pub-id></element-citation></ref><ref id="R4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Auger</surname><given-names>SD</given-names></name><name><surname>Mullally</surname><given-names>SL</given-names></name><name><surname>Maguire</surname><given-names>EA</given-names></name></person-group><article-title>Retrosplenial Cortex Codes for Permanent Landmarks</article-title><source>PLOS ONE</source><year>2012</year><volume>7</volume><issue>8</issue><elocation-id>e43620</elocation-id><pub-id pub-id-type="pmcid">PMC3422332</pub-id><pub-id pub-id-type="pmid">22912894</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0043620</pub-id></element-citation></ref><ref id="R5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Auger</surname><given-names>SD</given-names></name><name><surname>Zeidman</surname><given-names>P</given-names></name><name><surname>Maguire</surname><given-names>EA</given-names></name></person-group><article-title>A central role for the retrosplenial cortex in de novo environmental learning</article-title><source>eLife</source><year>2015</year><volume>4</volume><elocation-id>e09031</elocation-id><pub-id pub-id-type="pmcid">PMC4559753</pub-id><pub-id pub-id-type="pmid">26284602</pub-id><pub-id pub-id-type="doi">10.7554/eLife.09031</pub-id></element-citation></ref><ref id="R6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Backus</surname><given-names>AR</given-names></name><name><surname>Schoffelen</surname><given-names>J-M</given-names></name><name><surname>Szebényi</surname><given-names>S</given-names></name><name><surname>Hanslmayr</surname><given-names>S</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name></person-group><article-title>Hippocampal-Prefrontal Theta Oscillations Support Memory Integration</article-title><source>Current Biology</source><year>2016</year><volume>26</volume><issue>4</issue><fpage>450</fpage><lpage>457</lpage><pub-id pub-id-type="pmid">26832442</pub-id></element-citation></ref><ref id="R7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baumann</surname><given-names>O</given-names></name><name><surname>Mattingley</surname><given-names>JB</given-names></name></person-group><article-title>Extrahippocampal contributions to spatial navigation in humans: A review of the neuroimaging evidence</article-title><source>Hippocampus</source><year>2021</year><volume>31</volume><issue>7</issue><fpage>640</fpage><lpage>657</lpage><pub-id pub-id-type="pmid">33595156</pub-id></element-citation></ref><ref id="R8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berens</surname><given-names>SC</given-names></name><name><surname>Joensen</surname><given-names>BH</given-names></name><name><surname>Horner</surname><given-names>AJ</given-names></name></person-group><article-title>Tracking the emergence of location-based spatial representations in human scene-selective cortex</article-title><source>Journal of Cognitive Neuroscience</source><year>2021</year><volume>33</volume><issue>3</issue><fpage>445</fpage><lpage>462</lpage><pub-id pub-id-type="pmcid">PMC8658499</pub-id><pub-id pub-id-type="pmid">33284080</pub-id><pub-id pub-id-type="doi">10.1162/jocn_a_01654</pub-id></element-citation></ref><ref id="R9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bicanski</surname><given-names>A</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><article-title>A neural-level model of spatial memory and imagery</article-title><source>ELife</source><year>2018</year><volume>7</volume><elocation-id>e33752</elocation-id><pub-id pub-id-type="pmcid">PMC6122954</pub-id><pub-id pub-id-type="pmid">30176988</pub-id><pub-id pub-id-type="doi">10.7554/eLife.33752</pub-id></element-citation></ref><ref id="R10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burgess</surname><given-names>N</given-names></name><name><surname>Maguire</surname><given-names>EA</given-names></name><name><surname>O’Keefe</surname><given-names>J</given-names></name></person-group><article-title>The Human Hippocampus and Spatial and Episodic Memory</article-title><source>Neuron</source><year>2002</year><volume>35</volume><issue>4</issue><fpage>625</fpage><lpage>641</lpage><pub-id pub-id-type="pmid">12194864</pub-id></element-citation></ref><ref id="R11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><article-title>Theta Oscillations in the Hippocampus</article-title><source>Neuron</source><year>2002</year><volume>33</volume><issue>3</issue><fpage>325</fpage><lpage>340</lpage><pub-id pub-id-type="pmid">11832222</pub-id></element-citation></ref><ref id="R12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buzsáki</surname><given-names>G</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><article-title>Memory, navigation and theta rhythm in the hippocampal-entorhinal system</article-title><source>Nature Neuroscience</source><year>2013</year><volume>16</volume><issue>2</issue><comment>Article 2</comment><pub-id pub-id-type="pmcid">PMC4079500</pub-id><pub-id pub-id-type="pmid">23354386</pub-id><pub-id pub-id-type="doi">10.1038/nn.3304</pub-id></element-citation></ref><ref id="R13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Byrne</surname><given-names>P</given-names></name><name><surname>Becker</surname><given-names>S</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><article-title>Remembering the past and imagining the future</article-title><source>Psychological Review</source><year>2007</year><volume>114</volume><issue>2</issue><fpage>340</fpage><lpage>375</lpage><pub-id pub-id-type="pmcid">PMC2678675</pub-id><pub-id pub-id-type="pmid">17500630</pub-id><pub-id pub-id-type="doi">10.1037/0033-295X.114.2.340</pub-id></element-citation></ref><ref id="R14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bzymek</surname><given-names>K</given-names></name><name><surname>Kloosterman</surname><given-names>F</given-names></name></person-group><article-title>Theta cycle dynamics of spatial representations in the lateral septum</article-title><source>bioRxiv</source><year>2023</year><elocation-id>2023.07.17.549368</elocation-id><pub-id pub-id-type="doi">10.1101/2023.07.17.549368</pub-id></element-citation></ref><ref id="R15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caplan</surname><given-names>JB</given-names></name><name><surname>Glaholt</surname><given-names>MG</given-names></name></person-group><article-title>The roles of EEG oscillations in learning relational information</article-title><source>NeuroImage</source><year>2007</year><volume>38</volume><issue>3</issue><fpage>604</fpage><lpage>616</lpage><pub-id pub-id-type="pmid">17881249</pub-id></element-citation></ref><ref id="R16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>LL</given-names></name><name><surname>Lin</surname><given-names>LH</given-names></name><name><surname>Barnes</surname><given-names>CA</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><article-title>Head-direction cells in the rat posterior cortex. II. Contributions of visual and ideothetic information to the directional firing</article-title><source>Experimental Brain Research</source><year>1994</year><volume>101</volume><issue>1</issue><fpage>24</fpage><lpage>34</lpage><pub-id pub-id-type="pmid">7843299</pub-id></element-citation></ref><ref id="R17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chrastil</surname><given-names>ER</given-names></name><name><surname>Rice</surname><given-names>C</given-names></name><name><surname>Goncalves</surname><given-names>M</given-names></name><name><surname>Moore</surname><given-names>KN</given-names></name><name><surname>Wynn</surname><given-names>SC</given-names></name><name><surname>Stern</surname><given-names>CE</given-names></name><name><surname>Nyhus</surname><given-names>E</given-names></name></person-group><article-title>Theta oscillations support active exploration in human spatial navigation</article-title><source>NeuroImage</source><year>2022</year><volume>262</volume><elocation-id>119581</elocation-id><pub-id pub-id-type="pmid">35995375</pub-id></element-citation></ref><ref id="R18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crespo-García</surname><given-names>M</given-names></name><name><surname>Zeiller</surname><given-names>M</given-names></name><name><surname>Leupold</surname><given-names>C</given-names></name><name><surname>Kreiselmeyer</surname><given-names>G</given-names></name><name><surname>Rampp</surname><given-names>S</given-names></name><name><surname>Hamer</surname><given-names>HM</given-names></name><name><surname>Dalal</surname><given-names>SS</given-names></name></person-group><article-title>Slow-theta power decreases during item-place encoding predict spatial accuracy of subsequent context recall</article-title><source>NeuroImage</source><year>2016</year><volume>142</volume><fpage>533</fpage><lpage>543</lpage><pub-id pub-id-type="pmid">27521743</pub-id></element-citation></ref><ref id="R19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Denis</surname><given-names>D</given-names></name><name><surname>Mylonas</surname><given-names>D</given-names></name><name><surname>Poskanzer</surname><given-names>C</given-names></name><name><surname>Bursal</surname><given-names>V</given-names></name><name><surname>Payne</surname><given-names>JD</given-names></name><name><surname>Stickgold</surname><given-names>R</given-names></name></person-group><article-title>Sleep spindles preferentially consolidate weakly encoded memories</article-title><source>Journal of Neuroscience</source><year>2021</year><volume>41</volume><issue>18</issue><fpage>4088</fpage><lpage>4099</lpage><pub-id pub-id-type="pmcid">PMC8176750</pub-id><pub-id pub-id-type="pmid">33741722</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0818-20.2021</pub-id></element-citation></ref><ref id="R20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Du</surname><given-names>YK</given-names></name><name><surname>Liang</surname><given-names>M</given-names></name><name><surname>McAvan</surname><given-names>AS</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Ekstrom</surname><given-names>AD</given-names></name></person-group><article-title>Frontal-midline theta and posterior alpha oscillations index early processing of spatial representations during active navigation</article-title><source>bioRxiv</source><year>2023</year><elocation-id>2023.04.22.537940</elocation-id><pub-id pub-id-type="pmcid">PMC10841878</pub-id><pub-id pub-id-type="pmid">37862831</pub-id><pub-id pub-id-type="doi">10.1016/j.cortex.2023.09.005</pub-id></element-citation></ref><ref id="R21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Epstein</surname><given-names>RA</given-names></name></person-group><article-title>Parahippocampal and retrosplenial contributions to human spatial navigation</article-title><source>Trends in Cognitive Sciences</source><year>2008</year><volume>12</volume><issue>10</issue><fpage>388</fpage><lpage>396</lpage><pub-id pub-id-type="pmcid">PMC2858632</pub-id><pub-id pub-id-type="pmid">18760955</pub-id><pub-id pub-id-type="doi">10.1016/j.tics.2008.07.004</pub-id></element-citation></ref><ref id="R22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Epstein</surname><given-names>RA</given-names></name><name><surname>Baker</surname><given-names>CI</given-names></name></person-group><article-title>Scene Perception in the Human Brain</article-title><source>Annual Review of Vision Science</source><year>2019</year><volume>5</volume><issue>1</issue><fpage>373</fpage><lpage>397</lpage><pub-id pub-id-type="pmcid">PMC6989029</pub-id><pub-id pub-id-type="pmid">31226012</pub-id><pub-id pub-id-type="doi">10.1146/annurev-vision-091718-014809</pub-id></element-citation></ref><ref id="R23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Epstein</surname><given-names>RA</given-names></name><name><surname>Vass</surname><given-names>LK</given-names></name></person-group><article-title>Neural systems for landmark-based wayfinding in humans</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><year>2014</year><volume>369</volume><issue>1635</issue><elocation-id>20120533</elocation-id><pub-id pub-id-type="pmcid">PMC3866451</pub-id><pub-id pub-id-type="pmid">24366141</pub-id><pub-id pub-id-type="doi">10.1098/rstb.2012.0533</pub-id></element-citation></ref><ref id="R24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fan</surname><given-names>L</given-names></name><name><surname>Li</surname><given-names>H</given-names></name><name><surname>Zhuo</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Chen</surname><given-names>L</given-names></name><name><surname>Yang</surname><given-names>Z</given-names></name><name><surname>Chu</surname><given-names>C</given-names></name><name><surname>Xie</surname><given-names>S</given-names></name><name><surname>Laird</surname><given-names>AR</given-names></name><name><surname>Fox</surname><given-names>PT</given-names></name><etal/></person-group><article-title>The Human Brainnetome Atlas: A New Brain Atlas Based on Connectional Architecture</article-title><source>Cerebral Cortex (New York, NY: 1991)</source><year>2016</year><volume>26</volume><issue>8</issue><fpage>3508</fpage><lpage>3526</lpage><pub-id pub-id-type="pmcid">PMC4961028</pub-id><pub-id pub-id-type="pmid">27230218</pub-id><pub-id pub-id-type="doi">10.1093/cercor/bhw157</pub-id></element-citation></ref><ref id="R25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Farzanfar</surname><given-names>D</given-names></name><name><surname>Spiers</surname><given-names>HJ</given-names></name><name><surname>Moscovitch</surname><given-names>M</given-names></name><name><surname>Rosenbaum</surname><given-names>RS</given-names></name></person-group><article-title>From cognitive maps to spatial schemas</article-title><source>Nature Reviews Neuroscience</source><year>2022</year><fpage>1</fpage><lpage>17</lpage><pub-id pub-id-type="pmid">36414839</pub-id></element-citation></ref><ref id="R26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fellner</surname><given-names>M-C</given-names></name><name><surname>Bäuml</surname><given-names>K-HT</given-names></name><name><surname>Hanslmayr</surname><given-names>S</given-names></name></person-group><article-title>Brain oscillatory subséquent memory effects differ in power and long-range synchronization between semantic and survival processing</article-title><source>NeuroImage</source><year>2013</year><volume>79</volume><fpage>361</fpage><lpage>370</lpage><pub-id pub-id-type="pmid">23664950</pub-id></element-citation></ref><ref id="R27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fellner</surname><given-names>M-C</given-names></name><name><surname>Gollwitzer</surname><given-names>S</given-names></name><name><surname>Rampp</surname><given-names>S</given-names></name><name><surname>Kreiselmeyr</surname><given-names>G</given-names></name><name><surname>Bush</surname><given-names>D</given-names></name><name><surname>Diehl</surname><given-names>B</given-names></name><name><surname>Axmacher</surname><given-names>N</given-names></name><name><surname>Hamer</surname><given-names>H</given-names></name><name><surname>Hanslmayr</surname><given-names>S</given-names></name></person-group><article-title>Spectral fingerprints or spectral tilt? Evidence for distinct oscillatory signatures of memory formation</article-title><source>PLOS Biology</source><year>2019</year><volume>17</volume><issue>7</issue><elocation-id>e3000403</elocation-id><pub-id pub-id-type="pmcid">PMC6687190</pub-id><pub-id pub-id-type="pmid">31356598</pub-id><pub-id pub-id-type="doi">10.1371/journal.pbio.3000403</pub-id></element-citation></ref><ref id="R28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fellner</surname><given-names>M-C</given-names></name><name><surname>Volberg</surname><given-names>G</given-names></name><name><surname>Wimber</surname><given-names>M</given-names></name><name><surname>Goldhacker</surname><given-names>M</given-names></name><name><surname>Greenlee</surname><given-names>MW</given-names></name><name><surname>Hanslmayr</surname><given-names>S</given-names></name></person-group><article-title>Spatial Mnemonic Encoding: Theta Power Decreases and Medial Temporal Lobe BOLD Increases Co-Occur during the Usage of the Method of Loci</article-title><source>ENeuro</source><year>2016</year><volume>3</volume><issue>6</issue><pub-id pub-id-type="pmcid">PMC5223054</pub-id><pub-id pub-id-type="pmid">28101523</pub-id><pub-id pub-id-type="doi">10.1523/ENEURO.0184-16.2016</pub-id></element-citation></ref><ref id="R29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferrante</surname><given-names>O</given-names></name><name><surname>Liu</surname><given-names>L</given-names></name><name><surname>Minarik</surname><given-names>T</given-names></name><name><surname>Gorska</surname><given-names>U</given-names></name><name><surname>Ghafari</surname><given-names>T</given-names></name><name><surname>Luo</surname><given-names>H</given-names></name><name><surname>Jensen</surname><given-names>O</given-names></name></person-group><article-title>FLUX: A pipeline for MEG analysis</article-title><source>NeuroImage</source><year>2022</year><elocation-id>119047</elocation-id><pub-id pub-id-type="pmcid">PMC9127391</pub-id><pub-id pub-id-type="pmid">35276363</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2022.119047</pub-id></element-citation></ref><ref id="R30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gloveli</surname><given-names>T</given-names></name><name><surname>Dugladze</surname><given-names>T</given-names></name><name><surname>Rotstein</surname><given-names>HG</given-names></name><name><surname>Traub</surname><given-names>RD</given-names></name><name><surname>Monyer</surname><given-names>H</given-names></name><name><surname>Heinemann</surname><given-names>U</given-names></name><name><surname>Whittington</surname><given-names>MA</given-names></name><name><surname>Kopell</surname><given-names>NJ</given-names></name></person-group><article-title>Orthogonal arrangement of rhythm-generating microcircuits in the hippocampus</article-title><source>Proceedings of the National Academy of Sciences</source><year>2005</year><volume>102</volume><issue>37</issue><fpage>13295</fpage><lpage>13300</lpage><pub-id pub-id-type="pmcid">PMC1201613</pub-id><pub-id pub-id-type="pmid">16141320</pub-id><pub-id pub-id-type="doi">10.1073/pnas.0506259102</pub-id></element-citation></ref><ref id="R31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Griffiths</surname><given-names>BJ</given-names></name><name><surname>Martín-Buro</surname><given-names>MC</given-names></name><name><surname>Staresina</surname><given-names>BP</given-names></name><name><surname>Hanslmayr</surname><given-names>S</given-names></name></person-group><article-title>Disentangling neocortical alpha/beta and hippocampal theta/gamma oscillations in human episodic memory formation</article-title><source>NeuroImage</source><year>2021</year><volume>242</volume><elocation-id>118454</elocation-id><pub-id pub-id-type="pmcid">PMC8463840</pub-id><pub-id pub-id-type="pmid">34358658</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2021.118454</pub-id></element-citation></ref><ref id="R32"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Griffiths</surname><given-names>BJ</given-names></name><name><surname>Mayhew</surname><given-names>SD</given-names></name><name><surname>Mullinger</surname><given-names>KJ</given-names></name><name><surname>Jorge</surname><given-names>J</given-names></name><name><surname>Charest</surname><given-names>I</given-names></name><name><surname>Wimber</surname><given-names>M</given-names></name><name><surname>Hanslmayr</surname><given-names>S</given-names></name></person-group><article-title>Alpha/beta power decreases track the fidelity of stimulus-specific information</article-title><source>ELife</source><year>2019</year><month>November</month><day>29</day><publisher-name>eLife Sciences Publications Limited</publisher-name><pub-id pub-id-type="pmcid">PMC6904219</pub-id><pub-id pub-id-type="pmid">31782730</pub-id><pub-id pub-id-type="doi">10.7554/eLife.49562</pub-id></element-citation></ref><ref id="R33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Griffiths</surname><given-names>BJ</given-names></name><name><surname>Mazaheri</surname><given-names>A</given-names></name><name><surname>Debener</surname><given-names>S</given-names></name><name><surname>Hanslmayr</surname><given-names>S</given-names></name></person-group><article-title>Brain oscillations track the formation of episodic memories in the real world</article-title><source>NeuroImage</source><year>2016</year><volume>143</volume><fpage>256</fpage><lpage>266</lpage><pub-id pub-id-type="pmid">27622395</pub-id></element-citation></ref><ref id="R34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guderian</surname><given-names>S</given-names></name><name><surname>Schott</surname><given-names>BH</given-names></name><name><surname>Richardson-Klavehn</surname><given-names>A</given-names></name><name><surname>Düzel</surname><given-names>E</given-names></name></person-group><article-title>Medial temporal theta state before an event predicts episodic encoding success in humans</article-title><source>Proceedings of the National Academy of Sciences</source><year>2009</year><volume>106</volume><issue>13</issue><fpage>5365</fpage><lpage>5370</lpage><pub-id pub-id-type="pmcid">PMC2663999</pub-id><pub-id pub-id-type="pmid">19289818</pub-id><pub-id pub-id-type="doi">10.1073/pnas.0900289106</pub-id></element-citation></ref><ref id="R35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guitart-Masip</surname><given-names>M</given-names></name><name><surname>Barnes</surname><given-names>GR</given-names></name><name><surname>Horner</surname><given-names>A</given-names></name><name><surname>Bauer</surname><given-names>M</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Duzel</surname><given-names>E</given-names></name></person-group><article-title>Synchronization of Medial Temporal Lobe and Prefrontal Rhythms in Human Decision Making</article-title><source>Journal of Neuroscience</source><year>2013</year><volume>33</volume><issue>2</issue><fpage>442</fpage><lpage>451</lpage><pub-id pub-id-type="pmcid">PMC3562870</pub-id><pub-id pub-id-type="pmid">23303925</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2573-12.2013</pub-id></element-citation></ref><ref id="R36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hafting</surname><given-names>T</given-names></name><name><surname>Fyhn</surname><given-names>M</given-names></name><name><surname>Molden</surname><given-names>S</given-names></name><name><surname>Moser</surname><given-names>M-B</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><article-title>Microstructure of a spatial map in the entorhinal cortex</article-title><source>Nature</source><year>2005</year><volume>436</volume><issue>7052</issue><comment>Article 7052</comment><pub-id pub-id-type="pmid">15965463</pub-id></element-citation></ref><ref id="R37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hangya</surname><given-names>B</given-names></name><name><surname>Borhegyi</surname><given-names>Z</given-names></name><name><surname>Szilágyi</surname><given-names>N</given-names></name><name><surname>Freund</surname><given-names>TF</given-names></name><name><surname>Varga</surname><given-names>V</given-names></name></person-group><article-title>GABAergic Neurons of the Medial Septum Lead the Hippocampal Network during Theta Activity</article-title><source>Journal of Neuroscience</source><year>2009</year><volume>29</volume><issue>25</issue><fpage>8094</fpage><lpage>8102</lpage><pub-id pub-id-type="pmcid">PMC6666051</pub-id><pub-id pub-id-type="pmid">19553449</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5665-08.2009</pub-id></element-citation></ref><ref id="R38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanslmayr</surname><given-names>S</given-names></name><name><surname>Spitzer</surname><given-names>B</given-names></name><name><surname>Bäuml</surname><given-names>K-H</given-names></name></person-group><article-title>Brain Oscillations Dissociate between Semantic and Nonsemantic Encoding of Episodic Memories</article-title><source>Cerebral Cortex</source><year>2009</year><volume>19</volume><issue>7</issue><fpage>1631</fpage><lpage>1640</lpage><pub-id pub-id-type="pmid">19001457</pub-id></element-citation></ref><ref id="R39"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hanslmayr</surname><given-names>S</given-names></name><name><surname>Staresina</surname><given-names>BP</given-names></name><name><surname>Bowman</surname><given-names>H</given-names></name></person-group><chapter-title>Oscillations and Episodic Memory: Addressing the Synchronization/Desynchronization Conundrum</chapter-title><source>Trends in Neurosciences</source><year>2016</year><volume>39</volume><issue>1</issue><fpage>16</fpage><lpage>25</lpage><publisher-name>Elsevier Ltd</publisher-name><pub-id pub-id-type="pmcid">PMC4819444</pub-id><pub-id pub-id-type="pmid">26763659</pub-id><pub-id pub-id-type="doi">10.1016/j.tins.2015.11.004</pub-id></element-citation></ref><ref id="R40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanslmayr</surname><given-names>S</given-names></name><name><surname>Staudigl</surname><given-names>T</given-names></name></person-group><article-title>How brain oscillations form memories—A processing based perspective on oscillatory subsequent memory effects</article-title><source>NeuroImage</source><year>2014</year><volume>85</volume><fpage>648</fpage><lpage>655</lpage><pub-id pub-id-type="pmid">23769913</pub-id></element-citation></ref><ref id="R41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanslmayr</surname><given-names>S</given-names></name><name><surname>Volberg</surname><given-names>G</given-names></name><name><surname>Wimber</surname><given-names>M</given-names></name><name><surname>Raabe</surname><given-names>M</given-names></name><name><surname>Greenlee</surname><given-names>MW</given-names></name><name><surname>Bäuml</surname><given-names>KHT</given-names></name></person-group><article-title>The relationship between brain oscillations and BOLD signal during memory formation: A combined EEG-fMRI study</article-title><source>Journal of Neuroscience</source><year>2011</year><volume>31</volume><issue>44</issue><fpage>15674</fpage><lpage>15680</lpage><pub-id pub-id-type="pmcid">PMC6623030</pub-id><pub-id pub-id-type="pmid">22049410</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3140-11.2011</pub-id></element-citation></ref><ref id="R42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hartley</surname><given-names>T</given-names></name><name><surname>Lever</surname><given-names>C</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name><name><surname>O’Keefe</surname><given-names>J</given-names></name></person-group><article-title>Space in the brain: How the hippocampal formation supports spatial cognition</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><year>2014</year><volume>369</volume><issue>1635</issue><elocation-id>20120510</elocation-id><pub-id pub-id-type="pmcid">PMC3866435</pub-id><pub-id pub-id-type="pmid">24366125</pub-id><pub-id pub-id-type="doi">10.1098/rstb.2012.0510</pub-id></element-citation></ref><ref id="R43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasselmo</surname><given-names>ME</given-names></name><name><surname>Bodelón</surname><given-names>C</given-names></name><name><surname>Wyble</surname><given-names>BP</given-names></name></person-group><article-title>A Proposed Function for Hippocampal Theta Rhythm: Separate Phases of Encoding and Retrieval Enhance Reversal of Prior Learning</article-title><source>Neural Computation</source><year>2002</year><volume>14</volume><issue>4</issue><fpage>793</fpage><lpage>817</lpage><pub-id pub-id-type="pmid">11936962</pub-id></element-citation></ref><ref id="R44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Maguire</surname><given-names>EA</given-names></name></person-group><article-title>Deconstructing episodic memory with construction</article-title><source>Trends in Cognitive Sciences</source><year>2007</year><volume>11</volume><issue>7</issue><fpage>299</fpage><lpage>306</lpage><pub-id pub-id-type="pmid">17548229</pub-id></element-citation></ref><ref id="R45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herweg</surname><given-names>NA</given-names></name><name><surname>Solomon</surname><given-names>EA</given-names></name><name><surname>Kahana</surname><given-names>MJ</given-names></name></person-group><article-title>Theta Oscillations in Human Memory</article-title><source>Trends in Cognitive Sciences</source><year>2020</year><volume>24</volume><issue>3</issue><fpage>208</fpage><lpage>227</lpage><pub-id pub-id-type="pmcid">PMC8310425</pub-id><pub-id pub-id-type="pmid">32029359</pub-id><pub-id pub-id-type="doi">10.1016/j.tics.2019.12.006</pub-id></element-citation></ref><ref id="R46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horner</surname><given-names>AJ</given-names></name><name><surname>Bisby</surname><given-names>JA</given-names></name><name><surname>Bush</surname><given-names>D</given-names></name><name><surname>Lin</surname><given-names>W-J</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><article-title>Evidence for holistic episodic recollection via hippocampal pattern completion</article-title><source>Nature Communications</source><year>2015</year><volume>6</volume><issue>1</issue><comment>Article 1</comment><pub-id pub-id-type="pmcid">PMC4506995</pub-id><pub-id pub-id-type="pmid">26136141</pub-id><pub-id pub-id-type="doi">10.1038/ncomms8462</pub-id></element-citation></ref><ref id="R47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jensen</surname><given-names>O</given-names></name><name><surname>Mazaheri</surname><given-names>A</given-names></name></person-group><article-title>Shaping Functional Architecture by Oscillatory Alpha Activity: Gating by Inhibition</article-title><source>Frontiers in Human Neuroscience</source><year>2010</year><volume>4</volume><fpage>186</fpage><pub-id pub-id-type="pmcid">PMC2990626</pub-id><pub-id pub-id-type="pmid">21119777</pub-id><pub-id pub-id-type="doi">10.3389/fnhum.2010.00186</pub-id></element-citation></ref><ref id="R48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joensen</surname><given-names>BH</given-names></name><name><surname>Bush</surname><given-names>D</given-names></name><name><surname>Vivekananda</surname><given-names>U</given-names></name><name><surname>Horner</surname><given-names>AJ</given-names></name><name><surname>Bisby</surname><given-names>JA</given-names></name><name><surname>Diehl</surname><given-names>B</given-names></name><name><surname>Miserocchi</surname><given-names>A</given-names></name><name><surname>McEvoy</surname><given-names>AW</given-names></name><name><surname>Walker</surname><given-names>MC</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><article-title>Hippocampal theta activity during encoding promotes subsequent associative memory in humans</article-title><source>Cerebral Cortex</source><year>2023</year><elocation-id>bhad162</elocation-id><pub-id pub-id-type="pmcid">PMC10321091</pub-id><pub-id pub-id-type="pmid">37160345</pub-id><pub-id pub-id-type="doi">10.1093/cercor/bhad162</pub-id></element-citation></ref><ref id="R49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaplan</surname><given-names>R</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name><name><surname>Barnes</surname><given-names>GR</given-names></name><name><surname>Litvak</surname><given-names>V</given-names></name><name><surname>Düzel</surname><given-names>E</given-names></name><name><surname>Bandettini</surname><given-names>PA</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><article-title>Movement-related theta rhythm in humans: Coordinating self-directed hippocampal learning</article-title><source>PLoS Biology</source><year>2012</year><volume>10</volume><issue>2</issue><elocation-id>e1001267</elocation-id><pub-id pub-id-type="pmcid">PMC3289589</pub-id><pub-id pub-id-type="pmid">22389627</pub-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1001267</pub-id></element-citation></ref><ref id="R50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khader</surname><given-names>PH</given-names></name><name><surname>Jost</surname><given-names>K</given-names></name><name><surname>Ranganath</surname><given-names>C</given-names></name><name><surname>Rösler</surname><given-names>F</given-names></name></person-group><article-title>Theta and alpha oscillations during working-memory maintenance predict successful long-term memory encoding</article-title><source>Neuroscience Letters</source><year>2010</year><volume>468</volume><issue>3</issue><fpage>339</fpage><lpage>343</lpage><pub-id pub-id-type="pmcid">PMC3951969</pub-id><pub-id pub-id-type="pmid">19922772</pub-id><pub-id pub-id-type="doi">10.1016/j.neulet.2009.11.028</pub-id></element-citation></ref><ref id="R51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klimesch</surname><given-names>W</given-names></name></person-group><article-title>α-band oscillations, attention, and controlled access to stored information</article-title><source>Trends in Cognitive Sciences</source><year>2012</year><volume>16</volume><issue>12</issue><fpage>606</fpage><lpage>617</lpage><pub-id pub-id-type="pmcid">PMC3507158</pub-id><pub-id pub-id-type="pmid">23141428</pub-id><pub-id pub-id-type="doi">10.1016/j.tics.2012.10.007</pub-id></element-citation></ref><ref id="R52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knight</surname><given-names>R</given-names></name><name><surname>Piette</surname><given-names>CE</given-names></name><name><surname>Page</surname><given-names>H</given-names></name><name><surname>Walters</surname><given-names>D</given-names></name><name><surname>Marozzi</surname><given-names>E</given-names></name><name><surname>Nardini</surname><given-names>M</given-names></name><name><surname>Stringer</surname><given-names>S</given-names></name><name><surname>Jeffery</surname><given-names>KJ</given-names></name></person-group><article-title>Weighted cue integration in the rodent head direction system</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><year>2014</year><volume>369</volume><issue>1635</issue><elocation-id>20120512</elocation-id><pub-id pub-id-type="pmcid">PMC3866437</pub-id><pub-id pub-id-type="pmid">24366127</pub-id><pub-id pub-id-type="doi">10.1098/rstb.2012.0512</pub-id></element-citation></ref><ref id="R53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Korczyn</surname><given-names>AD</given-names></name><name><surname>Schachter</surname><given-names>SC</given-names></name><name><surname>Brodie</surname><given-names>MJ</given-names></name><name><surname>Dalal</surname><given-names>SS</given-names></name><name><surname>Engel</surname><given-names>J</given-names></name><name><surname>Guekht</surname><given-names>A</given-names></name><name><surname>Hecimovic</surname><given-names>H</given-names></name><name><surname>Jerbi</surname><given-names>K</given-names></name><name><surname>Kanner</surname><given-names>AM</given-names></name><name><surname>Johannessen Landmark</surname><given-names>C</given-names></name><name><surname>Mares</surname><given-names>P</given-names></name><etal/></person-group><article-title>Epilepsy, cognition, and neuropsychiatry (Epilepsy, Brain, and Mind, part 2)</article-title><source>Epilepsy &amp; Behavior</source><year>2013</year><volume>28</volume><issue>2</issue><fpage>283</fpage><lpage>302</lpage><pub-id pub-id-type="pmcid">PMC5016028</pub-id><pub-id pub-id-type="pmid">23764496</pub-id><pub-id pub-id-type="doi">10.1016/j.yebeh.2013.03.012</pub-id></element-citation></ref><ref id="R54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lever</surname><given-names>C</given-names></name><name><surname>Burton</surname><given-names>S</given-names></name><name><surname>Jeewajee</surname><given-names>A</given-names></name><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><article-title>Boundary vector cells in the subiculum of the hippocampal formation</article-title><source>The Journal of Neuroscience: The Official Journal of the Society for Neuroscience</source><year>2009</year><volume>29</volume><issue>31</issue><fpage>9771</fpage><lpage>9777</lpage><pub-id pub-id-type="pmcid">PMC2736390</pub-id><pub-id pub-id-type="pmid">19657030</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1319-09.2009</pub-id></element-citation></ref><ref id="R55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lozano</surname><given-names>YR</given-names></name><name><surname>Page</surname><given-names>H</given-names></name><name><surname>Jacob</surname><given-names>P-Y</given-names></name><name><surname>Lomi</surname><given-names>E</given-names></name><name><surname>Street</surname><given-names>J</given-names></name><name><surname>Jeffery</surname><given-names>K</given-names></name></person-group><article-title>Retrosplenial and postsubicular head direction cells compared during visual landmark discrimination</article-title><source>Brain and Neuroscience Advances</source><year>2017</year><volume>1</volume><elocation-id>2398212817721859</elocation-id><pub-id pub-id-type="pmcid">PMC6124005</pub-id><pub-id pub-id-type="pmid">30246155</pub-id><pub-id pub-id-type="doi">10.1177/2398212817721859</pub-id></element-citation></ref><ref id="R56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mao</surname><given-names>D</given-names></name><name><surname>Kandler</surname><given-names>S</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>Bonin</surname><given-names>V</given-names></name></person-group><article-title>Sparse orthogonal population representation of spatial context in the retrosplenial cortex</article-title><source>Nature Communications</source><year>2017</year><volume>8</volume><issue>1</issue><comment>Article 1</comment><pub-id pub-id-type="pmcid">PMC5557927</pub-id><pub-id pub-id-type="pmid">28811461</pub-id><pub-id pub-id-type="doi">10.1038/s41467-017-00180-9</pub-id></element-citation></ref><ref id="R57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marchette</surname><given-names>SA</given-names></name><name><surname>Vass</surname><given-names>LK</given-names></name><name><surname>Ryan</surname><given-names>J</given-names></name><name><surname>Epstein</surname><given-names>RA</given-names></name></person-group><article-title>Anchoring the neural compass: Coding of local spatial reference frames in human medial parietal lobe</article-title><source>Nature Neuroscience</source><year>2014</year><volume>17</volume><issue>11</issue><comment>Article 11</comment><pub-id pub-id-type="pmcid">PMC4309016</pub-id><pub-id pub-id-type="pmid">25282616</pub-id><pub-id pub-id-type="doi">10.1038/nn.3834</pub-id></element-citation></ref><ref id="R58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McNaughton</surname><given-names>N</given-names></name><name><surname>Ruan</surname><given-names>M</given-names></name><name><surname>Woodnorth</surname><given-names>M-A</given-names></name></person-group><article-title>Restoring theta-like rhythmicity in rats restores initial learning in the Morris water maze</article-title><source>Hippocampus</source><year>2006</year><volume>16</volume><issue>12</issue><fpage>1102</fpage><lpage>1110</lpage><pub-id pub-id-type="pmid">17068783</pub-id></element-citation></ref><ref id="R59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meeuwissen</surname><given-names>EB</given-names></name><name><surname>Takashima</surname><given-names>A</given-names></name><name><surname>Fernandez</surname><given-names>G</given-names></name><name><surname>Jensen</surname><given-names>O</given-names></name></person-group><article-title>Evidence for Human Fronto-Central Gamma Activity during Long-Term Memory Encoding of Word Sequences</article-title><source>PLOS ONE</source><year>2011</year><volume>6</volume><issue>6</issue><elocation-id>e21356</elocation-id><pub-id pub-id-type="pmcid">PMC3126803</pub-id><pub-id pub-id-type="pmid">21738641</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0021356</pub-id></element-citation></ref><ref id="R60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mitchell</surname><given-names>AS</given-names></name><name><surname>Czajkowski</surname><given-names>R</given-names></name><name><surname>Zhang</surname><given-names>N</given-names></name><name><surname>Jeffery</surname><given-names>K</given-names></name><name><surname>Nelson</surname><given-names>AJD</given-names></name></person-group><article-title>Retrosplenial cortex and its role in spatial cognition</article-title><source>Brain and Neuroscience Advances</source><year>2018</year><volume>2</volume><elocation-id>2398212818757098</elocation-id><pub-id pub-id-type="pmcid">PMC6095108</pub-id><pub-id pub-id-type="pmid">30221204</pub-id><pub-id pub-id-type="doi">10.1177/2398212818757098</pub-id></element-citation></ref><ref id="R61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Molitor</surname><given-names>RJ</given-names></name><name><surname>Sherrill</surname><given-names>KR</given-names></name><name><surname>Morton</surname><given-names>NW</given-names></name><name><surname>Miller</surname><given-names>AA</given-names></name><name><surname>Preston</surname><given-names>AR</given-names></name></person-group><article-title>Memory Reactivation during Learning Simultaneously Promotes Dentate Gyrus/CA2,3 Pattern Differentiation and CA1 Memory Intégration</article-title><source>Journal of Neuroscience</source><year>2021</year><volume>41</volume><issue>4</issue><fpage>726</fpage><lpage>738</lpage><pub-id pub-id-type="pmcid">PMC7842747</pub-id><pub-id pub-id-type="pmid">33239402</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0394-20.2020</pub-id></element-citation></ref><ref id="R62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morton</surname><given-names>NW</given-names></name><name><surname>Zippi</surname><given-names>EL</given-names></name><name><surname>Preston</surname><given-names>AR</given-names></name></person-group><article-title>Memory reactivation and suppression modulate integration of the semantic features of related memories in hippocampus</article-title><source>Cerebral Cortex</source><year>2023</year><volume>33</volume><issue>14</issue><fpage>9020</fpage><lpage>9037</lpage><pub-id pub-id-type="pmcid">PMC10350843</pub-id><pub-id pub-id-type="pmid">37264937</pub-id><pub-id pub-id-type="doi">10.1093/cercor/bhad179</pub-id></element-citation></ref><ref id="R63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nyhus</surname><given-names>E</given-names></name><name><surname>Curran</surname><given-names>T</given-names></name></person-group><article-title>Functional role of gamma and theta oscillations in episodic memory</article-title><source>Neuroscience and Biobehavioral Reviews</source><year>2010</year><volume>34</volume><issue>7</issue><fpage>1023</fpage><lpage>1035</lpage><comment>Neurosci Biobehav Rev</comment><pub-id pub-id-type="pmcid">PMC2856712</pub-id><pub-id pub-id-type="pmid">20060015</pub-id><pub-id pub-id-type="doi">10.1016/j.neubiorev.2009.12.014</pub-id></element-citation></ref><ref id="R64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><article-title>Geometric determinants of the place fields of hippocampal neurons</article-title><source>Nature</source><year>1996</year><volume>381</volume><issue>6581</issue><comment>Article 6581</comment><pub-id pub-id-type="pmid">8632799</pub-id></element-citation></ref><ref id="R65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Dostrovsky</surname><given-names>J</given-names></name></person-group><article-title>The hippocampus as a spatial map. Preliminary evidence from unit activity in the freely-moving rat</article-title><source>Brain Research</source><year>1971</year><volume>34</volume><issue>1</issue><fpage>171</fpage><lpage>175</lpage><pub-id pub-id-type="pmid">5124915</pub-id></element-citation></ref><ref id="R66"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Nadel</surname><given-names>L</given-names></name></person-group><source>The Hippocampus as a Cognitive Map</source><year>1978</year><publisher-name>Oxford University Press</publisher-name><publisher-loc>Oxford, UK</publisher-loc><comment>(1978), Oxford University Press. <ext-link ext-link-type="uri" xlink:href="http://www.cognitivemap.net/">http://www.cognitivemap.net/</ext-link></comment></element-citation></ref><ref id="R67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Neill</surname><given-names>GC</given-names></name><name><surname>Barry</surname><given-names>DN</given-names></name><name><surname>Tierney</surname><given-names>TM</given-names></name><name><surname>Mellor</surname><given-names>S</given-names></name><name><surname>Maguire</surname><given-names>EA</given-names></name><name><surname>Barnes</surname><given-names>GR</given-names></name></person-group><article-title>Testing covariance models for MEG source reconstruction of hippocampal activity</article-title><source>Scientific Reports</source><year>2021</year><volume>11</volume><issue>1</issue><comment>Article 1</comment><pub-id pub-id-type="pmcid">PMC8413350</pub-id><pub-id pub-id-type="pmid">34475476</pub-id><pub-id pub-id-type="doi">10.1038/s41598-021-96933-0</pub-id></element-citation></ref><ref id="R68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oostenveld</surname><given-names>R</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name><name><surname>Maris</surname><given-names>E</given-names></name><name><surname>Schoffelen</surname><given-names>JM</given-names></name></person-group><article-title>FieldTrip: Open source software for advanced analysis of MEG, EEG, and invasive electrophysiological data</article-title><source>Computational Intelligence and Neuroscience</source><year>2011</year><volume>2011</volume><pub-id pub-id-type="pmcid">PMC3021840</pub-id><pub-id pub-id-type="pmid">21253357</pub-id><pub-id pub-id-type="doi">10.1155/2011/156869</pub-id></element-citation></ref><ref id="R69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Osipova</surname><given-names>D</given-names></name><name><surname>Takashima</surname><given-names>A</given-names></name><name><surname>Oostenveld</surname><given-names>R</given-names></name><name><surname>Fernandez</surname><given-names>G</given-names></name><name><surname>Maris</surname><given-names>E</given-names></name><name><surname>Jensen</surname><given-names>O</given-names></name></person-group><article-title>Theta and gamma oscillations predict encoding and retrieval of declarative memory</article-title><source>Journal of Neuroscience</source><year>2006</year><volume>26</volume><issue>28</issue><fpage>7523</fpage><lpage>7531</lpage><pub-id pub-id-type="pmcid">PMC6674196</pub-id><pub-id pub-id-type="pmid">16837600</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1948-06.2006</pub-id></element-citation></ref><ref id="R70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parish</surname><given-names>G</given-names></name><name><surname>Hanslmayr</surname><given-names>S</given-names></name><name><surname>Bowman</surname><given-names>H</given-names></name></person-group><article-title>The Sync/deSync Model: How a Synchronized Hippocampus and a Desynchronized Neocortex Code Memories</article-title><source>Journal of Neuroscience</source><year>2018</year><volume>38</volume><issue>14</issue><fpage>3428</fpage><lpage>3440</lpage><pub-id pub-id-type="pmcid">PMC6596040</pub-id><pub-id pub-id-type="pmid">29487122</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2561-17.2018</pub-id></element-citation></ref><ref id="R71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peer</surname><given-names>M</given-names></name><name><surname>Epstein</surname><given-names>RA</given-names></name></person-group><article-title>The human brain uses spatial schemas to represent segmented environments</article-title><source>Current Biology</source><year>2021</year><volume>31</volume><issue>21</issue><fpage>4677</fpage><lpage>4688</lpage><elocation-id>e8</elocation-id><pub-id pub-id-type="pmcid">PMC8578397</pub-id><pub-id pub-id-type="pmid">34473949</pub-id><pub-id pub-id-type="doi">10.1016/j.cub.2021.08.012</pub-id></element-citation></ref><ref id="R72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pizzo</surname><given-names>F</given-names></name><name><surname>Roehri</surname><given-names>N</given-names></name><name><surname>Medina Villalon</surname><given-names>S</given-names></name><name><surname>Trébuchon</surname><given-names>A</given-names></name><name><surname>Chen</surname><given-names>S</given-names></name><name><surname>Lagarde</surname><given-names>S</given-names></name><name><surname>Carron</surname><given-names>R</given-names></name><name><surname>Gavaret</surname><given-names>M</given-names></name><name><surname>Giusiano</surname><given-names>B</given-names></name><name><surname>McGonigal</surname><given-names>A</given-names></name><name><surname>Bartolomei</surname><given-names>F</given-names></name><etal/></person-group><article-title>Deep brain activities can be detected with magnetoencephalography</article-title><source>Nature Communications</source><year>2019</year><volume>10</volume><issue>1</issue><fpage>1</fpage><pub-id pub-id-type="pmcid">PMC6393515</pub-id><pub-id pub-id-type="pmid">30814498</pub-id><pub-id pub-id-type="doi">10.1038/s41467-019-08665-5</pub-id></element-citation></ref><ref id="R73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Popov</surname><given-names>T</given-names></name><name><surname>Staudigl</surname><given-names>T</given-names></name></person-group><article-title>Cortico-ocular coupling in the service of episodic memory formation</article-title><source>Progress in Neurobiology</source><year>2023</year><volume>227</volume><elocation-id>102476</elocation-id><pub-id pub-id-type="pmid">37268034</pub-id></element-citation></ref><ref id="R74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Preston</surname><given-names>AR</given-names></name><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><article-title>Interplay of hippocampus and prefrontal cortex in memory</article-title><source>Current Biology: CB</source><year>2013</year><volume>23</volume><issue>17</issue><fpage>R764</fpage><lpage>773</lpage><pub-id pub-id-type="pmcid">PMC3789138</pub-id><pub-id pub-id-type="pmid">24028960</pub-id><pub-id pub-id-type="doi">10.1016/j.cub.2013.05.041</pub-id></element-citation></ref><ref id="R75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pu</surname><given-names>Y</given-names></name><name><surname>Cheyne</surname><given-names>DO</given-names></name><name><surname>Cornwell</surname><given-names>BR</given-names></name><name><surname>Johnson</surname><given-names>BW</given-names></name></person-group><article-title>Non-invasive Investigation of Human Hippocampal Rhythms Using Magnetoencephalography: A Review</article-title><source>Frontiers in Neuroscience</source><year>2018</year><volume>12</volume><comment><ext-link ext-link-type="uri" xlink:href="https://www.frontiersin.org/articles/10.3389/fnins.2018.00273">https://www.frontiersin.org/articles/10.3389/fnins.2018.00273</ext-link></comment><pub-id pub-id-type="pmcid">PMC5932174</pub-id><pub-id pub-id-type="pmid">29755314</pub-id><pub-id pub-id-type="doi">10.3389/fnins.2018.00273</pub-id></element-citation></ref><ref id="R76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pu</surname><given-names>Y</given-names></name><name><surname>Cornwell</surname><given-names>BR</given-names></name><name><surname>Cheyne</surname><given-names>D</given-names></name><name><surname>Johnson</surname><given-names>BW</given-names></name></person-group><article-title>The functional role of human right hippocampal/parahippocampal theta rhythm in environmental encoding during virtual spatial navigation</article-title><source>Human Brain Mapping</source><year>2017</year><volume>38</volume><issue>3</issue><fpage>1347</fpage><lpage>1361</lpage><pub-id pub-id-type="pmcid">PMC6866974</pub-id><pub-id pub-id-type="pmid">27813230</pub-id><pub-id pub-id-type="doi">10.1002/hbm.23458</pub-id></element-citation></ref><ref id="R77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robertson</surname><given-names>CE</given-names></name><name><surname>Hermann</surname><given-names>KL</given-names></name><name><surname>Mynick</surname><given-names>A</given-names></name><name><surname>Kravitz</surname><given-names>DJ</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name></person-group><article-title>Neural Representations Integrate the Current Field of View with the Remembered 360° Panorama in Scene-Selective Cortex</article-title><source>Current Biology</source><year>2016</year><volume>26</volume><issue>18</issue><fpage>2463</fpage><lpage>2468</lpage><pub-id pub-id-type="pmid">27618266</pub-id></element-citation></ref><ref id="R78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruzich</surname><given-names>E</given-names></name><name><surname>Crespo-García</surname><given-names>M</given-names></name><name><surname>Dalal</surname><given-names>SS</given-names></name><name><surname>Schneiderman</surname><given-names>JF</given-names></name></person-group><article-title>Characterizing hippocampal dynamics with MEG: A systematic review and evidence-based guidelines</article-title><source>Human Brain Mapping</source><year>2019</year><volume>40</volume><issue>4</issue><fpage>1353</fpage><lpage>1375</lpage><pub-id pub-id-type="pmcid">PMC6456020</pub-id><pub-id pub-id-type="pmid">30378210</pub-id><pub-id pub-id-type="doi">10.1002/hbm.24445</pub-id></element-citation></ref><ref id="R79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sederberg</surname><given-names>PB</given-names></name><name><surname>Gauthier</surname><given-names>LV</given-names></name><name><surname>Terushkin</surname><given-names>V</given-names></name><name><surname>Miller</surname><given-names>JF</given-names></name><name><surname>Barnathan</surname><given-names>JA</given-names></name><name><surname>Kahana</surname><given-names>MJ</given-names></name></person-group><article-title>Oscillatory correlates of the primacy effect in episodic memory</article-title><source>NeuroImage</source><year>2006</year><volume>32</volume><issue>3</issue><fpage>1422</fpage><lpage>1431</lpage><pub-id pub-id-type="pmid">16814568</pub-id></element-citation></ref><ref id="R80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skaggs</surname><given-names>WE</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>Wilson</surname><given-names>MA</given-names></name><name><surname>Barnes</surname><given-names>CA</given-names></name></person-group><article-title>Theta phase precession in hippocampal neuronal populations and the compression of temporal sequences</article-title><source>Hippocampus</source><year>1996</year><volume>6</volume><issue>2</issue><fpage>149</fpage><lpage>172</lpage><pub-id pub-id-type="pmid">8797016</pub-id></element-citation></ref><ref id="R81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Solstad</surname><given-names>T</given-names></name><name><surname>Boccara</surname><given-names>CN</given-names></name><name><surname>Kropff</surname><given-names>E</given-names></name><name><surname>Moser</surname><given-names>M-B</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><article-title>Representation of geometric borders in the entorhinal cortex</article-title><source>Science (New York, NY)</source><year>2008</year><volume>322</volume><issue>5909</issue><fpage>1865</fpage><lpage>1868</lpage><pub-id pub-id-type="pmid">19095945</pub-id></element-citation></ref><ref id="R82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Staudigl</surname><given-names>T</given-names></name><name><surname>Hanslmayr</surname><given-names>S</given-names></name></person-group><article-title>Theta Oscillations at Encoding Mediate the Context-Dependent Nature of Human Episodic Memory</article-title><source>Current Biology</source><year>2013</year><volume>23</volume><issue>12</issue><fpage>1101</fpage><lpage>1106</lpage><pub-id pub-id-type="pmid">23746635</pub-id></element-citation></ref><ref id="R83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Staudigl</surname><given-names>T</given-names></name><name><surname>Hartl</surname><given-names>E</given-names></name><name><surname>Noachtar</surname><given-names>S</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name><name><surname>Jensen</surname><given-names>O</given-names></name></person-group><article-title>Saccades are phase-locked to alpha oscillations in the occipital and medial temporal lobe during successful memory encoding</article-title><source>PLOS Biology</source><year>2017</year><volume>15</volume><issue>12</issue><elocation-id>e2003404</elocation-id><pub-id pub-id-type="pmcid">PMC5766246</pub-id><pub-id pub-id-type="pmid">29267286</pub-id><pub-id pub-id-type="doi">10.1371/journal.pbio.2003404</pub-id></element-citation></ref><ref id="R84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steel</surname><given-names>A</given-names></name><name><surname>Garcia</surname><given-names>BD</given-names></name><name><surname>Goyal</surname><given-names>K</given-names></name><name><surname>Mynick</surname><given-names>A</given-names></name><name><surname>Robertson</surname><given-names>CE</given-names></name></person-group><article-title>Scene Perception and Visuospatial Memory Converge at the Anterior Edge of Visually Responsive Cortex</article-title><source>Journal of Neuroscience</source><year>2023</year><volume>43</volume><issue>31</issue><fpage>5723</fpage><lpage>5737</lpage><pub-id pub-id-type="pmcid">PMC10401646</pub-id><pub-id pub-id-type="pmid">37474310</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2043-22.2023</pub-id></element-citation></ref><ref id="R85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Summerfield</surname><given-names>C</given-names></name><name><surname>Mangels</surname><given-names>JA</given-names></name></person-group><article-title>Coherent theta-band EEG activity predicts item-context binding during encoding</article-title><source>Neuroimage</source><year>2005</year><volume>24</volume><issue>3</issue><fpage>692</fpage><lpage>703</lpage><pub-id pub-id-type="pmid">15652304</pub-id></element-citation></ref><ref id="R86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taube</surname><given-names>JS</given-names></name><name><surname>Muller</surname><given-names>RU</given-names></name><name><surname>Ranck</surname><given-names>JB</given-names></name></person-group><article-title>Head-direction cells recorded from the postsubiculum in freely moving rats. I. Description and quantitative analysis</article-title><source>Journal of Neuroscience</source><year>1990</year><volume>10</volume><issue>2</issue><fpage>420</fpage><lpage>435</lpage><pub-id pub-id-type="pmcid">PMC6570151</pub-id><pub-id pub-id-type="pmid">2303851</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.10-02-00420.1990</pub-id></element-citation></ref><ref id="R87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vanderwolf</surname><given-names>CH</given-names></name></person-group><article-title>Hippocampal electrical activity and voluntary movement in the rat</article-title><source>Electroencephalography and Clinical Neurophysiology</source><year>1969</year><volume>26</volume><issue>4</issue><fpage>407</fpage><lpage>418</lpage><pub-id pub-id-type="pmid">4183562</pub-id></element-citation></ref><ref id="R88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vass</surname><given-names>LK</given-names></name><name><surname>Epstein</surname><given-names>RA</given-names></name></person-group><article-title>Abstract Representations of Location and Facing Direction in the Human Brain</article-title><source>Journal of Neuroscience</source><year>2013</year><volume>33</volume><issue>14</issue><fpage>6133</fpage><lpage>6142</lpage><pub-id pub-id-type="pmcid">PMC3656495</pub-id><pub-id pub-id-type="pmid">23554494</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3873-12.2013</pub-id></element-citation></ref><ref id="R89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Voss</surname><given-names>JL</given-names></name><name><surname>Bridge</surname><given-names>DJ</given-names></name><name><surname>Cohen</surname><given-names>NJ</given-names></name><name><surname>Walker</surname><given-names>JA</given-names></name></person-group><article-title>A Closer Look at the Hippocampus and Memory</article-title><source>Trends in Cognitive Sciences</source><year>2017</year><volume>21</volume><issue>8</issue><fpage>577</fpage><lpage>588</lpage><pub-id pub-id-type="pmcid">PMC5659202</pub-id><pub-id pub-id-type="pmid">28625353</pub-id><pub-id pub-id-type="doi">10.1016/j.tics.2017.05.008</pub-id></element-citation></ref><ref id="R90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zuure</surname><given-names>MB</given-names></name><name><surname>Hinkley</surname><given-names>LB</given-names></name><name><surname>Tiesinga</surname><given-names>PHE</given-names></name><name><surname>Nagarajan</surname><given-names>SS</given-names></name><name><surname>Cohen</surname><given-names>MX</given-names></name></person-group><article-title>Multiple Midfrontal Thetas Revealed by Source Separation of Simultaneous MEG and EEG</article-title><source>Journal of Neuroscience</source><year>2020</year><volume>40</volume><issue>40</issue><fpage>7702</fpage><lpage>7713</lpage><pub-id pub-id-type="pmcid">PMC7531541</pub-id><pub-id pub-id-type="pmid">32900834</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0321-20.2020</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>Stimuli used in the experiment and results from the behavioural tasks. Panels A-C are adapted from <xref ref-type="bibr" rid="R8">Berens et al., (2021)</xref>.</title><p>(A) An example panorama of a location with the two endpoint images marked with dotted lines. The whole panorama was never shown to the participants, like previous experiments (<xref ref-type="bibr" rid="R8">Berens et al., 2021</xref>; <xref ref-type="bibr" rid="R77">Robertson et al., 2016</xref>). (B) Videos participants watched in the MEG scanner. Both overlap and non-overlap videos panned from one endpoint to the centre, then switched to the other endpoint and panned to the centre. The central region is from the same panorama in overlap videos, but from different panoramas in non-overlap videos. Overlap videos therefore allowed for the formation of location-based representations. (C) Example trial in the endpoint-matching task. The target image was bordered in red and followed by presentation of 5 lures. Participants chose which lure belonged to the same location as the target. (D) Endpoint-matching accuracy compared between pre- and post-video endpoint-matching tasks grouped by video condition. Scatter dots reflect data from individual participants. Error bars represent 95% confidence intervals. Chance level for 5-AFC is 20%, represented by a dashed line.</p></caption><graphic xlink:href="EMS189889-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><p>Illustration of one trial in the video-watching learning task. Each trial consisted of two presentations of the location panorama, and 2 camera pans for each presentation, leading to a total of 4 camera pans. Each camera pan lasted for 5s, leading to 20s in each trial. For half of the trials, camera pans were in this order: left-to-centre, right-to-centre, left-to-centre, right-to-centre. The other half of the trials started with right-to-centre camera pans and alternated with left-to-centre pans. The video jumps to the other camera pan after completing the previous camera pan. For the MEG oscillation analysis, we chose three time-windows immediately after a camera pan began, (5 to 6.5s, 10 to 11.5s, and 15 to 16.5s), at end-point onset; and three time-windows around the mid-points of the camera pans (8 to 9.5s, 13 to 14.5s, and 18 to 19.5s), starting at the time-points where the shared location information starts becoming apparent. The solid borders depict these chosen time-windows. We found significant changes in neural activity during overlap vs. non-overlap video-watching in the 10-11.5s and 18-19.5s time windows, and these are depicted by pink borders. We did not find significant effects in the other time-windows, which are depicted by blue borders. The black dashed border indicates an endpoint image. Non-overlapping videos also followed the same exact presentation order.</p></caption><graphic xlink:href="EMS189889-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Results from the cluster-based permutation tests in MEG sensor-space and estimated sources of the sensor-space effects.</title><p>(A) Topographical plots of averaged power across timepoints from the significant cluster in the theta (top) and alpha (bottom) bands. Spectrograms from a posterior sensor (marked on the topographical plot) reflecting baseline-corrected oscillatory power (dB) from 10 to 11.5 seconds post-video onset. Time-frequency data-points that belonged to the cluster are bordered by black lines. (B) Estimated brain sources of the sensor-space effect found during 10 to 11.5s post-video onset between 4 and 20Hz. (C) Topographical plots of averaged power across timepoints from the significant cluster in the theta (top) and alpha (bottom) bands. Spectrograms from a posterior sensor (marked on the topographical plot) reflecting baseline-corrected oscillatory power (dB) from 18 to 19.5 seconds post-video onset. Time-frequency data-points that belonged to the cluster are bordered by black lines. (D) Estimated brain sources of the sensor-space effect found during 18 to 19.5s post-video onset between 4 and 11 Hz.</p></caption><graphic xlink:href="EMS189889-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Results from region-of-interest analyses of oscillatory power.</title><p>(A) Spectrograms depicting oscillatory power (dB) from 10 to 11.5s post-video onset in the right hippocampus (top), left hippocampus (middle), and precuneus (bottom). Time-frequency data-points that belonged to the cluster are bordered by black lines. (B) Spectrograms depicting baseline-corrected oscillatory power (dB) from 18 to 19.5s post-video onset in the right hippocampus (top), left hippocampus (middle), and precuneus (bottom). Time-frequency data-points that belonged to the cluster are bordered by black lines.</p></caption><graphic xlink:href="EMS189889-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><p>Oscillatory power averaged across theta (top) and alpha/beta (bottom) bands and plotted from video-onset to video-offset (0 to 19.5s) in the right hippocampus (A), left hippocampus (B), precuneus (C) and retrosplenial cortex (D). Grey shaded regions depict 10-11.5s and 18-19.5s post-video onset, where sensor-level effects were found.</p></caption><graphic xlink:href="EMS189889-f005"/></fig></floats-group></article>