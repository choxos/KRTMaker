<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS189384</article-id><article-id pub-id-type="doi">10.1101/2023.10.05.561037</article-id><article-id pub-id-type="archive">PPR738131</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">1</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Learning modifies attention during bumblebee visual search</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Robert</surname><given-names>Théo</given-names></name></contrib><contrib contrib-type="author"><name><surname>Tarapata</surname><given-names>Karolina</given-names></name></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-2878-2425</contrib-id><name><surname>Nityananda</surname><given-names>Vivek</given-names></name></contrib><aff id="A1">Biosciences Institute, Newcastle University, Henry Wellcome Building, Framlington Place, Newcastle Upon Tyne, NE2 4HH, UK</aff></contrib-group><author-notes><corresp id="CR1">Corresponding authors: Théo Robert, <email>theo.robert@newcastle.ac.uk</email>; Vivek Nityananda, <email>vivek.nityananda@newcastle.ac.uk</email></corresp></author-notes><pub-date pub-type="nihms-submitted"><day>11</day><month>10</month><year>2023</year></pub-date><pub-date pub-type="preprint"><day>06</day><month>10</month><year>2023</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">The role of visual search during bee foraging is relatively understudied compared to the choices made by bees. As bees learn about rewards, we predicted that visual search would be modified to prioritise rewarding flowers. To test this, we ran an experiment testing how bee search differs in the initial and later part of training as they learn about flowers with either higher- or lower-quality rewards. We then ran an experiment to see how this prior training with reward influences their search on a subsequent task with different flowers. We used the time spent inspecting flowers as a measure of attention and found that learning increased attention to rewards and away from distractors. Higher quality rewards led to decreased attention to non-flower regions, but lower quality rewards did not. Prior experience of lower rewards also led to more attention to higher rewards compared to distractors and non-flower regions. Our results suggest that flowers would elicit differences in bee search behaviour depending on the sugar content of their nectar. They also demonstrate the utility of studying visual search and have important implications for understanding the pollination ecology of flowers with different qualities of reward.</p></abstract><kwd-group><kwd>Reward</kwd><kwd>Saliency</kwd><kwd>Top-down attention</kwd><kwd>Insects</kwd><kwd>Bees</kwd><kwd>Cognitive Ecology</kwd></kwd-group></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">Foraging bees must learn which flowers are rewarding and which ones are not. Given this ecological demand, they have evolved to be expert learners and are well-studied as models of visual cognition (<xref ref-type="bibr" rid="R2">Avarguès-Weber et al. 2011</xref>; <xref ref-type="bibr" rid="R15">Giurfa 2012</xref>). Bees learn to choose rewarding flowers and avoid differently coloured flowers without rewards (<xref ref-type="bibr" rid="R24">Lubbock 1881</xref>; <xref ref-type="bibr" rid="R54">Turner 1910</xref>; <xref ref-type="bibr" rid="R55">von Frisch 1914</xref>; <xref ref-type="bibr" rid="R7">Benard et al. 2006</xref>; <xref ref-type="bibr" rid="R3">Avarguès-Weber and Giurfa 2014</xref>). They are also capable of discriminating between higher and lower rewarding flowers (<xref ref-type="bibr" rid="R6">Baude et al. 2011</xref>; <xref ref-type="bibr" rid="R48">Riveros and Gronenberg 2012</xref>; <xref ref-type="bibr" rid="R4">Avarguès-Weber et al. 2018</xref>; <xref ref-type="bibr" rid="R52">Solvi et al. 2022</xref>). While a large body of research has demonstrated reward-based learning in bees, most of the work has looked at how learning affects the choices made by bees. Much less research has investigated the influence of rewards on visual search and attention in bees (<xref ref-type="bibr" rid="R53">Spaethe et al. 2006</xref>; <xref ref-type="bibr" rid="R27">Morawetz and Spaethe 2012</xref>; <xref ref-type="bibr" rid="R30">Nityananda and Pattrick 2013</xref>; <xref ref-type="bibr" rid="R29">Nityananda and Chittka 2021</xref>).</p><p id="P3">Visuospatial attention has been defined as a spotlight focussing on one region compared to others (<xref ref-type="bibr" rid="R45">Posner 1980</xref>) and is often measured by responses to targets in a region or the time spent looking at specific regions or objects (<xref ref-type="bibr" rid="R49">Schütz et al. 2011</xref>; <xref ref-type="bibr" rid="R20">Henderson and Hayes 2018</xref>). Visual search experiments look at how attention is deployed when searching for one target amongst others (<xref ref-type="bibr" rid="R39">Horowitz and Wolfe 2001</xref>). This approach has been used in several animals including jays, owls and fish (<xref ref-type="bibr" rid="R12">Dukas and Kamil 2000</xref>; <xref ref-type="bibr" rid="R34">Bond and Kamil 2002</xref>; <xref ref-type="bibr" rid="R32">Ben-Tov et al. 2015</xref>; <xref ref-type="bibr" rid="R43">Orlowski et al. 2015, 2018</xref>; <xref ref-type="bibr" rid="R46">Saban et al. 2017</xref>). Recent work has begun to look at attention and visual search in insects (<xref ref-type="bibr" rid="R40">Nityananda 2016</xref>), especially in bumblebees. Bees have been shown to flexibly switch between multiple rewarding targets (<xref ref-type="bibr" rid="R30">Nityananda and Pattrick 2013</xref>; <xref ref-type="bibr" rid="R23">Li et al. 2017</xref>). In experimental set-ups, floral rewards influence not just their choices but their visual attention, as measured by the time spent around particular flowers (<xref ref-type="bibr" rid="R29">Nityananda and Chittka 2021</xref>). Bees spend more time around higher rewarding flowers even when they are less salient than lower rewarding flowers. We still, however, know little about how bee visual search changes over time as the bees learn about rewards.</p><p id="P4">Bee attention during learning could be influenced by multiple factors, including the reward value and the saliency of the flowers. These factors have been shown to influence both bee choices and visual search. Colour contrast against a background, one measure of saliency, influences their visual search (<xref ref-type="bibr" rid="R17">Goulson 2000</xref>). Naïve bees also have an innate bias toward colours in the blue-green wavelength range and colours that have spectral purity (<xref ref-type="bibr" rid="R25">Lunau 1990</xref>; <xref ref-type="bibr" rid="R26">Lunau et al. 1996</xref>). We would therefore expect that the visual search of Naïve bees would initially be influenced by saliency and innate biases. Subsequently, as bees learn about the reward value of flowers, we should expect them to pay more attention to rewarding flowers. We would also predict that there would be different effects on bumblebee visual search if the rewarding flowers had lower rewards or higher rewards. Given the effects of both reward value and stimulus saliency we would therefore expect learning to increased attention to higher reward but lower saliency flowers compared to lower reward high saliency flowers.</p><p id="P5">To test these ideas, we investigated the training bouts for bees trained as part of a previously published study (<xref ref-type="bibr" rid="R29">Nityananda and Chittka 2021</xref>) that focussed on the behaviour of bees in tests after the training. As part of that study, bees were trained on one of two flower types – either higher reward lower saliency flowers or lower reward higher saliency flowers. In both training regimes, the rewarding flowers were presented simultaneously with non-rewarding distractors. In the current study, we focus on the training period prior to the tests, that have not been previously analysed. We investigated the effect of learning on attention by comparing visual search in the initial period of the training with visual search in the final stage of the training. Prior expectations can change the perception of reward in social insects (<xref ref-type="bibr" rid="R33">Bitterman 1975</xref>; <xref ref-type="bibr" rid="R37">Gil et al. 2007</xref>; <xref ref-type="bibr" rid="R47">Wendt et al. 2019</xref>). In a second experiment, we therefore also investigated how prior experience of higher rewards and lower rewards influenced visual search when encountering new flowers that had different reward values.</p><p id="P6">We hypothesised that bees would increase their attention to rewarding flowers as they learnt about the rewards and that this effect would be greater for flowers with higher reward. We therefore predicted that in the first experiment, bees would attend more to rewarding flowers in the final phase of their training compared to the initial phase of their training. We further predicted that this change would be greater for the higher reward lower saliency flowers. Given the possibility of prior expectations influencing behaviour, we hypothesised that bees that had experienced higher reward should be less motivated by lower rewards. In the second experiment, we therefore predicted that bees would spend more attention away from rewarding flowers if they encountered lower rewarding flowers after having prior experience of higher rewards. We also predicted that bees would increase attention to rewarding flowers if the bees encountered higher rewards after experiencing lower rewards first.</p></sec><sec id="S2" sec-type="materials | methods"><title>Materials and methods</title><sec id="S3"><title>Bees</title><p id="P7">We obtained the bees from a commercial supplier (Syngenta Bioline, Weert, The Netherlands). We then tagged them with Opalith number tags (Christian Graze KG, Weinstadt-Endersbach, Germany) which allowed us to individually identify them. We transferred the bees under red light to one of two chambers of a wooden nest box (length × width × height: 28 × 16 × 11 cm). The floor of the other chamber was covered with cat litter to allow bees to discard refuse. This nest box was connected to an arena with a 24.5 cm long transparent Perspex tunnel. The arena consisted of a wooden box (length × width × height: 100 × 60 × 40 cm) covered with a UV-transparent Plexiglas lid and the arena floor was covered with green card. The arena was lit from above with two twin lamps (TMS 24 F with HF-B 236 TLD (4.3 kHz) ballasts; Philips, The Netherlands) fitted with Activa daylight full spectrum fluorescent tubes (Sylvania, New Haven, UK). Bees were allowed to forage for sucrose solution in the arena and provided ˜ 3g pollen directly in their colony every alternate evening.</p></sec><sec id="S4"><title>Spectral reflectance of flowers</title><p id="P8">We used an Avantes AvaSpec 2048 spectrophotometer (Anglia Instruments Limited, Soham, UK) along with a deuterium-halogen light source relative to a BaSO4 white standard to measure the reflectance spectra of the artificial flowers. We converted the spectra obtained into a bee-specific colour space (<xref ref-type="bibr" rid="R9">Chittka 1992</xref>) using the spectral sensitivity of bumblebee photoreceptors (<xref ref-type="bibr" rid="R51">Skorupski et al. 2007</xref>), the spectral distribution of the lights used and the spectral reflectance of the background. The colour hexagon space has three vertices representing the points of maximum excitation of the blue, green and ultraviolet (UV) photoreceptors of the bee (<xref ref-type="fig" rid="F1">Figure 1A</xref>). The other three vertices correspond to the response to mixtures of approximately equal excitation of each combination of two photoreceptors. The Euclidean distance between the centre of the hexagon and each vertex is 1 and colour distance greater than 0.1 can be distinguished by bees without special training procedures. After plotting the reflectance values of our flowers in this space, we were able to measure the distance in perceptual space between them. These data are provided in the previous paper (<xref ref-type="bibr" rid="R29">Nityananda and Chittka 2021</xref>).</p></sec><sec id="S5"><title>Pretraining</title><p id="P9">We trained bees with no experience of colour to forage for sucrose solution from transparent square Perspex chips (side: 25 mm, thickness: 5 mm). These served as artificial flowers (henceforth “flowers”) and the aim of the pretraining was to allow the bees to learn to forage from them. Each flower had a central well that could be loaded with rewarding or unrewarding solutions. Once bees learned to forage from these chips, we placed them on glass vials (1.5 cm diameter, 4 cm tall) and trained bees to forage from them. We arranged 24 such vials in a 6 X 4 horizontal grid, placed 15 cm apart. Twelve of the flowers had 12 μl of 50% (v/v) sucrose solution in them and the others were empty. We randomized the positions of rewarding and non-rewarding flowers. In the pretraining and in all experiments these positions were randomized using the random number generator function RAND() in Microsoft Excel®. We moved to the training phase once the bee had foraged on this grid for three bouts.</p></sec><sec id="S6"><title>Training</title><p id="P10">We trained 16 bees from three colonies on a visual discrimination task. Bees had to discriminate between rewarding flowers (targets) of one colour and distractor flowers of another colour. These flowers were coloured Perspex chips placed on glass vials in a grid as described above. In each experiment, there were a total of 12 rewarding flowers and 12 distractors. Rewarding flowers contained 12 μl of 50% (v/v) sucrose solution while distractors contained 12 μl of distilled water. Within one foraging bout, flowers were not refilled but bees were allowed to revisit flowers multiple times. Bees were allowed to forage over multiple bouts until they made 80% correct choices of the rewarding flowers in their last 20 choices. Choices were recorded when the bees landed on a flower and probed them for reward, including when bees revisited flowers. Between training bouts, we cleaned the chips with 99% ethanol to remove scent markings, and then with water to remove traces of ethanol. The positions of the rewarding flowers and distractors was then randomized again before the next bout.</p><p id="P11">We trained each bee in two consecutive experiments (<xref ref-type="fig" rid="F1">Figure 1B</xref>). The first looked at how training affected the visual search of naive bees and the role of reward quality. The second experiment looked at how prior training (in the first experiment) affected subsequent visual search when different rewards were encountered.</p></sec><sec id="S7"><title>Experiment 1: The Effects of Colour-Naïve Training</title><p id="P12">Bees were divided into two groups (<xref ref-type="fig" rid="F1">Figure 1B</xref>). The first group was trained on blue rewarding flowers with a lower reward of 30% (v/v) sucrose solution and fuchsia distractors. The second group were trained on yellow rewarding flowers with a higher reward of 50% (v/v) sucrose solution with cream distractors. We trained the bees until they reached the success criterion defined above.</p></sec><sec id="S8"><title>Experiment 2: The Effects of Prior Training</title><p id="P13">In the second experiment (<xref ref-type="fig" rid="F1">Figure 1B</xref>, right column), we continued to train the bees from Experiment 1 above on a novel task. For this task, we swapped the training regimes described in Experiment 1. Bees that were trained on lower rewarding blue flowers in Experiment 1 were now trained on higher rewarding yellow flowers with cream distractors. Bees in the other group that were trained in Experiment 1 on higher rewarding yellow flowers were now trained on lower rewarding blue flowers with fuchsia distractors. Higher rewards were always 50% (v/v) sucrose solution and lower rewards were always 30% (v/v) sucrose solution. Distractors always only held distilled water.</p><p id="P14">The choices made by the bees were noted to determine the success criterion and all bouts were recorded using a Sony DCR-SR58E Handycam at 25 frames per second.</p></sec><sec id="S9"><title>Video Coding</title><p id="P15">We analysed the videos using the open-source program Tracker (V5.15, ©2020 Douglas Brown, physlets.org/tracker). We perspective corrected the videos and tracked the position of the bees in each frame. Frames in which the bee was not clearly visible because of light reflections or because it flew to a corner of the arena were marked as missing data and excluded from subsequent analysis. We used the tracked position of the bees to obtain maps of bee search behaviour. To exclude time spent visiting a flower we excluded frames on which the bee was within 1.77 cm from the centre of a flower (for both distractors and rewarding flowers). This distance corresponds to the diagonal length from the centre to any corner of the artificial flowers we used. The visual search area was thus the area of our arena, after excluding the flower areas. Within the visual search area, we defined flower inspection regions on our maps as between 1.77 cm and 5 cm from the flowers’ centre. All other regions in the visual search area were defined as non-flower regions. We summed the total number of frames that a bee spent in each region and converted this to a measure of inspection time by dividing by the frame rate of the videos.</p><p id="P16">To investigate the effect of learning we compared the change in inspection time as our measure of attention. With this measure, we tested how attention for rewarding flowers, distractors, and other regions differed between the first six choices the bees made and the last six choices. We made the same comparison for both experiments.</p></sec><sec id="S10"><title>Statistical Analysis</title><p id="P17">All analyses were run on R (version 4.2.1). We analysed the results using the glm and glmmTMB function of the glmmTMB package (<xref ref-type="bibr" rid="R35">Brooks et al. 2017</xref>) to run general linear and generalized linear mixed models. We assessed the fit of all our models using the DHARMa package (<xref ref-type="bibr" rid="R38">Hartig 2022</xref>).</p><p id="P18">To analyse the inspection time results, we calculated the proportion of time spent in each region (reward, distractor or other) compared the total visual search time. To control for the differing areas of each region we divided these proportions by the total area corresponding to each region. We then log-transformed the weighted proportions and used this as the dependent variable in a general linear model. We used the models to test the three-way interaction effect of learning stage (first or last six), rewarding flower colour (blue or yellow) and region (reward, distractor or other), with each of these predictors included as factors. We ran the same analysis separately for both the first and second experiments. For the second experiment, we had to exclude two data points where the proportion of frames for the distractor was 0 and therefore could not be log-transformed.</p><p id="P19">We also ran an analysis on the duration (total number of frames) over which bees made their first and last choices. To do this we used the glmmTMB function from the glmmTMB package to run a generalised linear mixed model with duration as the dependent variable and a negative binomial family. The independent variables were learning stage and rewarding flower colour and bee identity was included as a random variable.</p><p id="P20">Finally, we analyzed the choices of the bees using a generalized linear mixed model with the proportion of choices of rewarding flowers as the dependent variable, bee identity as a random variable and a binomial family distribution and a logit link function. In consecutive models, we included rewarding flower colour, experiment and learning stage as independent variables and selected the best model after comparing the models with anova() function in R. Details of the model selection process are provided in the code in the supplementary material.</p></sec></sec><sec id="S11" sec-type="results"><title>Results</title><sec id="S12"><title>Experiment 1</title><p id="P21">Our model shows a significant main effect of training stage on bee inspection time (GLM, Estimate = 0.957, S.E.= 0.350, P = 0.008; <xref ref-type="fig" rid="F2">Figure 2A and B</xref>), showing that as bees learnt about the rewards they were more likely to spend time inspecting rewarding flowers. In the first training stage, there were no significant main effect of flowers of different reward value (GLM, Estimate = 0.132, S.E.= 0.350, P = 0.708, <xref ref-type="fig" rid="F2">Figure 2A and B</xref>, pink plots). In this stage, bees were not significantly more likely to inspect rewarding flowers compared to distractors for both values of reward (Yellow flowers: GLM, Estimate = -0.022, S.E. = 0.350, P= 0.951; Blue flowers: GLM, Estimate = -0.264, S.E. = 0.350, P = 0.453, <xref ref-type="fig" rid="F2">Figure 2B</xref>, pink plots). They were also not significantly more likely to inspect rewarding flowers compared to non-flower regions for either reward value (Yellow flowers: GLM, Estimate = 0.102, S.E. = 0.350, P = 0.771; Blue flowers: GLM, Estimate = -0.105, S.E. = 0.350, P= 0.765, <xref ref-type="fig" rid="F2">Figure 2A</xref>, pink plots).</p><p id="P22">For the higher rewarding yellow flowers, there were interaction effects between the training stage and the region type, showing that bees spent significantly more time inspecting these rewarding flowers compared to distractors and other regions in the later stage of training (Distractors: GLM, Estimate = -2.335, S.E.= 0.495, P &lt; 0.001; Non-flower regions: GLM, Estimate = - 1.282, S.E.= 0.495, P = 0.011; <xref ref-type="fig" rid="F2">Figure 2A and B</xref>, blue plots). This was not true for the lower rewarding blue flowers (Distractors: GLM, Estimate = -0.843, S.E. = 0.495, P = 0.092; Non-flower regions: GLM, Estimate = -0.019, S.E. = 0.495, P = 0.970; <xref ref-type="fig" rid="F2">Figure 2A and B</xref>, blue plots)</p><p id="P23">In the later training stage, there was a main effect of reward value on the inspection time of reward, indicating that bees were more likely to inspect the higher rewarding yellow flowers compared to lower rewarding blue flowers (GLM, Estimate = -0.730, S.E. = 0.350, P = 0.040). At this training stage, bees inspected both types of flowers significantly more than distractors (Yellow flowers: GLM, Estimate = -2.356, S.E. = -6.738, P &lt; 0.001; Blue flowers: Estimate = -1.107, S.E. = 0.350, P = 0.002). Bees trained on the yellow flowers, also inspected these higher rewarding flowers significantly more than non-flower regions (GLM, Estimate = -1.180, S.E. = 0.350, P = 0.001). Crucially, this was not true for bees trained on the lower rewarding blue flowers (GLM, Estimate = -0.124, S.E. = 0.350, P = 0.724).</p><p id="P24">These results suggest that bee attention to rewards is increased as they learn about the flowers. They also show that higher rewarding and lower rewarding flowers have slightly different effects. When flowers have lower rewards, bumblebees continue their searching behaviour rather than focussing on the rewarding flowers.</p><p id="P25">The number of correct choices made by the bees was best explained by a model that included the training stage and the flower (and thus reward) type as predictors but not the experiment (first or second). Bees were significantly less likely to make correct choices for blue flowers compared to yellow flowers (GLMM, Estimate = -1.525, S.E. = 0.464, P = 0.001). This likely reflects innate biases of the bees to blue but the bees were generally highly accurate. In the initial training stage of Experiment 1, bees made 79% correct choices to yellow flowers and 88% correct choices to blue flowers. The accuracy of the very first choices was however 50% (4 out of 8 bees) for yellow flowers and 62.5% (5 out of 8 bees) for blue flowers. These proportions were not different from chance (binomial tests, Yellow: P = 0.273, Blue: P = 0.219). In the later training stage, all bees were 100% accurate. This result also highlights the differences found when analysing choices and visual search and how both analyses complement each other.</p><p id="P26">Bees also made their last six choices faster than they made their first six choices (comparison with null model: χ<sup>2</sup> = 26.216, df = 1, P &lt; 0.001: First six VS last six: Estimate = -1.004, S.E. = 0.154, Z = -6.51, P &lt; 0.001). Including flower colour as a factor did not improve the model (comparison with model having only training stage: χ<sup>2</sup> = 0.753, df = 2, P = 0.686), suggesting that the effect was comparable in both higher and lower reward flowers. Learning thus increases the speed of choices regardless of flower reward level.</p></sec><sec id="S13"><title>Experiment 2</title><p id="P27">Unlike in Experiment 1, we did not find a main effect of training stage in this Experiment indicating that the training did not here increase bee inspection of rewarding flowers (Yellow flowers: GLM, Estimate = 0.384, S.E. = 0.244, P = 0.119, Blue flowers: GLM, Estimate = -0.218, S.E. = 0.244, P = 0.374, <xref ref-type="fig" rid="F3">Figure 3A and B</xref>). In the first training stage, the group of bees that had switched from lower to higher rewarding flowers between experiments were more likely to inspect rewarding flowers compared to the other group (GLM, Estimate = 0.586, S.E. = 0.244, P = 0.019, <xref ref-type="fig" rid="F3">Figure 3A and B</xref>, pink plots). This demonstrates the effect of the prior experience.</p><p id="P28">In this training stage, bees in both groups were significantly more likely to inspect rewarding flowers compared to non-flower regions (Yellow flowers: GLM, Estimate = -0.547, S.E. = 0.244, P = 0.028, Blue Flowers: GLM, Estimate = -1.02, S.E. = 0.244, P &lt; 0.001, <xref ref-type="fig" rid="F3">Figure 3A and B</xref>, pink plots). Bees with prior experience of high rewards also were significantly more likely to attend to the now lower rewarding flowers compared to distractors (GLM, Estimate = -1.197, S.E. = 0.244, P &lt; 0.001). For bees in the other group this effect was not significant (GLM, Estimate = -0.272, S.E. = 0.244, P = 0.267).</p><p id="P29">There was a significant interaction effect showing that training increased attention to rewarding flowers compared to distractors when bees encountered higher rewarding yellow flowers (GLM, Estimate = -1.819, S.E. = 0.351, P &lt; 0.001). This was not true for the lower rewarding blue flowers (GLM, Estimate = 0.423, S.E. = 0.351, P= 0.231). In the later training stage, there was no main effect of reward value (GLM, Estimate = -0.002. S. E. = 0.317, P = 0.996). In this stage, bees inspected rewarding flowers significantly more than distractors (Yellow flowers: GLM, Estimate = -2.063, S.E. = -0.325, P &lt; 0.001, Blue flowers: GLM, Estimate = -0.802, S.E. = 0.327, P = 0.017). They also inspected rewarding flowers significantly more than non-flower regions (Yellow flowers: GLM, Estimate = -0.854, S.E. = 0.250, P = 0.001; Blue flowers: Estimate = -0.583, S.E. = 0.255, P = 0.025).</p><p id="P30">Training thus boosted attention to rewarding flowers for the bees that had previously encountered low rewarding flowers in Experiment 1 but now encountered higher rewarding flowers. This confirms our predictions of the effect of prior experience on visual search to subsequent rewards. However, our prediction was not true for bees that switched from higher to lower rewards. Here bees continued attending to the rewarding flowers even though they now encountered lower rewards.</p><p id="P31">The choices of the bees in Experiment 2 were again highly accurate. In the initial training stage of Experiment 2, bees made 65% correct choices to yellow flowers and 92% correct choices to blue flowers. In the later stage, bees from both groups chose the rewarding flower with 100% accuracy. Contrary to what we observed in the first experiment, including flower colour made for a better model, suggesting that the effect of learning on the time taken to perform six choices differed with the reward quality (or colour) (Comparison with model including only training stage: χ<sup>2</sup> = 7.544, df = 2, P = 0.023). There was no effect of training for bees that switched from higher rewarding flowers in Experiment 1 to lower rewarding flowers in Experiment 2 (First six blue vs last six blue: Estimate = -0.212, S.E. = 0.156, Z = -1.36, P = 0.175). However, when the bees changed from lower rewarding flowers to higher rewarding flowers, their first six choices were faster than these of the other flower colour group (First six blue VS First six yellow: Estimate = 0.439, S.E. = 0.196, Z = 2.24, P = 0.025) and training further increased the speed at which these bees made their last six choices (First six yellow VS last six yellow: Estimate = -0.630, S.E. = 0.222, Z = -2.84, P = 0.005).</p></sec></sec><sec id="S14" sec-type="discussion"><title>Discussion</title><p id="P32">We tested whether learning modified visual search in two related experiments. We found that learning resulted in an increase in the proportion of time spent by the bees around rewarding flowers compared to distractors and notably to non-flower regions, but this depended on reward value and prior experience of rewards. Lower rewarding flowers led to greater visual search in areas away from both rewarding and distracting flowers. This suggests that attention is more widely distributed for lower rewarding flowers compared to higher rewarding flowers. It’s also important to note that since the distractors were not rewarding, they would also provide the bees with negative reinforcement. This would also partially explain the clear difference in attention between rewards and distractors. Bees with prior experience of higher reward were also more likely to persist in attending to rewarding flowers even when they later encountered lower rewards. In our experiments, we cannot disentangle the effect of reward quality and colour or saliency. However, the fact that the high saliency of low reward flowers did not increase inspection of these flowers in Experiment 1 indicates that our results are likely to reflect reward quality of the flowers rather than their saliency.</p><p id="P33">In primates, eye movements are often used as proxies for overt attention (<xref ref-type="bibr" rid="R49">Schütz et al. 2011</xref>). The duration spent looking at aspects of a scene have also been used to compute attentional maps (<xref ref-type="bibr" rid="R20">Henderson and Hayes 2018</xref>). Our maps of inspection time perhaps best parallel these attentional maps. Results from these studies of eye movements have shown that attention can be influenced by several factors including saliency, reward value and the structure of a scene (<xref ref-type="bibr" rid="R28">Navalpakkam et al. 2010</xref>; <xref ref-type="bibr" rid="R49">Schütz et al. 2011</xref>; <xref ref-type="bibr" rid="R20">Henderson and Hayes 2018</xref>). In non-primates, attentional limitations have most often been studied in predators (<xref ref-type="bibr" rid="R12">Dukas and Kamil 2000</xref>; <xref ref-type="bibr" rid="R14">Dukas et al. 2002</xref>; <xref ref-type="bibr" rid="R11">Dukas 2004</xref>). There, findings show that attentional resources are more focussed when searching for cryptic prey. Conversely, hunger leads to praying mantises widening their search for possible prey (<xref ref-type="bibr" rid="R8">Bertsch et al. 2019</xref>; <xref ref-type="bibr" rid="R31">Pickard et al. 2021</xref>). Our findings further argue that learning about reward value also influences attention in bees, even when the rewarding flowers are not cryptic.</p><p id="P34">The median nectar sugar concentrations for flowers in Europe and globally is around 40% (<xref ref-type="bibr" rid="R44">Pamminger et al. 2019</xref>). Our reward values therefore correspond to a higher than median reward (50%) and lower than median reward (30%). The latter corresponds to the reward value of flowers in the 25<sup>th</sup> percentile. However, bees in our experiment were pretrained on 50% sucrose solution. This could have had some influence our results. Prior experience of a particular reward can influence future behaviour of bees and ants in response to higher or lower rewards – a phenomenon called incentive contrast (<xref ref-type="bibr" rid="R33">Bitterman 1975</xref>; <xref ref-type="bibr" rid="R47">Wendt et al. 2019</xref>). However, in our first experiment, we do not see a difference between visual search to the two rewards in the first training stage, suggesting that the experience of higher rewards during pre-training did not have an immediate effect. We do, however, see an increase in visual search to the rewards compared to other areas, but only in the later training stage, suggesting that as bees encounter higher (but not lower) rewards, they spend less time searching and more time inspecting rewarding flowers. We find some evidence that prior experience can influence visual search behaviour in line with ideas about incentive contrast – bees that experience lower rewards in Experiment 1 had increased attention to higher rewards during Experiment 2 and made faster choices. However, we did not find the converse for bees that switched from higher rewards to lower rewards. One confounding factor here could be that the lower rewarding blue flowers in Experiment 2 were more attractive due to the innate biases of bees. Alternatively, continuous experience of high rewards from the pre-training and Experiment 1 might have boosted the motivation of bees to a high level and persisted for a longer time.</p><p id="P35">Our results demonstrate the value of investigating search behaviour rather than focussing on flower choice alone. Previous work (<xref ref-type="bibr" rid="R29">Nityananda and Chittka 2021</xref>) has looked at bee visual search when faced with a choice between multiple rewarding flowers of different reward and saliency values. Research there found that reward value biased inspection time at flowers, even for lower saliency flowers. Other work has also shown that bees fly shorter distances after encountering rewarding flowers, compared to non-rewarding flowers (<xref ref-type="bibr" rid="R13">Dukas and Real 1993</xref>). Our results further show how reward value modifies bee visual search during learning. This difference in bee behaviour might specifically reflect foraging behaviour in bumblebees. Bumblebees are less flower constant than honeybees (<xref ref-type="bibr" rid="R57">Wells and Wells 1983</xref>; <xref ref-type="bibr" rid="R56">Waser 1986</xref>; <xref ref-type="bibr" rid="R21">Hill et al. 1997</xref>), sampling other flowers even when specializing on a specific flower type – behaviours that have been called ‘minoring’ and ‘majoring’ respectively (<xref ref-type="bibr" rid="R19">Heinrich 1976</xref>, <xref ref-type="bibr" rid="R18">1979</xref>). Given that honeybees are more constant to flowers, it is possible that we might find different results from honeybees with more focussed attention even for lower rewarding flowers. Previous work on bee visual search has already shown differences between honeybees and bumblebees. Honeybees show serial visual search, while bumblebees are capable of parallel visual search – their visual search for a target is independent of the number of distractors (<xref ref-type="bibr" rid="R53">Spaethe et al. 2006</xref>; <xref ref-type="bibr" rid="R27">Morawetz and Spaethe 2012</xref>). Running similar experiments to ours with honeybees and other bees might bring up further interesting differences in visual search and attention.</p><p id="P36">Our findings suggest that flowers that have higher concentration of reward are more likely to have focussed attention from bumblebees. Bees that encounter flowers with lower rewards would be expected to keep searching even as they visit the flowers. We might therefore expect flowers with lower rewards to compensate for this loss of attention. One possibility is that these flowers might be more salient than flowers with higher rewards. However, blue flowers which are salient in temperate zones are actually the ones that are the most rewarding to bees (<xref ref-type="bibr" rid="R16">Giurfa et al. 1995</xref>). Another study in Australia found no significant correlation between reward values and chromatic contrast (<xref ref-type="bibr" rid="R50">Shrestha et al. 2020</xref>). Our results also show that simply having high saliency does not lead to focussed attention as the high saliency lower reward flowers did not attract greater bee visual search. Flowers with lower rewards might therefore be under selective pressure to either invest in multimodal cues (<xref ref-type="bibr" rid="R22">Kulahci et al. 2008</xref>) or include secondary compounds in their nectar that might affect pollinator memory and attention. Caffeine and nicotine have both been shown to have effects on bee learning (<xref ref-type="bibr" rid="R58">Wright et al. 2013</xref>; <xref ref-type="bibr" rid="R10">Couvillon et al. 2015</xref>; <xref ref-type="bibr" rid="R5">Baracchi et al. 2017</xref>; <xref ref-type="bibr" rid="R1">Arnold et al. 2021</xref>) and we would predict that they should be more likely to be present in the nectar of flowers with lower concentrations of reward.</p><p id="P37">Our findings demonstrate the importance of investigating bee behaviour beyond flower choices. Understanding how visual search and attention is influenced by a variety of factors could further enhance our understanding of pollination ecology and bee cognition.</p></sec></body><back><ack id="S15"><title>Acknowledgements</title><p>VN and TR are supported by a BBSRC David Phillips fellowship BB/S009760/1 to VN. This work was also partly supported by a Marie Curie Incoming International Fellowship (PIIF-GA-2009–253593) to VN.</p></ack><sec id="S16" sec-type="data-availability"><title>Data Availability</title><p id="P38">All code and data relevant to this paper are included as supplementary material to this paper.</p></sec><fn-group><fn fn-type="con" id="FN1"><p id="P39"><bold>Author Contributions</bold>: VN conducted the experiment. KT and VN analysed the videos. VN and TR ran the statistical analyses and wrote the paper.</p></fn><fn fn-type="conflict" id="FN2"><p id="P40"><bold>Competing Interests</bold>: The authors have no competing interests to declare that are relevant to the content of this article.</p></fn></fn-group><ref-list><ref id="R1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arnold</surname><given-names>SEJ</given-names></name><name><surname>Dudenhöffer</surname><given-names>J-H</given-names></name><name><surname>Fountain</surname><given-names>MT</given-names></name><etal/></person-group><article-title>Bumble bees show an induced preference for flowers when primed with caffeinated nectar and a target floral odor</article-title><source>Curr Biol</source><year>2021</year><fpage>4127</fpage><lpage>4131</lpage><pub-id pub-id-type="pmid">34324835</pub-id></element-citation></ref><ref id="R2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Avarguès-Weber</surname><given-names>A</given-names></name><name><surname>Deisig</surname><given-names>N</given-names></name><name><surname>Giurfa</surname><given-names>M</given-names></name><etal/></person-group><article-title>Visual cognition in social insects</article-title><source>Annu Rev Entomol</source><year>2011</year><volume>56</volume><fpage>423</fpage><lpage>43</lpage><pub-id pub-id-type="pmid">20868283</pub-id></element-citation></ref><ref id="R3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Avarguès-Weber</surname><given-names>A</given-names></name><name><surname>Giurfa</surname><given-names>M</given-names></name></person-group><article-title>Cognitive components of color vision in honey bees: How conditioning variables modulate color learning and discrimination</article-title><source>J Comp Physiol A</source><year>2014</year><volume>200</volume><fpage>449</fpage><lpage>461</lpage><pub-id pub-id-type="pmid">24788332</pub-id></element-citation></ref><ref id="R4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Avarguès-Weber</surname><given-names>A</given-names></name><name><surname>Lachlan</surname><given-names>R</given-names></name><name><surname>Chittka</surname><given-names>L</given-names></name></person-group><article-title>Bumblebee social learning can lead to suboptimal foraging choices</article-title><source>Anim Behav</source><year>2018</year><volume>135</volume><fpage>209</fpage><lpage>214</lpage><pub-id pub-id-type="doi">10.1016/j.anbehav.2017.11.022</pub-id></element-citation></ref><ref id="R5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baracchi</surname><given-names>D</given-names></name><name><surname>Marples</surname><given-names>A</given-names></name><name><surname>Jenkins</surname><given-names>AJ</given-names></name><etal/></person-group><article-title>Nicotine in floral nectar pharmacologically influences bumblebee learning of floral features</article-title><source>Sci Rep</source><year>2017</year><volume>7</volume><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="pmcid">PMC5434031</pub-id><pub-id pub-id-type="pmid">28512323</pub-id><pub-id pub-id-type="doi">10.1038/s41598-017-01980-1</pub-id></element-citation></ref><ref id="R6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baude</surname><given-names>M</given-names></name><name><surname>Danchin</surname><given-names>É</given-names></name><name><surname>Mugabo</surname><given-names>M</given-names></name><name><surname>Dajoz</surname><given-names>I</given-names></name></person-group><article-title>Conspecifics as informers and competitors: An experimental study in foraging bumble-bees</article-title><source>Proc R Soc B Biol Sci</source><year>2011</year><volume>278</volume><fpage>2806</fpage><lpage>2813</lpage><pub-id pub-id-type="pmcid">PMC3145184</pub-id><pub-id pub-id-type="pmid">21288951</pub-id><pub-id pub-id-type="doi">10.1098/rspb.2010.2659</pub-id></element-citation></ref><ref id="R7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benard</surname><given-names>J</given-names></name><name><surname>Stach</surname><given-names>S</given-names></name><name><surname>Giurfa</surname><given-names>M</given-names></name></person-group><article-title>Categorization of visual stimuli in the honeybee Apis mellifera</article-title><source>Anim Cogn</source><year>2006</year><volume>9</volume><fpage>257</fpage><lpage>70</lpage><pub-id pub-id-type="pmid">16909238</pub-id></element-citation></ref><ref id="R8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bertsch</surname><given-names>DJ</given-names></name><name><surname>Martin</surname><given-names>JP</given-names></name><name><surname>Svenson</surname><given-names>GJ</given-names></name><name><surname>Ritzmann</surname><given-names>RE</given-names></name></person-group><article-title>Predatory behavior changes with satiety or increased insulin levels in the praying mantis (Tenodera sinensis)</article-title><source>J Exp Biol</source><year>2019</year><volume>222</volume><elocation-id>jeb197673</elocation-id><pub-id pub-id-type="pmid">31160429</pub-id></element-citation></ref><ref id="R9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chittka</surname><given-names>L</given-names></name></person-group><article-title>The colour hexagon: a chromaticity diagram based on photoreceptor excitations as a generalized representation of colour opponency</article-title><source>J Comp Physiol A</source><year>1992</year><volume>170</volume><fpage>533</fpage><lpage>543</lpage></element-citation></ref><ref id="R10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Couvillon</surname><given-names>MJ</given-names></name><name><surname>Al Toufailia</surname><given-names>H</given-names></name><name><surname>Butterfield</surname><given-names>TM</given-names></name><etal/></person-group><article-title>Caffeinated forage tricks honeybees into increasing foraging and recruitment behaviors</article-title><source>Curr Biol</source><year>2015</year><volume>25</volume><fpage>2815</fpage><lpage>2818</lpage><pub-id pub-id-type="pmid">26480843</pub-id></element-citation></ref><ref id="R11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dukas</surname><given-names>R</given-names></name></person-group><article-title>Causes and consequences of limited attention</article-title><source>Brain Behav Evol</source><year>2004</year><volume>63</volume><fpage>197</fpage><lpage>210</lpage><pub-id pub-id-type="pmid">15084813</pub-id></element-citation></ref><ref id="R12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dukas</surname><given-names>R</given-names></name><name><surname>Kamil</surname><given-names>AC</given-names></name></person-group><article-title>The cost of limited attention in blue jays</article-title><source>Behav Ecol</source><year>2000</year><volume>11</volume><fpage>502</fpage><lpage>506</lpage><pub-id pub-id-type="doi">10.1093/beheco/11.5.502</pub-id></element-citation></ref><ref id="R13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dukas</surname><given-names>R</given-names></name><name><surname>Real</surname><given-names>LA</given-names></name></person-group><article-title>Effects of recent experience on foraging decisions by bumble bees</article-title><source>Oecologia</source><year>1993</year><volume>94</volume><fpage>244</fpage><lpage>246</lpage><pub-id pub-id-type="pmid">28314038</pub-id></element-citation></ref><ref id="R14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dukas</surname><given-names>R</given-names></name><name><surname>Trans Soc Lond</surname><given-names>B</given-names></name><name><surname>Reuven Dukas</surname><given-names>PR</given-names></name><name><surname>Dukas</surname><given-names>R</given-names></name></person-group><article-title>Behavioural and ecological consequences of limited attention</article-title><source>Philos Trans R Soc Ser B Biol Sci</source><year>2002</year><volume>357</volume><fpage>1539</fpage><lpage>1547</lpage><pub-id pub-id-type="pmcid">PMC1693070</pub-id><pub-id pub-id-type="pmid">12495511</pub-id><pub-id pub-id-type="doi">10.1098/rstb.2002.1063</pub-id></element-citation></ref><ref id="R15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giurfa</surname><given-names>M</given-names></name></person-group><article-title>Visual Cognition in Honey Bees: From Elemental Visual Learning to Non-elemental Problem Solving</article-title><source>Honeybee Neurobiology and Behavior</source><year>2012</year><fpage>471</fpage><lpage>484</lpage></element-citation></ref><ref id="R16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giurfa</surname><given-names>M</given-names></name><name><surname>Nunez</surname><given-names>J</given-names></name><name><surname>Chittka</surname><given-names>L</given-names></name><name><surname>Menzel</surname><given-names>R</given-names></name></person-group><article-title>Colour preferences of flower-naive honeybees</article-title><source>J Comp Physiol A</source><year>1995</year><volume>177</volume><fpage>247</fpage><lpage>259</lpage></element-citation></ref><ref id="R17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goulson</surname><given-names>D</given-names></name></person-group><article-title>Are insects flower constant because they use search images to find flowers?</article-title><source>Oikos</source><year>2000</year><volume>88</volume><fpage>547</fpage><lpage>552</lpage><pub-id pub-id-type="doi">10.1034/j.1600-0706.2000.880311.x</pub-id></element-citation></ref><ref id="R18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heinrich</surname><given-names>B</given-names></name></person-group><article-title>Majoring and Minoring by Foraging Bumblebees, Bombus Vagans: An Experimental Analysis</article-title><source>Ecology</source><year>1979</year><volume>60</volume><fpage>245</fpage><lpage>255</lpage><pub-id pub-id-type="doi">10.2307/1937652</pub-id></element-citation></ref><ref id="R19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heinrich</surname><given-names>B</given-names></name></person-group><article-title>The Foraging Specializations of Individual Bumblebees</article-title><source>Ecol Monogr</source><year>1976</year><volume>46</volume><fpage>105</fpage><lpage>128</lpage><pub-id pub-id-type="doi">10.2307/1942246</pub-id></element-citation></ref><ref id="R20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henderson</surname><given-names>JM</given-names></name><name><surname>Hayes</surname><given-names>TR</given-names></name></person-group><article-title>Meaning guides attention in real-world scene images: Evidence from eye movements and meaning maps</article-title><source>J Vis</source><year>2018</year><volume>18</volume><fpage>1</fpage><lpage>18</lpage><pub-id pub-id-type="pmcid">PMC6012218</pub-id><pub-id pub-id-type="pmid">30029216</pub-id><pub-id pub-id-type="doi">10.1167/18.6.10</pub-id></element-citation></ref><ref id="R21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hill</surname><given-names>PSMM</given-names></name><name><surname>Wells</surname><given-names>PH</given-names></name><name><surname>Wells</surname><given-names>H</given-names></name></person-group><article-title>Spontaneous flower constancy and learning in honey bees as a function of colour</article-title><source>Anim Behav</source><year>1997</year><volume>54</volume><fpage>615</fpage><lpage>27</lpage><pub-id pub-id-type="pmid">9299046</pub-id></element-citation></ref><ref id="R22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kulahci</surname><given-names>IG</given-names></name><name><surname>Dornhaus</surname><given-names>A</given-names></name><name><surname>Papaj</surname><given-names>DR</given-names></name></person-group><article-title>Multimodal signals enhance decision making in foraging bumble-bees</article-title><source>Proc R Soc B Biol Sci</source><year>2008</year><volume>275</volume><fpage>797</fpage><lpage>802</lpage><pub-id pub-id-type="pmcid">PMC2596894</pub-id><pub-id pub-id-type="pmid">18198150</pub-id><pub-id pub-id-type="doi">10.1098/rspb.2007.1176</pub-id></element-citation></ref><ref id="R23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>L</given-names></name><name><surname>Egertová</surname><given-names>H</given-names></name><etal/></person-group><article-title>A possible structural correlate of learning performance on a colour discrimination task in the brain of the bumblebee</article-title><source>Proc R Soc B Biol Sci</source><year>2017</year><volume>284</volume><elocation-id>20171323</elocation-id><pub-id pub-id-type="pmcid">PMC5647297</pub-id><pub-id pub-id-type="pmid">28978727</pub-id><pub-id pub-id-type="doi">10.1098/rspb.2017.1323</pub-id></element-citation></ref><ref id="R24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lubbock</surname><given-names>SJ</given-names></name></person-group><article-title>Observations on ants, bees, and wasps. IX. Color of flowers as an attraction to bees: Experiments and considerations thereon</article-title><source>Zool J Linn Soc</source><year>1881</year><volume>16</volume><fpage>110</fpage><lpage>121</lpage></element-citation></ref><ref id="R25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lunau</surname><given-names>K</given-names></name></person-group><article-title>Colour saturation triggers innate reactions to flower signals: Flower dummy experiments with bumblebees</article-title><source>J Comp Physiol A</source><year>1990</year><volume>166</volume><fpage>827</fpage><lpage>834</lpage></element-citation></ref><ref id="R26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lunau</surname><given-names>K</given-names></name><name><surname>Wacht</surname><given-names>S</given-names></name><name><surname>Chittka</surname><given-names>L</given-names></name></person-group><article-title>Colour choices of naive bumble bees and their implications for colour perception</article-title><source>J Comp Physiol A</source><year>1996</year><volume>178</volume><fpage>477</fpage><lpage>489</lpage><pub-id pub-id-type="doi">10.1007/BF00190178</pub-id></element-citation></ref><ref id="R27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morawetz</surname><given-names>L</given-names></name><name><surname>Spaethe</surname><given-names>J</given-names></name></person-group><article-title>Visual attention in a complex search task differs between honeybees and bumblebees</article-title><source>J Exp Biol</source><year>2012</year><volume>215</volume><fpage>2515</fpage><lpage>2523</lpage><pub-id pub-id-type="pmid">22723491</pub-id></element-citation></ref><ref id="R28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Navalpakkam</surname><given-names>V</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Rangel</surname><given-names>A</given-names></name><name><surname>Perona</surname><given-names>P</given-names></name></person-group><article-title>Optimal reward harvesting in complex perceptual environments</article-title><source>Proc Natl Acad Sci U S A</source><year>2010</year><volume>107</volume><fpage>5232</fpage><lpage>5237</lpage><pub-id pub-id-type="pmcid">PMC2841865</pub-id><pub-id pub-id-type="pmid">20194768</pub-id><pub-id pub-id-type="doi">10.1073/pnas.0911972107</pub-id></element-citation></ref><ref id="R29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nityananda</surname><given-names>V</given-names></name><name><surname>Chittka</surname><given-names>L</given-names></name></person-group><article-title>Different effects of reward value and saliency during bumblebee visual search for multiple rewarding targets</article-title><source>Anim Cogn</source><year>2021</year><volume>24</volume><fpage>803</fpage><lpage>814</lpage><pub-id pub-id-type="pmcid">PMC8238720</pub-id><pub-id pub-id-type="pmid">33515306</pub-id><pub-id pub-id-type="doi">10.1007/s10071-021-01479-3</pub-id></element-citation></ref><ref id="R30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nityananda</surname><given-names>V</given-names></name><name><surname>Pattrick</surname><given-names>JG</given-names></name></person-group><article-title>Bumblebee visual search for multiple learned target types</article-title><source>J Exp Biol</source><year>2013</year><volume>216</volume><fpage>4154</fpage><lpage>60</lpage><pub-id pub-id-type="pmid">23948481</pub-id></element-citation></ref><ref id="R31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pickard</surname><given-names>SC</given-names></name><name><surname>Bertsch</surname><given-names>DJ</given-names></name><name><surname>Le Garrec</surname><given-names>Z</given-names></name><etal/></person-group><article-title>Internal state effects on behavioral shifts in freely behaving praying mantises (Tenodera sinensis)</article-title><source>PLOS Comput Biol</source><year>2021</year><volume>17</volume><elocation-id>e1009618</elocation-id><pub-id pub-id-type="pmcid">PMC8751982</pub-id><pub-id pub-id-type="pmid">34928939</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1009618</pub-id></element-citation></ref><ref id="R32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ben-Tov</surname><given-names>M</given-names></name><name><surname>Donchin</surname><given-names>O</given-names></name><name><surname>Ben-Shahar</surname><given-names>O</given-names></name><name><surname>Segev</surname><given-names>R</given-names></name></person-group><article-title>Pop-out in visual search of moving targets in the archer fish</article-title><source>Nat Commun</source><year>2015</year><volume>6</volume><elocation-id>6476</elocation-id><pub-id pub-id-type="pmid">25753807</pub-id></element-citation></ref><ref id="R33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bitterman</surname><given-names>M</given-names></name></person-group><article-title>Incentive Contrast in Honey Bees</article-title><source>Science (80-)</source><year>1975</year><volume>192</volume><fpage>380</fpage><lpage>382</lpage><pub-id pub-id-type="pmid">1257773</pub-id></element-citation></ref><ref id="R34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bond</surname><given-names>AB</given-names></name><name><surname>Kamil</surname><given-names>AC</given-names></name></person-group><article-title>Visual predators select for crypticity and polymorphism in virtual prey</article-title><source>Nature</source><year>2002</year><volume>415</volume><fpage>609</fpage><lpage>13</lpage><pub-id pub-id-type="pmid">11832937</pub-id></element-citation></ref><ref id="R35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brooks</surname><given-names>M</given-names></name><name><surname>Kristensen</surname><given-names>K</given-names></name><name><surname>van Benthem</surname><given-names>K</given-names></name><etal/></person-group><article-title>glmmTMB Balances Speed and Flexibility Among Packages for Zero-inflated Generalized Linear Mixed Modeling</article-title><source>R J</source><year>2017</year><volume>9</volume><fpage>378</fpage><lpage>400</lpage><pub-id pub-id-type="doi">10.32614/RJ-2017-066</pub-id></element-citation></ref><ref id="R36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dukas</surname><given-names>R</given-names></name><name><surname>Kamil</surname><given-names>AC</given-names></name></person-group><article-title>The cost of limited attention in blue jays</article-title><source>Behav Ecol</source><year>2000</year><volume>11</volume><fpage>502</fpage><lpage>506</lpage><pub-id pub-id-type="doi">10.1093/beheco/11.5.502</pub-id></element-citation></ref><ref id="R37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gil</surname><given-names>M</given-names></name><name><surname>De Marco</surname><given-names>RJ</given-names></name><name><surname>Menzel</surname><given-names>R</given-names></name></person-group><article-title>Learning reward expectations in honeybees</article-title><source>Learn Mem</source><year>2007</year><volume>14</volume><fpage>491</fpage><lpage>496</lpage><pub-id pub-id-type="pmcid">PMC1934344</pub-id><pub-id pub-id-type="pmid">17626907</pub-id><pub-id pub-id-type="doi">10.1101/lm.618907</pub-id></element-citation></ref><ref id="R38"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Hartig</surname><given-names>F</given-names></name></person-group><source>DHARMa: Residual Diagnostics for Hierarchical (Multi-Level / Mixed) Regression Models. R package version 0 4 6</source><year>2022</year><comment><ext-link ext-link-type="uri" xlink:href="http://florianhartig.github.io/DHARMa/">http://florianhartig.github.io/DHARMa/</ext-link></comment></element-citation></ref><ref id="R39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horowitz</surname><given-names>TS</given-names></name><name><surname>Wolfe</surname><given-names>JM</given-names></name></person-group><article-title>Search for multiple targets: remember the targets, forget the search</article-title><source>Percept Psychophys</source><year>2001</year><volume>63</volume><fpage>272</fpage><lpage>85</lpage><pub-id pub-id-type="pmid">11281102</pub-id></element-citation></ref><ref id="R40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nityananda</surname><given-names>V</given-names></name></person-group><article-title>Attention-like processes in insects</article-title><source>Proc R Soc B Biol Sci</source><year>2016</year><volume>283</volume><elocation-id>20161986</elocation-id><pub-id pub-id-type="pmcid">PMC5124100</pub-id><pub-id pub-id-type="pmid">27852803</pub-id><pub-id pub-id-type="doi">10.1098/rspb.2016.1986</pub-id></element-citation></ref><ref id="R41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nityananda</surname><given-names>V</given-names></name><name><surname>Chittka</surname><given-names>L</given-names></name></person-group><article-title>Different effects of reward value and saliency during bumblebee visual search for multiple rewarding targets</article-title><source>Anim Cogn</source><year>2021</year><volume>24</volume><fpage>803</fpage><lpage>814</lpage><pub-id pub-id-type="doi">10.1007/s10071-021-01479-3</pub-id></element-citation></ref><ref id="R42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Orlowski</surname><given-names>J</given-names></name><name><surname>Beissel</surname><given-names>C</given-names></name><name><surname>Rohn</surname><given-names>F</given-names></name><etal/></person-group><article-title>Visual pop-out in barn owls: Human-like behavior in the avian brain</article-title><source>J Vis</source><year>2015</year><volume>15</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="pmid">26448146</pub-id></element-citation></ref><ref id="R43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Orlowski</surname><given-names>J</given-names></name><name><surname>Ben-Shahar</surname><given-names>O</given-names></name><name><surname>Wagner</surname><given-names>H</given-names></name><etal/></person-group><article-title>Visual search in barn owls : Task difficulty and saccadic behavior</article-title><source>J Vis</source><year>2018</year><volume>18</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="pmid">29322165</pub-id></element-citation></ref><ref id="R44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pamminger</surname><given-names>T</given-names></name><name><surname>Becker</surname><given-names>R</given-names></name><name><surname>Himmelreich</surname><given-names>S</given-names></name><etal/></person-group><article-title>The nectar report: quantitative review of nectar sugar concentrations offered by bee visited flowers in agricultural and non-agricultural landscapes</article-title><source>PeerJ</source><year>2019</year><volume>7</volume><elocation-id>e6329</elocation-id><pub-id pub-id-type="pmcid">PMC6397631</pub-id><pub-id pub-id-type="pmid">30834180</pub-id><pub-id pub-id-type="doi">10.7717/peerj.6329</pub-id></element-citation></ref><ref id="R45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Posner</surname><given-names>MI</given-names></name></person-group><article-title>Orienting of attention</article-title><source>Q J Exp Psychol</source><year>1980</year><volume>32</volume><fpage>3</fpage><lpage>25</lpage><pub-id pub-id-type="pmid">7367577</pub-id></element-citation></ref><ref id="R46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saban</surname><given-names>W</given-names></name><name><surname>Sekely</surname><given-names>L</given-names></name><name><surname>Klein</surname><given-names>RM</given-names></name><name><surname>Gabay</surname><given-names>S</given-names></name></person-group><article-title>Endogenous orienting in the archer fish</article-title><source>Proc Natl Acad Sci</source><year>2017</year><volume>114</volume><fpage>7577</fpage><lpage>7581</lpage><pub-id pub-id-type="pmcid">PMC5530659</pub-id><pub-id pub-id-type="pmid">28673997</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1700574114</pub-id></element-citation></ref><ref id="R47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wendt</surname><given-names>S</given-names></name><name><surname>Strunk</surname><given-names>KS</given-names></name><name><surname>Heinze</surname><given-names>J</given-names></name><etal/></person-group><article-title>Positive and negative incentive contrasts lead to relative value perception in ants</article-title><source>Elife</source><year>2019</year><volume>8</volume><fpage>1</fpage><lpage>22</lpage><pub-id pub-id-type="pmcid">PMC6606023</pub-id><pub-id pub-id-type="pmid">31262401</pub-id><pub-id pub-id-type="doi">10.7554/eLife.45450</pub-id></element-citation></ref><ref id="R48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Riveros</surname><given-names>AJ</given-names></name><name><surname>Gronenberg</surname><given-names>W</given-names></name></person-group><article-title>Decision-making and associative color learning in harnessed bumblebees (Bombus impatiens)</article-title><source>Anim Cogn</source><year>2012</year><volume>15</volume><fpage>1183</fpage><lpage>93</lpage><pub-id pub-id-type="pmid">22837045</pub-id></element-citation></ref><ref id="R49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schütz</surname><given-names>AC</given-names></name><name><surname>Braun</surname><given-names>DI</given-names></name><name><surname>Gegenfurtner</surname><given-names>KR</given-names></name></person-group><article-title>Eye movements and perception: A selective review</article-title><source>J Vis</source><year>2011</year><volume>11</volume><fpage>1</fpage><lpage>30</lpage><pub-id pub-id-type="pmid">21917784</pub-id></element-citation></ref><ref id="R50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shrestha</surname><given-names>M</given-names></name><name><surname>Garcia</surname><given-names>JE</given-names></name><name><surname>Burd</surname><given-names>M</given-names></name><name><surname>Dyer</surname><given-names>AG</given-names></name></person-group><article-title>Australian native flower colours: Does nectar reward drive bee pollinator flower preferences?</article-title><source>PLoS One</source><year>2020</year><volume>15</volume><fpage>11</fpage><lpage>15</lpage><pub-id pub-id-type="pmcid">PMC7289428</pub-id><pub-id pub-id-type="pmid">32525873</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0226469</pub-id></element-citation></ref><ref id="R51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skorupski</surname><given-names>P</given-names></name><name><surname>Döring</surname><given-names>TF</given-names></name><name><surname>Chittka</surname><given-names>L</given-names></name></person-group><article-title>Photoreceptor spectral sensitivity in island and mainland populations of the bumblebee, Bombus terrestris</article-title><source>J Comp Physiol A Neuroethol Sensory, Neural, Behav Physiol</source><year>2007</year><volume>193</volume><fpage>485</fpage><lpage>494</lpage><pub-id pub-id-type="pmid">17333207</pub-id></element-citation></ref><ref id="R52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Solvi</surname><given-names>C</given-names></name><name><surname>Zhou</surname><given-names>Y</given-names></name><name><surname>Feng</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Bumblebees retrieve only the ordinal ranking of foraging options when comparing memories obtained in distinct settings</article-title><source>Elife</source><year>2022</year><volume>11</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="pmcid">PMC9514845</pub-id><pub-id pub-id-type="pmid">36164830</pub-id><pub-id pub-id-type="doi">10.7554/eLife.78525</pub-id></element-citation></ref><ref id="R53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spaethe</surname><given-names>J</given-names></name><name><surname>Tautz</surname><given-names>J</given-names></name><name><surname>Chittka</surname><given-names>L</given-names></name></person-group><article-title>Do honeybees detect colour targets using serial or parallel visual search?</article-title><source>J Exp Biol</source><year>2006</year><volume>209</volume><fpage>987</fpage><lpage>993</lpage><pub-id pub-id-type="pmid">16513924</pub-id></element-citation></ref><ref id="R54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turner</surname><given-names>CH</given-names></name></person-group><article-title>Experiments on color-vision of the honey bee</article-title><source>Biol Bull</source><year>1910</year><volume>18</volume><fpage>257</fpage><lpage>279</lpage><pub-id pub-id-type="doi">10.1086/bblv18n5p213</pub-id></element-citation></ref><ref id="R55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>von Frisch</surname><given-names>K</given-names></name></person-group><article-title>Der Farbensinn und Formensinn der Biene</article-title><source>Zool Jahrb Abt Allg Zool Physiol Tiere</source><year>1914</year><volume>7</volume><fpage>1</fpage><lpage>238</lpage></element-citation></ref><ref id="R56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Waser</surname><given-names>NM</given-names></name></person-group><article-title>Flower Constancy: Definition, Cause, and Measurement</article-title><source>Am Nat</source><year>1986</year><volume>127</volume><fpage>593</fpage><lpage>603</lpage></element-citation></ref><ref id="R57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wells</surname><given-names>H</given-names></name><name><surname>Wells</surname><given-names>PH</given-names></name></person-group><article-title>Honey Bee Foraging Ecology : Optimal Diet, Minimal Uncertainty or Individual Constancy?</article-title><source>J Anim Ecol</source><year>1983</year><volume>52</volume><fpage>829</fpage><lpage>836</lpage></element-citation></ref><ref id="R58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wright</surname><given-names>GA</given-names></name><name><surname>Baker</surname><given-names>DD</given-names></name><name><surname>Palmer</surname><given-names>MJ</given-names></name><etal/></person-group><article-title>Caffeine in floral nectar enhances a pollinator’s memory of reward</article-title><source>Science (80-)</source><year>2013</year><volume>339</volume><fpage>1202</fpage><lpage>1204</lpage><pub-id pub-id-type="pmcid">PMC4521368</pub-id><pub-id pub-id-type="pmid">23471406</pub-id><pub-id pub-id-type="doi">10.1126/science.1228806</pub-id></element-citation></ref></ref-list></back><floats-group><boxed-text id="BX1" position="float" orientation="portrait"><caption><title>Significance Statement</title></caption><p>Studies investigating how foraging bees learn about reward typically focus on the choices made by the bees. How bees deploy attention and visual search during foraging is less well studied. We analysed flight videos to characterise visual search as bees learn which flowers are rewarding. We found that learning increases the focus of bees on flower regions. We also found that the quality of the reward a flower offers influences how much bees search in non-flower areas. This means that a flower with lower reward attracts less focussed foraging compared to one with a higher reward. Since flowers do differ in floral reward, this has important implications for how focussed pollinators will be on different flowers. Our approach of looking at search behaviour and attention thus advances our understanding of the cognitive ecology of pollination.</p></boxed-text><fig id="F1" position="float"><label>Figure 1</label><caption><title>Experimental protocol.</title><p>A) Colour loci of the artificial flower colours used in the experiments in the colour hexagon (<xref ref-type="bibr" rid="R9">Chittka 1992</xref>). Three vertices correspond to maximum excitation of photoreceptors sensitive to blue (B), green (G) and ultraviolet (UV) light. The distance from the centre to any vertex is 1 (see scale) and represents how salient is a colour. The distance between points represents hue discriminability, with 0.1 being easily distinguishable. B) Training paradigm in the experiments. Half the bees followed the protocol in the top row and half the bees followed the one in the bottom row. Rewarding (Blue and Yellow) and distractor (Fucshia and Cream) colours were the same in both but the order in which they were encountered (i.e. Experiment 1 or 2) was reversed. The rewarding flowers had 12 μl of 30% (lower reward) or 50% (higher reward) sucrose solution while distractors had an equal quantity of distilled water.</p></caption><graphic xlink:href="EMS189384-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><p>Bee visual search in Experiment 1. Top row: Proportion of time spent by the bees in different regions weighted by the area of each region. Bees were presented with A) lower reward (30% sucrose) high saliency blue flowers or B) higher reward (50% sucrose) lower saliency yellow flowers. Pink plots depict data from the first six choices and blue plots depict data from the last six choices of the training. Box plots depict the median and the first and third quartiles, the whiskers depict the largest and smallest values that are within 1.5 times the interquartile range from the edge of the boxes. Dots represent data from individual bees. C-F) Example visual search maps for two bees depicted as a top view of the flight arena with rewarding and distractor flowers. Colours depict the inspection times up to a maximum of 500 ms. Squares depict flower zones and the inner bound of the defined inspection zones, white circles illustrate the outer bound of the inspection zones. Only one circle is depicted in each figure here for ease of illustration. <italic>R</italic> = Rewarding flowers; <italic>D</italic> = Distractor flowers. C) and D) depict examples for the first six choices of training for bees trained on lower reward and higher reward flowers respectively. E) and F) depict the visual search during the last six choices of the same two bees as in C) and D) respectively.</p></caption><graphic xlink:href="EMS189384-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><p>Bee visual search in Experiment 2. The data here represent bees initially trained on one reward type (higher or lower) in Experiment 1 (<xref ref-type="fig" rid="F2">Figure 2</xref>) and subsequently trained on the opposite reward type (lower or higher) in Experiment 2. Top row: Proportion of time spent by the bees in different regions weighted by the area of each region. Bees were presented with A) lower reward (30% sucrose) high saliency blue flowers or B) higher reward (50% sucrose) lower saliency yellow flowers. Pink plots depict data from the first six choices and blue plots depict data from the last six choices of the training. Box plots depict the median and the first and third quartiles, the whiskers depict the largest and smallest values that are within 1.5 times the interquartile range from the edge of the boxes. Dots represent data from individual bees. C-F) Example visual search maps for two bees depicted as a top view of the flight arena with rewarding and distractor flowers. Colours depict the inspection times up to a maximum of 500 ms. Squares depict flower zones and the inner bound of the defined inspection zones, white circles illustrate the outer bound of the inspection zones. Only one circle is depicted in each figure here for ease of illustration. <italic>R</italic> = Rewarding flowers; <italic>D</italic> = Distractor flowers. C) and D) depict examples for the first six choices of training for bees trained on lower reward and higher reward flowers respectively. E) and F) depict the visual search during the last six choices of the same two bees as in C) and D) respectively. The example in C) and E) here is the same bee trained in D) and F) in <xref ref-type="fig" rid="F2">Figure 2</xref> and the example in D) and F) here is the same bee trained in C) and F) in <xref ref-type="fig" rid="F2">Figure 2</xref>.</p></caption><graphic xlink:href="EMS189384-f003"/></fig></floats-group></article>