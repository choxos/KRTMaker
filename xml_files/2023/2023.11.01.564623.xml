<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS190583</article-id><article-id pub-id-type="doi">10.1101/2023.11.01.564623</article-id><article-id pub-id-type="archive">PPR752643</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">2</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>MolecularWebXR: Multiuser discussions about chemistry and biology in immersive and inclusive VR</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Cortés Rodríguez</surname><given-names>Fabio J.</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Frattini</surname><given-names>Gianfranco</given-names></name><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Phloi-Montri</surname><given-names>Sittha</given-names></name><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Meireles</surname><given-names>Fernando Teixeira Pinto</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Terrien</surname><given-names>Danaé A.</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Cruz-León</surname><given-names>Sergio</given-names></name><xref ref-type="aff" rid="A4">4</xref></contrib><contrib contrib-type="author"><name><surname>Peraro</surname><given-names>Matteo Dal</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Schier</surname><given-names>Eva</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Lindorff-Larsen</surname><given-names>Kresten</given-names></name><xref ref-type="aff" rid="A5">5</xref></contrib><contrib contrib-type="author"><name><surname>Limpanuparb</surname><given-names>Taweetham</given-names></name><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Moreno</surname><given-names>Diego M.</given-names></name><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Abriata</surname><given-names>Luciano A.</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib></contrib-group><aff id="A1"><label>1</label>School of Life Sciences, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/02s376052</institution-id><institution>École Polytechnique Fédérale de Lausanne</institution></institution-wrap>, <postal-code>CH-1015</postal-code><country country="CH">Switzerland</country></aff><aff id="A2"><label>2</label>Instituto de Química Rosario (IQUIR, CONICET-UNR) and Facultad de Ciencias Bioquímicas y Farmacéuticas, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/02tphfq59</institution-id><institution>Universidad Nacional de Rosario</institution></institution-wrap>, <city>Rosario</city>, <state>Santa Fe</state>, <country country="AR">Argentina</country></aff><aff id="A3"><label>3</label>Mahidol University International College, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/01znkr924</institution-id><institution>Mahidol University</institution></institution-wrap>, <city>Salaya</city><postal-code>73170</postal-code>, <country country="TH">Thailand</country></aff><aff id="A4"><label>4</label>Department of Theoretical Biophysics, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/02panr271</institution-id><institution>Max Planck Institute of Biophysics</institution></institution-wrap>, <city>Frankfurt am Main</city>, <country country="DE">Germany</country></aff><aff id="A5"><label>5</label>Linderstrøm-Lang Centre for Protein Science, Department of Biology, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/035b05819</institution-id><institution>University of Copenhagen</institution></institution-wrap>, <city>Copenhagen</city>, <country country="DK">Denmark</country></aff><author-notes><corresp id="CR1">
<label>*</label>Corresponding autor: <email>luciano.abriata@epfl.ch</email></corresp></author-notes><pub-date pub-type="nihms-submitted"><day>04</day><month>11</month><year>2023</year></pub-date><pub-date pub-type="preprint"><day>02</day><month>11</month><year>2023</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">MolecularWebXR is a new website for education, science communication and scientific peer discussion in chemistry and biology, based on modern web-based Virtual Reality (VR) and Augmented Reality (AR). With no installs as it is all web-served, MolecularWebXR enables multiple users to simultaneously explore, communicate and discuss concepts about chemistry and biology in immersive 3D environments, by manipulating and passing around objects with their bare hands and pointing at different elements with natural hand gestures. User may either be present in the same real space or distributed around the world, in the latter case talking naturally with each other thanks to built-in audio features. Although MolecularWebXR is most immersive when running in the web browsers of high-end AR/VR headsets, its WebXR core also allows participation by users with consumer devices such as smartphones, possibly inserted into cardboard goggles for deeper immersivity, or even in computers and tablets. MolecularWebXR comes with preset VR rooms that cover topics from general, inorganic and organic chemistry, biophysics and structural biology, and general biology; besides, new content can be added at will through moleculARweb’s PDB2AR tool or by contacting the lead authors. We verified MolecularWebXR’s ease of use and versatility by people aged 12-80 years old in entirely virtual sessions or in mixed real-virtual sessions at various science outreach events, in courses at the bachelor, masters and early doctoral levels, in scientific collaborations, and in conference lectures. MolecularWebXR is available for free use without registration at <ext-link ext-link-type="uri" xlink:href="https://molecularwebxr.org">https://molecularwebxr.org</ext-link>, and a blog post version of this preprint with embedded videos is available at <ext-link ext-link-type="uri" xlink:href="https://go.epfl.ch/molecularwebxr-blog-post">https://go.epfl.ch/molecularwebxr-blog-post</ext-link>.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">In education and also in the daily work in the chemical and biological sciences, the human ability to visually grasp and communicate the details of objects that are inherently three-dimensional is essential, yet most technical means of presenting and manipulating 3D information are intrinsically two-dimensional.<sup><xref ref-type="bibr" rid="R1">1</xref></sup> In fact, today most molecular visualization and manipulation takes place in the form of two-dimensional interfaces and representations such as pictures, diagrams and flat-screen computer graphics. Even the most advanced molecular graphics programs at their core typically display molecules on flat 2D screens, and allow users to interact with the molecular system only through mouse moves and key strokes which are inherently one-handed and very limited in terms of natural interactivity, let alone in allowing concurrent action of multiple users. Attempting to alleviate these drawbacks, over various “waves of hype” on virtual reality (VR) most classical programs for molecular modeling and graphics introduced VR extensions that provide immersive visualization and spatial control on manual operations.<sup><xref ref-type="bibr" rid="R2">2</xref>–<xref ref-type="bibr" rid="R4">4</xref></sup> In addition, various programs have been developed specifically for manipulating molecules in VR, often with limited functionality compared to the VR versions of more complete molecular graphics software but with the benefit of being much simpler to deploy and utilize. Besides, tests have been conducted to explore the benefits and drawbacks of the technology in real-world utilization, including tests on how multiple users can work concurrently in shared VR sessions.<sup><xref ref-type="bibr" rid="R5">5</xref></sup> However, the adoption of VR software for molecular graphics has been very limited, and one could argue that the lack of success is most likely due to a technology that was not ripe enough until this decade.</p><p id="P3">Since around year 2020, a new wave of VR and also augmented reality (AR) technologies has opened up new frontiers for immersive and interactive learning experiences, with these technologies evolving faster than ever among consumers.<sup><xref ref-type="bibr" rid="R6">6</xref></sup> This renewed interest in VR and AR, along with the substantial investment fueled by the idea of building the pieces of a “Metaverse”, has fostered the development of new AR and VR devices that are smaller and more wearable, have sensors that track the environment and the user’s pose with high accuracy, and are fully built into the headset eliminating the need to connect to external computers. Recent AR and VR headsets include built-in Wi-Fi connectivity and web browsing capabilities and are more affordable. For example, immersive devices like Meta’s Oculus Quest 2 and 3, used in this work, are available for USD 300-600 as of June 2024.</p><p id="P4">Together with the advent of new AR and VR hardware, new programming standards have also evolved coordinated by major vendors, and new software tools have emerged in the last years that allow users to teach, self-learn and work in immersive environments.<sup><xref ref-type="bibr" rid="R7">7</xref></sup> In the specific context of chemistry and biology,<sup><xref ref-type="bibr" rid="R8">8</xref></sup> stand-alone programs for AR/VR and modules that extend the capabilities of regular computer graphics programs into AR-VR have emerged.<sup><xref ref-type="bibr" rid="R9">9</xref>–<xref ref-type="bibr" rid="R14">14</xref></sup> Importantly, the most advanced of these AR/VR programs are starting to support at least two-user sessions,<sup><xref ref-type="bibr" rid="R5">5</xref></sup> thus slowly starting to enable virtual human interactions and collaborations as required for teaching, collaborative work and discussions, etc.</p><p id="P5">However, despite the recent emergence of several new programs for immersive molecular visualization and modeling in VR/AR, their adoption still seems very limited. We argue that the main limitation is not only the cost of the AR and/or VR headsets, which has lowered but is still substantial, but also involves the complex nature of the setups involved and the limited cross-device compatibility of the existing programs. This is why over the last 5 years we have advocated for and built purely web-based solutions for molecular graphics,<sup><xref ref-type="bibr" rid="R15">15</xref></sup> meant to work “out of the box” without installation, recently capitalizing on the WebXR standard and API.<sup><xref ref-type="bibr" rid="R16">16</xref></sup> WebXR-based solutions bring two advantages of unparalleled relevance to adoption and democratization of access to immersive content: (i) high portability across devices and operating systems, from laptops and smartphones to high-end AR/VR headsets; and (ii) low barriers to deployment and availability as all content runs inside web browsers hence requires no installs or updates and is instantly available upon internet connection.<sup><xref ref-type="bibr" rid="R16">16</xref>–<xref ref-type="bibr" rid="R18">18</xref></sup> Plus, by not requiring any login or registration, the website is used under full privacy (and no files loaded by the users are stored in our server).</p><p id="P6">With this philosophy in mind, 3 years ago we released moleculARweb, a free platform that offers several activities and playgrounds for chemistry and structural biology education in commodity AR, that is AR that runs on non-specialized devices such as smartphones, computers, and laptops.<sup><xref ref-type="bibr" rid="R19">19</xref>–<xref ref-type="bibr" rid="R21">21</xref></sup> Next, building on the WebXR standard we extended moleculARweb with PDB2AR, a web tool that allows users to create web-based AR and VR sessions for any kind of consumer device, including basic forms of WebXR-based display. In PDB2AR the virtual objects are generated with VMD,<sup><xref ref-type="bibr" rid="R22">22</xref></sup> and as such it supports all its “representations” from simple ball-and-stick models and cartoons to isosurfaces useful to represent electronic orbitals or cryo-electron maps.<sup><xref ref-type="bibr" rid="R23">23</xref></sup></p><p id="P7">Here we introduce MolecularWebXR (<xref ref-type="fig" rid="F1">Figure 1A</xref>), a new platform for education, science communication and scientific peer discussion in topics of chemistry and (mainly structural) biology exploiting immersive VR and AR as supported by the WebXR standard. Being web-served and hence not requiring installation or any additional software, MolecularWebXR enables multiple users to simultaneously explore, communicate and discuss concepts about chemistry and biology in immersive 3D environments by manipulating and passing around objects with their bare hands and pointing at their features with natural hand gestures. Users can be present in the same physical space or distributed around the world, in the latter case talking naturally with each other through the device thanks to built-in audio features. MolecularWebXR offers rooms with pre-built material about a series of topics for chemistry and (structural) biology education, and an empty room that users can populate with custom-made objects from moleculARweb’s PDB2AR app to create personalized VR sessions for classes, demonstrations, and scientific discussions.</p><p id="P8">Inside MolecularWebXR sessions, users wearing VR headsets are displayed with their heads and hands reflecting their natural poses and moves; they can grab objects to move them and resize them in space, point with their hands in a natural fashion, and communicate with each other by talking naturally directly through the headset’s microphone, in VR (<xref ref-type="fig" rid="F1">Figure 1B</xref>) or AR (<xref ref-type="fig" rid="F1">Figure 1C</xref>). Users without access to hardware specialized for VR can still follow the sessions from their laptops, tablets or smartphones (<xref ref-type="fig" rid="F1">Figure 1D-F</xref>). Moreover, the latter supports immersive VR modes with 3 degrees of freedom (rotations) by using cardboard-made goggles (<xref ref-type="fig" rid="F1">Figure 1E</xref>), and through-screen AR with 6 degrees of freedom (<xref ref-type="fig" rid="F1">Figure 1F</xref>).</p><p id="P9">Throughout the article we showcase example applications of MolecularWebXR as either entirely virtual sessions or mixed real-virtual sessions, in VR and in AR, deployed in science outreach days at our institutions, student instruction at courses of varied levels, scientific collaboration, and at conference lectures.</p><sec id="S2"><title>System</title><p id="P10">MolecularWebXR relies on WebXR, an API and specification for web content and web apps to interface with mixed reality hardware and supported by all major vendors, thus easily enabling cross-device compatibility.<sup><xref ref-type="bibr" rid="R16">16</xref></sup> This API automatically parses the device’s input capabilities into standardized events and mechanisms that are fed into the web browser, for which the software is written in JavaScript at the core. A server, running in Node.js, centralizes the creation and management of rooms where VR sessions take place. The exact VR devices used in the experiences presented throughout the figures of this article were the Oculus Quest 2, Meta Quest 3 and Meta Quest Pro, all with the hand tracking feature enabled. We also allow object manipulation with handheld controls in these 3 devices, and we verified proper working of the website in the App Vision Pro, Oculus Quest 1 and HTC Vive Pro, the latter two only handheld controls.</p><p id="P11">By design, access to MolecularWebXR is highly democratized, as the web standard ensures that the software works out of the box in the web browsers of all kinds of devices from high-end VR headsets to smartphones, tablets and computers, leaving no one out as discussed above and exemplified throughout all figures of this paper. In high-end VR headsets, users can grab objects and pass them around with their hands or controls, zoom them in or out with natural gestures, use their hands to point at objects, and freely move around scenes, in AR or VR (<xref ref-type="fig" rid="F1">Figure 1B-D</xref>). Users accessing with headsets are displayed as hands-and-head avatars that all other users can see. In modern smartphones, users can move around the scene with a joystick located on the bottom left and choose where to gaze by touching on the screen (<xref ref-type="fig" rid="F1">Figure 1E</xref> top, where the joystick is the grey circle on the bottom left). They can also access sessions in immersive VR by using cardboard goggles, without the ability to grab objects as smartphones do not (yet) offer built-in hand tracking but with full capability to see the scene and the other users as well as hearing the conversations and talking. A limitation of smartphones in the goggle-assisted VR mode is that they only offer 3 degrees of freedom, allowing 360° visualization but not displacements around the scene, which can only be achieved outside of VR mode by using the joystick. However, modern smartphones also allow see-through AR with 6 degrees of freedom as in <xref ref-type="fig" rid="F1">Figure 1F</xref>. Last, in tablets, laptops and other kinds of computers there is naturally no immersive AR or VR of any type; however, users can move around the VR scenes by using the arrow (or W, A, S and D) keys and mouse or touch gestures and they can see and hear all users who are inside AR or VR.</p></sec><sec id="S3"><title>Using MolecularWebXR</title><p id="P12">To access MolecularWebXR, users must direct the web browsers of their devices to <ext-link ext-link-type="uri" xlink:href="https://molecularwebxr.org/">https://molecularwebxr.org/</ext-link>. On first entry with a given device, users must allow audio functions to support talking over the internet, if this feature is to be used. No login or registration is required. For details on how to use MolecularWebXR, see <xref ref-type="supplementary-material" rid="SD1">Figures S1-S3</xref>.</p><p id="P13">Once in the main hall (<xref ref-type="fig" rid="F1">Figure 1A</xref>), the user can create a new room or join an existing one by using a unique code provided by the person who created it, whom we refer to as the <italic>Admin</italic>. When a user creates a new room, s/he becomes its <italic>Admin</italic> and obtains codes to invite <italic>VR-active</italic> and other users who can act as guests, <italic>i.e.</italic> who can follow the presentation but only passively. <italic>VR-active</italic> users can enter VR if they use a WebXR-capable device and can grab virtual objects with their hands or controls if they are using a VR headset and if the <italic>Admin</italic> has enabled object grabbing. <italic>VR-active</italic> users can also talk to each other and to the <italic>Admin</italic>. All users can move around the VR scene and listen to the <italic>Admin</italic> and <italic>VR-active</italic> users, but those in passive mode cannot grab objects or talk. This distinction between different classes of users allows sessions to be set up in different formats; for example, as discussions where <italic>VR-active</italic> users can present and discuss while other users follow passively; or as courses/lectures/presentations where a single <italic>Admin</italic> or <italic>VR-active</italic> user presents to various passive users.</p><p id="P14">Importantly, VR sessions running in MolecularWebXR can accommodate users located in the same physical space or accessing from remote locations (<xref ref-type="fig" rid="F2">Figure 2A and 2B</xref>). In the latter case, the audio features are essential to allow for natural conversation and discussion. If all users are located in the same physical space, the audio features should rather be turned off. For mixed locations, audio features can be kept at the <italic>Admin</italic> level, but ensuring that individuals located in the same physical space turn off all but one of their personal audio inputs.</p><p id="P15">When a session consists of users in the same physical space, it is important that the safe-space of all VR devices (the “guardians” in the jargon of Oculus/Meta products) is set up in the same way, so that the relative positions of different users match in the real and virtual spaces. With the right setup, users can feel their physical proximity and talk directly to each other in a very natural way, in the same real space but handling the virtual objects and not seeing their real bodies but their avatars.</p><p id="P16">We note that bandwidth consumption is high when the VR objects are downloaded upon the user entering the room. Once the room is ready, very high-speed Wi-Fi is not needed but it is important to have a stable internet connection to keep updates fluid as the different users move objects and themselves around the virtual room. We note that no video is transmitted between users but just the quaternions that describe object positions, orientations and scales of the VR objects and of the hands and head avatars of all users inside VR.</p><p id="P17">We have had up to 8 simultaneous <italic>VR-active</italic> users inside VR, an <italic>Admin</italic> running on a laptop and two passive users following the sessions online, without apparent lag (all 8 VR devices and the <italic>Admin</italic> were on the same Wi-Fi network).</p></sec><sec id="S4"><title>Content and example applications</title><p id="P18">When the <italic>Admin</italic> user creates a session, she/he can choose to use a preset room containing content that we have prepared specifically to cover certain topics of chemistry and structural biology expected to benefit largely from deep 3D visualization, or from an empty room where objects can be added at will (<xref ref-type="fig" rid="F3">Figure 3</xref>). Fully customized content can be created via PDB2AR (<ext-link ext-link-type="uri" xlink:href="https://molecularweb.epfl.ch/pages/pdb2ar.html">https://molecularweb.epfl.ch/pages/pdb2ar.html</ext-link>) (<xref ref-type="fig" rid="F3">Figure 3A</xref>). The preset content covers topics on molecular structure (<xref ref-type="fig" rid="F3">Figure 3B-F</xref>), atomic and molecular electronic orbitals (<xref ref-type="fig" rid="F3">Figure 3C</xref>), symmetry elements in molecules of the main point groups (<xref ref-type="fig" rid="F3">Figure 3B</xref>), crystal latices and atomic arrangements in simple materials (<xref ref-type="fig" rid="F3">Figure 3D</xref>), introductory structural biology (<xref ref-type="fig" rid="F3">Figure 3F</xref>), and 3D views of cellular compartments and viruses obtained by cryo-electron tomography (<xref ref-type="fig" rid="F3">Figure 3G-I</xref>).</p><p id="P19">Immersive 3D visualizations are particularly well suited for analyzing <italic>in situ</italic> cryo-electron tomography data to unravel the spatial interactions that underlie cellular organization. In fact, researchers working at the frontier of automatic structure identification have shown great enthusiasm for the possibilities offered by MolecularWebXR. Indeed, some groups have contributed with cellular 3D reconstructions, and we are open to add more material on request. <xref ref-type="fig" rid="F3">Figure 3H</xref> shows a map of <italic>T. kivui</italic> cells. The model depicts the plasma membrane, S-layer, and the unusual filamentous enzyme that drives CO2 fixation.<sup><xref ref-type="bibr" rid="R25">25</xref></sup> <xref ref-type="fig" rid="F3">Figure 3I</xref> shows a 3D landscape around the nuclear envelope of <italic>S. pombe</italic> cells, as seen inside VR. The model was generated from a public dataset (EMPIAR: 10988)<sup><xref ref-type="bibr" rid="R26">26</xref></sup> as described in ref.<sup><xref ref-type="bibr" rid="R27">27</xref></sup> and displays ribosomes, nuclear pore complexes, fatty acid synthases and the nuclear envelope. Other content in the same room includes models of three different viruses and bacteriophages, with their identifying EMDB codes provided in labels (<xref ref-type="fig" rid="F3">Figure 3G</xref>).</p><p id="P20">Along the lines of general chemistry, we also incorporated rooms created specifically for undergraduate students with content about the 3D shapes of atomic orbitals and about VSEPR theory, deployed during activities as explained in a separate paper<sup><xref ref-type="bibr" rid="R31">31</xref></sup> (<xref ref-type="fig" rid="F4">Figure 4A</xref>), and we are planning to soon add a room with a periodic table of the elements for a series of specific activities with high school and early undergraduate students (draft version in <xref ref-type="fig" rid="F4">Figure 4B</xref>). Likewise, besides a standard room for structural biology, we incorporated a room specifically tailored to a MSc/early PhD-level course in integrative structural biology that covers the main techniques used to determine protein structures. In this case we used malate synthase G as a test case, as its structure was separately solved by NMR, X-ray and Cryo-EM.<sup><xref ref-type="bibr" rid="R28">28</xref>–<xref ref-type="bibr" rid="R30">30</xref></sup> By showing these structures and some of the experimental data used to derive them, we illustrate the strengths, limitations and complementarity of the three main atomic resolution techniques (<xref ref-type="fig" rid="F4">Figure 4C and 4D</xref>).</p><p id="P21">Besides accessing the preset content, users can create with our PDB2AR tool<sup><xref ref-type="bibr" rid="R23">23</xref></sup> <italic>ad hoc</italic> content for their presentations starting from either raw PDB files (uploaded locally or fetched from the PDB or the AlphaFold-EBI database) or from VMD-generated wavefront objects. In this case, users must follow the procedures described in our previous work,<sup><xref ref-type="bibr" rid="R23">23</xref></sup> and then copy-paste the link to the GLB file obtained via email. An example application of custom-generated content is shown in <xref ref-type="fig" rid="F2">Figure 2A</xref> for which the users had to prepare virtual representations of the structures they presented as part of a series of scientific talks during a conference.</p><p id="P22">Furthermore, starting from the empty room and by leveraging content created inhouse with PDB2AR and downloaded or purchased from the 3D art platform Sketchfab.com, we have held sessions designed specifically for certain science communication events and school visits where we show not only molecules but also models. For example, <xref ref-type="fig" rid="F2">Figure 2D</xref> is a snapshot from a 15 min long VR session where a presenter tells an engaging story that connects physics with chemistry and biology attempting to demonstrate the continuous nature of science, with all participants inside VR.</p><p id="P23">As described throughout the paper, we have successfully applied MolecularWebXR in various formats at scientific presentations in conferences, science outreach events, and for teaching, including combinations where users wore VR headsets or employed other kinds of devices. Importantly, we have had almost 150 people trying the 15 min long VR presentation from <xref ref-type="fig" rid="F2">Figure 2D</xref> (in groups of 4 to 7 people plus a presenter) and none of the participants had to quit the experience prematurely due to VR sickness or other problems. Furthermore, users who tried the experiences inside VR headsets spanned an age range from 12 to 80 years old, and all of them could seamlessly manipulate objects with their hands, even when they had absolutely no previous experience utilizing VR headsets (&gt;80% of the participants).</p></sec></sec><sec id="S5" sec-type="discussion"><title>Discussion</title><p id="P24">Modern VR and AR headsets allow users to visualize and manipulate 3D models with a level of depth and realism that was unattainable just 5 years ago. Unfortunately, multiple factors hinder widespread access to the technology, leaving out a large proportion of the population as compared to solutions based on regular consumer devices. Our previous big release, MoleculARweb, tackled the need for more immersive visualization and more intuitive object control for chemistry and structural biology education through web-based but only partially WebXR-based activities and playgrounds. With a steady base of 2,500 users per month and almost 110,000 users since its launch, MoleculARweb is widely employed at schools. Now, based on similar core concepts and material but building on WebXR and with the aim of achieving more immersive sessions, we hope the new MolecularWebXR will be welcomed for education, science outreach, and scientific discussions. We note that the device we used most for development, testing and application on users, Meta’s Oculus Quest 2 with 128 GB of memory, costs under USD 300 as of June 2024, which is around that of a mid-range smartphone. In October 2023, the Meta Quest 3 was launched for under USD 600, and other companies have their own WebXR-supporting VR devices with prices starting around similar values. While these costs might still be prohibitive for many individual users, they will hopefully bring an option for VR/AR for many institutions, and will likely come further down in the future.</p><p id="P25">Profiting from the lower costs and building on web standards with cross-device/cross-OS compatibility and ease of deployment as our main values up from the early stages of the project, and by exploiting WebXR’s ability to unify all devices, we envision that MolecularWebXR can bridge the digital divide and produce more equal opportunities. It encourages a more inclusive use of VR and democratizes access to the modern possibilities that the technology offers. For example, a well-funded educational institution, company or research lab can afford multiple VR headsets to do concurrent multiuser collaboration or teaching with several students inside immersive VR; while institutions with less funding can have just one or two users wearing VR headsets to manipulate objects while other users participate from their smartphones, possibly inserted in carboard goggles to feel immersive, or simply on a computer screen or beaming on a widescreen.</p><p id="P26">We cannot emphasize enough how WebXR makes the experience highly inclusive and content so readily available. We take the chance to encourage other developers creating scientific VR/AR applications to move to this platform. All developers of VR and AR headsets, from major players like Apple, Meta and Microsoft to smaller, highly specialized companies, have included web browsers that support the standard, ensuring that developments for the web should work out of the box in all of them.<sup><xref ref-type="bibr" rid="R16">16</xref>–<xref ref-type="bibr" rid="R18">18</xref></sup> From our side, next in the line is the release of a web app for immersive molecular simulations that will enable educational and research activities like those offered by moleculARweb’s virtual modeling kits<sup><xref ref-type="bibr" rid="R20">20</xref></sup> but in multiuser, immersive VR that runs, like all of MolecularWebXR’s content, on VR and non-VR capable devices. A growing universe of tools based on WebXR has the potential to transform the way how chemistry and biology, and science in general, are taught, learned, communicated and discussed, leaving no one behind.</p></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supporting Information</label><media xlink:href="EMS190583-supplement-Supporting_Information.docx" mimetype="application" mime-subtype="vnd.openxmlformats-officedocument.wordprocessingml.document" id="d34aAcCbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S6"><title>Acknowledgements</title><p>This work was initiated with funds from Hasler Stiftung (Bern, Switzerland) and then executed with funds from the Swiss National Science Foundation (CRARP2_209794 and 205321_207487) to LAA. We acknowledge Prof. H. Abriel, Dr. P. Teixidor and Dr. V. Rossetti (University of Bern, Switzerland) for their help deploying VR-based scientific presentations during the closing event of NCCR TransCure. We acknowledge Dr. Ricardo Diogo Righetto (University of Basel, Switzerland) for help preparing the 3D view of <italic>T. kivui</italic> cell. We acknowledge funding from the Novo Nordisk Foundation (NNF22SA0076513) for support for the course on integrative structural biology at the University of Copenhagen, Denmark.</p></ack><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Richardson</surname><given-names>JS</given-names></name><name><surname>Richardson</surname><given-names>DC</given-names></name><name><surname>Goodsell</surname><given-names>DS</given-names></name></person-group><article-title>Seeing the PDB</article-title><source>J Biol Chem</source><year>2021</year><volume>296</volume><pub-id pub-id-type="pmcid">PMC8167287</pub-id><pub-id pub-id-type="pmid">33957126</pub-id><pub-id pub-id-type="doi">10.1016/j.jbc.2021.100742</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goddard</surname><given-names>TD</given-names></name><etal/></person-group><article-title>Molecular visualization on the holodeck</article-title><source>J Mol Biol</source><year>2018</year><volume>430</volume><fpage>3982</fpage><lpage>3996</lpage><pub-id pub-id-type="pmcid">PMC6223615</pub-id><pub-id pub-id-type="pmid">29964044</pub-id><pub-id pub-id-type="doi">10.1016/j.jmb.2018.06.040</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fombona-Pascual</surname><given-names>A</given-names></name><name><surname>Fombona</surname><given-names>J</given-names></name><name><surname>Vázquez-Cano</surname><given-names>E</given-names></name></person-group><article-title>VR in chemistry, a review of scientific research on advanced atomic/molecular visualization</article-title><source>Chem Educ Res Pract</source><year>2022</year><volume>23</volume><fpage>300</fpage><lpage>312</lpage></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martinez</surname><given-names>X</given-names></name><name><surname>Chavent</surname><given-names>M</given-names></name><name><surname>Baaden</surname><given-names>M</given-names></name></person-group><article-title>Visualizing protein structures—tools and trends</article-title><source>Biochem Soc Trans</source><year>2020</year><volume>48</volume><fpage>499</fpage><lpage>506</lpage><pub-id pub-id-type="pmid">32196545</pub-id></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Connor</surname><given-names>M</given-names></name><etal/></person-group><article-title>Sampling molecular conformations and dynamics in a multiuser virtual reality framework</article-title><source>Sci Adv</source><year>2018</year><volume>4</volume><elocation-id>eaat2731</elocation-id><pub-id pub-id-type="pmcid">PMC6025904</pub-id><pub-id pub-id-type="pmid">29963636</pub-id><pub-id pub-id-type="doi">10.1126/sciadv.aat2731</pub-id></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joo</surname><given-names>W-J</given-names></name><name><surname>Brongersma</surname><given-names>ML</given-names></name></person-group><article-title>Creating the ultimate virtual reality display</article-title><source>Science</source><year>2022</year><volume>377</volume><fpage>1376</fpage><lpage>1378</lpage><pub-id pub-id-type="pmid">36137048</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>M</given-names></name><name><surname>Yu</surname><given-names>H</given-names></name><name><surname>Bell</surname><given-names>Z</given-names></name><name><surname>Chu</surname><given-names>X</given-names></name></person-group><article-title>Constructing an Edu-Metaverse ecosystem: A new and innovative framework</article-title><source>IEEE Trans Learn Technol</source><year>2022</year><volume>15</volume><fpage>685</fpage><lpage>696</lpage></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kufák</surname><given-names>D</given-names></name><etal/></person-group><chapter-title>State of the art of molecular visualization in immersive virtual environments</chapter-title><source>Computer Graphics Forum</source><publisher-name>Wiley Online Library</publisher-name><year>2023</year></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walters</surname><given-names>RK</given-names></name><name><surname>Gale</surname><given-names>EM</given-names></name><name><surname>Barnoud</surname><given-names>J</given-names></name><name><surname>Glowacki</surname><given-names>DR</given-names></name><name><surname>Mulholland</surname><given-names>AJ</given-names></name></person-group><article-title>The emerging potential of interactive virtual reality in drug discovery</article-title><source>Expert Opin Drug Discov</source><year>2022</year><volume>17</volume><fpage>685</fpage><lpage>698</lpage><pub-id pub-id-type="pmid">35638298</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sakshuwong</surname><given-names>S</given-names></name><name><surname>Weir</surname><given-names>H</given-names></name><name><surname>Raucci</surname><given-names>U</given-names></name><name><surname>Martínez</surname><given-names>TJ</given-names></name></person-group><article-title>Bringing chemical structures to life with augmented reality, machine learning, and quantum chemistry</article-title><source>J Chem Phys</source><year>2022</year><volume>156</volume><elocation-id>204801</elocation-id><pub-id pub-id-type="pmid">35649841</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Jamieson-Binnie</surname><given-names>AD</given-names></name><etal/></person-group><source>Narupa iMD: A VR-enabled multiplayer framework for streaming interactive molecular simulations</source><conf-name>ACM SIGGRAPH 2020 Immersive Pavilion</conf-name><year>2020</year><fpage>1</fpage><lpage>2</lpage></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Bennie</surname><given-names>SJ</given-names></name><etal/></person-group><source>A Virtual and Mixed Reality Platform for Molecular Design &amp; Drug Discovery-Nanome Version 1.24</source><year>2023</year></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pettersen</surname><given-names>EF</given-names></name><etal/></person-group><article-title>UCSF ChimeraX: Structure visualization for researchers, educators, and developers</article-title><source>Protein Sci</source><year>2021</year><volume>30</volume><fpage>70</fpage><lpage>82</lpage><pub-id pub-id-type="pmcid">PMC7737788</pub-id><pub-id pub-id-type="pmid">32881101</pub-id><pub-id pub-id-type="doi">10.1002/pro.3943</pub-id></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doak</surname><given-names>DG</given-names></name><name><surname>Denyer</surname><given-names>GS</given-names></name><name><surname>Gerrard</surname><given-names>JA</given-names></name><name><surname>Mackay</surname><given-names>JP</given-names></name><name><surname>Allison</surname><given-names>JR</given-names></name></person-group><article-title>Peppy: a virtual reality environment for exploring the principles of polypeptide structure</article-title><source>Protein Sci</source><year>2020</year><volume>29</volume><fpage>157</fpage><lpage>168</lpage><pub-id pub-id-type="pmcid">PMC6933844</pub-id><pub-id pub-id-type="pmid">31622516</pub-id><pub-id pub-id-type="doi">10.1002/pro.3752</pub-id></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abriata</surname><given-names>LA</given-names></name></person-group><article-title>Building blocks for commodity augmented reality-based molecular visualization and modeling in web browsers</article-title><source>PeerJ Comput Sci</source><year>2020</year><volume>6</volume><fpage>e260</fpage><pub-id pub-id-type="pmcid">PMC7924717</pub-id><pub-id pub-id-type="pmid">33816912</pub-id><pub-id pub-id-type="doi">10.7717/peerj-cs.260</pub-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rodríguez</surname><given-names>FC</given-names></name><name><surname>Dal Peraro</surname><given-names>M</given-names></name><name><surname>Abriata</surname><given-names>LA</given-names></name></person-group><article-title>Democratizing interactive, immersive experiences for science education with WebXR</article-title><source>Nat Comput Sci</source><year>2021</year><volume>1</volume><fpage>631</fpage><lpage>632</lpage><pub-id pub-id-type="pmid">38217192</pub-id></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>MacIntyre</surname><given-names>B</given-names></name><name><surname>Smith</surname><given-names>TF</given-names></name></person-group><source>Thoughts on the Future of WebXR and the Immersive Web</source><conf-name>IEEE international symposium on mixed and augmented reality adjunct (ISMAR- Adjunct)</conf-name><conf-sponsor>IEEE</conf-sponsor><year>2018</year><fpage>338</fpage><lpage>342</lpage></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferrão</surname><given-names>J</given-names></name><name><surname>Dias</surname><given-names>P</given-names></name><name><surname>Santos</surname><given-names>BS</given-names></name><name><surname>Oliveira</surname><given-names>M</given-names></name></person-group><article-title>Environment-aware rendering and interaction in web-based augmented reality</article-title><source>J Imaging</source><year>2023</year><volume>9</volume><fpage>63</fpage><pub-id pub-id-type="pmcid">PMC10057055</pub-id><pub-id pub-id-type="pmid">36976114</pub-id><pub-id pub-id-type="doi">10.3390/jimaging9030063</pub-id></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cortés Rodríguez</surname><given-names>F</given-names></name><etal/></person-group><article-title>MoleculARweb: A Web Site for Chemistry and Structural Biology Education through Interactive Augmented Reality out of the Box in Commodity Devices</article-title><source>J Chem Educ</source><year>2021</year></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rodríguez</surname><given-names>FC</given-names></name><name><surname>Krapp</surname><given-names>L</given-names></name><name><surname>Dal Peraro</surname><given-names>M</given-names></name><name><surname>Abriata</surname><given-names>L</given-names></name></person-group><article-title>Visualization, Interactive Handling and Simulation of Molecules in Commodity Augmented Reality in Web Browsers Using moleculARweb’s Virtual Modeling Kits</article-title><source>CHIMIA</source><year>2022</year><volume>76</volume><fpage>145</fpage><pub-id pub-id-type="pmid">38069760</pub-id></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rodríguez</surname><given-names>FC</given-names></name><etal/></person-group><article-title>Updates on moleculARweb, the Swiss Portal for Chemistry and Structural Biology Education Using Augmented and now also Virtual Reality: Chemical Education</article-title><source>Chimia</source><year>2023</year><volume>77</volume><fpage>264</fpage></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Humphrey</surname><given-names>W</given-names></name><name><surname>Dalke</surname><given-names>A</given-names></name><name><surname>Schulten</surname><given-names>K</given-names></name></person-group><article-title>VMD: visual molecular dynamics</article-title><source>J Mol Graph</source><year>1996</year><volume>14</volume><fpage>33</fpage><lpage>38</lpage><comment>27-28</comment><pub-id pub-id-type="pmid">8744570</pub-id></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rodríguez</surname><given-names>FC</given-names></name><name><surname>Dal Peraro</surname><given-names>M</given-names></name><name><surname>Abriata</surname><given-names>LA</given-names></name></person-group><article-title>Online tools to easily build virtual molecular models for display in augmented and virtual reality on the web</article-title><source>J Mol Graph Model</source><year>2022</year><volume>114</volume><elocation-id>108164</elocation-id><pub-id pub-id-type="pmid">35325844</pub-id></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yao</surname><given-names>H</given-names></name><etal/></person-group><article-title>Molecular architecture of the SARS-CoV-2 virus</article-title><source>Cell</source><year>2020</year><volume>183</volume><fpage>730</fpage><lpage>738</lpage><elocation-id>e13</elocation-id><pub-id pub-id-type="pmcid">PMC7474903</pub-id><pub-id pub-id-type="pmid">32979942</pub-id><pub-id pub-id-type="doi">10.1016/j.cell.2020.09.018</pub-id></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dietrich</surname><given-names>HM</given-names></name><etal/></person-group><article-title>Membrane-anchored HDCR nanowires drive hydrogen-powered CO2 fixation</article-title><source>Nature</source><year>2022</year><volume>607</volume><fpage>823</fpage><lpage>830</lpage><pub-id pub-id-type="pmid">35859174</pub-id></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Teresa-Trueba</surname><given-names>I</given-names></name><etal/></person-group><article-title>Convolutional networks for supervised mining of molecular patterns within cellular context</article-title><source>Nat Methods</source><year>2023</year><volume>20</volume><fpage>284</fpage><lpage>294</lpage><pub-id pub-id-type="pmcid">PMC9911354</pub-id><pub-id pub-id-type="pmid">36690741</pub-id><pub-id pub-id-type="doi">10.1038/s41592-022-01746-2</pub-id></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cruz-Leon</surname><given-names>S</given-names></name><etal/></person-group><article-title>High-confidence 3D template matching for cryo-electron tomography</article-title><source>bioRxiv</source><year>2023</year><elocation-id>2023.09.05.556310</elocation-id><pub-id pub-id-type="pmcid">PMC11088655</pub-id><pub-id pub-id-type="pmid">38734767</pub-id><pub-id pub-id-type="doi">10.1038/s41467-024-47839-8</pub-id></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tugarinov</surname><given-names>V</given-names></name><name><surname>Choy</surname><given-names>W-Y</given-names></name><name><surname>Yu Orekhov</surname><given-names>V</given-names></name><name><surname>Kay</surname><given-names>LE</given-names></name></person-group><article-title>Solution NMR-derived global fold of a monomeric 82-kDa enzyme</article-title><source>Proc Natl Acad Sci</source><year>2005</year><volume>102</volume><fpage>622</fpage><lpage>627</lpage><pub-id pub-id-type="pmcid">PMC545550</pub-id><pub-id pub-id-type="pmid">15637152</pub-id><pub-id pub-id-type="doi">10.1073/pnas.0407792102</pub-id></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ho</surname><given-names>M-R</given-names></name><name><surname>Wu</surname><given-names>Y-M</given-names></name><name><surname>Lu</surname><given-names>Y-C</given-names></name><name><surname>Ko</surname><given-names>T-P</given-names></name><name><surname>Wu</surname><given-names>K-P</given-names></name></person-group><article-title>Cryo-EM reveals the structure and dynamics of a 723-residue malate synthase G</article-title><source>J Struct Biol</source><year>2023</year><volume>215</volume><elocation-id>107958</elocation-id><pub-id pub-id-type="pmid">36997036</pub-id></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howard</surname><given-names>BR</given-names></name><name><surname>Endrizzi</surname><given-names>JA</given-names></name><name><surname>Remington</surname><given-names>SJ</given-names></name></person-group><article-title>Crystal Structure of Escherichia coli Malate Synthase G Complexed with Magnesium and Glyoxylate at 2.0 ÅResolution:□ Mechanistic Implications</article-title><source>Biochemistry</source><year>2000</year><volume>39</volume><fpage>3156</fpage><lpage>3168</lpage><pub-id pub-id-type="pmid">10715138</pub-id></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pimpasri</surname><given-names>C</given-names></name><name><surname>Limpanuparb</surname><given-names>T</given-names></name></person-group><article-title>From Plastic Models to Virtual Reality Headsets: Enhancing Molecular Structure Education for Undergraduate Students</article-title><source>CHIMIA</source><year>2024</year><volume>78</volume><fpage>439</fpage><lpage>442</lpage><pub-id pub-id-type="pmid">38946418</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>MolecularWebXR as seen in web browsers on various WebXR-capable devices.</title><p>(A) Welcome page as seen in a laptop. (B) In VR headsets, the 6 degrees of freedom allow users to explore the VR scene simply by walking around and moving their heads and limbs naturally. In addition, users can translate, rotate and scale objects via natural manual operations with their hands or by using the device’s handheld controls. The hands/controls and the heads of participants using VR headsets are broadcast to all other users as simplified avatars. If audio is on, these users can naturally talk to each other and with guests who follow the session from any device can listen to the users in VR. (C) A two-user session seen from the view cast by a user wearing an Oculus Quest 3 (orange hands) while another user (blue avatar) follows closely. (D) A session featuring seven speakers wearing VR headsets as seen from a laptop (looks similar on a tablet). Users can move around the scenes by using the W, A, S and D or the arrow keys if the keyboard (in computers) or a virtual joystick (in smartphones and tablets), and they can direct their looks by using the mouse (computers) or <italic>via</italic> touch gestures (tablets). (E-F) A session with a user in VR mode accessing through a headset (blue avatar) as seen by a user accessing the session with a smartphone. Outside of VR (top) users accessing via smartphones can move around the scene with a virtual joystick and they can gaze <italic>via</italic> touch gestures. In smartphones supporting WebXR (going down through the panel), users can enter WebXR mode and either insert the phone into cardboard goggles to explore the scene via 3 degrees of freedom at the entry point in VR (panel E, without the ability to move around the session but with the option to move their heads to look around naturally) or simply see through the phone for AR (panel F, with six degrees of freedom). For more on how to use MolecularWebXR, see <xref ref-type="supplementary-material" rid="SD1">Figures S1-S3</xref>.</p></caption><graphic xlink:href="EMS190583-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Real vs. virtual presence in MolecularWebXR, and example content.</title><p>(A) Five users attending a VR session where the avatar in blue is describing the structure of a protein complex. Example taken from an application of the website to a subset of talks during a structural biology conference. The safety spaces of the 5 VR headsets were synchronized to optimize match between real and virtual worlds, and audio features were off. Other attendees of the conference could follow the talks by projecting the view of a sixth user accessing through a laptop. (B) A teacher in Rosario, Argentina (blue avatar) teaching his students from inside a room populated with VR content about the symmetry elements of molecules, as seen by a visitor accessing in a VR headset from Lausanne, Switzerland, over 11,000 km away. Students in this case followed the teacher’s presentation through the view of a third user who accessed the session with a laptop and projected its view on a widescreen. (C) Two users inside the same VR session, as seen from the viewpoint of the orange avatar as she/he is aligning a model of the SARS-CoV2 Spike protein bound to an ACE2 receptor to the electron density of a Spike protein protruding from the viral particle reported from cryo-electron tomography and subtomogram averaging deposited as EMDB 30430<sup><xref ref-type="bibr" rid="R24">24</xref></sup>. (D) A session deployed over an open science day at EPFL using MolecularWebXR with seven people in the VR room, on content prepared by combining custom representations of molecules created by PDB2AR with models obtained from Sketchfab.com in free or paid forms (this room is not available on the website as it contains purchased objects). For photograph in C and D colors on the users were removed to mask their identities and we have overlaid circles whose colors match the corresponding avatars as seen in the projected views.</p></caption><graphic xlink:href="EMS190583-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Examples of 3D content running in VR sessions inside MolecularWebXR.</title><p>(A) All the rooms and pre-built content available at MolecularWebXR at launch. Besides the empty room to be populated with objects from PDB2AR, we offer rooms displaying the symmetry elements of molecules from the main point groups, the frontier molecular orbitals most widely studied at university level, examples on isomerism, example structures of materials and crystalline arrangements, example structures of biological macromolecules, and examples of subcellular structures imaged in 3D through cryo-electron tomography. (B) Small cut from a laptop screen around CO<sub>2</sub>’s symmetry elements, from the room on molecular geometry. (C) Screenshot from a smartphone in portrait orientation showing O<sub>2</sub>’s LUMO, from the room on molecular orbitals. (D) Zoom inside VR on the local geometry around Ca<sup>2+</sup> ions in calcite, CaCO<sub>3</sub>, with the viewer’s index finger pointing at a Ca<sup>2+</sup> ion. (E) Models of butane in eclipsed and gauge conformations, from the room on isomerism. (F) Superimposing by hand an atomically detailed model of an alpha helix onto a helix in a cartoon-only representation of a transcription factor bound to DNA. (G) A SARS-CoV-2 particle, a <italic>Salmonella</italic> bacteriophage punching through the two bacterial membranes (orange) with its needle (blue), and a T4 bacteriophage, all retrieved from the indicated the EMDB entries displayed in the labels, as seen in the room about cryo-tomography for biology. (H) Also from the room on cryo-tomography for biology, cut of <italic>Thermoanaerobacter kivui</italic> cell showing the carbon-fixing organelles in yellow, the membrane and some of its invaginations in grey, and the S-layer in purple (Model from ref. <sup><xref ref-type="bibr" rid="R25">25</xref></sup>). (I) Another object in the room on cryo-tomography for biology: 3D landscape around the nuclear envelope for a <italic>S. pombe</italic> cell. The model was obtained from ref. <sup><xref ref-type="bibr" rid="R26">26</xref></sup> as detailed in ref.<sup><xref ref-type="bibr" rid="R27">27</xref></sup> and shows the nuclear envelope (purple) with some nuclear pore complex subunits (grey), 80S ribosomes (green) and fatty acid synthases (magenta).</p></caption><graphic xlink:href="EMS190583-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Some of the VR rooms built specifically for deployment in courses.</title><p>(A) VSEPR theory for undergraduate students, utilized for lessons at Mahidol University as described in ref. <sup><xref ref-type="bibr" rid="R31">31</xref></sup>. (B) A virtual periodic table of the elements, in preparation for future deployment in class. (C) Structure of Malate Synthase G as determined by NMR spectroscopy, cryo-electron microscopy and X-ray diffraction, used in a MSc / PhD level course on integrative structural biology. (D) Four students (red, blue, magenta and cyan avatars) following inside VR the explanations of an instructor (green avatar).</p></caption><graphic xlink:href="EMS190583-f004"/></fig></floats-group></article>