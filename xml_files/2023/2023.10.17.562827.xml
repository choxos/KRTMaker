<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS189855</article-id><article-id pub-id-type="doi">10.1101/2023.10.17.562827</article-id><article-id pub-id-type="archive">PPR743865</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">1</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group><subj-group subj-group-type="europepmc-category"><subject>Covid-19</subject></subj-group></article-categories><title-group><article-title><italic>De novo</italic> generation of antibody CDRH3 with a pre-trained generative large language model</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><name><surname>He</surname><given-names>Haohuai</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>He</surname><given-names>Bing</given-names></name><xref ref-type="aff" rid="A2">2</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Guan</surname><given-names>Lei</given-names></name><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Zhao</surname><given-names>Yu</given-names></name><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Chen</surname><given-names>Guanxing</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Zhu</surname><given-names>Qingge</given-names></name><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Chen</surname><given-names>Calvin Yu-Chian</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A4">4</xref><xref ref-type="aff" rid="A5">5</xref><xref ref-type="aff" rid="A6">6</xref><xref ref-type="aff" rid="A7">7</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><contrib contrib-type="author"><name><surname>Li</surname><given-names>Ting</given-names></name><xref ref-type="aff" rid="A3">3</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><contrib contrib-type="author"><name><surname>Yao</surname><given-names>Jianhua</given-names></name><xref ref-type="aff" rid="A2">2</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib></contrib-group><aff id="A1"><label>1</label>Artificial Intelligence Medical Research Center, School of Intelligent Systems Engineering, Shenzhen Campus of Sun Yat-sen University, Shenzhen, China</aff><aff id="A2"><label>2</label>Tencent AI Lab, Shenzhen, China</aff><aff id="A3"><label>3</label>State Key Laboratory of Holistic Integrative Management of Gastrointestinal Cancers and National Clinical Research Center for Digestive Diseases, Xijing Hospital of Digestive Diseases, Xi’an, China</aff><aff id="A4"><label>4</label>AI for Science (AI4S)-Preferred Program, Peking University Shenzhen Graduate School, Shenzhen, Guangdong 518055, China</aff><aff id="A5"><label>5</label>School of Electronic and Computer Engineering, Peking University Shenzhen Graduate School, Shenzhen, Guangdong 518055, China</aff><aff id="A6"><label>6</label>Department of Medical Research, China Medical University Hospital, Taichung 40447, Taiwan</aff><aff id="A7"><label>7</label>Department of Bioinformatics and Medical Engineering, Asia University, Taichung 41354, Taiwan</aff><author-notes><corresp id="CR1">
<label>*</label>Corresponding Authors: Dr. Bing He, <email>hebinghb@gmail.com</email>, Dr. Calvin Yu-Chian Chen, <email>chenyuchian@mail.sysu.edu.cn</email>, Dr. Ting Li, <email>romaliting18@163.com</email>, Dr. Jianhua Yao, <email>jianhua.yao@gmail.com</email></corresp></author-notes><pub-date pub-type="nihms-submitted"><day>21</day><month>10</month><year>2023</year></pub-date><pub-date pub-type="preprint"><day>18</day><month>10</month><year>2023</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Artificial Intelligence (AI) techniques have made great advances in assisting antibody design. However, antibody design still heavily relies on isolating antigen-specific antibodies from serum, which is a resource-intensive and time-consuming process. To address this issue, we propose a Pre-trained Antibody generative large Language Model (PALM) for the de novo generation of artificial antibodies heavy chain complementarity-determining region 3 (CDRH3) with desired antigen-binding specificity, reducing the reliance on natural antibodies. We also build a high-precision model antigen-antibody binder (A2binder) that pairs antigen epitope sequences with antibody sequences to predict binding specificity and affinity. PALM-generated antibodies exhibit binding ability to SARS-CoV-2 antigens, including the emerging XBB variant, as confirmed through <italic>in-silico</italic> analysis and <italic>in-vitro</italic> assays. The <italic>in-vitro</italic> assays validated that PALM-generated antibodies achieve high binding affinity and potent neutralization capability against both wild-type and XBB spike proteins of SARS-CoV-2. Meanwhile, A2binder demonstrated exceptional predictive performance on binding specificity for various epitopes and variants. Furthermore, by incorporating the attention mechanism into the PALM model, we have improved its interpretability, providing crucial insights into the fundamental principles of antibody design.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">Antibody drugs, also known as monoclonal antibodies, play a vital role in biotherapy<sup><xref ref-type="bibr" rid="R1">1</xref>,<xref ref-type="bibr" rid="R2">2</xref></sup>. By mimicking the actions of the immune system, these drugs selectively target pathogenic agents such as viruses and cancer cells<sup><xref ref-type="bibr" rid="R3">3</xref></sup>. Compared to traditional treatments, antibody drugs offer a more specific and efficacious approach<sup><xref ref-type="bibr" rid="R4">4</xref></sup>. Antibody drugs have demonstrated positive outcomes in the treatment of numerous diseases<sup><xref ref-type="bibr" rid="R5">5</xref></sup>, including COVID-19<sup><xref ref-type="bibr" rid="R6">6</xref></sup>.</p><p id="P3">Developing antibody drugs is a complex process that involves isolating antibodies from animal sources, humanizing them, and optimizing their affinity<sup><xref ref-type="bibr" rid="R7">7</xref>,<xref ref-type="bibr" rid="R8">8</xref></sup>. Moreover, with advancements in technology and research methodologies, several faster and more contemporary approaches have emerged. These include isolating antibodies directly from patients<sup><xref ref-type="bibr" rid="R9">9</xref></sup>, immunizing transgenic mice with human immune systems<sup><xref ref-type="bibr" rid="R10">10</xref></sup>, and utilizing <italic>in-vitro</italic> discovery methods from donor and synthetic libraries<sup><xref ref-type="bibr" rid="R11">11</xref></sup>. The development of computational methods such as Rosetta<sup><xref ref-type="bibr" rid="R12">12</xref></sup>, SnugDock<sup><xref ref-type="bibr" rid="R13">13</xref></sup>, and artificial intelligence (AI) algorithms<sup><xref ref-type="bibr" rid="R14">14</xref></sup> has greatly facilitated the prediction of antibody affinity and the optimization of the antibody design process, making it faster and more efficient. These methods have the potential to significantly accelerate the design of antibody drugs. Despite these advances, the development of antibody drugs still heavily relies on natural antibodies.</p><p id="P4">The sequence data of protein can be regarded as a language, so the large-scale pre-training models in the natural language processing (NLP) field have been used to learn the characterization pattern of the protein. Verkuil et al.<sup><xref ref-type="bibr" rid="R15">15</xref></sup> employed EMS2<sup><xref ref-type="bibr" rid="R16">16</xref></sup>, a large language model trained only on protein sequences, to learn the deep grammar of protein language. Nijkamp et al.<sup><xref ref-type="bibr" rid="R17">17</xref></sup> introduced a suite of protein language models that show state-of-the-art performance in many downstream tasks. Madani et al. proposed ProGen<sup><xref ref-type="bibr" rid="R18">18</xref></sup>, a method for generating protein sequences that are controlled by protein properties. However, the generation of antibodies with high affinity to specific antigen epitopes remains a challenging task due to the high diversity of antibodies and the scarcity of available antigen-antibody pairing data.</p><p id="P5">To address the aforementioned challenges, we propose a Pre-trained Antibody generative large Language Model (PALM) for optimizing and generating the heavy chain complementarity-determining region 3 (CDRH3), which plays a vital role in the specificity and diversity of antibodies<sup><xref ref-type="bibr" rid="R19">19</xref>,<xref ref-type="bibr" rid="R20">20</xref></sup>. To avoid the problem of lacking paired datasets and improve model performance, we pre-train the Roformer<sup><xref ref-type="bibr" rid="R21">21</xref></sup> on a large number of unpaired protein sequences, followed by fine-tuning and evaluating the model on an antigen-antibody affinity dataset. Subsequently, we use the fine-tuned model and antigen-antibody pairing data to generate the CDRH3 of the antibody.</p><p id="P6">To evaluate the affinity of the antibodies generated by PALM for antigens, we utilized a combination of antigen-antibody docking<sup><xref ref-type="bibr" rid="R13">13</xref></sup> and AI-based methods. Previous AI methods have utilized antibody structural information to predict the antigen-antibody binding affinity<sup><xref ref-type="bibr" rid="R22">22</xref>–<xref ref-type="bibr" rid="R24">24</xref></sup>. However, collecting confident protein structures through wet-lab experiments is a time-consuming and labor-intensive process<sup><xref ref-type="bibr" rid="R25">25</xref></sup>. Some other methods utilize antibody sequences, which are relatively cheaper and easier to obtain, to predict affinity for specific antibodies<sup><xref ref-type="bibr" rid="R26">26</xref>,<xref ref-type="bibr" rid="R27">27</xref></sup>. Although such methods employ large-scale pre-trained language models to achieve even more accurate affinity predictions<sup><xref ref-type="bibr" rid="R28">28</xref>,<xref ref-type="bibr" rid="R29">29</xref></sup>, their prediction ability is limited to the trained antigens since they do not consider the antigen information. When dealing with unknown antigens, such as in new mutation affinity tasks like XBB, the lack of antigen information is a significant limitation. To address this issue, we developed the A2binder for evaluating antibody-antigen affinity. A2binder uses a large-scale pre-trained model for sequence feature extraction from both antigens and antibodies, followed by feature fusion and final affinity prediction using MF-CNN. This approach enables A2binder to achieve accurate and generalizable affinity predictions even for unknown antigens.</p><p id="P7">In this study, we introduced two novel methods, PALM and A2Binder, and developed a comprehensive workflow for antibody generation and affinity optimization. With the abundance of antigen-antibody data generated during the COVID-19 pandemic, we evaluated our approach using COVID-19 data. Our results demonstrated the successful generation of antibodies targeting a stable peptide in the HR2 region of COVID-19 and antibodies with higher affinity for the new variant XBB. In conclusion, we have established an artificial intelligence framework for antibody generation and evaluation, which has the potential to significantly accelerate the development of antibody drugs.</p></sec><sec id="S2" sec-type="results"><title>Results</title><sec id="S3"><title>The framework of PALM and A2Binder</title><p id="P8">The workflow and model framework of the pre-trained Antibody generative large Language Model (PALM) and the antigen-antibody binder (A2binder) are shown in <xref ref-type="fig" rid="F1">Figure 1</xref>. The purpose of PALM is to generate the CDRH3 sequence in the antibody. As illustrated in <xref ref-type="fig" rid="F1">Figure 1a</xref>, the CDRH3 region plays the most vital role in determining an antibody’s binding specificity against a particular antigen sequence. As illustrated in <xref ref-type="fig" rid="F1">Figures 1b</xref>, 1c, and 1d, PALM is a transformer-like model <sup><xref ref-type="bibr" rid="R30">30</xref></sup> that uses the ESM2<sup><xref ref-type="bibr" rid="R16">16</xref></sup>-based Antigen model as the encoder and Antibody Roformer as the decoder. The training of PALM and A2binder consists of three steps: first, we pre-train two language models on unpaired antibody heavy and light chain sequences, respectively. Then we construct A2binder and fine-tune it using paired affinity data. Finally, we construct PALM using the pre-trained ESM2<sup><xref ref-type="bibr" rid="R16">16</xref></sup> and Roformer models and train it on paired Antigen-CDRH3 data for designing and evaluating the AI-generated CDRH3. The data statistics used for training can be found in Supplementary Table S1, while the details of the training and model hyperparameter settings can be found in Supplementary Section ‘Training detail’ and Table S2.</p><p id="P9">To pre-train the antibody Roformer, the characterization patterns of both light and heavy chain sequences of antibodies were utilized in developing a feature extraction pre-training model for COVID-19 antibodies. As illustrated in <xref ref-type="fig" rid="F1">Figure 1e</xref>, the model’s architecture was based on the Roformer<sup><xref ref-type="bibr" rid="R21">21</xref></sup> and was trained using the pre-training strategy of learning language representation patterns. The OAS database<sup><xref ref-type="bibr" rid="R31">31</xref>,<xref ref-type="bibr" rid="R32">32</xref></sup> contains over 1 billion unpaired light and heavy chain sequences.</p><p id="P10">Our objective was to uncover generalizable patterns about SARS-CoV-2 antibody sequences, so we screened this repository to extract 81,750,886 heavy chain and 17,754,502 light chain sequences from COVID-19 patient data. While derived from COVID-19 immune repertoires, these sequences likely only show limited SARS-CoV-2 specificity and contain many off-target binders not related to COVID-19. However, analyzing this large-scale sequence corpus from COVID-19 patients enabled our model to learn structural patterns common across diverse antibodies beyond any single antigen specificity. The Mask Amino Acid (MAA) task was then applied to obtain neural network models to characterize patterns of antibody light and heavy chain sequences.</p><p id="P11">We fine-tuned A2binder on the antigen-antibody affinity task to enable it to learn the rules of antigen-antibody binding. The architecture of the A2binder is shown in <xref ref-type="fig" rid="F1">Figure 1f</xref>, it encompasses of pre-trained language models for feature extraction, serving to extract information from light chain, heavy chain, and antigen sequences. Following each language model is a multi-layered CNN architecture named Multi-Fusion CNN (MF-CNN). The light-chain and heavy-chain Roformers from pre-training are used to extract information about light and heavy chains. We also employ a large-scale pre-trained model ESM2<sup><xref ref-type="bibr" rid="R16">16</xref></sup> for extracting features of antigen sequences. The MF-CNN was designed to combine the sequence feature extraction outputs from pre-training models. The output from the concatenation of the features from MF-CNN was utilized to predict the affinity. Further introduction to the model can be found in the ‘Methods’ section.</p><p id="P12">Following previous work<sup><xref ref-type="bibr" rid="R33">33</xref></sup>, we used the pre-trained ESM2 model as our antigen model and the pre-trained heavy Roformer from step one as our decoder to create PALM. As illustrated in <xref ref-type="fig" rid="F1">Figures 1b</xref> and <xref ref-type="fig" rid="F1">1d</xref>, the antigen and antibody models are stacked by multiple antigen and antibody layers, respectively. PALM incorporates encoder and decoder self-attention layers, with their initial weights inherited from the pre-trained ESM2 model and antibody Roformer, respectively. The decoder also includes an Antibody Cross-attention Layer, which is randomly initialized and fine-tuned using paired CDRH3-antigen sequence data for the sequence-to-sequence task. The last antigen layer passes k, v matrices into all Antibody Cross-attention Layers, while the q matrix comes from the Antibody Self-attention Layer. Through the attention mechanism<sup><xref ref-type="bibr" rid="R30">30</xref></sup>, PALM realizes the translation task from antigen to CDRH3.</p></sec><sec id="S4"><title>Pre-training allows the model to learn a better representation of antibodies</title><p id="P13">During the pre-training stage, the model learns potential representation patterns of antibody sequences through exposure to a diverse range of antibody sequences, facilitating effective feature extraction from the input antibody sequences. The prediction accuracy was 92.74% and 94.14% for heavy chain Roformer and light chain Roformer, respectively, indicating excellent pattern characterization capability of the pre-trained model.</p><p id="P14">We further investigated whether the pre-trained model could differentiate the antigenic region, type, and binding affinity targeted by the antibody. Initially, we utilize the CoV-AbDab<sup><xref ref-type="bibr" rid="R34">34</xref></sup> database, which contains variant and epitope information of the antigens. From this database, we filter out antibody data that specifically target a single variant of the novel coronavirus. Subsequently, we input the antibody sequences into both the untrained Roformer and the pre-trained Roformer to obtain the embedding of the antibody sequence. We ran t-SNE to visualize the feature distribution, as shown in <xref ref-type="fig" rid="F2">Figure 2a</xref>. The feature representation of the untrained Roformer was scattered, whereas the pre-trained Roformers exhibited feature clustering according to the same antigen.</p><p id="P15">Then, we evaluated the pre-trained model’s ability to represent epitopes. We selected antibody data from the CoV-AbDab<sup><xref ref-type="bibr" rid="R34">34</xref></sup> database that target a specific epitope. Similarly, we utilized both the untrained and pre-trained models to obtain embeddings and subsequently employed t-SNE for dimensional reduction visualization. <xref ref-type="fig" rid="F2">Figure 2b</xref> depicts the reduced dimensional visualization of the pre-trained model’s epitope embeddings for antibody-bound antigens, demonstrating that the pre-trained model produces aggregated embeddings for each epitope. In contrast, the model without pre-training generated scattered embeddings.</p><p id="P16">Moreover, we aimed to assess the model’s proficiency in characterizing binding abilities. Thus, we utilized antibodies from the BioMap <sup><xref ref-type="bibr" rid="R35">35</xref></sup> dataset, which includes binding free energy (Delta G) as the antigen-antibody affinity data, to visualize the dimensionality reduction of embeddings. All samples in the BioMap dataset are derived from the Biomap company. <xref ref-type="fig" rid="F2">Figure 2c</xref> presents the embedding results of the model before and after pre-training. The pre-trained model effectively aggregated high and low-affinity embeddings.</p><p id="P17">Collectively, these three comparison results demonstrate that pre-training enhances the model’s ability to extract critical information, such as the antibody’s binding antigen type, region, and affinity.</p></sec><sec id="S5"><title>A2binder can accurately predict the antigen-antibody binding probability</title><p id="P18">The performance of A2binder was evaluated by comparing its ability to predict affinity to that of several baseline methods including ESM-F, Ens-Grad, and Vanilla BERT on multiple affinity datasets. Section “Baseline” provides detailed information about the baseline methods.</p><p id="P19">Initially, the CoV-AbDab dataset was used <sup><xref ref-type="bibr" rid="R34">34</xref></sup>, resulting in 27,324 antigen-antibody pair data for 22 SARS-CoV-2 variants as antigens. Since this dataset does not contain specific affinity values, we used neutralization or non-neutralization as a label to evaluate the performance of the A2binder in a binary classification task. The details of data processing procedures are expounded upon in the dataset subsection of the Methods section.</p><p id="P20"><xref ref-type="fig" rid="F3">Figures 3a</xref>, <xref ref-type="fig" rid="F3">3b</xref>, and Supplementary Table S3 illustrate the performance of A2binder and the baseline methods on the CoV-AbDab dataset. A2binder outperformed all the baseline models in terms of the area under the receiver operating characteristic (ROC-AUC) and the precision-recall area under the curve (PR-AUC). A2binder achieved a ROC of 0.930 which was a 2% performance improvement. It is observed that the BERT model without pre-training performed the worst, which highlights the importance of pre-training in obtaining the characterization of antibody and antigen sequences for model performance. We also compared the model performance under different epitopes and variants, and the results are shown in <xref ref-type="fig" rid="F3">Figures 3c</xref> and <xref ref-type="fig" rid="F3">3d</xref>. The model can achieve good performance under different epitopes and variants.</p></sec><sec id="S6"><title>A2binder can accurately predict antigen-antibody affinity</title><p id="P21">The task of predicting binding affinity values through regression is more challenging than the binary task of predicting neutralization or non-neutralization. To assess the model’s performance in predicting affinity values, we also utilized two datasets, 14H and 14L <sup><xref ref-type="bibr" rid="R36">36</xref></sup>, that contain labels for affinity values. Both datasets contain a measure of the affinity of the antibody to a stable peptide in the HR2 region of SARS-CoV-2 <sup><xref ref-type="bibr" rid="R37">37</xref></sup>. The heavy chains of the 14H dataset vary, while the light chain is constant, whereas the 14L dataset is the opposite. Therefore, for the 14H dataset, we used the pre-trained heavy chain Roformer to extract features from the CDRH1, 2, and 3 regions, while the 14L dataset used the pre-trained light chain Roformer. The details of the specific data processing process are in the dataset subsection of the Methods section. <xref ref-type="fig" rid="F4">Figures 4a</xref>, <xref ref-type="fig" rid="F4">4b</xref>, and Supplementary Table S4 illustrate the performance comparison of models on 14H and 14L. A2binder outperformed all baseline models in Spearman’s rank correlation coefficient metrics. A2binder achieved a Spearman of 0.553 on the 14H dataset (7% improvement), and 0.688 (1% improvement) on the 14L dataset. The pre-trained model ESM-F outperformed other baseline methods in all metrics, further verifying the significance of pre-training. Additionally, the sequence pre-training of SARS-CoV-2 antigens may assist the model in learning the characterization of SARS-CoV-2-related antibody sequences more effectively.</p><p id="P22">To verify the model’s ability to predict antibody affinities for antigens other than SARS-CoV-2, the BioMap dataset was used to evaluate the model’s prediction performance.</p><p id="P23"><xref ref-type="fig" rid="F4">Figure 4c</xref> illustrates the performance comparison of the proposed model on the BioMap dataset. A2binder achieves a 6% performance improvement in reaching a Spearman of 0.746. Consistent with previous results, A2binder outperforms the baseline methods on all metrics. This further supports the model’s ability to accurately predict antigen-antibody affinity, regardless of whether the antigen is related to SARS-CoV-2 or not. This may be attributed to the use of MF-CNN architecture in A2binder, which enables the extraction of global feature output from a large-scale pre-trained model. And it is noteworthy that our model was pre-trained on a dataset that included a substantial amount of data related to COVID-19 antibodies, forming a strong foundation for predicting binding affinities for this specific antigen. However, the 14H and 14L datasets, characterized by limit ed variability in antibody sequences, present a more challenging prediction task. This may be the reason why the performance of the model in Biomap is higher than that of 14H and 14L.</p></sec><sec id="S7"><title>PALM can generate antibodies that are dissimilar to natural ones in sequence yet exhibit a high binding probability</title><p id="P24">To investigate the diversity of antibodies generated by the PALM, we selected the CDRH3 sequences of natural antibodies targeting the wild-type SARS-CoV-2 RBD region from the CoV-AbDab. Subsequently, we employed PALM to generate CDRH3 sequences targeting the same epitope. And we created a sequence logo plot for both artificial and natural antibodies. <xref ref-type="fig" rid="F5">Figure 5a</xref> illustrates that the first three amino acids of the generated antibodies are similar to the natural antibodies since ‘ARD’ has the highest probability. The artificial antibodies exhibit greater diversity in their tail sequences, with the most probable tail being ‘DY’. Additionally, the middle regions of the generated antibodies display considerable diversity.</p><p id="P25">To investigate whether dissimilar sequences result in reduced binding probability, we computed the edit distance between generated antibody sequences and natural antibodies. We divided the dataset based on edit distance and employed the A2binder to predict the binding probability, as shown in <xref ref-type="fig" rid="F5">Figure 5b</xref>. For comparison, we also generated sequences with random mutations and randomly generated sequences in line with the edit distance.</p><p id="P26">The results indicated that the generated antibodies exhibited a higher binding probability and did not exhibit a declining trend in probability as the edit distance increased. In contrast, the random mutation results showed a decrease in affinity probability as the edit distance increased.</p><p id="P27">Furthermore, we obtained the BitScore of the artificial antibody by Blast. A larger BitScore value indicates a higher similarity with the natural antibody. As shown in <xref ref-type="fig" rid="F5">Figure 5c</xref>, the artificial antibodies did not exhibit a decrease in binding probability due to low similarity, which is consistent with the previous analysis.</p><p id="P28">To investigate the influence of structure on binding probability, we utilized AlphaFold2 (AF2) <sup><xref ref-type="bibr" rid="R38">38</xref></sup> to generate the structure of the artificial antibody and computed the Rmsd between the artificial and natural antibodies.</p><p id="P29">As depicted ed in <xref ref-type="fig" rid="F5">Figure 5d</xref>, an increase in Rmsd results in a decrease in the average probability of antibody binding. This may suggest that a decrease in structural similarity could lead to a reduction in the likelihood of antigen-antibody binding. However, even in the interval with the highest RMSD, the binding probability remains higher than 0.5. In conclusion, the PALM is capable of generating a diverse set of antibody sequences with low sequence similarity, yet still exhibiting high binding probabilities.</p></sec><sec id="S8"><title>PALM can generate antibodies that bind to the desired epitopes on the antigens</title><p id="P30">To determine if the sequences generated by the PALM can target the correct site, we generated antibodies against various domains. As illustrated in <xref ref-type="fig" rid="F6">Figure 6a</xref>, the antibodies generated by the PALM can be similar to the natural antibodies that target the same domain.</p><p id="P31">We utilized PALM to generate antibodies against the specified antigens in the 14H dataset and then used A2binder for evaluation. It is worth noting that A2binder is a fast screening method that helps us quickly screen for potential high-affinity antibodies. To further validate the effectiveness, we conducted subsequent validation. The results indicated that the affinity prediction values of some of the generated sequences were higher than those of the natural sequences. One CDRH3 region generated by PALM was XXXXXXXXXX<sup><xref ref-type="fn" rid="FN1">1</xref></sup>, of which the predicted binding free energy is 1.70, smaller than the other generated CDRH3 and the natural CDRH3, XXXXXXXXXX.</p><p id="P32">To further validate the performance of the PALM, we selected the highest-affinity antibodies from the A2binder’s predictions and conducted structural simulation using AlphaFold2 <sup><xref ref-type="bibr" rid="R38">38</xref></sup>. We retrieved the crystal structure of the HR2 region of the SARS-CoV-2 virus from the PDB database <sup><xref ref-type="bibr" rid="R39">39</xref></sup> and used the ClusPro <sup><xref ref-type="bibr" rid="R40">40</xref>,<xref ref-type="bibr" rid="R41">41</xref></sup> to perform antigen-antibody docking. For comparison, we also performed the same docking process on the natural antibodies. To investigate the ability of the A2binder, we employed SnugDock <sup><xref ref-type="bibr" rid="R13">13</xref></sup> to adjust the pose of the antigen-antibody complex. It is worth noting that the validation of docking may not be entirely accurate, but it is a widely used computational method for antibody assessment. Docking has aided in the development of numerous antibody design approaches. We employ docking as an external validation tool to further discern the affinity of antibodies selected through A2binder screening.</p><p id="P33">As shown in <xref ref-type="fig" rid="F6">Figure 6b</xref>, the A2binder predicted that the optimal generated sequence, XXXXXXXXXX<sup><xref ref-type="fn" rid="FN1">1</xref></sup>, had the lowest binding surface energy and Interface Root Mean Square Deviations (Irmsd), while the natural sequences XXXXXXXXXX and XXXXXXXXXX had higher energies which mean fewer stable bonds. Another artificial sequence, XXXXXXXXXX<sup><xref ref-type="fn" rid="FN1">1</xref></sup>, which was predicted to have higher affinity than the natural sequence, exhibits lower binding surface energy than the natural sequence by SnugDock. This result validates the predictive ability of A2binder for binding energies.</p><p id="P34"><xref ref-type="fig" rid="F6">Figure 6c-d</xref> illustrates the results of the docking results between the generated and natural antibodies and the crystal structure of the HR2 region of SARS-CoV-2 (PDB ID: 7ZR2 <sup><xref ref-type="bibr" rid="R42">42</xref></sup>). The generated antibody was observed to form hydrogen bonds between the CDRH3 region and the stable peptide in the HR2 region at 101R and 3D sites. In contrast, the natural antibody was found to form hydrogen bonds with the HR1 region instead of the stable peptide in the HR2 region. This demonstrates that PALM is capable of generating antibodies that bind to the correct sites on the SARS-CoV-2 virus. And this capability of targeting the stable regions of the antigen is essential in the design of antibodies against rapidly evolving viruses such as SARS-CoV-2.</p></sec><sec id="S9"><title>Comparison of PALM with previous methods in antibody design</title><p id="P35">We used PALM to generate 1000 antibody CDRH3 sequences for the HR2 region of the SARS-CoV-2 virus, which were found to have Levenshtein distances from 4 to 10 from natural antibodies, as shown in <xref ref-type="fig" rid="F7">Figure 7a</xref>. To compare the efficiency of PALM with traditional antibody design methods, we utilized two widely used antibody optimization tools, Rosetta<sup><xref ref-type="bibr" rid="R12">12</xref></sup> and Absolute!<sup><xref ref-type="bibr" rid="R43">43</xref></sup>, to design antibodies for the given epitope of HR2. More specifically, we used the Rosetta SnugDock program for antibody-antigen docking. SnugDock expansions on the standard RosettaDock approach to predict antibody-antigen complexes by optimizing antibody-degrees of freedom relative to binding. The general idea of using Rosetta<sup><xref ref-type="bibr" rid="R12">12</xref></sup> and Absolute!<sup><xref ref-type="bibr" rid="R43">43</xref></sup> in antibody design is to replace amino acids of natural antibodies and subsequently assess the efficacy of the modified antibody using these tools. Exploring all possible combinations of amino acid changes is impossible due to the computational resources required by these tools. Thus, a popular strategy is to change the amino acid sequentially<sup><xref ref-type="bibr" rid="R23">23</xref></sup>. This involves changing the amino acid at one position during each design round and assessing the impact on affinity. The altered antibody with the highest affinity is then utilized as the foundation for introducing a new amino acid modification in the next round. <xref ref-type="fig" rid="F7">Figure 7b</xref> presents the CPU hours required for the three methods to generate antibodies at different distances from natural ones. PALM exhibits great advances in saving the computational resources of antibody design. Notably, due to the direct generation of results with different edit distances, PALM’s computational consumption is not affected by an increase in distance. Our results demonstrate that PALM outperforms previous methods in terms of efficiency, which has significant implications for the rapid design of antibody drugs. Such a strategy saves computational resources but has limitations, such as the potential to become trapped in local optima, which hinders exploration of the global fitness landscape of the sequence space. As a result, the traditional strategy may lead to suboptimal or ineffective antibody designs. To investigate whether antibodies designed by PALM exhibit a higher affinity than the traditional strategy, we employed EvoEF2<sup><xref ref-type="bibr" rid="R44">44</xref></sup> to design antibodies using the traditional strategy and compared their affinity to those designed by PALM. To enable a fair comparison, we selected the antibody generated by PALM which was deemed optimal by A2binder and had an edit distance of 7. Therefore, we utilized EvoEF2 to perform seven rounds of single-point mutation on natural antibodies and selected the generated antibody with the highest affinity. <xref ref-type="fig" rid="F7">Figure 7c</xref> displays the comparison of the interface energy of antibodies obtained from SnugDock<sup><xref ref-type="bibr" rid="R13">13</xref></sup> with the highest affinity generated by PALM and EvoEF2, indicating that the binding surface energy of antibodies generated by PALM is significantly lower than that of EvoEF2. This comparison further emphasizes the advantages of PALM in antibody design.</p></sec><sec id="S10"><title>PALM can generate antibodies that exhibit high binding affinity to novel variants of SARS-CoV-2</title><p id="P36">To investigate whether the antibodies generated by the PALM exhibit stronger binding abilities against new variants of SARS-CoV-2, we attempted to design high-affinity antibodies targeting these variants using PALM. The CoV-AbDab dataset contains over 20 variants of SARS-CoV-2, but it does not include the new variant XBB, which is rapidly spreading worldwide and rapidly increasing in proportion among all infected cases. Therefore, we aimed to use the PALM to generate specific antibodies against XBB. After training in all positive samples in the CoV-AbDab dataset, we selected the antibodies with the highest predicted binding affinity from the CoV-AbDab dataset and formed a set of similar antibodies for further specific training. We obtained the sequence of the XBB variant from the NCBI database <sup><xref ref-type="bibr" rid="R45">45</xref></sup> and inputted the RDB sequence of XBB into the AF2 <sup><xref ref-type="bibr" rid="R38">38</xref></sup>. We replaced the CDRH3 region of the natural antibody targeting to XBB with the generated results and used ClusPro <sup><xref ref-type="bibr" rid="R40">40</xref>,<xref ref-type="bibr" rid="R41">41</xref></sup>, SnugDock <sup><xref ref-type="bibr" rid="R13">13</xref></sup>, and A2binder to evaluate the binding affinity against XBB. One CDRH3 region generated by the PALM was XXXXXXXXXX<sup><xref ref-type="fn" rid="FN1">1</xref></sup>, and A2binder predicted a degree of neutralization of 3.01, which was higher than the other generated CDRH3 and the natural antibody.</p><p id="P37">After that, we employed tools such as AF2<sup><xref ref-type="bibr" rid="R38">38</xref></sup> and ClusPro<sup><xref ref-type="bibr" rid="R40">40</xref>,<xref ref-type="bibr" rid="R41">41</xref></sup> to conduct structural validation. To further validate the binding abilities of the generated antibodies, we input the docking results of the generated antibodies and natural antibodies from ClusPro<sup><xref ref-type="bibr" rid="R40">40</xref>,<xref ref-type="bibr" rid="R41">41</xref></sup> into SnugDock <sup><xref ref-type="bibr" rid="R13">13</xref></sup>, a paratope structural optimization algorithm based on RosettaDock <sup><xref ref-type="bibr" rid="R46">46</xref></sup>, for structure optimization.</p><p id="P38">We analyzed the 1000 optimized results of generated and natural antibodies on the Rosetta server and found that the Interface Energy of generated results is significantly lower than that of the natural antibodies (<xref ref-type="fig" rid="F8">Figure 8a</xref>), and the Interface Root Mean Square Deviation (Irmsd) is also generally lower for the generated antibodies (<xref ref-type="fig" rid="F8">Figure 8b</xref>). We assume that the distribution of the artificial results is smaller than the natural results, and the p-value in the independent t-test is 5.9e-48. These findings indicate that the generated antibodies have improved binding capabilities to the antigen. The results suggest that PALM has the potential to generate higher affinity antibody sequences against new variants of SARS-CoV-2.</p><p id="P39"><xref ref-type="fig" rid="F8">Figures 8c</xref> and <xref ref-type="fig" rid="F8">8d</xref> illustrate the docking results and Rosetta optimization results of the generated antibodies and natural antibodies. We can observe that the binding region of the generated antibodies to XBB is more concentrated, primarily binding to the light chain residues A25, Q27, S28, Y32, and Y92. In contrast, the binding sites of the natural antibodies are dispersed and include light chain residues Y32, Y92, and N93.</p></sec><sec id="S11"><title>PALM is highly interpretable</title><p id="P40">In addition to its ability to generate high-affinity antibodies against new variants of SARS-CoV-2, we also investigated the interpretability of our model. By utilizing the attention mechanism, PALM may have the potential to focus on key sites during the learning process. We inputted the artificial antibody and the HR2 sequence of SARS-CoV-2 mentioned in section “PALM can generate antibodies that bind to the desired epitopes on the antigens” into PALM. We then computed the average of the multi-layer attention weights of the model.</p><p id="P41"><xref ref-type="fig" rid="F9">Figure 9a</xref> illustrates the attention weights output by PALM, with red indicating high attention weights and blue indicating low attention weights. The intensity of the color represents the strength of attention. Our analysis revealed that the attention weights of the correct docking sites in PALM’s output were generally high, with the highest attention values observed at the R residues in the CDRH3 region, which forms hydrogen bonds with D residues in the HR2 peptide segment. This suggests that PALM can correctly capture key contact sites, providing insight for further research and optimization of antigen-antibody binding.</p><p id="P42">Moreover, we analyzed the ability of the model to generate high-affinity antibodies against the new variant XBB. <xref ref-type="fig" rid="F9">Figure 9b</xref> illustrates the attention weights generated by PALM. We observed that the model exhibited a higher attention weight on the region 167-177 of the antigen, specifically corresponding to the binding pocket of XBB and the antibody. <xref ref-type="fig" rid="F9">Figure 9c</xref> shows a zoomed-in view of this region, which indicates that the attention weights are generally higher than the average. Additionally, the key positions for hydrogen bond formation between the antigen and the antibody, S168-C170, and Q175-S176, were found to have high attention values. Among these key positions, only C170 had an attention weight lower than the average, while all other key positions had attention weights higher than the average. We observed that the region 167-177 of the antigen contains XBB-specific mutation sites: S168, N169, and Q175. A previous study has shown that S168 may confer resistance to RBD class 1 and 2 mAbs, while N169 contributes to resistance against RBD class 3 mAbs<sup><xref ref-type="bibr" rid="R47">47</xref></sup>. Additionally, previous studies have indicated that the Q175 mutation in XBB restores its receptor affinity, thereby restoring its fitness<sup><xref ref-type="bibr" rid="R48">48</xref>,<xref ref-type="bibr" rid="R49">49</xref></sup>. These findings further suggest that the model may be able to correctly identify and capture key positions of antigen-antibody interaction, pointing the direction for further investigation of the XBB variant.</p><p id="P43">To further validate the model’s interpretability, we performed statistical tests on PDB structures from the BioMap<sup><xref ref-type="bibr" rid="R35">35</xref></sup> dataset. Specifically, we used Pymol <sup><xref ref-type="bibr" rid="R50">50</xref></sup> to identify potential hydrogen bond locations between chains, then compared to the mean attention weights from PALM between those chains. This allowed assessing whether the model attends to structurally interacting residue positions. We divided attention weights into two groups - those at hydrogen bond sites versus elsewhere. An independent t-test revealed significantly higher attention at hydrogen bond locations compared to other sites (p&lt;0.01). This provides further evidence that the model captures key interacting positions between antigens and antibodies.</p></sec><sec id="S12"><title>
<italic>In</italic>-<italic>vitro</italic> assays of artificial and natural antibodies</title><p id="P44">To further validate the effectiveness of antibodies generated by PALM against the wild-type spike protein of SARS-CoV-2, we selected the top-ranked Artificial 1 antibody along with Artificial 2 antibody based on their predicted binding probabilities by A2binder and two natural antibodies, Natural 1 and 2 (<xref ref-type="fig" rid="F6">Figure 6b</xref>). We then evaluated their binding ability using <italic>in-vitro</italic> assays. The Western blot analysis demonstrated that Artificial 1 and 2 were capable of binding to the spike protein at levels similar to or even surpassing, those of natural antibodies (<xref ref-type="fig" rid="F10">Figure 10a</xref>). To further determine their binding affinity and neutralization capability, we conducted surface plasmon resonance analysis and pseudovirus neutralization. Artificial 1 demonstrated high binding affinity with an equilibrium dissociation constant (KD) of 0.05 nm, and superior neutralization potency with a half maximal inhibitory concentration (IC50) of 0.023 μg/ml, compared to all the tested natural antibodies (<xref ref-type="fig" rid="F10">Figure 10c</xref>). The above assays demonstrated that PALM could generate antibodies surpassing natural antibodies for antigens known in training.</p><p id="P45">We next evaluated PALM’s ability to generate artificial antibodies against the novel Omicron variant XBB, which represents a more challenging test case as the model did not see this antigen during training. Like the <italic>in-silico</italic> evaluation shown in <xref ref-type="fig" rid="F8">Figure 8a</xref>, we selected the top-ranked artificial antibody Artificial 1 predicted by A2binder against XBB, along with the natural XBB antibody for the <italic>in-vitro</italic> assays. Besides that, to evaluate the A2binder model using <italic>in-vitro</italic> assays, we also randomly selected three other artificial antibodies, Artificial 2, 3, and 4, which had moderate and lower predicted binding probabilities. Western blot analysis validated the binding of these antibodies to the XBB spike protein (<xref ref-type="fig" rid="F10">Figure 10b</xref>). To further quantify their functional activity, surface plasmon resonance analysis and pseudovirus neutralization assays were performed. As shown in <xref ref-type="fig" rid="F10">Figure 10c</xref>, Artificial 1 demonstrated higher binding affinity, with a KD of 0.13 nm, compared to the natural antibody, and superior neutralization potency against XBB, with an IC50 of 0.00301 μg/ml. The improved performance of Artificial 1 despite no prior exposure to XBB proved PALM’s capacity to generate highly potent antibodies even against novel antigen variants. Consistent with the lower bind probabilities predicted by A2Binder, Artificial 2-4 showed much lower affinities and neutralization than Artificial 1 and natural XBB antibodies. This demonstrated A2binder’s capability to effectively guide the antibody selection for further wet-lab investigations.</p></sec></sec><sec id="S13" sec-type="discussion"><title>Discussion</title><p id="P46">In this study, we introduce PALM, a method for generating high-affinity antibody CDRH3 sequences targeting a specific antigen, and A2binder, a method that pairs antigen epitope sequences with antibody sequences to predict the binding specificity and affinity between them. We combined PALM with A2binder to select antibodies with even higher affinity. The efficacy of the A2binder was evaluated by comparing its performance to that of baseline models on various affinity datasets. The results revealed that A2binder exhibited superior antigen-antibody affinity prediction ability, outperforming baseline models on all datasets.</p><p id="P47">A2binder demonstrates superior performance on affinity datasets, partly attributed to the pre-training of antibody sequences, which enabled the A2binder to learn the unique patterns present in these sequences. The results show that A2binder outperforms the baseline model ESM-F, which has the same framework but the pre-trained model is replaced with ESM2, on all antigen-antibody affinity prediction datasets, suggesting that pre-training with antibody sequences can be beneficial for related downstream tasks.</p><p id="P48">However, we observed a slight decrease in performance for A2binder and other baseline models on the 14H and 14L datasets compared to other datasets. This observation is consistent with previous studies <sup><xref ref-type="bibr" rid="R28">28</xref></sup>. It may be due to a lack of predictive power for large affinity variants arising from only a small number of mutations in the LL-SARS-CoV-2 database, which only contains 1-3 amino acid mutations in antibody sequences.</p><p id="P49">We explored the differences between the antibodies generated by PALM and natural antibodies. We found that there were significant differences in their sequences, but the binding probability of the generated antibodies was not significantly affected by these differences. Meanwhile, differences in their structures did result in a decrease in binding affinity. These results are consistent with previous studies about network analysis of the antibody repertoires<sup><xref ref-type="bibr" rid="R51">51</xref></sup>, and functional protein sequences generation<sup><xref ref-type="bibr" rid="R18">18</xref></sup>. And the potential causes of these phenomena may be due to the binding affinity of an antibody being determined by its ability to recognize and bind to a specific antigen. The structure of its binding site plays a critical role<sup><xref ref-type="bibr" rid="R52">52</xref></sup>. Small changes in the structure can affect its ability to bind with a high affinity<sup><xref ref-type="bibr" rid="R53">53</xref>–<xref ref-type="bibr" rid="R55">55</xref></sup>. PALM captures important features and patterns contributing to binding affinity through its training on a large dataset of natural antibodies. It can generate antibodies with different sequences while retaining key features necessary for high binding probability. Overall, our results demonstrate that PALM is capable of generating a diverse range of antibody sequences with high binding affinities, despite their dissimilarity to natural antibodies.</p><p id="P50">Moreover, we validated the performance of PALM by ClusPro<sup><xref ref-type="bibr" rid="R40">40</xref>,<xref ref-type="bibr" rid="R41">41</xref></sup> and SnugDock<sup><xref ref-type="bibr" rid="R13">13</xref></sup>, which are widely accepted antibody validation tools<sup><xref ref-type="bibr" rid="R56">56</xref>–<xref ref-type="bibr" rid="R59">59</xref></sup>. PALM was able to generate antibody CDRH3 sequences targeting the stable peptide in the HR2 region of SARS-CoV-2. It generated novel CDRH3 sequences, and the generated sequence XXXXXXXXXX<sup><xref ref-type="fn" rid="FN1">1</xref></sup> was validated to demonstrate improved targeting of the stable peptide of the antigen compared to the natural CDHR3 sequence XXXXXXXXXX. Generating antibodies that can accurately target specific antigen sites is crucial in developing effective disease treatment plans <sup><xref ref-type="bibr" rid="R60">60</xref></sup>. Rapid and precise antibody generation could lead to the development of new and more effective therapies for various diseases <sup><xref ref-type="bibr" rid="R61">61</xref></sup>. Furthermore, PALM was able to generate antibody CDRH3 sequences with higher affinity against the newly emerged variant XBB of SARS-CoV-2. The generated sequence XXXXXXXXXX<sup><xref ref-type="fn" rid="FN1">1</xref></sup> displayed a stronger affinity to XBB than natural CDHR3 sequence XXXXXXXXXX. PALM’s output encompasses multiple amino acid variations in CDRH3, surpassing the capabilities of previous antibody optimization models that only allowed for single-point mutations.</p><p id="P51">In addition, we conducted the <italic>in-vitro</italic> assays, including Western blot, surface plasmon resonance analysis, and pseudovirus neutralization assays, providing critical validation of the efficacy of PALM-designed antibodies. Both the antibodies targeting the spike protein of SARS-CoV-2 wild-type and XBB variant generated by PALM achieved superior binding affinity and neutralization potency compared to natural antibodies in these assays. The strong empirical results from these wet-lab experiments complement the computational predictions and analyses, providing validation of PALM’s and A2binder’s capabilities in generating and selecting robust antibodies with high specificity and affinity against both known and novel antigens.</p><p id="P52">Our validations on antibodies against the new SARS-CoV-2 variant XBB demonstrate the potential of using a pre-trained model to rapidly generate high-affinity antibodies against a new variant of the virus. This result is significant as it provides a promising approach to developing effective treatments for emerging and evolving viruses. Additionally, this approach could potentially be applied to other infectious diseases, allowing for more efficient and targeted development of treatments.</p><p id="P53">Unlike the previous antibody optimization methods, we used the pre-training model to learn the construction mode of antibody sequence and then employed the transformer-like model architecture to directly generate the sequence from antigen to antibody key region, which may accelerate the process of antibody design.</p><p id="P54">At the same time, we used a multi-scale feature fusion neural network to extract global features of the pre-training model. It improves the ability of the A2binder to predict the affinity and assists PALM in finding antibodies with higher affinity.</p><p id="P55">Significant limitations remain within our methods and more broadly within the study of antibody design. The first is the few minimally curated antigen-antibody pair datasets that exist currently. Due to the lack of antigen-antibody pairing data, we did not directly pre-train the encoder-decoder model, instead opting to train the models for antigen and antibody separately. Also, this led us to generate only CDRH3. Furthermore, our work as a general framework still lacks design for universal antibodies, but rather experiments and validation for SARS-CoV-2 antigens with abundant antigen-antibody pairs. Besides, the validation of antibodies using computational methods such as A2Binder and SnugDock docking methods still has limitations. Docking methods can exhibit instability when calculating binding energies. Additionally, while the high-affinity CDRH3 sequences generated by PALM are promising, certain motifs like the RR dipeptide and Trp residue in XXXXXXXXXX<sup><xref ref-type="fn" rid="FN1">1</xref></sup> may increase the risks of polyreactivity and rapid clearance <sup><xref ref-type="bibr" rid="R62">62</xref>–<xref ref-type="bibr" rid="R64">64</xref></sup>. Such developability liabilities could make these sequences less suitable as clinical candidates despite high predicted affinity. Future work should explore approaches to balance affinity with minimized developability risks, such as filtering certain motifs or optimizing to remove liabilities like the RR and Trp while maintaining potency. Advanced models could also be trained to directly predict developability profiles. There is a substantial need to better integrate proper antibody draggability into computational design. In the coming future, we aim to procure more comprehensive antigen-antibody data from richer sources to enable the creation of universal antibody bi-chains. Furthermore, we aim to explore the possibility of further engineering on this molecule, aiming to preserve its affinity while mitigating any associated drawbacks. Nonetheless, our study serves as evidence that generative models hold great potential in producing high-affinity antibodies.</p><p id="P56">In conclusion, the proposed PALM integrates the capability of large-scale antibody pre-training and the effectiveness of global feature fusion, resulting in superior affinity prediction performance and the ability to design a high-affinity antibody. Furthermore, the direct sequence generation and the interpretable weight visualization make it an efficient and insightful tool for designing high-affinity antibodies.</p></sec><sec id="S14" sec-type="methods"><title>Methods</title><sec id="S15"><title>Datasets</title><p id="P57">Observed Antibody Space (OAS): The OAS database <sup><xref ref-type="bibr" rid="R31">31</xref>,<xref ref-type="bibr" rid="R32">32</xref></sup> compiles and annotates an extensive collection of immune repertoires, encompassing over one billion sequence data from more than 80 studies. These data encompass a broad spectrum of immune states and subjects. A significant discrepancy exists between the volume of unpaired sequence data and paired data within this dataset. We isolated sequences from the unpaired data set that corresponded to the human species and obtained from individuals diagnosed with SARS-CoV-2 at the time of sequencing. This resulted in a selection of 81,750,886 unpaired heavy chains and 17,754,502 unpaired light chains.</p><p id="P58">The Coronavirus Antibody Database (Cov-AbDab): Cov-AbDab<sup><xref ref-type="bibr" rid="R34">34</xref></sup> is a public database that catalogs all published and patented antibodies and nanobodies with the capability to bind to coronaviruses, including SARS-CoV-2, SARS-CoV-1, and MERS-CoV. It comprises 11,868 studies, each of which encompasses multiple data pairs that indicate the neutralizing capacity of the antibody towards a specific virus strain. During the curation process, we restricted our focus to the 10,720 studies that included both the light and heavy chain sequences of the antibodies, resulting in a total of 35,970 antigen-antibody pairs. Subsequently, we removed data with indeterminate locus positions. Finally, we retained only the data of the variants associated with the SARS-CoV-2 antigen, which resulted in a total of 27,324 unique data entries.</p><p id="P59">14H and 14L: The 14H and 14L datasets are sourced from the LL-SARS-CoV-2 database<sup><xref ref-type="bibr" rid="R36">36</xref></sup>. This database was designed to choose two heavy chains and two light chains from three main chains of antibodies as the framework for constructing an antibody library. Each dataset includes 1-3 mutations in the CDR region of the skeleton sequence. The AlphaSeq<sup><xref ref-type="bibr" rid="R65">65</xref></sup> technology was applied to quantify the affinity binding of each sequence variant to the SARS-CoV-2 target. As part of the data processing, we eliminated raw data that lacked affinity information for both 14H and 14L datasets. Then, we averaged the affinity measurements for all sequences with the same antibody sequence. This resulted in 13,922 unique heavy chain data entries in 14H and 18,708 unique light chain data entries in 14L. In the 14H dataset, only the heavy chain is varied, with the light chain and antigen remaining the same for each entry. Similarly, in the 14L dataset, only the light chain is different, while the heavy chain and antigen remain constant for all entries.</p><p id="P60">BioMap<sup><xref ref-type="bibr" rid="R35">35</xref></sup>: BioMap data set was derived from an antigen-antibody affinity prediction competition held by BioMap. It contains 1,706 antigen-antibody pairing data and has binding free energy (Delta G) as the label. The antigen-antibody sequences and Delta G data in the BioMap dataset are sourced from the Biomap company, specifically from 473 PDB complex entries. It comprises 638 unique antigens and 1,277 unique antibodies, with most antibodies of human and mouse origin along with minor fractions from hamsters, chimpanzees, rhesus monkeys, rabbits, rats, and llamas. No nanobodies are included.</p></sec><sec id="S16"><title>Rotary Transformer (RoFormer)</title><p id="P61">Roformer improves the Transformer structure using Rotary Position Embedding (RoPE). This design achieves relative position coding in the form of absolute position coding. Experimental results on various long text classification benchmark datasets show that the enhanced Transformer with rotary position embedding, namely RoFormer, can give better performance compared to baseline alternatives and thus demonstrates the efficacy of the proposed RoPE. Suppose <inline-formula><mml:math id="M1"><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> is the word embedding of N input tokens. Self-attention first merges the location information into the word embeddings and converts them into q, k, and v representations: <disp-formula id="FD1"><label>(1)</label><mml:math id="M2"><mml:msub><mml:mi>q</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></disp-formula> The information of the <italic>m</italic><sup><italic>th</italic></sup> and <italic>n</italic><sup><italic>th</italic></sup> positions are obtained by functions <italic>f</italic><sub><italic>q</italic></sub>, <italic>f</italic><sub><italic>k</italic></sub> and <italic>f</italic><sub><italic>v</italic></sub>. The attention weights are then obtained by q and k: <disp-formula id="FD2"><label>(2)</label><mml:math id="M3"><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>q</mml:mi><mml:mi>m</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msub><mml:mi>k</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mi>d</mml:mi></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>∑</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:mi>exp</mml:mi></mml:mrow></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>q</mml:mi><mml:mi>m</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msub><mml:mi>k</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mi>d</mml:mi></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mtext>.</mml:mtext></mml:math></disp-formula> As seen in <xref ref-type="disp-formula" rid="FD2">equation (2)</xref>, <inline-formula><mml:math id="M4"><mml:msubsup><mml:mi>q</mml:mi><mml:mi>m</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msub><mml:mi>k</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula> can transfer knowledge between tokens at different positions. To merge relative location information, RoPE requires that the inner product of the query <italic>a</italic><sub><italic>m</italic></sub> and the key <italic>k</italic><sub><italic>n</italic></sub> is represented by a function <italic>g</italic> that takes as input variables only the word embeddings <italic>x</italic><sub><italic>m</italic></sub>, <italic>x</italic><sub><italic>n</italic></sub> and their relative locations <italic>m</italic> − <italic>n</italic>: <disp-formula id="FD3"><label>(3)</label><mml:math id="M5"><mml:mrow><mml:mo>〈</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>〉</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:math></disp-formula> Su et al.<sup><xref ref-type="bibr" rid="R21">21</xref></sup> assumed that the inner product encodes position information only in the relative form. After derivation, they obtained the representation of RoPE: <disp-formula id="FD4"><label>(4)</label><mml:math id="M6"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>θ</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>θ</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>Re</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>∗</mml:mo></mml:msup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> Where (<italic>W</italic><sub><italic>k</italic></sub> <italic>x</italic><sub><italic>n</italic></sub>)<sup>∗</sup> represents the conjugate complex number of <italic>W</italic><sub><italic>k</italic></sub> <italic>x</italic><sub><italic>n</italic></sub>, and <italic>Re</italic>[·] is the real part of a complex number, <italic>θ</italic> ∈ <italic>R</italic> is a preset non-zero constant. Details of the derivation of the above equation can be found in the original paper<sup><xref ref-type="bibr" rid="R21">21</xref></sup>.</p><p id="P62">The RoPE rotates the affine-transformed word embedding vector by a specific angle multiple of its position index. It employs absolute position encoding to achieve relative position encoding and eliminates the need to operate the Attention matrix. As a result, RoPE has the potential to be used with linear attention. Considering the conformation of amino acid folding in proteins, relative position-coding may be better suited for constructing linkage patterns between proteins, such as antigens and antibodies, when modeling a language model.</p></sec><sec id="S17"><title>MF-CNN</title><p id="P63">We use an elaborate multi-scale feature fusion CNN architecture MF-CNN to further fuse the sequence features extracted by Roformer.</p><p id="P64">The input of MF-CNN is the output of all the tokens of Roformer. It utilizes a 3-layer CNN skeleton containing convolution, pooling, and Relu for multi-scale feature extraction. <disp-formula id="FD5"><label>(5)</label><mml:math id="M7"><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mspace width="0.2em"/><mml:mi>M</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mspace width="0.2em"/><mml:mo stretchy="false">(</mml:mo><mml:mspace width="0.2em"/><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>q</mml:mi><mml:mspace width="0.2em"/><mml:mo stretchy="false">)</mml:mo><mml:mspace width="0.2em"/><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:math></disp-formula> The features are then further fused using a multi-layer FC layer and residual operations for the final output. <disp-formula id="FD6"><label>(6)</label><mml:math id="M8"><mml:mspace width="0.2em"/><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mspace width="0.2em"/><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mi>u</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>F</mml:mi><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>M</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>M</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>M</mml:mi><mml:mo>.</mml:mo></mml:math></disp-formula></p></sec><sec id="S18"><title>Baseline</title><p id="P65">ESM-F: ESM-F is based on the ESM2 <sup><xref ref-type="bibr" rid="R16">16</xref></sup>. It modifies pre-trained Roformers of A2binder to ESM2s and retains the MF-CNN model for feature fusion. ESM-2<sup><xref ref-type="bibr" rid="R16">16</xref></sup> is a state-of-the-art protein representation model. It is suitable for fine-tuning a wide range of tasks that take protein sequences as input. They used a BERT-style encoder-only transformer architecture with modifications. They changed the number of layers, number of attention heads, hidden size, and feed-forward hidden size as they scaled the ESM model. The purpose of constructing ESM-F as a baseline is to investigate the extent of improvement that can be achieved in the antigen-antibody affinity model by employing pre-training with antibody sequences.</p><p id="P66">Ens-Grad: The Ens-Grad model is derived from the high-capacity CNN architecture proposed by Liu et al.<sup><xref ref-type="bibr" rid="R66">66</xref></sup> for antibody CDR design. Each input token of the architecture is converted into a one-hot vector, where each position of the vector is the channel input of CNN. All sequences are filled with zero to the maximum sequence length of the dataset. The model is composed of two convolutional layers followed by a standard FC decision layer. Using Ens-Grad as the baseline allows us to compare the performance of A2binder and the antigen-antibody affinity prediction model without pre-training.</p><p id="P67">Vanilla BERT: The BERT is based on Transformer’s encoder architecture<sup><xref ref-type="bibr" rid="R30">30</xref></sup>. It consists of multiple encoder layers, and each layer contains self-attention and feed-forward modules. It assigns token position information through absolute position coding. We selected Vanilla BERT as the baseline to investigate the impact of RoPE, MF-CNN, and pre-training on the model’s performance.</p></sec><sec id="S19"><title>Pre-training</title><p id="P68">We employed the Unique Amino Acid (UAA) Tokenizer during pre-training and downstream fine-tuning, as antibodies are highly responsive to single-point mutations. The UAA Tokenizer works by assigning a unique token to each unique amino acid present in the protein sequence. Each token represents a specific amino acid, which allows models to understand and analyze the sequence. The UAA tokenizer assigns each amino acid a unique integer value. After UAA tokenization, a weighted, learnable embedding layer converts each amino acid’s integer value into a dense vector representation. This embedding allows the model to learn the complex features of each residue about its position. This retains positional relationships between residues, enabling the model to better learn mutations, deletions, and insertions.</p><p id="P69">Roformer’s model parameters refer to BERT-light. The hidden size is 768, including 12 hidden layers and 12 attention heads. The intermediate size is 1,536.</p><p id="P70">MAA task is a self-supervised pre-training method. Through a part of the token of the random mask input sequence, it uses the model to predict the mask position and conduct self-supervised learning of the model. We randomly masked 15% of the tokens to conduct MAA training.</p><p id="P71">For the pre-training of heavy chain Roformer, we used 81,730,448 training data and 20,438 test data, for the pre-training of light chain Roformer. 17,736,747 training data and 17,755 test data were used.</p><p id="P72">The batch size of the pre-training was set to 2048. The heavy chain model was trained for more than 200,000 steps, while the light chain model was trained for more than 100,000 steps.</p><p id="P73">Both heavy and light Roformer were trained on NVIDIA Volta V100 GPUs using a distributed computing architecture.</p></sec><sec id="S20"><title>Antigen-antibody Affinity Prediction</title><p id="P74">In the antigen-antibody affinity prediction task, we split the training, validation, and test sets in a ratio of 8:1:1. To improve the model’s performance, we employed two learning rates for optimizing the Roformer and MF-CNN, respectively. Additionally, a linear learning rate schedule was implemented to facilitate an effective training process. We repeat experiments five times by choosing different random seeds and reporting the average results for our model and baseline methods.</p><p id="P75">In the binding specificity classification task carried out on the Cov-AbDab dataset, we used the ROC-AUC, PR-AUC, and Accuracy as evaluation metrics. In the affinity prediction task, we used Spearman’s rank correlation coefficient as metric.</p></sec><sec id="S21"><title>Antibody Generation</title><p id="P76">Since the antibodies in the 14H dataset target a stable peptide in the HR2 region of SARS-CoV-2, to train the cross-attention layer in the Antibody Layer of the decoder, we first utilized positive samples from the CoV-AbDab dataset to train PALM for 10 epochs. In the case of generating the correct target key sites, we used the antigen-CDRH3 paired data from the 14H data set for further fine-tuning. In the case of antibody generation for the new variant XBB, we selected positive samples with the same 15 amino acids of light and heavy chain prefixes in the antibody for further training.</p><p id="P77">The Beam search method was used in the generation phase. Beam search can reduce memory consumption through a breadth-first searching strategy, which is widely employed to boost the output text quality. It often leads to substantial improvement over the greedy search strategy, which is equivalent to setting the beam size to 1. We set the Beam size to 10. After generation, we replaced the CDRH3 of the natural sample, used A2binder trained on the corresponding dataset for affinity prediction, and selected the best of them for subsequent validation of the results.</p></sec><sec id="S22"><title>Western blot</title><p id="P78">The antigen protein was separated by SDS-PAGE and transferred to an NC membrane. After blocking, the membrane was incubated with different antibodies overnight at 4°C. Then the membrane was incubated with a secondary antibody conjugated to HRP for 1 hour at room temperature. ECL substrate was applied to visualize antibody binding bands. The Western blot results were imaged using a chemiluminescence imaging system.</p></sec><sec id="S23"><title>Surface plasmon resonance analysis</title><p id="P79">The interaction between RBD and antibodies was analyzed by surface plasmon resonance using a BIAcore T200 instrument. PBS running buffer containing 0.005% Tween 20 was used. The RBD analyte was injected into the PBS buffer for buffer exchange. Antibodies were captured on the sensor chip, and then serial dilutions of RBD flowed over the surface to obtain binding data. Curve fitting was performed to calculate each antibody-RBD pair’s dissociation constant (KD).</p></sec><sec id="S24"><title>Pseudovirus neutralization assay</title><p id="P80">Pseudoviruses expressing spike proteins were produced in HEK 293T cells and harvested from cell culture supernatant. The pseudoviruses were incubated with serial dilutions of antibodies starting from 100 μg/mL for 1 hour at 37°C to allow neutralization. The antibody-pseudovirus mixtures were then added to Vero cells seeded in 96-well plates to infect the cells. After overnight incubation, pseudovirus transduction units were quantified by imaging cytometry to generate neutralization curves. The half-maximal inhibitory concentration (IC50) was determined for each antibody.</p></sec></sec></body><back><ack id="S25"><title>Acknowledgements</title><p>This work was supported by the National Natural Science Foundation of China (Grant No. 62176272), Research and Development Program of Guangzhou Science and Technology Bureau (No. 2023B01J1016), and Key-Area Research and Development Program of Guangdong Province (No. 2020B1111100001).</p></ack><sec id="S26" sec-type="data-availability"><title>Code and data Availability</title><p id="P81">Pre-trained Roformer and well-trained PALM and A2binder models on the comprehensive training dataset are available on Zenodo: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.7794583">https://doi.org/10.5281/zenodo.7794583</ext-link>. The source code of PALM are also available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/TencentAILabHealthcare/PALM">https://github.com/TencentAILabHealthcare/PALM</ext-link>.</p></sec><fn-group><fn id="FN1"><label>1</label><p id="P82">under patent application</p></fn><fn fn-type="con" id="FN2"><p id="P83"><bold>Author Contributions</bold></p><p id="P84">H.H: Methodology, Software, Formal analysis, Writing – original draft, Visualization. B.H.: Conceptualization, Supervision, Methodology, Investigation, Data Curation, Writing – Original Draft. L.G.: Wet Lab Validation. Y.Z.: Software, Resources, Data Curation. G.C.: Visualization, Formal analysis. Q. Z.: Wet Lab Validation. C.Y.-C.C.: Supervision, Writing – Review &amp; Editing. T. L.: Supervision, Wet Lab Validation. J.Y.: Conceptualization, Supervision, Writing – Review &amp; Editing.</p></fn><fn id="FN3" fn-type="conflict"><p id="P85"><bold>Competing interests</bold></p><p id="P86">The authors declare no competing interests.</p></fn></fn-group><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zahavi</surname><given-names>D</given-names></name><name><surname>Weiner</surname><given-names>L</given-names></name></person-group><article-title>Monoclonal Antibodies in Cancer Therapy</article-title><source>Antibodies</source><year>2020</year><volume>9</volume><fpage>34</fpage><pub-id pub-id-type="pmcid">PMC7551545</pub-id><pub-id pub-id-type="pmid">32698317</pub-id><pub-id pub-id-type="doi">10.3390/antib9030034</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taylor</surname><given-names>PC</given-names></name><etal/></person-group><article-title>Neutralizing monoclonal antibodies for treatment of COVID-19</article-title><source>Nat Rev Immunol</source><year>2021</year><volume>21</volume><fpage>382</fpage><lpage>393</lpage><pub-id pub-id-type="pmcid">PMC8054133</pub-id><pub-id pub-id-type="pmid">33875867</pub-id><pub-id pub-id-type="doi">10.1038/s41577-021-00542-x</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yoo</surname><given-names>J-W</given-names></name><name><surname>Irvine</surname><given-names>DJ</given-names></name><name><surname>Discher</surname><given-names>DE</given-names></name><name><surname>Mitragotri</surname><given-names>S</given-names></name></person-group><article-title>Bio-inspired, bioengineered and biomimetic drug delivery carriers</article-title><source>Nat Rev Drug Discov</source><year>2011</year><volume>10</volume><fpage>521</fpage><lpage>535</lpage><pub-id pub-id-type="pmid">21720407</pub-id></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Imai</surname><given-names>K</given-names></name><name><surname>Takaoka</surname><given-names>A</given-names></name></person-group><article-title>Comparing antibody and small-molecule therapies for cancer</article-title><source>Nat Rev Cancer</source><year>2006</year><volume>6</volume><fpage>714</fpage><lpage>727</lpage><pub-id pub-id-type="pmid">16929325</pub-id></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Z</given-names></name><etal/></person-group><article-title>Development of therapeutic antibodies for the treatment of diseases</article-title><source>Molecular Biomedicine</source><year>2022</year><volume>3</volume><pub-id pub-id-type="pmcid">PMC9684400</pub-id><pub-id pub-id-type="pmid">36418786</pub-id><pub-id pub-id-type="doi">10.1186/s43556-022-00100-4</pub-id></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Teng</surname><given-names>J</given-names></name><etal/></person-group><article-title>Detection of IgM and IgG antibodies against SARS-CoV-2 in patients with autoimmune diseases</article-title><source>Lancet Rheumatol</source><year>2020</year><volume>2</volume><fpage>e384</fpage><lpage>e385</lpage><pub-id pub-id-type="pmcid">PMC7234786</pub-id><pub-id pub-id-type="pmid">32835238</pub-id><pub-id pub-id-type="doi">10.1016/S2665-9913(20)30128-4</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mason</surname><given-names>DM</given-names></name><etal/></person-group><article-title>Optimization of therapeutic antibodies by predicting antigen specificity from antibody sequence via deep learning</article-title><source>Nature Biomedical Engineering</source><year>2021</year><volume>5</volume><fpage>600</fpage><lpage>612</lpage><pub-id pub-id-type="pmid">33859386</pub-id></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paul</surname><given-names>SM</given-names></name><etal/></person-group><article-title>How to improve R&amp;D productivity: the pharmaceutical industry’s grand challenge</article-title><source>Nat Rev Drug Discov</source><year>2010</year><volume>9</volume><fpage>203</fpage><lpage>214</lpage><pub-id pub-id-type="pmid">20168317</pub-id></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ingber</surname><given-names>DE</given-names></name></person-group><article-title>Human organs-on-chips for disease modelling, drug development and personalized medicine</article-title><source>Nat Rev Genet</source><year>2022</year><volume>23</volume><fpage>467</fpage><lpage>491</lpage><pub-id pub-id-type="pmcid">PMC8951665</pub-id><pub-id pub-id-type="pmid">35338360</pub-id><pub-id pub-id-type="doi">10.1038/s41576-022-00466-9</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nimmo</surname><given-names>JT</given-names></name><etal/></person-group><article-title>Immunisation with UB-312 in the Thy1SNCA mouse prevents motor performance deficits and oligomeric α-synuclein accumulation in the brain and gut</article-title><source>Acta Neuropathol</source><year>2022</year><volume>143</volume><fpage>55</fpage><lpage>73</lpage><pub-id pub-id-type="pmcid">PMC8732825</pub-id><pub-id pub-id-type="pmid">34741635</pub-id><pub-id pub-id-type="doi">10.1007/s00401-021-02381-5</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoet</surname><given-names>RM</given-names></name><etal/></person-group><article-title>Generation of high-affinity human antibodies by combining donor-derived and synthetic complementarity-determining-region diversity</article-title><source>Nat Biotechnol</source><year>2005</year><volume>23</volume><fpage>344</fpage><lpage>348</lpage><pub-id pub-id-type="pmid">15723048</pub-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weitzner</surname><given-names>BD</given-names></name><etal/></person-group><article-title>Modeling and docking of antibody structures with Rosetta</article-title><source>Nat Protoc</source><year>2017</year><volume>12</volume><fpage>401</fpage><lpage>416</lpage><pub-id pub-id-type="pmcid">PMC5739521</pub-id><pub-id pub-id-type="pmid">28125104</pub-id><pub-id pub-id-type="doi">10.1038/nprot.2016.180</pub-id></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sircar</surname><given-names>A</given-names></name><name><surname>Gray</surname><given-names>JJ</given-names></name></person-group><article-title>SnugDock: Paratope Structural Optimization during Antibody-Antigen Docking Compensates for Errors in Antibody Homology Models</article-title><source>PLoS Comput Biol</source><year>2010</year><volume>6</volume><elocation-id>e1000644</elocation-id><pub-id pub-id-type="pmcid">PMC2800046</pub-id><pub-id pub-id-type="pmid">20098500</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000644</pub-id></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Myung</surname><given-names>Y</given-names></name><name><surname>Pires</surname><given-names>DEV</given-names></name><name><surname>Ascher</surname><given-names>DB</given-names></name></person-group><article-title>mmCSM-AB: guiding rational antibody engineering through multiple point mutations</article-title><source>Nucleic Acids Res</source><year>2020</year><volume>48</volume><fpage>W125</fpage><lpage>W131</lpage><pub-id pub-id-type="pmcid">PMC7319589</pub-id><pub-id pub-id-type="pmid">32432715</pub-id><pub-id pub-id-type="doi">10.1093/nar/gkaa389</pub-id></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Verkuil</surname><given-names>R</given-names></name><etal/></person-group><article-title>Language models generalize beyond natural proteins</article-title><source>bioRxiv</source><year>2022</year><elocation-id>2022.12.21.521521</elocation-id><pub-id pub-id-type="doi">10.1101/2022.12.21.521521</pub-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>Z</given-names></name><etal/></person-group><article-title>Evolutionary-scale prediction of atomic level protein structure with a language model</article-title><source>bioRxiv</source><year>2022</year><elocation-id>2022.07.20.500902</elocation-id><pub-id pub-id-type="pmid">36927031</pub-id></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nijkamp</surname><given-names>E</given-names></name><name><surname>Ruffolo</surname><given-names>J</given-names></name><name><surname>Weinstein</surname><given-names>EN</given-names></name><name><surname>Naik</surname><given-names>N</given-names></name><name><surname>Madani</surname><given-names>A</given-names></name></person-group><article-title>ProGen2: Exploring the Boundaries of Protein Language Models</article-title><year>2022</year><pub-id pub-id-type="pmid">37909046</pub-id></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Madani</surname><given-names>A</given-names></name><etal/></person-group><article-title>Large language models generate functional protein sequences across diverse families</article-title><source>Nat Biotechnol</source><year>2023</year><pub-id pub-id-type="pmcid">PMC10400306</pub-id><pub-id pub-id-type="pmid">36702895</pub-id><pub-id pub-id-type="doi">10.1038/s41587-022-01618-2</pub-id></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>JL</given-names></name><name><surname>Davis</surname><given-names>MM</given-names></name></person-group><article-title>Diversity in the CDR3 Region of VH Is Sufficient for Most Antibody Specificities</article-title><source>Immunity</source><year>2000</year><volume>13</volume><fpage>37</fpage><lpage>45</lpage><pub-id pub-id-type="pmid">10933393</pub-id></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuroda</surname><given-names>D</given-names></name><name><surname>Shirai</surname><given-names>H</given-names></name><name><surname>Jacobson</surname><given-names>MP</given-names></name><name><surname>Nakamura</surname><given-names>H</given-names></name></person-group><article-title>Computer-aided antibody design</article-title><source>Protein Eng Des Sel</source><year>2012</year><volume>25</volume><fpage>507</fpage><lpage>522</lpage><pub-id pub-id-type="pmcid">PMC3449398</pub-id><pub-id pub-id-type="pmid">22661385</pub-id><pub-id pub-id-type="doi">10.1093/protein/gzs024</pub-id></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Su</surname><given-names>J</given-names></name><etal/></person-group><article-title>RoFormer: Enhanced Transformer with Rotary Position Embedding</article-title><year>2021</year><pub-id pub-id-type="doi">10.48550/arXiv.2104.09864</pub-id></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Myung</surname><given-names>Y</given-names></name><name><surname>Pires</surname><given-names>DEV</given-names></name><name><surname>Ascher</surname><given-names>DB</given-names></name></person-group><article-title>CSM-AB: graph-based antibody–antigen binding affinity prediction and docking scoring function</article-title><source>Bioinformatics</source><year>2021</year><volume>38</volume><fpage>1141</fpage><lpage>1143</lpage><pub-id pub-id-type="pmid">34734992</pub-id></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shan</surname><given-names>S</given-names></name><etal/></person-group><article-title>Deep learning guided optimization of human antibody against SARS-CoV-2 variants with broad neutralization</article-title><source>Proc Natl Acad Sci U S A</source><year>2022</year><volume>119</volume><elocation-id>e2122954119</elocation-id><pub-id pub-id-type="pmcid">PMC8931377</pub-id><pub-id pub-id-type="pmid">35238654</pub-id><pub-id pub-id-type="doi">10.1073/pnas.2122954119</pub-id></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>M</given-names></name><name><surname>Cang</surname><given-names>Z</given-names></name><name><surname>Wei</surname><given-names>G-W</given-names></name></person-group><article-title>A topology-based network tree for the prediction of protein–protein binding affinity changes following mutation</article-title><source>Nature Machine Intelligence</source><year>2020</year><volume>2</volume><fpage>116</fpage><lpage>123</lpage><pub-id pub-id-type="pmcid">PMC7223817</pub-id><pub-id pub-id-type="pmid">34170981</pub-id><pub-id pub-id-type="doi">10.1038/s42256-020-0149-6</pub-id></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fowler</surname><given-names>NJ</given-names></name><name><surname>Sljoka</surname><given-names>A</given-names></name><name><surname>Williamson</surname><given-names>MP</given-names></name></person-group><article-title>A method for validating the accuracy of NMR protein structures</article-title><source>Nat Commun</source><year>2020</year><volume>11</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="pmcid">PMC7749147</pub-id><pub-id pub-id-type="pmid">33339822</pub-id><pub-id pub-id-type="doi">10.1038/s41467-020-20177-1</pub-id></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kang</surname><given-names>Y</given-names></name><name><surname>Leng</surname><given-names>D</given-names></name><name><surname>Guo</surname><given-names>J</given-names></name><name><surname>Pan</surname><given-names>L</given-names></name></person-group><article-title>Sequence-based deep learning antibody design for in silico antibody affinity maturation</article-title><year>2021</year><pub-id pub-id-type="doi">10.48550/arXiv.2103.03724</pub-id></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>J</given-names></name><etal/></person-group><article-title>Predicting unseen antibodies’ neutralizability via adaptive graph neural networks</article-title><source>Nature Machine Intelligence</source><year>2022</year><volume>4</volume><fpage>964</fpage><lpage>976</lpage></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>L</given-names></name><etal/></person-group><article-title>Antibody Representation Learning for Drug Discovery</article-title><year>2022</year><pub-id pub-id-type="doi">10.48550/arXiv.2210.02881</pub-id></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bachas</surname><given-names>S</given-names></name><etal/></person-group><article-title>Antibody optimization enabled by artificial intelligence predictions of binding affinity and naturalness</article-title><source>bioRxiv</source><year>2022</year><elocation-id>2022.08.16.504181</elocation-id><pub-id pub-id-type="doi">10.1101/2022.08.16.504181</pub-id></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vaswani</surname><given-names>A</given-names></name><etal/></person-group><article-title>Attention is all you need</article-title><source>Adv Neural Inf Process Syst</source><year>2017</year><volume>30</volume></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olsen</surname><given-names>TH</given-names></name><name><surname>Boyles</surname><given-names>F</given-names></name><name><surname>Deane</surname><given-names>CM</given-names></name></person-group><article-title>Observed Antibody Space: A diverse database of cleaned, annotated, and translated unpaired and paired antibody sequences</article-title><source>Protein Sci</source><year>2022</year><volume>31</volume><fpage>141</fpage><lpage>146</lpage><pub-id pub-id-type="pmcid">PMC8740823</pub-id><pub-id pub-id-type="pmid">34655133</pub-id><pub-id pub-id-type="doi">10.1002/pro.4205</pub-id></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kovaltsuk</surname><given-names>A</given-names></name><etal/></person-group><article-title>Observed Antibody Space: A Resource for Data Mining Next-Generation Sequencing of Antibody Repertoires</article-title><source>J Immunol</source><year>2018</year><volume>201</volume><fpage>2502</fpage><lpage>2509</lpage><pub-id pub-id-type="pmid">30217829</pub-id></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rothe</surname><given-names>S</given-names></name><name><surname>Narayan</surname><given-names>S</given-names></name><name><surname>Severyn</surname><given-names>A</given-names></name></person-group><article-title>Leveraging Pre-trained Checkpoints for Sequence Generation Tasks</article-title><source>Transactions of the Association for Computational Linguistics</source><year>2020</year><volume>8</volume><fpage>264</fpage><lpage>280</lpage></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raybould</surname><given-names>MIJ</given-names></name><name><surname>Kovaltsuk</surname><given-names>A</given-names></name><name><surname>Marks</surname><given-names>C</given-names></name><name><surname>Deane</surname><given-names>CM</given-names></name></person-group><article-title>CoV-AbDab: the coronavirus antibody database</article-title><source>Bioinformatics</source><year>2020</year><volume>37</volume><fpage>734</fpage><lpage>735</lpage><pub-id pub-id-type="pmcid">PMC7558925</pub-id><pub-id pub-id-type="pmid">32805021</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/btaa739</pub-id></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>B</given-names></name><etal/></person-group><article-title>xTrimoPGLM: Unified 100B-Scale Pre-trained Transformer for Deciphering the Language of Protein</article-title><year>2023</year></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engelhart</surname><given-names>E</given-names></name><etal/></person-group><article-title>A dataset comprised of binding interactions for 104,972 antibodies against a SARS-CoV-2 peptide</article-title><source>Scientific Data</source><year>2022</year><volume>9</volume><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="pmcid">PMC9606274</pub-id><pub-id pub-id-type="pmid">36289234</pub-id><pub-id pub-id-type="doi">10.1038/s41597-022-01779-4</pub-id></element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lai</surname><given-names>S-C</given-names></name><etal/></person-group><article-title>Characterization of neutralizing monoclonal antibodies recognizing a 15-residues epitope on the spike protein HR2 region of severe acute respiratory syndrome coronavirus (SARS-CoV)</article-title><source>J Biomed Sci</source><year>2005</year><volume>12</volume><fpage>711</fpage><lpage>727</lpage><pub-id pub-id-type="pmcid">PMC7089214</pub-id><pub-id pub-id-type="pmid">16132115</pub-id><pub-id pub-id-type="doi">10.1007/s11373-005-9004-3</pub-id></element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jumper</surname><given-names>J</given-names></name><etal/></person-group><article-title>Highly accurate protein structure prediction with AlphaFold</article-title><source>Nature</source><year>2021</year><volume>596</volume><fpage>583</fpage><lpage>589</lpage><pub-id pub-id-type="pmcid">PMC8371605</pub-id><pub-id pub-id-type="pmid">34265844</pub-id><pub-id pub-id-type="doi">10.1038/s41586-021-03819-2</pub-id></element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rose</surname><given-names>PW</given-names></name><etal/></person-group><article-title>The RCSB protein data bank: integrative view of protein, gene and 3D structural information</article-title><source>Nucleic Acids Res</source><year>2016</year><volume>45</volume><fpage>D271</fpage><lpage>D281</lpage><pub-id pub-id-type="pmcid">PMC5210513</pub-id><pub-id pub-id-type="pmid">27794042</pub-id><pub-id pub-id-type="doi">10.1093/nar/gkw1000</pub-id></element-citation></ref><ref id="R40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Desta</surname><given-names>IT</given-names></name><name><surname>Porter</surname><given-names>KA</given-names></name><name><surname>Xia</surname><given-names>B</given-names></name><name><surname>Kozakov</surname><given-names>D</given-names></name><name><surname>Vajda</surname><given-names>S</given-names></name></person-group><article-title>Performance and Its Limits in Rigid Body Protein-Protein Docking</article-title><source>Structure</source><year>2020</year><volume>28</volume><fpage>1071</fpage><lpage>1081</lpage><elocation-id>e3</elocation-id><pub-id pub-id-type="pmcid">PMC7484347</pub-id><pub-id pub-id-type="pmid">32649857</pub-id><pub-id pub-id-type="doi">10.1016/j.str.2020.06.006</pub-id></element-citation></ref><ref id="R41"><label>41</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brenke</surname><given-names>R</given-names></name><etal/></person-group><article-title>Application of asymmetric statistical potentials to antibody-protein docking</article-title><source>Bioinformatics</source><year>2012</year><volume>28</volume><fpage>2608</fpage><lpage>2614</lpage><pub-id pub-id-type="pmcid">PMC3467743</pub-id><pub-id pub-id-type="pmid">23053206</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/bts493</pub-id></element-citation></ref><ref id="R42"><label>42</label><element-citation publication-type="journal"><article-title>Novel chimeric proteins mimicking SARS-CoV-2 spike epitopes with broad inhibitory activity</article-title><source>Int J Biol Macromol</source><year>2022</year><volume>222</volume><fpage>2467</fpage><lpage>2478</lpage><pub-id pub-id-type="pmcid">PMC9546781</pub-id><pub-id pub-id-type="pmid">36220405</pub-id><pub-id pub-id-type="doi">10.1016/j.ijbiomac.2022.10.031</pub-id></element-citation></ref><ref id="R43"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robert</surname><given-names>PA</given-names></name><etal/></person-group><article-title>Unconstrained generation of synthetic antibody–antigen structures to guide machine learning methodology for antibody specificity prediction</article-title><source>Nat Comput Sci</source><year>2022</year><volume>2</volume><fpage>845</fpage><lpage>865</lpage></element-citation></ref><ref id="R44"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>X</given-names></name><name><surname>Pearce</surname><given-names>R</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name></person-group><article-title>EvoEF2: accurate and fast energy function for computational protein design</article-title><source>Bioinformatics</source><year>2020</year><volume>36</volume><fpage>1135</fpage><lpage>1142</lpage><pub-id pub-id-type="pmcid">PMC7144094</pub-id><pub-id pub-id-type="pmid">31588495</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/btz740</pub-id></element-citation></ref><ref id="R45"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hatcher</surname><given-names>EL</given-names></name><etal/></person-group><article-title>Virus Variation Resource – improved response to emergent viral outbreaks</article-title><source>Nucleic Acids Res</source><year>2016</year><volume>45</volume><fpage>D482</fpage><lpage>D490</lpage><pub-id pub-id-type="pmcid">PMC5210549</pub-id><pub-id pub-id-type="pmid">27899678</pub-id><pub-id pub-id-type="doi">10.1093/nar/gkw1065</pub-id></element-citation></ref><ref id="R46"><label>46</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>C</given-names></name><name><surname>Bradley</surname><given-names>P</given-names></name><name><surname>Baker</surname><given-names>D</given-names></name></person-group><article-title>Protein–Protein Docking with Backbone Flexibility</article-title><source>Journal of Molecular Biology</source><year>2007</year><volume>373</volume><fpage>503</fpage><lpage>519</lpage><pub-id pub-id-type="pmid">17825317</pub-id></element-citation></ref><ref id="R47"><label>47</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Q</given-names></name><etal/></person-group><article-title>Alarming antibody evasion properties of rising SARS-CoV-2 BQ and XBB subvariants</article-title><source>Cell</source><year>2023</year><volume>186</volume><fpage>279</fpage><lpage>286</lpage><elocation-id>e8</elocation-id><pub-id pub-id-type="pmcid">PMC9747694</pub-id><pub-id pub-id-type="pmid">36580913</pub-id><pub-id pub-id-type="doi">10.1016/j.cell.2022.12.018</pub-id></element-citation></ref><ref id="R48"><label>48</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Q</given-names></name><etal/></person-group><article-title>Antibody evasion by SARS-CoV-2 Omicron subvariants BA.2.12.1, BA.4 and BA.5</article-title><source>Nature</source><year>2022</year><volume>608</volume><fpage>603</fpage><lpage>608</lpage><pub-id pub-id-type="pmcid">PMC9385487</pub-id><pub-id pub-id-type="pmid">35790190</pub-id><pub-id pub-id-type="doi">10.1038/s41586-022-05053-w</pub-id></element-citation></ref><ref id="R49"><label>49</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Q</given-names></name><etal/></person-group><article-title>Antigenic characterization of the SARS-CoV-2 Omicron subvariant BA.2.75</article-title><source>Cell Host Microbe</source><year>2022</year><volume>30</volume><fpage>1512</fpage><lpage>1517</lpage><elocation-id>e4</elocation-id><pub-id pub-id-type="pmcid">PMC9444898</pub-id><pub-id pub-id-type="pmid">36108630</pub-id><pub-id pub-id-type="doi">10.1016/j.chom.2022.09.002</pub-id></element-citation></ref><ref id="R50"><label>50</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Scientific</surname><given-names>DeLano</given-names></name><name><surname>Carlos</surname><given-names>San</given-names></name></person-group><publisher-loc>California, USA</publisher-loc><source>PyMol: An Open-Source Molecular Graphics Tool</source><year>2002</year><publisher-name>CCP4 Newsletter</publisher-name></element-citation></ref><ref id="R51"><label>51</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miho</surname><given-names>E</given-names></name><name><surname>Roškar</surname><given-names>R</given-names></name><name><surname>Greiff</surname><given-names>V</given-names></name><name><surname>Reddy</surname><given-names>ST</given-names></name></person-group><article-title>Large-scale network analysis reveals the sequence space architecture of antibody repertoires</article-title><source>Nat Commun</source><year>2019</year><volume>10</volume><elocation-id>1321</elocation-id><pub-id pub-id-type="pmcid">PMC6428871</pub-id><pub-id pub-id-type="pmid">30899025</pub-id><pub-id pub-id-type="doi">10.1038/s41467-019-09278-8</pub-id></element-citation></ref><ref id="R52"><label>52</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barnes</surname><given-names>CO</given-names></name><etal/></person-group><article-title>SARS-CoV-2 neutralizing antibody structures inform therapeutic strategies</article-title><source>Nature</source><year>2020</year><volume>588</volume><fpage>682</fpage><lpage>687</lpage><pub-id pub-id-type="pmcid">PMC8092461</pub-id><pub-id pub-id-type="pmid">33045718</pub-id><pub-id pub-id-type="doi">10.1038/s41586-020-2852-1</pub-id></element-citation></ref><ref id="R53"><label>53</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Torres</surname><given-names>M</given-names></name><name><surname>Casadevall</surname><given-names>A</given-names></name></person-group><article-title>The immunoglobulin constant region contributes to affinity and specificity</article-title><source>Trends in Immunology</source><year>2008</year><volume>29</volume><fpage>91</fpage><lpage>97</lpage><pub-id pub-id-type="pmid">18191616</pub-id></element-citation></ref><ref id="R54"><label>54</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koide</surname><given-names>A</given-names></name><etal/></person-group><article-title>Exploring the capacity of minimalist protein interfaces: interface energetics and affinity maturation to picomolar KD of a single-domain antibody with a flat paratope</article-title><source>J Mol Biol</source><year>2007</year><volume>373</volume><fpage>941</fpage><lpage>953</lpage><pub-id pub-id-type="pmcid">PMC2148503</pub-id><pub-id pub-id-type="pmid">17888451</pub-id><pub-id pub-id-type="doi">10.1016/j.jmb.2007.08.027</pub-id></element-citation></ref><ref id="R55"><label>55</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Devlin</surname><given-names>JR</given-names></name><etal/></person-group><article-title>Structural dissimilarity from self drives neoepitope escape from immune tolerance</article-title><source>Nat Chem Biol</source><year>2020</year><volume>16</volume><fpage>1269</fpage><lpage>1276</lpage><pub-id pub-id-type="pmcid">PMC8210748</pub-id><pub-id pub-id-type="pmid">32807968</pub-id><pub-id pub-id-type="doi">10.1038/s41589-020-0610-1</pub-id></element-citation></ref><ref id="R56"><label>56</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maani</surname><given-names>Z</given-names></name><etal/></person-group><article-title>Rational design of an anti-cancer peptide inhibiting CD147 / Cyp A interaction</article-title><source>J Mol Struct</source><year>2023</year><volume>1272</volume><elocation-id>134160</elocation-id><pub-id pub-id-type="pmcid">PMC9479519</pub-id><pub-id pub-id-type="pmid">36128074</pub-id><pub-id pub-id-type="doi">10.1016/j.molstruc.2022.134160</pub-id></element-citation></ref><ref id="R57"><label>57</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pourmand</surname><given-names>S</given-names></name><name><surname>Zareei</surname><given-names>S</given-names></name><name><surname>Shahlaei</surname><given-names>M</given-names></name><name><surname>Moradi</surname><given-names>S</given-names></name></person-group><article-title>Inhibition of SARS-CoV-2 pathogenesis by potent peptides designed by the mutation of ACE2 binding region</article-title><source>Comput Biol Med</source><year>2022</year><volume>146</volume><elocation-id>105625</elocation-id><pub-id pub-id-type="pmcid">PMC9110306</pub-id><pub-id pub-id-type="pmid">35688710</pub-id><pub-id pub-id-type="doi">10.1016/j.compbiomed.2022.105625</pub-id></element-citation></ref><ref id="R58"><label>58</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Han</surname><given-names>W</given-names></name><etal/></person-group><article-title>Predicting the antigenic evolution of SARS-COV-2 with deep learning</article-title><comment>Preprint at</comment><pub-id pub-id-type="pmcid">PMC10261845</pub-id><pub-id pub-id-type="pmid">37311849</pub-id><pub-id pub-id-type="doi">10.1038/s41467-023-39199-6</pub-id></element-citation></ref><ref id="R59"><label>59</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Manieri</surname><given-names>TM</given-names></name><etal/></person-group><article-title>Characterization of Neutralizing Human Anti-Tetanus Monoclonal Antibodies Produced by Stable Cell Lines</article-title><source>Pharmaceutics</source><year>2022</year><volume>14</volume><pub-id pub-id-type="pmcid">PMC9611486</pub-id><pub-id pub-id-type="pmid">36297421</pub-id><pub-id pub-id-type="doi">10.3390/pharmaceutics14101985</pub-id></element-citation></ref><ref id="R60"><label>60</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>MacCallum</surname><given-names>RM</given-names></name><name><surname>Martin</surname><given-names>AC</given-names></name><name><surname>Thornton</surname><given-names>JM</given-names></name></person-group><article-title>Antibody-antigen interactions: contact analysis and binding site topography</article-title><source>J Mol Biol</source><year>1996</year><volume>262</volume><fpage>732</fpage><lpage>745</lpage><pub-id pub-id-type="pmid">8876650</pub-id></element-citation></ref><ref id="R61"><label>61</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mascola</surname><given-names>JR</given-names></name><name><surname>Haynes</surname><given-names>BF</given-names></name></person-group><article-title>HIV-1 neutralizing antibodies: understanding nature’s pathways</article-title><source>Immunol Rev</source><year>2013</year><volume>254</volume><fpage>225</fpage><lpage>244</lpage><pub-id pub-id-type="pmcid">PMC3738265</pub-id><pub-id pub-id-type="pmid">23772623</pub-id><pub-id pub-id-type="doi">10.1111/imr.12075</pub-id></element-citation></ref><ref id="R62"><label>62</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vergani</surname><given-names>S</given-names></name><name><surname>Yuan</surname><given-names>J</given-names></name></person-group><article-title>Developmental changes in the rules for B cell selection</article-title><source>Immunol Rev</source><year>2021</year><volume>300</volume><fpage>194</fpage><lpage>202</lpage><pub-id pub-id-type="pmid">33501672</pub-id></element-citation></ref><ref id="R63"><label>63</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cunningham</surname><given-names>O</given-names></name><name><surname>Scott</surname><given-names>M</given-names></name><name><surname>Zhou</surname><given-names>ZS</given-names></name><name><surname>Finlay</surname><given-names>WJJ</given-names></name></person-group><article-title>Polyreactivity and polyspecificity in therapeutic antibody development: risk factors for failure in preclinical and clinical development campaigns</article-title><source>MAbs</source><year>2021</year><volume>13</volume><elocation-id>1999195</elocation-id><pub-id pub-id-type="pmcid">PMC8726659</pub-id><pub-id pub-id-type="pmid">34780320</pub-id><pub-id pub-id-type="doi">10.1080/19420862.2021.1999195</pub-id></element-citation></ref><ref id="R64"><label>64</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Vries</surname><given-names>OJ</given-names></name><etal/></person-group><article-title>The elimination half-life of benzodiazepines and fall risk: two prospective observational studies</article-title><source>Age Ageing</source><year>2013</year><volume>42</volume><fpage>764</fpage><lpage>770</lpage><pub-id pub-id-type="pmid">23900130</pub-id></element-citation></ref><ref id="R65"><label>65</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walsh</surname><given-names>M</given-names></name><etal/></person-group><article-title>mit-ll/AlphaSeq_Antibody_Dataset: Initial release of AlphaSeq Antibody Dataset</article-title><year>2021</year><pub-id pub-id-type="doi">10.5281/zenodo.5095284</pub-id></element-citation></ref><ref id="R66"><label>66</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>G</given-names></name><etal/></person-group><article-title>Antibody complementarity determining region design using high-capacity machine learning</article-title><source>Bioinformatics</source><year>2019</year><volume>36</volume><fpage>2126</fpage><lpage>2133</lpage><pub-id pub-id-type="pmcid">PMC7141872</pub-id><pub-id pub-id-type="pmid">31778140</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/btz895</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>Overview of the PALM and A2binder workflow.</title><p><bold>a</bold>, Schematic of an antibody binding to the epitope region of an antigen. The antibody paratope comprised of CDRs from the heavy and light chains mediates the recognition and binding of the antigen. The CDRH3 loop, as the third CDR of the antibody heavy chain, plays an essential role in enabling specific antigen binding. <bold>b</bold>, The framework of PALM. It’s a Transformer-like neural network containing an antigen encoder model and an antibody decoder model. It takes the antigen sequence as input and generates a CDRH3 antibody sequence aiming to bind to the input antigen. The antigen encoder model is a ESM2-based model, which comprised of 12 antigen layers that were pre-trained using UniRef50 protein sequences and fine-tuned using antigen sequences. The antibody decoder is a RoFormer –based model, which contains 12 antibody layers that were pre-trained and fine-tuned using antibody sequenses. The key (K) and value (V) matrices from the last antigen layer are passed to every antibody layer as the input of the cross-attention sub-layer. <bold>c</bold>, Internal architecture of the antigen layer and antibody layer. Both antigen layer and antibody layer have two basic sub-layers, including a fully connected feed-forward sub-layer and a multi-head self-attention sub-layer. Additionally, the antibody layer uniquely includes cross-attention sub-layers. Input tokens of each layer are represented by the sum of token embeddings and rotary position embeddings, while the output is a high-dimensional vector representation for each input token. <bold>d</bold>, The cross-attention sub-layer is the key to combine the high-dimensional representation of antigen sequence (K and V matrices) and in-context antibody sequence(Q matrix). <bold>e</bold>, Schematic of the self-supervised pre-training of antibody RoFormer. Unpaired antibody sequences were used to pre-train the antibody RoFormer via masked language modeling. Sequences were tokenized and had partial random tokens masked. The model was trained to predict the identity of the masked tokens, learning generalizable representations of antibody sequences. <bold>f</bold>, The framework of A2Binder. It takes the antigen sequence along with antibody heavy and light chain sequences as input. Each sequence is encoded by passing through a pre-trained encoder and a Multi-Fusion Convolutional Neural Network (MF-CNN) feature extractor. The MLP (a multilayer perceptron) model finally fuses the features from all three sequences to predict antibody-antigen binding affinity. The architecture of the MF-CNN is shown below, comprising 3 convolutional layers and 3 fully-connected layers. The encoder for both the antibody heavy chain and light chain are built upon the pre-trained antibody RoFormer, whereas the antigen encoder utilizes the ESM2.</p></caption><graphic xlink:href="EMS189855-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Comparison of latent capabilities between pre-trained and untrained models.</title><p>Dimensionality reduction visualizations demonstrate the pre-trained model’s inherent ability to capture the feature of antibodies that determine the antigen binding specificity and affinity. <bold>a</bold>, T-SNE projection of sequence embeddings for antibodies selectively targeting distinct SARS-CoV-2 variants. Antibodies that bound to multiple variants were eliminated. <bold>b</bold>, T-SNE projection of model embeddings for antibodies specifically targeting unique epitopes of SARS-CoV-2. Antibodies that bound to multiple epitopes were eliminated. Antibody sequences used in subgraph a and b are from CoV-AbDab dataset. <bold>c</bold>, T-SNE projection of model embeddings of antibody sequences with different binding affinity. Each point represents a single antibody sequence from the BioMap dataset, with colors indicating the binding affinity, expressed as binding free energy (ΔG).</p></caption><graphic xlink:href="EMS189855-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Performance comparison of A2Binder versus baseline methods for antibody-antigen binding specificity prediction.</title><p><bold>a-b</bold>, Receiver operating characteristic (ROC) curve (a), and precision-recall (PR) curve (b) evaluating the overall predictive performance of antibody binding specificity. Models compared include A2Binder (blue), ESM-F (orange), Ens-Grad (green), and Vanilla BERT (red). <bold>c-d</bold>, Performance breakdown of A2Binder in predicting antibody binding specificity by antigen epitope region (c) and variant (d). The x-axis labels indicate the different epitope categories (c) and variants (d). The CoV-AbDab dataset was split into training (80%), validation (10%) and test (10%) sets. Results shown in this comparison are based on the test set.</p></caption><graphic xlink:href="EMS189855-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Performance comparison of A2Binder versus baseline methods for antibody-antigen binding affinity prediction.</title><p><bold>a-c</bold> Scatter plots showing predicted vs. true binding affinity for each model using the 14H (a), 14L (b), and BioMAP (c) datasets, respectively. Models compared include A2Binder (red), ESM-F (orange), Ens-Grad (blue), and Vanilla BERT (purple). The 14H, 14L, and BioMap datasets were each divided into training (80%), validation (10%), and test (10%) sets. Results shown in this comparison are based on the test sets. Upon statistical testing, we found A2Binder’s improvements in Spearman correlation over baselines to be significant (p&lt;0.05 on 14H and 14L; p&lt;0.01 on BioMap, t-test).</p></caption><graphic xlink:href="EMS189855-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>Similarity analysis of artificial and natural antibodies.</title><p><bold>a</bold>, Sequence logo of the CDRH3 region in artificial and natural antibodies. The CDRH3 sequences of natural antibodies are sourced from antibodies in the CoV-AbDab dataset that bind to the RBD region of wild-type SARS-CoV-2, while artificial antibodies CDRH3 sequences are obtained by inputting the RBD sequence of the wild-type SARS-CoV-2 to the PALM. <bold>b</bold>, Comparison of A2binder-predicted binding probabilities to the wild-type SARS-CoV-2 RBD region between generated antibodies and randomly mutated antibodies. Artificial antibodies and randomly mutated antibodies with the same Levenshtein distance to natural antibodies are compared. Boxplot showing distribution of A2binder-predicted binding probabilities across different Levenshtein distances. The x-axis denotes Levenshtein distance and the y-axis shows predicted binding probability. Blue boxes represent human engineered antibodies while purple boxes denote randomly mutated antibodies. The top whisker, top of the box, middle line, bottom of the box, and bottom whisker indicate the maximum, 75th percentile, median, 25th percentile, and minimum values, respectively. <bold>c</bold>, A2binder-predicted binding probabilities of artificial antibodies at different BitScore ranges. The BitScore measures the sequence similarity between artificial antibodies and natural antibodies binding to the same epitope. The x-axis denotes Bit score ranges and the y-axis shows predicted binding probability. The depth of the color indicates an increase in BitScore. The diamond represents outliers. <bold>d</bold>, A2binder-predicted binding probabilities of artificial antibodies at different RMSD (root mean square deviation) ranges. The RMSD measures the structure similarity between artificial antibodies and natural antibodies binding to the same epitope. The x-axis denotes RMSD ranges and the y-axis shows predicted binding probability. The depth of the color indicates an increase in RMSD value. The diamond represents outliers.</p></caption><graphic xlink:href="EMS189855-f005"/></fig><fig id="F6" position="float"><label>Figure 6</label><caption><title>The performance of PALM in generating artificial antibodies binding to the different epitopes of SARS-CoV-2.</title><p><bold>a</bold>, The t-SNE plot shows that artificial and natural antibodies with identical binding specificity are clustered in the same group. Each blue dot indicates an artificial antibody, while a red dot indicates a natural antibody. Each antibody sequence is embedded using the pre-trained light chain and heavy chain Roformers, followed by dimensionality reduction to obtain feature representations using t-SNE. <bold>b</bold>, Density distribution plots of the binding affinity of the artificial and natural antibodies targeting the same epitope. The binding affinity represented by Interface Energy and Irmsd are derived from 1000 optimized poses of the antibody-antigen binding complex using SnugDock. The artificial CDRH3 sequences are XXXXXXXXXX<sup>1</sup> and XXXXXXXXXX<sup>1</sup>, while natural CDRH3 sequences are XXXXXXXXXX and XXXXXXXXXX. <bold>c</bold>, Structure of the binding complex formed by PALM-generated CDRH3 XXXXXXXXXX<sup>1</sup> targeting the HR2 region of SARS-CoV-2. The PALM-generated CDRH3 successfully targets the stable peptide region within HR2, which is the input sequence of PALM. <bold>d</bold>, Molecular complex visualization depicting the binding of a natural antibody to the HR1 regions of SARS-CoV-2. It’s noteworthy that the natural antibody does not exhibit binding to the stable peptide in the HR2 region.</p></caption><graphic xlink:href="EMS189855-f006"/></fig><fig id="F7" position="float"><label>Figure 7</label><caption><title>Comparison between PALM and traditional computational antibody design methods.</title><p><bold>a</bold>, Distribution plot showcasing the Levenshtein distance among antibodies generated using PALM. <bold>b</bold>, A comparison of the time expenditure for antibody design at varying Levenshtein distances from natural antibodies is conducted among Rosetta, Absolute!, and PALM. The top row illustrates various Levenshtein distances, while the subsequent three rows represent the time required by each method to design antibodies at these distances to natural antibody, measured in CPU hours. <bold>c</bold>, Comparison of the binding affinity, indicated by interface energy, between antibodies produced by PALM and those generated by EvoEF2. The interface energy values were determined independently through SnugDock.</p></caption><graphic xlink:href="EMS189855-f007"/></fig><fig id="F8" position="float"><label>Figure 8</label><caption><title>Evaluating PALM’s efficacy in creating artificial antibodies against the novel SARS-CoV-2 variant XBB.</title><p><bold>a</bold>, Density distribution plots comparing the affinity of artificial and natural antibodies to XBB, based on 1000 optimized poses of Interface Energy and Irmsd acquired through SnugDock simulations. The artificial antibodies are generated by PALM for XBB, while the natural antibodies are known to target Omicoron variants. Independent t-test results unequivocally demonstrate that both the Interface Energy and Irmsd values of the artificial antibody are significantly lower than those of the natural antibody, underscoring its heightened affinity for variant XBB. <bold>b-c</bold>, Structures of the binding complex formed by the PALM-generated artificial antibody binding to variant XBB. The right side shows a zoomed-in portion of the binding interface on the left, with residues involved in antigen-antibody docking interactions highlighted. The artificial antibody sequence is depicted below the structure, while the PALM-generated CDRH3 sequence is highlighted in blue. The subgraph b corresponds to the left plot of subgraph a, while subgraph c corresponds to the right plot of subgraph a.</p></caption><graphic xlink:href="EMS189855-f008"/></fig><fig id="F9" position="float"><label>Figure 9</label><caption><title>Interpretability analysis of PALM in generating antigen-specific antibody CDRH3 sequence.</title><p><bold>a</bold>, Heat maps displaying cross-attention values of PALM when generating CDRH3 sequence “XXXXXXXXXX1” that targets the epitope “PDVDLGDISGINAS” of SARS-CoV-2. Notably, residue D of the epitope and residue R of the CDRH3 region of the antibody exhibits the highest interaction attention values. Cosistent with the cross-attention values, in the binding complexes shown on the right, these two residues form a hydrogen bond link between them. <bold>b</bold>, Heat maps displaying cross-attention values of PALM when generating CDRH3 sequence “XXXXXXXXXX1” that targets the SARS-CoV-2 variant XBB. <bold>c</bold>, Cosistent with the high cross-attention values of the residue 167-177 in the SARS-CoV-2 variant XBB, these reidues play important roles in binding to the generated CDRH3.</p></caption><graphic xlink:href="EMS189855-f009"/></fig><fig id="F10" position="float"><label>Figure 10</label><caption><title>
<italic>In-vitro</italic> assays of the binding affinity and neutralization of artificial and natural antibodies.</title><p><bold>a-b</bold>, Western blot analysis of artificial and natural antibodies. Antibodies in subfigure <bold>a</bold> target wild-type SARS-CoV-2 S protein, while antibodies in subfigure <bold>b</bold> target SARS-CoV-2 XBB variant S protein. HEK293T cells are used to produce pseudotyped vectors. The x-axis indicates the sample of each band, and the y-axis shows the position of antigen binding. Band intensity demonstrates the affinity between the corresponding antibody and antigen. β- Actin bands at the bottom monitor loading consistency across samples. <bold>c</bold>, The result of surface plasmon resonance analysis and pseudovirus neutralization assays of artificial and natural antibodies. The color legend below indicates value ranges for different colors. Binding affinity and neutralization are measured by KD and IC50, respectively. Lower values signify stronger binding affinity to the antigen and more potent neutralization capability of the antibody.</p></caption><graphic xlink:href="EMS189855-f010"/></fig></floats-group></article>