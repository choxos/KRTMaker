<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS190456</article-id><article-id pub-id-type="doi">10.1101/2023.10.26.564263</article-id><article-id pub-id-type="archive">PPR750597</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">1</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Signature Informed Sampling for Transcriptomic Data</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-7886-8385</contrib-id><name><surname>Janakarajan</surname><given-names>Nikita</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-3456-945X</contrib-id><name><surname>Graziani</surname><given-names>Mara</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-3766-4233</contrib-id><name><surname>Martínez</surname><given-names>María Rodríguez</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib></contrib-group><aff id="A1"><label>1</label>Accelerated Discovery, IBM Research Europe, Zürich, Switzerland</aff><aff id="A2"><label>2</label>Institute of Machine Learning, D-INFK, ETH Zürich, Zürich, Switzerland</aff><author-notes><corresp id="CR1"><label>*</label>Corresponding author: <email>nja@zurich.ibm.com</email></corresp></author-notes><pub-date pub-type="nihms-submitted"><day>02</day><month>11</month><year>2023</year></pub-date><pub-date pub-type="preprint"><day>31</day><month>10</month><year>2023</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Working with transcriptomic data is challenging in deep learning applications due to its high dimensionality and low patient numbers. Deep learning models tend to overfit this data and do not generalize well on out-of-distribution samples and new cohorts. Data augmentation strategies help alleviate this problem by introducing synthetic data points and acting as regularisers. However, existing approaches are either computationally intensive or require parametric estimates. We introduce a new solution to an old problem - a simple, non-parametric, and novel data augmentation approach inspired by the phenomenon of chromosomal crossover. Based on the assumption that there exist non-overlapping gene signatures describing each phenotype of interest, we demonstrate how new synthetic data points can be generated by sampling gene signatures from different patients under certain phenotypic constraints. As a case study, we apply our method to transcriptomic data of colorectal cancer. Through discriminative and generative experiments on two different datasets, we show that our method improves patient stratification by generating samples that mirror biological variability as well as the models’ robustness to overfitting and distribution shift. Our approach requires little to no computation, and outperforms, or at the very least matches, the performance of established augmentation methods.</p></abstract><kwd-group><kwd>Data Augmentation</kwd><kwd>Transcriptomics</kwd><kwd>Machine Learning</kwd></kwd-group></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">The application of machine learning in biomedicine, particularly for classification tasks, has become increasingly popular over the last decade [<xref ref-type="bibr" rid="R1">1</xref>, <xref ref-type="bibr" rid="R2">2</xref>]. High-throughput sequencing has provided access to transcriptomic data, catalyzing an increase in machine learning research aimed at pattern discovery, phenotype classification, disease subtyping, survival analysis, and more. However, the inherent challenges in this domain persist, notably the high dimensionality of data and limited sample numbers [<xref ref-type="bibr" rid="R3">3</xref>]. These challenges make machine learning models prone to overfitting, and reduces their ability to generalize to new datasets [<xref ref-type="bibr" rid="R4">4</xref>], even from different institutions [<xref ref-type="bibr" rid="R5">5</xref>].</p><p id="P3">To address these challenges, multiple techniques for dimensionality reduction and data augmentation have been developed. On one hand, dimensionality reduction methods help mitigate overfitting and enhance generalisation by only selecting highly informative features [<xref ref-type="bibr" rid="R6">6</xref>, <xref ref-type="bibr" rid="R7">7</xref>], or combinations of features such as in Principal Component Analysis (PCA) [<xref ref-type="bibr" rid="R8">8</xref>], Non-Negative Matrix Factorisation (NMF) [<xref ref-type="bibr" rid="R9">9</xref>], and Autoencoders [<xref ref-type="bibr" rid="R10">10</xref>]. On the other hand, data augmentation generates new data points from existing ones, addressing dataset imbalances and under-representation. Common data augmentation techniques involve noise injection-based methods, particularly in the imaging domain [<xref ref-type="bibr" rid="R11">11</xref>, <xref ref-type="bibr" rid="R12">12</xref>].</p><p id="P4">The noise perturbation prevents complex models from memorizing the training data [<xref ref-type="bibr" rid="R13">13</xref>]. Applying noise injection to transcriptomic and biological data, however, requires caution since the noise may potentially disrupt the biological signal. For this, other augmentation approaches were proposed for transcriptomic data, including parametric and non-parametric strategies. Parametric approaches assume specific data distributions, such as negative binomial [<xref ref-type="bibr" rid="R14">14</xref>] or Poisson [<xref ref-type="bibr" rid="R15">15</xref>], to generate new data points. Unfortunately, these approaches can be compromised by extreme data support values or sensitivity to outliers. Non-parametric techniques, such as random oversampling [<xref ref-type="bibr" rid="R16">16</xref>, <xref ref-type="bibr" rid="R17">17</xref>, <xref ref-type="bibr" rid="R18">18</xref>], do not have this issue, as they bypass distribution assumptions but cannot generate new samples to enhance diversity and improve robustness. In this paper, we address some of these limitations by proposing novel non-parametric approaches for transcriptomic data augmentation.</p><p id="P5">Our method is adapted to the biology domain, and leverages phenotypic gene signatures – sets of genes with distinct expression patterns that hold prognostic, diagnostic or predictive value – to drive the augmentation. Gene signatures are invaluable for phenotypic predictions, and are especially useful in cancer subtyping [<xref ref-type="bibr" rid="R19">19</xref>, <xref ref-type="bibr" rid="R20">20</xref>, <xref ref-type="bibr" rid="R21">21</xref>, <xref ref-type="bibr" rid="R22">22</xref>, <xref ref-type="bibr" rid="R23">23</xref>]. They can be leveraged to reduce the dimensionality of the data, where each patient is represented by the set of all gene signatures associated with the phenotypes instead of the entire 60,000 genes.</p><p id="P6">Although gene signatures reduce the dimension of the feature space, their integration with computational methods such as machine learning models remains challenging due to limited patient samples. Here we present a solution to this problem by leveraging identified gene signatures to generate new data. Specifically, we make the following assumptions: (i) Highly predictive gene signatures are available for each variant of the phenotype of interest; (ii) Gene signatures of phenotype variants are non-overlapping; (iii) The genes associated with each gene signature can interact with other genes from the same signature (directly or indirectly).</p><p id="P7">Our approach is inspired by chromosomal crossover and involves performing crossovers between patients’ gene signatures within and between phenotype variants. The study evaluates this method against standard techniques, including random oversampling, current state-of-the-art SMOTE [<xref ref-type="bibr" rid="R24">24</xref>], and parametric approaches like negative binomial and Poisson sampling. To make the latter a challenging baseline, we propose a modification of the original approaches with respect to the sampling step. Briefly, we use local parameter estimations to generate each new sample. The modifications are explained in detail in 3.2 and 3.3, respectively. To demonstrate the effectiveness of our sampling methods, the TCGA COADREAD dataset is used, and generalisation performance is assessed using the external validation of the CPTAC COAD dataset. The method successfully addresses class imbalance, improves model performance, and offers a promising solution for data augmentation in the biomedical domain.</p><p id="P8">Our contributions are as follows: <list list-type="order" id="L1"><list-item><p id="P9">We introduce a novel, non-parametric data augmentation method and benchmark it against conventional techniques.</p></list-item><list-item><p id="P10">We demonstrate the utility of the negative binomial and Poisson distributions as data augmentation strategies that alleviate class imbalance and enhance the diversity of generated samples.</p></list-item><list-item><p id="P11">We highlight the influence of augmentation size on model performance through a series of experiments in both discriminative and generative settings.</p></list-item></list></p></sec><sec id="S2"><title>Related Work</title><p id="P12">Transcriptomics data augmentation strategies vary in their approaches and effectiveness. One of the simplest methods is non-parametric random sampling with replacement [<xref ref-type="bibr" rid="R16">16</xref>]. While effective for constructing accurate classifiers [<xref ref-type="bibr" rid="R25">25</xref>], it lacks diversity in newly generated samples. To increase sample diversity, [<xref ref-type="bibr" rid="R26">26</xref>] proposed a weighted mixing of observations, inspired by the concept of mixing images [<xref ref-type="bibr" rid="R11">11</xref>]. Here, observations are multiplied by small random weights to create artificial samples. The advantage of this technique is that all observations contribute to the generation of new samples. However, assigning unique labels to such samples can be challenging, making this approach less suitable for supervised learning.</p><p id="P13">Parametric methods rely on population statistics and data models. The Poisson distribution is a widely used distribution to model RNA-Seq count data [<xref ref-type="bibr" rid="R15">15</xref>, <xref ref-type="bibr" rid="R27">27</xref>, <xref ref-type="bibr" rid="R28">28</xref>], but assumes equal variance and mean. This limits its effectiveness for count data with a large support [<xref ref-type="bibr" rid="R29">29</xref>] and fails to capture over-dispersion in the data. The negative binomial distribution, also known as the gamma-Poisson distribution, is another widely used distribution that captures the over-dispersion of RNA-Seq count data [<xref ref-type="bibr" rid="R30">30</xref>, <xref ref-type="bibr" rid="R31">31</xref>]. To solve class imbalance, augmenting transcripomic data using parametric methods requires class-specific parameter estimation. Challenges arise when the data distribution support is too large, leading to low data density in some regions and potentially generating uninformative data distributions. Conversely, limited support can result in insufficient sample diversity. Additionally, out-of-distribution data points can also impact parameter inference, rendering these methods sensitive to outliers and measurement errors [<xref ref-type="bibr" rid="R32">32</xref>].</p><p id="P14">Oversampling by interpolation is a popular method of augmenting biological data. Synthetic Minority Oversampling Technique (SMOTE) [<xref ref-type="bibr" rid="R24">24</xref>] and its variants [<xref ref-type="bibr" rid="R25">25</xref>, <xref ref-type="bibr" rid="R33">33</xref>, <xref ref-type="bibr" rid="R34">34</xref>, <xref ref-type="bibr" rid="R35">35</xref>, <xref ref-type="bibr" rid="R36">36</xref>, <xref ref-type="bibr" rid="R37">37</xref>] are prime examples of this sampling strategy. Primarily developed to target class imbalance, SMOTE generates a new sample on the line connecting a reference sample and a randomly chosen sample from its neighbourhood. This strategy has achieved state of the art performances on tasks affected by class imbalances. However, it has been found that for high-dimensional datasets SMOTE does not attenuate the bias towards the majority class [<xref ref-type="bibr" rid="R38">38</xref>]. Furthermore, when SMOTE is applied to high-dimensional data, it preserves the expected value of the minority class while decreasing its biological variability, which can be problematic for classifiers that rely on class-specific variances [<xref ref-type="bibr" rid="R38">38</xref>]. Moreover, SMOTE can be computationally demanding due to extensive pairwise distance calculations.</p><p id="P15">Alternative methods for data expansion include aggregation and the generation of synthetic samples <italic>in silico</italic> [<xref ref-type="bibr" rid="R39">39</xref>, <xref ref-type="bibr" rid="R40">40</xref>, <xref ref-type="bibr" rid="R41">41</xref>]. Generative adversarial network (GAN) [<xref ref-type="bibr" rid="R42">42</xref>] and its variants are used to create synthetic gene expression samples [<xref ref-type="bibr" rid="R43">43</xref>, <xref ref-type="bibr" rid="R44">44</xref>, <xref ref-type="bibr" rid="R45">45</xref>, <xref ref-type="bibr" rid="R26">26</xref>], but are computationally intensive, difficult to train, and require detailed knowledge about gene regulatory networks.</p><p id="P16">In contrast, our proposed signature-based crossover sampling approach is computationally efficient and requires no distribution parameter inference. It offers versatility for various scenarios, making it a promising addition to transcriptomic data augmentation methods.</p></sec><sec id="S3"><title>Proposed Augmentation Techniques</title><sec id="S4"><title>Crossover sampling</title><p id="P17">Inspired by chromosomal crossover during meiosis, phenotype-driven sampling aims to create new data points from existing data points while increasing diversity in the generated samples. Simply put, to generate new samples for a given phenotype, we leverage the high informativeness of the associated gene signatures for that particular phenotype, while assuming that the signatures for the other phenotypes in that sample are less informative for the given phenotype. We investigate two ways of augmenting the data samples: <list list-type="order" id="L2"><list-item><p id="P18">Crossing over between samples having the same phenotypic variant.</p></list-item><list-item><p id="P19">Crossing over between samples across all phenotypic variants.</p></list-item></list></p><p id="P20">In the following sections, we describe the details of our method and then illustrate its applicability to the gene expression of patients with colorectal cancer from TCGA as the data source.</p><sec id="S5"><title>Intra-class crossover sampling</title><p id="P21">To limit the likelihood of mixing phenotypes, and hence introducing samples of dubious labels, we first perform crossing over between samples belonging to the same phenotype. Thus, in this setting, new samples are generated only from samples having the same phenotype and so naturally, the synthetic sample inherits that phenotype. The crossing-over between samples is done at the gene signature level. Consider a dataset with n samples <italic>x<sub>i</sub></italic>, where <italic>i</italic> ∈ 1,…,<italic>n</italic>, and m phenotype variants <italic>P<sub>j</sub></italic>, where <italic>j</italic> ∈ 1, …, <italic>m</italic>. Each sample <italic>x<sub>i</sub></italic> is of one phenotype <italic>P<sub>j</sub></italic>. Given each variant <italic>P<sub>j</sub></italic> is associated with a gene signature <italic>S<sub>j</sub></italic>, we represent each sample by the set of signatures associated with all possible variants, that is, <italic>x<sub>i</sub></italic> = {<italic>S</italic>ι,…,<italic>S<sub>m</sub></italic>}. The number of genes in a signature is given by |<italic>S<sub>j</sub></italic>|. Therefore, each patient is represented by <inline-formula><mml:math id="M1"><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>∑</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:msubsup><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></inline-formula> genes. For the sake of simplicity, the genes are ordered by signature - all genes belonging to signature <italic>S</italic><sub>1</sub> come first and so on, thus creating signature blocks, one for each phenotypic variant. To generate a new sample, <italic>X</italic><sub><italic>n</italic> + 1</sub> with phenotype <italic>P</italic><sub><italic>j</italic>=1</sub>, we first subset all samples, belonging to this phenotype (<xref ref-type="disp-formula" rid="FD1">Equation 1</xref>). This subset, <italic>X</italic><sub><italic>j</italic>=1</sub>, is analogous to a bag of signature blocks (<xref ref-type="disp-formula" rid="FD2">Equation 2</xref>). <disp-formula id="FD1"><label>(1)</label><mml:math id="M2"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>:</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∀</mml:mo><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> <disp-formula id="FD2"><label>(2)</label><mml:math id="M3"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>:</mml:mo><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>∀</mml:mo><mml:mi>i</mml:mi><mml:mo>:</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p id="P22">We randomly sample signature blocks from this subset (<xref ref-type="disp-formula" rid="FD3">Equation 3</xref>) which are put together to create a new sample <italic>x</italic><sub><italic>n</italic> + 1</sub>. <disp-formula id="FD3"><label>(3)</label><mml:math id="M4"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mo>∈</mml:mo><mml:mi>R</mml:mi></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∀</mml:mo><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p id="P23">We illustrate a practical example on the gene expression of patients with colorectal cancer, using the Consensus Molecular Subtype (CMS) as phenotype. This phenotype has four variants, namely, CMS1, CMS2, CMS3, and CMS4 [<xref ref-type="bibr" rid="R46">46</xref>]. A study conducted in 2020 found a set of 10 genes that are highly predictive for each CMS class [<xref ref-type="bibr" rid="R47">47</xref>]. This greatly reduces the dimensionality of our gene expression dataset and gives us a panel of 40 genes that can be used for classifying patients into the 4 colorectal cancer subtypes. <xref ref-type="fig" rid="F1">Figure 1</xref> illustrates the process of intra-class crossover sampling. Consider an ordered gene matrix where the patients and the genes are sorted according to their CMS class. To generate a new CMS1 sample, we first consider the subset of all CMS1 patients (highlighted by a red rectangle in <xref ref-type="fig" rid="F1">Figure 1</xref>). To create a new CMS1 sample, we randomly and sequentially sample one gene signature block represented by the blue, yellow, green, and orange columns, each comprising genes predictive of the CMS1, CMS2, CMS3, and CMS4 classes.</p><p id="P24">Since we are sampling the blocks only from the subset of patients belonging to CMS1, the expression values of genes associated with the other CMS types are typical of what is observed in a CMS1 patient. Thus, we minimise the likelihood of creating ambiguous samples where the combined expression values indicate a different CMS than the one assigned. This process is repeated for the other CMS types, that is, a CMS2 patient is sampled only from the subset of patients belonging to CMS2, and so on.</p></sec><sec id="S6"><title>Inter-class crossover sampling</title><p id="P25">Inter-class crossover sampling aims at utilising the entire dataset to create new samples, as opposed to just the phenotype specific subset in intra-class crossover sampling. In this method, we investigate the effect of sampling signature blocks across all samples as opposed to just a subset of samples. To avoid ambiguous labels, we add a constraint that prevents sampling the defining signature block from a sample unless it belongs to the phenotype to be sampled. To formalise this, consider a similar premise as the one described in subsubsection 3.1.1. To generate a synthetic sample of phenotype <italic>P</italic><sub><italic>j</italic>=1</sub>, we sample <italic>S</italic><sub><italic>j</italic> = 1</sub> only from the subset of patients, <italic>X</italic><sub><italic>j</italic>=1</sub>, that have phenotype <italic>P</italic><sub><italic>j</italic> = 1</sub>, that is. <italic>S</italic><sub><italic>j</italic></sub> ∈<sub><italic>R</italic></sub> <italic>X<sub>j</sub></italic>. We then randomly sample the remainder signatures <italic>S<sub>k</sub></italic> for <italic>k</italic> ∈ 1, …, <italic>m</italic> and <italic>k</italic> ≠ <italic>j</italic>, from all samples except those that belong to phenotype <italic>P<sub>k</sub></italic> as described in <xref ref-type="disp-formula" rid="FD4">Equation 4</xref>. The sampled signatures are then put together to create a new synthetic sample, <italic>x</italic><sub><italic>n</italic> + 1</sub> = {<italic>S<sub>j</sub></italic>, <italic>S<sub>k</sub></italic>} for <italic>k</italic> ∈ 1,…,<italic>m</italic> and <italic>k</italic> = <italic>j</italic> and where <italic>j</italic> = 1. <disp-formula id="FD4"><label>(4)</label><mml:math id="M5"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mo>∈</mml:mo><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mspace width="0.2em"/><mml:mo>∀</mml:mo><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mspace width="0.2em"/><mml:mtext>and</mml:mtext><mml:mspace width="0.2em"/><mml:mi>k</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:math></disp-formula></p><p id="P26">This method is illustrated in <xref ref-type="fig" rid="F2">Figure 2</xref> in the context of CMS classes. When creating a CMS1 sample, the CMS1 gene block has to come from the set of patients belonging to CMS1, as this generates expression values typical of a patient with CMS1. However, the CMS2 block can come from all patients except those belonging to CMS2, since the expression values are in a range that is not predictive of CMS2. If it comes from a CMS2 patient, then the class label of the new sample being generated would have multiple labels, namely CMS1 and CMS2. Due to this ambiguity in label assignment, we avoid sampling the CMS2-associated gene block from a CMS2 patient. Similarly, the CMS3- and CMS4-associated gene blocks can come from all patients except those belonging to the CMS3 and CMS4 classes respectively.</p></sec></sec><sec id="S7"><title>Modified gamma-Poisson sampling</title><p id="P27">The negative-binomial (NB) distribution is a commonly used parametric method for augmenting RNA-Seq data for differential expression analysis due to it’s ability to capture the overdispersion typically seen in these data. To model the RNA-Seq read frequency <italic>Y</italic> of a given gene <italic>j</italic>, the distribution relies on two parameters, namely the mean and dispersion of the counts, i.e, <italic>Y<sub>j</sub></italic> = NB(<italic>μ<sub>j</sub>, ϕ</italic>).</p><p id="P28">Here, <italic>φ</italic> is the dispersion parameter that controls the variance of the counts, <inline-formula><mml:math id="M6"><mml:mrow><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>ϕ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>. The estimation of <italic>ϕ</italic> is, however, not trivial. The negativebinomial (NB) distribution is typically expressed as a gamma-Poisson mixture [<xref ref-type="bibr" rid="R48">48</xref>, <xref ref-type="bibr" rid="R49">49</xref>] to make it more tractable. In this formulation, the rate parameter <italic>λ</italic> of the Poisson distribution is a random variable sampled from a gamma distribution parameterised by the shape (<italic>α</italic>) and rate (<italic>β</italic>) parameters, which are estimated from the observed population, <italic>λ</italic> ~ Γ(<italic>α,β</italic>). The RNA-Seq read counts are then sampled from this initialised Poisson distribution, <italic>Y<sub>j</sub></italic> ~ <italic>Poisson</italic>(<italic>λ<sub>j</sub></italic>).</p><p id="P29">To ensure that the newly generated samples add some diversity while maintaining the same distribution as the augmented class, we create a mixture of gamma-Poisson distributions. In this strategy, to generate every new observation, a subset <italic>S</italic> of samples is randomly chosen to estimate the <italic>α</italic> and <italic>β</italic> parameters from its mean <italic>μ</italic> and variance <italic>σ</italic><sup>2</sup> as shown in <xref ref-type="disp-formula" rid="FD5">Equation 5</xref>. These parameters initialise the gamma distribution. Since the augmentation is aimed at solving class imbalance, the subset is created from samples belonging to the same class. Thus, the newly generated observation will have the same label as the subset. The size of the subset |<italic>S</italic>| is a hyperparameter defined by the user. The random variable sampled from this gamma distribution is used to initialise the Poisson distribution from which a new observation is sampled. This process is repeated <italic>n</italic> times to generate <italic>n</italic> new observations. We recommend a smaller subset size to maximise the variance in the subset. A larger variance would mean more scattered observations, thereby generating a diverse set of samples as opposed to dense local clusters with a smaller variance. <disp-formula id="FD5"><label>(5)</label><mml:math id="M7"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mi>∑</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mspace width="0.2em"/><mml:mo>∈</mml:mo><mml:mspace width="0.2em"/><mml:mi>S</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mi>∑</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:mi>μ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>μ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mi>μ</mml:mi><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p></sec><sec id="S8"><title>Modified Poisson sampling</title><p id="P30">The Poisson distribution is another method commonly used to model RNA-Seq read counts. Similarly to the gamma-Poisson strategy, a subset is first sampled from the class to be augmented, after which the mean is computed and set as the rate parameter λ for the Poisson distribution as shown in <xref ref-type="disp-formula" rid="FD6">Equation 6</xref>. <disp-formula id="FD6"><label>(6)</label><mml:math id="M8"><mml:mrow><mml:mtext>λ</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mi>∑</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mspace width="0.2em"/><mml:mi>S</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.2em"/><mml:mspace width="0.2em"/><mml:mspace width="0.2em"/><mml:mspace width="0.2em"/><mml:msub><mml:mi>Y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>~</mml:mo><mml:mi>P</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mtext>λ</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p id="P31">However, unlike the gamma-Poisson, this distribution assumes the variance of the sample equals the mean and fails to capture overdispersion in the data. To generate new observations with this method, a larger subset size is recommended such that the variance is closer to the mean while still being high enough to generate variability in the new data.</p></sec></sec><sec id="S9" sec-type="materials | methods"><title>Materials and Methods</title><sec id="S10"><title>Datasets</title><p id="P32">TCGA COADRED (Colon Adenocarcinoma and Rectal Adenocarcinoma)[<xref ref-type="bibr" rid="R50">50</xref>] and CPTAC[<xref ref-type="bibr" rid="R51">51</xref>] are used for all experiments. TCGA COADREAD is designated for training and in-domain testing, while the CPTAC Colon Cancer gene expression data are used for external validation. As an initial preprocessing step, we filter out replicates and only consider patients with primary tumours and available CMS labels. Summary of the class counts of the datasets are shown in <xref ref-type="table" rid="T1">Table 1</xref>. Additionally, since we are interested in colorectal cancer subtyping, we only consider the 40 signature genes of the subtypes [<xref ref-type="bibr" rid="R47">47</xref>]. Details on dataset creation are described in Supplementary A.3.</p></sec><sec id="S11"><title>Models</title><p id="P33">For all discriminative tasks, we consider 6 different classifiers, namely, Logistic Regression (LR), K-Nearest Neighbours (KNN), Support Vector Machines with RBF kernel (SVM), Explainable Boosting Machines (EBM), Random Forests (RF) and Multi-Layer Perceptron (MLP). For the generative tasks, we consider a variational autoencoder [<xref ref-type="bibr" rid="R52">52</xref>]. Implementation details for the discriminative and generative experiments are in Supplementary A.4 and A.5, respectively.</p></sec><sec id="S12"><title>Evaluation Criteria</title><p id="P34">We report the balanced accuracy (Equation 7) for the discriminative tasks as it takes into account both the sensitivity and specificity of the model, and is particularly useful when dealing with imbalanced datasets. If the support samples for each class exhibit sufficient and meaningful diversity, the performance of a standard classification model is expected to outperform one trained on the unbalanced dataset. In the generative tasks, we evaluate the latent embeddings in terms of cluster purity (Equation 8), a K-means based metric that quantifies the homogeneity of clusters. The basis for this metric is that high quality latent embeddings will effectively separate data into distinct clusters. We perform a 5-fold stratified cross-validation repeated 5 times for each augmentation method and augmentation size. Performance metrics are reported as the average across all splits.</p></sec></sec><sec id="S13" sec-type="results | discussions"><title>Results and Discussions</title><sec id="S14"><title>Tuning the parametric sample set size</title><p id="P35">As described in section 3, the gamma-Poisson and Poisson methods require a sample set <italic>S</italic> of a predefined size <italic>r</italic> = |<italic>S</italic>| from which parameters are estimated and a new sample is generated. To set the hyperparameter <italic>r</italic> for the gamma-Poisson method, we explore a range of values and select the optimal size by testing the average performance of the augmented dataset in the CMS prediction task across various classification models (Supplementary A.2). On average, we find <italic>r</italic> = 5 to be the optimal value across all models (<xref ref-type="supplementary-material" rid="SD1">Supplementary Figure 6</xref>). For the modified Poisson sampling, we double the sample size to <italic>r</italic> = 10 to help mitigate the effects of over-dispersion while still ensuring diversity in terms of variability in the newly generated samples (<xref ref-type="supplementary-material" rid="SD1">Supplementary Figure 7</xref>).</p></sec><sec id="S15"><title>Visualising the augmented data</title><p id="P36">A qualitative assessment of the augmentation methods in capturing trends in the data is shown in <xref ref-type="fig" rid="F3">Figure 3</xref>. We report the results for class size 5000, as the trends are more evident due to the large size. Similar trends are observed in smaller class sizes although less distinctly (<xref ref-type="supplementary-material" rid="SD1">Supplementary Figure 4, Figure 5</xref>). Visually, both our crossover and gamma-Poisson sampling strategies capture data trends better than the other methods. We find that the intra-class crossover, inter-class crossover and gamma-Poisson sampling methods (<xref ref-type="fig" rid="F3">Figure 3B,C,D</xref>) best capture both the global and local structure of the original unbalanced data <xref ref-type="fig" rid="F3">Figure 3A</xref>. The real and synthetic samples are interspersed with the newly generated samples and in general, the synthetic samples appear well distributed over the latent space. The Poisson sampled data (<xref ref-type="fig" rid="F3">Figure 3E</xref>) form unique clusters for each subtype, whereas in the unbalanced data visualisation <xref ref-type="fig" rid="F3">Figure 3A</xref>, we see mixing of samples between clusters. These points could potentially correspond to samples of a mixed subtype or shared transcriptional states, which the data augmented by the Poisson distribution does not reflect. The data augmented by SMOTE are generated by interpolating between reference samples in close proximity to each other, and therefore fail to occupy the input space evenly, as shown in the inset of <xref ref-type="fig" rid="F3">Figure 3F</xref>.</p><p id="P37">Discriminative modeling of augmented data We conduct quantitative experiments to determine if our data augmentation is representative of the original data and contributes to improving the accuracy on downstream tasks. The aim of this task is to predict the colorectal cancer subtype (CMS), which is challenging due to high class imbalance in the data (<xref ref-type="table" rid="T1">Table 1</xref>). We use the 6 data augmentation methods described in Section A.3 to balance classes during training, and evaluate various augmentation sizes (subsection 4.1) using the classifiers mentioned in subsection 4.2.</p><p id="P38">The results of this experiment are reported in <xref ref-type="table" rid="T2">Table 2</xref> for three types of classifiers, namely SVM, EBM and RF, and in <xref ref-type="supplementary-material" rid="SD1">Supplementary Table 7</xref> for the rest. While training on gamma-Poisson augmented data improves in-domain test performance, training on the inter-class crossover augmented data enables the models to generalise better to the CPTAC external dataset. Interestingly, as the class size increases, the in-domain performance associated with both cross-over methods decreases, whereas the performance on the external dataset increases. This suggests that the crossover methods generate new samples that are <italic>out-of-distribution</italic> with respect to the given dataset, which in turn provide better support for learning a robust decision boundary. Moreover, with the inter-class crossover method, augmenting only the minority classes (class size “Max”) is sufficient for an in-domain performance that is as good as that with the gamma-Poisson at higher class sizes. For instance, the SVM achieves a balanced accuracy score of 89.6% for data augmented to class size “Max” by the by inter-class crossover method, whereas the modified gamma-Poisson needs to generate more data for the SVM to achieve similar performances — 90.1% at class size 500 and 89.7% at class size 5000. Therefore, inter-class crossover proves to be a suitable method for oversampling minority classes in in-domain data. It creates a variety of samples that allow models to learn robust decision boundaries, which can generalize well to external data, particularly when augmentation sizes are increased.</p></sec><sec id="S16"><title>Generative modeling of augmented data</title><p id="P39">We now consider generative modeling and evaluate how effectively the augmented data contributes to estimating a parametric representation of the data. We expect greater diversity in the input samples to lead to more accurate parametric estimates of the latent space distribution.</p><p id="P40">We train a variational autoencoder (VAE) on the augmented data with the ELBO loss as the objective [<xref ref-type="bibr" rid="R52">52</xref>] to learn a compressed 4-D representation of the data. The cluster purity of the test data in the latent space is reported in <xref ref-type="table" rid="T3">Table 3</xref>. We observe that the inter-class crossover method has the highest cluster purity score for both TCGA and CPTAC. When data is augmented to a class size of 5000, it leads to significantly better (p-value]0.02) performance than modified gammaPoisson, modified Poisson, SMOTE and unbalanced datasets. The modified Poisson method is associated with the best performance at lower class sizes but it is only significantly better for TCGA data with class size 500 (p-value] 0.05). The performance of modified Poisson can be explained by its tendency to create distinct clusters (<xref ref-type="fig" rid="F3">Figure 3</xref>, <xref ref-type="supplementary-material" rid="SD1">Figure 5 and Figure 4</xref>), which are, however, not reflective of the original distribution. When increasing in the class size, the method generates artefacts that cause the drop in latent cluster purity, suggesting lower embedding quality. Conversely, the inter-class crossover method consistently maintains a high performance on both TCGA and CPTAC data across all augmentation sizes. This shows that our data augmentation method facilitates the learning of a latent space with high fidelity to the original data.</p><p id="P41">Next, we investigate if the learned 4-D compression of the data is informative for the prediction of MSI, CIMP and OS, which are key clinical variables of colorectal cancer phenotypes. Predicting these variables, among others such as demographic factors, genomic markers and treatment response, is relevant for patient prognostics, disease monitoring and disease subtyping. Here, we discuss explicitly MSI and CIMP prediction, and report the survival analysis task results in Supplementary subsubsection A.5.1. The implementation details of all tasks are also described in Supplementary A.5.</p><sec id="S17"><title>Predicting MSI</title><p id="P42">MSI is a valuable marker for prognosis [<xref ref-type="bibr" rid="R54">54</xref>, <xref ref-type="bibr" rid="R55">55</xref>], treatment choice [<xref ref-type="bibr" rid="R56">56</xref>, <xref ref-type="bibr" rid="R57">57</xref>] and colorectal cancer subtyping. CMS1 shows a high level of microsatellite instability (MSI-H), whereas CMS2 and CMS4 are microsatellite stable. CMS3, on the other hand, shows a mixed MSI status (MSI-Low). We train both an SVM and an EBM to predict the MSI status from the 4D latent embeddings of the VAE models.</p><p id="P43">The balanced accuracy from a 5-fold stratified 5 times repeated cross-validation for the class size ‘5000’ setting is reported in <xref ref-type="table" rid="T4">Table 4</xref>. All the SVM models – except for those trained on SMOTE – achieved comparable balanced accuracy in both in-domain and external validation. Resamplingbased augmentation led to the highest average balanced accuracy (57% on TCGA and 89% on CPTAC). Nonetheless, both crossover methods, the modified gamma-Poisson, and modified Poisson models, resulted in accuracies that fell within the confidence interval of this method. Particularly, the inter-class crossover method is associated with a better external performance (88.9%), which is significantly better than the one obtained on the gamma-Poisson (p-value = 0.002), Poisson (p-value = 0.01), SMOTE (p-value = 2.98e-8) and unbalanced (p-value = 0.0008) datasets. Interestingly, SMOTE-derived representations deteriorate in quality as the augmentation class size increases. In the case of “Max” class size, they provide a strong signal resulting in on-par performance with the other models (<xref ref-type="supplementary-material" rid="SD1">Supplementary Table 11</xref>. As the augmentation class size increases, the performance with SMOTE-augmented data drops significantly (<xref ref-type="supplementary-material" rid="SD1">Supplementary Table 11</xref>).</p><p id="P44">With the EBMs, the crossover methods perform better than the other augmentation methods in terms of averaged balanced accuracy. As before, all models but those trained with SMOTE achieve statistically similar accuracies on in-domain TCGA data. On external data, however, both cross-over methods lead to significantly better performance than the rest, showing that these data augmentation methods foster model generalisation. As seen with SVMs, SMOTE-derived models perform poorly as they are trained on larger class sizes(<xref ref-type="supplementary-material" rid="SD1">Supplementary Table 11</xref>). In addition to reporting the balanced accuracy, we use the global explanation feature of EBMs to understand which features contributed the most to the predictions. The results are discussed in subsubsection A.5.2.</p></sec><sec id="S18"><title>Predicting CIMP</title><p id="P45">The CIMP status is not only useful in characterising the subtypes of colorectal cancer but also in predicting response to therapy [<xref ref-type="bibr" rid="R58">58</xref>, <xref ref-type="bibr" rid="R59">59</xref>]. For example, CMS1 shows a high level of CpG Island Methylator Phenotype (CIMP.High). CMS2 and CMS4 on the other hand are negative for CpG Island Methylator Phenotype (CIMP.Neg), and CMS3 shows a low level of CIMP (CIMP.Low) [<xref ref-type="bibr" rid="R46">46</xref>, <xref ref-type="bibr" rid="R60">60</xref>]. We perform similar experiments as with the MSI, and report the balanced accuracy from a 5-fold stratified 5 times repeated cross-validation for the class size ‘5000’ setting in <xref ref-type="table" rid="T4">Table 4</xref>. As the CIMP status is not available for patients in the CPTAC cohort, we omit the external validation. Results on the TCGA test set are in favour of the inter-class crossover method, which leads to a significantly better SVM performance than intra-class crossover (p-value=0.006), gamma-Poisson (p-value = 0.0005), Poisson (p-value = 0.0008), SMOTE (p-value = 2.98e-8), resampling (p-value = 0.0006) augmentation methods and unbalanced data (p-value = 2.08e-6). With the EBM, our inter-class crossover augmentation method is significantly better than Poisson (p-value = 0.009), SMOTE (2.98e-8) and unbalanced (0.007). Similar to the findings from the MSI experiment, SMOTE-augmented representations perform the worst. This reinforces our understanding that the good performances attained with SMOTE are limited to minority oversampling, and do not extend to oversampling all classes. Results for CIMP prediction for all class sizes are reported in <xref ref-type="supplementary-material" rid="SD1">Supplementary Table 10</xref>.</p></sec></sec></sec><sec id="S19" sec-type="conclusions"><title>Conclusion</title><p id="P46">We introduced a novel method for augmenting transcriptomic data using chromosomal crossover, which demands minimal computational resources. When distinct gene signatures represent target phenotypes, our approach allows us to generate synthetic data by sampling values across patients while adhering to specific phenotypic constraints.</p><p id="P47">Results show that the augmented datasets obtained by our method not only reflect biological variability but also enhance model robustness against overfitting and distribution shifts. The effectiveness of our approach is demonstrated by the higher performances on the classification experiments on TCGA COADREAD, and CPTAC COAD. Our data augmentation approaches, including the modified gamma-Poisson, excel in generalisation and were in most experiments superior to popular methods like SMOTE.</p><p id="P48">A limitation of the intra- and inter-class crossover approaches is the reliance on non-overlapping gene signatures predictive of each phenotype. This can be overcome, however, also in research areas lacking established signatures, by preliminary feature selection analyses that can identify distinct phenotype-predictive gene sets.</p><p id="P49">We envision extending our approach to gene signatures with correlated genes, as classifiers can disentangle existing correlations. Although augmenting datasets with correlated classes may introduce challenges, we intend to explore this further in future work. Additionally, we plan to investigate the impact of our method when applied to the entire genome without phenotype conditioning. This entails dividing the genome into chunks and performing crossovers. We expect potential spurious correlations and signal corruption.</p><p id="P50">Despite these limitations, our sampling methods hold promise for heterogeneity studies, particularly in disease analysis. By cross-mixing samples, we create a landscape of mixed phenotypes, the diversity of which depends on the dataset size, and offers potential applications in unsupervised or semisupervised learning given fully unlabeled data.</p></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary Material</label><media xlink:href="EMS190456-supplement-Supplementary_Material.pdf" mimetype="application" mime-subtype="pdf" id="d31aAdGbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S20"><title>Acknowledgments</title><p>This work is supported by funds from the Swiss National Science Foundation (Sinergia CRSII5_193832). The results shown here are in whole or part based upon data generated by the TCGA Research Network: <ext-link ext-link-type="uri" xlink:href="https://www.cancer.gov/tcga">https://www.cancer.gov/tcga</ext-link>. Data used in this publication were generated by the Clinical Proteomic Tumor Analysis Consortium (NCI/NIH).</p></ack><sec id="S21" sec-type="data-availability"><title>Data and Code availability</title><p id="P51">The code is hosted at <ext-link ext-link-type="uri" xlink:href="https://github.com/PaccMann/transcriptomic_signature_sampling">https://github.com/PaccMann/transcriptomic_signature_sampling</ext-link>, and includes a link to the augmented datasets for reproducibility.</p></sec><fn-group><fn id="FN1" fn-type="con"><p id="P52">Author contributions statement</p><p id="P53">N.J. and M.G. conceived the experiments, N.J. conducted the experiments, N.J created visualisations and summarised results, N.J. and M.G analysed the results, N.J., M.G. and M.R.M wrote and reviewed the manuscript.</p></fn></fn-group><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rajkomar</surname><given-names>Alvin</given-names></name><name><surname>Dean</surname><given-names>Jeffrey</given-names></name><name><surname>Kohane</surname><given-names>Isaac</given-names></name></person-group><article-title>Machine learning in medicine</article-title><source>New England Journal of Medicine</source><year>2019</year><volume>380</volume><issue>14</issue><fpage>1347</fpage><lpage>1358</lpage><pub-id pub-id-type="pmid">30943338</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mamoshina</surname><given-names>Polina</given-names></name><name><surname>Vieira</surname><given-names>Armando</given-names></name><name><surname>Putin</surname><given-names>Evgeny</given-names></name><name><surname>Zhavoronkov</surname><given-names>Alex</given-names></name></person-group><article-title>Applications of deep learning in biomedicine</article-title><source>Molecular pharmaceutics</source><year>2016</year><volume>13</volume><issue>5</issue><fpage>1445</fpage><lpage>1454</lpage><pub-id pub-id-type="pmid">27007977</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dudoit</surname><given-names>Sandrine</given-names></name><name><surname>Fridlyand</surname><given-names>Jane</given-names></name><name><surname>Speed</surname><given-names>Terence P</given-names></name></person-group><article-title>Comparison of discrimination methods for the classification of tumors using gene expression data</article-title><source>Journal of the American statistical association</source><year>2002</year><volume>97</volume><issue>457</issue><fpage>77</fpage><lpage>87</lpage></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hastie</surname><given-names>Trevor</given-names></name><name><surname>Tibshirani</surname><given-names>Robert</given-names></name><name><surname>Friedman</surname><given-names>Jerome H</given-names></name><name><surname>Friedman</surname><given-names>Jerome H</given-names></name></person-group><source>The elements of statistical learning: data mining, inference, and prediction</source><publisher-name>Springer</publisher-name><year>2009</year><volume>2</volume></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sugiyama</surname><given-names>Masashi</given-names></name><name><surname>Kawanabe</surname><given-names>Motoaki</given-names></name></person-group><source>Machine learning in non-stationary environments: Introduction to covariate shift adaptation</source><publisher-name>MIT press</publisher-name><year>2012</year></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dash</surname><given-names>Manoranjan</given-names></name><name><surname>Liu</surname><given-names>Huan</given-names></name></person-group><article-title>Feature selection for classification</article-title><source>Intelligent data analysis</source><year>1997</year><volume>1</volume><issue>1–4</issue><fpage>131</fpage><lpage>156</lpage></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saeys</surname><given-names>Yvan</given-names></name><name><surname>Inza</surname><given-names>Inaki</given-names></name><name><surname>Larranaga</surname><given-names>Pedro</given-names></name></person-group><article-title>A review of feature selection techniques in bioinformatics</article-title><source>bioinformatics</source><year>2007</year><volume>23</volume><issue>19</issue><fpage>2507</fpage><lpage>2517</lpage><pub-id pub-id-type="pmid">17720704</pub-id></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Jolliffe</surname><given-names>Ian T</given-names></name></person-group><source>Principal component analysis for special types of data</source><publisher-name>Springer</publisher-name><year>2002</year></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>Daniel D</given-names></name><name><surname>Seung</surname><given-names>H Sebastian</given-names></name></person-group><article-title>Learning the parts of objects by non-negative matrix factorization</article-title><source>Nature</source><year>1999</year><volume>401</volume><issue>6755</issue><fpage>788</fpage><lpage>791</lpage><pub-id pub-id-type="pmid">10548103</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hinton</surname><given-names>Geoffrey E</given-names></name><name><surname>Salakhutdinov</surname><given-names>Ruslan R</given-names></name></person-group><article-title>Reducing the dimensionality of data with neural networks</article-title><source>science</source><year>2006</year><volume>313</volume><issue>5786</issue><fpage>504</fpage><lpage>507</lpage><pub-id pub-id-type="pmid">16873662</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shorten</surname><given-names>Connor</given-names></name><name><surname>Khoshgoftaar</surname><given-names>Taghi M</given-names></name></person-group><article-title>A survey on image data augmentation for deep learning</article-title><source>Journal of big data</source><year>2019</year><volume>6</volume><issue>1</issue><fpage>1</fpage><lpage>48</lpage><pub-id pub-id-type="pmcid">PMC8287113</pub-id><pub-id pub-id-type="pmid">34306963</pub-id><pub-id pub-id-type="doi">10.1186/s40537-021-00492-0</pub-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chlap</surname><given-names>Phillip</given-names></name><name><surname>Min</surname><given-names>Hang</given-names></name><name><surname>Vandenberg</surname><given-names>Nym</given-names></name><name><surname>Dowling</surname><given-names>Jason</given-names></name><name><surname>Holloway</surname><given-names>Lois</given-names></name><name><surname>Haworth</surname><given-names>Annette</given-names></name></person-group><article-title>A review of medical image data augmentation techniques for deep learning applications</article-title><source>Journal of Medical Imaging and Radiation Oncology</source><year>2021</year><volume>65</volume><issue>5</issue><fpage>545</fpage><lpage>563</lpage><pub-id pub-id-type="pmid">34145766</pub-id></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bishop</surname><given-names>Christopher M</given-names></name><etal/></person-group><source>Neural networks for pattern recognition</source><publisher-name>Oxford university press</publisher-name><year>1995</year></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anders</surname><given-names>Simon</given-names></name><name><surname>Huber</surname><given-names>Wolfgang</given-names></name></person-group><article-title>Differential expression analysis for sequence count data</article-title><source>Nature Precedings</source><year>2010</year><comment>1-1</comment><pub-id pub-id-type="pmcid">PMC3218662</pub-id><pub-id pub-id-type="pmid">20979621</pub-id><pub-id pub-id-type="doi">10.1186/gb-2010-11-10-r106</pub-id></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marioni</surname><given-names>John C</given-names></name><name><surname>Mason</surname><given-names>Christopher E</given-names></name><name><surname>Mane</surname><given-names>Shrikant M</given-names></name><name><surname>Stephens</surname><given-names>Matthew</given-names></name><name><surname>Gilad</surname><given-names>Yoav</given-names></name></person-group><article-title>Rna-seq: an assessment of technical reproducibility and comparison with gene expression arrays</article-title><source>Genome research</source><year>2008</year><volume>18</volume><issue>9</issue><fpage>1509</fpage><lpage>1517</lpage><pub-id pub-id-type="pmcid">PMC2527709</pub-id><pub-id pub-id-type="pmid">18550803</pub-id><pub-id pub-id-type="doi">10.1101/gr.079558.108</pub-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Efron</surname><given-names>Bradley</given-names></name><name><surname>Tibshirani</surname><given-names>Robert J</given-names></name></person-group><source>An introduction to the bootstrap</source><publisher-name>CRC press</publisher-name><year>1994</year></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Japkowicz</surname><given-names>Nathalie</given-names></name><name><surname>Stephen</surname><given-names>Shaju</given-names></name></person-group><article-title>The class imbalance problem: A systematic study</article-title><source>Intelligent data analysis</source><year>2002</year><volume>6</volume><issue>5</issue><fpage>429</fpage><lpage>449</lpage></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Branco</surname><given-names>Paula</given-names></name><name><surname>Torgo</surname><given-names>Luis</given-names></name><name><surname>Ribeiro</surname><given-names>Rita P</given-names></name></person-group><article-title>A survey of predictive modeling on imbalanced domains</article-title><source>ACM computing surveys (CSUR)</source><year>2016</year><volume>49</volume><issue>2</issue><fpage>1</fpage><lpage>50</lpage></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yersal</surname><given-names>Ozlem</given-names></name><name><surname>Barutca</surname><given-names>Sabri</given-names></name></person-group><article-title>Biological subtypes of breast cancer: Prognostic and therapeutic implications</article-title><source>World journal of clinical oncology</source><year>2014</year><volume>5</volume><issue>3</issue><fpage>412</fpage><pub-id pub-id-type="pmcid">PMC4127612</pub-id><pub-id pub-id-type="pmid">25114856</pub-id><pub-id pub-id-type="doi">10.5306/wjco.v5.i3.412</pub-id></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rodriguez-Salas</surname><given-names>Nuria</given-names></name><name><surname>Dominguez</surname><given-names>Gema</given-names></name><name><surname>Barderas</surname><given-names>Rodrigo</given-names></name><name><surname>Mendiola</surname><given-names>Marta</given-names></name><name><surname>Garcéa-Albéniz</surname><given-names>Xabier</given-names></name><name><surname>Maurel</surname><given-names>Juan</given-names></name><name><surname>Batlle</surname><given-names>Jaime Feliu</given-names></name></person-group><article-title>Clinical relevance of colorectal cancer molecular subtypes</article-title><source>Critical reviews in oncology/hematology</source><year>2017</year><volume>109</volume><fpage>9</fpage><lpage>19</lpage><pub-id pub-id-type="pmid">28010901</pub-id></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>Xu</given-names></name><name><surname>Hu</surname><given-names>Kai</given-names></name><name><surname>Bailey</surname><given-names>Peter</given-names></name><name><surname>Springfeld</surname><given-names>Christoph</given-names></name><name><surname>Roth</surname><given-names>Susanne</given-names></name><name><surname>Kurilov</surname><given-names>Roma</given-names></name><name><surname>Brors</surname><given-names>Benedikt</given-names></name><name><surname>Gress</surname><given-names>Thomas</given-names></name><name><surname>Buchholz</surname><given-names>Malte</given-names></name><name><surname>An</surname><given-names>Jingyu</given-names></name><etal/></person-group><article-title>Clinical impact of molecular subtyping of pancreatic cancer</article-title><source>Frontiers in cell and developmental biology</source><year>2021</year><volume>9</volume><elocation-id>743908</elocation-id><pub-id pub-id-type="pmcid">PMC8603393</pub-id><pub-id pub-id-type="pmid">34805152</pub-id><pub-id pub-id-type="doi">10.3389/fcell.2021.743908</pub-id></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Golub</surname><given-names>Todd R</given-names></name><name><surname>Slonim</surname><given-names>Donna K</given-names></name><name><surname>Tamayo</surname><given-names>Pablo</given-names></name><name><surname>Huard</surname><given-names>Christine</given-names></name><name><surname>Gaasenbeek</surname><given-names>Michelle</given-names></name><name><surname>Mesirov</surname><given-names>Jill P</given-names></name><name><surname>Coller</surname><given-names>Hilary</given-names></name><name><surname>Loh</surname><given-names>Mignon L</given-names></name><name><surname>Downing</surname><given-names>James R</given-names></name><name><surname>Caligiuri</surname><given-names>Mark A</given-names></name><etal/></person-group><article-title>Molecular classification of cancer: class discovery and class prediction by gene expression monitoring</article-title><source>science</source><year>1999</year><volume>286</volume><issue>5439</issue><fpage>531</fpage><lpage>537</lpage><pub-id pub-id-type="pmid">10521349</pub-id></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Su</surname><given-names>Andrew I</given-names></name><name><surname>Welsh</surname><given-names>John B</given-names></name><name><surname>Sapinoso</surname><given-names>Lisa M</given-names></name><name><surname>Kern</surname><given-names>Suzanne G</given-names></name><name><surname>Dimitrov</surname><given-names>Petre</given-names></name><name><surname>Lapp</surname><given-names>Hilmar</given-names></name><name><surname>Schultz</surname><given-names>Peter G</given-names></name><name><surname>Powell</surname><given-names>Steven M</given-names></name><name><surname>Moskaluk</surname><given-names>Christopher A</given-names></name><name><surname>Frierson</surname><given-names>Henry F</given-names><suffix>Jr</suffix></name><etal/></person-group><article-title>Molecular classification of human carcinomas by use of gene expression signatures</article-title><source>Cancer research</source><year>2001</year><volume>61</volume><issue>20</issue><fpage>7388</fpage><lpage>7393</lpage><pub-id pub-id-type="pmid">11606367</pub-id></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chawla</surname><given-names>Nitesh V</given-names></name><name><surname>Bowyer</surname><given-names>Kevin W</given-names></name><name><surname>Hall</surname><given-names>Lawrence O</given-names></name><name><surname>Kegelmeyer</surname><given-names>W Philip</given-names></name></person-group><article-title>Smote: synthetic minority over-sampling technique</article-title><source>Journal of artificial intelligence research</source><year>2002</year><volume>16</volume><fpage>321</fpage><lpage>357</lpage></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Batista</surname><given-names>Gustavo EAPA</given-names></name><name><surname>Prati</surname><given-names>Ronaldo C</given-names></name><name><surname>Monard</surname><given-names>Maria Carolina</given-names></name></person-group><article-title>A study of the behavior of several methods for balancing machine learning training data</article-title><source>ACM SIGKDD explorations newsletter</source><year>2004</year><volume>6</volume><issue>1</issue><fpage>20</fpage><lpage>29</lpage></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kircher</surname><given-names>Magdalena</given-names></name><name><surname>Chludzinski</surname><given-names>Elisa</given-names></name><name><surname>Krepel</surname><given-names>Jessica</given-names></name><name><surname>Saremi</surname><given-names>Babak</given-names></name><name><surname>Beineke</surname><given-names>Andreas</given-names></name><name><surname>Jung</surname><given-names>Klaus</given-names></name></person-group><article-title>Augmentation of transcriptomic data for improved classification of patients with respiratory diseases of viral origin</article-title><source>International journal of molecular sciences</source><year>2022</year><volume>23</volume><issue>5</issue><fpage>2481</fpage><pub-id pub-id-type="pmcid">PMC8910329</pub-id><pub-id pub-id-type="pmid">35269624</pub-id><pub-id pub-id-type="doi">10.3390/ijms23052481</pub-id></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bullard</surname><given-names>James H</given-names></name><name><surname>Purdom</surname><given-names>Elizabeth</given-names></name><name><surname>Hansen</surname><given-names>Kasper D</given-names></name><name><surname>Dudoit</surname><given-names>Sandrine</given-names></name></person-group><article-title>Evaluation of statistical methods for normalization and differential expression in mrna-seq experiments</article-title><source>BMC bioinformatics</source><year>2010</year><volume>11</volume><issue>1</issue><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="pmcid">PMC2838869</pub-id><pub-id pub-id-type="pmid">20167110</pub-id><pub-id pub-id-type="doi">10.1186/1471-2105-11-94</pub-id></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Likun</given-names></name><name><surname>Feng</surname><given-names>Zhixing</given-names></name><name><surname>Wang</surname><given-names>Xi</given-names></name><name><surname>Wang</surname><given-names>Xiaowo</given-names></name><name><surname>Zhang</surname><given-names>Xuegong</given-names></name></person-group><article-title>Degseq: an r package for identifying differentially expressed genes from rna-seq data</article-title><source>Bioinformatics</source><year>2010</year><volume>26</volume><issue>1</issue><fpage>136</fpage><lpage>138</lpage><pub-id pub-id-type="pmid">19855105</pub-id></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><collab>Radhika Khetani Meeta Mistry</collab><source>Gene-level differential expression analysis</source><year>2020</year><month>May</month></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Love</surname><given-names>Michael I</given-names></name><name><surname>Huber</surname><given-names>Wolfgang</given-names></name><name><surname>Anders</surname><given-names>Simon</given-names></name></person-group><article-title>Moderated estimation of fold change and dispersion for rna-seq data with deseq2</article-title><source>Genome biology</source><year>2014</year><volume>15</volume><issue>12</issue><fpage>1</fpage><lpage>21</lpage><pub-id pub-id-type="pmcid">PMC4302049</pub-id><pub-id pub-id-type="pmid">25516281</pub-id><pub-id pub-id-type="doi">10.1186/s13059-014-0550-8</pub-id></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robinson</surname><given-names>Mark D</given-names></name><name><surname>McCarthy</surname><given-names>Davis J</given-names></name><name><surname>Smyth</surname><given-names>Gordon K</given-names></name></person-group><article-title>edger: a bioconductor package for differential expression analysis of digital gene expression data</article-title><source>bioinformatics</source><year>2010</year><volume>26</volume><issue>1</issue><fpage>139</fpage><lpage>140</lpage><pub-id pub-id-type="pmcid">PMC2796818</pub-id><pub-id pub-id-type="pmid">19910308</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/btp616</pub-id></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hendrycks</surname><given-names>Dan</given-names></name><name><surname>Gimpel</surname><given-names>Kevin</given-names></name></person-group><article-title>A baseline for detecting misclassified and out-of-distribution examples in neural networks</article-title><source>arXiv preprint</source><year>2016</year><elocation-id>arXiv:1610.02136</elocation-id></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>H</given-names></name><name><surname>Bai</surname><given-names>Y</given-names></name><name><surname>Garcia</surname><given-names>EA</given-names></name><name><surname>Li</surname><given-names>S</given-names></name></person-group><article-title>Adasyn adaptive synthetic sampling approach for imbalanced learning. ieee international joint conference on neural networks</article-title><source>IEEE World Congress On Computational Intelligence</source><year>2008</year></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Last</surname><given-names>Felix</given-names></name><name><surname>Douzas</surname><given-names>Georgios</given-names></name><name><surname>Bacao</surname><given-names>Fernando</given-names></name></person-group><article-title>Oversampling for imbalanced learning based on k-means and smote</article-title><source>arXiv preprint</source><year>2017</year><elocation-id>arXiv:1711.00837</elocation-id></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Han</surname><given-names>Hui</given-names></name><name><surname>Wang</surname><given-names>Wen-Yuan</given-names></name><name><surname>Mao</surname><given-names>Bing-Huan</given-names></name></person-group><source>Borderline-smote: a new over-sampling method in imbalanced data sets learning</source><conf-name>International conference on intelligent computing</conf-name><conf-sponsor>Springer</conf-sponsor><year>2005</year><fpage>878</fpage><lpage>887</lpage></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Wan</surname><given-names>Qikang</given-names></name><name><surname>Deng</surname><given-names>Xiongshi</given-names></name><name><surname>Li</surname><given-names>Min</given-names></name><name><surname>Yang</surname><given-names>Haotian</given-names></name></person-group><source>Sddsmote: Synthetic minority oversampling technique based on sample density distribution for enhanced classification on imbalanced microarray data</source><conf-name>2022 The 6th International Conference on Compute and Data Analysis</conf-name><year>2022</year><fpage>35</fpage><lpage>42</lpage></element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Junnan</given-names></name><name><surname>Zhu</surname><given-names>Qingsheng</given-names></name><name><surname>Wu</surname><given-names>Quanwang</given-names></name><name><surname>Fan</surname><given-names>Zhu</given-names></name></person-group><article-title>A novel oversampling technique for class-imbalanced learning based on smote and natural neighbors</article-title><source>Information Sciences</source><year>2021</year><volume>565</volume><fpage>438</fpage><lpage>455</lpage></element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blagus</surname><given-names>Rok</given-names></name><name><surname>Lusa</surname><given-names>Lara</given-names></name></person-group><article-title>Smote for high-dimensional class-imbalanced data</article-title><source>BMC bioinformatics</source><year>2013</year><volume>14</volume><issue>1</issue><fpage>1</fpage><lpage>16</lpage><pub-id pub-id-type="pmcid">PMC3648438</pub-id><pub-id pub-id-type="pmid">23522326</pub-id><pub-id pub-id-type="doi">10.1186/1471-2105-14-106</pub-id></element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>Hai-Hui</given-names></name><name><surname>Rao</surname><given-names>Hao</given-names></name><name><surname>Miao</surname><given-names>Rui</given-names></name><name><surname>Liang</surname><given-names>Yong</given-names></name></person-group><article-title>A novel meta-analysis based on data augmentation and elastic data shared lasso regularization for gene expression</article-title><source>BMC bioinformatics</source><year>2022</year><volume>23</volume><issue>10</issue><fpage>1</fpage><lpage>24</lpage><pub-id pub-id-type="pmcid">PMC9396780</pub-id><pub-id pub-id-type="pmid">35999505</pub-id><pub-id pub-id-type="doi">10.1186/s12859-022-04887-5</pub-id></element-citation></ref><ref id="R40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van den Bulcke</surname><given-names>Tim</given-names></name><name><surname>Van Leemput</surname><given-names>Koenraad</given-names></name><name><surname>Naudts</surname><given-names>Bart</given-names></name><name><surname>van Remortel</surname><given-names>Piet</given-names></name><name><surname>Ma</surname><given-names>Hongwu</given-names></name><name><surname>Verschoren</surname><given-names>Alain</given-names></name><name><surname>De Moor</surname><given-names>Bart</given-names></name><name><surname>Marchal</surname><given-names>Kathleen</given-names></name></person-group><article-title>Syntren: a generator of synthetic gene expression data for design and analysis of structure learning algorithms</article-title><source>BMC bioinformatics</source><year>2006</year><volume>7</volume><issue>1</issue><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="pmcid">PMC1373604</pub-id><pub-id pub-id-type="pmid">16438721</pub-id><pub-id pub-id-type="doi">10.1186/1471-2105-7-43</pub-id></element-citation></ref><ref id="R41"><label>41</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schaffter</surname><given-names>Thomas</given-names></name><name><surname>Marbach</surname><given-names>Daniel</given-names></name><name><surname>Floreano</surname><given-names>Dario</given-names></name></person-group><article-title>Genenetweaver: in silico benchmark generation and performance profiling of network inference methods</article-title><source>Bioinformatics</source><year>2011</year><volume>27</volume><issue>16</issue><fpage>2263</fpage><lpage>2270</lpage><pub-id pub-id-type="pmid">21697125</pub-id></element-citation></ref><ref id="R42"><label>42</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goodfellow</surname><given-names>Ian</given-names></name><name><surname>Pouget-Abadie</surname><given-names>Jean</given-names></name><name><surname>Mirza</surname><given-names>Mehdi</given-names></name><name><surname>Xu</surname><given-names>Bing</given-names></name><name><surname>Warde-Farley</surname><given-names>David</given-names></name><name><surname>Ozair</surname><given-names>Sherjil</given-names></name><name><surname>Courville</surname><given-names>Aaron</given-names></name><name><surname>Bengio</surname><given-names>Yoshua</given-names></name></person-group><article-title>Generative adversarial networks</article-title><source>Communications of the ACM</source><year>2020</year><volume>63</volume><issue>11</issue><fpage>139</fpage><lpage>144</lpage></element-citation></ref><ref id="R43"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vinas</surname><given-names>Ramon</given-names></name><name><surname>Andrés-Terré</surname><given-names>Helena</given-names></name><name><surname>Lio</surname><given-names>Pietro</given-names></name><name><surname>Bryson</surname><given-names>Kevin</given-names></name></person-group><article-title>Adversarial generation of gene expression data</article-title><source>Bioinformatics</source><year>2022</year><volume>38</volume><issue>3</issue><fpage>730</fpage><lpage>737</lpage><pub-id pub-id-type="pmcid">PMC8756177</pub-id><pub-id pub-id-type="pmid">33471074</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/btab035</pub-id></element-citation></ref><ref id="R44"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chaudhari</surname><given-names>Poonam</given-names></name><name><surname>Agrawal</surname><given-names>Himanshu</given-names></name><name><surname>Kotecha</surname><given-names>Ketan</given-names></name></person-group><article-title>Data augmentation using mg-gan for improved cancer classification on gene expression data</article-title><source>Soft Computing</source><year>2020</year><volume>24</volume><issue>15</issue><fpage>11381</fpage><lpage>11391</lpage></element-citation></ref><ref id="R45"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marouf</surname><given-names>Mohamed</given-names></name><name><surname>Machart</surname><given-names>Pierre</given-names></name><name><surname>Bansal</surname><given-names>Vikas</given-names></name><name><surname>Kilian</surname><given-names>Christoph</given-names></name><name><surname>Magruder</surname><given-names>Daniel S</given-names></name><name><surname>Krebs</surname><given-names>Christian F</given-names></name><name><surname>Bonn</surname><given-names>Stefan</given-names></name></person-group><article-title>Realistic in silico generation and augmentation of single-cell rna-seq data using generative adversarial networks</article-title><source>Nature communications</source><year>2020</year><volume>11</volume><issue>1</issue><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="pmcid">PMC6952370</pub-id><pub-id pub-id-type="pmid">31919373</pub-id><pub-id pub-id-type="doi">10.1038/s41467-019-14018-z</pub-id></element-citation></ref><ref id="R46"><label>46</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guinney</surname><given-names>Justin</given-names></name><name><surname>Dienstmann</surname><given-names>Rodrigo</given-names></name><name><surname>Wang</surname><given-names>Xin</given-names></name><name><surname>De Reynies</surname><given-names>Auréelien</given-names></name><name><surname>Schlicker</surname><given-names>Andreas</given-names></name><name><surname>Soneson</surname><given-names>Charlotte</given-names></name><name><surname>Marisa</surname><given-names>Laetitia</given-names></name><name><surname>Roepman</surname><given-names>Paul</given-names></name><name><surname>Nyamundanda</surname><given-names>Gift</given-names></name><name><surname>Angelino</surname><given-names>Paolo</given-names></name><etal/></person-group><article-title>The consensus molecular subtypes of colorectal cancer</article-title><source>Nature medicine</source><year>2015</year><volume>21</volume><issue>11</issue><fpage>1350</fpage><lpage>1356</lpage><pub-id pub-id-type="pmcid">PMC4636487</pub-id><pub-id pub-id-type="pmid">26457759</pub-id><pub-id pub-id-type="doi">10.1038/nm.3967</pub-id></element-citation></ref><ref id="R47"><label>47</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buechler</surname><given-names>Steven A</given-names></name><name><surname>Stephens</surname><given-names>Melissa T</given-names></name><name><surname>Hummon</surname><given-names>Amanda B</given-names></name><name><surname>Ludwig</surname><given-names>Katelyn</given-names></name><name><surname>Cannon</surname><given-names>Emily</given-names></name><name><surname>Carter</surname><given-names>Tonia C</given-names></name><name><surname>Resnick</surname><given-names>Jeffrey</given-names></name><name><surname>Gökmen-Polar</surname><given-names>Yesim</given-names></name><name><surname>Badve</surname><given-names>Sunil S</given-names></name></person-group><article-title>Colotype: a forty gene signature for consensus molecular subtyping of colorectal cancer tumors using whole-genome assay or targeted rna-sequencing</article-title><source>Scientific reports</source><year>2020</year><volume>10</volume><issue>1</issue><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="pmcid">PMC7374173</pub-id><pub-id pub-id-type="pmid">32694712</pub-id><pub-id pub-id-type="doi">10.1038/s41598-020-69083-y</pub-id></element-citation></ref><ref id="R48"><label>48</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greenwood</surname><given-names>Ma jor</given-names></name><name><surname>Yule</surname><given-names>G Udny</given-names></name></person-group><article-title>An inquiry into the nature of frequency distributions representative of multiple happenings with particular reference to the occurrence of multiple attacks of disease or of repeated accidents</article-title><source>Journal of the Royal statistical society</source><year>1920</year><volume>83</volume><issue>2</issue><fpage>255</fpage><lpage>279</lpage></element-citation></ref><ref id="R49"><label>49</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barry</surname><given-names>Tim</given-names></name></person-group><article-title>Tim barry: Gamma, poisson, and negative binomial distributions</article-title><year>2020</year></element-citation></ref><ref id="R50"><label>50</label><element-citation publication-type="journal"><collab>Cancer Genome Atlas Network</collab><article-title>Comprehensive molecular characterization of human colon and rectal cancer</article-title><source>Nature</source><year>2012</year><volume>487</volume><issue>7407</issue><fpage>330</fpage><pub-id pub-id-type="pmcid">PMC3401966</pub-id><pub-id pub-id-type="pmid">22810696</pub-id><pub-id pub-id-type="doi">10.1038/nature11252</pub-id></element-citation></ref><ref id="R51"><label>51</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Edwards</surname><given-names>Nathan J</given-names></name><name><surname>Oberti</surname><given-names>Mauricio</given-names></name><name><surname>Thangudu</surname><given-names>Ratna R</given-names></name><name><surname>Cai</surname><given-names>Shuang</given-names></name><name><surname>McGarvey</surname><given-names>Peter B</given-names></name><name><surname>Jacob</surname><given-names>Shine</given-names></name><name><surname>Madhavan</surname><given-names>Subha</given-names></name><name><surname>Ketchum</surname><given-names>Karen A</given-names></name></person-group><article-title>The cptac data portal: a resource for cancer proteomics research</article-title><source>Journal of proteome research</source><year>2015</year><volume>14</volume><issue>6</issue><fpage>2707</fpage><lpage>2713</lpage><pub-id pub-id-type="pmid">25873244</pub-id></element-citation></ref><ref id="R52"><label>52</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kingma</surname><given-names>Diederik P</given-names></name><name><surname>Welling</surname><given-names>Max</given-names></name></person-group><source>Autoencoding variational bayes</source><conf-name>Proceedings of the International Conference on Learning Representations (ICLR)</conf-name><year>2014</year></element-citation></ref><ref id="R53"><label>53</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McInnes</surname><given-names>Leland</given-names></name><name><surname>Healy</surname><given-names>John</given-names></name><name><surname>Melville</surname><given-names>James</given-names></name></person-group><article-title>Umap: Uniform manifold approximation and projection for dimension reduction</article-title><source>arXiv preprint</source><year>2018</year><elocation-id>arXiv:1802.03426</elocation-id></element-citation></ref><ref id="R54"><label>54</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kang</surname><given-names>Sanghee</given-names></name><name><surname>Na</surname><given-names>Younghyun</given-names></name><name><surname>Joung</surname><given-names>Sung Yup</given-names></name><name><surname>Lee</surname><given-names>Sun Il</given-names></name><name><surname>Oh</surname><given-names>Sang Cheul</given-names></name><name><surname>Min</surname><given-names>Byung Wook</given-names></name></person-group><article-title>The significance of microsatellite instability in colorectal cancer after controlling for clinicopathological factors</article-title><source>Medicine</source><year>2018</year><volume>97</volume><issue>9</issue><pub-id pub-id-type="pmcid">PMC5851768</pub-id><pub-id pub-id-type="pmid">29489646</pub-id><pub-id pub-id-type="doi">10.1097/MD.0000000000010019</pub-id></element-citation></ref><ref id="R55"><label>55</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Popat</surname><given-names>S</given-names></name><name><surname>Hubner</surname><given-names>R</given-names></name><name><surname>Houlston</surname><given-names>RS</given-names></name></person-group><article-title>Systematic review of microsatellite instability and colorectal cancer prognosis</article-title><source>Journal of clinical oncology</source><year>2005</year><volume>23</volume><issue>3</issue><fpage>609</fpage><lpage>618</lpage><pub-id pub-id-type="pmid">15659508</pub-id></element-citation></ref><ref id="R56"><label>56</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diao</surname><given-names>Zhenli</given-names></name><name><surname>Han</surname><given-names>Yanxi</given-names></name><name><surname>Chen</surname><given-names>Yuqing</given-names></name><name><surname>Zhang</surname><given-names>Rui</given-names></name><name><surname>Li</surname><given-names>Jinming</given-names></name></person-group><article-title>The clinical utility of microsatellite instability in colorectal cancer</article-title><source>Critical reviews in oncology/hematology</source><year>2021</year><volume>157</volume><elocation-id>103171</elocation-id><pub-id pub-id-type="pmid">33290824</pub-id></element-citation></ref><ref id="R57"><label>57</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sillo</surname><given-names>TO</given-names></name><name><surname>Beggs</surname><given-names>AD</given-names></name><name><surname>Morton</surname><given-names>DG</given-names></name><name><surname>Middleton</surname><given-names>G</given-names></name></person-group><article-title>Mechanisms of immunogenicity in colorectal cancer</article-title><source>Journal of British Surgery</source><year>2019</year><volume>106</volume><issue>10</issue><fpage>1283</fpage><lpage>1297</lpage><pub-id pub-id-type="pmcid">PMC6772007</pub-id><pub-id pub-id-type="pmid">31216061</pub-id><pub-id pub-id-type="doi">10.1002/bjs.11204</pub-id></element-citation></ref><ref id="R58"><label>58</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Min</surname><given-names>Byung-Hoon</given-names></name><name><surname>Bae</surname><given-names>Jeong Mo</given-names></name><name><surname>Lee</surname><given-names>Eui Jin</given-names></name><name><surname>Yu</surname><given-names>Hong Suk</given-names></name><name><surname>Kim</surname><given-names>Young-Ho</given-names></name><name><surname>Chang</surname><given-names>Dong Kyung</given-names></name><name><surname>Kim</surname><given-names>Hee Cheol</given-names></name><name><surname>Park</surname><given-names>Cheol Keun</given-names></name><name><surname>Lee</surname><given-names>Suk-Hee</given-names></name><name><surname>Kim</surname><given-names>Kyoung-Mee</given-names></name><etal/></person-group><article-title>The cpg island methylator phenotype may confer a survival benefit in patients with stage ii or iii colorectal carcinomas receiving fluoropyrimidine-based adjuvant chemotherapy</article-title><source>BMC cancer</source><year>2011</year><volume>11</volume><issue>1</issue><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="pmcid">PMC3162585</pub-id><pub-id pub-id-type="pmid">21827707</pub-id><pub-id pub-id-type="doi">10.1186/1471-2407-11-344</pub-id></element-citation></ref><ref id="R59"><label>59</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shiovitz</surname><given-names>Stacey</given-names></name><name><surname>Bertagnolli</surname><given-names>Monica M</given-names></name><name><surname>Renfro</surname><given-names>Lindsay A</given-names></name><name><surname>Nam</surname><given-names>Eunmi</given-names></name><name><surname>Foster</surname><given-names>Nathan R</given-names></name><name><surname>Dzieciatkowski</surname><given-names>Slavomir</given-names></name><name><surname>Luo</surname><given-names>Yanxin</given-names></name><name><surname>Lao</surname><given-names>Victoria Valinluck</given-names></name><name><surname>Monnat</surname><given-names>Raymond J</given-names><suffix>Jr</suffix></name><name><surname>Emond</surname><given-names>Mary J</given-names></name><etal/></person-group><article-title>Cpg island methylator phenotype is associated with response to adjuvant irinotecanbased therapy for stage iii colon cancer</article-title><source>Gastroenterology</source><year>2014</year><volume>147</volume><issue>3</issue><fpage>637</fpage><lpage>645</lpage><pub-id pub-id-type="pmcid">PMC4143495</pub-id><pub-id pub-id-type="pmid">24859205</pub-id><pub-id pub-id-type="doi">10.1053/j.gastro.2014.05.009</pub-id></element-citation></ref><ref id="R60"><label>60</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Valenzuela</surname><given-names>Guillermo</given-names></name><name><surname>Canepa</surname><given-names>Joaquin</given-names></name><name><surname>Simonetti</surname><given-names>Carolina</given-names></name><name><surname>de Zaldivar</surname><given-names>Loreto Solo</given-names></name><name><surname>Marcelain</surname><given-names>Katherine</given-names></name><name><surname>Gonzaélez-Montero</surname><given-names>Jaime</given-names></name></person-group><article-title>Consensus molecular subtypes of colorectal cancer in clinical practice: A translational approach</article-title><source>World journal of clinical oncology</source><year>2021</year><volume>12</volume><issue>11</issue><fpage>1000</fpage><pub-id pub-id-type="pmcid">PMC8641009</pub-id><pub-id pub-id-type="pmid">34909395</pub-id><pub-id pub-id-type="doi">10.5306/wjco.v12.i11.1000</pub-id></element-citation></ref><ref id="R61"><label>61</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lemaître</surname><given-names>Guillaume</given-names></name><name><surname>Nogueira</surname><given-names>Fernando</given-names></name><name><surname>Christos</surname><given-names>K</given-names></name></person-group><article-title>Aridas. Imbalanced-learn: A python toolbox to tackle the curse of imbalanced datasets in machine learning</article-title><source>Journal of Machine Learning Research</source><year>2017</year><volume>18</volume><issue>17</issue><fpage>1</fpage><lpage>5</lpage></element-citation></ref><ref id="R62"><label>62</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Conesa</surname><given-names>Ana</given-names></name><name><surname>Madrigal</surname><given-names>Pedro</given-names></name><name><surname>Tarazona</surname><given-names>Sonia</given-names></name><name><surname>Gomez-Cabrero</surname><given-names>David</given-names></name><name><surname>Cervera</surname><given-names>Alejandra</given-names></name><name><surname>McPherson</surname><given-names>Andrew</given-names></name><name><surname>Szczeéniak</surname><given-names>Michal Wojciech</given-names></name><name><surname>Gaffney</surname><given-names>Daniel J</given-names></name><name><surname>Elo</surname><given-names>Laura L</given-names></name><name><surname>Zhang</surname><given-names>Xuegong</given-names></name><etal/></person-group><article-title>A survey of best practices for rna-seq data analysis</article-title><source>Genome biology</source><year>2016</year><volume>17</volume><issue>1</issue><fpage>1</fpage><lpage>19</lpage><pub-id pub-id-type="pmcid">PMC4728800</pub-id><pub-id pub-id-type="pmid">26813401</pub-id><pub-id pub-id-type="doi">10.1186/s13059-016-0881-8</pub-id></element-citation></ref><ref id="R63"><label>63</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F</given-names></name><name><surname>Varoquaux</surname><given-names>G</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Michel</surname><given-names>V</given-names></name><name><surname>Thirion</surname><given-names>B</given-names></name><name><surname>Grisel</surname><given-names>O</given-names></name><name><surname>Blondel</surname><given-names>M</given-names></name><name><surname>Prettenhofer</surname><given-names>P</given-names></name><name><surname>Weiss</surname><given-names>R</given-names></name><name><surname>Dubourg</surname><given-names>V</given-names></name><name><surname>Vanderplas</surname><given-names>J</given-names></name><etal/></person-group><article-title>Scikit-learn: Machine learning in Python</article-title><source>Journal of Machine Learning Research</source><year>2011</year><volume>12</volume><fpage>2825</fpage><lpage>2830</lpage></element-citation></ref><ref id="R64"><label>64</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Agarap</surname><given-names>Abien Fred</given-names></name></person-group><article-title>Deep learning using rectified linear units (relu)</article-title><source>arXiv preprint</source><year>2018</year><elocation-id>arXiv:1803.08375</elocation-id></element-citation></ref><ref id="R65"><label>65</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kingma</surname><given-names>Diederik P</given-names></name><name><surname>Ba</surname><given-names>Jimmy</given-names></name></person-group><article-title>Adam: A method for stochastic optimization</article-title><source>arXiv preprint</source><year>2014</year><elocation-id>arXiv:1412.6980</elocation-id></element-citation></ref><ref id="R66"><label>66</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Purcell</surname><given-names>Rachel V</given-names></name><name><surname>Schmeier</surname><given-names>Sebastian</given-names></name><name><surname>Lau</surname><given-names>Yee Chen</given-names></name><name><surname>Pearson</surname><given-names>John F</given-names></name><name><surname>Frizelle</surname><given-names>Francis A</given-names></name></person-group><article-title>Molecular subtyping improves prognostication of stage 2 colorectal cancer</article-title><source>BMC cancer</source><year>2019</year><volume>19</volume><issue>1</issue><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="pmcid">PMC6882162</pub-id><pub-id pub-id-type="pmid">31775679</pub-id><pub-id pub-id-type="doi">10.1186/s12885-019-6327-4</pub-id></element-citation></ref><ref id="R67"><label>67</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herrmann</surname><given-names>Moritz</given-names></name><name><surname>Probst</surname><given-names>Philipp</given-names></name><name><surname>Hornung</surname><given-names>Roman</given-names></name><name><surname>Jurinovic</surname><given-names>Vindi</given-names></name><name><surname>Boulesteix</surname><given-names>Anne-Laure</given-names></name></person-group><article-title>Large-scale benchmark study of survival prediction methods using multi-omicsdata</article-title><source>Briefings in bioinformatics</source><year>2021</year><volume>22</volume><issue>3</issue><elocation-id>bbaa167</elocation-id><pub-id pub-id-type="pmcid">PMC8138887</pub-id><pub-id pub-id-type="pmid">32823283</pub-id><pub-id pub-id-type="doi">10.1093/bib/bbaa167</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Fig. 1</label><caption><p>An illustration of intra-class crossover sampling. A sample with class CMS1 can be generated by sampling gene signature blocks from the subset of CMS1 patients (surrounded by the red box). Similarly, an observation with class CMS3 can be generated by sampling gene signature blocks from the subset of CMS3 patients (surrounded by the dark green box).</p></caption><graphic xlink:href="EMS190456-f001"/></fig><fig id="F2" position="float"><label>Fig. 2</label><caption><p>An illustration of inter-class crossover sampling. A sample with class CMS1 can be generated by sampling the CMS1 gene signature block from the subset of CMS1 patients (surrounded by the blue box). The remaining gene blocks can be sampled from those patients that do not belong to the CMS class the gene block predicts.</p></caption><graphic xlink:href="EMS190456-f002"/></fig><fig id="F3" position="float"><label>Fig. 3</label><caption><title>UMAP [<xref ref-type="bibr" rid="R53">53</xref>] visualisations of datasets in the study.</title><p>A. Unbalanced dataset. B. Intra-class crossover sampled dataset. C. Inter-class crossover sampled dataset. D. Gamma-Poisson sampled dataset. E. Poisson sampled dataset. F. SMOTE sampled dataset. All augmented datasets have 5000 samples per class.</p></caption><graphic xlink:href="EMS190456-f003"/></fig><table-wrap id="T1" position="float" orientation="portrait"><label>Table 1</label><caption><title>Sample counts of the different colorectal cancer subtypes in the TCGA and CPTAC gene expression datasets.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle">Datasets</th><th align="center" valign="middle">CMS1</th><th align="center" valign="middle">CMS2</th><th align="center" valign="middle">CMS3</th><th align="center" valign="middle">CMS4</th><th align="center" valign="middle">Total</th></tr></thead><tbody><tr><td align="center" valign="middle">TCGA</td><td align="center" valign="middle">74</td><td align="center" valign="middle">216</td><td align="center" valign="middle">74</td><td align="center" valign="middle">142</td><td align="center" valign="middle">506</td></tr><tr><td align="center" valign="middle">CPTAC</td><td align="center" valign="middle">14</td><td align="center" valign="middle">33</td><td align="center" valign="middle">16</td><td align="center" valign="middle">22</td><td align="center" valign="middle">85</td></tr></tbody></table></table-wrap><table-wrap id="T2" position="float" orientation="portrait"><label>Table 2</label><caption><p>5x5 cross-validation results for supervised classification (CMS prediction) on augmented data with various classifiers. Each classifier is trained with data augmented by different sampling methods. Each class is augmented to a different class-size - Max, 500, and 5000. The TCGA test set indicates in-domain performance. The CPTAC dataset serves as external validation. We report the average balanced accuracy scores and their standard deviation, with the best highlighted in bold. Although in-domain performances vary depending on the classifier and class-size, models trained with the inter-class crossover augmented data generalise best in 6 out of the 9 <italic>out-of-distribution</italic> settings (i.e, CPTAC).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" rowspan="2">Class-Size</th><th align="center" valign="middle" rowspan="2">Sampling Methods</th><th align="center" valign="middle" colspan="2">SVM</th><th align="center" valign="middle" colspan="2">EBM</th><th align="center" valign="middle" colspan="2">RF</th></tr><tr><th align="center" valign="middle">TCGA</th><th align="center" valign="middle">CPTAC</th><th align="center" valign="middle">TCGA</th><th align="center" valign="middle">CPTAC</th><th align="center" valign="middle">TCGA</th><th align="center" valign="middle">CPTAC</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="6">Max</td><td align="center" valign="middle">Intra-Crossover (Ours)</td><td align="center" valign="middle">0.890 ± 0.029</td><td align="center" valign="middle">0.594 ± 0.033</td><td align="center" valign="middle">0.888 ± 0.026</td><td align="center" valign="middle">0.647 ± 0.035</td><td align="center" valign="middle">0.876 ± 0.030</td><td align="center" valign="middle">0.643 ± 0.021</td></tr><tr><td align="center" valign="middle">Inter-Crossover (Ours)</td><td align="center" valign="middle">0.896 ± 0.028</td><td align="center" valign="middle"><bold>0.608 ± 0.030</bold></td><td align="center" valign="middle"><bold>0.893 ± 0.032</bold></td><td align="center" valign="middle"><bold>0.670 ± 0.026</bold></td><td align="center" valign="middle"><bold>0.878 ± 0.039</bold></td><td align="center" valign="middle">0.625 ± 0.023</td></tr><tr><td align="center" valign="middle">Mod. Gamma-Poisson</td><td align="center" valign="middle">0.892 ± 0.028</td><td align="center" valign="middle">0.600 ± 0.033</td><td align="center" valign="middle">0.882 ± 0.032</td><td align="center" valign="middle">0.647 ± 0.029</td><td align="center" valign="middle">0.876 ± 0.035</td><td align="center" valign="middle">0.645 ± 0.026</td></tr><tr><td align="center" valign="middle">Mod. Poisson</td><td align="center" valign="middle">0.882 ± 0.036</td><td align="center" valign="middle">0.602 ± 0.031</td><td align="center" valign="middle">0.875 ± 0.029</td><td align="center" valign="middle">0.623 ± 0.031</td><td align="center" valign="middle">0.865 ± 0.034</td><td align="center" valign="middle">0.627 ± 0.038</td></tr><tr><td align="center" valign="middle">SMOTE</td><td align="center" valign="middle">0.894 ± 0.025</td><td align="center" valign="middle">0.584 ± 0.030</td><td align="center" valign="middle">0.88 ± 0.03</td><td align="center" valign="middle">0.633 ± 0.030</td><td align="center" valign="middle">0.871 ± 0.034</td><td align="center" valign="middle"><bold>0.653 ± 0.028</bold></td></tr><tr><td align="center" valign="middle">Resampling</td><td align="center" valign="middle"><bold>0.897 ± 0.031</bold></td><td align="center" valign="middle">0.596 ± 0.032</td><td align="center" valign="middle">0.871 ± 0.030</td><td align="center" valign="middle">0.628 ± 0.026</td><td align="center" valign="middle">0.875 ± 0.032</td><td align="center" valign="middle">0.632 ± 0.038</td></tr><tr><td align="center" valign="middle" rowspan="6">500</td><td align="center" valign="middle">Intra-Crossover (Ours)</td><td align="center" valign="middle">0.885 ± 0.023</td><td align="center" valign="middle">0.592 ± 0.041</td><td align="center" valign="middle">0.884 ± 0.032</td><td align="center" valign="middle">0.683 ± 0.029</td><td align="center" valign="middle">0.868 ± 0.036</td><td align="center" valign="middle"><bold>0.673 ± 0.020</bold></td></tr><tr><td align="center" valign="middle">Inter-Crossover (Ours)</td><td align="center" valign="middle">0.881 ± 0.037</td><td align="center" valign="middle"><bold>0.643 ± 0.028</bold></td><td align="center" valign="middle">0.877 ± 0.039</td><td align="center" valign="middle"><bold>0.708 ± 0.023</bold></td><td align="center" valign="middle">0.873 ± 0.038</td><td align="center" valign="middle">0.669 ± 0.027</td></tr><tr><td align="center" valign="middle">Mod. Gamma-Poisson</td><td align="center" valign="middle"><bold>0.901 ± 0.023</bold></td><td align="center" valign="middle">0.608 ± 0.031</td><td align="center" valign="middle"><bold>0.895 ± 0.026</bold></td><td align="center" valign="middle">0.669 ± 0.025</td><td align="center" valign="middle">0.876 ± 0.040</td><td align="center" valign="middle">0.658 ± 0.016</td></tr><tr><td align="center" valign="middle">Mod. Poisson</td><td align="center" valign="middle">0.878 ± 0.034</td><td align="center" valign="middle">0.601 ± 0.035</td><td align="center" valign="middle">0.877 ± 0.029</td><td align="center" valign="middle">0.615 ± 0.021</td><td align="center" valign="middle">0.862 ± 0.038</td><td align="center" valign="middle">0.627 ± 0.039</td></tr><tr><td align="center" valign="middle">SMOTE</td><td align="center" valign="middle">0.894 ± 0.032</td><td align="center" valign="middle">0.583 ± 0.032</td><td align="center" valign="middle">0.879 ± 0.028</td><td align="center" valign="middle">0.642 ± 0.031</td><td align="center" valign="middle"><bold>0.876 ± 0.030</bold></td><td align="center" valign="middle">0.665 ± 0.032</td></tr><tr><td align="center" valign="middle">Resampling</td><td align="center" valign="middle">0.889 ± 0.028</td><td align="center" valign="middle">0.563 ± 0.038</td><td align="center" valign="middle">0.862 ± 0.032</td><td align="center" valign="middle">0.618 ± 0.040</td><td align="center" valign="middle">0.872 ± 0.035</td><td align="center" valign="middle">0.623 ± 0.029</td></tr><tr><td align="center" valign="middle" rowspan="6">5000</td><td align="center" valign="middle">Intra-Crossover (Ours)</td><td align="center" valign="middle">0.876 ± 0.028</td><td align="center" valign="middle">0.613 ± 0.024</td><td align="center" valign="middle">0.871 ± 0.033</td><td align="center" valign="middle">0.659 ± 0.040</td><td align="center" valign="middle">0.861 ± 0.029</td><td align="center" valign="middle">0.677 ± 0.028</td></tr><tr><td align="center" valign="middle">Inter-Crossover (Ours)</td><td align="center" valign="middle">0.870 ± 0.033</td><td align="center" valign="middle"><bold>0.662 ± 0.014</bold></td><td align="center" valign="middle">0.846 ± 0.043</td><td align="center" valign="middle">0.654 ± 0.023</td><td align="center" valign="middle">0.849 ± 0.031</td><td align="center" valign="middle"><bold>0.685 ± 0.019</bold></td></tr><tr><td align="center" valign="middle">Mod. Gamma-Poisson</td><td align="center" valign="middle"><bold>0.897 ± 0.030</bold></td><td align="center" valign="middle">0.614 ± 0.021</td><td align="center" valign="middle"><bold>0.893 ± 0.026</bold></td><td align="center" valign="middle"><bold>0.674 ± 0.033</bold></td><td align="center" valign="middle">0.879 ± 0.032</td><td align="center" valign="middle">0.677 ± 0.013</td></tr><tr><td align="center" valign="middle">Mod. Poisson</td><td align="center" valign="middle">0.876 ± 0.035</td><td align="center" valign="middle">0.600 ± 0.033</td><td align="center" valign="middle">0.882 ± 0.031</td><td align="center" valign="middle">0.61 ± 0.03</td><td align="center" valign="middle">0.871 ± 0.037</td><td align="center" valign="middle">0.634 ± 0.043</td></tr><tr><td align="center" valign="middle">SMOTE</td><td align="center" valign="middle">0.893 ± 0.027</td><td align="center" valign="middle">0.589 ± 0.032</td><td align="center" valign="middle">0.883 ± 0.027</td><td align="center" valign="middle">0.637 ± 0.031</td><td align="center" valign="middle"><bold>0.879 ± 0.025</bold></td><td align="center" valign="middle">0.661 ± 0.024</td></tr><tr><td align="center" valign="middle">Resampling</td><td align="center" valign="middle">0.886 ± 0.028</td><td align="center" valign="middle">0.580 ± 0.038</td><td align="center" valign="middle">0.866 ± 0.033</td><td align="center" valign="middle">0.621 ± 0.032</td><td align="center" valign="middle">0.863 ± 0.034</td><td align="center" valign="middle">0.627 ± 0.026</td></tr><tr><td align="center" valign="middle"/><td align="center" valign="middle">Unbalanced</td><td align="center" valign="middle">0.886 ± 0.032</td><td align="center" valign="middle">0.606 ± 0.029</td><td align="center" valign="middle">0.867 ± 0.027</td><td align="center" valign="middle">0.637 ± 0.026</td><td align="center" valign="middle">0.862 ± 0.034</td><td align="center" valign="middle">0.626 ± 0.036</td></tr></tbody></table></table-wrap><table-wrap id="T3" position="float" orientation="portrait"><label>Table 3</label><caption><p>5x5 cross-validation results of latent space cluster purity. VAEs are trained with data augmented by different sampling methods and to different class-sizes to learn a 4D latent representation. The latent spaces are quantitatively assessed by cluster purity. The best scores are highlighted in bold. The inter-class crossover method when augmented to class-size 5000 has the highest in-domain and external purity scores.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" rowspan="2">Sampling Methods</th><th align="center" valign="middle" colspan="2">Max</th><th align="center" valign="middle" colspan="2">500</th><th align="center" valign="middle" colspan="2">5000</th></tr><tr><th align="center" valign="middle">TCGA</th><th align="center" valign="middle">CPTAC</th><th align="center" valign="middle">TCGA</th><th align="center" valign="middle">CPTAC</th><th align="center" valign="middle">TCGA</th><th align="center" valign="middle">CPTAC</th></tr></thead><tbody><tr><td align="center" valign="middle">Intra-Crossover (Ours)</td><td align="center" valign="middle">0.739 ± 0.052</td><td align="center" valign="middle">0.618 ± 0.051</td><td align="center" valign="middle">0.757 ± 0.050</td><td align="center" valign="middle">0.635 ± 0.060</td><td align="center" valign="middle">0.762 ± 0.041</td><td align="center" valign="middle">0.634 ± 0.042</td></tr><tr><td align="center" valign="middle">Inter-Crossover (Ours)</td><td align="center" valign="middle">0.753 ± 0.053</td><td align="center" valign="middle"><bold>0.624 ± 0.065</bold></td><td align="center" valign="middle">0.739 ± 0.050</td><td align="center" valign="middle">0.678 ± 0.062</td><td align="center" valign="middle"><bold>0.772 ± 0.032</bold></td><td align="center" valign="middle"><bold>0.680 ± 0.038</bold></td></tr><tr><td align="center" valign="middle">Mod. Gamma-Poisson</td><td align="center" valign="middle">0.735 ± 0.055</td><td align="center" valign="middle">0.605 ± 0.046</td><td align="center" valign="middle">0.732 ± 0.068</td><td align="center" valign="middle">0.639 ± 0.053</td><td align="center" valign="middle">0.719 ± 0.034</td><td align="center" valign="middle">0.677 ± 0.040</td></tr><tr><td align="center" valign="middle">Mod. Poisson</td><td align="center" valign="middle"><bold>0.772 ± 0.070</bold></td><td align="center" valign="middle">0.609 ± 0.048</td><td align="center" valign="middle"><bold>0.791 ± 0.041</bold></td><td align="center" valign="middle"><bold>0.683 ± 0.040</bold></td><td align="center" valign="middle">0.733 ± 0.041</td><td align="center" valign="middle">0.636 ± 0.036</td></tr><tr><td align="center" valign="middle">SMOTE</td><td align="center" valign="middle">0.731 ± 0.094</td><td align="center" valign="middle">0.586 ± 0.048</td><td align="center" valign="middle">0.735 ± 0.065</td><td align="center" valign="middle">0.605 ± 0.038</td><td align="center" valign="middle">0.531 ± 0.109</td><td align="center" valign="middle">0.484 ± 0.104</td></tr><tr><td align="center" valign="middle">Resampling</td><td align="center" valign="middle">0.724 ± 0.069</td><td align="center" valign="middle">0.605 ± 0.045</td><td align="center" valign="middle">0.760 ± 0.053</td><td align="center" valign="middle">0.590 ± 0.038</td><td align="center" valign="middle">0.731 ± 0.052</td><td align="center" valign="middle">0.588 ± 0.042</td></tr><tr><td align="center" valign="middle">Unbalanced</td><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle">0.740 ± 0.058</td><td align="center" valign="middle">0.637 ± 0.054</td><td align="center" valign="middle"/><td align="center" valign="middle"/></tr></tbody></table></table-wrap><table-wrap id="T4" position="float" orientation="portrait"><label>Table 4</label><caption><p>5x5 cross-validation results for MSI and CIMP Classification from VAEs trained with data augmented by different sampling methods. We report the averaged balanced accuracy for class-size 5000. Results for other class sizes are shown in <xref ref-type="supplementary-material" rid="SD1">Supplementary Table 11 and Table 10</xref>, respectively. The best scores are highlighted in bold. For MSI classification, all data augmentation models – except for SMOTE – achieved comparable balanced accuracy with both SVM and EBM in both in-domain and external validation. For CIMP classification, the inter-class crossover method is significantly better than all the other augmentation methods for the SVM model in in-domain testing, and significantly better than Poisson, SMOTE and unbalanced (p-value ≤ 0.05) for the EBM.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" rowspan="2">Clinical Variable</th><th align="center" valign="middle" rowspan="2">Sampling Methods</th><th align="center" valign="middle" colspan="2">SVM</th><th align="center" valign="middle" colspan="2">EBM</th></tr><tr><th align="center" valign="middle">TCGA</th><th align="center" valign="middle">CPTAC</th><th align="center" valign="middle">TCGA</th><th align="center" valign="middle">CPTAC</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="6">MSI</td><td align="center" valign="middle">Intra-Crossover (Ours)</td><td align="center" valign="middle">0.570 ± 0.034</td><td align="center" valign="middle">0.884 ± 0.046</td><td align="center" valign="middle"><bold>0.555 ± 0.047</bold></td><td align="center" valign="middle">0.863 ± 0.047</td></tr><tr><td align="center" valign="middle">Inter-Crossover (Ours)</td><td align="center" valign="middle">0.569 ± 0.041</td><td align="center" valign="middle">0.889 ± 0.044</td><td align="center" valign="middle">0.552 ± 0.042</td><td align="center" valign="middle"><bold>0.867 ± 0.042</bold></td></tr><tr><td align="center" valign="middle">Mod. Gamma-Poisson</td><td align="center" valign="middle">0.566 ± 0.040</td><td align="center" valign="middle">0.845 ± 0.051</td><td align="center" valign="middle">0.550 ± 0.039</td><td align="center" valign="middle">0.761 ± 0.067</td></tr><tr><td align="center" valign="middle">Mod. Poisson</td><td align="center" valign="middle">0.557 ± 0.032</td><td align="center" valign="middle">0.848 ± 0.062</td><td align="center" valign="middle">0.542 ± 0.049</td><td align="center" valign="middle">0.794 ± 0.051</td></tr><tr><td align="center" valign="middle">SMOTE</td><td align="center" valign="middle">0.390 ± 0.088</td><td align="center" valign="middle">0.578 ± 0.130</td><td align="center" valign="middle">0.373 ± 0.067</td><td align="center" valign="middle">0.558 ± 0.109</td></tr><tr><td align="center" valign="middle">Resampling</td><td align="center" valign="middle"><bold>0.578 ± 0.033</bold></td><td align="center" valign="middle"><bold>0.891 ± 0.048</bold></td><td align="center" valign="middle">0.548 ± 0.042</td><td align="center" valign="middle">0.814 ± 0.045</td></tr><tr><td align="center" valign="middle"/><td align="center" valign="middle">Unbalanced</td><td align="center" valign="middle">0.565 ± 0.037</td><td align="center" valign="middle">0.838 ± 0.062</td><td align="center" valign="middle">0.527 ± 0.045</td><td align="center" valign="middle">0.795 ± 0.071</td></tr><tr><td align="center" valign="middle" rowspan="6">CIMP</td><td align="center" valign="middle">Intra-Crossover (Ours)</td><td align="center" valign="middle">0.552 ± 0.052</td><td align="center" valign="middle">—</td><td align="center" valign="middle">0.528 ± 0.043</td><td align="center" valign="middle">—</td></tr><tr><td align="center" valign="middle">Inter-Crossover (Ours)</td><td align="center" valign="middle"><bold>0.576 ± 0.043</bold></td><td align="center" valign="middle">—</td><td align="center" valign="middle"><bold>0.638 ± 0.060</bold></td><td align="center" valign="middle">—</td></tr><tr><td align="center" valign="middle">Mod. Gamma-Poisson</td><td align="center" valign="middle">0.542 ± 0.049</td><td align="center" valign="middle">—</td><td align="center" valign="middle">0.521 ± 0.044</td><td align="center" valign="middle">—</td></tr><tr><td align="center" valign="middle">Mod. Poisson</td><td align="center" valign="middle">0.542 ± 0.038</td><td align="center" valign="middle">—</td><td align="center" valign="middle">0.502 ± 0.036</td><td align="center" valign="middle">—</td></tr><tr><td align="center" valign="middle">SMOTE</td><td align="center" valign="middle">0.389 ± 0.081</td><td align="center" valign="middle">—</td><td align="center" valign="middle">0.372 ± 0.064</td><td align="center" valign="middle">—</td></tr><tr><td align="center" valign="middle">Resampling</td><td align="center" valign="middle">0.539 ± 0.039</td><td align="center" valign="middle">—</td><td align="center" valign="middle">0.524 ± 0.043</td><td align="center" valign="middle">—</td></tr><tr><td align="center" valign="middle"/><td align="center" valign="middle">Unbalanced</td><td align="center" valign="middle">0.539 ± 0.044</td><td align="center" valign="middle">—</td><td align="center" valign="middle">0.500 ± 0.045</td><td align="center" valign="middle">—</td></tr></tbody></table></table-wrap></floats-group></article>