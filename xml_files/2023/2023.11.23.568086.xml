<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS191753</article-id><article-id pub-id-type="doi">10.1101/2023.11.23.568086</article-id><article-id pub-id-type="archive">PPR764200</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">1</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Primate origins of human event cognition</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Wilson</surname><given-names>Vanessa A. D.</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><contrib contrib-type="author"><name><surname>Sauppe</surname><given-names>Sebastian</given-names></name><xref ref-type="aff" rid="A3">3</xref><xref ref-type="aff" rid="A4">4</xref></contrib><contrib contrib-type="author"><name><surname>Brocard</surname><given-names>Sarah</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Ringen</surname><given-names>Erik</given-names></name><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref><xref ref-type="aff" rid="A5">5</xref></contrib><contrib contrib-type="author"><name><surname>Daum</surname><given-names>Moritz M.</given-names></name><xref ref-type="aff" rid="A3">3</xref><xref ref-type="aff" rid="A4">4</xref><xref ref-type="aff" rid="A6">6</xref></contrib><contrib contrib-type="author"><name><surname>Wermelinger</surname><given-names>Stephanie</given-names></name><xref ref-type="aff" rid="A4">4</xref><xref ref-type="aff" rid="A6">6</xref></contrib><contrib contrib-type="author"><name><surname>Gu</surname><given-names>Nianlong</given-names></name><xref ref-type="aff" rid="A3">3</xref><xref ref-type="aff" rid="A5">5</xref></contrib><contrib contrib-type="author"><name><surname>Andrews</surname><given-names>Caroline</given-names></name><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Isasi-Isasmendi</surname><given-names>Arrate</given-names></name><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Bickel</surname><given-names>Balthasar</given-names></name><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref><xref ref-type="fn" rid="FN1">†</xref></contrib><contrib contrib-type="author"><name><surname>Zuberbühler</surname><given-names>Klaus</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A3">3</xref><xref ref-type="fn" rid="FN1">†</xref></contrib><aff id="A1"><label>1</label>Department of Comparative Cognition, Institute of Biology; University of Neuchatel, Neuchatel 2000, Switzerland</aff><aff id="A2"><label>2</label>Department of Comparative Language Science, University of Zurich; Zurich 8050, Switzerland</aff><aff id="A3"><label>3</label>Center for the Interdisciplinary Study of Language Evolution, University of Zurich; Zurich 8050, Switzerland</aff><aff id="A4"><label>4</label>Department of Psychology, University of Zurich; Zurich 8050, Switzerland</aff><aff id="A5"><label>5</label>NCCR@LiRI Group, Linguistic Research Infrastructure, University of Zurich; Zurich 8050, Switzerland</aff><aff id="A6"><label>6</label>Jacobs Center for Productive Youth Development, University of Zurich; Zurich 8050, Switzerland</aff></contrib-group><author-notes><corresp id="CR1">
<label>*</label>corresponding author,</corresp><fn id="FN1"><label>†</label><p id="P1">joint senior authorship</p></fn></author-notes><pub-date pub-type="nihms-submitted"><day>25</day><month>11</month><year>2023</year></pub-date><pub-date pub-type="preprint"><day>24</day><month>11</month><year>2023</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P2">Human language relies on a rich cognitive machinery, partially shared with other animals. One key mechanism, decomposing events into causally-linked agent-patient roles, however, has remained elusive with no known animal equivalent. In humans, agent-patient relations in event cognition drive how languages are processed neurally and expressions structured syntactically. We compared visual event tracking between humans and great apes, using stimuli that would elicit causal processing in humans. After accounting for attention to background information, we found similar gaze patterns to agent-patient relations in all species, mostly alternating attention to agents and patients, presumably in order to learn the nature of the event, and occasionally privileging agents under specific conditions. Six-month-old infants, in contrast, did not follow agent-patient relations and attended mostly to background information. We conclude that event role tracking, a cognitive foundation of syntax, evolved long before language but requires time and experience to become ontogenetically available.</p></abstract></article-meta></front><body><p id="P3">Language is considered unique to humans, a distinction which leads to the prevailing question of how it has evolved. An empirical strategy has been to identify the cognitive mechanisms that language relies on, and to reconstruct their evolutionary history using comparative research with humans and other animals. One important cognitive mechanism is the propensity for speakers and listeners to decompose events into causally structured agent-patient relations (<xref ref-type="bibr" rid="R1">1</xref>). For example, a sentence like “Alice picked up the caterpillar” has Alice as the agent and the caterpillar as the patient. This distinction is deeply entrenched in meaning, neuroanatomically detectable (<xref ref-type="bibr" rid="R2">2</xref>) and responsible for core syntactic phenomena, such as case marking or constituent hierarchies (<xref ref-type="bibr" rid="R3">3</xref>), with only very few exceptions across the world’s languages (<xref ref-type="bibr" rid="R4">4</xref>). Furthermore, languages privilege agent over patient roles, preferring the simplest and default expressions for agents (<xref ref-type="bibr" rid="R5">5</xref>), even though this often incurs uncertainty and additional neural activity during sentence planning (<xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R7">7</xref>). Correspondingly, agents tend to be named before patients (<xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R9">9</xref>), a trend only matched in sentence structure by a concurrent preference for placing reference to humans before reference to inanimate things (<xref ref-type="bibr" rid="R10">10</xref>).</p><p id="P4">These biases in linguistic expression build on resilient mechanisms in human event cognition (<xref ref-type="bibr" rid="R11">11</xref>). For instance, when apprehending the gist of events from still pictures, people tend to be quicker to identify agents than patients (<xref ref-type="bibr" rid="R12">12</xref>), and assign agency almost instantly and with remarkably little variation across cultures and languages (<xref ref-type="bibr" rid="R13">13</xref>). Early agent identification is typically followed by distributed attention between agents and patients in a processing stage known as ‘relational encoding’ during early sentence planning (<xref ref-type="bibr" rid="R6">6</xref>). The same resilience is also apparent in comprehension during sentence processing. When sentences violate expectations about agent and patient roles, for example, by putting patients before agents, neurophysiological measures indicate that agency is usually assigned as the initial default, even when this goes against usage probabilities and the rules of grammar (<xref ref-type="bibr" rid="R5">5</xref>,<xref ref-type="bibr" rid="R14">14</xref>,<xref ref-type="bibr" rid="R15">15</xref>). Together, these findings suggest that language builds on a universal neurocognitive mechanism of event decomposition to make sense of the world and its linguistic representations.</p><p id="P5">This raises the question of how human event cognition has evolved. We are not aware of any evidence in the animal communication literature that demonstrates that signals can refer to agent-patient interactions, neither in natural communication nor with artificial languages (<xref ref-type="bibr" rid="R16">16</xref>). One hypothesis, therefore, is that nonhuman animals (from here on, ‘animals’) do not possess the cognitive resources for decomposing events into agents and patients. Certainly, animals can comprehend aspects of physical causality (e.g., that pushing causes falling) (<xref ref-type="bibr" rid="R17">17</xref>). Still, it is unclear whether this is due to perceptions of simple co-occurrences or more complex perceptions of events as agent activities causing patient changes. Related to this, although there is little doubt that animals perceive the participants of events, their attention may be absorbed by the participants’ social attributes, such as their identities, social roles (<xref ref-type="bibr" rid="R18">18</xref>), or behavioral intentions (<xref ref-type="bibr" rid="R17">17</xref>,<xref ref-type="bibr" rid="R19">19</xref>), all of which predict large situational and individual variation in how events are processed.</p><p id="P6">The alternative hypothesis, to be tested here, is that animals are capable of human-like event decomposition (<xref ref-type="bibr" rid="R1">1</xref>), but do not have the motivation or the resources to communicate about agent-patient relations. To explore this, we tested how participants across closely related species of hominids perceived a range of naturalistic events that would elicit causal processing in humans. We compared gaze responses to short video clips between members of the four genera of great apes - humans (<italic>Homo sapiens</italic>), chimpanzees (<italic>Pan troglodytes</italic>), gorillas (<italic>Gorilla gorilla</italic>) and orangutans (<italic>Pongo abelii</italic>). We also tested human infants at 6 months old, before they start to actively use language and whilst still developing linguistic processing abilities. By this age, infants already show an impressive cognitive toolkit: they are sensitive to goal-directed actions and agency (<xref ref-type="bibr" rid="R20">20</xref>), track changes in goal-directed behavior (<xref ref-type="bibr" rid="R21">21</xref>), and extract key information from video stimuli to understand events (<xref ref-type="bibr" rid="R22">22</xref>). At the same time, young infants struggle to process goal predictions (<xref ref-type="bibr" rid="R23">23</xref>) and third-party social interactions (<xref ref-type="bibr" rid="R24">24</xref>). As infants develop, language and event perception become increasingly intertwined, as documented by the way verbs and actions are processed (<xref ref-type="bibr" rid="R25">25</xref>).</p><p id="P7">Currently, our understanding of agent-privileged event cognition in humans rests mainly on paradigms that use static stimuli, which are often artificial or overly simplistic, and do not reflect the complexity of real-life interactions. In this study, we used dynamic scenarios across a broad range of natural events to compare overt visual attention to agents and patients as the actions unfold. Scenarios were presented as <italic>N</italic>=84 short (2-10 s long), silent video clips, depicting animate agents and both animate and inanimate patients of (unfamiliar) humans, chimpanzees, gorillas, and orangutans engaged in natural interactions. All participants saw the same stimuli (<xref ref-type="supplementary-material" rid="SD1">Supplementary Material Table 1</xref>). When creating the videos, we deliberately avoided rigidly controlling for low-level perceptual features, as this would have created sterile footage with low socio-ecological validity (<xref ref-type="bibr" rid="R26">26</xref>) and, critically, reduced interest for ape participants. Instead, we presented scenes that sought to capture much greater variation of real life. Possible confounding factors, such as differences in the amount of agent motion or relatively larger sizes of agents or patients between videos, were accounted for in the statistical models (see <xref ref-type="supplementary-material" rid="SD1">Methods</xref> section in the Supplementary Material; <xref ref-type="supplementary-material" rid="SD1">Supplementary Material Figures 5 &amp; 6</xref>).</p><p id="P8">For human adults, we expected to see early and overall agent biases, consistent with previous findings, but with attention patterns mediated by the progression of the action rather than the need to extract agent-patient information rapidly, as in brief exposure studies (<xref ref-type="bibr" rid="R12">12</xref>). We predicted that if event decomposition were a general feature of great ape cognition and present without language, then visual attention should not differ across the four species. In particular, we predicted earlier attendance to agents than patients, in line with the privileged status of agents in language and gist apprehension in still pictures. Alternatively, if event decomposition were uniquely human — or dependent on language — we expected to find this pattern only in adult humans, and large and random variation in the nonhuman primates, which would likely depend on low-level features such as color or contrast of the stimuli. Regarding the infants, if event-role decomposition required experience gained through observing third-party interactions, we expected to see differences in how they attended to agents and patients compared with adults.</p><p id="P9">For the analysis, we ran two types of models. Firstly, we conducted a Bayesian time series analysis (for details, see <italic>Statistical analyses</italic> in the methods), for which we split the videos into scenes depicting social interactions (i.e., with animate patients) and scenes depicting interactions with inanimate patients. Preliminary examination of the data revealed large heterogeneity in the time course data between videos, which was not captured by either differences in inanimate and social videos, or relative AOI size (see <xref ref-type="supplementary-material" rid="SD1">Methods</xref> for more details on accounting for differences in AOI size). To determine where these gaze differences came from, we explored the videos with heterogeneous responses, which concerned specifically inanimate videos of apes. From these scenarios, we identified four categories that might explain the resulting variance: 1) Scenes generally containing food, 2) tool use, such as nut cracking or honey dipping, 3) instances where the agent or patient were oriented towards the camera, and 4) instances where the agent or patient had direct gaze towards the camera, something that could have been perceived as threatening by some ape participants. To estimate the effects of these categories, we fitted additional models (figures for these models can be viewed in a dashboard within the <xref ref-type="supplementary-material" rid="SD1">Supplementary data</xref>, at <ext-link ext-link-type="uri" xlink:href="https://osf.io/47wap/?view_only=8c2b20667fc441178269291fda5262bf">https://osf.io/47wap/?view_only=8c2b20667fc441178269291fda5262bf</ext-link>). These models indicated a clear difference in gaze patterns to inanimate scenes containing food, compared to those containing objects. We thus further split the inanimate videos into those containing food or not.</p><p id="P10">GLMMs such as ours are best understood by examining model predictions given different values of the covariates (time, species, condition), rather than interpreting individual coefficients. This is due to both the large number of parameters in multilevel models and the non-linearity induced by the link function. As such, we draw on the credible intervals of the models’ predictions at multiple time points to interpret the data (<xref ref-type="bibr" rid="R27">27</xref>) (see, for example, <xref ref-type="fig" rid="F1">Figures 1</xref> and <xref ref-type="fig" rid="F2">2</xref>). Four main findings emerged. Firstly, in both adult humans and apes, after accounting for attention to background information, there was an early focus on the action with attentional switches between agents and patients, suggesting participants engaged in relational encoding, similar to what humans do when asked to describe actions depicted in still images (<xref ref-type="fig" rid="F1">Figure 1</xref>; <xref ref-type="supplementary-material" rid="SD1">Supplementary Material Table 3</xref>). Secondly, in both adult humans and apes, the inanimate food condition triggered a striking bias towards agents at the onset of the action (with posterior probabilities for log odds ratios of agent vs. patient fixations all being above 0), absent from the other conditions (<xref ref-type="fig" rid="F1">Figure 1</xref>). For humans, agents remained salient throughout the scenario, whilst for apes, this gaze pattern was less pronounced. Thirdly, human adults directed most of their visual attention to agents and patients, whilst apes attended more to other information. This effect was slightly stronger for orangutans, suggesting a possible phylogenetic emergence of event role attribution (<xref ref-type="fig" rid="F2">Figure 2</xref>; <xref ref-type="supplementary-material" rid="SD1">Supplementary Material Tables 4 - 5</xref>; <xref ref-type="supplementary-material" rid="SD1">Supplementary Material Figures 2-4</xref>). Finally, human infants radically differed from the other groups, by attending mostly to other, non-agent and non-patient, information within each scene (<xref ref-type="fig" rid="F2">Figure 2</xref>).</p><p id="P11">In addition to the time series analysis, we fitted a Dirichlet model that examined whether accounting for event roles better explained gaze patterns than any of the covariates (such as relative size of agents and patients), by comparing two models that differed in their expectations about gaze proportion to agents and patients (for details, see <italic>Trial Averaged Model Comparison</italic> in the methods). A null model predicted that, assuming event roles were not needed to differentiate two entities, gaze proportion to agents and patients should be equal. An alternative model predicted that, assuming event roles better explained gaze patterns to two entities, gaze proportion would differ between agents and patients. Results indicated that the non-null model (i.e., assuming different gaze proportions to agents and patients) better predicted the gaze patterns, indicating that participants do not simply differentiate between two entities, but between the roles attached to those entities (<xref ref-type="table" rid="T1">Table 1</xref>).</p><p id="P12">Evolutionary theories of syntax have focused mainly on how formal complexity has emerged (<xref ref-type="bibr" rid="R28">28</xref>–<xref ref-type="bibr" rid="R30">30</xref>), whereas the underlying cognitive mechanisms have rarely been addressed. Here, we tested a cognitive hypothesis, which proposes that central aspects of human syntax, such as case-marking or constituent hierarchy, build on a prelinguistic cognitive mechanism that decomposes events into causally structured agent-patient relations (<xref ref-type="bibr" rid="R1">1</xref>). To test this, we exposed apes to stimuli that elicit causal processing in humans, and compared the gaze patterns between humans and nonhuman apes. Participants across species tracked events in strikingly similar ways, focusing on the action between agents and patients in a manner reminiscent of relational encoding for planning to speak (<xref ref-type="bibr" rid="R6">6</xref>). This finding suggests that apes, like humans, decompose the causal agent-patient roles depicted. The only noticeable difference was that nonhuman apes showed more visual exploration of background information than humans, perhaps due to differences in experience with watching and interpreting videos or higher intrinsic interest in scanning the larger environment. This is reflected in <xref ref-type="supplementary-material" rid="SD1">Supplementary Figures 2 and 3</xref>, where human adult attention to agents and patients is more pronounced, because these results do not account for attention to ‘other’ information. Notably, apes’ looking behavior showed more similarity to human adults than did human infants. If apes were unable to track agent-patient relations, we would expect attention patterns similar to those seen in infants. These observations reject the hypothesis that event decomposition emerged as a unique form of human cognition together with language.</p><p id="P13">Unexpectedly, across all event categories, in neither humans nor great apes did we find a strong bias towards agents (with the exception of food scenarios). This is in contrast to findings from a large body of previous research using static images, as well as a recent comparative study examining event role preferences (<xref ref-type="bibr" rid="R31">31</xref>). This difference is likely due to the nature of the stimuli. Static stimuli tap into rapid event perception (<xref ref-type="bibr" rid="R32">32</xref>) and usually capture the midpoint of an event, which increases the difficulty in identifying distinct roles, similar to when listeners have to come up with rapid predictions on roles while processing a sentence (<xref ref-type="bibr" rid="R33">33</xref>,<xref ref-type="bibr" rid="R34">34</xref>). It is likely that an agent bias manifests itself primarily under these high-demand conditions, while it is not as relevant when watching an event that unfolds over time (<xref ref-type="bibr" rid="R35">35</xref>). Additionally, unlike some previous studies, we controlled for size and movement of the areas of interest, as well as event type; size of the agent or patient, in particular, has a strong effect on gaze probability (<xref ref-type="supplementary-material" rid="SD1">Supplementary Material Figure 5</xref>). Curiously, when considering gaze differences between event categories, we found the strongest agent bias in video scenes depicting interactions with food. One possible explanation is that, in social species, attending to agents who have access to food provides a survival advantage. This points to social learning as a possible precursor for semantic role attribution. An intriguing possibility requiring further studies, therefore, is that the agent bias reported elsewhere has its roots in trophic interactions. Further research is needed to more systematically explore different degrees and kinds of cognitive pressure in event cognition and different ecological contexts of events.</p><p id="P14">The 6-month-old infants attended to agents and patients with very low probability. Perhaps this was due to a lack of experience with videos, which is somewhat inconsistent with the fact they showed an initial agency bias in food scenarios, and the fact that young infants have been able to attribute agency in other experiments (<xref ref-type="bibr" rid="R36">36</xref>). A more plausible explanation may be that infants this young have trouble detecting causality in complex visual material (<xref ref-type="bibr" rid="R37">37</xref>), especially in social interactions. Indeed, our stimuli were more complex than typically used in infant studies. However, these were chosen to reflect real-life diversity of events. Key ingredients, such as event parsing (<xref ref-type="bibr" rid="R38">38</xref>), causal integration across scenes (<xref ref-type="bibr" rid="R23">23</xref>) and triadic awareness (<xref ref-type="bibr" rid="R39">39</xref>), are known to develop gradually during the first 12 months, suggesting that our content was too challenging and probably too alien to their existing world experience. Another plausible hypothesis is that processing of dynamic natural scenes requires computational resources and oculomotor control not yet sufficiently developed at this age (<xref ref-type="bibr" rid="R40">40</xref>). As a consequence, integration and interpretation of relevant information is more time-consuming (<xref ref-type="bibr" rid="R22">22</xref>) or just not yet possible. Given that event categorisation relies on neurally constructed models which are updated with experience (<xref ref-type="bibr" rid="R41">41</xref>), it is likely that at this age, infants are still developing the event models that will guide their attention to scene information.</p><p id="P15">In sum, our study demonstrates that nonhuman great apes share with human adults the cognitive mechanism required for tracking agent-patient relations, which naturally triggers the question of why they do not have language. Earlier explanations that relied on human-animal morphological differences in vocal tracts (<xref ref-type="bibr" rid="R42">42</xref>), lack of declarative communication (<xref ref-type="bibr" rid="R43">43</xref>), and lack of call composition (<xref ref-type="bibr" rid="R44">44</xref>) no longer stand. Our results add to the shared cognitive foundations of language by indicating that event decomposition, a foundation of syntax, evolved before language, on par with signal combinations (<xref ref-type="bibr" rid="R45">45</xref>), theory of mind (<xref ref-type="bibr" rid="R46">46</xref>) and joint commitment (<xref ref-type="bibr" rid="R47">47</xref>).</p><p id="P16">What has happened then during human evolutionary history that allowed us to map event roles into verbal expression? We can think of three probably interlinked evolutionary transitions that may have paved the way from primate-like communication to human language: (a) changes in social cognition, (b) changes in communicative needs and (c) changes in expressive power. Regarding social cognition, the key step may have been to externalize event cognition through language, by moving from implicit to explicit attributions. For example, compared to chimpanzees, adult humans attend more to an agent’s face following an unexpected action outcome, as if explicitly trying to discern the actor’s mental state (<xref ref-type="bibr" rid="R48">48</xref>). Regarding communicative needs, one argument is that increased levels of cooperation and coordination brought about increased communicative needs, a convergent evolution independent of wider cognitive evolution (<xref ref-type="bibr" rid="R49">49</xref>,<xref ref-type="bibr" rid="R50">50</xref>). Finally, regarding expressive power, modern humans roughly have three-fold larger brains than chimpanzees, with vastly more computational power, allowing for processing of more varied signal structures. Although there are examples of limited compositionality in animal communication, there is no evidence for free variation and creative use (<xref ref-type="bibr" rid="R45">45</xref>). Testing these hypotheses may provide further answers in the quest for the origins of language by better understanding why nonhuman apes do not communicate in the same way as humans do, despite an increasingly closing gap with human cognitive abilities.</p><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary Materials</label><media xlink:href="EMS191753-supplement-Supplementary_Materials.pdf" mimetype="application" mime-subtype="pdf" id="d155aAdObB" position="anchor"/></supplementary-material></sec></body><back><ack id="S1"><title>Acknowledgements</title><p>For support and assistance at Basel Zoo we thank Adrian Baumeyer, Fabia Wyss, Raphaela Heesen, Stephan Lopez, Gaby Rindlisbacher, Rene Buob, Roland Kleger, Jonas Schaub, Nicole Fischer, Reto Lehmann, Corinne Zollinger, Markus Beutler, Dominic Hohler, Patrick Wyser, Flurin Baer, Amanda Spillmann, Stephan Argast, and the technician team. We also thank Carla Pascual for help with data collection. For providing footage from apes, we thank Emily Genty, Cat Hobaiter, Jennifer Botting, Erin Stromberg, and Atlanta Zoo, as well as Zurich Zoo for allowing us to film their apes. We thank Sara I. Fabrikant and Tumasch Reichenbacher for providing their eye-tracking laboratory for the human adult data collection and Sina Nägelin, Nina Philipp, and Deborah Lamm for collecting the data from human adults and infants, as well as Marco Bleiker for technical assistance with infant data collection. We thank Sebastien Quigley and Carla Pascual for assistance in data processing. We also thank Shreejata Gupta, Christopher Krupenye, and Josep Call for their advice on establishing the eye-tracking setups for data collection from great apes.</p><sec id="S2"><title>Funding</title><p>Swiss National Science Foundation (project grant numbers 310030_185324, K.Z., and 100015_182845, B.B.)</p><p>The National Center for Competence in Research “Evolving Language” (SNSF agreement number 51NF40_180888, B.B., K.Z., M.M.D., and Top-Up grant number N603-18-01, V.A.D.W., K.Z., B.B., M.M.D.)</p><p>Foundation for Research in Science and the Humanities at the University of Zurich (grant number 20-014, V.A.D.W., S.S., B.B.)</p><p>Seed money grant, University Research Priority Program “Evolution in Action”, University of Zurich (S.S.).</p></sec></ack><sec id="S3" sec-type="data-availability"><title>Data and Materials availability</title><p id="P17">Data and code are available at <ext-link ext-link-type="uri" xlink:href="https://osf.io/47wap/?view_only=8c2b20667fc441178269291fda5262bf">https://osf.io/47wap/?view_only=8c2b20667fc441178269291fda5262bf</ext-link></p></sec><fn-group><fn fn-type="con" id="FN2"><p id="P18"><bold>Author contributions</bold></p><p id="P19">Conceptualization: VADW, SS, SB, MMD, SW, BB, KZ</p><p id="P20">Methodology: VADW, SS, SB, MMD, SW, BB, KZ</p><p id="P21">Investigation: VADW, SB Software: SS, ER, NG</p><p id="P22">Validation: ER</p><p id="P23">Formal analysis: ER, VADW, SS, BB, KZ</p><p id="P24">Resources: VADW, SS, SB, MMD, CA, AI, BB, KZ</p><p id="P25">Data curation: VADW, SS, SB, SW, ER, NG</p><p id="P26">Visualization: ER, VADW, SS, BB</p><p id="P27">Writing - original draft: VADW</p><p id="P28">Writing - review and editing: VADW, SS, SB, MMD, EK, SW, NG, CA, AI, BB, KZ</p><p id="P29">Supervision: BB, KZ</p><p id="P30">Project administration: VADW</p><p id="P31">Funding acquisition: BB, KZ, VADW, SS, MMD</p></fn><fn fn-type="conflict" id="FN3"><p id="P32"><bold>Competing interests:</bold> The authors declare that they have no competing interests.</p></fn></fn-group><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>VAD</given-names></name><name><surname>Zuberbühler</surname><given-names>K</given-names></name><name><surname>Bickel</surname><given-names>B</given-names></name></person-group><article-title>The evolutionary origins of syntax: Event cognition in nonhuman primates</article-title><source>Sci Adv</source><year>2022</year><volume>8</volume><elocation-id>8464</elocation-id><pub-id pub-id-type="pmcid">PMC9216513</pub-id><pub-id pub-id-type="pmid">35731868</pub-id><pub-id pub-id-type="doi">10.1126/sciadv.abn8464</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frankland</surname><given-names>SM</given-names></name><name><surname>Greene</surname><given-names>JD</given-names></name></person-group><article-title>An architecture for encoding sentence meaning in left mid-superior temporal cortex</article-title><source>Proceedings of the National Academy of Sciences</source><year>2015</year><volume>112</volume><issue>37</issue><fpage>11732</fpage><lpage>7</lpage><pub-id pub-id-type="pmcid">PMC4577152</pub-id><pub-id pub-id-type="pmid">26305927</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1421236112</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bickel</surname><given-names>B</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Song</surname><given-names>JJ</given-names></name></person-group><chapter-title>Grammatical Relations Typology</chapter-title><source>The Oxford Handbook of Language Typology</source><year>2011</year><fpage>399</fpage><lpage>444</lpage><publisher-name>Oxford University Press</publisher-name><publisher-loc>Oxford</publisher-loc></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gil</surname><given-names>D</given-names></name></person-group><article-title>Where does predication come from?</article-title><source>The Canadian Journal of Linguistics/La revue canadienne de linguistique</source><year>2012</year><volume>57</volume><issue>2</issue><fpage>303</fpage><lpage>33</lpage></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bickel</surname><given-names>B</given-names></name><name><surname>Witzlack-Makarevich</surname><given-names>A</given-names></name><name><surname>Choudhary</surname><given-names>KK</given-names></name><name><surname>Schlesewsky</surname><given-names>M</given-names></name><name><surname>Bornkessel-Schlesewsky</surname><given-names>I</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Smith</surname><given-names>K</given-names></name></person-group><article-title>The neurophysiology of language processing shapes the evolution of grammar: Evidence from case marking</article-title><source>PLoS ONE</source><year>2015</year><volume>10</volume><issue>8</issue><elocation-id>e0132819</elocation-id><pub-id pub-id-type="pmcid">PMC4534460</pub-id><pub-id pub-id-type="pmid">26267884</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0132819</pub-id></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sauppe</surname><given-names>S</given-names></name><name><surname>Kamal</surname><given-names>CK</given-names></name><name><surname>Giroud</surname><given-names>N</given-names></name><name><surname>Blasi</surname><given-names>DE</given-names></name><name><surname>Norcliffe</surname><given-names>E</given-names></name><name><surname>Bhattamishra</surname><given-names>S</given-names></name><etal/></person-group><article-title>Neural signatures of syntactic variation in speech planning</article-title><source>PLoS Biology</source><year>2021</year><volume>19</volume><issue>1</issue><elocation-id>e3001038</elocation-id><pub-id pub-id-type="pmcid">PMC7837500</pub-id><pub-id pub-id-type="pmid">33497384</pub-id><pub-id pub-id-type="doi">10.1371/journal.pbio.3001038</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Egurtzegi</surname><given-names>A</given-names></name><name><surname>Blasi</surname><given-names>DE</given-names></name><name><surname>Bornkessel-Schlesewsky</surname><given-names>I</given-names></name><name><surname>Laka</surname><given-names>I</given-names></name><name><surname>Meyer</surname><given-names>M</given-names></name><name><surname>Bickel</surname><given-names>B</given-names></name><etal/></person-group><article-title>Cross-linguistic differences in case marking shape neural power dynamics and gaze behavior during sentence planning</article-title><source>Brain and Language</source><year>2022</year><volume>230</volume><elocation-id>105127</elocation-id><pub-id pub-id-type="pmid">35605312</pub-id></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dryer</surname><given-names>MS</given-names></name></person-group><chapter-title>Order of subject, object, and verb</chapter-title><source>The World Atlas of Language Structures Online</source><year>2013</year><publisher-name>Max-Planck-Institut für Evolutionäre Anthropologie</publisher-name></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Napoli</surname><given-names>DJ</given-names></name><name><surname>Sutton-Spence</surname><given-names>R</given-names></name></person-group><article-title>Order of the major constituents in sign languages: implications for all language</article-title><source>Front Psychol</source><year>2014</year><volume>5</volume><pub-id pub-id-type="pmcid">PMC4026690</pub-id><pub-id pub-id-type="pmid">24860523</pub-id><pub-id pub-id-type="doi">10.3389/fpsyg.2014.00376</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meir</surname><given-names>I</given-names></name><name><surname>Aronoff</surname><given-names>M</given-names></name><name><surname>Börstell</surname><given-names>C</given-names></name><name><surname>Hwang</surname><given-names>SO</given-names></name><name><surname>Ilkbasaran</surname><given-names>D</given-names></name><name><surname>Kastner</surname><given-names>I</given-names></name><etal/></person-group><article-title>The effect of being human and the basis of grammatical word order: Insights from novel communication systems and young sign languages</article-title><source>Cognition</source><year>2017</year><volume>158</volume><fpage>189</fpage><lpage>207</lpage><pub-id pub-id-type="pmid">27837693</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rissman</surname><given-names>L</given-names></name><name><surname>Majid</surname><given-names>A</given-names></name></person-group><article-title>Thematic roles: Core knowledge or linguistic construct?</article-title><source>Psychonomic Bulletin &amp; Review</source><year>2019</year><volume>26</volume><issue>6</issue><fpage>1850</fpage><lpage>69</lpage><pub-id pub-id-type="pmcid">PMC6863944</pub-id><pub-id pub-id-type="pmid">31290008</pub-id><pub-id pub-id-type="doi">10.3758/s13423-019-01634-5</pub-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>F</given-names></name><name><surname>Papafragou</surname><given-names>A</given-names></name><name><surname>Bunger</surname><given-names>A</given-names></name><name><surname>Trueswell</surname><given-names>J</given-names></name></person-group><source>Rapid extraction of event participants in caused motion events</source><conf-name>Proceedings of the Annual Meeting of the Cognitive Science Society</conf-name><year>2011</year></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Isasi-Isasmendi</surname><given-names>A</given-names></name><name><surname>Andrews</surname><given-names>C</given-names></name><name><surname>Flecken</surname><given-names>M</given-names></name><name><surname>Laka</surname><given-names>I</given-names></name><name><surname>Meyer</surname><given-names>M</given-names></name><name><surname>Bickel</surname><given-names>B</given-names></name><etal/></person-group><article-title>The agent preference in visual event apprehension</article-title><source>Open Mind</source><year>2023</year><volume>7</volume><fpage>240</fpage><lpage>82</lpage><pub-id pub-id-type="pmcid">PMC10320828</pub-id><pub-id pub-id-type="pmid">37416075</pub-id><pub-id pub-id-type="doi">10.1162/opmi_a_00083</pub-id></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Demiral</surname><given-names>ŞB</given-names></name><name><surname>Schlesewsky</surname><given-names>M</given-names></name><name><surname>Bornkessel-Schlesewsky</surname><given-names>I</given-names></name></person-group><article-title>On the universality of language comprehension strategies: Evidence from Turkish</article-title><source>Cognition</source><year>2008</year><volume>106</volume><issue>1</issue><fpage>484</fpage><lpage>500</lpage><pub-id pub-id-type="pmid">17336956</pub-id></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sauppe</surname><given-names>S</given-names></name><name><surname>Næss</surname><given-names>Å</given-names></name><name><surname>Roversi</surname><given-names>G</given-names></name><name><surname>Meyer</surname><given-names>M</given-names></name><name><surname>Bornkessel-Schlesewsky</surname><given-names>I</given-names></name><name><surname>Bickel</surname><given-names>B</given-names></name></person-group><article-title>An agent-first preference in a patient-first language during sentence comprehension</article-title><source>Cognitive Science</source><year>2023</year><volume>47</volume><issue>9</issue><elocation-id>e13340</elocation-id><pub-id pub-id-type="pmid">37715510</pub-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zuberbühler</surname><given-names>K</given-names></name></person-group><article-title>Event parsing and the origins of grammar</article-title><source>Wiley Interdisciplinary Reviews: Cognitive Science</source><year>2022</year><volume>13</volume><issue>3</issue><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="pmcid">PMC9285794</pub-id><pub-id pub-id-type="pmid">34929755</pub-id><pub-id pub-id-type="doi">10.1002/wcs.1587</pub-id></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cacchione</surname><given-names>T</given-names></name><name><surname>Krist</surname><given-names>H</given-names></name></person-group><article-title>Recognizing impossible object relations: Intuitions about support in chimpanzees (<italic>Pan troglodytes</italic>)</article-title><source>Journal of Comparative Psychology</source><year>2004</year><volume>118</volume><issue>2</issue><fpage>140</fpage><lpage>8</lpage><pub-id pub-id-type="pmid">15250801</pub-id></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bergman</surname><given-names>TJ</given-names></name><name><surname>Beehner</surname><given-names>JC</given-names></name><name><surname>Cheney</surname><given-names>DL</given-names></name><name><surname>Seyfarth</surname><given-names>RM</given-names></name></person-group><article-title>Hierarchical classification by rank and kinship in baboons</article-title><source>Science</source><year>2003</year><volume>302</volume><issue>5648</issue><fpage>1234</fpage><lpage>6</lpage><pub-id pub-id-type="pmid">14615544</pub-id></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Myowa-Yamakoshi</surname><given-names>M</given-names></name><name><surname>Scola</surname><given-names>C</given-names></name><name><surname>Hirata</surname><given-names>S</given-names></name></person-group><article-title>Humans and chimpanzees attend differently to goal-directed actions</article-title><source>Nat Commun</source><year>2012</year><volume>3</volume><issue>1</issue><fpage>693</fpage><pub-id pub-id-type="pmid">22353723</pub-id></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elsner</surname><given-names>B</given-names></name><name><surname>Adam</surname><given-names>M</given-names></name></person-group><article-title>Infants’ goal prediction for simple action events: The role of experience and agency cues</article-title><source>Topics in Cognitive Science</source><year>2021</year><volume>13</volume><issue>1</issue><fpage>45</fpage><lpage>62</lpage><pub-id pub-id-type="pmid">32128981</pub-id></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maffongelli</surname><given-names>L</given-names></name><name><surname>Antognini</surname><given-names>K</given-names></name><name><surname>Daum</surname><given-names>MM</given-names></name></person-group><article-title>Syntactical regularities of action sequences in the infant brain: When structure matters</article-title><source>Developmental Science</source><year>2018</year><volume>21</volume><issue>6</issue><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="pmid">29920867</pub-id></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Renswoude</surname><given-names>DR</given-names></name><name><surname>Visser</surname><given-names>I</given-names></name><name><surname>Raijmakers</surname><given-names>MEJ</given-names></name><name><surname>Tsang</surname><given-names>T</given-names></name><name><surname>Johnson</surname><given-names>SP</given-names></name></person-group><article-title>Real-world scene perception in infants: What factors guide attention allocation?</article-title><source>Infancy</source><year>2019</year><volume>24</volume><issue>5</issue><fpage>693</fpage><lpage>717</lpage><pub-id pub-id-type="pmid">32677279</pub-id></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ganglmayer</surname><given-names>K</given-names></name><name><surname>Attig</surname><given-names>M</given-names></name><name><surname>Daum</surname><given-names>MM</given-names></name><name><surname>Paulus</surname><given-names>M</given-names></name></person-group><article-title>Infants’ perception of goal-directed actions: A multi-lab replication reveals that infants anticipate paths and not goals</article-title><source>Infant Behavior and Development</source><year>2019</year><volume>57</volume><elocation-id>101340</elocation-id><pub-id pub-id-type="pmid">31387059</pub-id></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Farris</surname><given-names>K</given-names></name><name><surname>Kelsey</surname><given-names>CM</given-names></name><name><surname>Krol</surname><given-names>KM</given-names></name><name><surname>Thiele</surname><given-names>M</given-names></name><name><surname>Hepach</surname><given-names>R</given-names></name><name><surname>Haun</surname><given-names>DB</given-names></name><etal/></person-group><article-title>Processing third-party social interactions in the human infant brain</article-title><source>Infant Behavior and Development</source><year>2022</year><volume>68</volume><elocation-id>101727</elocation-id><pub-id pub-id-type="pmid">35667276</pub-id></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sciutti</surname><given-names>A</given-names></name><name><surname>Lohan</surname><given-names>KS</given-names></name><name><surname>Gredebäck</surname><given-names>G</given-names></name><name><surname>Koch</surname><given-names>B</given-names></name><name><surname>Rohlfing</surname><given-names>KJ</given-names></name></person-group><article-title>Language meddles with infants’ processing of observed actions</article-title><source>Front Robot AI</source><year>2016</year><volume>3</volume></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sonkusare</surname><given-names>S</given-names></name><name><surname>Breakspear</surname><given-names>M</given-names></name><name><surname>Guo</surname><given-names>C</given-names></name></person-group><article-title>Naturalistic stimuli in neuroscience: Critically acclaimed</article-title><source>Trends in Cognitive Sciences</source><year>2019</year><volume>23</volume><issue>8</issue><fpage>699</fpage><lpage>714</lpage><pub-id pub-id-type="pmid">31257145</pub-id></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>McElreath</surname><given-names>R</given-names></name></person-group><source>Statistical Rethinking</source><edition>Second Edition</edition><year>2020</year><publisher-loc>Boca Raton, FL</publisher-loc><publisher-name>CRC Press</publisher-name></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferrigno</surname><given-names>S</given-names></name><name><surname>Cheyette</surname><given-names>SJ</given-names></name><name><surname>Piantadosi</surname><given-names>ST</given-names></name><name><surname>Cantlon</surname><given-names>JF</given-names></name></person-group><article-title>Recursive sequence generation in monkeys, children, U.S. adults, and native Amazonians</article-title><source>Sci Adv</source><year>2020</year><volume>6</volume><issue>26</issue><elocation-id>eaaz1002</elocation-id><pub-id pub-id-type="pmcid">PMC7319756</pub-id><pub-id pub-id-type="pmid">32637593</pub-id><pub-id pub-id-type="doi">10.1126/sciadv.aaz1002</pub-id></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hauser</surname><given-names>MD</given-names></name><name><surname>Chomsky</surname><given-names>N</given-names></name><name><surname>Fitch</surname><given-names>WT</given-names></name></person-group><article-title>The faculty of language: What it is, who has it, and how did it evolve?</article-title><source>Science</source><year>2002</year><volume>298</volume><fpage>1569</fpage><lpage>79</lpage><pub-id pub-id-type="pmid">12446899</pub-id></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kirby</surname><given-names>S</given-names></name><name><surname>Cornish</surname><given-names>H</given-names></name><name><surname>Smith</surname><given-names>K</given-names></name></person-group><article-title>Cumulative cultural evolution in the laboratory: An experimental approach to the origins of structure in human language</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><year>2008</year><volume>105</volume><fpage>10681</fpage><lpage>6</lpage><pub-id pub-id-type="pmcid">PMC2504810</pub-id><pub-id pub-id-type="pmid">18667697</pub-id><pub-id pub-id-type="doi">10.1073/pnas.0707835105</pub-id></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brocard</surname><given-names>S</given-names></name><name><surname>Chloé</surname><given-names>VAD</given-names></name><name><surname>Zuberbühler</surname><given-names>K</given-names></name><name><surname>Bickel</surname><given-names>B</given-names></name></person-group><article-title>A universal preference for animate agents in hominids</article-title><source>Under review</source></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sauppe</surname><given-names>S</given-names></name><name><surname>Flecken</surname><given-names>M</given-names></name></person-group><article-title>Speaking for seeing: Sentence structure guides visual event apprehension</article-title><source>Cognition</source><year>2020</year><volume>206</volume><elocation-id>104516</elocation-id><pub-id pub-id-type="pmid">33228969</pub-id></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bornkessel-Schlesewsky</surname><given-names>I</given-names></name><name><surname>Schlesewsky</surname><given-names>M</given-names></name></person-group><source>Processing syntax and morphology: a neurocognitive perspective</source><year>2009</year><publisher-loc>Oxford</publisher-loc><publisher-name>Oxford University Press</publisher-name></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Su</surname><given-names>Y</given-names></name><name><surname>MacGregor</surname><given-names>LJ</given-names></name><name><surname>Olasagasti</surname><given-names>I</given-names></name><name><surname>Giraud</surname><given-names>AL</given-names></name></person-group><article-title>A deep hierarchy of predictions enables online meaning extraction in a computational model of human speech comprehension</article-title><source>PLOS Biology</source><year>2023</year><volume>21</volume><issue>3</issue><fpage>1</fpage><lpage>37</lpage><pub-id pub-id-type="pmcid">PMC10079236</pub-id><pub-id pub-id-type="pmid">36947552</pub-id><pub-id pub-id-type="doi">10.1371/journal.pbio.3002046</pub-id></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Papafragou</surname><given-names>A</given-names></name><name><surname>Hulbert</surname><given-names>J</given-names></name><name><surname>Trueswell</surname><given-names>J</given-names></name></person-group><article-title>Does language guide event perception? Evidence from eye movements</article-title><source>Cognition</source><year>2008</year><volume>108</volume><issue>1</issue><fpage>155</fpage><lpage>84</lpage><pub-id pub-id-type="pmcid">PMC2810627</pub-id><pub-id pub-id-type="pmid">18395705</pub-id><pub-id pub-id-type="doi">10.1016/j.cognition.2008.02.007</pub-id></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goupil</surname><given-names>N</given-names></name><name><surname>Papeo</surname><given-names>L</given-names></name><name><surname>Hochmann</surname><given-names>JR</given-names></name></person-group><article-title>Visual perception grounding of social cognition in preverbal infants</article-title><source>Infancy</source><year>2022</year><volume>27</volume><issue>2</issue><fpage>210</fpage><lpage>31</lpage><pub-id pub-id-type="pmid">35064958</pub-id></element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daum</surname><given-names>MM</given-names></name><name><surname>Gampe</surname><given-names>A</given-names></name><name><surname>Wronski</surname><given-names>C</given-names></name><name><surname>Attig</surname><given-names>M</given-names></name></person-group><article-title>Effects of movement distance, duration, velocity, and type on action prediction in 12-month-olds</article-title><source>Infant Behavior and Development</source><year>2016</year><volume>43</volume><fpage>75</fpage><lpage>84</lpage><pub-id pub-id-type="pmid">27175908</pub-id></element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yates</surname><given-names>TS</given-names></name><name><surname>Skalaban</surname><given-names>LJ</given-names></name><name><surname>Ellis</surname><given-names>CT</given-names></name><name><surname>Bracher</surname><given-names>AJ</given-names></name><name><surname>Baldassano</surname><given-names>C</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name></person-group><article-title>Neural event segmentation of continuous experience in human infants</article-title><source>PNAS</source><year>2022</year><volume>119</volume><issue>43</issue><elocation-id>e2200257119</elocation-id><pub-id pub-id-type="pmcid">PMC9618143</pub-id><pub-id pub-id-type="pmid">36252007</pub-id><pub-id pub-id-type="doi">10.1073/pnas.2200257119</pub-id></element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carpenter</surname><given-names>M</given-names></name><name><surname>Nagell</surname><given-names>K</given-names></name><name><surname>Tomasello</surname><given-names>M</given-names></name><name><surname>Butterworth</surname><given-names>G</given-names></name><name><surname>Moore</surname><given-names>C</given-names></name></person-group><article-title>Social cognition, joint attention, and communicative competence from 9 to 15 months of age</article-title><source>Monographs of the Society for Research in Child Development</source><year>1998</year><volume>63</volume><issue>4</issue><pub-id pub-id-type="pmid">9835078</pub-id></element-citation></ref><ref id="R40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pomaranski</surname><given-names>KI</given-names></name><name><surname>Hayes</surname><given-names>TR</given-names></name><name><surname>Kwon</surname><given-names>MK</given-names></name><name><surname>Henderson</surname><given-names>JM</given-names></name><name><surname>Oakes</surname><given-names>LM</given-names></name></person-group><article-title>Developmental changes in natural scene viewing in infancy</article-title><source>Developmental Psychology</source><year>2021</year><month>Jul</month><volume>57</volume><issue>7</issue><fpage>1025</fpage><lpage>41</lpage><pub-id pub-id-type="pmcid">PMC8406411</pub-id><pub-id pub-id-type="pmid">34435820</pub-id><pub-id pub-id-type="doi">10.1037/dev0001020</pub-id></element-citation></ref><ref id="R41"><label>41</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stawarczyk</surname><given-names>D</given-names></name><name><surname>Bezdek</surname><given-names>MA</given-names></name><name><surname>Zacks</surname><given-names>JM</given-names></name></person-group><article-title>Event representations and predictive processing: The role of the midline default network core</article-title><source>Topics in Cognitive Science</source><year>2021</year><volume>13</volume><issue>1</issue><fpage>164</fpage><lpage>86</lpage><pub-id pub-id-type="pmcid">PMC7984453</pub-id><pub-id pub-id-type="pmid">31486286</pub-id><pub-id pub-id-type="doi">10.1111/tops.12450</pub-id></element-citation></ref><ref id="R42"><label>42</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fitch</surname><given-names>WT</given-names></name></person-group><article-title>Empirical approaches to the study of language evolution</article-title><source>Psychon Bull Rev</source><year>2017</year><volume>24</volume><issue>1</issue><fpage>3</fpage><lpage>33</lpage><pub-id pub-id-type="pmid">28150125</pub-id></element-citation></ref><ref id="R43"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilke</surname><given-names>C</given-names></name><name><surname>Lahiff</surname><given-names>NJ</given-names></name><name><surname>Sabbi</surname><given-names>KH</given-names></name><name><surname>Watts</surname><given-names>DP</given-names></name><name><surname>Townsend</surname><given-names>SW</given-names></name><name><surname>Slocombe</surname><given-names>KE</given-names></name></person-group><article-title>Declarative referential gesturing in a wild chimpanzee (<italic>Pan troglodytes</italic>)</article-title><source>Proc Natl Acad Sci USA</source><year>2022</year><volume>119</volume><issue>47</issue><elocation-id>e2206486119</elocation-id><pub-id pub-id-type="pmcid">PMC9704713</pub-id><pub-id pub-id-type="pmid">36375066</pub-id><pub-id pub-id-type="doi">10.1073/pnas.2206486119</pub-id></element-citation></ref><ref id="R44"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leroux</surname><given-names>M</given-names></name><name><surname>Schel</surname><given-names>AM</given-names></name><name><surname>Wilke</surname><given-names>C</given-names></name><name><surname>Chandia</surname><given-names>B</given-names></name><name><surname>Zuberbühler</surname><given-names>K</given-names></name><name><surname>Slocombe</surname><given-names>KE</given-names></name><etal/></person-group><article-title>Call combinations and compositional processing in wild chimpanzees</article-title><source>Nature Communications</source><year>2023</year><volume>14</volume><issue>1</issue><elocation-id>2225</elocation-id><pub-id pub-id-type="pmcid">PMC10160036</pub-id><pub-id pub-id-type="pmid">37142584</pub-id><pub-id pub-id-type="doi">10.1038/s41467-023-37816-y</pub-id></element-citation></ref><ref id="R45"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Townsend</surname><given-names>SW</given-names></name><name><surname>Engesser</surname><given-names>S</given-names></name><name><surname>Stoll</surname><given-names>S</given-names></name><name><surname>Zuberbühler</surname><given-names>K</given-names></name><name><surname>Bickel</surname><given-names>B</given-names></name></person-group><article-title>Compositionality in animals and humans</article-title><source>PLoS Biol</source><year>2018</year><volume>16</volume><issue>8</issue><elocation-id>e2006425</elocation-id><pub-id pub-id-type="pmcid">PMC6093600</pub-id><pub-id pub-id-type="pmid">30110319</pub-id><pub-id pub-id-type="doi">10.1371/journal.pbio.2006425</pub-id></element-citation></ref><ref id="R46"><label>46</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krupenye</surname><given-names>C</given-names></name><name><surname>Kano</surname><given-names>F</given-names></name><name><surname>Hirata</surname><given-names>S</given-names></name><name><surname>Call</surname><given-names>J</given-names></name><name><surname>Tomasello</surname><given-names>M</given-names></name></person-group><article-title>Great apes anticipate that other individuals will act according to false beliefs</article-title><source>Science</source><year>2016</year><volume>354</volume><issue>6308</issue><fpage>110</fpage><lpage>4</lpage><pub-id pub-id-type="pmid">27846501</pub-id></element-citation></ref><ref id="R47"><label>47</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heesen</surname><given-names>R</given-names></name><name><surname>Bangerter</surname><given-names>A</given-names></name><name><surname>Zuberbühler</surname><given-names>K</given-names></name><name><surname>Rossano</surname><given-names>F</given-names></name><name><surname>Iglesias</surname><given-names>K</given-names></name><name><surname>Guery</surname><given-names>JP</given-names></name><etal/></person-group><article-title>Bonobos engage in joint commitment</article-title><source>Science Advances</source><year>2020</year><volume>6</volume><issue>51</issue><pub-id pub-id-type="pmid">33355132</pub-id></element-citation></ref><ref id="R48"><label>48</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Myowa-Yamakoshi</surname><given-names>M</given-names></name><name><surname>Yoshida</surname><given-names>C</given-names></name><name><surname>Hirata</surname><given-names>S</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Kendal</surname><given-names>RL</given-names></name></person-group><article-title>Humans but not chimpanzees vary face-scanning patterns depending on contexts during action observation</article-title><source>PLoS ONE</source><year>2015</year><volume>10</volume><issue>11</issue><elocation-id>e0139989</elocation-id><pub-id pub-id-type="pmcid">PMC4633149</pub-id><pub-id pub-id-type="pmid">26535901</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0139989</pub-id></element-citation></ref><ref id="R49"><label>49</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burkart</surname><given-names>JM</given-names></name><name><surname>van Schaik</surname><given-names>CP</given-names></name></person-group><article-title>Cognitive consequences of cooperative breeding in primates?</article-title><source>Animal Cognition</source><year>2010</year><volume>13</volume><issue>1</issue><fpage>1</fpage><lpage>19</lpage><pub-id pub-id-type="pmid">19629551</pub-id></element-citation></ref><ref id="R50"><label>50</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heesen</surname><given-names>R</given-names></name><name><surname>Bangerter</surname><given-names>A</given-names></name><name><surname>Zuberbühler</surname><given-names>K</given-names></name><name><surname>Iglesias</surname><given-names>K</given-names></name><name><surname>Neumann</surname><given-names>C</given-names></name><name><surname>Pajot</surname><given-names>A</given-names></name><etal/></person-group><article-title>Assessing joint commitment as a process in great apes</article-title><source>iScience</source><year>2021</year><volume>24</volume><issue>8</issue><elocation-id>102872</elocation-id><pub-id pub-id-type="pmcid">PMC8390869</pub-id><pub-id pub-id-type="pmid">34471860</pub-id><pub-id pub-id-type="doi">10.1016/j.isci.2021.102872</pub-id></element-citation></ref><ref id="R51"><label>51</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Segal</surname><given-names>SC</given-names></name><name><surname>Marquis</surname><given-names>AR</given-names></name><name><surname>Moulson</surname><given-names>MC</given-names></name></person-group><article-title>Are our samples representative? Understanding whether temperament influences infant dropout rates at 3 and 7 months</article-title><source>Infant Behavior and Development</source><year>2021</year><volume>65</volume><elocation-id>101630</elocation-id><pub-id pub-id-type="pmid">34418795</pub-id></element-citation></ref><ref id="R52"><label>52</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kano</surname><given-names>F</given-names></name><name><surname>Hirata</surname><given-names>S</given-names></name><name><surname>Deschner</surname><given-names>T</given-names></name><name><surname>Behringer</surname><given-names>V</given-names></name><name><surname>Call</surname><given-names>J</given-names></name></person-group><article-title>Nasal temperature drop in response to a playback of conspecific fights in chimpanzees: A thermo-imaging study</article-title><source>Physiology and Behavior</source><year>2016</year><volume>155</volume><fpage>83</fpage><lpage>94</lpage><pub-id pub-id-type="pmid">26657470</pub-id></element-citation></ref><ref id="R53"><label>53</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewis</surname><given-names>LS</given-names></name><name><surname>Kano</surname><given-names>F</given-names></name><name><surname>Stevens</surname><given-names>JMG</given-names></name><name><surname>DuBois</surname><given-names>JG</given-names></name><name><surname>Call</surname><given-names>J</given-names></name><name><surname>Krupenye</surname><given-names>C</given-names></name></person-group><article-title>Bonobos and chimpanzees preferentially attend to familiar members of the dominant sex</article-title><source>Animal Behaviour</source><year>2021</year><volume>177</volume><fpage>193</fpage><lpage>206</lpage><pub-id pub-id-type="pmcid">PMC8274698</pub-id><pub-id pub-id-type="pmid">34292277</pub-id><pub-id pub-id-type="doi">10.1016/j.anbehav.2021.06.014</pub-id></element-citation></ref><ref id="R54"><label>54</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Esaulova</surname><given-names>Y</given-names></name><name><surname>Dolscheid</surname><given-names>S</given-names></name><name><surname>Reuters</surname><given-names>S</given-names></name><name><surname>Penke</surname><given-names>M</given-names></name></person-group><article-title>The alignment of agent-first preferences with visual event representations: contrasting German and Arabic</article-title><source>Journal of Psycholinguistic Research</source><year>2021</year><elocation-id>0123456789</elocation-id><pub-id pub-id-type="pmcid">PMC8282564</pub-id><pub-id pub-id-type="pmid">33704632</pub-id><pub-id pub-id-type="doi">10.1007/s10936-020-09750-3</pub-id></element-citation></ref><ref id="R55"><label>55</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gleitman</surname><given-names>LR</given-names></name><name><surname>January</surname><given-names>D</given-names></name><name><surname>Nappa</surname><given-names>R</given-names></name><name><surname>Trueswell</surname><given-names>JC</given-names></name></person-group><article-title>On the give and take between event apprehension and utterance formulation</article-title><source>Journal of Memory and Language</source><year>2007</year><volume>57</volume><issue>4</issue><fpage>544</fpage><lpage>69</lpage><pub-id pub-id-type="pmcid">PMC2151743</pub-id><pub-id pub-id-type="pmid">18978929</pub-id><pub-id pub-id-type="doi">10.1016/j.jml.2007.01.007</pub-id></element-citation></ref><ref id="R56"><label>56</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Myachykov</surname><given-names>A</given-names></name><name><surname>Garrod</surname><given-names>S</given-names></name><name><surname>Scheepers</surname><given-names>C</given-names></name></person-group><article-title>Determinants of structural choice in visually situated sentence production</article-title><source>Acta Psychologica</source><year>2012</year><volume>141</volume><issue>3</issue><fpage>304</fpage><lpage>15</lpage><pub-id pub-id-type="pmid">23085142</pub-id></element-citation></ref><ref id="R57"><label>57</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pokhoday</surname><given-names>M</given-names></name><name><surname>Shtyrov</surname><given-names>Y</given-names></name><name><surname>Myachykov</surname><given-names>A</given-names></name></person-group><article-title>Effects of visual priming and event orientation on word order choice in russian sentence production</article-title><source>Front Psychol</source><year>2019</year><volume>10</volume><elocation-id>1661</elocation-id><pub-id pub-id-type="pmcid">PMC6710380</pub-id><pub-id pub-id-type="pmid">31481907</pub-id><pub-id pub-id-type="doi">10.3389/fpsyg.2019.01661</pub-id></element-citation></ref><ref id="R58"><label>58</label><element-citation publication-type="book"><collab>R Core Team</collab><source>R: A language and environment for statistical computing</source><year>2022</year><publisher-loc>Vienna</publisher-loc><publisher-name>R Foundation for Statistical Computing</publisher-name></element-citation></ref><ref id="R59"><label>59</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barr</surname><given-names>DJ</given-names></name></person-group><article-title>Analyzing ‘visual world’ eyetracking data using multilevel logistic regression</article-title><source>Journal of Memory and Language</source><year>2008</year><volume>59</volume><issue>4</issue><fpage>457</fpage><lpage>74</lpage></element-citation></ref><ref id="R60"><label>60</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cho</surname><given-names>SJ</given-names></name><name><surname>Brown-Schmidt</surname><given-names>S</given-names></name><name><surname>yeol</surname><given-names>Lee W</given-names></name></person-group><article-title>Autoregressive generalized linear mixed effect models with crossed random effects: an application to intensive binary time series eye-tracking data</article-title><source>Psychometrika</source><year>2018</year><volume>83</volume><issue>3</issue><fpage>751</fpage><lpage>71</lpage><pub-id pub-id-type="pmid">29417454</pub-id></element-citation></ref><ref id="R61"><label>61</label><element-citation publication-type="web"><collab>Stan Development Team</collab><source>Stan Modeling Language Users’ Guide and Reference Manual</source><year>2023</year><comment>[Internet] Available from<ext-link ext-link-type="uri" xlink:href="https://mc-stan.org">https://mc-stan.org</ext-link></comment></element-citation></ref><ref id="R62"><label>62</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salthouse</surname><given-names>TA</given-names></name><name><surname>Ellis</surname><given-names>CL</given-names></name></person-group><article-title>Determinants of eye-fixation duration</article-title><source>AJP</source><year>1980</year><volume>93</volume><issue>2</issue><fpage>207</fpage><lpage>34</lpage><pub-id pub-id-type="pmid">7406068</pub-id></element-citation></ref><ref id="R63"><label>63</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>YD</given-names></name><name><surname>Naughton</surname><given-names>BP</given-names></name><name><surname>Bondell</surname><given-names>HD</given-names></name><name><surname>Reich</surname><given-names>BJ</given-names></name></person-group><article-title>Bayesian regression using a prior on the model fit: The R2-D2 shrinkage prior</article-title><source>Journal of the American Statistical Association</source><year>2022</year><volume>117</volume><issue>538</issue><fpage>862</fpage><lpage>74</lpage></element-citation></ref><ref id="R64"><label>64</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aguilar</surname><given-names>JE</given-names></name><name><surname>Bürkner</surname><given-names>PC</given-names></name></person-group><article-title>Intuitive joint priors for Bayesian linear multilevel models: The R2D2M2 prior</article-title><source>Electron J Statist</source><year>2023</year><volume>17</volume><issue>1</issue></element-citation></ref><ref id="R65"><label>65</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vehtari</surname><given-names>A</given-names></name><name><surname>Gelman</surname><given-names>A</given-names></name><name><surname>Gabry</surname><given-names>J</given-names></name></person-group><article-title>Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC</article-title><source>Stat Comput</source><year>2017</year><volume>27</volume><issue>5</issue><fpage>1413</fpage><lpage>32</lpage></element-citation></ref><ref id="R66"><label>66</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yao</surname><given-names>Y</given-names></name><name><surname>Vehtari</surname><given-names>A</given-names></name><name><surname>Simpson</surname><given-names>D</given-names></name><name><surname>Gelman</surname><given-names>A</given-names></name></person-group><article-title>Using stacking to average Bayesian predictive distributions</article-title><source>Bayesian Analysis</source><year>2018</year><volume>10</volume><pub-id pub-id-type="doi">10.1214/17-BA1091</pub-id></element-citation></ref><ref id="R67"><label>67</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vehtari</surname><given-names>A</given-names></name><name><surname>Gelman</surname><given-names>A</given-names></name><name><surname>Gabry</surname><given-names>J</given-names></name><name><surname>Yao</surname><given-names>Y</given-names></name></person-group><article-title>Package ‘loo’</article-title><source>Efficient leave-one-out cross-validation and WAIC for Bayesian models</source><year>2021</year></element-citation></ref></ref-list></back><floats-group><boxed-text id="BX1" position="float" orientation="portrait"><caption><title>Significance statement</title></caption><p>Human adults and great apes, but not human infants, track natural events as agent-patient relations, a cognitive foundation for syntax.</p></boxed-text><fig id="F1" position="float"><label>Figure 1</label><caption><p>Model predictions of log odds ratio for fixation to either agent (red) or patient (orange) over time. Thick lines represent the grand mean, thin lines represent individual participants. Time point 0 on the x-axis indicates action start time, normalized across stimuli. Light shaded ribbons indicate 90% credible intervals. When these exceed 0, there is a 90% probability of gaze to the agent (light red); when they are below 0, there is a 90% probability of gaze to the patient (light orange); when they include zero, there is a 90% probability that gaze alternates between agent and patient. The darker shaded ribbons indicate the middle 50% of the posterior probability mass.</p></caption><graphic xlink:href="EMS191753-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><p>Model predictions of log odds ratio for fixation to agent or patient (orange) versus other (turquoise) over time. Thick lines represent the grand mean, thin lines represent individual participants. Time point 0 on the x-axis indicates action start time, normalized across stimuli. Light shaded ribbons refer to 90% credible intervals. They exceed 0 for humans, indicating gaze priority for agents and patients (orange). They are below 0 for human infants (turquoise) (with the exception of inanimate food), indicating gaze primarily to background information. 90% credible intervals for apes border around 0, indicating that attention is divided between agents and patients (orange) and other information (turquoise). Darker shaded intervals indicate the middle 50% of the posterior probability mass.</p></caption><graphic xlink:href="EMS191753-f002"/></fig><table-wrap id="T1" orientation="portrait" position="float"><label>Table 1</label><caption><title>Model comparison differentiating event role specification as a predictor of agent-patient gaze proportion</title></caption><table frame="hsides" rules="groups"><tbody><tr><td valign="top" align="center" style="border-top: 1px solid #000000;border-bottom: 2px solid #000000"/><td valign="top" align="center" style="border-top: 1px solid #000000;border-bottom: 2px solid #000000"/><td valign="top" align="center" style="border-top: 1px solid #000000;border-bottom: 2px solid #000000"><bold>Human adults</bold></td><td valign="top" align="center" style="border-top: 1px solid #000000;border-bottom: 2px solid #000000"/><td valign="top" align="center" style="border-top: 1px solid #000000;border-bottom: 2px solid #000000"/><td valign="top" align="center" style="border-top: 1px solid #000000;border-bottom: 2px solid #000000"/></tr><tr><td valign="top" align="right" style="border-right: 2px solid #7f7f7f"/><td valign="top" align="center">ELPD<sub>LOO</sub></td><td valign="top" align="center">SE(ELPD<sub>LOO</sub>)</td><td valign="top" align="center">Δ<sub>ELPD</sub></td><td valign="top" align="center">SE(Δ<sub>ELPD</sub>)</td><td valign="top" align="center">weight</td></tr><tr><td valign="top" align="right" style="border-right: 2px solid #7f7f7f"><italic>Null model</italic></td><td valign="top" align="center">1047.6</td><td valign="top" align="center">39</td><td valign="top" align="center">-509.9</td><td valign="top" align="center">43.5</td><td valign="top" align="center">0.058</td></tr><tr><td valign="top" align="right" style="border-bottom: 1px solid #000000;border-right: 2px solid #7f7f7f"><italic>Alternative model</italic></td><td valign="top" align="center" style="border-bottom: 1px solid #000000">1557.5</td><td valign="top" align="center" style="border-bottom: 1px solid #000000">46.2</td><td valign="top" align="center" style="border-bottom: 1px solid #000000"/><td valign="top" align="center" style="border-bottom: 1px solid #000000"/><td valign="top" align="center" style="border-bottom: 1px solid #000000">0.942</td></tr><tr><td valign="top" align="center" style="border-bottom: 1px solid #000000"/><td valign="top" align="center" style="border-bottom: 1px solid #000000"/><td valign="top" align="center" style="border-bottom: 1px solid #000000"><bold>Human infants</bold></td><td valign="top" align="center" style="border-bottom: 1px solid #000000"/><td valign="top" align="center" style="border-bottom: 1px solid #000000"/><td valign="top" align="center" style="border-bottom: 1px solid #000000"/></tr><tr><td valign="top" align="right" style="border-right: 2px solid #7f7f7f"/><td valign="top" align="center">ELPD_LOO</td><td valign="top" align="center">SE(ELPD_LOO)</td><td valign="top" align="center">ΔELPD</td><td valign="top" align="center">SE(ΔELPD)</td><td valign="top" align="center">weight</td></tr><tr><td valign="top" align="right" style="border-right: 2px solid #7f7f7f"><italic>Null model</italic></td><td valign="top" align="center">8762.4</td><td valign="top" align="center">184.4</td><td valign="top" align="center">-191</td><td valign="top" align="center">22.3</td><td valign="top" align="center">0.086</td></tr><tr><td valign="top" align="right" style="border-bottom: 1px solid #000000;border-right: 2px solid #7f7f7f"><italic>Alternative model</italic></td><td valign="top" align="center" style="border-bottom: 1px solid #000000">8953.3</td><td valign="top" align="center" style="border-bottom: 1px solid #000000">181.4</td><td valign="top" align="center" style="border-bottom: 1px solid #000000"/><td valign="top" align="center" style="border-bottom: 1px solid #000000"/><td valign="top" align="center" style="border-bottom: 1px solid #000000">0.914</td></tr><tr><td valign="top" align="center" style="border-bottom: 1px solid #000000"/><td valign="top" align="center" style="border-bottom: 1px solid #000000"/><td valign="top" align="center" style="border-bottom: 1px solid #000000"><bold>Apes</bold></td><td valign="top" align="center" style="border-bottom: 1px solid #000000"/><td valign="top" align="center" style="border-bottom: 1px solid #000000"/><td valign="top" align="center" style="border-bottom: 1px solid #000000"/></tr><tr><td valign="top" align="right" style="border-right: 2px solid #7f7f7f"/><td valign="top" align="left">ELPD_LOO</td><td valign="top" align="center">SE(ELPD_LOO)</td><td valign="top" align="center">ΔELPD</td><td valign="top" align="center">SE(ΔELPD)</td><td valign="top" align="center">weight</td></tr><tr><td valign="top" align="right" style="border-right: 2px solid #7f7f7f"><italic>Null model</italic></td><td valign="top" align="center">1325.9</td><td valign="top" align="center">63.8</td><td valign="top" align="center">-167</td><td valign="top" align="center">23.2</td><td valign="top" align="center">0.086</td></tr><tr><td valign="top" align="right" style="border-bottom: 1px solid #000000;border-right: 2px solid #7f7f7f"><italic>Alternative model</italic></td><td valign="top" align="center" style="border-bottom: 1px solid #000000">1492.9</td><td valign="top" align="center" style="border-bottom: 1px solid #000000">65.6</td><td valign="top" align="center" style="border-bottom: 1px solid #000000"/><td valign="top" align="center" style="border-bottom: 1px solid #000000"/><td valign="top" align="center" style="border-bottom: 1px solid #000000">0.914</td></tr></tbody></table><table-wrap-foot><p id="P33">Note. <italic>Null model</italic> = without event role as predictor. <italic>Alternative model</italic> = with event role as predictor. ELPD<sub>LOO</sub> is the expected log pointwise density, which indicates the predictive accuracy of the model. Δ<sub>ELPD</sub> indicates the difference in predictive accuracy between the null model and the alternative model. Model weights indicate the probability that the alternative model will predict new data better than the null model.</p></table-wrap-foot></table-wrap></floats-group></article>