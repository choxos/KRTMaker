<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS189367</article-id><article-id pub-id-type="doi">10.1101/2023.10.06.561171</article-id><article-id pub-id-type="archive">PPR738057</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">2</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Concurrent encoding of sequence predictability and event-evoked prediction error in unfolding auditory patterns</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Hu</surname><given-names>Mingyue</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-9613-8933</contrib-id><name><surname>Bianco</surname><given-names>Roberta</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Hidalgo</surname><given-names>Antonio Rodriguez</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-7808-3593</contrib-id><name><surname>Chait</surname><given-names>Maria</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib></contrib-group><aff id="A1"><label>1</label>Ear Institute, University College London, London, WC1X 8EE, United Kingdom</aff><aff id="A2"><label>2</label>Neuroscience of Perception &amp; Action Lab, Italian Institute of Technology (IΓTj, Rome, Italy</aff><author-notes><corresp id="CR1">Corresponding Author:Maria Chait <email>m.chait@ucl.ac.uk</email> Ear Institute, University College London, 332 Gray’s Inn Road, London WC1X 8EE, UK</corresp></author-notes><pub-date pub-type="nihms-submitted"><day>11</day><month>10</month><year>2023</year></pub-date><pub-date pub-type="preprint"><day>07</day><month>10</month><year>2023</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Human listeners possess an innate capacity to discern patterns within rapidly evolving auditory sequences. Core questions, at the forefront of ongoing research, focus on the mechanisms through which these representations are acquired and whether the brain prioritizes or suppresses predictable sensory signals.</p><p id="P2">Previous work, using fast sequences (tone-pips presented at a rate of 20Hz), revealed sustained response effects that appear to track the dynamic predictability of the sequence. Here we extend the investigation to slower sequences (4Hz), permitting the isolation of responses to individual tones. Stimuli were 50ms tone-pips, ordered into random (RND) and regular (REG; a repeating pattern of 10 frequencies) sequences; Two timing profiles were created: in ‘fast’ sequences tone-pips were presented in direct succession (20 Hz); in ‘slow’ sequences tone-pips were separated by a 200ms silent gap (4 Hz).</p><p id="P3">Naive participants (N=22; both sexes) passively listened to these sequences, while brain responses were recorded using magnetoencephalography (MEG). Results unveiled a heightened magnitude of sustained brain responses in REG when compared to RND patterns. This manifested from three tones after the onset of the pattern repetition, even in the context of slower sequences characterized by extended pattern durations (2500ms). This observation underscores the remarkable implicit sensitivity of the auditory brain to acoustic regularities. Importantly, brain responses evoked by single tones exhibited the opposite pattern - stronger responses to tones in RND compared to REG sequences. The demonstration of simultaneous but opposing sustained and evoked response effects reveals concurrent processes that shape the representation of unfolding auditory patterns.</p></abstract><kwd-group><kwd>Predictive Coding</kwd><kwd>Bayesian processing</kwd><kwd>Hearing</kwd><kwd>Auditory scene analysis</kwd><kwd>Expectation suppression</kwd><kwd>Precision</kwd></kwd-group></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P4">The physical rules that govern the environment and impose constraints on its agents result in statistically structured, predictable sensory signals. The brain is hypothesized to have developed the capacity to rapidly detect and track the regularities within these signals (<xref ref-type="bibr" rid="R18">de Lange et al., 2018</xref>; <xref ref-type="bibr" rid="R57">Press et al., 2020</xref>). This ability plays a crucial role in the comprehension of our surroundings, facilitating efficient recognition and processing of incoming information, to empower us to respond rapidly and adaptively to changing circumstances.</p><p id="P5">The auditory system, in particular, has demonstrated remarkable tuning to regularities across various time scales and dimensions (<xref ref-type="bibr" rid="R10">Bendixen, 2014</xref>; <xref ref-type="bibr" rid="R28">Heilbron &amp; Chait, 2018</xref>; Carbajal &amp; Malmierca, 2018; Asokan et al, 2019; Fitzgerald &amp; Todd, 2020). This plays a crucial role in our ability to understand spoken language (<xref ref-type="bibr" rid="R2">Arnal and Giraud, 2012</xref>), appreciate the nuances of musical compositions (<xref ref-type="bibr" rid="R34">Koelsch et al., 2019</xref>) and make sense of the complex soundscape that surrounds us. However, core questions regarding the mechanisms through which regularity is discovered and tracked remain elusive. In particular, pivotal issues revolve around whether the brain chooses to prioritize or suppress predictable sensory signals (<xref ref-type="bibr" rid="R57">Press et al, 2020</xref>).</p><p id="P6"><xref ref-type="bibr" rid="R6">Barascud et al. (2016)</xref>; see also (<xref ref-type="bibr" rid="R63">Sohoglu and Chait, 2016</xref>; <xref ref-type="bibr" rid="R64">Southwell et al., 2017</xref>; <xref ref-type="bibr" rid="R31">Herrmann and Johnsrude, 2018</xref>; <xref ref-type="bibr" rid="R30">Herrmann et al., 2019</xref>) provided insight into the brain's automatic ability to detect the emergence of predictable acoustic structure by examining low-frequency activity in the M/EEG signal. Using rapidly unfolding (20 Hz) tone-pip sequences that contained transitions from a random (RND) to a regularly repeating pattern (REG), they observed that a gradual increase in sustained power accompanies the emergence of repeating structures. The timing of the differentiation between REG and RND sequences (3 tones after the first cycle) was consistent with that predicted by an ideal observer model (<xref ref-type="bibr" rid="R55">Pearce, 2005</xref>; <xref ref-type="bibr" rid="R27">Harrison et al., 2020</xref>), demonstrating statistically efficient processing of structure even when not behaviourally relevant (<xref ref-type="bibr" rid="R6">Barascud et al., 2016</xref>).</p><p id="P7">The sustained response effect is interesting for several reasons: Firstly, it suggests that the brain encodes the inherent state of the stimulus (RND vs REG) rather than merely registering changes in the environment. Secondly, the observed <italic>increase</italic> in sustained power during structure discovery challenges our understanding of how the brain processes and represents predictability. Specifically, it appears to contradict expectations derived from predictive coding frameworks (e.g. <xref ref-type="bibr" rid="R21">Friston, 2005</xref>, <xref ref-type="bibr" rid="R22">2009</xref>; <xref ref-type="bibr" rid="R58">Rao &amp; Ballard, 1999</xref>), where predictable information is typically associated with <italic>reduced</italic> neural activity, as the brain can efficiently encode and predict upcoming events (<xref ref-type="bibr" rid="R18">de Lange et al., 2018</xref>). Barascud et al. showed that the sustained response, underpinned by activation in the auditory cortex, hippocampus, and inferior frontal gyrus, increases with the predictability of the ongoing stimulus sequence. This prompted the hypothesis that it might reflect the process of tracking the inferred reliability of the unfolding input (‘precision’; the accuracy, or conversely the ‘expected uncertainty’ with which future inputs can be predicted, <xref ref-type="bibr" rid="R53">O’Reilly et al., 2013</xref>) whereby predictable sensory streams are associated with heightened sensitivity.</p><p id="P8">Several issues need to be addressed for a better interpretation of the sustained response. Firstly, it is important to consider that the effects observed may be specific to the rapid sequences used in <xref ref-type="bibr" rid="R6">Barascud et al. (2016)</xref>. Other research (e.g. reviewed by (<xref ref-type="bibr" rid="R18">de Lange et al., 2018</xref>; <xref ref-type="bibr" rid="R28">Heilbron and Chait, 2018</xref>) has focused on slower patterns, which may elicit different neural responses. Secondly, it is crucial to determine whether the observed effect primarily reflects a shift in background neural activity or if it also extends to modulations of responses to individual events due to their integration within the structured sequence.</p><p id="P9">To address these questions, the current study expands upon the original stimulus by introducing silent gaps between successive tones (<xref ref-type="fig" rid="F1">Figure 1</xref>, <xref ref-type="fig" rid="F2">2</xref>). We aim to explore the generality of the sustained-response effects across different temporal scales and provide a clearer understanding of the mechanisms involved in the processing of structured auditory sequences.</p></sec><sec id="S2" sec-type="methods"><title>Methods</title><sec id="S3"><title>Experiment 1 - Online behavioural study</title><p id="P10">The behavioural study was designed to probe how the introduction of silent gaps between tones affects explicit pattern detection. We sought to pinpoint an optimal gap duration that is sufficiently long to allow us to isolate responses to individual tones, yet brief enough to maintain high-performance levels in pattern detection.</p><sec id="S4"><title>Stimuli</title><p id="P11">Stimuli were sequences of 50-ms tone-pips (gated on and off with 5-ms raised cosine ramps) drawn from a pool of 20 values equally spaced on a logarithmic scale between 222 and 2000 Hz (12% steps). The order in which these tone-pips were successively distributed defined two different sequence types. <bold>RND</bold> sequences consisted of 20 tone-pips (sampled from the full pool) arranged in random order. Each tone-pip occurred equi-probably across the sequence duration. <bold>RNDREG</bold> sequences contained a transition between a RND sequence, and a regularly repeating pattern (REG). REG consisted of 10 different tone-pips, randomly chosen from the full pool on each trial, and repeated in 3 identical cycles. The RND to REG transition always occurred after 30 tone-pips. Opting for this method, as opposed to a variable transition time, ensured a consistent context (in terms of frequency information available) both preceding each transition and across different gap duration conditions. RND and RNDREG sequences were generated anew for each trial and presented equi-probably throughout the experiment. Therefore, the occurrence of a transition in any given trial was unpredictable. The amplitude of each tone pip was normalized to yield an approximately similar perceived loudness (<xref ref-type="bibr" rid="R44">Moore, 2014</xref>). Across blocks, the inter-tone-intervals were manipulated to form four conditions (<xref ref-type="fig" rid="F1">Figure 1A</xref>): <bold>Gap0</bold> (continuous presentation), <bold>Gap100</bold> (a 100 ms gap inserted between tones), <bold>Gap200</bold> (a 200 ms gap inserted between tones), <bold>Gap500</bold> (a 500 ms gap inserted between tones).</p><p id="P12">Two control stimuli were also included: sequences of contiguous (no silent gap) tone-pips of a fixed frequency <bold>(CONT)</bold> that lasted 4000 ms, and sequences with a step change in frequency partway through the trial (<bold>STEP:</bold> the change always occurred after 2000 ms). These were used to measure individuals’ response time to simple acoustic changes and served as ‘catch trials’ to assess task engagement.</p></sec><sec id="S5" sec-type="methods"><title>Procedure</title><p id="P13">The experiment was implemented online using the Gorilla Experiment Builder (<ext-link ext-link-type="uri" xlink:href="http://www.gorilla.sc">www.gorilla.sc</ext-link>). Before the main task, participants completed a headphone screening task (<xref ref-type="bibr" rid="R42">Milne et al., 2020</xref>) to ensure they were using appropriate audio equipment. They then received an explanation of the task and completed a practice session. Due to length constraints, the experiment was divided into two parts, performed by two different groups of participants. Experiment 1a contained the Gap0, Gap100 and Gap200 conditions along with the control stimuli (STEP and CONT; see above). Experiment 1b contained the Gap0, Gap100 and Gap500 conditions, along with the control stimuli.</p><p id="P14">Participants were instructed to respond, by pressing a keyboard button, as soon as possible once they had detected a RNDREG transition or a STEP. To motivate participants to focus on the task, they were given feedback on their accuracy and speed after each trial. A small monetary bonus was given for each correct response (<xref ref-type="bibr" rid="R12">Bianco et al., 2021</xref>).</p><p id="P15">In each experiment, three blocks of 40 trials were delivered. Each block contained the following sequence types: 15 RNDREG, 15 RND, 5 STEP, and 5 CONT. The first block always presented the Gap0 condition. This block lasted 5 minutes. Thereafter, listeners completed the other two blocks (Gap100 and Gap200 in experiment1a, Gap100 and Gap500 in experiment1b) in random order. Starting with Gap0 ensured that all participants experienced the easiest condition first and had adequate opportunity to practice the regularity detection task, reducing the likelihood of frustration and dropout that may occur if participants are immediately faced with the most difficult condition. The main task in experiment 1a lasted about 20 minutes, and that in experiment 1b lasted about 30 minutes.</p></sec><sec id="S6"><title>Participant Rejection Criteria</title><p id="P16">Previous work (<xref ref-type="bibr" rid="R6">Barascud et al., 2016</xref>; <xref ref-type="bibr" rid="R11">Bianco et al., 2020</xref>) demonstrated that participants are sensitive to the emergence of regularity in RNDREG sequences, exhibiting high sensitivity and rapid detection time (usually responding within two regularity cycles). Due to the online nature of the present experiments and associated reduced control over participants’ environments, equipment, and engagement (<xref ref-type="bibr" rid="R12">Bianco et al., 2021</xref>), it was important to implement a series of rejection criteria to make sure that data reflect true sequence tracking sensitivity. Therefore, subjects were excluded from the experiment following the below criteria:
<list list-type="simple" id="L1"><list-item><label>1)</label><p id="P17">Failure on the Headphone screen: We used the task introduced by <xref ref-type="bibr" rid="R42">Milne et al. (2020)</xref>. Participants who failed the test did not proceed to the main experiment.</p></list-item><list-item><label>2)</label><p id="P18">Low performance in the practice run: To ensure participants understand the task, 24 trials with no gap (10 RNDREG, 10 RND, 2 CONT and 2 STEP) were given. Participants did not proceed to the main task if their correct response rate was below 80% in the practice task. This ensured that those participants who proceeded to the main experiment could detect the REG transitions, thus allowing us to focus on how performance is affected by increasing the gaps between tones. Our previous experience with similar stimuli in lab settings (see e.g. <xref ref-type="bibr" rid="R6">Barascud et al, 2016</xref>; <xref ref-type="bibr" rid="R11">Bianco et al, 2020</xref>) suggests that the vast majority of young participants can achieve ceiling performance. We, therefore, reasoned that those online participants who perform below 80% are likely not sufficiently engaged with the task (i.e. distracted, not following instructions, etc).</p></list-item><list-item><label>(3)</label><p id="P19">Of those participants who completed the full experiment, we rejected subjects who failed to respond to STEP trials (allowing at most one miss per block) or whose RT to STEP trials fell above 2 STDEV relative to the group mean. Failure to respond quickly to the (easy) STEP trials indicated low task engagement.</p></list-item></list>
</p></sec><sec id="S7" sec-type="subjects"><title>Participants</title><p id="P20">Two participant groups were recruited via the Prolific platform (<ext-link ext-link-type="uri" xlink:href="https://www.prolific.co/">https://www.prolific.co/</ext-link>). 29 subjects were included in the analysis of experiment1a (7 females; average age, 24.3 ± 4.79 years). 27 subjects were included in the analysis of experiment1b (6 females; average age: 22 ± 4.69 years).</p></sec></sec><sec id="S8"><title>Experiment 2 - MEG in naïve passively listening participants.</title><sec id="S9"><title>Stimuli</title><p id="P21">Stimuli (<xref ref-type="fig" rid="F2">Figure 2</xref>) were generated similarly to those in experiment 1. To reduce the duration of the (passive listening) MEG experiment, we focused on REG and RND sequences, without transitions. Sensitivity to regularity is investigated by comparing brain responses to the onset of REG and RND sequences. During the initial portion of the sequence (first cycle in REG), responses to the two sequence types should be identical, with differences emerging as soon as the auditory system has discovered that the pattern is repeating. Ideal observer modelling (<xref ref-type="bibr" rid="R6">Barascud et al., 2016</xref>; <xref ref-type="bibr" rid="R27">Harrison et al., 2020</xref>) suggests that about 3 tones, following the first cycle, are needed for the transition to be statistically detectable. REG sequences were generated by randomly selecting (without replacement) 10 frequencies from the pool and iterating that order to create a regularly repeating pattern. RND sequences consisted of a random succession of 10 tones, newly selected on each trial. All stimuli contained 60 tone-pips. Two timing conditions were used: in <bold>‘<italic>fast’</italic></bold> sequences tone-pips were presented in direct succession (20 Hz rate; 500ms REG cycle duration; 3 s overall sequence duration); in <italic>‘slow’</italic> sequences tone-pips were separated by a 200 ms silent gap (4 Hz rate; 2500ms REG cycle duration; 15 s overall sequence duration). One hundred instances of each condition were presented. Sequences were generated anew for each trial such that each stimulus was created of the same frequency “building blocks” (random selection of 10 out of 20 frequencies). Condition presentation was fully randomized.</p></sec><sec id="S10" sec-type="methods"><title>Procedure</title><p id="P22">The experiment was controlled with the Psychophysics Toolbox extension in MATLAB (<xref ref-type="bibr" rid="R33">Kleiner et al., 2007</xref>). All auditory stimuli were presented binaurally via tube earphones (EARTONE 3A 10 Ω; Etymotic Research) inserted into the ear canal, with the volume set at a comfortable listening level, adjusted for each participant.</p><p id="P23">The experiment lasted 40 minutes. Participants listened passively to the stimuli (presented in random order with an ISI jittered between 1400-1800 ms) and engaged in an incidental visual task. The task consisted of landscape images, grouped in triplets (the duration of each image was 5 s, with 2 s ISI between trials during which the screen was blank). Participants were instructed to fixate on a cross in the centre of the screen and press a button whenever the third image was identical to the first image (10% trials). The visual task served as a decoy task for diverting subjects’ attention away from the auditory stimuli. Participants were naïve to the nature of the auditory stimuli and encouraged to focus on the visual task. Feedback was displayed at the end of each block. The experimental session was divided into six 12 min blocks. Participants were allowed a short break between blocks but were required to remain still.</p></sec><sec id="S11" sec-type="subjects"><title>Participants</title><p id="P24">23 naïve subjects participated in the study. One of them was discarded due to excessive noise in the data. Data from 22 participants (11 females; average age, 25.14 ± 4.61 years) are reported below.</p></sec><sec id="S12"><title>Data recording and pre-processing</title><p id="P25">Magnetic signals were recorded using CTF-275 MEG system (axial gradiometers, 274 channels; 30 reference channels; VSM MedTech). The acquisition was continuous, with a sampling rate of 600 Hz. Offline low-pass filtering was applied at 30 Hz (all filtering in this study was performed with a two-pass, Butterworth filter with zero phase shift). All pre-processing and time domain analyses were performed using the fieldtrip toolbox (<xref ref-type="bibr" rid="R52">Oostenveld et al., 2011</xref>). To analyse time domain data, we selected the <bold>40 most responsive channels</bold> for each subject. This was done by collapsing across all conditions and identifying the M100 component of the onset response (<xref ref-type="bibr" rid="R47">Näätänen and Picton, 1987</xref>; <xref ref-type="bibr" rid="R66">Stufflebeam et al., 1998</xref>; <xref ref-type="bibr" rid="R46">Näätänen et al., 2011</xref>; <xref ref-type="bibr" rid="R26">Gorina-Careta et al., 2021</xref>), as a source-sink pair located over the temporal region of each hemisphere. For each subject, the 40 most strongly activated channels at the peak of the M100 (20 in each hemisphere; 10 in each sink/source) were considered to best reflect auditory activity and thus selected for all subsequent time-domain analyses. This procedure served the dual purpose of enhancing the relevant response components and compensating for any channel misalignment between subjects.</p><p id="P26">We report two time-domain analysis pipelines:</p></sec></sec><sec id="S13"><title>Whole sequence analysis</title><p id="P27">Initially, we focused on responses to the entire sequence. Low-frequency activity is of prime importance as a possible marker of predictability tracking (<xref ref-type="bibr" rid="R6">Barascud et al., 2016</xref>; <xref ref-type="bibr" rid="R64">Southwell et al., 2017</xref>). Therefore, no high-pass filter was used. Data were segmented into epochs from 200ms before onset to 1000ms post offset (yielding epochs of 4200ms and 16200ms in ‘fast’ and <italic>‘slow’</italic> conditions, respectively). Epochs containing artefacts were removed (based on variance summary statistics) variance using Fieldtrip’s manual visual artefact rejection function. Around 5% of epochs were removed from each subject (range 0-10%). The remaining epochs were then averaged by condition. To help denoise the data from <italic>‘slow’</italic> conditions (low-frequency drift artefacts) denoising source separation (DSS) analysis was applied to maximize reproducibility across trials. (<xref ref-type="bibr" rid="R61">Särelä and Valpola, 2005</xref>; <xref ref-type="bibr" rid="R17">de Cheveigné and Simon, 2008</xref>; <xref ref-type="bibr" rid="R16">de Cheveigné and Parra, 2014</xref>). For each subject, the three most significant components (i.e., the three ‘most reproducible’ components across trials) were kept and projected back into sensor space.</p></sec><sec id="S14"><title>The single-tone response analysis</title><p id="P28">A subsequent analysis focused on responses to individual tones in REG vs. RND sequences in the <italic>‘slow’</italic> sequences. To identify activity associated with individual tone-evoked responses which might be masked by the sustained activity, the raw data were high-pass filtered at 2Hz. Filtered data were then cut into individual tone epochs, from 50 ms before the onset of the tone, to 200 ms post onset. Responses from tones within each cycle were averaged, yielding 6 time series per condition per subject (tones in Cycle#1, Cycle#2, etc.). Time series were baselined based on pre-tone onset activity.</p><sec id="S15"><title>Statistical analysis</title><p id="P29">The time domain data are summarised as root-mean square (RMS) across the 40 selected channels for each subject (see above). The RMS is a useful summary signal, reflecting the instantaneous power of the neural response irrespective of its polarity. Group RMS (RMS of individual subject RMSs) is plotted; statistical analysis was always performed across subjects.</p><p id="P30">To evaluate differences between conditions (RND vs REG), the RMS differences at each time point were computed for each participant, and a bootstrap re-sampling (<xref ref-type="bibr" rid="R19">Efron and Tibshirani, 1998</xref>) was applied (10000 iterations) on the entire epoch. Significance was inferred by inspecting the proportion of bootstrap iterations that fell above or below zero, here p=0.01 was used as a threshold.</p></sec><sec id="S16"><title>Source analysis</title><p id="P31">To estimate the brain sources that underly the observed time domain effects at the sensor level, we performed source reconstruction using the standard approach implemented in SPM12 (<xref ref-type="bibr" rid="R38">Litvak and Friston, 2008</xref>; <xref ref-type="bibr" rid="R39">López et al., 2014</xref>; <xref ref-type="bibr" rid="R8">Bartha-Doering et al., 2015</xref>) Sensor-level data were converted from Fieldtrip to SPM. By using 3 fiducial marker locations, the data were co-registered to a generic 8196-vertex inverse-normalised canonical mesh warped to match the SPM’s template head model based on the MNI brain (<xref ref-type="bibr" rid="R3">Ashburner and Friston, 2005</xref>). This had the advantage of providing a one-to-one mapping between the individual's source-space and the template space, facilitating group analyses (<xref ref-type="bibr" rid="R38">Litvak and Friston, 2008</xref>). The forward model was solved with a single shell forward head model for all subjects. Source reconstruction was performed using the multiple sparse priors (MSP) model that assumes that activity can be expressed in multiple patches or covariance components, each of which has an associated hyperparameter (<xref ref-type="bibr" rid="R38">Litvak and Friston, 2008</xref>; <xref ref-type="bibr" rid="R39">López et al., 2014</xref>; <xref ref-type="bibr" rid="R8">Bartha-Doering et al., 2015</xref>). These were optimised with greedy search (GS) technique (<xref ref-type="bibr" rid="R38">Litvak and Friston, 2008</xref>) by iterating over successive partitions of multiple sparse priors to find the set yielding the best fit (here we specify a total of 512 total dipoles). The MSP model was used to identify distributed sources of brain activity, hence the 2 conditions (RND and REG) were inverted together.</p><p id="P32">We were interested in capturing the sources underlying two aspects of the data:
<list list-type="order" id="L2"><list-item><p id="P33">The discovery of regularity (REG vs RND) in the <italic>‘fast’</italic> sequence evoked response. The analysis used DSSed data (<xref ref-type="bibr" rid="R16">de Cheveigné and Parra, 2014</xref>), with the three most reproducible components projected back into sensor space and used for the inversion. Trials were averaged by condition and the inverse estimates were obtained for the two conditions together using an interval of 300ms between 665 and 965 ms post-stimulus onset. The interval was chosen to coincide with the timing of divergence between the REG and RND conditions as seen in the time domain analysis (<xref ref-type="fig" rid="F3">Figure 3</xref>).</p></list-item><list-item><p id="P34">The effect of regularity (REG vs. RND) on the individual tone responses in <italic>‘slow’</italic> sequences. A similar analysis pipeline as that described above was used. This analysis focused on the interval between 5 and 15 s – from the 3<sup>rd</sup> cycle of the REG until offset, i.e., where the regularity in REG stimuli was well established (theoretically, and, as seen in the time domain data, regularity is discovered partway through the 2<sup>nd</sup> cycle and well established by the 3<sup>rd</sup> cycle). The filtered raw signal (2-30 Hz), epoched over 0-200ms post tone onset and averaged across tone presentations, was used for the inversion. The interval was chosen to coincide with the largest possible time window post tone onset to allow the algorithm to encompass all brain sources responsible for generating the response (<xref ref-type="bibr" rid="R29">Henson et al., 2011</xref>).</p></list-item></list></p><p id="P35">After inversion, source activity for each condition was projected to a three-dimensional source space and smoothed [12-mm full width at half maximum (FWHM) Gaussian smoothing kernel] to create Neuroimaging Informatics Technology Initiative (NIfTI) images of source activity for each subject. At the second level of statistical analysis, the two conditions (REG vs RND) were modelled with the within-subject factor Regularity (REG / RND). Statistical maps of the contrast were thresholded at a level of p &lt; 0.05 uncorrected (F contrasts) across the whole-brain volume. Relevant brain regions were identified using the AAL3 toolbox (<ext-link ext-link-type="uri" xlink:href="https://www.oxcns.org/aal3.html">https://www.oxcns.org/aal3.html</ext-link>).</p></sec></sec></sec><sec id="S17" sec-type="results"><title>Results</title><sec id="S18"><title>Behavioural performance reveals good sensitivity to regularity even following the introduction of silent gaps between tones</title><p id="P36">We tested how pattern detection ability is affected by the introduction of a silent gap of increasing length between successive tone pips. <xref ref-type="fig" rid="F1">Figure 1B</xref> shows performance (quantified as d’ sensitivity score) for each condition in experiments 1a and 1b. With increasing gap duration, an overall gradual worsening of performance was observed. A repeated measures ANOVA over the three gap duration conditions in experiment 1a confirmed a main effect of condition [F (2, 56) = 3.814, η2 = .123, p = .026]. Post hoc tests (Bonferroni corrected) indicated a significant difference between Gap0 and Gap100 conditions [p = .034] and between Gap0 and Gap200 conditions [p = .026]. No difference between Gap100 and Gap200 was seen [p = 1]. In general, most participants achieved a d’ above 2 in the Gap200 condition, revealing a largely conserved sensitivity even though the duration of the pattern increased five-fold from 500ms in Gap0 to 2500ms in Gap200. In experiment 1b we further tested the performance for silence gaps of 500 ms. A repeated measures ANOVA with factor Gap (0, 100, 500 ms) confirmed a main effect of condition [F(2, 52) = 33.687, η2 = .564, p &lt; .001]. Post hoc (Bonferroni corrected) comparisons indicated significantly worse performance in Gap100 [p=.025] and Gap500 [p&lt;.001] compared to Gap0, and between Gap100 and Gap500 [p &lt; .001].</p><p id="P37">Overall, the pattern of results is consistent with a slow decline in performance for gaps up to 200ms and a steeper drop thereafter. We, therefore, selected the 200ms gap duration for the MEG experiments (in naïve distracted listeners) below.</p></sec><sec id="S19"><title>The emergence of regularity is associated with an increase in sustained MEG activity</title><p id="P38">The Group RMS (mean of all subjects’ RMSs) of the evoked response to the <italic>‘fast’</italic> sequences are shown in <xref ref-type="fig" rid="F3">Figure 3A</xref>. The brain response presents prototypical onset activity, followed by a subsequent rise to a sustained response that persists until offset. A pronounced offset response is seen about 100 ms after sound cessation. Fluctuations at 20 Hz, reflecting the tone presentation rate, are visible in the sustained portion of the response. In line with previous observations (<xref ref-type="bibr" rid="R6">Barascud et al., 2016</xref>; <xref ref-type="bibr" rid="R64">Southwell et al., 2017</xref>; <xref ref-type="bibr" rid="R65">Southwell and Chait, 2018</xref>), REG shows an increased sustained response when compared with RND. The timing at which the response to REG diverges from RND is considered to reflect the information required to detect the regularity. A significant difference between conditions emerged after 665 ms, (13 tone-pips, 1.3 cycles). This estimate is consistent with previous modelling work (<xref ref-type="bibr" rid="R6">Barascud et al., 2016</xref>; <xref ref-type="bibr" rid="R27">Harrison et al., 2020</xref>) which demonstrated that an ideal observer model required 3-4 tones following the first cycle to detect the emergence of regularity.</p><p id="P39"><xref ref-type="fig" rid="F3">Figure 3B</xref> displays the source analysis, applied over a 300 ms interval over which the REG and RND conditions begin to diverge (yellow shading in <xref ref-type="fig" rid="F3">Figure 3A</xref>). The activation map (F contrast, REG&gt;RND) demonstrates increased activity in auditory cortex (AC; bilaterally), inferior frontal gyrus (IFG; bilaterally) and hippocampus (HP; RH only). No areas were identified by using the opposite (RND &gt; REG) contrast. Overall, the source data are largely consistent with what was previously shown by <xref ref-type="bibr" rid="R6">Barascud et al. 2016</xref> for similar stimuli,confirming a distributed network spanning auditory, frontal and hippocampal sources which underlies sensitivity to regular patterns.</p><p id="P40">Responses to the <italic>‘slow’</italic> (Gap200) sequences are shown in <xref ref-type="fig" rid="F4">Figure 4A</xref>. Pronounced fluctuations at 4 Hz, reflecting the tone presentation rate, are clearly visible on top of the sustained response. Similar to what was observed for the <italic>‘fast’</italic> sequences, a difference in sustained response emerges between REG and RND when the REG pattern begins to repeat (after 2500ms). This effect is much smaller, however. To separate the sustained response from phasic activity associated with tone-evoked responses, the data were low pass filtered (0-2Hz; <xref ref-type="fig" rid="F4">Figure 4B</xref>). A significant difference between conditions emerged after 13 tones (3266 ms) consistent with the observations from the <italic>‘fast’</italic> sequence above. This suggests that irrespective of the rate at which tones are presented (at least within the range tested here), regularity detection requires a constant amount of information (as measured in number of tones pips). However, it is notable that the sustained difference between REG and RND conditions in the <italic>‘slow’</italic> sequences is smaller and rather noisier (e.g. as reflected by the discontinuous significance, see <xref ref-type="fig" rid="F4">Figure 4</xref>) than in the <italic>‘fast’</italic> sequences.</p><p id="P41">Overall, the MEG results demonstrate that passively elicited brain responses to REG relative to RND sequences are associated with significantly stronger sustained response magnitude, including when pattern durations are long (2500 ms in <italic>‘slow’</italic> sequences).</p><p id="P42">To focus on phasic activity associated with responses to individual tones, sequence-evoked responses were high pass filtered at 2Hz (<xref ref-type="fig" rid="F4">Figure 4C</xref>) and tone-centred epochs were extracted (from 50ms pre-tone-onset to 200ms post-tone-onset). The main analysis (<xref ref-type="fig" rid="F5">Figure 5</xref>), focused on tones presented in each cycle of the REG sequences (see indicated in <xref ref-type="fig" rid="F4">Figure 4C</xref>; 0-2.5 s; 2.5-5 s; 5-7.5 s; 7.5-10 s; 10-12.5 s; 2.5-15 s), and corresponding tones in RND sequences. As expected, no differences between conditions are seen in the first cycle (cycle#1) (<xref ref-type="fig" rid="F5">Figure 5A</xref>). In contrast, clear differences between tones presented in REG vs RND contexts are seen in cycle #2 onwards (<xref ref-type="fig" rid="F5">Figure 5B</xref>; cycle #6 also plotted; <xref ref-type="fig" rid="F5">Figure 5C</xref>). Critically, REG tones evoke <italic>reduced</italic> responses relative to RND tones. This effect appears to be specific to the latter part of the tone-evoked response: from ~100ms post tone onset, i.e., during the tone-evoked M100 peak.</p><p id="P43">An additional repeated measures ANOVA on response magnitude (mean power between 100-200ms post tone onset) with regularity (REG vs RND) and tone position in the 2<sup>nd</sup> – 6<sup>th</sup> cycles (i.e., from tone #11 to tone #60) as factors revealed a main effect of regularity only (F(1,21)=4.634, η2=.181, p=.043), with no effect of tone position (F(1,49)=1.063, η2=.048, p=.359) or interaction of the two factors (F(1,49)=.937, η2=.043, p=.599). Though clearly noisy, this tone-by-tone analysis reveals a sustained, stable difference between REG and RND conditions. As a control analysis, a repeated measures ANOVA on the first 10 tones in the sequence (cycle#1) indicated a main effect of tone position (F(1,21)=9.877, η2=.32, p&lt;.001) only. Post hoc tests indicated that the responses to the first two tones are significantly different from the third through tenth tones (p&lt;.01) in both REG and RND sequences, reflecting increased responses at sequence onset. Neither condition (F(1,9)=2.647, η2=.112, p=.119) nor the interaction of condition by tone position (F(1,9)=.556, η2=.026, p=.832) were significant. Together, these analyses confirm no difference between REG and RND during the first cycle (cycle#1), with a sustained difference between conditions emerging during the second cycle (cycle#2) onwards.</p><p id="P44">To further understand whether and how the tone-evoked responses in REG and RND contexts changed over time, we computed the mean evoked field differences between tones presented in the first and subsequent cycles in REG and RND conditions. Because responses to the initial couple of tones (first 2 tones in cycle#1) were affected by onset-response activity, we focused this analysis on the last eight tones of each cycle (cycle#1: tone 3-10; cycle#2: tone 13-20; and so on). The mean tone-evoked response (computed between 100-200 post onset) during cycle#1 was subtracted from that of cycle#2-#6 to understand how the presence of regularity affects tone responses. The data are plotted in <xref ref-type="fig" rid="F5">Figure 5D</xref>. A repeated measures ANOVA with condition and cycle number as factors yielded a main effect of condition only (F(1,21) =4.723, η2=.184, p=.041). No effect of cycle number (F(4,84)=1.078, η2=.049, p=.373) or interaction of those two factors (F(4,84)=1.087, η2=.049, p=.368) was observed. This indicates a sustained difference between REG and RND conditions, that does not change over time. A one-sample t-test (uncorrected) confirmed that such differences for cycles#2-#6 in the REG condition were below zero, i.e. consistently <italic>reduced</italic> relative to cycle 1. [cycle#2 t(1,21)=-3.102,d=-.661,p=.003; cycle#3 t(1,21)=-3.288,d=-.701,p=.002; cycle#4 t(1,21)=-3.702,d=-.789,p&lt;.001; cycle#5 t(1,21)=-2.161,d=-.461,p=.021; cycle#6 t(1,21)=- 2.478,d=-.528,p=.011]. In contrast, the same analysis for RND indicated non-significant effects [cycle#2 t(1,21)=-1.051,d=-.224,p=.153; cycle#3 t(1,21)=-1.7,d=-.363,p=.052; cycle#4 t(1,21)=-1.604,d=-.342,p=.062; cycle#5 t(1,21)=-1.829,d=-.390,p=.041; cycle#6 t(1,21)=-,125,d=-.027,p=.451].</p><p id="P45">Overall, the tone-evoked analysis demonstrates a consistent difference between tones presented in REG relative to RND contexts, the effect emerges early during the second regularity cycle (i.e. when the regularity has been established) and is manifested as a reduction in responses to REG tones, whilst responses to RND tones remain stable throughout the stimulus period.</p><p id="P46">Source localisation (see <xref ref-type="fig" rid="F5">Figure 5F</xref>) for the contrast RND&gt;REG during the tone-evoked response (full epoch – 0-200ms; extracted from the 3<sup>rd</sup> cycle until sequence offset; 5-15 s; i.e. after the regularity in REG has been established; see <xref ref-type="fig" rid="F4">Figure 4B</xref> and <xref ref-type="fig" rid="F5">Figure 5E</xref>) identified sources in bilateral temporal lobe (superior temporal gyrus, Heschel’s gyrus) and bilateral IFG that underly the time-domain effect. The opposite contrast (REG&gt;RND) yielded no significant activations.</p></sec><sec id="S20"><title>No significant correlation between tone-evoked and sustained-response effects</title><p id="P47">To investigate a potential link between the sustained response and tone evoked responses we correlated (spearman) the difference in the tone evoked response (REG-RND; mean power between 100-200ms post tone onset) with a difference in the sustained response (REG-RND; low pass filtered as in <xref ref-type="fig" rid="F4">Figure 4B</xref>) during Cycle#2 and Cycle#6 across subjects. Both analyses yielded non-significant effects (p&gt;0.2).</p><p id="P48">We also attempted more complex ridge regression analyses (<xref ref-type="bibr" rid="R9">Bates et al., 2015</xref>) over single trial data during Cycle#2 and Cycle#6 predicting the tone evoked response with the sustained response and trial number as predictors and subjects as random variable. No significant effects were observed (p&gt;0.29).</p></sec></sec><sec id="S21" sec-type="discussion"><title>Discussion</title><p id="P49">We demonstrated that an increased sustained response to regular (REG) compared to random (RND) patterns previously observed in rapid tone sequences (20Hz; 500ms cycle duration), also occurs in slower sequences (4Hz; 2500ms cycle duration). This confirms the auditory brain’s remarkable implicit sensitivity to complex patterns. Critically, brain responses evoked by single tones exhibited the opposite effect - lower responses to tones in REG compared to RND sequences. The observation of opposing sustained and evoked response effects reveals parallel processes that shape the representation of unfolding auditory patterns.</p><sec id="S22"><title>Sustained brain responses track pattern emergence even in slow sequences</title><p id="P50">Increased brain responses to predictable, relative to random patterns have previously been documented in many contexts (<xref ref-type="bibr" rid="R6">Barascud et al., 2016</xref>; <xref ref-type="bibr" rid="R63">Sohoglu and Chait, 2016</xref>; <xref ref-type="bibr" rid="R64">Southwell et al., 2017</xref>; <xref ref-type="bibr" rid="R31">Herrmann and Johnsrude, 2018</xref>; <xref ref-type="bibr" rid="R30">Herrmann et al., 2019</xref>). A greater amplitude for REG over RND stimuli is not easily interpretable as a response to physical attributes of the signal. Adaptation, for example, would result in the opposite pattern (<xref ref-type="bibr" rid="R40">Megela and Teyler, 1979</xref>; <xref ref-type="bibr" rid="R56">Pérez-González and Malmierca, 2014</xref>). Instead, the dynamics of this response, including when it diverges between REG and RND stimuli, suggest that the brain is sensitive to changes in the predictability of sound sequences. On an abstract level, observations regarding how the sustained response is modulated by sequence predictability suggest it might reflect the coding of precision, or <italic>inferred reliability,</italic> of the incoming sensory information (<xref ref-type="bibr" rid="R6">Barascud et al., 2016</xref>; <xref ref-type="bibr" rid="R24">Friston et al., 2017</xref>; <xref ref-type="bibr" rid="R28">Heilbron and Chait, 2018</xref>; <xref ref-type="bibr" rid="R74">Yon and Frith, 2021</xref>).</p><p id="P51">Here we showed that sustained response effects persist even when sequences are presented at a slower rate (4Hz). Despite the 5-fold increase in pattern duration, the divergence between REG and RND conditions occurred roughly at the same time (3 tones into the second cycle), in <italic>slow</italic> and <italic>fast</italic> sequences, consistent with ideal observer benchmarks (<xref ref-type="bibr" rid="R55">Pearce, 2005</xref>; <xref ref-type="bibr" rid="R6">Barascud et al., 2016</xref>; <xref ref-type="bibr" rid="R27">Harrison et al., 2020</xref>).</p><p id="P52">It is noteworthy that the sustained response was diminished in the <italic>slow</italic> compared to <italic>fast</italic> sequences. This could be attributed, at least in part, to limitations in human listeners' memory capacity. Indeed, <xref ref-type="bibr" rid="R6">Barascud et al. (2016)</xref> observed a reduced sustained response to REG sequences consisting of cycles of 15 tones relative to 10 tones. This was interpreted as indicative of a threshold in encoding patterns that emerges when detecting longer repeating cycles. Similarly, <xref ref-type="bibr" rid="R30">Herrmann et al. (2019)</xref> reported reduced sustained responses in older individuals compared to younger participants, hypothesizing that this reduction could stem from age-related decline in tracking regularity patterns. To detect the emergence of regularity, the auditory system must presumably maintain and update a statistical model of the auditory input, registering tone repetitions, and decide at which point there is sufficient evidence to indicate a regular pattern. The efficiency of this process relies on the interplay between echoic and short-/long-term memory capacity (<xref ref-type="bibr" rid="R11">Bianco et al., 2020</xref>; <xref ref-type="bibr" rid="R27">Harrison et al., 2020</xref>).In our study, the introduction of gaps between consecutive tones and the subsequent increase in cycle duration from 500 ms to 2500 ms likely strained short-term memory capacity, leading to less precise memory encoding and therefore overall lower precision for the slow sequences. The behavioural results indeed indicate a decline in pattern detection (<xref ref-type="fig" rid="F1">Figure 1</xref>). However, it is crucial to emphasize that despite this decline, the mean performance level remained high, underscoring the largely preserved sequence tracking capacity.</p><p id="P53">The brain mechanisms underlying the sustained response remain unclear. Source analysis suggests that the amplified response is driven by cortical activation in auditory, IFG and hippocampal sources (see also <xref ref-type="bibr" rid="R6">Barascud et al. (2016)</xref>. A similar network involving the auditory cortex and IFG has been implicated in the generation of the Mismatch Negativity response (<xref ref-type="bibr" rid="R45">Näätänen et al., 2012</xref>) and has been postulated to represent the circuit responsible for maintaining an auditory model and conveying predictions to lower processing levels (<xref ref-type="bibr" rid="R25">Garrido et al., 2009</xref>; <xref ref-type="bibr" rid="R28">Heilbron and Chait, 2018</xref>).</p><p id="P54">According to one interpretation, the sustained response might reflect an excitatory processing mechanism, characterized by an increase in gain, potentially via neuromodulation, on units responsible for encoding reliable sensory information (<xref ref-type="bibr" rid="R20">Feldman and Friston, 2010</xref>; <xref ref-type="bibr" rid="R4">Auksztulewicz et al., 2017</xref>). In particular, tonic Acetylcholine (ACh) has been shown to be modulated by environmental uncertainty (<xref ref-type="bibr" rid="R15">Dalley et al., 2001</xref>; <xref ref-type="bibr" rid="R75">Yu and Dayan, 2005</xref>; <xref ref-type="bibr" rid="R14">Bland and schaefer, 2012</xref>). However, this interpretation may be less tenable, as it predicts heightened responses to tones within the REG sequences, which is contrary to our observed findings (see below). Alternatively, the sustained response may indicate an enhancement in the inhibition of neuronal units that convey low information content. This is consistent with prior research, albeit involving simpler stimuli, where an increase in inhibitory activity linked to the presence of predictable information has been documented (<xref ref-type="bibr" rid="R48">Natan et al., 2015</xref>, <xref ref-type="bibr" rid="R49">2017</xref>; <xref ref-type="bibr" rid="R62">Schulz et al., 2021</xref>; <xref ref-type="bibr" rid="R60">Richter and Gjorgjieva, 2022</xref>; <xref ref-type="bibr" rid="R73">Yarden et al., 2022</xref>). Indirect evidence from dynamic causal modelling also suggests that the encoding of precision may be attributed to inhibitory mechanisms (<xref ref-type="bibr" rid="R36">Lecaignard et al., 2022</xref>). A specific role for inhibition, instead of excitation, in governing responses to predictable sensory stimuli, is also substantiated by behavioural findings: rather than capturing attention, predictable patterns are more easily ignored (<xref ref-type="bibr" rid="R64">Southwell et al., 2017</xref>) and are linked to reduced arousal (<xref ref-type="bibr" rid="R43">Milne et al., 2021</xref>). It is important to emphasize that M/EEG (or BOLD) do not readily differentiate between inhibitory and excitatory activity. Therefore, further advancement in understanding this phenomenon necessitates focused investigations at the cellular level.</p></sec><sec id="S23"><title>Reduced responses to tones in REG relative to RND patterns</title><p id="P55">Introducing temporal gaps between successive pips allowed us to disentangle the neural responses elicited by individual tones. Results revealed a reduction in neural activity in response to tones embedded within regularly repeating relatively to random patterns. This effect appears to be driven by relatively stable responses to tones in random patterns, but declining responses in the REG context. The dynamics of this effect are consistent with a step change in response magnitude during the second cycle (after the regularity has been introduced) that is then fixed for the remainder of the sequence.</p><p id="P56">Reduced response to REG tones is consistent with predictive coding theories (<xref ref-type="bibr" rid="R58">Rao and Ballard, 1999</xref>; <xref ref-type="bibr" rid="R37">Lee and Mumford, 2003</xref>; <xref ref-type="bibr" rid="R21">Friston, 2005</xref>, <xref ref-type="bibr" rid="R22">2009</xref>). According to these models, top-down expectations, derived from statistical regularities in the external world, play a crucial role in suppressing anticipated sensory input. This mechanism serves as an efficient neural coding scheme, optimizing the allocation of neural resources and enabling the brain to prioritize the processing of novel or unexpected information, which may hold greater relevance (<xref ref-type="bibr" rid="R50">Olshausen and Field, 1996</xref>, <xref ref-type="bibr" rid="R51">2004</xref>; <xref ref-type="bibr" rid="R21">Friston, 2005</xref>, <xref ref-type="bibr" rid="R22">2009</xref>; <xref ref-type="bibr" rid="R69">Tang et al., 2018</xref>). Empirical support for these predictions, often referred to as 'expectation suppression', has been mounting across sensory modalities, (<xref ref-type="bibr" rid="R5">Baldeweg, 2006</xref>; <xref ref-type="bibr" rid="R68">Summerfield et al., 2008</xref>; <xref ref-type="bibr" rid="R1">Alink et al., 2010</xref>; <xref ref-type="bibr" rid="R54">Ouden et al., 2010</xref>; <xref ref-type="bibr" rid="R70">Todorovic et al., 2011</xref>; <xref ref-type="bibr" rid="R35">Kok et al., 2012</xref>; <xref ref-type="bibr" rid="R71">Todorovic and Lange, 2012</xref>; <xref ref-type="bibr" rid="R7">Barbosa and Kouider, 2018</xref>; <xref ref-type="bibr" rid="R28">Heilbron and Chait, 2018</xref>). In the auditory domain, <xref ref-type="bibr" rid="R71">Todorovic and de Lange (2012)</xref> demonstrated that when tones were expected based on the probability structure of tone transitions, they elicited suppressed auditory activity within a specific time window of 100–200 ms. This suppression was uniquely attributable to the phenomenon of expectation suppression and distinct from adaptation (repetition suppression) effects.</p><p id="P57">Notably, the effects we report manifest within this same time-window (120-200ms; during the M100 phase of the response). Whilst it is difficult to exclude low-level processes such as adaptation, several patterns in the dynamics of the development of these effects suggest that simple adaptation is unlikely to be a main factor. Firstly, the effects require processes that persist for 2500ms (duration of a cycle). Secondly, we do not see a gradual reduction in responses to REG tones that builds up over cycles. Rather there is a step change in the second cycle that is then consistent for the remainder of the sequence.</p></sec><sec id="S24"><title>Multiplexed representation of sequence predictability</title><p id="P58">The challenge faced by sensory systems is to accurately and swiftly represent information to support adaptive behaviour and facilitate interaction with the environment. A fundamental question pertains to whether the brain primarily encodes predictable or novel information (<xref ref-type="bibr" rid="R57">Press et al., 2020</xref>). Bayesian cognitive models propose that our predisposition to perceive what we expect enhances the fidelity of our sensory experiences (<xref ref-type="bibr" rid="R72">Wyart et al., 2012</xref>; <xref ref-type="bibr" rid="R67">Summerfield and de Lange, 2014</xref>; <xref ref-type="bibr" rid="R32">Kaiser et al., 2019</xref>). In contrast, cancellation models suggest that our perceptual system prioritizes unexpected stimuli, as they carry an informative value (<xref ref-type="bibr" rid="R13">Blakemore et al., 1998</xref>; <xref ref-type="bibr" rid="R41">Meyer and Olson, 2011</xref>; <xref ref-type="bibr" rid="R59">Richter et al., 2018</xref>). In line with these considerations, predictive coding models (<xref ref-type="bibr" rid="R58">Rao and Ballard, 1999</xref>; <xref ref-type="bibr" rid="R21">Friston, 2005</xref>, <xref ref-type="bibr" rid="R22">2009</xref>) postulate the existence of two functionally distinct subpopulations of neurons within the brain. One encodes the conditional expectations of perceptual causes, while the other encodes prediction error.</p><p id="P59">Our findings confirm the coexistence of these facets of regularity coding within the MEG signal: the sustained response is consistent with the encoding of the predictability of the signal, whereas responses to individual tones appear to correspond to the coding of prediction error, as indicated by the reduced responses to predictable tones. Intriguingly, our results underscore the active involvement of the same neural network, encompassing the auditory cortex and the IFG, in both discovering structural patterns within auditory sequences and dampening responses to anticipated stimuli. However, the spatial resolution limitations inherent to MEG source analysis prevent definitive conclusions about the precise co-localization of these neural processes.</p><p id="P60">Indeed, the question of whether these manifestations stem from a singular process exhibiting differential characteristics in sustained and tone-evoked responses, or if they represent two distinct mechanisms, as proposed in previous works (<xref ref-type="bibr" rid="R58">Rao and Ballard, 1999</xref>; <xref ref-type="bibr" rid="R21">Friston, 2005</xref>, <xref ref-type="bibr" rid="R22">2009</xref>), emerges as a crucial avenue for future exploration. For example, it is possible that the sustained response reflects activity linked to a tonic inhibitory drive (implementing gain control) onto sensory units, resulting in a diminished evoked response to individual stimuli. Notably, our study did not reveal a correlational relationship between tone-evoked and sustained responses. While this may tentatively suggest no direct linkage between the two mechanisms, it's essential to consider the possibility that this observation could be influenced by the inherent noise in MEG measurements. We anticipate that more nuanced insights will be gleaned with the application of sensitive invasive tools in future investigations.</p></sec></sec></body><back><ack id="S25"><title>Acknowledgements</title><p>We thank Theofilos Petsas for contributing to data collection. This work was supported by a BBSRC project grant to MC. RB. is funded by the European Union (MSCA 101064334). The funders had no role in study design, data collection and analysis, decision to publish or preparation of the manuscript.</p></ack><sec id="S26" sec-type="data-availability"><title>Data sharing</title><p id="P61">The data reported in this manuscript alongside related information will be available on figshare upon publication.</p></sec><fn-group><fn id="FN1" fn-type="conflict"><p id="P62">Conflicts of interest:</p><p id="P63">The authors declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p></fn></fn-group><ref-list><ref id="R1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alink</surname><given-names>A</given-names></name><name><surname>Schwiedrzik</surname><given-names>CM</given-names></name><name><surname>Kohler</surname><given-names>A</given-names></name><name><surname>Singer</surname><given-names>W</given-names></name><name><surname>Muckli</surname><given-names>L</given-names></name></person-group><article-title>Stimulus Predictability Reduces Responses in Primary Visual Cortex</article-title><source>J Neurosci</source><year>2010</year><volume>30</volume><fpage>2960</fpage><lpage>2966</lpage><pub-id pub-id-type="pmcid">PMC6633950</pub-id><pub-id pub-id-type="pmid">20181593</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3730-10.2010</pub-id></element-citation></ref><ref id="R2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arnal</surname><given-names>LH</given-names></name><name><surname>Giraud</surname><given-names>A-L</given-names></name></person-group><article-title>Cortical oscillations and sensory predictions</article-title><source>Trends Cogn Sci</source><year>2012</year><volume>16</volume><fpage>390</fpage><lpage>398</lpage><pub-id pub-id-type="pmid">22682813</pub-id></element-citation></ref><ref id="R3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashburner</surname><given-names>J</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><article-title>Unified segmentation</article-title><source>NeuroImage</source><year>2005</year><volume>26</volume><fpage>839</fpage><lpage>851</lpage><pub-id pub-id-type="pmid">15955494</pub-id></element-citation></ref><ref id="R4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Auksztulewicz</surname><given-names>R</given-names></name><name><surname>Barascud</surname><given-names>N</given-names></name><name><surname>Cooray</surname><given-names>G</given-names></name><name><surname>Nobre</surname><given-names>AC</given-names></name><name><surname>Chait</surname><given-names>M</given-names></name><name><surname>Friston</surname><given-names>K</given-names></name></person-group><article-title>The Cumulative Effects of Predictability on Synaptic Gain in the Auditory Processing Stream</article-title><source>J Neurosci</source><year>2017</year><volume>37</volume><fpage>6751</fpage><lpage>6760</lpage><pub-id pub-id-type="pmcid">PMC5508257</pub-id><pub-id pub-id-type="pmid">28607165</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0291-17.2017</pub-id></element-citation></ref><ref id="R5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baldeweg</surname><given-names>T</given-names></name></person-group><article-title>Repetition effects to sounds: evidence for predictive coding in the auditory system</article-title><source>Trends Cogn Sci</source><year>2006</year><volume>10</volume><fpage>93</fpage><lpage>94</lpage><pub-id pub-id-type="pmid">16460994</pub-id></element-citation></ref><ref id="R6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barascud</surname><given-names>N</given-names></name><name><surname>Pearce</surname><given-names>MT</given-names></name><name><surname>Griffiths</surname><given-names>TD</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Chait</surname><given-names>M</given-names></name></person-group><article-title>Brain responses in humans reveal ideal observer-like sensitivity to complex acoustic patterns</article-title><source>Proc Natl Acad Sci</source><year>2016</year><volume>113</volume><fpage>E616</fpage><lpage>E625</lpage><pub-id pub-id-type="pmcid">PMC4747708</pub-id><pub-id pub-id-type="pmid">26787854</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1508523113</pub-id></element-citation></ref><ref id="R7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barbosa</surname><given-names>LS</given-names></name><name><surname>Kouider</surname><given-names>S</given-names></name></person-group><article-title>Prior Expectation Modulates Repetition Suppression without Perceptual Awareness</article-title><source>Sci Rep</source><year>2018</year><volume>8</volume><elocation-id>5055</elocation-id><pub-id pub-id-type="pmcid">PMC5864919</pub-id><pub-id pub-id-type="pmid">29568041</pub-id><pub-id pub-id-type="doi">10.1038/s41598-018-23467-3</pub-id></element-citation></ref><ref id="R8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bartha-Doering</surname><given-names>L</given-names></name><name><surname>Deuster</surname><given-names>D</given-names></name><name><surname>Giordano</surname><given-names>V</given-names></name><name><surname>am Zehnhoff-Dinnesen</surname><given-names>A</given-names></name><name><surname>Dobel</surname><given-names>C</given-names></name></person-group><article-title>A systematic review of the mismatch negativity as an index for auditory sensory memory: From basic research to clinical and developmental perspectives</article-title><source>Psychophysiology</source><year>2015</year><volume>52</volume><fpage>1115</fpage><lpage>1130</lpage><pub-id pub-id-type="pmid">26096130</pub-id></element-citation></ref><ref id="R9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bates</surname><given-names>D</given-names></name><name><surname>Mächler</surname><given-names>M</given-names></name><name><surname>Bolker</surname><given-names>B</given-names></name><name><surname>Walker</surname><given-names>S</given-names></name></person-group><article-title>Fitting Linear Mixed-Effects Models Using Ime4</article-title><source>J Stat Softw</source><year>2015</year><volume>67</volume><fpage>1</fpage><lpage>48</lpage></element-citation></ref><ref id="R10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bendixen</surname><given-names>A</given-names></name></person-group><article-title>Predictability effects in auditory scene analysis: a review</article-title><source>Front Neurosci</source><year>2014</year><volume>8</volume><date-in-citation>Accessed October 2, 2023</date-in-citation><comment>Available at</comment><pub-id pub-id-type="pmcid">PMC3978260</pub-id><pub-id pub-id-type="pmid">24744695</pub-id><pub-id pub-id-type="doi">10.3389/fnins.2014.00060</pub-id></element-citation></ref><ref id="R11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bianco</surname><given-names>R</given-names></name><name><surname>Harrison</surname><given-names>PM</given-names></name><name><surname>Hu</surname><given-names>M</given-names></name><name><surname>Bolger</surname><given-names>C</given-names></name><name><surname>Picken</surname><given-names>S</given-names></name><name><surname>Pearce</surname><given-names>MT</given-names></name><name><surname>Chait</surname><given-names>M</given-names></name></person-group><article-title>Long-term implicit memory for sequential auditory patterns in humans</article-title><person-group person-group-type="editor"><name><surname>Shinn-Cunningham</surname><given-names>BG</given-names></name><name><surname>Obleser</surname><given-names>J</given-names></name><name><surname>Schroger</surname><given-names>E</given-names></name><name><surname>Bieszczad</surname><given-names>K</given-names></name></person-group><source>eLife</source><year>2020</year><volume>9</volume><elocation-id>e56073</elocation-id><pub-id pub-id-type="pmcid">PMC7338054</pub-id><pub-id pub-id-type="pmid">32420868</pub-id><pub-id pub-id-type="doi">10.7554/eLife.56073</pub-id></element-citation></ref><ref id="R12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bianco</surname><given-names>R</given-names></name><name><surname>Mills</surname><given-names>G</given-names></name><name><surname>de Kerangal</surname><given-names>M</given-names></name><name><surname>Rosen</surname><given-names>S</given-names></name><name><surname>Chait</surname><given-names>M</given-names></name></person-group><article-title>Reward enhances online participants’ engagement with a demanding auditory task</article-title><source>Trends Hear</source><year>2021</year><volume>25</volume><elocation-id>23312165211025941</elocation-id><pub-id pub-id-type="pmcid">PMC8246484</pub-id><pub-id pub-id-type="pmid">34170748</pub-id><pub-id pub-id-type="doi">10.1177/23312165211025941</pub-id></element-citation></ref><ref id="R13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blakemore</surname><given-names>SJ</given-names></name><name><surname>Wolpert</surname><given-names>DM</given-names></name><name><surname>Frith</surname><given-names>CD</given-names></name></person-group><article-title>Central cancellation of self-produced tickle sensation</article-title><source>Nat Neurosci</source><year>1998</year><volume>1</volume><fpage>635</fpage><lpage>640</lpage><pub-id pub-id-type="pmid">10196573</pub-id></element-citation></ref><ref id="R14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bland</surname><given-names>A</given-names></name><name><surname>alexandre</surname><given-names>schaefer</given-names></name></person-group><article-title>Different Varieties of Uncertainty in Human Decision-Making</article-title><source>Front Neurosci</source><year>2012</year><volume>6</volume><date-in-citation>Accessed November 30, 2023</date-in-citation><comment>Available at</comment><pub-id pub-id-type="pmcid">PMC3370661</pub-id><pub-id pub-id-type="pmid">22701401</pub-id><pub-id pub-id-type="doi">10.3389/fnins.2012.00085</pub-id></element-citation></ref><ref id="R15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dalley</surname><given-names>JW</given-names></name><name><surname>McGaughy</surname><given-names>J</given-names></name><name><surname>O’Connell</surname><given-names>MT</given-names></name><name><surname>Cardinal</surname><given-names>RN</given-names></name><name><surname>Levita</surname><given-names>L</given-names></name><name><surname>Robbins</surname><given-names>TW</given-names></name></person-group><article-title>Distinct Changes in Cortical Acetylcholine and Noradrenaline Efflux during Contingent and Noncontingent Performance of a Visual Attentional Task</article-title><source>J Neurosci</source><year>2001</year><volume>21</volume><fpage>4908</fpage><lpage>4914</lpage><pub-id pub-id-type="pmcid">PMC6762350</pub-id><pub-id pub-id-type="pmid">11425918</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.21-13-04908.2001</pub-id></element-citation></ref><ref id="R16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Cheveigné</surname><given-names>A</given-names></name><name><surname>Parra</surname><given-names>LC</given-names></name></person-group><article-title>Joint decorrelation, a versatile tool for multichannel data analysis</article-title><source>NeuroImage</source><year>2014</year><volume>98</volume><fpage>487</fpage><lpage>505</lpage><pub-id pub-id-type="pmid">24990357</pub-id></element-citation></ref><ref id="R17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Cheveigné</surname><given-names>A</given-names></name><name><surname>Simon</surname><given-names>JZ</given-names></name></person-group><article-title>Denoising based on spatial filtering</article-title><source>J Neurosci Methods</source><year>2008</year><volume>171</volume><fpage>331</fpage><lpage>339</lpage><pub-id pub-id-type="pmcid">PMC2483698</pub-id><pub-id pub-id-type="pmid">18471892</pub-id><pub-id pub-id-type="doi">10.1016/j.jneumeth.2008.03.015</pub-id></element-citation></ref><ref id="R18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Lange</surname><given-names>FP</given-names></name><name><surname>Heilbron</surname><given-names>M</given-names></name><name><surname>Kok</surname><given-names>P</given-names></name></person-group><article-title>How Do Expectations Shape Perception?</article-title><source>Trends Cogn Sci</source><year>2018</year><volume>22</volume><fpage>764</fpage><lpage>779</lpage><pub-id pub-id-type="pmid">30122170</pub-id></element-citation></ref><ref id="R19"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Efron</surname><given-names>B</given-names></name><name><surname>Tibshirani</surname><given-names>R</given-names></name></person-group><source>An introduction to the bootstrap, Nachdr</source><publisher-name>Chapman Hall</publisher-name><publisher-loc>Boca Raton, Fla</publisher-loc><year>1998</year></element-citation></ref><ref id="R20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feldman</surname><given-names>H</given-names></name><name><surname>Friston</surname><given-names>K</given-names></name></person-group><article-title>Attention, Uncertainty, and Free-Energy</article-title><source>Front Hum Neurosci</source><year>2010</year><volume>4</volume><date-in-citation>Accessed September 29, 2023</date-in-citation><pub-id pub-id-type="pmcid">PMC3001758</pub-id><pub-id pub-id-type="pmid">21160551</pub-id><pub-id pub-id-type="doi">10.3389/fnhum.2010.00215</pub-id></element-citation></ref><ref id="R21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name></person-group><article-title>A theory of cortical responses</article-title><source>Philos Trans R Soc B Biol Sci</source><year>2005</year><volume>360</volume><fpage>815</fpage><lpage>836</lpage><pub-id pub-id-type="pmcid">PMC1569488</pub-id><pub-id pub-id-type="pmid">15937014</pub-id><pub-id pub-id-type="doi">10.1098/rstb.2005.1622</pub-id></element-citation></ref><ref id="R22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name></person-group><article-title>The free-energy principle: a rough guide to the brain?</article-title><source>Trends Cogn Sci</source><year>2009</year><volume>13</volume><fpage>293</fpage><lpage>301</lpage><pub-id pub-id-type="pmid">19559644</pub-id></element-citation></ref><ref id="R23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name><name><surname>Chu</surname><given-names>C</given-names></name><name><surname>Mourão-Miranda</surname><given-names>J</given-names></name><name><surname>Hulme</surname><given-names>O</given-names></name><name><surname>Rees</surname><given-names>G</given-names></name><name><surname>Penny</surname><given-names>W</given-names></name><name><surname>Ashburner</surname><given-names>J</given-names></name></person-group><article-title>Bayesian decoding of brain images</article-title><source>NeuroImage</source><year>2008</year><volume>39</volume><fpage>181</fpage><lpage>205</lpage><pub-id pub-id-type="pmid">17919928</pub-id></element-citation></ref><ref id="R24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name><name><surname>Fitz Gerald</surname><given-names>T</given-names></name><name><surname>Rigoli</surname><given-names>F</given-names></name><name><surname>Schwartenbeck</surname><given-names>P</given-names></name><name><surname>Pezzulo</surname><given-names>G</given-names></name></person-group><article-title>Active Inference: A Process Theory</article-title><source>Neural Comput</source><year>2017</year><volume>29</volume><fpage>1</fpage><lpage>49</lpage><pub-id pub-id-type="pmid">27870614</pub-id></element-citation></ref><ref id="R25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garrido</surname><given-names>Ml</given-names></name><name><surname>Kilner</surname><given-names>JM</given-names></name><name><surname>Stephan</surname><given-names>KE</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><article-title>The mismatch negativity: A review of underlying mechanisms</article-title><source>Clin Neurophysiol</source><year>2009</year><volume>120</volume><fpage>453</fpage><lpage>463</lpage><pub-id pub-id-type="pmcid">PMC2671031</pub-id><pub-id pub-id-type="pmid">19181570</pub-id><pub-id pub-id-type="doi">10.1016/j.clinph.2008.11.029</pub-id></element-citation></ref><ref id="R26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gorina-Careta</surname><given-names>N</given-names></name><name><surname>Kurkela</surname><given-names>JLO</given-names></name><name><surname>Hämäläinen</surname><given-names>J</given-names></name><name><surname>Astikainen</surname><given-names>P</given-names></name><name><surname>Escera</surname><given-names>C</given-names></name></person-group><article-title>Neural generators of the frequency-following response elicited to stimuli of low and high frequency: A magnetoencephalographic (MEG) study</article-title><source>NeuroImage</source><year>2021</year><volume>231</volume><elocation-id>117866</elocation-id><pub-id pub-id-type="pmid">33592244</pub-id></element-citation></ref><ref id="R27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harrison</surname><given-names>PMC</given-names></name><name><surname>Bianco</surname><given-names>R</given-names></name><name><surname>Chait</surname><given-names>M</given-names></name><name><surname>Pearce</surname><given-names>MT</given-names></name></person-group><article-title>PPM-Decay: A computational model of auditory prediction with memory decay</article-title><source>PLOS Comput Biol</source><year>2020</year><volume>16</volume><elocation-id>e1008304</elocation-id><pub-id pub-id-type="pmcid">PMC7668605</pub-id><pub-id pub-id-type="pmid">33147209</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008304</pub-id></element-citation></ref><ref id="R28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heilbron</surname><given-names>M</given-names></name><name><surname>Chait</surname><given-names>M</given-names></name></person-group><article-title>Great Expectations: Is there Evidence for Predictive Coding in Auditory Cortex?</article-title><source>Neuroscience</source><year>2018</year><volume>389</volume><fpage>54</fpage><lpage>73</lpage><pub-id pub-id-type="pmid">28782642</pub-id></element-citation></ref><ref id="R29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henson</surname><given-names>R</given-names></name><name><surname>Wakeman</surname><given-names>D</given-names></name><name><surname>Litvak</surname><given-names>V</given-names></name><name><surname>Friston</surname><given-names>K</given-names></name></person-group><article-title>A Parametric Empirical Bayesian Framework for the EEG/MEG Inverse Problem: Generative Models for Multi-Subject and Multi-Modal Integration</article-title><source>Front Hum Neurosci</source><year>2011</year><volume>5</volume><fpage>76</fpage><pub-id pub-id-type="pmcid">PMC3160752</pub-id><pub-id pub-id-type="pmid">21904527</pub-id><pub-id pub-id-type="doi">10.3389/fnhum.2011.00076</pub-id></element-citation></ref><ref id="R30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herrmann</surname><given-names>B</given-names></name><name><surname>Buckland</surname><given-names>C</given-names></name><name><surname>Johnsrude</surname><given-names>IS</given-names></name></person-group><article-title>Neural signatures of temporal regularity processing in sounds differ between younger and older adults</article-title><source>Neurobiol Aging</source><year>2019</year><volume>83</volume><fpage>73</fpage><lpage>85</lpage><pub-id pub-id-type="pmid">31585369</pub-id></element-citation></ref><ref id="R31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herrmann</surname><given-names>B</given-names></name><name><surname>Johnsrude</surname><given-names>IS</given-names></name></person-group><article-title>Neural Signatures of the Processing of Temporal Patterns in Sound</article-title><source>J Neurosci</source><year>2018</year><volume>38</volume><fpage>5466</fpage><lpage>5477</lpage><pub-id pub-id-type="pmcid">PMC8174133</pub-id><pub-id pub-id-type="pmid">29773757</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0346-18.2018</pub-id></element-citation></ref><ref id="R32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaiser</surname><given-names>D</given-names></name><name><surname>Quek</surname><given-names>GL</given-names></name><name><surname>Cichy</surname><given-names>RM</given-names></name><name><surname>Peelen</surname><given-names>MV</given-names></name></person-group><article-title>Object Vision in a Structured World</article-title><source>Trends Cogn Sci</source><year>2019</year><volume>23</volume><fpage>672</fpage><lpage>685</lpage><pub-id pub-id-type="pmcid">PMC7612023</pub-id><pub-id pub-id-type="pmid">31147151</pub-id><pub-id pub-id-type="doi">10.1016/j.tics.2019.04.013</pub-id></element-citation></ref><ref id="R33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kleiner</surname><given-names>M</given-names></name><name><surname>Brainard</surname><given-names>DH</given-names></name><name><surname>Pelli</surname><given-names>D</given-names></name><name><surname>Ingling</surname><given-names>A</given-names></name><name><surname>Murray</surname><given-names>R</given-names></name><name><surname>Broussard</surname><given-names>C</given-names></name></person-group><article-title>What’s new in Psychtoolbox-3</article-title><source>Perception</source><year>2007</year><volume>36</volume><fpage>1</fpage><lpage>16</lpage></element-citation></ref><ref id="R34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koelsch</surname><given-names>S</given-names></name><name><surname>Vuust</surname><given-names>P</given-names></name><name><surname>Friston</surname><given-names>K</given-names></name></person-group><article-title>Predictive Processes and the Peculiar Case of Music</article-title><source>Trends Cogn Sci</source><year>2019</year><volume>23</volume><fpage>63</fpage><lpage>77</lpage><pub-id pub-id-type="pmid">30471869</pub-id></element-citation></ref><ref id="R35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kok</surname><given-names>P</given-names></name><name><surname>Jehee</surname><given-names>JFM</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><article-title>Less Is More: Expectation Sharpens Representations in the Primary Visual Cortex</article-title><source>Neuron</source><year>2012</year><volume>75</volume><fpage>265</fpage><lpage>270</lpage><pub-id pub-id-type="pmid">22841311</pub-id></element-citation></ref><ref id="R36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lecaignard</surname><given-names>F</given-names></name><name><surname>Bertrand</surname><given-names>O</given-names></name><name><surname>Caclin</surname><given-names>A</given-names></name><name><surname>Mattout</surname><given-names>J</given-names></name></person-group><article-title>Neurocomputational Underpinnings of Expected Surprise</article-title><source>J Neurosci</source><year>2022</year><volume>42</volume><fpage>474</fpage><lpage>486</lpage><pub-id pub-id-type="pmcid">PMC8802931</pub-id><pub-id pub-id-type="pmid">34819342</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0601-21.2021</pub-id></element-citation></ref><ref id="R37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>TS</given-names></name><name><surname>Mumford</surname><given-names>D</given-names></name></person-group><article-title>Hierarchical Bayesian inference in the visual cortex</article-title><source>J Opt Soc Am A Opt Image Sci Vis</source><year>2003</year><volume>20</volume><fpage>1434</fpage><lpage>1448</lpage><pub-id pub-id-type="pmid">12868647</pub-id></element-citation></ref><ref id="R38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Litvak</surname><given-names>V</given-names></name><name><surname>Friston</surname><given-names>K</given-names></name></person-group><article-title>Electromagnetic source reconstruction for group studies</article-title><source>NeuroImage</source><year>2008</year><volume>42</volume><fpage>1490</fpage><lpage>1498</lpage><pub-id pub-id-type="pmcid">PMC2581487</pub-id><pub-id pub-id-type="pmid">18639641</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2008.06.022</pub-id></element-citation></ref><ref id="R39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>López</surname><given-names>JD</given-names></name><name><surname>Litvak</surname><given-names>V</given-names></name><name><surname>Espinosa</surname><given-names>JJ</given-names></name><name><surname>Friston</surname><given-names>K</given-names></name><name><surname>Barnes</surname><given-names>GR</given-names></name></person-group><article-title>Algorithmic procedures for Bayesian MEG/EEG source reconstruction in SPM</article-title><source>Neuroimage</source><year>2014</year><volume>84</volume><fpage>476</fpage><lpage>487</lpage><pub-id pub-id-type="pmcid">PMC3913905</pub-id><pub-id pub-id-type="pmid">24041874</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.09.002</pub-id></element-citation></ref><ref id="R40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Megela</surname><given-names>AL</given-names></name><name><surname>Teyler</surname><given-names>TJ</given-names></name></person-group><article-title>Habituation and the human evoked potential</article-title><source>J Comp Physiol Psychol</source><year>1979</year><volume>93</volume><fpage>1154</fpage><lpage>1170</lpage><pub-id pub-id-type="pmid">521525</pub-id></element-citation></ref><ref id="R41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname><given-names>T</given-names></name><name><surname>Olson</surname><given-names>CR</given-names></name></person-group><article-title>Statistical learning of visual transitions in monkey inferotemporal cortex</article-title><source>Proc Natl Acad Sci</source><year>2011</year><volume>108</volume><fpage>19401</fpage><lpage>19406</lpage><pub-id pub-id-type="pmcid">PMC3228439</pub-id><pub-id pub-id-type="pmid">22084090</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1112895108</pub-id></element-citation></ref><ref id="R42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Milne</surname><given-names>A</given-names></name><name><surname>Bianco</surname><given-names>R</given-names></name><name><surname>Poole</surname><given-names>K</given-names></name><name><surname>Zhao</surname><given-names>S</given-names></name><name><surname>Oxenham</surname><given-names>A</given-names></name><name><surname>Billig</surname><given-names>A</given-names></name><name><surname>Chait</surname><given-names>M</given-names></name></person-group><article-title>An online headphone screening test based on dichotic pitch</article-title><source>Behav Res Methods</source><year>2020</year><volume>53</volume><pub-id pub-id-type="pmcid">PMC7725427</pub-id><pub-id pub-id-type="pmid">33300103</pub-id><pub-id pub-id-type="doi">10.3758/s13428-020-01514-0</pub-id></element-citation></ref><ref id="R43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Milne</surname><given-names>A</given-names></name><name><surname>Zhao</surname><given-names>S</given-names></name><name><surname>Tampakaki</surname><given-names>C</given-names></name><name><surname>Bury</surname><given-names>G</given-names></name><name><surname>Chait</surname><given-names>M</given-names></name></person-group><article-title>Sustained pupil responses are modulated by predictability of auditory sequences</article-title><source>J Neurosci Off J Soc Neurosci</source><year>2021</year><volume>41</volume><fpage>6116</fpage><lpage>6127</lpage><pub-id pub-id-type="pmcid">PMC8276747</pub-id><pub-id pub-id-type="pmid">34083259</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2879-20.2021</pub-id></element-citation></ref><ref id="R44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moore</surname><given-names>BCJ</given-names></name></person-group><article-title>Development and Current Status of the Cambridge Loudness Models</article-title><source>Trends Hear</source><year>2014</year><volume>18</volume><elocation-id>2331216514550620</elocation-id><pub-id pub-id-type="pmcid">PMC4227665</pub-id><pub-id pub-id-type="pmid">25315375</pub-id><pub-id pub-id-type="doi">10.1177/2331216514550620</pub-id></element-citation></ref><ref id="R45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Näätänen</surname><given-names>R</given-names></name><name><surname>Kujala</surname><given-names>T</given-names></name><name><surname>Escera</surname><given-names>C</given-names></name><name><surname>Baldeweg</surname><given-names>T</given-names></name><name><surname>Kreegipuu</surname><given-names>K</given-names></name><name><surname>Carlson</surname><given-names>S</given-names></name><name><surname>Ponton</surname><given-names>C</given-names></name></person-group><article-title>The mismatch negativity (MMN)-a unique window to disturbed central auditory processing in ageing and different clinical conditions</article-title><source>Clin Neurophysiol Off J Int Fed Clin Neurophysiol</source><year>2012</year><volume>123</volume><fpage>424</fpage><lpage>458</lpage><pub-id pub-id-type="pmid">22169062</pub-id></element-citation></ref><ref id="R46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Näätänen</surname><given-names>R</given-names></name><name><surname>Kujala</surname><given-names>T</given-names></name><name><surname>Winkler</surname><given-names>I</given-names></name></person-group><article-title>Auditory processing that leads to conscious perception: A unique window to central auditory processing opened by the mismatch negativity and related responses</article-title><source>Psychophysiology</source><year>2011</year><volume>48</volume><fpage>4</fpage><lpage>22</lpage><pub-id pub-id-type="pmid">20880261</pub-id></element-citation></ref><ref id="R47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Näätänen</surname><given-names>R</given-names></name><name><surname>Picton</surname><given-names>T</given-names></name></person-group><article-title>The N1 Wave of the Human Electric and Magnetic Response to Sound: A Review and an Analysis of the Component Structure</article-title><source>Psychophysiology</source><year>1987</year><volume>24</volume><fpage>375</fpage><lpage>425</lpage><pub-id pub-id-type="pmid">3615753</pub-id></element-citation></ref><ref id="R48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Natan</surname><given-names>RG</given-names></name><name><surname>Briguglio</surname><given-names>JJ</given-names></name><name><surname>Mwilambwe-Tshilobo</surname><given-names>L</given-names></name><name><surname>Jones</surname><given-names>SI</given-names></name><name><surname>Aizenberg</surname><given-names>M</given-names></name><name><surname>Goldberg</surname><given-names>EM</given-names></name><name><surname>Geffen</surname><given-names>MN</given-names></name></person-group><article-title>Complementary control of sensory adaptation by two types of cortical interneurons</article-title><person-group person-group-type="editor"><name><surname>King</surname><given-names>AJ</given-names></name></person-group><source>eLife</source><year>2015</year><volume>4</volume><elocation-id>e09868</elocation-id><pub-id pub-id-type="pmcid">PMC4641469</pub-id><pub-id pub-id-type="pmid">26460542</pub-id><pub-id pub-id-type="doi">10.7554/eLife.09868</pub-id></element-citation></ref><ref id="R49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Natan</surname><given-names>RG</given-names></name><name><surname>Rao</surname><given-names>W</given-names></name><name><surname>Geffen</surname><given-names>MN</given-names></name></person-group><article-title>Cortical Interneurons Differentially Shape Frequency Tuning following Adaptation</article-title><source>Cell Rep</source><year>2017</year><volume>21</volume><fpage>878</fpage><lpage>890</lpage><pub-id pub-id-type="pmcid">PMC5830304</pub-id><pub-id pub-id-type="pmid">29069595</pub-id><pub-id pub-id-type="doi">10.1016/j.celrep.2017.10.012</pub-id></element-citation></ref><ref id="R50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olshausen</surname><given-names>BA</given-names></name><name><surname>Field</surname><given-names>DJ</given-names></name></person-group><article-title>Emergence of simple-cell receptive field properties by learning a sparse code for natural images</article-title><source>Nature</source><year>1996</year><volume>381</volume><fpage>607</fpage><lpage>609</lpage><pub-id pub-id-type="pmid">8637596</pub-id></element-citation></ref><ref id="R51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olshausen</surname><given-names>BA</given-names></name><name><surname>Field</surname><given-names>DJ</given-names></name></person-group><article-title>Sparse coding of sensory inputs</article-title><source>Curr Opin Neurobiol</source><year>2004</year><volume>14</volume><fpage>481</fpage><lpage>487</lpage><pub-id pub-id-type="pmid">15321069</pub-id></element-citation></ref><ref id="R52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oostenveld</surname><given-names>R</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name><name><surname>Maris</surname><given-names>E</given-names></name><name><surname>Schoffelen</surname><given-names>J-M</given-names></name></person-group><article-title>FieldTrip: open source software for advanced analysis of MEG, EEG, and invasive electrophysiological data</article-title><source>Comput Intell Neurosci</source><year>2011</year><volume>2011</volume><fpage>1:1</fpage><lpage>1:9</lpage><pub-id pub-id-type="pmcid">PMC3021840</pub-id><pub-id pub-id-type="pmid">21253357</pub-id><pub-id pub-id-type="doi">10.1155/2011/156869</pub-id></element-citation></ref><ref id="R53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Reilly</surname><given-names>JX</given-names></name><name><surname>Jbabdi</surname><given-names>S</given-names></name><name><surname>Rushworth</surname><given-names>MFS</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name></person-group><article-title>Brain Systems for Probabilistic and Dynamic Prediction: Computational Specificity and Integration</article-title><source>PLOS Biol H</source><year>2013</year><elocation-id>e1001662</elocation-id><pub-id pub-id-type="pmcid">PMC3782423</pub-id><pub-id pub-id-type="pmid">24086106</pub-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1001662</pub-id></element-citation></ref><ref id="R54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>den Ouden</surname><given-names>HEM</given-names></name><name><surname>Daunizeau</surname><given-names>J</given-names></name><name><surname>Roiser</surname><given-names>J</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Stephan</surname><given-names>KE</given-names></name></person-group><article-title>Striatal Prediction Error Modulates Cortical Coupling</article-title><source>J Neurosci</source><year>2010</year><volume>30</volume><fpage>3210</fpage><lpage>3219</lpage><pub-id pub-id-type="pmcid">PMC3044875</pub-id><pub-id pub-id-type="pmid">20203180</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4458-09.2010</pub-id></element-citation></ref><ref id="R55"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Pearce</surname><given-names>MT</given-names></name></person-group><source>The construction and evaluation of statistical models of melodic structure in music perception and composition</source><year>2005</year><date-in-citation>Accessed October 5, 2023</date-in-citation><comment>Available at: <ext-link ext-link-type="uri" xlink:href="https://openaccess.city.ac.uk/id/eprint/8459/">https://openaccess.city.ac.uk/id/eprint/8459/</ext-link></comment></element-citation></ref><ref id="R56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pérez-González</surname><given-names>D</given-names></name><name><surname>Malmierca</surname><given-names>M</given-names></name></person-group><article-title>Adaptation in the auditory system: an overview</article-title><source>Front Integr Neurosci</source><year>2014</year><volume>8</volume><date-in-citation>Accessed June 6, 2023</date-in-citation><pub-id pub-id-type="pmcid">PMC3931124</pub-id><pub-id pub-id-type="pmid">24600361</pub-id><pub-id pub-id-type="doi">10.3389/fnint.2014.00019</pub-id></element-citation></ref><ref id="R57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Press</surname><given-names>C</given-names></name><name><surname>Kok</surname><given-names>P</given-names></name><name><surname>Yon</surname><given-names>D</given-names></name></person-group><article-title>The Perceptual Prediction Paradox</article-title><source>Trends Cogn Sci</source><year>2020</year><volume>24</volume><fpage>13</fpage><lpage>24</lpage><pub-id pub-id-type="pmid">31787500</pub-id></element-citation></ref><ref id="R58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rao</surname><given-names>RPN</given-names></name><name><surname>Ballard</surname><given-names>DH</given-names></name></person-group><article-title>Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects</article-title><source>Nat Neurosci</source><year>1999</year><volume>2</volume><fpage>79</fpage><lpage>87</lpage><pub-id pub-id-type="pmid">10195184</pub-id></element-citation></ref><ref id="R59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Richter</surname><given-names>D</given-names></name><name><surname>Ekman</surname><given-names>M</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><article-title>Suppressed Sensory Response to Predictable Object Stimuli throughout the Ventral Visual Stream</article-title><source>J Neurosci</source><year>2018</year><volume>38</volume><fpage>7452</fpage><lpage>7461</lpage><pub-id pub-id-type="pmcid">PMC6596138</pub-id><pub-id pub-id-type="pmid">30030402</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3421-17.2018</pub-id></element-citation></ref><ref id="R60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Richter</surname><given-names>LMA</given-names></name><name><surname>Gjorgjieva</surname><given-names>J</given-names></name></person-group><article-title>A circuit mechanism for independent modulation of excitatory and inhibitory firing rates after sensory deprivation</article-title><source>Proc Natl Acad Sci H</source><year>2022</year><volume>9</volume><elocation-id>e2ll6895ll9</elocation-id><pub-id pub-id-type="pmcid">PMC9371725</pub-id><pub-id pub-id-type="pmid">35925891</pub-id><pub-id pub-id-type="doi">10.1073/pnas.2116895119</pub-id></element-citation></ref><ref id="R61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Särelä</surname><given-names>J</given-names></name><name><surname>Valpola</surname><given-names>H</given-names></name></person-group><article-title>Denoising Source Separation</article-title><source>J Mach Learn Res</source><year>2005</year><volume>6</volume><fpage>233</fpage><lpage>272</lpage></element-citation></ref><ref id="R62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schulz</surname><given-names>A</given-names></name><name><surname>Miehl</surname><given-names>C</given-names></name><name><surname>Berry</surname><given-names>MJ</given-names><suffix>II</suffix></name><name><surname>Gjorgjieva</surname><given-names>J</given-names></name></person-group><article-title>The generation of cortical novelty responses through inhibitory plasticity</article-title><person-group person-group-type="editor"><name><surname>Geffen</surname><given-names>MN</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Geffen</surname><given-names>MN</given-names></name></person-group><source>eLife</source><year>2021</year><volume>10</volume><elocation-id>e65309</elocation-id><pub-id pub-id-type="pmcid">PMC8516419</pub-id><pub-id pub-id-type="pmid">34647889</pub-id><pub-id pub-id-type="doi">10.7554/eLife.65309</pub-id></element-citation></ref><ref id="R63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sohoglu</surname><given-names>E</given-names></name><name><surname>Chait</surname><given-names>M</given-names></name></person-group><article-title>Detecting and representing predictable structure during auditory scene analysis</article-title><person-group person-group-type="editor"><name><surname>King</surname><given-names>AJ</given-names></name></person-group><source>eLife</source><year>2016</year><volume>5</volume><elocation-id>el9ll3</elocation-id><pub-id pub-id-type="pmcid">PMC5014546</pub-id><pub-id pub-id-type="pmid">27602577</pub-id><pub-id pub-id-type="doi">10.7554/eLife.19113</pub-id></element-citation></ref><ref id="R64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Southwell</surname><given-names>R</given-names></name><name><surname>Baumann</surname><given-names>A</given-names></name><name><surname>Gal</surname><given-names>C</given-names></name><name><surname>Barascud</surname><given-names>N</given-names></name><name><surname>Friston</surname><given-names>K</given-names></name><name><surname>Chait</surname><given-names>M</given-names></name></person-group><article-title>Is predictability salient? A study of attentional capture by auditory patterns</article-title><source>Philos Trans R Soc B Biol Sci</source><year>2017</year><volume>372</volume><fpage>1</fpage><lpage>26</lpage><pub-id pub-id-type="pmcid">PMC5206273</pub-id><pub-id pub-id-type="pmid">28044016</pub-id><pub-id pub-id-type="doi">10.1098/rstb.2016.0105</pub-id></element-citation></ref><ref id="R65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Southwell</surname><given-names>R</given-names></name><name><surname>Chait</surname><given-names>M</given-names></name></person-group><article-title>Enhanced deviant responses in patterned relative to random sound sequences</article-title><source>Cortex J Devoted Study NervSyst Behav</source><year>2018</year><volume>109</volume><fpage>92</fpage><lpage>103</lpage><pub-id pub-id-type="pmcid">PMC6259587</pub-id><pub-id pub-id-type="pmid">30312781</pub-id><pub-id pub-id-type="doi">10.1016/j.cortex.2018.08.032</pub-id></element-citation></ref><ref id="R66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stufflebeam</surname><given-names>SM</given-names></name><name><surname>Poeppel</surname><given-names>D</given-names></name><name><surname>Rowley</surname><given-names>HA</given-names></name><name><surname>Roberts</surname><given-names>TPL</given-names></name></person-group><article-title>Peri-threshold encoding of stimulus frequency and intensity in the M100 latency</article-title><source>Neuro Report</source><year>1998</year><volume>9</volume><fpage>91</fpage><pub-id pub-id-type="pmid">9592054</pub-id></element-citation></ref><ref id="R67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Summerfield</surname><given-names>C</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><article-title>Expectation in perceptual decision making: neural and computational mechanisms</article-title><source>Nat Rev Neurosci</source><year>2014</year><volume>15</volume><fpage>745</fpage><lpage>756</lpage><pub-id pub-id-type="pmid">25315388</pub-id></element-citation></ref><ref id="R68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Summerfield</surname><given-names>C</given-names></name><name><surname>Trittschuh</surname><given-names>EH</given-names></name><name><surname>Monti</surname><given-names>JM</given-names></name><name><surname>Mesulam</surname><given-names>MM</given-names></name><name><surname>Egner</surname><given-names>T</given-names></name></person-group><article-title>Neural repetition suppression reflects fulfilled perceptual expectations</article-title><source>Nat Neurosci</source><year>2008</year><volume>11</volume><fpage>1004</fpage><lpage>1006</lpage><pub-id pub-id-type="pmcid">PMC2747248</pub-id><pub-id pub-id-type="pmid">19160497</pub-id><pub-id pub-id-type="doi">10.1038/nn.2163</pub-id></element-citation></ref><ref id="R69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tang</surname><given-names>MF</given-names></name><name><surname>Smout</surname><given-names>CA</given-names></name><name><surname>Arabzadeh</surname><given-names>E</given-names></name><name><surname>Mattingley</surname><given-names>JB</given-names></name></person-group><article-title>Prediction error and repetition suppression have distinct effects on neural representations of visual information</article-title><person-group person-group-type="editor"><name><surname>Summerfield</surname><given-names>C</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name><name><surname>Kok</surname><given-names>P</given-names></name><name><surname>Op de Beeck</surname><given-names>H</given-names></name></person-group><source>eLife</source><year>2018</year><volume>7</volume><elocation-id>e33l23</elocation-id><pub-id pub-id-type="pmcid">PMC6312401</pub-id><pub-id pub-id-type="pmid">30547881</pub-id><pub-id pub-id-type="doi">10.7554/eLife.33123</pub-id></element-citation></ref><ref id="R70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Todorovic</surname><given-names>A</given-names></name><name><surname>van Ede</surname><given-names>F</given-names></name><name><surname>Maris</surname><given-names>E</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><article-title>Prior Expectation Mediates Neural Adaptation to Repeated Sounds in the Auditory Cortex: An MEG Study</article-title><source>J Neurosci</source><year>2011</year><volume>31</volume><fpage>9118</fpage><lpage>9123</lpage><pub-id pub-id-type="pmcid">PMC6623501</pub-id><pub-id pub-id-type="pmid">21697363</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1425-11.2011</pub-id></element-citation></ref><ref id="R71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Todorovic</surname><given-names>A</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><article-title>Repetition Suppression and Expectation Suppression Are Dissociable in Time in Early Auditory Evoked Fields</article-title><source>J Neurosci</source><year>2012</year><volume>32</volume><fpage>13389</fpage><lpage>13395</lpage><pub-id pub-id-type="pmcid">PMC6621367</pub-id><pub-id pub-id-type="pmid">23015429</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2227-12.2012</pub-id></element-citation></ref><ref id="R72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wyart</surname><given-names>V</given-names></name><name><surname>de Gardelle</surname><given-names>V</given-names></name><name><surname>Scholl</surname><given-names>J</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name></person-group><article-title>Rhythmic fluctuations in evidence accumulation during decision making in the human brain</article-title><source>Neuron</source><year>2012</year><volume>76</volume><fpage>847</fpage><lpage>858</lpage><pub-id pub-id-type="pmcid">PMC3975574</pub-id><pub-id pub-id-type="pmid">23177968</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2012.09.015</pub-id></element-citation></ref><ref id="R73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yarden</surname><given-names>TS</given-names></name><name><surname>Mizrahi</surname><given-names>A</given-names></name><name><surname>Nelken</surname><given-names>I</given-names></name></person-group><article-title>Context-Dependent Inhibitory Control of Stimulus-Specific Adaptation</article-title><source>J Neurosci</source><year>2022</year><volume>42</volume><fpage>4629</fpage><lpage>4651</lpage><pub-id pub-id-type="pmcid">PMC9186800</pub-id><pub-id pub-id-type="pmid">35477904</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0988-21.2022</pub-id></element-citation></ref><ref id="R74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yon</surname><given-names>D</given-names></name><name><surname>Frith</surname><given-names>CD</given-names></name></person-group><article-title>Precision and the Bayesian brain</article-title><source>Curr Biol 3</source><year>2021</year><volume>1</volume><fpage>R1026</fpage><lpage>R1032</lpage><pub-id pub-id-type="pmid">34520708</pub-id></element-citation></ref><ref id="R75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>AJ</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><article-title>Uncertainty, Neuromodulation, and Attention</article-title><source>Neuron</source><year>2005</year><volume>46</volume><fpage>681</fpage><lpage>692</lpage><pub-id pub-id-type="pmid">15944135</pub-id></element-citation></ref></ref-list></back><floats-group><boxed-text id="BX1" position="float" orientation="portrait"><caption><title>Significance Statement</title></caption><p>Humans excel at detecting predictable patterns within sound sequences, a process crucial for listening, language processing, and music appreciation. However, questions persistabout the underlying neural mechanisms and the specific information monitored by the brain.</p><p>Our study addresses these questions by analysing magnetoencephalography (MEG) signals from participants exposed to predictable and unpredictable tone-pip patterns. We found that the MEG signal simultaneously captures two crucial aspects of predictability tracking.</p><p>Firstly, sustained MEG activity, tracking the sequence’s evolution, dynamically assesses pattern predictability, shedding light on how the brain evaluates reliability. Secondly, phasic MEG activity, reflecting responses to individual events, shows reduced activity to predictable tones, aligning with the idea that the brain efficiently encodes and anticipates upcoming events in predictable contexts.</p></boxed-text><fig id="F1" position="float"><label>Figure 1</label><caption><title>Behavioural experiment</title><p>[A] Examples of the four gap duration stimuli (to scale). RNDREG sequences are plotted (the stimulus set also contained 50% no-change RND sequences). Four gap duration conditions are used (0, 100, 200 and 500 ms), resulting in regularity cycles of 500, 1500, 2500 and 5500 ms, respectively. Participants listened to the sound sequences and were instructed to press a keyboard button as soon as they detected the emergence of a REG pattern; indicated with a red line. [B] Behavioural performance. Performance steadily declined with increasing gap duration. Generally good performance (mean d’&gt;2) was seen for the Gap200 condition and it was therefore chosen for the MEG experiment.</p></caption><graphic xlink:href="EMS189367-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Examples of stimuli in the MEG experiment (to scale).</title><p>All stimuli consisted of 60 tones (6 regularity cycles in REG sequences; red lines), ‘fast’ sequences were 3 s long; ‘slow’ sequences were 15 s long. Naive participants listened to the sound sequences passively and were instructed to focus on a visual task. If brain responses track the emergence of regularity, responses REG and RND sequences should be differentiated following cycle#l. Ideal observer REG detection latency (~3 tones into the 2<sup>nd</sup> cycle, e.g. Barascud et al, 2016) is indicated with a dashed line.</p></caption><graphic xlink:href="EMS189367-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>MEG response to ‘fast’ (Gap0) sequences.</title><p>[A] The full stimulus epoch, from stimulus onset (t = Os) to offset (t = 3s). The shaded area around the traces indicates the standard error of the mean. The grey horizontal line indicates time intervals where a significant difference is observed between the two conditions (p&lt;0.01). Yellow highlighting indicates the interval (665 ms to 965 ms) used for source analysis in [C], [B] Mean sustained response power computed during the last second of stimulus presentation (2-3 s post-onset) and averaged over trials for each subject in RND and REG conditions. [C] Source analysis. Group F map for the REG &gt; RND during the rising slope of the sustained response (yellow shaded area in A), thresholded at p = 0.05 (uncorrected).</p></caption><graphic xlink:href="EMS189367-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>MEG response to ‘slow’ (Gap200) sequences.</title><p>[A] Wideband; 0-30Hz. The entire stimulus epoch (16s) is plotted. A sustained difference between responses to REG and RND sequences emerges from ~ 3s post-onset. Responses evoked by individual tones (4Hz) are observed throughout the epoch. [B] Low pass filtered responses (0-2Hz) focusing on the slow sustained response activity. The horizontal black and grey lines denote time intervals where a significant difference is observed between conditions (p &lt; .05 and p&lt;.01, respectively). Mean sustained response power computed between 10-15 s (from the 5th cycle onwards) post-onset for each individual in each condition is shown on the right. [C] High pass filtered activity, with clearly visible responses to individual tones. The 6 REG cycles analysed in <xref ref-type="fig" rid="F5">Figure 5</xref> are indicated. Shaded areas are those plotted in <xref ref-type="fig" rid="F5">Figure 5B, C</xref>.</p></caption><graphic xlink:href="EMS189367-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>Responses to individual tones are decreased in REG relative to RND sequences.</title><p>Tone evoked responses. [A] Tone-evoked responses averaged over the first 10 tones (0-2.5 s; first cycle) in the RND and REG conditions. Shading around the traces indicates the standard error of the mean. Field maps corresponding to the M5O (60-80 ms) and M100 (130-150 ms) responses are shown below. As expected, no differences are seen because the REG pattern can only be distinguished from RND following the first cycle (once the pattern starts repeating) [B] Tone-evoked responses averaged over tones presented between 2.5 - 5 s in the RND and REG conditions (‘Cycle#2). The horizontal grey line indicates time intervals where a significant difference is observed between conditions (p&lt;.01) [C] Tone-evoked responses averaged over tones presented between 12.5 - 15 s in the RND and REG conditions (‘Cycle#6). [D] Difference from 1<sup>st</sup> cycle computed (over the M100 time interval; 100-200ms) for each subsequent cycle in REG and RND. Tones presented in REG contexts show consistently reduced activity relative to the 1<sup>st</sup> cycle, p-values indicate a difference from 0 (one sample t-test). [E] Tone-evoked responses averaged over tones presented during 5-15 s (cycle#3 to cycle#6) [F] Source analysis results computed from the data in [E] The image is a group F map for the RND &gt; REG thresholded at p = 0.05 (uncorrected).</p></caption><graphic xlink:href="EMS189367-f005"/></fig><table-wrap id="T1" position="float" orientation="portrait"><label>Table 1</label><caption><title>Summary of MEG source localisation results. MNI coordinates (x,y,z), and F values
(p<sub>voxel</sub> &lt; 0.05). Anatomical labelling based on the Harvard-Oxford Cortical Structural Atlas.</title></caption><table frame="void" rules="none"><thead><tr><th align="left" valign="middle"/><th align="left" valign="middle"/><th align="left" valign="middle"/><th align="left" valign="middle"/><th align="left" valign="middle"/><th align="right" valign="middle" colspan="3">MNI Coordinates</th></tr><tr><th align="left" valign="middle"/><th align="left" valign="middle" style="border-top: solid thin">Region</th><th align="left" valign="middle" style="border-top: solid thin">Side</th><th align="left" valign="middle" style="border-top: solid thin">P- value(peak- level)</th><th align="left" valign="middle" style="border-top: solid thin">F- value</th><th align="left" valign="middle" style="border-top: solid thin">x</th><th align="left" valign="middle" style="border-top: solid thin">y</th><th align="left" valign="middle" style="border-top: solid thin">z</th></tr></thead><tbody><tr><td align="left" valign="top" rowspan="5">REG - RND(<italic>‘fast’</italic> sequence)</td><td align="left" valign="middle">Middle temporal gyrus</td><td align="left" valign="middle">Left</td><td align="left" valign="middle">0.002</td><td align="left" valign="middle">12.42</td><td align="left" valign="middle">-56</td><td align="left" valign="middle">-28</td><td align="left" valign="middle">-10</td></tr><tr><td align="left" valign="middle">Inferior frontal gyrus</td><td align="left" valign="middle">Left</td><td align="left" valign="middle">0.026</td><td align="left" valign="middle">5.78</td><td align="left" valign="middle">-50</td><td align="left" valign="middle">34</td><td align="left" valign="middle">-4</td></tr><tr><td align="left" valign="middle">Middle temporal gyrus</td><td align="left" valign="middle">Right</td><td align="left" valign="middle">0.002</td><td align="left" valign="middle">12.9</td><td align="left" valign="middle">54</td><td align="left" valign="middle">-28</td><td align="left" valign="middle">-6</td></tr><tr><td align="left" valign="middle">Inferior frontal gyrus</td><td align="left" valign="middle">Right</td><td align="left" valign="middle">0.024</td><td align="left" valign="middle">5.98</td><td align="left" valign="middle">46</td><td align="left" valign="middle">32</td><td align="left" valign="middle">-4</td></tr><tr><td align="left" valign="middle">Hippocampus</td><td align="left" valign="middle">Right</td><td align="left" valign="middle">0.033</td><td align="left" valign="middle">5.22</td><td align="left" valign="middle">30</td><td align="left" valign="middle">12</td><td align="left" valign="middle">-38</td></tr><tr style="border-top: solid thin"><td align="left" valign="top" rowspan="4">RND-REG (tone response extracted from <italic>‘slow’</italic> sequence)</td><td align="left" valign="middle">Heschl’s gyrus/Superior temporal gyrus</td><td align="left" valign="middle">Left</td><td align="left" valign="middle">0.01</td><td align="left" valign="middle">8.09</td><td align="left" valign="middle">-60</td><td align="left" valign="middle">-8</td><td align="left" valign="middle">12</td></tr><tr><td align="left" valign="middle">Inferior frontal gyrus</td><td align="left" valign="middle">Left</td><td align="left" valign="middle">0.035</td><td align="left" valign="middle">5.06</td><td align="left" valign="middle">-48</td><td align="left" valign="middle">34</td><td align="left" valign="middle">-6</td></tr><tr><td align="left" valign="middle">Rolandic operculum</td><td align="left" valign="middle">Right</td><td align="left" valign="middle">0.035</td><td align="left" valign="middle">5.06</td><td align="left" valign="middle">52</td><td align="left" valign="middle">-4</td><td align="left" valign="middle">14</td></tr><tr style="border-below: solid thin"><td align="left" valign="middle">Inferior frontal gyrus</td><td align="left" valign="middle">Right</td><td align="left" valign="middle">0.039</td><td align="left" valign="middle">4.85</td><td align="left" valign="middle">48</td><td align="left" valign="middle">28</td><td align="left" valign="middle">-8</td></tr></tbody></table></table-wrap></floats-group></article>