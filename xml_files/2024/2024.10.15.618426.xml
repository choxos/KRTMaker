<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS199457</article-id><article-id pub-id-type="doi">10.1101/2024.10.15.618426</article-id><article-id pub-id-type="archive">PPR924600</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">1</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Optimal network sizes for most robust Turing patterns</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><name><surname>Shaberi</surname><given-names>Hazlam S. Ahmad</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Kappassov</surname><given-names>Aibek</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Matas-Gil</surname><given-names>Antonio</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Endres</surname><given-names>Robert G.</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref></contrib></contrib-group><aff id="A1"><label>1</label>Department of Life Sciences, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/041kmwe10</institution-id><institution>Imperial College</institution></institution-wrap>, <city>London</city><postal-code>SW7 2AZ</postal-code>, <country country="GB">United Kingdom</country></aff><aff id="A2"><label>2</label>Center for Integrative Systems Biology and Bioinformatics, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/041kmwe10</institution-id><institution>Imperial College</institution></institution-wrap>, <city>London</city><postal-code>SW7 2AZ</postal-code>, <country country="GB">United Kingdom</country></aff><aff id="A3"><label>3</label>Institute of Systems Biology, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/00bw8d226</institution-id><institution>National University of Malaysia</institution></institution-wrap></aff><pub-date pub-type="nihms-submitted"><day>17</day><month>10</month><year>2024</year></pub-date><pub-date pub-type="preprint"><day>15</day><month>10</month><year>2024</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Many cellular patterns exhibit a reaction-diffusion component, suggesting that Turing instability may contribute to pattern formation. However, biological gene-regulatory pathways are more complex than simple Turing activator-inhibitor models and generally do not require fine-tuning of parameters as dictated by the Turing conditions. To address these issues, we employ random matrix theory to analyze the Jacobian matrices of larger networks with robust statistical properties. Our analysis reveals that Turing patterns are more likely to occur by chance than previously thought and that the most robust Turing networks have an optimal size, surprisingly consisting only of a handful of molecular species, thus significantly increasing their identifiability in biological systems. This optimal size emerges from a tradeoff between the highest stability in small networks and the greatest instability with diffusion in large networks. Furthermore, we find that with multiple immobile nodes, differential diffusion ceases to be important for Turing patterns. Our findings may inform future synthetic biology approaches and provide insights into bridging the gap to complex developmental pathways.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">Spatial patterns and structures are ubiquitous in biological systems, ranging from microbial communities and biofilms to developmental biology and ecological systems [<xref ref-type="bibr" rid="R1">1</xref>] [<xref ref-type="bibr" rid="R2">2</xref>] [<xref ref-type="bibr" rid="R3">3</xref>]. In seminal work, Alan Turing (and later Gierer-Meinhardt) proposed a self-organizing emergent mechanism for pattern formation based on a diffusion-driven instability, utilizing a slowly diffusing activator and a fast-diffusing inhibitor molecule [<xref ref-type="bibr" rid="R4">4</xref>] [<xref ref-type="bibr" rid="R5">5</xref>]. According to Turing’s definition, the chemical reactions are stable without diffusion, leading to a homogeneous steady state, but become unstable with diffusion, forming a periodic pattern at certain wave numbers. The mathematical analysis is generally based on reaction-diffusion models, implemented using partial differential equations, and linear stability analysis to investigate the effect of perturbations on a steady state [<xref ref-type="bibr" rid="R6">6</xref>]. Nonetheless, employing Turing models to understand biological patterns is still a topic of debate.</p><p id="P3">The Turing mechanism clearly has biological relevance in cell and developmental biology, likely explaining aspects of digit formation in mice, zebrafish skin, fingerprint formation, and cortical folds of the fetal brain [<xref ref-type="bibr" rid="R7">7</xref>][<xref ref-type="bibr" rid="R8">8</xref>][<xref ref-type="bibr" rid="R9">9</xref>][<xref ref-type="bibr" rid="R10">10</xref>]. However, this mechanism has two main drawbacks: extreme simplicity and a need for fine-tuning. In contrast to simple activator-inhibitor Turing models, biological gene regulatory networks in embryonic development generally consist of hundreds of molecular species and are notable for their immense complexity, hierarchical structure, and tolerance to noise [<xref ref-type="bibr" rid="R11">11</xref>]. In contrast, the Turing conditions lead to a lack of structural robustness, which is at odds with the noise tolerance and evolutionary adaptability required for such patterning solutions to occur [<xref ref-type="bibr" rid="R12">12</xref>][<xref ref-type="bibr" rid="R13">13</xref>][<xref ref-type="bibr" rid="R14">14</xref>]. However, there are also bottom-up approaches to further elucidate the issues with Turing models.</p><p id="P4">As developmental biology is complex, synthetic biology provides an alternative route, following Feynman’s mantra: “What I cannot create, I do not understand” [<xref ref-type="bibr" rid="R15">15</xref>]. By implementing the Turing mechanism from scratch in cells that communicate via chemicals, our understanding of how to generate stable pattern can be systematically improved. Two previous synthetic biology attempts failed due to the lack of differential diffusion, leading to highly irregular patterns. First, stochastic Turing patterns were engineered in <italic>E. coli</italic> cells. The implemented circuit contained self-activation and lateral inhibition, with two diffusible quorum-sensing signals [<xref ref-type="bibr" rid="R16">16</xref>]. Second, solitary patterns were engineered in HEK cells using the Nodal–Lefty system [<xref ref-type="bibr" rid="R17">17</xref>]. The issue is that small molecules have roughly the same diffusion constant, although extra nonspecific binding can help slow down diffusion. In recent work, a more robust three-node network was implemented using synthetic circuits of six genes with small diffusible quorum-sensing molecules and extra control cassettes [<xref ref-type="bibr" rid="R18">18</xref>]. This showed regular patterns in growing bacterial colonies, but the variability is immense, and robustness is still limited. Hence, while there is progress in the rational design of circuits with specific properties, the lack of control over robustness represents a significant downside in tissue engineering, patterned biomaterial deposition, and bridging developmental programs [<xref ref-type="bibr" rid="R19">19</xref>][<xref ref-type="bibr" rid="R20">20</xref>][<xref ref-type="bibr" rid="R21">21</xref>].</p><p id="P5">The need to develop theoretical frameworks beyond the two-equation Turing model has been recognized previously. An exhaustive exploration of all two- and three-node topologies showed that three nodes are, on average, more robust than two nodes, pointing toward complexity increasing robustness [<xref ref-type="bibr" rid="R22">22</xref>]. More specifically, approximately 60% of all topologies produced patterns for some parameter combinations, but the parameter space producing Turing patterns was overall minuscule, around 0.1%. This finding is supported by another study that explored networks with up to four nodes [<xref ref-type="bibr" rid="R23">23</xref>]. Motivated by Robert May’s work in theoretical ecology [<xref ref-type="bibr" rid="R24">24</xref>] (based on earlier work by Eugene Wigner [<xref ref-type="bibr" rid="R25">25</xref>]) a random matrix approach for <italic>N</italic> ≤ 6 showed that larger networks add robustness by reducing the ”diffusive threshold”, i.e., softening the requirement of differential diffusion [<xref ref-type="bibr" rid="R26">26</xref>]. This raises the question: why not investigate even larger matrices? While the diagonalization of Jacobian matrices is a slow <italic>O</italic>(<italic>N</italic><sup>3</sup>) process, it is still efficient for significantly larger networks with modern computers. The advantages of exploring random Jacobian matrices are apparent; such an approach produces excellent statistics, and biological realism can be introduced through the distributions and topologies.</p><p id="P6">Here, we go beyond small Turing networks and use large random Jacobian matrices to systematically explore how network size affects robustness. We begin by motivating distributions for Jacobian matrix elements from explicit small Hill-function-based models for gene regulation, as relevant to synthetic biology [<xref ref-type="bibr" rid="R18">18</xref>]. We then continue by exploring large random networks with up to <italic>N</italic> = 100 nodes using corresponding random Jacobian matrices with two diffusers and variable sparsity. We identify an optimal network size <italic>N</italic><sub>opt</sub> ~ 5 − 8, arising from a tradeoff between stability without diffusion and instability with diffusion, each with opposite <italic>N</italic>-dependencies. This increased robustness relieves the constraints on parameters, known as Turing conditions, including differential diffusion for the two diffusing species. Our results are expected to renew the quest for robust Turing patterns in synthetic biology and to identify Turing modules in larger networks of developmental biology.</p></sec><sec id="S2" sec-type="results"><title>Results</title><p id="P7">We are interested in the robustness of large Turing networks, that is reaction-diffusion models with many molecular species with a large parameter space to support diffusion-driven instabilities. <xref ref-type="fig" rid="F1">Fig. 1</xref> shows example networks, ranging from small (<italic>N</italic> = 2 nodes) to large (<italic>N</italic> ≫ 1). We restrict ourselves to two diffusing species similar to Turing’s original paper. In order to understand how to model large networks we begin by investigating examples of smaller networks to gain intuition. For a network of <italic>N</italic> nodes and hence <italic>N</italic> species with time and space dependent concentrations <bold><italic>X</italic></bold>(<bold><italic>r</italic></bold>, <italic>t</italic>) = {<italic>x</italic><sub>1</sub> (<bold><italic>r</italic></bold>, <italic>t</italic>), <italic>x</italic><sub>2</sub>(<bold><italic>r</italic></bold>, <italic>t</italic>),…, <italic>x<sub>N</sub></italic>(<bold><italic>r</italic></bold>, <italic>t</italic>)}, the general dynamics are given by the partial differential equations <disp-formula id="FD1"><label>(1)</label><mml:math id="M1"><mml:mrow><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mo>∇</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mi>X</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P8">where <bold><italic>D</italic></bold> = <italic>diag</italic>(<italic>D</italic><sub>1</sub>, <italic>D</italic><sub>2</sub>, 0,…, 0) is the diagonal diffusion matrix, and Laplacian <inline-formula><mml:math id="M2"><mml:mrow><mml:msup><mml:mo>∇</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>∑</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>d</mml:mi></mml:msubsup><mml:mrow><mml:msup><mml:mo>∂</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mo>/</mml:mo><mml:mo>∂</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:mrow></mml:math></inline-formula> in <italic>d</italic> dimensions, given by the sum of second spatial derivatives. For simplicity, we assume an infinite domain, allowing us to neglect boundary effects and to use a continuous wave number. As our motivation is to learn how to build these with synthetic gene circuits, we model the activating and inhibiting interactions with Hill functions, along with basal expression and degradation: <disp-formula id="FD2"><label>(2)</label><mml:math id="M3"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∏</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mi>j</mml:mi><mml:mo>+</mml:mo></mml:msubsup></mml:mrow></mml:munder><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∏</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mi>j</mml:mi><mml:mo>−</mml:mo></mml:msubsup></mml:mrow></mml:munder><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P9">with <bold><italic>θ</italic></bold> = {<italic><bold>b</bold>, <bold>V</bold> , <bold>K</bold>, <bold>n</bold>, <bold>μ</bold></italic>} respectively the sets of basal and maximal expression rates, concentration thresholds, Hill coefficients, and degradation rates. Furthermore, <inline-formula><mml:math id="M4"><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> denotes the set of positive (negative) edges ending in node <italic>i</italic>, where the different regulators act (and saturate) independently (non-competitively) of each other. Following [<xref ref-type="bibr" rid="R22">22</xref>], we sample parameters from a wide range of allowed values in arbitrary units.</p><p id="P10">To understand whether such parameter combinations produce Turing patterns, we use linear stability analysis following Turing’s approach (see <xref ref-type="sec" rid="S4">Methods</xref> for additional details). Briefly, first the model needs to have a stable homogeneous steady state <bold><italic>X</italic></bold>* without diffusion, defined by <disp-formula id="FD3"><label>(3)</label><mml:math id="M5"><mml:mrow><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>;</mml:mo><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P11">which we solve with the Newton-Raphson method using different initial conditions. Second, we linearize the dynamic equations assuming small perturbations around steady state, using <inline-formula><mml:math id="M6"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, leading to <disp-formula id="FD4"><label>(4)</label><mml:math id="M7"><mml:mrow><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>δ</mml:mi><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi>δ</mml:mi><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">D</mml:mi><mml:msup><mml:mo>∇</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mi>δ</mml:mi><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P12">with Jacobian matrix <bold><italic>J</italic></bold> of first derivative with matrix elements <italic>J<sub>ij</sub></italic> = <italic>∂f<sub>i</sub></italic>/<italic>∂x<sub>j</sub></italic>.</p><p id="P13">To get rid off the second derivatives, we Fourier transform in the space domain, or more simply apply a wave-like perturbation <inline-formula><mml:math id="M8"><mml:mrow><mml:mi>δ</mml:mi><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>δ</mml:mi><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> exp (<italic>i<bold>kr</bold></italic>) with <bold><italic>k</italic></bold> = {<italic>k</italic><sub>1</sub>, <italic>k</italic><sub>2</sub>,…, <italic>k<sub>d</sub></italic>) and <bold><italic>kr</italic></bold> the scalar product between the <bold><italic>k</italic></bold> and <bold><italic>r</italic></bold> vectors. Plugged into <xref ref-type="disp-formula" rid="FD4">Eq. 4</xref>, this leads to a new Jacobian matrix with modified diagonal matrix elements and an extra parameter <italic>k</italic> = |<bold><italic>k</italic></bold>| <disp-formula id="FD5"><label>(5)</label><mml:math id="M9"><mml:mrow><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P14">indicating that for a rotationally invariant system, the dependence is only on the modulus of <bold><italic>k</italic></bold>, rendering linear stability analysis an effective one-dimensional problem. As a result, diagonalization of the modified Jacobian matrix leads to a <italic>k</italic>-dependent eigenvalues, called dispersion relations, where the one with the largest real part, termed <italic>Re</italic>(<italic>λ</italic><sub>max</sub>(<italic>k</italic>)), determines the stability. For a Turing instability, we require the homogeneous steady state without diffusion to be stable (corresponding to <italic>k</italic>=0), i.e. with a negative real part given by <italic>Re</italic>(<italic>λ</italic><sub>max</sub>(<italic>k</italic>(0))) &lt; 0. Furthermore, with diffusion we require instability for a wave number (<italic>k</italic> &gt; 0) and thus a positive real part given by <italic>Re</italic>(<italic>λ</italic><sub>max</sub>(<italic>k</italic>)) &gt; 0. For a classic Turing instability leading to a well-defined wave pattern, there is a <italic>k</italic><sub>max</sub> &gt; 0, for which the dispersion has a clear maximum, and for <italic>k</italic> → ∞, the system becomes stable again (negative real part of eigenvalue). This type of instability is called Turing I (<xref ref-type="fig" rid="F2">Fig. 2A</xref>). However, there are other possibilities, such as instability for <italic>k</italic> → ∞ (Turing II in <xref ref-type="fig" rid="F2">Fig. 2B</xref>). (Note, this is a simplified classification scheme - in other schemes our Turing I is given by Turing Ia, and our Turing II is given by Turing Ib, IIa, and IIb with subtle differences [<xref ref-type="bibr" rid="R22">22</xref>].) Yet, another type of instability is the Turing-Hopf, for which the imaginary part can additionally lead to oscillations (not shown).</p><p id="P15">Focusing on small networks (<italic>N</italic> = 2 − 4), we used Latin hypercube sampling of 10<sup>7</sup> parameter sets and filtered these for Turing I instabilities. <xref ref-type="fig" rid="F3">Fig. 3</xref> shows the fits of the empirical histograms of the Jacobian matrix elements (<italic>j</italic>) to the beta distribution <italic>B</italic>(<italic>j; α,β</italic>) (see <xref ref-type="sec" rid="S4">Methods</xref> for details on parameter searches and fitting procedure). The beta distribution depends on two parameters, <italic>α</italic> and <italic>β</italic>, allowing a wide range of distributions from symmetric Gaussian-like to non-Gaussian shapes with various levels of skewness and kurtosis. We generally observe that the Turing-I matrix elements are more narrowly distributed in line with Turing I having to fulfill Turing conditions, leading to a subset of parameters and hence Jacobian matrix elements. This can clearly be seen in <xref ref-type="fig" rid="F3">Fig. 3A</xref> (see <xref ref-type="supplementary-material" rid="SD1">Fig. S1</xref> in Supplementary Materials for additional histograms). To fulfill the Turing conditions, the (1,1) Jacobian matrix elements need to be positive (activator), which is the case for the histogram and fitted line (blue), but not for the orange line, representating the non-Turing case. Furthermore, the (2,2) matrix elements need to be negative (inhibitor), which is here already fulfilled for non-Turing due to model constraints (degradation). In contrast, the (1,2) and (2,1) matrix elements can respectively be either negative and positive (here the case even for non-Turing due to model constraints), or the other way around (however not for our 2-equation model) [<xref ref-type="bibr" rid="R6">6</xref>]. We generally did not observe multimodal distributions, pointing to a certain level of simplicity in the distributions.</p><p id="P16">The difference between Turing and non-Turing Jacobian matrix elements is further visible in <xref ref-type="fig" rid="F4">Fig. 4</xref>, where panel A shows beehive plots based on the empirical data from <xref ref-type="fig" rid="F3">Fig. 3</xref>. Clearly, the variances of the off-diagonal matrix elements of the non-Turing cases are much broader than the Turing-I cases. This is further provided in panel B, showing the sum of the Jacobian matrix elements (equivalent plots can be made for the mean of those random variables). For larger matrices, we expect to observe the central limit theorem, with the sums calculated from <italic>N</italic>(<italic>N</italic> − 1) off-diagonal Jacobian matrix elements. For increasing matrix size, and this is already evident for <italic>N</italic> = 4, we obtain approximate Gaussian distributions (still with a sharp peak at zero): The mean is approximately zero, the variance approaches a finite value (as variances are positive numbers), and the skewness and kurtosis vanish. Hence not surprisingly, on average a Gaussian distribution with zero mean and finite variance describes the Jacobian matrix elements. Note this trend would be even stronger, if we average over all possible network topologies with <italic>N</italic> nodes, which scales as <inline-formula><mml:math id="M10"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mn>3</mml:mn><mml:mi>N</mml:mi></mml:msup><mml:msup><mml:mn>9</mml:mn><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mi>N</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>2</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and hence is super-exponentially increasing with <italic>N</italic> (see <xref ref-type="fig" rid="F1">Fig. 1E</xref>). In the following we exploit these insights and use random Jacobian matrices directly.</p><p id="P17">Inspired by Robert May’s statistical treatment of non-equilibrium ecological communities that studied asymmetric random Jacobians to represent linearized population dynamics, as opposed to Wigner’s symmetric (Hermitian) random matrices [<xref ref-type="bibr" rid="R24">24</xref>][<xref ref-type="bibr" rid="R27">27</xref>], we analyzed Turing instabilities by sampling asymmetric random Jacobian matrices that represent the linearized reaction dynamics. Similar to May’s ”neutral interaction” model, our Jacobian matrix without diffusion is given by <disp-formula id="FD6"><label>(6)</label><mml:math id="M11"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">G</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P18">where <bold><italic>G</italic></bold> is a random matrix with elements <italic>g<sub>ij</sub></italic> randomly assigned from a Gaussian distribution that has mean value zero and variance Var(<italic>g<sub>ij</sub></italic>) = <italic>σ</italic><sup>2</sup>, but with diagonal terms <italic>g<sub>ii</sub></italic> = 0. For simplicity (and convenience), the latter are modeled by the identity matrix, <bold><italic>I</italic></bold>, responsible for providing stability. In such a Turing system, a positive value of <italic>J<sub>ij</sub></italic> (or <italic>g<sub>ii</sub></italic>) implies activation while a negative value implies inhibition, similarly to previous matrix representations of Turing systems [<xref ref-type="bibr" rid="R22">22</xref>][<xref ref-type="bibr" rid="R28">28</xref>]. The identity matrix <bold><italic>I</italic></bold> represents the degradation of the species. Further self-interactions are neglected, leading to the curious result that there are no Turing instabilities for <italic>N</italic> = 2 (see proof in <xref ref-type="sec" rid="S4">Methods</xref>). While the Gaussian distribution is motivated by <xref ref-type="fig" rid="F4">Fig. 4</xref>, there is no reason to expect the reaction kinetics in a reaction-diffusion system to be independent as there is no reason for the population dynamics in the work of May [<xref ref-type="bibr" rid="R24">24</xref>] to be independent (or normally distributed). Nevertheless, in the absence of experimental understanding of what the distribution of the parameters should be, the potential of the random matrix approach to explaining stability principles is greatly evidenced for population dynamics [<xref ref-type="bibr" rid="R29">29</xref>, <xref ref-type="bibr" rid="R30">30</xref>] and in small Turing systems (<italic>N</italic> ≤ 6) [<xref ref-type="bibr" rid="R26">26</xref>].</p><p id="P19">Next, we investigated the eigenvalue distributions of such random matrices (see <xref ref-type="fig" rid="F5">Fig. 5A</xref>). In the absence of diffusion (i.e. at <italic>k</italic> = 0), the eigenvalues are distributed in a circle with radius <inline-formula><mml:math id="M12"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:msqrt><mml:mi>N</mml:mi></mml:msqrt></mml:mrow></mml:math></inline-formula> according to May’s ”circular law”, derived from random ecological communities [<xref ref-type="bibr" rid="R24">24</xref>][<xref ref-type="bibr" rid="R27">27</xref>]. In the presence of diffusion, the eigenvalue distribution can be described as having ”in-bulk” and ”outlier” distributions (see <xref ref-type="fig" rid="F5">Fig. 5B</xref>). The outlier distribution has extreme negative real parts, following approximately <inline-formula><mml:math id="M13"><mml:mo>−</mml:mo><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>∑</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (see <xref ref-type="sec" rid="S4">Methods</xref>), which tends to minus infinity for increasing <italic>k</italic> and network size <italic>N</italic>. As we are only interested in the maximal real part to determine the linear stability, it is safe to ignore the ”outliers” and only focus on the “in-bulk” eigenvalue distribution where the maximal real eigenvalues are located in.</p><p id="P20">We subsequently sampled thousands of random matrices to analyse how network size affects the stability of a reaction-diffusion system. We observed three relationships between network size and stability. Firstly, in the absence of diffusion, a random reaction-diffusion system with fixed radius <italic>γ</italic> is likely more stable for smaller network size (<xref ref-type="fig" rid="F6">Fig. 6A</xref>). Asymptotically, the circlar law predicts a step function for <italic>N</italic> → ∞, i.e. stability for radii <italic>γ</italic> &lt; 1 (as circles are fully to the left of the imaginary axis) and instability for <italic>γ</italic> &gt; 1 (as circles crosses the imaginary axis) [<xref ref-type="bibr" rid="R25">25</xref>]. Secondly, a previously stable system without diffusion is more likely to turn unstable (i.e. have a diffusion-driven instability) when diffusion is present for larger network size (<xref ref-type="fig" rid="F6">Fig. 6B</xref>). Therefore, thirdly, out of all random matrices, Turing instabilities are maximized (i.e. found the most) at an optimal intermediate network size that is not too small or not too large (<xref ref-type="fig" rid="F6">Fig. 6C</xref>).</p><p id="P21">As the Turing-Hopf instability is competing with the Turing instability, and Turing I is of importance in producing spatial patterns, we analysed the effects of network size on Turing I and Turing-Hopf instabilities. Out of stable systems without diffusion, the systems are likely to become Turing-Hopf unstable in the presence of diffusion with larger network size (<xref ref-type="fig" rid="F6">Fig. 6B</xref>). This trend for the Turing-Hopf instability is similar to the trend for Turing I. However, particularly at a very large network size, the Turing-Hopf instability becomes more likely to occur and ultimately out-competes Turing I, as can be seen for <italic>N</italic> = 50 in the figure. A similar trend is observed for Turing I relative to the overall Turing instabilities of all types: Turing I is more likely for larger network size being approximately half the occurrence of all Turing instabilities. Among all Turing instability types, we found that Turing II is the most common to arise (4.2% maximum occurrence of all random reaction-diffusion systems), followed by Turing I (3.6%).</p><p id="P22">Without having an experimental understanding of the variability of interaction strength between nodes, an optimal network size should produce Turing I instabilities for a wide range of variances. Such a network size would be most robust to changes in interaction strength, which is a desirable outcome from a biological perspective. To find the exact network size that is the most optimal, we plotted the occurrence of Turing instabilities for different network sizes and variances from <italic>N</italic> = 3 to 100 (<xref ref-type="fig" rid="F7">Fig. 7A</xref>). Based on the heat map, the majority of the Turing instabilities arose just above <italic>γ</italic> = 1, as we should expect since <italic>γ</italic> ≫ 1 would likely result in an unstable system without diffusion, but <italic>γ</italic> ≪ 1 would make it harder for a stable system to become unstable with diffusion. In fact, the occurrence of Turing is ”pinned” to radius <italic>γ</italic> = 1 for large <italic>N</italic>, and the percentage density then follows closely the circular law <italic>σ</italic><sup>2</sup> ~ 1/<italic>N</italic>.</p><p id="P23">Is there an optimal network size for highest robustness of the occurance of Turing patterns? We expect such an <italic>N</italic><sub>opt</sub> as there are no Turing patterns for <italic>N</italic> = 2 and for <italic>N</italic> → ∞. Turing patterns disappear as the eigenvalue distribution becomes a step function, allowing no instability with diffusion. To confirm our intuition, we then calculated the percentage of Turing I for each network size from the heat map (<xref ref-type="fig" rid="F7">Fig. 7B</xref>), demonstrating that <italic>N</italic><sub>opt</sub> = 5 is the most optimal network size based on its highest percentage of Turing patterns. Thus, for a network with two diffusible species, having additional three immobile nodes gives the optimal network size for Turing instabilities. Compared to <italic>N</italic> = 3 with one non-diffusible species (4.73%), Turing instabilities are three times more likely to occur for <italic>N</italic> = 5 (13.86%).</p><p id="P24">While our random matrices are fully connected, it was suggested that biological networks tend to be sparsely connected due to its evolutionary advantage in preserving robustness [<xref ref-type="bibr" rid="R31">31</xref>]. Let us assume that the probability of observing <italic>k</italic> connections is binomially distributed <inline-formula><mml:math id="M14"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mi>n</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>k</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> where <italic>n</italic> the number of matrix elements to consider (’trials’) such as <italic>n</italic> = <italic>N</italic>(<italic>N</italic> − 1) for the number of off-diagonal matrix elements, and <italic>p</italic> the probability for having a connection (’success’). As the variance <italic>np</italic>(1 − <italic>p</italic>) is largest for <italic>p</italic> = 0.5, corresponding to the maximum entropy distribution, we would expect on average 50% connections. This corresponds to the maximum number of possible network structures found by evolution. However, does sparcity also translate into higher Turing robustness? We incorporated sparsity but found that its effect is minor, without qualitatively changing our results (see <xref ref-type="supplementary-material" rid="SD1">Figs. S2 and S3 in Supplementary Materials</xref>). The peak value of the Turing I percentage slightly reduces with sparcity (≈ 14, 12, and 10% for respective sparcities 0, 25, and 50%), while the corresponding optimal network sizes increase slightly (<italic>N</italic><sub>opt</sub> = 5, 7, and 8 for above sparcities). Hence, overall the robustness of Turing is reduced with sparcity, pointing to feedback being important for pattern formation. Note the circular law also applies to sparcity, but needs modification. The radius is just rescaled to <inline-formula><mml:math id="M15"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:msqrt><mml:mrow><mml:mi>N</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula> where connectivity <italic>C</italic> = <italic>p</italic> is the probability for having an off-diagonal matrix element [<xref ref-type="bibr" rid="R25">25</xref>]. This points to our results being broadly representative for a large range of random Turing networks.</p><p id="P25">A major constraint on Turing patterns is that the inhibitor has to diffuse much faster than the activator. How does having immobile nodes change this constraint? Previous work on small networks hinted towards a softening of this constraint [<xref ref-type="bibr" rid="R23">23</xref>, <xref ref-type="bibr" rid="R22">22</xref>, <xref ref-type="bibr" rid="R26">26</xref>]. By varying the diffusion of the two diffusible species modeled in our random reaction-diffusion systems, we sampled systems of <italic>N</italic> = 2, 3, 5, and 50 nodes, with <italic>N</italic> = 2 not supporting Turing for our random matrices with equal degradation of −1 for all nodes (see proof in <xref ref-type="sec" rid="S4">Methods</xref>). Importantly, we found that differential diffusivity is important for Turing I instabilities to arise for very few immobile nodes, but not for systems with many immobile nodes: Based on <xref ref-type="fig" rid="F8">Fig. 8</xref>, a network of <italic>N</italic> = 3 with one immobile node has nearly zero percent Turing instabilities arising at equal diffusivity (i.e. at the identity line <italic>D</italic><sub>1</sub>/<italic>D</italic><sub>2</sub> = 1). As the diffusion ratio deviates from 1, Turing instabilities become more likely for <italic>N</italic> = 3, creating a distinct gap around the identity line. Notably, the plot is symmetric with respect to the identity line for all <italic>N</italic> since the assignment to activator or inhibitor is arbitrary. In contrast, in the presence of more immobile nodes, Turing instabilities can arise at equal diffusivity: As network size increases, the gap at the identity line becomes more narrow, indicating Turing instabilities occurring at a wider combination of the diffusion parameters (see also <xref ref-type="supplementary-material" rid="SD1">Fig. S4 in the Supplementary Materials</xref>). For the a large network size of <italic>N</italic> = 50, we observed a similar occurrence of Turing instability for the majority of the diffusion parameter combinations, except for when the diffusion parameters are both extremely low, approximating the case of no diffusion. Since the Turing instability is a diffusion-driven instability, it is reasonable to have no Turing instability arising here. Additionally, there is no ’dark line’ (indicating zero or low percentage) at the very bottom or very left of all surface plots, indicating that a Turing instability can arise in systems with only one diffusible species. The absence of differential diffusion is even stronger when consider all Turing cases (Turing I, II, and Turing-Hopf) - see <xref ref-type="supplementary-material" rid="SD1">Fig. S5</xref> of the Supplementary Materials. In summary, having numerous immobile nodes significantly relaxes the constraints from Turing conditions.</p></sec><sec id="S3" sec-type="discussion"><title>Discussion</title><p id="P26">Turing networks have traditionally been small in size, making a direct mapping to complex developmental pathways with many unknown molecular species and parameter values difficult. Another drawback of using Turing models in biology has been the requirement to fine-tune parameters to fulfill Turing’s conditions on stability without diffusion and instability for certain wave numbers with diffusion, in contrast to biology’s robustness and evolvability [<xref ref-type="bibr" rid="R32">32</xref>]. Here, we circumvented these issues by using large random matrices to describe linearized Jacobian systems, greatly extending previous studies on <italic>N</italic> ≤ 6 [<xref ref-type="bibr" rid="R26">26</xref>]. By extensively sampling matrix elements, we obtained excellent statistics for networks with up to 100 molecular species.</p><p id="P27">Applying Robert May’s circular law [<xref ref-type="bibr" rid="R24">24</xref>] to cases without and with diffusion of two designated species, in line with Turing’s original model [<xref ref-type="bibr" rid="R4">4</xref>], we identified an optimal network size for maximal robustness, reaching 13.86% of sampled matrices. This value is orders of magnitude higher than previous estimates for small networks [<xref ref-type="bibr" rid="R22">22</xref>]. Our results are robust even when sparcity is introduced, leading only to minor changes in the observed Turing percentage or optimal network size. Importantly, an optimum in Turing robustness emerges in our model due to the tradeoff between maximizing stability without diffusion, which favors small networks centered around eigenvalues on the negative real axis, and maximizing instability with diffusion, which favors large networks for eigenvalues to reach positive real values. According to the circular law, small networks have small radii for the distribution of their eigenvalues, while large networks have large radii. For increasingly large Turing networks, we further found that differential diffusion constants are not required, in line with studies on Turing topologies [<xref ref-type="bibr" rid="R23">23</xref>]. Having many immobile nodes effectively allows for delays and hence different diffusion constants. We hope these results shed new light on Turing mechanisms in developmental systems and help make Turing mechanisms more relevant to quantitative biology.</p><p id="P28">To make our model interpretable, we used a number of simplifying assumptions, resulting in limitations of our predictions. A major simplification is our diagonal matrix elements, which are set to a constant value for all species, representing equal degradation rates for all species. This led to the convenient behavior that all eigenvalues are centered around a single point on the negative real axis, following Robert May’s circular law. Without that assumption, the eigenvalue distributions would still be restricted by circles, but now following the less restrictive Gerschgorin theorem. Based on the latter, the radius scales as ~ <italic>N</italic>, and not ~ <inline-formula><mml:math id="M16"><mml:mrow><mml:msqrt><mml:mi>N</mml:mi></mml:msqrt></mml:mrow></mml:math></inline-formula> as in May’s circular law. This leads not only to larger circles but also to unions of overlapping circles, restricting the real parts less efficiently [<xref ref-type="bibr" rid="R33">33</xref>]. Using the same degradation rates also does not allow for flexibility in the levels of self-activation and inhibition often observed in biological pathways. Choosing degradation rates from a distribution introduces correlations among corresponding off-diagonal matrix elements <italic>J<sub>ij</sub></italic> and <italic>J<sub>ji</sub></italic> and hence different shapes of eigenvalue distributions [<xref ref-type="bibr" rid="R25">25</xref>].</p><p id="P29">Our work opens new avenues for exciting research in systems biology. In future work, more specific small networks could be investigated similar to the ones shown in <xref ref-type="fig" rid="F1">Fig. 1</xref>, to better understand the distributions of Jacobian matrix elements with pattern-forming capability from sampled parameter values. In addition, examining random networks would allow one to obtain joint distributions of matrix elements and hence correlations among these, leading to renewed investigations into the role of network topology [<xref ref-type="bibr" rid="R28">28</xref>]. Of course, more diffusing species could be included, and the effects of boundary conditions investigated. The latter effect was removed in our study by considering systems of infinite domain size, in line with previous studies [<xref ref-type="bibr" rid="R22">22</xref>].</p><p id="P30">In conclusion, we find that Turing patterns do not only occur more frequently by chance than previously thought, but also that there is a surprising sweet spot of network size for most robust Turing patterns. This optimal network size occurred via a stability and instability tradeoff, which did not change significantly when varying the sparsity of the network. This finding supports the idea that the Turing mechanism, if employed by evolution in developmental pathways, is represented by relatively small and hence likely identifiable modules. Understanding their embedding and hierarchical organization in large developmental networks will be worthwhile endeavors.</p></sec><sec id="S4" sec-type="methods"><title>Methods</title><sec id="S5"><title>Parameter searches including Latin hypercube sampling</title><p id="P31">For <xref ref-type="fig" rid="F3">Fig. 3</xref> we sampled 10<sup>7</sup> parameter combinations for each network topology using Latin hypercube sampling <italic>lhs</italic> function from <italic>pyDOE</italic> library, using a loguniform distribution with the following bounds: <italic>V<sub>i</sub></italic> : (0.1, 10), <italic>K<sub>ij</sub></italic> : (0.01, 1), <italic>b<sub>i</sub></italic> : (0.001, 0.1), <italic>μ<sub>i</sub></italic> : (0.01, 1) (see <xref ref-type="disp-formula" rid="FD2">Eq. 2</xref>). The diffusion constants for Species 1 and 2 were fixed to 1 and 10, and the Hill coefficient was set to <italic>n<sub>ij</sub></italic> = 2 throughout. For each parameter set we calculated the unique steady states using 10 different initial guess using the Newton-Raphson method (function <italic>root</italic> with ’hybrid’ setting). In <xref ref-type="fig" rid="F6">Figs. 6</xref> and <xref ref-type="fig" rid="F7">7</xref> we used 10<sup>3</sup> random matrices for each <italic>N</italic> and <italic>γ</italic> pair, and in <xref ref-type="fig" rid="F8">Fig. 8</xref> we used 10<sup>3</sup> random matrices for each <italic>D<sub>1</sub></italic> and <italic>D<sub>2</sub></italic> pair.</p></sec><sec id="S6"><title>Linear stability analysis</title><p id="P32">For each steady state of a parameter set, and there can be more than one due to multistability, we conducted linear stability analysis by calculating and diagonalizing the Jacobian matrices for wave numbers from 0 to <italic>k<sub>max</sub></italic> = 10 using stead size <bold>Δ</bold><italic>k</italic> = 0.01 and with <italic>linalg.eigenvals</italic> function from <italic>numpy</italic> library. Subsequently, we analyzed for Turing I, II etc using a simplified version of the classification scheme in [<xref ref-type="bibr" rid="R22">22</xref>].</p></sec><sec id="S7"><title>Numerical implementation and code availability</title><p id="P33">For <xref ref-type="fig" rid="F3">Fig. 3</xref>, the high-dimensional parameter space created by nested loops was flattened, and ran in parallel by dividing up the linear parameter array equally on different cores using the <italic>multiprocessing</italic> library. The code used for producing <xref ref-type="fig" rid="F2">Figs. 2</xref>-<xref ref-type="fig" rid="F8">8</xref> can be accessed on <italic>github.com/Endresgroup/Random_Turing_networks</italic>.</p></sec><sec id="S8"><title>Fitting of beta distribution</title><p id="P34">Fitting a beta distribution to the data of the Jacobian matrix elements in <xref ref-type="fig" rid="F3">Fig. 3</xref> involves estimating the distribution’s parameters, typically using the method of moments or maximum likelihood estimation (MLE). The method of moments involves calculating the sample mean and variance to derive initial estimates for the shape parameters <italic>α</italic> and <italic>β.</italic> MLE, on the other hand, maximizes the log-likelihood function, which measures how well the beta distribution with specific parameters explains the observed data, to find the best-fitting parameters. Both methods aim to provide a beta distribution that accurately represents the underlying data distribution. Here, we used the method of moments to obtain an initial guess for the parameter values of <italic>α</italic> and <italic>β</italic>, which we then used as an initial guess for the maximisation of the log-likelihood function.</p></sec><sec id="S9"><title>Mathematical proofs</title><p id="P35">Proof that the outliers of the Jacobian matrices have extreme negative real parts, following approximately <inline-formula><mml:math id="M17"><mml:mrow><mml:mo>−</mml:mo><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>∑</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:math></inline-formula>. This is because the trace is given by <inline-formula><mml:math id="M18"><mml:mrow><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mn>0</mml:mn></mml:mstyle></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mn>1</mml:mn></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msub><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>∑</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mi>D</mml:mi></mml:mstyle></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>∑</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mi>λ</mml:mi></mml:mstyle></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, which is invariant under similarity transformations during diagonalization and hence equals the sum of all the eigenvalues <italic>λ<sub>i</sub></italic> (<italic>i</italic> = 1,…, <italic>N</italic>). Or in other words, the mean of the eigenvalues stays the same under such a transformation. Hence, at least one eigenvalue, if real, or a complex conjugate pair, if with an imaginary part, becomes an outlier and tends to minus infinity for increasing wave number <italic>k</italic> at a given network size <italic>N</italic>. This is relevant for <xref ref-type="fig" rid="F5">Fig. 5A</xref>.</p><p id="P36">Proof that there are no Turing instabilities for random matrices with <italic>N</italic> = 2: Based on <xref ref-type="disp-formula" rid="FD5">Eq. 5</xref>, the <italic>k</italic>-dependent Jacobian matrix is given by <disp-formula id="FD7"><label>(7)</label><mml:math id="M19"><mml:mrow><mml:mi>J</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msup><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mn>21</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msup><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p id="P37">Hence, the trace is always negative for all <italic>k</italic>, i.e. <disp-formula id="FD8"><label>(8)</label><mml:math id="M20"><mml:mrow><mml:mi>T</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P38">fulfilling one of Turing’s conditions. Furthermore, the determinant without diffusion (<italic>k</italic> = 0) is required to be positive, and hence must be <disp-formula id="FD9"><label>(9)</label><mml:math id="M21"><mml:mrow><mml:mi>D</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mn>21</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P39">leading to the required stability in absence of diffusion. However, with diffusion (<italic>k</italic> &gt; 0), the determinant cannot become negative as needed for a saddle node and hence instability. Instead, we have <disp-formula id="FD10"><label>(10)</label><mml:math id="M22"><mml:mi>D</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msup><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msub><mml:mi>D</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mn>21</mml:mn></mml:mrow></mml:msub></mml:math></disp-formula> <disp-formula id="FD11"><label>(11)</label><mml:math id="M23"><mml:mo>=</mml:mo><mml:mi>D</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>D</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msup><mml:mi>k</mml:mi><mml:mn>4</mml:mn></mml:msup><mml:mo>&gt;</mml:mo><mml:mn>0.</mml:mn></mml:math></disp-formula></p><p id="P40">Hence, the last of Turing’s conditions cannot be fulfilled for two nodes, which is relevant for <xref ref-type="fig" rid="F7">Figs. 7A</xref> and <xref ref-type="fig" rid="F8">8A</xref>.</p></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary Material</label><media xlink:href="EMS199457-supplement-Supplementary_Material.pdf" mimetype="application" mime-subtype="pdf" id="d8aAcEbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S10"><title>Acknowledgements</title><p>We thank Martina Oliver Huidobro, Mark Isalan, David Lacoste, and Roozbeh Pazuki for helpful discussions, and funding through a studentship from the Department of Life Sciences at Imperial College London (to AMG) and the AI-4-EB Consortium for Bioengineered Cells and Systems (BBSRC award BB/W013770/1) (to RGE).</p></ack><sec id="S11" sec-type="data-availability"><title>Data availability</title><p id="P41">The datasets generated and analyzed in <xref ref-type="fig" rid="F3">Figs. 3</xref> and <xref ref-type="fig" rid="F4">4</xref> are available in the Zenodo repository <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/records/13142658">https://zenodo.org/records/13142658</ext-link></p></sec><ref-list><ref id="R1"><label>[1]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maini</surname><given-names>P</given-names></name></person-group><article-title>Bones, feathers, teeth and coat marking: a unified model</article-title><source>Scientific Progress</source><year>1997</year><comment>Available from: <ext-link ext-link-type="uri" xlink:href="https://ora.ox.ac.uk/objects/uuid:f31e4aad-7188-44de-8143-6c8839385077">https://ora.ox.ac.uk/objects/uuid:f31e4aad-7188-44de-8143-6c8839385077</ext-link></comment></element-citation></ref><ref id="R2"><label>[2]</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Urban</surname><given-names>MC</given-names></name><name><surname>Strauss</surname><given-names>SY</given-names></name><name><surname>Pelletier</surname><given-names>F</given-names></name><name><surname>Palkovacs</surname><given-names>EP</given-names></name><name><surname>Leibold</surname><given-names>MA</given-names></name><name><surname>Hendry</surname><given-names>AP</given-names></name><etal/></person-group><article-title>Evolutionary origins for ecological patterns in space</article-title><source>Proceedings of the National Academy of Sciences</source><publisher-name>Proceedings of the National Academy of Sciences</publisher-name><year>2020</year><month>Jul</month><volume>117</volume><issue>30</issue><fpage>17482</fpage><lpage>90</lpage><pub-id pub-id-type="doi">10.1073/pnas.1918960117</pub-id></element-citation></ref><ref id="R3"><label>[3]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martinez-Garcia</surname><given-names>R</given-names></name><name><surname>Tarnita</surname><given-names>CE</given-names></name><name><surname>Bonachela</surname><given-names>JA</given-names></name></person-group><article-title>Spatial patterns in ecological systems: from microbial colonies to landscapes</article-title><source>Emerging Topics in Life Sciences</source><year>2022</year><month>Jun</month><volume>6</volume><issue>3</issue><fpage>245</fpage><lpage>58</lpage><pub-id pub-id-type="doi">10.1042/ETLS20210282</pub-id></element-citation></ref><ref id="R4"><label>[4]</label><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Turing</surname><given-names>AM</given-names></name></person-group><article-title>The chemical basis of morphogenesis</article-title><source>Philosophical Transactions of the Royal Society of London Series B Biological Sciences</source><year>1952</year><month>Aug</month><volume>237</volume><issue>641</issue><fpage>37</fpage><lpage>72</lpage><comment>Available from:</comment><pub-id pub-id-type="doi">10.1098/rstb.1952.0012</pub-id></element-citation></ref><ref id="R5"><label>[5]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gierer</surname><given-names>A</given-names></name><name><surname>Meinhardt</surname><given-names>H</given-names></name></person-group><article-title>A theory of biological pattern formation</article-title><source>Kybernetik</source><year>1972</year><month>Dec</month><volume>12</volume><issue>1</issue><fpage>30</fpage><lpage>9</lpage><comment>Available from:</comment><pub-id pub-id-type="doi">10.1007/BF00289234</pub-id></element-citation></ref><ref id="R6"><label>[6]</label><element-citation publication-type="book"><person-group person-group-type="editor"><name><surname>Murray</surname><given-names>JD</given-names></name></person-group><source>Mathematical Biology: I. An Introduction. vol. 17 of Interdisciplinary Applied Mathematics</source><publisher-name>Springer</publisher-name><publisher-loc>New York, NY</publisher-loc><year>2002</year><comment>Available from:</comment><pub-id pub-id-type="doi">10.1007/b98868</pub-id></element-citation></ref><ref id="R7"><label>[7]</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lefèvre</surname><given-names>J</given-names></name><name><surname>Mangin</surname><given-names>JF</given-names></name></person-group><article-title>A Reaction-Diffusion Model of Human Brain Development</article-title><source>PLOS Computational Biology</source><publisher-name>Public Library of Science</publisher-name><year>2010</year><month>Apr</month><volume>6</volume><issue>4</issue><elocation-id>e1000749</elocation-id><comment>Available from:</comment><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000749</pub-id></element-citation></ref><ref id="R8"><label>[8]</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sheth</surname><given-names>R</given-names></name><name><surname>Marcon</surname><given-names>L</given-names></name><name><surname>Bastida</surname><given-names>MF</given-names></name><name><surname>Junco</surname><given-names>M</given-names></name><name><surname>Quintana</surname><given-names>L</given-names></name><name><surname>Dahn</surname><given-names>R</given-names></name><etal/></person-group><article-title>Hox Genes Regulate Digit Patterning by Controlling the Wavelength of a Turing-Type Mechanism</article-title><source>Science</source><publisher-name>American Association for the Advancement of Science</publisher-name><year>2012</year><month>Dec</month><volume>338</volume><issue>6113</issue><fpage>1476</fpage><lpage>80</lpage><comment>Available from:</comment><pub-id pub-id-type="doi">10.1126/science.1226804</pub-id></element-citation></ref><ref id="R9"><label>[9]</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Watanabe</surname><given-names>M</given-names></name><name><surname>Kondo</surname><given-names>S</given-names></name></person-group><article-title>Is pigment patterning in fish skin determined by the Turing mechanism?</article-title><source>Trends in Genetics</source><publisher-name>Elsevier</publisher-name><year>2015</year><month>Feb</month><volume>31</volume><issue>2</issue><fpage>88</fpage><lpage>96</lpage><comment>Available from: <ext-link ext-link-type="uri" xlink:href="https://www.cell.com/trends/genetics/abstract/S0168-9525(14)00197-8">https://www.cell.com/trends/genetics/abstract/S0168-9525(14)00197-8</ext-link></comment></element-citation></ref><ref id="R10"><label>[10]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glover</surname><given-names>JD</given-names></name><name><surname>Sudderick</surname><given-names>ZR</given-names></name><name><surname>Shih</surname><given-names>BBJ</given-names></name><name><surname>Batho-Samblas</surname><given-names>C</given-names></name><name><surname>Charlton</surname><given-names>L</given-names></name><name><surname>Krause</surname><given-names>AL</given-names></name><etal/></person-group><article-title>The developmental basis of fingerprint pattern formation and variation</article-title><source>Cell</source><year>2023</year><month>Mar</month><volume>186</volume><issue>5</issue><fpage>940</fpage><lpage>56</lpage><elocation-id>e20</elocation-id><comment>Available from: <ext-link ext-link-type="uri" xlink:href="https://linkinghub.elsevier.com/retrieve/pii/S0092867423000454">https://linkinghub.elsevier.com/retrieve/pii/S0092867423000454</ext-link></comment></element-citation></ref><ref id="R11"><label>[11]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Samarasinghe</surname><given-names>S</given-names></name><name><surname>Minh-Thai</surname><given-names>TN</given-names></name></person-group><article-title>A Comprehensive conceptual and computational dynamics framework for autonomous regeneration of form and function in biological organisms</article-title><source>PNAS Nexus</source><year>2023</year><month>Feb</month><volume>2</volume><issue>2</issue><elocation-id>pgac308</elocation-id><comment>Available from:</comment><pub-id pub-id-type="doi">10.1093/pnasnexus/pgac308/697982</pub-id></element-citation></ref><ref id="R12"><label>[12]</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Maini</surname><given-names>PK</given-names></name><name><surname>Woolley</surname><given-names>TE</given-names></name><name><surname>Baker</surname><given-names>RE</given-names></name><name><surname>Gaffney</surname><given-names>EA</given-names></name><name><surname>Lee</surname><given-names>SS</given-names></name></person-group><chapter-title>Turing’s model for biological pattern formation and the robustness problem</chapter-title><source>Interface Focus</source><publisher-name>Royal Society</publisher-name><year>2012</year><month>Feb</month><volume>2</volume><issue>4</issue><fpage>487</fpage><lpage>96</lpage><comment>Available from:</comment><pub-id pub-id-type="doi">10.1098/rsfs.2011.0113</pub-id></element-citation></ref><ref id="R13"><label>[13]</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Vittadello</surname><given-names>ST</given-names></name><name><surname>Leyshon</surname><given-names>T</given-names></name><name><surname>Schnoerr</surname><given-names>D</given-names></name><name><surname>Stumpf</surname><given-names>MPH</given-names></name></person-group><article-title>Turing pattern design principles and their robustness</article-title><source>Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences</source><publisher-name>Royal Society</publisher-name><year>2021</year><month>Nov</month><volume>379</volume><issue>2213</issue><elocation-id>20200272</elocation-id><comment>Available from:</comment><pub-id pub-id-type="doi">10.1098/rsta.2020.0272</pub-id></element-citation></ref><ref id="R14"><label>[14]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krause</surname><given-names>AL</given-names></name><name><surname>Gaffney</surname><given-names>EA</given-names></name><name><surname>Jewell</surname><given-names>TJ</given-names></name><name><surname>Klika</surname><given-names>V</given-names></name><name><surname>Walker</surname><given-names>BJ</given-names></name></person-group><article-title>Turing Instabilities are Not Enough to Ensure Pattern Formation</article-title><source>Bulletin of Mathematical Biology</source><year>2024</year><month>Jan</month><volume>86</volume><issue>2</issue><fpage>21</fpage><comment>Available from:</comment><pub-id pub-id-type="doi">10.1007/s11538-023-01250-4</pub-id></element-citation></ref><ref id="R15"><label>[15]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Way</surname><given-names>M</given-names></name></person-group><article-title>“What I cannot create, I do not understand”</article-title><source>Journal of Cell Science</source><year>2017</year><month>Sep</month><volume>130</volume><issue>18</issue><fpage>2941</fpage><lpage>2</lpage><comment>Available from:</comment><pub-id pub-id-type="doi">10.1242/jcs.209791</pub-id></element-citation></ref><ref id="R16"><label>[16]</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Karig</surname><given-names>D</given-names></name><name><surname>Martini</surname><given-names>KM</given-names></name><name><surname>Lu</surname><given-names>T</given-names></name><name><surname>DeLateur</surname><given-names>NA</given-names></name><name><surname>Goldenfeld</surname><given-names>N</given-names></name><name><surname>Weiss</surname><given-names>R</given-names></name></person-group><article-title>Stochastic Turing patterns in a synthetic bacterial population</article-title><source>Proceedings of the National Academy of Sciences</source><publisher-name>Proceedings of the National Academy of Sciences</publisher-name><year>2018</year><month>Jun</month><volume>115</volume><issue>26</issue><fpage>6572</fpage><lpage>7</lpage><comment>Available from:</comment><pub-id pub-id-type="doi">10.1073/pnas.1720770115</pub-id></element-citation></ref><ref id="R17"><label>[17]</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sekine</surname><given-names>R</given-names></name><name><surname>Shibata</surname><given-names>T</given-names></name><name><surname>Ebisuya</surname><given-names>M</given-names></name></person-group><chapter-title>Synthetic mammalian pattern formation driven by differential diffusivity of Nodal and Lefty</chapter-title><source>Nature Communications</source><publisher-name>Nature Publishing Group</publisher-name><year>2018</year><month>Dec</month><volume>9</volume><issue>1</issue><elocation-id>5456</elocation-id><comment>Number: 1 Available from: <ext-link ext-link-type="uri" xlink:href="https://www.nature.com/articles/s41467-018-07847-x">https://www.nature.com/articles/s41467-018-07847-x</ext-link></comment></element-citation></ref><ref id="R18"><label>[18]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tica</surname><given-names>J</given-names></name><name><surname>Oliver Huidobro</surname><given-names>M</given-names></name><name><surname>Zhu</surname><given-names>T</given-names></name><name><surname>Wachter</surname><given-names>G</given-names></name><name><surname>Pazuki</surname><given-names>R</given-names></name><name><surname>Tonello</surname><given-names>E</given-names></name><etal/></person-group><article-title>A three-node Turing gene circuit forms periodic spatial patterns in bacteria</article-title><source>Synthetic Biology</source><year>2023</year><comment>Available from:</comment><pub-id pub-id-type="doi">10.1101/2023.10.19.563112</pub-id></element-citation></ref><ref id="R19"><label>[19]</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cao</surname><given-names>Y</given-names></name><name><surname>Feng</surname><given-names>Y</given-names></name><name><surname>Ryser</surname><given-names>MD</given-names></name><name><surname>Zhu</surname><given-names>K</given-names></name><name><surname>Herschlag</surname><given-names>G</given-names></name><name><surname>Cao</surname><given-names>C</given-names></name><etal/></person-group><article-title>Programmable assembly of pressure sensors using pattern-forming bacteria</article-title><source>Nature Biotechnology</source><publisher-name>Nature Publishing Group</publisher-name><year>2017</year><month>Nov</month><volume>35</volume><issue>11</issue><fpage>1087</fpage><lpage>93</lpage><comment>Number: 11 Available from: <ext-link ext-link-type="uri" xlink:href="https://www.nature.com/articles/nbt.3978">https://www.nature.com/articles/nbt.3978</ext-link></comment></element-citation></ref><ref id="R20"><label>[20]</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Din</surname><given-names>MO</given-names></name><name><surname>Martin</surname><given-names>A</given-names></name><name><surname>Razinkov</surname><given-names>I</given-names></name><name><surname>Csicsery</surname><given-names>N</given-names></name><name><surname>Hasty</surname><given-names>J</given-names></name></person-group><article-title>Interfacing gene circuits with microelectronics through engineered population dynamics</article-title><source>Science Advances</source><publisher-name>American Association for the Advancement of Science</publisher-name><year>2020</year><month>May</month><volume>6</volume><issue>21</issue><elocation-id>eaaz8344</elocation-id><comment>Available from:</comment><pub-id pub-id-type="doi">10.1126/sciadv.aaz8344</pub-id></element-citation></ref><ref id="R21"><label>[21]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davies</surname><given-names>J</given-names></name></person-group><article-title>Using synthetic biology to explore principles of development</article-title><source>Development</source><year>2017</year><month>Apr</month><volume>144</volume><issue>7</issue><fpage>1146</fpage><lpage>58</lpage><comment>Available from:</comment><pub-id pub-id-type="doi">10.1242/dev.144196</pub-id></element-citation></ref><ref id="R22"><label>[22]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scholes</surname><given-names>NS</given-names></name><name><surname>Schnoerr</surname><given-names>D</given-names></name><name><surname>Isalan</surname><given-names>M</given-names></name><name><surname>Stumpf</surname><given-names>MPH</given-names></name></person-group><article-title>A Comprehensive Network Atlas Reveals That Turing Patterns Are Common but Not Robust</article-title><source>Cell Systems</source><year>2019</year><month>Sep</month><volume>9</volume><issue>3</issue><fpage>243</fpage><lpage>57</lpage><elocation-id>e4</elocation-id><comment>Available from: <ext-link ext-link-type="uri" xlink:href="https://linkinghub.elsevier.com/retrieve/pii/S2405471219302649">https://linkinghub.elsevier.com/retrieve/pii/S2405471219302649</ext-link></comment></element-citation></ref><ref id="R23"><label>[23]</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Marcon</surname><given-names>L</given-names></name><name><surname>Diego</surname><given-names>X</given-names></name><name><surname>Sharpe</surname><given-names>J</given-names></name><name><surname>Muller</surname><given-names>P</given-names></name></person-group><article-title>High-throughput mathematical analysis identifies Turing networks for patterning with equally diffusing signals</article-title><source>eLife</source><publisher-name>eLife Sciences Publications, Ltd</publisher-name><year>2016</year><month>Apr</month><volume>5</volume><elocation-id>e14022</elocation-id><comment>Available from:</comment><pub-id pub-id-type="doi">10.7554/eLife.14022</pub-id></element-citation></ref><ref id="R24"><label>[24]</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>May</surname><given-names>RM</given-names></name></person-group><article-title>Will a Large Complex System be Stable?</article-title><source>Nature</source><publisher-name>Nature Publishing Group</publisher-name><year>1972</year><month>Aug</month><volume>238</volume><issue>5364</issue><fpage>413</fpage><lpage>4</lpage><comment>Number: 5364Available from: <ext-link ext-link-type="uri" xlink:href="https://www.nature.com/articles/238413a0">https://www.nature.com/articles/238413a0</ext-link></comment></element-citation></ref><ref id="R25"><label>[25]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allesina</surname><given-names>S</given-names></name><name><surname>Tang</surname><given-names>S</given-names></name></person-group><article-title>The stability–complexity relationship at age 40: a random matrix perspective</article-title><source>Population Ecology</source><year>2015</year><volume>57</volume><issue>1</issue><fpage>63</fpage><lpage>75</lpage><pub-id pub-id-type="doi">10.1007/s10144-014-0471-0</pub-id></element-citation></ref><ref id="R26"><label>[26]</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Haas</surname><given-names>PA</given-names></name><name><surname>Goldstein</surname><given-names>RE</given-names></name></person-group><article-title>Turing’s Diffusive Threshold in Random Reaction-Diffusion Systems</article-title><source>Physical Review Letters</source><publisher-name>American Physical Society</publisher-name><year>2021</year><month>Jun</month><volume>126</volume><issue>23</issue><elocation-id>238101</elocation-id><comment>Available from:</comment><pub-id pub-id-type="doi">10.1103/PhysRevLett.126.238101</pub-id></element-citation></ref><ref id="R27"><label>[27]</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Stone</surname><given-names>L</given-names></name></person-group><article-title>The feasibility and stability of large complex biological networks: a random matrix approach</article-title><source>Scientific Reports</source><publisher-name>Nature Publishing Group</publisher-name><year>2018</year><month>May</month><volume>8</volume><issue>1</issue><elocation-id>8246</elocation-id><comment>Number: 1 Available from: <ext-link ext-link-type="uri" xlink:href="https://www.nature.com/articles/s41598-018-26486-2">https://www.nature.com/articles/s41598-018-26486-2</ext-link></comment></element-citation></ref><ref id="R28"><label>[28]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diego</surname><given-names>X</given-names></name><name><surname>Marcon</surname><given-names>L</given-names></name><name><surname>Muller</surname><given-names>P</given-names></name><name><surname>Sharpe</surname><given-names>J</given-names></name></person-group><article-title>Key Features of Turing Systems are Determined Purely by Network Topology</article-title><source>Physical Review X</source><year>2018</year><month>Jun</month><volume>8</volume><issue>2</issue><elocation-id>021071</elocation-id><comment>Available from:</comment><pub-id pub-id-type="doi">10.1103/PhysRevX.8.021071</pub-id></element-citation></ref><ref id="R29"><label>[29]</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Allesina</surname><given-names>S</given-names></name><name><surname>Tang</surname><given-names>S</given-names></name></person-group><article-title>Stability criteria for complex ecosystems</article-title><source>Nature</source><publisher-name>Nature Publishing Group</publisher-name><year>2012</year><month>Mar</month><volume>483</volume><issue>7388</issue><fpage>205</fpage><lpage>8</lpage><comment>Number: 7388 Available from: <ext-link ext-link-type="uri" xlink:href="https://www.nature.com/articles/nature10832">https://www.nature.com/articles/nature10832</ext-link></comment></element-citation></ref><ref id="R30"><label>[30]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Servan</surname><given-names>C</given-names></name><name><surname>Capitan</surname><given-names>J</given-names></name><name><surname>Grilli</surname><given-names>J</given-names></name><name><surname>Morrison</surname><given-names>K</given-names></name><name><surname>Allesina</surname><given-names>S</given-names></name></person-group><article-title>Coexistence of many species in random ecosystems</article-title><source>Nat Ecol Evol</source><year>2018</year><month>Aug</month><volume>2</volume><issue>8</issue><fpage>1237</fpage><lpage>42</lpage><comment>Available from: <ext-link ext-link-type="uri" xlink:href="https://www.nature.com/articles/s41559-018-0603-6">https://www.nature.com/articles/s41559-018-0603-6</ext-link></comment></element-citation></ref><ref id="R31"><label>[31]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pavlopoulos</surname><given-names>GA</given-names></name><name><surname>Secrier</surname><given-names>M</given-names></name><name><surname>Moschopoulos</surname><given-names>CN</given-names></name><name><surname>Soldatos</surname><given-names>TG</given-names></name><name><surname>Kossida</surname><given-names>S</given-names></name><name><surname>Aerts</surname><given-names>J</given-names></name><etal/></person-group><article-title>Using graph theory to analyze biological networks</article-title><source>BioData Mining</source><year>2011</year><month>Apr</month><volume>4</volume><issue>1</issue><fpage>10</fpage><comment>Available from:</comment><pub-id pub-id-type="doi">10.1186/1756-0381-4-10</pub-id></element-citation></ref><ref id="R32"><label>[32]</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wagner</surname><given-names>A</given-names></name></person-group><article-title>Robustness and evolvability: a paradox resolved</article-title><source>Proceedings of the Royal Society B: Biological Sciences</source><publisher-name>Royal Society</publisher-name><year>2007</year><month>Oct</month><volume>275</volume><issue>1630</issue><fpage>91</fpage><lpage>100</lpage><comment>Available from:</comment><pub-id pub-id-type="doi">10.1098/rspb.2007.1137</pub-id></element-citation></ref><ref id="R33"><label>[33]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pazuki</surname><given-names>R</given-names></name><name><surname>Endres</surname><given-names>R</given-names></name></person-group><article-title>Robustness of Turing models and gene regulatory networks with a sweet spot</article-title><source>Physical Review E</source><year>2024</year><month>Jun</month><volume>109</volume><issue>6</issue><elocation-id>064305</elocation-id><comment>Available from:</comment><pub-id pub-id-type="doi">10.1103/PhysRevE.109.064305</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>Network graph representations of pre-defined Turing topologies.</title><p>(Ai) 2-node Gierer-Meinhardt network. (Bi) 3-node network based on [<xref ref-type="bibr" rid="R22">22</xref>, <xref ref-type="bibr" rid="R18">18</xref>]. (C) Extended 4-node network. (D) Large <italic>N</italic> ≫ 1 network. (E) Number of different Turing topologies (graphs) for <italic>N</italic> nodes, exemplified by all 2 and 3-node networks in (Aii) and (Bii), respectively. Dark blue (red) arrows indicate activation (inhibition), and wiggly lines indicate diffusion.</p></caption><graphic xlink:href="EMS199457-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Dispersion relations illustrating different Turing instabilities.</title><p>(A) Turing type I instability with a peak and negative real part for <italic>k</italic> ≫ 1. (B) Turing type II instability which stays positive (note this is however not possible when all species diffuse). The <italic>y</italic> axis represents the maximum real part of the eigenvalue and the <italic>x</italic> axis shows wave number <italic>k</italic>. The plots are generated from random matrices with network size <italic>N</italic> = 10 and variance <italic>σ</italic><sup>2</sup> = 0.25.</p></caption><graphic xlink:href="EMS199457-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Empirical distributions of Jacobian matrix elements.</title><p>(A) Histograms for parameters leading to Turing I instabilities (light blue) and fits to the beta distribution for Turing I (blue line) and non-Turing (orange line). Empirical distributions are computed based on parameter sampling for the pre-defined 2-4-node network topologies in <xref ref-type="fig" rid="F1">Fig. 1Ai, Bi, and C</xref> for 2-node (A), 3-node (B), and 4-node (C) networks. Note some matrix elements are zero due to missing links in the network (or entries in the adjacency matrix).</p></caption><graphic xlink:href="EMS199457-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Jacobian matrix elements are different for Turing I and non-Turing.</title><p>(A) Beehive plots of the mean (top) and variance (bottom) of the empirical distributions of the non-zero off-diagonal Jacobian matrix elements from <xref ref-type="fig" rid="F3">Fig. 3</xref> (based on the pre-defined 2-4-node network topologies in <xref ref-type="fig" rid="F1">Fig. 1Ai, Bi, and C</xref>). A statistical Brown-Forsythe test was utilised to verify whether the difference in variance between each pair of Turing and non-Turing distributions was statistically significant. For all pairs of the Jacobian distributions except one, we found that the test showed a statistically significant difference between the variances. Furthermore, 12 out of 16 p-values were under 0.001, showing a strong statistical significance. (B) Sum of off-diagnal matrix elements, showing a clear visual difference between Turing I (light blue) and non-Turing (light orange) for the 2-4 node topologies. The distributions become increasingly symmetric (and Gaussian) for more nodes.</p></caption><graphic xlink:href="EMS199457-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>Eigenvalue distribution of a large random network.</title><p>(A) Circular scatter plot and corresponding kernel density estimations of eigenvalues in the complex plain for network size <italic>N</italic> = 100, variance <italic>σ</italic><sup>2</sup> = 0.01, and diffusion constants <italic>D</italic><sub>1</sub> = 1, <italic>D</italic><sub>2</sub> = 10. While the system without diffusion has all the eigenvalues distribute around <italic>γ</italic> = 1, the same system with diffusion has most but not all of its eigenvalues distribute in a circle with radius <italic>γ</italic> = 1. (B) Full eigenvalue distribution with outliers. Green, red and blue points correspond to wave numbers <italic>k</italic> &lt; 1, <italic>k</italic> = 1 and <italic>k</italic> &gt; 1, respectively.</p></caption><graphic xlink:href="EMS199457-f005"/></fig><fig id="F6" position="float"><label>Figure 6</label><caption><title>Relationships between network size <italic>N</italic> and radius <inline-formula><mml:math id="M24"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:msqrt><mml:mi>N</mml:mi></mml:msqrt></mml:mrow></mml:math></inline-formula>.</title><p>10<sup>3</sup> random matrices are sampled for each <italic>N</italic> and <italic>γ</italic> pair. (A) Percentage of stable random matrices without diffusion. (B) Percentage of previously stable random matrices turning unstable with diffusion. ’Hopf’ indicates Turing-Hopf. (C) Percentage of random matrices leading to Turing instabilities (Turing I, II, and Turing-Hopf). (D) Percentage of random matrices leading to Turing I instabilities.</p></caption><graphic xlink:href="EMS199457-f006"/></fig><fig id="F7" position="float"><label>Figure 7</label><caption><title>Optimal network size for highest Turing robustness.</title><p>(A) Heat map of percentage occurrence of Turing I in random matrices of different networks sizes <italic>N</italic> and variances <italic>σ</italic><sup>2</sup> for <italic>γ</italic> = 1 and zero off-diagonal element sparsity (or connectivity <italic>C</italic> =1). (B) Corresponding percentage shares of each network size <italic>N</italic>. For our parameters, the optimal network size is <italic>N</italic> = 5. The horizontal axis is set to a linear scale (logarithmic scale in inset).</p></caption><graphic xlink:href="EMS199457-f007"/></fig><fig id="F8" position="float"><label>Figure 8</label><caption><title>Effect of diffusion constants on Turing pattern formation.</title><p>Heat map of percentage occurrence of Turing I in random matrices for different diffusion parameters, <italic>D</italic><sub>1</sub> and <italic>D</italic><sub>2</sub>: (A) <italic>N</italic> = 2, <italic>σ</italic><sup>2</sup> = 0.5; (B) <italic>N</italic> = 3, <italic>σ</italic><sup>2</sup> = 0.33; (C) <italic>N</italic> = 5, <italic>σ</italic><sup>2</sup> = 0.2 (D) <italic>N</italic> = 50, <italic>σ</italic><sup>2</sup> = 0.02. For increasing <italic>N</italic>, constraints on diffusion constants being different vanish.</p></caption><graphic xlink:href="EMS199457-f008"/></fig></floats-group></article>