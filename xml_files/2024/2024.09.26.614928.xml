<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS199077</article-id><article-id pub-id-type="doi">10.1101/2024.09.26.614928</article-id><article-id pub-id-type="archive">PPR917336</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">1</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>A hierarchical Bayesian model reveals increased precision weighting for afferent cardiac signals, and reduced anxiety, as a function of interoceptive training</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Suksasilp</surname><given-names>Chatrin</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="corresp" rid="CR1">a</xref></contrib><contrib contrib-type="author"><name><surname>McLanachan</surname><given-names>Abigail</given-names></name><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Quadt</surname><given-names>Lisa</given-names></name><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A4">4</xref></contrib><contrib contrib-type="author"><name><surname>Boulton</surname><given-names>Blaise</given-names></name><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Mulcahy</surname><given-names>James</given-names></name><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Critchley</surname><given-names>Hugo D</given-names></name><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A4">4</xref></contrib><contrib contrib-type="author"><name><surname>Smith</surname><given-names>Ryan</given-names></name><xref ref-type="aff" rid="A5">5</xref><xref ref-type="aff" rid="A6">6</xref><xref ref-type="fn" rid="FN1">b</xref></contrib><contrib contrib-type="author"><name><surname>Garfinkel</surname><given-names>Sarah N</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="fn" rid="FN1">b</xref></contrib><aff id="A1"><label>1</label>Institute of Cognitive Neuroscience, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>University College London</institution></institution-wrap>, <country country="GB">UK</country></aff><aff id="A2"><label>2</label>Neuroscience, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/01qz7fr76</institution-id><institution>Brighton and Sussex Medical School</institution></institution-wrap>, <country country="GB">UK</country></aff><aff id="A3"><label>3</label>Psychology, Open University, UK</aff><aff id="A4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05fmrjg27</institution-id><institution>Sussex Partnership NHS Foundation Trust</institution></institution-wrap>, <country id="GB">UK</country></aff><aff id="A5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05e6pjy56</institution-id><institution>Laureate Institute for Brain Research</institution></institution-wrap>, <city>Tulsa</city>, <state>OK</state>, <country country="US">USA</country></aff><aff id="A6"><label>6</label>Oxley College of Health &amp; Natural Sciences, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/04wn28048</institution-id><institution>The University of Tulsa</institution></institution-wrap>, <state>OK</state>, <country country="US">USA</country></aff></contrib-group><author-notes><corresp id="CR1">
<label>a</label>Corresponding author: <email>c.suksasilp.16@ucl.ac.uk</email> Tel: +44 (0)20-7679-1177</corresp><fn id="FN1"><label>b</label><p id="P1">Joint senior authors</p></fn></author-notes><pub-date pub-type="nihms-submitted"><day>30</day><month>09</month><year>2024</year></pub-date><pub-date pub-type="preprint"><day>28</day><month>09</month><year>2024</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P2">Perceptual accuracy for interoceptive signals, such as heartbeats, varies in a trait-like manner across individuals and may influence the capacity for emotion regulation and vulnerability to affective symptoms, notably anxiety. Here, we demonstrate that an interoceptive training protocol improved perceptual accuracy in two tasks of heartbeat perception and reduced both state and trait anxiety in a subclinical sample, extending previous findings in autistic adults. Computational modelling indicated that accuracy improvement in the heartbeat discrimination task was associated with increases in the internal reliability estimate for interoceptive signals – their precision weighting – while a lower-level parameter representing noise in the interoceptive signal itself (which influences speed of learning) moderated this precision weighting improvement. Reductions in both state and trait anxiety in the training group were uniquely explained by computational parameter estimates, and not by conventional accuracy measures. These findings indicate that trait-like differences in interoceptive processing are modifiable and can be targeted to alleviate anxiety symptoms, and that interoceptive interventions may be best guided by a computational phenotyping approach.</p></abstract><kwd-group><kwd>interoception</kwd><kwd>anxiety</kwd><kwd>interoceptive awareness</kwd><kwd>emotion</kwd><kwd>active inference</kwd><kwd>computational modelling</kwd><kwd>precision</kwd><kwd>priors</kwd><kwd>Bayesian perception</kwd></kwd-group></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P3">Interoception refers to the afferent peripheral signalling, central neural processing, and mental representation of internal bodily changes. These processes inform homeostatic control (<xref ref-type="bibr" rid="R39">Pezzulo et al., 2015</xref>) and induce momentary changes in a variety of cognitive and emotional processes (<xref ref-type="bibr" rid="R5">Ashhad et al., 2022</xref>; <xref ref-type="bibr" rid="R10">Critchley &amp; Garfinkel, 2017</xref>). There is a growing body of evidence for altered interoceptive processing across a range of clinical populations (<xref ref-type="bibr" rid="R24">Khalsa et al., 2018</xref>; <xref ref-type="bibr" rid="R42">Quadt et al., 2018</xref>), including anxiety disorders (<xref ref-type="bibr" rid="R12">Domschke et al., 2010</xref>; <xref ref-type="bibr" rid="R17">Ehlers &amp; Breuer, 1992</xref>), eating disorders (<xref ref-type="bibr" rid="R41">Pollatos et al., 2008</xref>; <xref ref-type="bibr" rid="R40">Pollatos &amp; Georgiou, 2016</xref>), and depression (<xref ref-type="bibr" rid="R6">Avery et al., 2014</xref>; <xref ref-type="bibr" rid="R13">Dunn et al., 2007</xref>).</p><p id="P4">When instructed to attend to bodily signals in behavioural tasks, healthy individuals vary in their ability to accurately perceive those signals (<xref ref-type="bibr" rid="R23">Katkin et al., 1982</xref>; <xref ref-type="bibr" rid="R26">Koch &amp; Pollatos, 2014</xref>). Further, trait-like differences in both objective and self-reported interoceptive accuracy have been linked to the perceived intensity of affective stimuli (<xref ref-type="bibr" rid="R46">Schandry, 1981</xref>; <xref ref-type="bibr" rid="R64">Wiens et al., 2000</xref>), difficulties understanding one’s own emotions (alexithymia; <xref ref-type="bibr" rid="R9">Brewer et al., 2016</xref>; <xref ref-type="bibr" rid="R62">Trevisan et al., 2019</xref>), and the capacity to regulate one’s own emotional states (<xref ref-type="bibr" rid="R16">Edwards &amp; Pinna, 2020</xref>; <xref ref-type="bibr" rid="R66">Zamariola et al., 2019</xref>).</p><p id="P5">Theoretical work has proposed that anxiety arises, in part, from dysfunction in processes of Bayesian perception that are thought to underpin interoception. Specifically, individuals may develop anxious symptoms when confronted with chronic interoceptive prediction errors, or discrepancies between expected and observed bodily signals (<xref ref-type="bibr" rid="R25">Khalsa &amp; Feinstein, 2018</xref>; <xref ref-type="bibr" rid="R37">Paulus &amp; Stein, 2006</xref>). Chronic interoceptive prediction errors are proposed to arise either from (a) chronically noisy or imprecise afferent interoceptive signals; or (b) from the brain inappropriately treating afferent signals as unreliable by maintaining low internal (sub-personal) estimates of their precision – referred to as precision weighting – and/or (c) the brain generating maladaptive prior expectations about interoceptive states (<xref ref-type="bibr" rid="R36">Paulus et al., 2019</xref>; <xref ref-type="bibr" rid="R37">Paulus &amp; Stein, 2006</xref>). Correspondingly, ‘normalising’ the precision weighting afforded to interoceptive signals has been proposed as a potential means of improving affective symptomatology (<xref ref-type="bibr" rid="R35">Owens et al., 2018</xref>). Conventional measures of interoceptive accuracy, assessed using behavioural tasks, are also thought to derive from interoceptive precision weighting (<xref ref-type="bibr" rid="R2">Ainley et al., 2016</xref>), which therefore represents a mechanistic computational target for interoceptive interventions that aim to decrease anxiety.</p><p id="P6">The present study therefore aimed to test the utility of an intervention designed to improve cardiac interoceptive accuracy and ameliorate anxiety symptoms in a subclinical sample, following a previous report of successful results in a randomised controlled trial in autistic adults (<xref ref-type="bibr" rid="R43">Quadt et al., 2021</xref>). Participants in the training group completed tasks of cardiac perception with feedback over eight sessions across five weeks, and were compared against a passive control group. We hypothesised that the training intervention would reduce both trait and state anxiety, while improving cardiac interoceptive accuracy.</p><p id="P7">This study also aimed to clarify the mechanisms underpinning interoceptive training and test whether these mechanisms could explain individual differences in anxiety reduction and interoceptive changes. To do so, we fit Bayesian computational models to participant responses during a cardiac perception task, using a ‘computational phenotyping’ approach that can characterise individual differences, not just in terms of task responses, but in the belief updating mechanisms underlying those responses under ideal Bayesian observer assumptions (<xref ref-type="bibr" rid="R48">Schwartenbeck &amp; Friston, 2016</xref>). This study extends previous computational models of interoception (<xref ref-type="bibr" rid="R28">Lavalley et al., 2023</xref>; <xref ref-type="bibr" rid="R51">Smith, Kuplicki, Feinstein, Forthman, Stewart, Paulus, Tulsa 1000 investigators, et al., 2020</xref>; <xref ref-type="bibr" rid="R51">Smith, Kuplicki, Teed, et al., 2020</xref>; <xref ref-type="bibr" rid="R49">Smith, Mayeli, et al., 2021</xref>) by implementing the bottom-up effects of interoceptive signals within a hierarchical Bayesian model, applying it to the heartbeat discrimination task in a novel implementation (i.e., the previous models were confined to a heartbeat tapping task), and testing a large number of competing hypotheses for the mechanisms of interoceptive learning.</p><p id="P8">We hypothesised that training-based improvements in cardiac interoceptive accuracy would correspond to increases in the precision weighting assigned to cardiac signals, and that these improvements would be moderated by a computational measure of baseline noise in the interoceptive signal that can influence speed of learning. Furthermore, we predicted that increases in the precision weighting assigned to cardiac signals due to training would be associated with anxiety reduction, in line with the hypothesis that ‘normalising’ interoceptive precision weighting should reduce anxiety.</p></sec><sec id="S2" sec-type="methods"><title>Methods</title><sec id="S3" sec-type="subjects"><title>Participants</title><p id="P9">Participants included staff and students recruited from the University of Sussex and through adverts placed around the local community in Brighton and Hove. A total of 54 participants took part in the study; 28 (20 F) were assigned to the interoceptive training group and 26 (22 F) to the control group. The mean age was 27.9 yrs in the training group (range 18 – 48 yrs) and 25.5 yrs in the control group (range 19 – 45 yrs). Ethical approval for the study was granted by the Research Ethics and Governance Committee (School of Psychology) at the University of Sussex. All participants gave informed consent after being provided with written details of the experiment.</p></sec><sec id="S4"><title>Interoceptive training</title><p id="P10">Participants in the training group completed eight training sessions within a five-week period, resulting in 1-3 training sessions per week. Each training session comprised two blocks of heartbeat perception tasks modified to incorporate feedback. In each block, participants completed six trials of the heartbeat counting task (<xref ref-type="bibr" rid="R8">Brener &amp; Kluvitse, 1988</xref>; <xref ref-type="bibr" rid="R63">Whitehead et al., 1977</xref>), followed by twenty trials of the heartbeat discrimination task (<xref ref-type="bibr" rid="R46">Schandry, 1981</xref>).</p><p id="P11">In the heartbeat discrimination task, participants judged the synchronicity of sets of ten tones, relative to their own heartbeat. They were given the instruction: ‘<italic>You will hear ten tones. Please tell me if the tones are in sync or out of sync with your own heartbeat</italic>’. Within each trial, the tones were presented at 440 Hz for 100 ms and triggered by the participant’s own consecutive heartbeats. Synchronous tones were presented at the beginning of the rising edge of the pulse pressure wave and asynchronous tones were presented after a delay of 300 ms, adjusting for the average delay (~250 ms) between the R-wave and the arrival of the pressure wave at the finger (<xref ref-type="bibr" rid="R38">Payne et al., 2006</xref>). At the end of each trial, participants reported whether the tones were synchronous or asynchronous with their own heartbeats and then received feedback about whether their response was correct or incorrect. Each block of the discrimination task included ten trials in the synchronous condition and ten trials in the asynchronous condition presented in random order.</p><p id="P12">In the heartbeat counting task, participants were instructed: ‘<italic>Without manually checking, can you silently count each heartbeat you feel in your body from the time you hear “start” to when you hear “stop</italic>”‘. In each block of this task, participants completed six trials, across randomised time-windows of 25, 30, 35, 40, 45 and 50 s. The number of heartbeats counted was recorded after each trial, and participants were given accurate feedback about the true number of heartbeats that occurred.</p><p id="P13">In between training task blocks, participants were instructed to engage in a self-paced low-level physical activity for 1-2 minutes, to the point where their heartrate became noticeably elevated, but to stop before discomfort occurred. Suggested methods were star jumps or jogging on the spot, but other methods were accepted so long as participants reported feeling an elevated heart rate. The physical activity was always performed prior to the second block of tasks, to minimise the time taken for each training session, because performing physical activity prior to the first block would have necessitated a resting period between blocks to prevent cardiovascular arousal from the first ‘physically active’ block contaminating performance in the subsequent ‘resting’ block.</p><p id="P14">All tasks were programmed in Matlab GUIDE v2.5 running under MATLAB R2012a (The MathWorks, Inc., Natick, MA), while heartbeats were monitored using medical grade pulse oximeters (Nonin 8600 with a ‘soft’ sensor fitting to reduce exteroceptive feedback). Heartrate during each trial of the heartbeat discrimination task was recorded, and averaged within each training session, across all training sessions, and within each assessment session. Due to technical error, six participants in the training group were presented a slightly greater proportion of synchronous trials than asynchronous trials in the heartbeat discrimination task during training sessions, ranging between 53% to 63% synchronous trials, rather than the intended 50% (however, it should be noted that this difference is naturally accounted for when fitting computational models to this data).</p><sec id="S5"><title>Assessment sessions</title><p id="P15">Both the training and control groups completed baseline, mid-point, and final assessment sessions (<xref ref-type="fig" rid="F1">Figure 1</xref>). All participants completed both the heartbeat counting and heartbeat discrimination tasks during each assessment to measure interoceptive accuracy. Importantly, participants were not given feedback on their responses during assessment tasks. In all three assessments, the heartbeat tracking task was always performed first so as not to prime participants with immediate temporal cues regarding their own heart rate. State anxiety and trait anxiety, along with self-reported interoception, were also measured at baseline and final assessment sessions.</p><p id="P16">Due to technical error, participants in the control group completed 20 heartbeat discrimination trials during baseline, mid-point, and final sessions, while individuals in the training group completed 26 trials in each assessment.</p></sec></sec><sec id="S6"><title>Computational Modelling</title><p id="P17">To test competing hypotheses concerning the mechanisms underpinning interoceptive learning, several computational models were fit to participant responses on the heartbeat discrimination task to estimate each participant’s prior beliefs, evidence accumulation rate, and interoceptive sensory precision(s), among other parameters in extended models (described below). <xref ref-type="fig" rid="F2">Figure 2</xref> provides a graphical depiction and explanation of the model structure used for subsequent between-subject analyses, and its associated vectors and matrices.</p><p id="P18">Here we extended a hidden Markov model that has previously been used to implement Bayesian inference processes underlying interoceptive task behaviour in the cardiac and gastric domains (<xref ref-type="bibr" rid="R28">Lavalley et al., 2023</xref>; <xref ref-type="bibr" rid="R51">Smith, Kuplicki, Feinstein, Forthman, Stewart, Paulus, Investigators, et al., 2020</xref>; <xref ref-type="bibr" rid="R51">Smith, Kuplicki, Teed, et al., 2020</xref>; <xref ref-type="bibr" rid="R49">Smith, Mayeli, et al., 2021</xref>). <xref ref-type="bibr" rid="R49">Smith, Friston et al. (2021)</xref> and <xref ref-type="bibr" rid="R11">Da Costa et al. (2020)</xref> offer an overview of the structure and mathematics of the broader class of decision models (active inference models) from which the present model was adapted. <xref ref-type="table" rid="T1">Table 1</xref> gives full definitions of the various elements in the present model and explains the equations that governed (Bayes-optimal) perceptual inference and learning. MATLAB code used to implement this model and produce the computational modelling results is available on GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/ChatrinS/interoceptive-training-Bayesian-modelling">https://github.com/ChatrinS/interoceptive-training-Bayesian-modelling</ext-link>).</p><sec id="S7"><title>Parameter estimation</title><p id="P19">For each model fitted to heartbeat discrimination task responses, we employed a Bayesian optimization algorithm to estimate the set of parameter values for each individual that best explained their task behaviour, as described by <xref ref-type="bibr" rid="R48">Schwartenbeck and Friston (2016)</xref>. Parameter estimation was specifically carried out using variational Laplace (<xref ref-type="bibr" rid="R19">Friston et al., 2007</xref>), implemented using the spm_nlsi_Newton.m routine (freely available within the SPM12 software package; Wellcome Trust Centre for Neuroimaging, London, UK, <ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm">http://www.fil.ion.ucl.ac.uk/spm</ext-link>). This estimation approach maximizes the log-likelihood of participant behaviour under a model while incorporating a complexity cost to deter overfitting (based on parameter covariance and divergence from prior values). The prior variance for estimation was set to .5 for each parameter, while prior means were set as follows: <italic>IP</italic><sub>1</sub> = .75, <italic>IP</italic><sub>2</sub> = .75, <italic>pS</italic> = .50, <italic>η</italic> = .50, <italic>ω</italic> = .75, <italic>ω</italic><sub><italic>Block</italic></sub> = .50, <italic>ζ</italic> = .50, η<sub>D</sub> = .50, <italic>IP</italic><sub>1 <italic>diff</italic></sub> = .25 (see <xref ref-type="table" rid="T2">Table 2</xref> for explanation of each parameter). Most prior means were set to the midpoint within the range of plausible values to minimize estimate bias. For example, prior means for <italic>IP</italic><sub>1</sub> and <italic>IP</italic><sub>2</sub> were set at the midpoint between completely imprecise (.50) and completely precise (1.00) mappings between outcomes and states, while the prior mean for <italic>pS</italic> assumes flat or balanced prior beliefs. An exception to this principle was inverse forgetting rate (<italic>ω</italic>), where initial simulations suggested that a midpoint prior mean (.50) produced implausibly fast forgetting over the course of trials, and so .75 was chosen to bias towards slower forgetting (i.e., higher values correspond to less forgetting). Another exception was <italic>IP</italic><sub>1 <italic>diff</italic></sub>, for which the prior mean was chosen to fit the bound <italic>IP</italic><sub>1</sub> + <italic>IP</italic><sub>1 <italic>diff</italic></sub> ≤ 1.</p></sec><sec id="S8"><title>Model comparison, parameter recoverability, and model identifiability</title><p id="P20"><xref ref-type="table" rid="T2">Table 2</xref> explains the different computational parameters considered, which represent potential mechanisms of learning, forgetting, and Bayesian belief updating. <xref ref-type="table" rid="T3">Table 3</xref> displays which parameters were included in each model, each representing competing hypotheses about the mechanisms involved in interoceptive training. Model 1 was the simplest, which assumed that there was no learning, no hierarchical structure, and no prior bias, and that a static interoceptive precision weighting (<italic>IP</italic><sub>2</sub>) could solely explain participants’ responses. Model 2 added the effect of prior bias (<italic>pS</italic>) on participant responses. Models 3 and 4 incorporated learning controlled by <italic>η</italic>, without or with prior bias, respectively. Models 5 through 13 incorporated the bottom-up effects of afferent cardiac signal precision (represented by <italic>IP</italic><sub>1</sub>) and interactions between levels in a hierarchical structure. In these models, <italic>IP</italic><sub>1</sub> also effectively served as a (static) rate of evidence accumulation for learning <italic>IP</italic><sub>2</sub> over the course of trials, as higher values lead to more precise posteriors over first-level states, which in turn amplifies change in second-level precision estimates after each observation. Model 5 assumed no learning or prior bias within this hierarchical structure, while model 6 additionally included a prior bias. Models 7 and 8 assumed both learning and a hierarchical structure, without or with prior bias, respectively. Models 9 – 13 extended model 8 by considering additional learning and forgetting mechanisms: model 9 introduced an (inverse) forgetting between each trial (<italic>ω</italic>), while model 10 further posited forgetting between each training session (<italic>ω</italic><sub><italic>Block</italic></sub>). Model 11 hypothesised heightened lower-level precision during physical activity blocks (<italic>IP</italic><sub>1 <italic>Diff</italic></sub>), while model 12 introduced learning for the prior bias (<italic>η</italic><sub><bold>D</bold></sub>), and model 13 introduced a ‘faulty memory’ mechanism (<italic>ζ</italic>).</p><p id="P21">Bayesian model comparison evaluated the relative evidence for each model provided by the behavioural data, to determine the best-fitting or ‘winning’ model – for details on this procedure, see <xref ref-type="bibr" rid="R44">Rigoux et al., (2014)</xref>. This model comparison procedure produces the protected exceedance probability (<italic>pxp</italic>) and <italic>α</italic> metrics for each model compared. A model’s <italic>pxp</italic> quantifies the posterior probability that the model is more likely (given the data) than all other models being compared, while <italic>α</italic> quantifies the expected number of participants whose data was generated by the model.</p><p id="P22">Heartbeat discrimination task responses in the training group, concatenated across all training sessions (i.e., up to 320 trials with feedback), was used to determine the winning model (i.e., as only this group underwent training sessions for which learning would be expected and could be modelled).</p><p id="P23">Prior to performing Bayesian model comparison, the space of possible models listed above was first checked to confirm parameter recoverability and model identifiability. Only models that were recoverable and identifiable were then compared. Recoverability and identifiability were accomplished by first generating 13 synthetic datasets (one per model). This was done by simulating behavioural data for each participant under each model’s optimised parameter estimates. For parameter recovery, we then fit each of the 13 models on the synthetic dataset generated by itself, to produce parameter estimates, and then tested the correlation between estimated parameter values and the parameter values used to generate the simulated data. Models with parameters that proved unrecoverable (i.e., no significant correlation between the generative and estimated values) were eliminated from further consideration. Subsequently, we tested the identifiability of the remaining models by fitting them on all remaining synthetic datasets and passing the resulting model fits into Bayesian model comparison. A model was deemed identifiable if it was selected in Bayesian model comparison on the synthetic dataset that it generated, indicating that if this model was indeed the ground truth, it could be successfully ‘identified’ in model comparison. Non-identifiable models were excluded from consideration, and the remaining models were finally passed into Bayesian model comparison to determine the best-fitting model to the empirical data.</p><p id="P24">Synthetic datasets were also used to assess models in terms of their ability to reproduce the empirical data. To do so, we calculated for each participant the ‘model response accuracy’, or the proportion of trials in which simulated responses (in the model’s synthetic dataset) matched the participant’s actual responses during the task. The model response accuracy was averaged across training group participants and reported. We also calculated the ‘mean action probability’, or the probability of emitting the participant’s actual response (determined by the higher-level posterior over hidden states after stimulus presentation, <inline-formula><mml:math id="M1"><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, averaged across trials. The mean action probability was averaged across training group participants (as a mean of means) and reported.</p><p id="P25">Parameter estimates for the best-fitting model (i.e., out of those that were recoverable and identifiable) were then used for between-subjects analyses, as latent variables that best explained behavioural responses across training sessions for each participant. For each control group participant, who only had available data at assessment sessions, responses from up to 60 trials (without feedback) were concatenated and modelled together to produce complementary parameter estimates. Additionally, for both groups, responses from the three assessment sessions were modelled as three separate blocks, producing ‘snapshot’ parameter estimates for each participant at each timepoint.</p></sec></sec><sec id="S9"><title>Interoceptive accuracy</title><p id="P26">Model-free measures of task performance were also calculated using responses during assessment sessions to index their change over time, following the ‘conventional’ approach for analysing task behaviour. Interoceptive accuracy on the heartbeat discrimination task was calculated using signal detection analysis (<xref ref-type="bibr" rid="R60">Stanislaw &amp; Todorov, 1999</xref>): the number of hits (correct in-sync trials), misses (incorrect in-sync trials), correct rejections (correct out-of-sync trials) and false alarms (incorrect out-of-sync trials) were counted for each assessment session. The sensitivity index <italic>d’</italic> was calculated as <italic>z</italic>(<italic>Hit rate</italic>) − <italic>z</italic>(<italic>False alarm rate</italic>) and used as the measure of interoceptive accuracy for this task. Here, <italic>z</italic> denotes the left-tail <italic>p</italic>-value from the normal distribution. The Criterion (<italic>C</italic>), which specifies response bias, was also derived as <inline-formula><mml:math id="M2"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>z</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>H</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mspace width="0.2em"/><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>F</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.2em"/><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mspace width="0.2em"/><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula></p><p id="P27">For the heartbeat counting task, accuracy in each trial was calculated using the number of heartbeats that occurred (<italic>nbeats</italic><sub><italic>real</italic></sub>) and the number of heartbeats the participant reported in each trial (<italic>nbeats</italic><sub><italic>reported</italic></sub>), as <inline-formula><mml:math id="M3"><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo>∣</mml:mo><mml:mi>n</mml:mi><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mspace width="0.2em"/><mml:mi>n</mml:mi><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mspace width="0.2em"/><mml:mi>n</mml:mi><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mspace width="0.2em"/><mml:mi>n</mml:mi><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>. Resulting accuracy scores were averaged over the 6 trials, and used as the overall measure of interoceptive accuracy for this task (<xref ref-type="bibr" rid="R20">Garfinkel et al., 2015</xref>; <xref ref-type="bibr" rid="R22">Hart et al., 2013</xref>).</p></sec><sec id="S10"><title>Anxiety</title><p id="P28">State anxiety and trait anxiety were assessed using the Spielberger State-Trait Anxiety Inventory (<xref ref-type="bibr" rid="R59">Spielberger et al., 1983</xref>). This questionnaire is divided into two 20-question sections: the first section includes questions intended to capture current state anxiety, such as “<italic>I feel strained</italic>”, using a response scale which runs from “<italic>Not at all</italic>”, to “<italic>Very much so</italic>”. The second section targets a dispositional tendency for trait anxiety, and includes questions such as “<italic>I worry too much over something that doesn’t really matter</italic>”, with a response scale from “<italic>Almost never</italic>” to “<italic>Almost always</italic>”.</p></sec><sec id="S11"><title>Self-reported interoception</title><p id="P29">The Multidimensional Assessment of Interoceptive Awareness (MAIA) was used to measure subjectively perceived facets of interoception (<xref ref-type="bibr" rid="R32">Mehling et al., 2012</xref>). The MAIA is a 32-item self-report scale, divided into eight different subscales: 1) Noticing, assessing the awareness of uncomfortable, comfortable, or neutral body sensations, 2) Not-Distracting, assessing the tendency <italic>not</italic> to use distraction to cope with discomfort, 3) Not-Worrying, assessing the tendency <italic>not</italic> to experience emotional distress with physical discomfort, 4) Attention Regulation, assessing the reported ability to sustain and control attention to body sensations, 5) Emotional Awareness, assessing the reported ability to attribute specific physical sensations to physiological manifestations of emotions, 6) Self-Regulation scale, assessing the reported ability to regulate distress by attention to body sensations, 7) Body Listening scale, assessing the tendency to actively listen to the body for insight, and 8) Trusting scale, assessing the experience of one’s body as safe and trustworthy.</p></sec><sec id="S12"><title>Statistical Analyses</title><p id="P30">A series of linear mixed effects models (LMEs) tested the effects of group (training vs. control), time (baseline, midpoint, final), and the group by time interaction on conventional interoceptive task measures (tracking task accuracy, discrimination task <italic>d’</italic>, and <italic>C</italic>) and parameter estimates of the winning computational model derived from the assessment sessions (<italic>IP</italic><sub>1</sub>, <italic>IP</italic><sub>2</sub>, and <italic>pS</italic>). Similar LMEs tested the effects of group and time (baseline vs. final) and their interaction on self-reported anxiety (STAI-T and STAI-S) and self-reported interoception (scores on each MAIA sub-scale). Participant age and sex were controlled for as fixed effects. Sum-coding was used for group (control = -1, training = 1) and sex (male = - 1, female = 1), while treatment coding was used for time (baseline = 0, midpoint = 1; and baseline = 0, final = 1). Age was mean-centered. Resultingly, coefficients for time are interpretable as main effects. All LMEs initially included the maximal random effects structure that was testable given the number of observations, but these were subsequently simplified to produce converging and non-singular model fits whenever required. In most cases, the above LMEs retained only random intercepts for each participant. Random effects structures and tabular model outputs are reported for all LMEs in <xref ref-type="supplementary-material" rid="SD1">Supplementary Results</xref>.</p><p id="P31">Another series of LMEs tested whether changes in trait and state anxiety from baseline to final assessment were associated with computational parameter estimates, in the training group only. Change scores for both trait and state anxiety were calculated for each participant, and used as the outcome variables for these LMEs. Estimates for the three computational parameters, <italic>IP</italic><sub>1</sub>, <italic>IP</italic><sub>2</sub>, and <italic>pS</italic> were included as fixed effects factors. Similar LMEs tested whether changes in trait and state anxiety could be explained by changes in conventional interoceptive task measures (tracking task accuracy, discrimination task <italic>d’</italic>, and <italic>C</italic>) from baseline to final assessment. Age and sex were again controlled for as fixed effects. Sex was sum-coded (male = -1, female = 1), and age was mean-centered, such that coefficients for other fixed effects factors could be interpreted as main effects. To determine whether baseline computational and interoceptive measures could predict future change in trait and state anxiety, these LMEs predicting change scores for trait and state anxiety were repeated using parameter estimates and model-free interoceptive task measures derived from the baseline assessment only. Again, these LMEs initially included the maximal random effects structure, which were subsequently simplified to produce converging and non-singular model fits. In most cases, LMEs retained a random intercept for Sex, and when no viable random effects structures could be found, ordinary multiple regression was used instead (see <xref ref-type="supplementary-material" rid="SD1">Supplementary Results 6.1 – 6.3</xref>).</p><p id="P32">For all LMEs, the normality of residuals was assessed using Q-Q plots and Shapiro-Wilk tests (also reported in <xref ref-type="supplementary-material" rid="SD1">Supplementary Results</xref>). Whenever required, non-normally distributed variables were log-transformed using the R package 'optLog' (<ext-link ext-link-type="uri" xlink:href="https://github.com/kforthman/optLog">https://github.com/kforthman/optLog</ext-link>), which identifies optimal log-transformations to minimize variable skew – log-transformations are noted in the results whenever they have been applied. Where multicollinearity was suspected in LMEs finding significant effects (i.e., if variance inflation factors [VIFs] &gt; 5), predictors were removed from models until VIFs were all below 5, and ridge regression was performed to confirm that coefficient estimates remained in the same direction using the R library ‘ridge’ (<xref ref-type="bibr" rid="R33">Moritz et al., 2012</xref>). All relevant VIFs are reported in <xref ref-type="supplementary-material" rid="SD1">Supplementary Results</xref>. However, we also note that coefficient estimates and uncertainty estimates produced by LMEs have been shown to demonstrate robustness to violations of distributional assumptions (<xref ref-type="bibr" rid="R47">Schielzeth et al., 2020</xref>).</p><p id="P33">LMEs were implemented using the <italic>lme4</italic> and <italic>lmerTest</italic> packages within RStudio, and reported using the <italic>sjPlot</italic> package (<xref ref-type="bibr" rid="R7">Bates et al., 2015</xref>; <xref ref-type="bibr" rid="R27">Kuznetsova et al., 2017</xref>; <xref ref-type="bibr" rid="R30">Lüdecke, 2024</xref>; <xref ref-type="bibr" rid="R45">RStudio Team, 2022</xref>). Significance values and degrees of freedom for fixed effects were derived using Kenward-Roger approximations, following <xref ref-type="bibr" rid="R31">Luke (2017)</xref>. Significant effects were interrogated with post-hoc pairwise comparisons using the <italic>emmeans</italic> package (<xref ref-type="bibr" rid="R29">Lenth et al., 2023</xref>), which calculated estimated marginal means (<italic>EM</italic>), standard errors (<italic>SE</italic>), and associated effect sizes (Cohen’s <italic>d</italic> using estimated marginal means). To account for the sex imbalance in the sample, estimated marginal means were calculated using proportional weights.</p></sec></sec><sec id="S13" sec-type="results"><title>Results</title><sec id="S14"><title>Computational modelling</title><sec id="S15"><title>Model comparison, parameter recoverability, and model identifiability</title><p id="P34">Bayesian model comparison indicated that behavioural data provided the most evidence for model 8 (<italic>IP</italic><sub>1</sub>, <italic>IP</italic><sub>2</sub>, <italic>pS</italic>; protected exceedance probability [<italic>pxp</italic>] = .37; model response accuracy = .62, range .49 - .88; mean action probability = .62, range .51 - .87). This model comparison included six models that survived both parameter recovery and identifiability analyses (<xref ref-type="table" rid="T3">Table 3</xref>). Results for parameter recovery and identifiability are shown in <xref ref-type="supplementary-material" rid="SD1">Supplementary Results 1.1 – 1.2</xref>.</p><p id="P35">We note that the evidence for model 8 increased (<italic>pxp</italic> = .83) when model 12 was additionally excluded from comparison. Model 12 incorporated an additional learning rate for prior biases favouring sync or async percepts, assuming this learning process differed between individuals). This is likely because although model 8 produced the best fit to the overall dataset (<italic>α</italic> = 15.52), model 12 produced a better fit to a small number of participants (<italic>α</italic> = 4.62). When model 12 was excluded, these participants are subsequently largely explained by model 8 (<italic>α</italic> = 18.88). Given this pattern, and the fact that model 8 is more parsimonious in containing fewer parameters, we move forward with subsequent analyses based on this model.</p><p id="P36">Parameter recovery for model 8 indicated good reliability for all three parameters (<xref ref-type="table" rid="T4">Table 4</xref>). Identifiability analysis for model 8 also supported its robustness: in a synthetic dataset generated by model 8, Bayesian model comparison again found the most evidence for model 8 (<italic>pxp</italic> = .90). This model posited that the interoceptive precision weighting is learned over time, with its starting value controlled by the parameter <italic>IP</italic><sub>2</sub>.Here, it was possible to derive the overall change in the interoceptive precision weighting over the course of training (denoted by Δ<italic>IP</italic><sub>2</sub>) for each participant using their optimised parameter values and the model equations that govern how interoceptive precision weighting evolves across trials (described in <xref ref-type="table" rid="T2">Table 2</xref>), allowing a model-based metric of individual training effectiveness.</p></sec><sec id="S16"><title>Computational parameter estimates</title><p id="P37">Parameter values that best explained heartbeat discrimination task responses in the training group (across 320 training trials with feedback) and the control group (across 60 assessment trials without feedback) were estimated for <italic>IP</italic><sub>1</sub>, <italic>IP</italic><sub>2</sub>, and <italic>pS</italic>, and the derived change in interoceptive precision weighting (Δ<italic>IP</italic><sub>2</sub>) was subsequently calculated. <xref ref-type="fig" rid="F3">Figure 3</xref> <bold>(top)</bold> illustrates descriptive correlations between estimated model parameters and indices of task responses, while <xref ref-type="fig" rid="F3">Figure 3</xref> <bold>(bottom)</bold> shows the distribution of parameter estimates in the training group and their correlations with each other, including Δ<italic>IP</italic><sub>2</sub>. <xref ref-type="fig" rid="F4">Figure 4</xref> illustrates the same measures for the parameter estimates in the control group, derived from concatenated assessment trials.</p><p id="P38">Parameter estimates in the training group were normally distributed for <italic>IP</italic><sub>1</sub> (<italic>W</italic> = .97, <italic>p</italic> = .60) and <italic>pS</italic> (<italic>W</italic> = .98, <italic>p</italic> = .75), but were non-normally distributed for <italic>IP</italic><sub>2</sub> (<italic>W</italic> = .64, <italic>p</italic> &lt; .001) and Δ<italic>IP</italic><sub>2</sub> (<italic>W</italic> = .91, <italic>p</italic> = .02). In the control group, <italic>IP</italic><sub>1</sub> (<italic>W</italic> = .95, <italic>p</italic> = .28), <italic>IP</italic><sub>2</sub> (<italic>W</italic> = .94, <italic>p</italic> = .13), and <italic>pS</italic> (<italic>W</italic> = .93, <italic>p</italic> = .07) were normally distributed, while Δ<italic>IP</italic><sub>2</sub> was not (<italic>W</italic> = .80, <italic>p</italic> &lt; .001). When pooling both groups together, <italic>IP</italic><sub>1</sub> was normally distributed (<italic>W</italic> = .98, <italic>p</italic> = .69), but <italic>IP</italic><sub>2</sub> (<italic>W</italic> = .63, <italic>p</italic> &lt; .001), Δ<italic>IP</italic><sub>2</sub> (<italic>W</italic> = .85, <italic>p</italic> &lt; .001), and <italic>pS</italic> (<italic>W</italic> = .89, <italic>p</italic> &lt; .001) were non-normally distributed. As such, computational variables that were non-normally distributed were log-transformed for further statistical analysis (noted whenever applicable).</p></sec><sec id="S17"><title>Relationship with heartrate and conventional interoceptive task measures</title><p id="P39">Across both groups, the mean heartrate taken across all trials of the heartrate discrimination task was significantly associated with <italic>IP</italic><sub>1</sub> parameter estimates (<italic>r</italic>(52) = -.33, <italic>p</italic> = .01), such that a lower heartrate across all trials was associated with higher <italic>IP</italic><sub>1</sub>. Multiple regression analyses indicated that this effect was significant independent of contributions from other parameter estimates, age, and sex (<italic>β</italic> = -0.003, <italic>SE</italic> = 0.001, <italic>t</italic>(20.00) = -2.87, <italic>p</italic> = .01; <xref ref-type="fig" rid="F5">Figure 5</xref>, <xref ref-type="supplementary-material" rid="SD1">Supplementary Results 2.1</xref>). The effect remained significant when considering the training group only (<xref ref-type="supplementary-material" rid="SD1">Supplementary Results 2.2</xref>). This could be seen to support the assumption made in the computational model that <italic>IP</italic><sub>1</sub> represents a cardiovascular trait corresponding to the physiological afferent signal precision, which would be expected to moderate learning (i.e., an objectively noisier signal would be more difficult to learn from).</p><p id="P40">Conventional measures of perceptual accuracy in the heartbeat discrimination and heartbeat counting tasks improved over time in the training group, but not the control group (<xref ref-type="fig" rid="F6">Figure 6</xref>). The training group showed a significant increase in tracking task accuracy from the baseline (estimated marginal mean [<italic>EM</italic>] = 0.53, standard error [<italic>SE</italic>] = 0.04) to midpoint assessments (<italic>EM</italic> = 0.78, <italic>SE</italic> = 0.04; <italic>t</italic>(102) = 6.99, <italic>p</italic> &lt; .001, Cohen’s <italic>d</italic> = 1.87), with no subsequent improvement between the mid-point and final assessments (<italic>EM</italic> = 0.83, <italic>SE</italic> = 0.04; <italic>t</italic>(102) = 1.30, <italic>p =</italic> .20, Cohen’s <italic>d</italic> = 0.35). The control group showed no significant improvement from the baseline (<italic>EM</italic> = 0.59, <italic>SE</italic> = 0.04) to midpoint assessments (<italic>EM</italic> = 0.59, <italic>SE</italic> = 0.04; <italic>t</italic>(103) = -0.07, <italic>p</italic> = .94, Cohen’s <italic>d</italic> = 0.02) or final assessments (<italic>EM</italic> = 0.65, <italic>SE</italic> = 0.04; <italic>t</italic>(103) = 1.66, <italic>p</italic> = .10, Cohen’s <italic>d</italic> = 0.47; linear mixed model reported in <xref ref-type="supplementary-material" rid="SD1">Supplementary Results 3.1</xref>).</p><p id="P41">The training group showed a significant increase in discrimination task <italic>d’</italic> between the baseline (<italic>EM</italic> = 0.12, <italic>SE</italic> = 0.18) and mid-point assessments (<italic>EM</italic> = 1.22, <italic>SE</italic> = 0.18; <italic>t</italic>(101) = 6.38, <italic>p</italic> &lt; .001, Cohen’s <italic>d</italic> = 1.70), with no subsequent improvement between the mid-point and final assessments (<italic>EM</italic> = 1.46, <italic>SE</italic> = 0.18; <italic>t</italic>(101) = 1.39, <italic>p =</italic> .17, Cohen’s <italic>d</italic> = .37). The control group again showed no significant improvement from the baseline (<italic>EM</italic> = 0.58, <italic>SE</italic> = 0.19) to midpoint assessments (<italic>EM</italic> = 0.54, <italic>SE</italic> = 0.19; <italic>t</italic>(103) = -0.25, <italic>p</italic> = .81, Cohen’s <italic>d</italic> = 0.07) or final assessments (<italic>EM</italic> = 0.71, <italic>SE</italic> = 0.19; <italic>t</italic>(102) = 0.97, <italic>p</italic> = .33, Cohen’s <italic>d</italic> = 0.27; linear mixed model reported in <xref ref-type="supplementary-material" rid="SD1">Supplementary Results 3.2</xref>).</p><p id="P42">Importantly, gains in heartbeat discrimination accuracy – indexed by change in signal detection <italic>d’</italic> from the baseline to final timepoints – were positively correlated with the increase in interoceptive precision weighting (Δ<italic>IP</italic><sub>2</sub>), both within the training group (Spearman’s <italic>r</italic><sub><italic>s</italic></sub>(26) = .67, <italic>p</italic> &lt; .001) and across both groups combined (<italic>r</italic><sub><italic>s</italic></sub>(52) = .65, <italic>p</italic> &lt; .001). <italic>IP</italic><sub>1</sub> estimates were significantly positively correlated with increase in signal detection <italic>d’</italic> from baseline to final timepoints (Pearson’s <italic>r</italic>(26) = .64, <italic>p</italic> &lt; .001) and with Δ<italic>IP</italic><sub>2</sub> in the training group (<italic>r</italic><sub><italic>s</italic></sub>(26) = .87, <italic>p</italic> &lt; .001). Similar associations were found when combining both groups for signal detection <italic>d’</italic> (<italic>r</italic>(51) = .31, <italic>p</italic> = .023) and Δ<italic>IP</italic><sub>2</sub>: (<italic>r</italic><sub><italic>s</italic></sub>(52) = .68, <italic>p</italic> &lt; .001).</p><p id="P43">Furthermore, a mediation analysis including both groups indicated that the relationship between <italic>IP</italic><sub>1</sub> (as the independent variable) and the change in signal detection <italic>d’</italic> (as the dependent variable) was fully mediated by log-transformed Δ<italic>IP</italic><sub>2</sub> (Average Causal Mediation Effect = 6.12, <italic>p</italic> &lt; .001; Average Direct Effect = -1.55, <italic>p</italic> = .41; Total Effect = 4.63, <italic>p</italic> = .007; proportion mediated = 1.34, <italic>p</italic> = .007). These results were consistent with the hypotheses that learning to detect cardiac signals was underpinned by increasing the precision weighting afforded to cardiac signals and that the (lower-level) precision of the afferent signal itself moderated the rate of learning.</p></sec><sec id="S18"><title>Computational parameter estimates from separate assessment sessions</title><p id="P44">Computational parameters were also estimated on heartbeat discrimination task responses in each assessment session separately, producing ‘snapshot’ computational measures at each timepoint for both groups.</p><p id="P45"><italic>IP</italic><sub>1</sub> significantly increased in the training group from the baseline (<italic>EM</italic> = 0.72, <italic>SE</italic> = 0.01) to mid-point (<italic>EM</italic> = 0.81, <italic>SE</italic> = 0.01) assessments (<italic>t</italic>(103) = 6.10, <italic>p</italic> &lt; .001, Cohen’s <italic>d</italic> = 1.63), while the subsequent increase from mid-point to final assessment (<italic>EM</italic> = 0.83, <italic>SE</italic> = 0.01) was non-significant (t(103) = 1.67, <italic>p</italic> =.10, Cohen’s <italic>d</italic> = 0.45; <xref ref-type="fig" rid="F7">Figure 7</xref>, <bold>top;</bold> linear mixed model reported in <xref ref-type="supplementary-material" rid="SD1">Supplementary Results 4.1</xref>). In contrast, the control group showed no significant increases in <italic>IP</italic><sub>1</sub> from the baseline (<italic>EM</italic> = 0.74, <italic>SE</italic> = 0.01) to midpoint assessments (<italic>EM</italic> = 0.75, <italic>SE</italic> = 0.01; <italic>t</italic>(104) = 0.61, <italic>p</italic> = .54, Cohen’s <italic>d</italic> = 0.17) or final assessments (<italic>EM</italic> = 0.77, <italic>SE</italic> = 0.01 <italic>t</italic>(104) = 1.17, <italic>p</italic> = .24, Cohen’s <italic>d</italic> = 0.33).</p><p id="P46">The training group also showed significant increases in <italic>IP</italic><sub>2</sub> from the baseline (<italic>EM</italic> = 0.73, <italic>SE</italic> = 0.006) to mid-point (<italic>EM</italic> = 0.78, <italic>SE</italic> = 0.006) assessments (<italic>t</italic>(103) = 6.32, <italic>p</italic> &lt; .0001, Cohen’s <italic>d</italic> = 1.69), but not between the mid-point to final assessments (<italic>EM</italic> = 0.78, <italic>SE</italic> = 0.006; <italic>t</italic>(103) = -0.01, <italic>p</italic> = .99, Cohen’s <italic>d</italic> = 0.00; <xref ref-type="fig" rid="F7">Figure 7</xref>, <bold>middle</bold>; <xref ref-type="supplementary-material" rid="SD1">Supplementary Results 4.2</xref>). The control group again did not show any significant differences in <italic>IP</italic><sub>2</sub> estimates from the baseline (<italic>EM</italic> = 0.75, <italic>SE</italic> = 0.01) to midpoint assessments (<italic>EM</italic> = 0.76, <italic>SE</italic> = 0.01; <italic>t</italic>(104) = 1.02, <italic>p</italic> = .31, Cohen’s <italic>d</italic> = 0.29) or final assessments (<italic>EM</italic> = 0.76, <italic>SE</italic> = 0.01 <italic>t</italic>(104) = - 0.69, <italic>p</italic> = .49, Cohen’s <italic>d</italic> = 0.19).</p><p id="P47">The training group showed a significant increase in <italic>pS</italic> from the baseline (<italic>EM</italic> = 0.50, <italic>SE</italic> = 0.02) to midpoint assessments (<italic>EM</italic> = 0.56, <italic>SE</italic> = 0.02; <italic>t</italic>(103) = 3.10, <italic>p</italic> = .003, Cohen’s <italic>d</italic> = 0.83), but a subsequent decrease between the mid-point and final assessments (<italic>EM</italic> = 0.52, <italic>SE</italic> = 0.02; <italic>t</italic>(103) = -2.03, <italic>p =</italic> .045, Cohen’s <italic>d</italic> = 0.54; <xref ref-type="fig" rid="F7">Figure 7</xref>, <bold>bottom</bold>; <xref ref-type="supplementary-material" rid="SD1">Supplementary Results 4.3</xref>). Recall that a value of <italic>pS</italic> &gt; .5 indicates biased prior beliefs towards synchronous cardiac-auditory stimuli (and biased towards asynchronous stimuli below .5); thus, based on the Ems, these results indicate the temporary induction of a positive bias that subsequently returned to unbiased values by the end of training. The control group showed no significant change in <italic>pS</italic> from the baseline (<italic>EM</italic> = 0.50, <italic>SE</italic> = 0.02) to midpoint assessments (<italic>EM</italic> = 0.51, <italic>SE</italic> = 0.02; <italic>t</italic>(104) = 0.45, <italic>p</italic> = .66, Cohen’s <italic>d</italic> = 0.13) or final assessments (<italic>EM</italic> = 0.51, <italic>SE</italic> = 0.2 <italic>t</italic>(104) = 0.29, <italic>p</italic> = .77, Cohen’s <italic>d</italic> = 0.08)</p></sec></sec><sec id="S19"><title>Anxiety</title><sec id="S20"><title>Baseline anxiety and change over time</title><p id="P48">Participants showed a moderate range of subclinical anxiety scores on the STAI at baseline (max: 80 points, range 23-70 for trait anxiety; 21-71 for state anxiety). Note that baseline trait anxiety was normally distributed (<italic>W</italic> = .98, <italic>p</italic> = .41), while baseline state anxiety was not (<italic>W</italic> = .92, <italic>p</italic> &lt; .01).</p><p id="P49">State anxiety showed a non-significant decrease in the training group [baseline: <italic>EM</italic> = 40.5, <italic>SE</italic> = 2.06; final: <italic>EM</italic> = 37.1, <italic>SE</italic> = 2.06; <italic>t</italic>(52) = -1.55, <italic>p</italic> = .13, Cohen’s <italic>d</italic> = 0.41], and a non-significant increase in the control group (baseline: <italic>EM</italic> = 36.6, <italic>SE</italic> = 2.14; final: <italic>EM</italic> = 40.0, <italic>SE</italic> = 2.14; <italic>t</italic>(52)= 1.50, <italic>p</italic> = .14, Cohen’s <italic>d</italic> = 0.42) [<xref ref-type="fig" rid="F8">Figure 8</xref>, <bold>top</bold>]. These changes resulted in a significant group by time interaction (<italic>β</italic> = -3.37, <italic>SE</italic> = 1.56, <italic>t</italic>(52) = -2.15, <italic>p</italic> = .036). The two groups did not differ significantly in baseline state anxiety (<italic>β</italic> = 3.83, <italic>SE</italic> = 3.00, <italic>t</italic>(83.2) = 1.28, <italic>p</italic> = .21). Age was significantly associated with greater state anxiety (<italic>β</italic> = 0.36, <italic>SE</italic> = 0.16, <italic>t</italic>(50) = 2.22, <italic>p</italic> = .03), while participant sex was not (<xref ref-type="supplementary-material" rid="SD1">Supplementary Results 5.1</xref>).</p><p id="P50">Trait anxiety decreased in the training group from baseline (<italic>EM</italic> = 46.2, <italic>SE</italic> = 2.01) to final assessment (<italic>EM</italic> = 40.8, <italic>SE</italic> = 2.01; <italic>t</italic>(52) = -4.12, <italic>p</italic> &lt; .001, Cohen’s <italic>d</italic> = 1.10). There was no significant change in trait anxiety within the control group (baseline: <italic>EM</italic> = 42.2, <italic>SE</italic> = 2.09; final: <italic>EM</italic> = 41.5, <italic>SE</italic> = 2.09; <italic>t</italic>(52) = -0.51, <italic>p</italic> = .61, Cohen’s <italic>d</italic> = 0.14; <xref ref-type="fig" rid="F8">Figure 8</xref>, <bold>bottom</bold>), resulting in a significant group by time interaction (<italic>β</italic> = -2.35, <italic>SE</italic> = 0.94, <italic>t</italic>(52) = -2.49, <italic>p</italic> = .02). The two groups did not differ significantly in baseline trait anxiety (<italic>β</italic> = 3.83, <italic>SE</italic> = 2.92, <italic>t</italic>(61.1) = 1.29, <italic>p</italic> = .20). Neither participant age nor sex were significantly associated with trait anxiety (<xref ref-type="supplementary-material" rid="SD1">Supplementary Results 5.2</xref>).</p></sec><sec id="S21"><title>Relationships between change in anxiety and computational parameters</title><p id="P51">In the training group, we tested whether reduction in state and/or trait anxiety following interoceptive training could be explained by computational parameter estimates using LMEs. LMEs initially included each model parameter (<italic>IP</italic><sub>1</sub>, log-transformed <italic>IP</italic><sub>2</sub>, and <italic>pS</italic>) and the derived change in interoceptive precision weighting (log-transformed Δ<italic>IP</italic><sub>2</sub>), while controlling for baseline state anxiety, age, and sex as fixed effects (<xref ref-type="supplementary-material" rid="SD1">Supplementary Results 6.1.1 – 6.1.2</xref>). However, multicollinearity was suspected in these LMEs, and so the log-transformed <italic>IP</italic><sub>2</sub> was later excluded from the predictors, such that VIFs we all below 5.</p><p id="P52">This analysis revealed that weaker prior biases toward perceiving synchrony (<italic>pS</italic>) were associated with greater decreases (or smaller increases) in state anxiety (<italic>β</italic> = 123.18, <italic>SE</italic> = 42.09, <italic>t</italic>(21.00) = 2.93, <italic>p</italic> = .008; <xref ref-type="fig" rid="F9">Figure 9</xref>, <bold>top</bold>; <xref ref-type="supplementary-material" rid="SD1">Supplementary Results 6.1.3</xref>), while greater baseline state anxiety was associated with greater decreases in state anxiety (as expected due to regression to the mean; <italic>β</italic> = -0.70, <italic>SE</italic> = 0.15, <italic>t</italic>(21.00) = -4.59, <italic>p</italic> &lt; .001).</p><p id="P53">The LME predicting change in trait anxiety in the training group indicated that greater <italic>IP</italic><sub>1</sub> values were significantly associated with greater increases in trait anxiety (<italic>β</italic> = 73.41, <italic>SE</italic> = 34.47, <italic>t</italic>(21.00) = 2.13, <italic>p</italic> = .045; <xref ref-type="fig" rid="F9">Figure 9</xref>, <bold>middle</bold>). Conversely, greater Δ<italic>IP</italic><sub>2</sub> values (log-transformed) predicted greater reductions in trait anxiety (i.e., or smaller increases; <italic>β</italic> = - 11.59, <italic>SE</italic> = 5.41, <italic>t</italic>(21.00) = -2.14, <italic>p</italic> = .044; <xref ref-type="fig" rid="F9">Figure 9</xref>, <bold>bottom</bold>; <xref ref-type="supplementary-material" rid="SD1">Supplementary Results 6.1.4</xref>). As expected, greater baseline trait anxiety was also associated with greater decreases in trait anxiety (<italic>β</italic> = -0.26, <italic>SE</italic> = 0.11, <italic>t</italic>(21.00) = -2.26, <italic>p</italic> = .035).</p><p id="P54">Ridge regression results confirmed coefficient estimates in the same direction for significant effects in both LMEs, but only the effect for <italic>pS</italic> was significant in ridge regression (<italic>p</italic> = .046; <xref ref-type="supplementary-material" rid="SD1">Supplementary Results 6.1.5 – 6.1.6</xref>). This is likely due to the reduced statistical power afforded by this more conservative approach. However, these findings suggest results should be interpreted with some caution.</p><p id="P55">When pooling both the training and control groups, an LME including all computational predictors indicated that greater reductions (or smaller increases) in trait anxiety were again associated with greater Δ<italic>IP</italic><sub>2</sub> values (<italic>β</italic> = -3.72, <italic>SE</italic> = 1.82, <italic>t</italic>(46.00) = -2.04, <italic>p</italic> = .047; <xref ref-type="supplementary-material" rid="SD1">Supplementary Results 6.2.2</xref>). A similar LME found no significant associations with state anxiety change in the two groups when pooled (<xref ref-type="supplementary-material" rid="SD1">Supplementary Results 6.2.1</xref>).</p><p id="P56">In contrast, the control group alone showed no significant effects in multiple regression models to explain trait or state anxiety reduction using computational parameters (<xref ref-type="supplementary-material" rid="SD1">Supplementary Results 6.3</xref>). Multiple regression models were used here instead of LMEs, as no random effects structures could be found that produced a converging and non-singular fit.</p><p id="P57">Conventional (model-free) measures of interoceptive task performance were associated with neither state nor trait anxiety change, when considering the training group only, the control group only, or both groups pooled. That is, LMEs (or multiple regressions when no viable mixed effects structure was found) controlling for age, sex, and baseline anxiety levels found no significant associations with the change in heartbeat counting accuracy, heartbeat discrimination <italic>d’</italic>, or <italic>C</italic> (<xref ref-type="supplementary-material" rid="SD1">Supplementary Results 7.1 – 7.3</xref>).</p><p id="P58">Parameter estimates that were derived separately from each assessment session showed no significant associations with anxiety reduction, whether using the change from baseline to final assessments or the baseline parameter values only (all <italic>p</italic>s &gt; .24).</p></sec></sec><sec id="S22"><title>Self-reported interoception</title><p id="P59">An LME testing possible effects of group, time, and their interaction (while controlling for age and sex) on MAIA total score found a significant group by time interaction (<italic>β</italic> = 1.28, <italic>SE</italic> = 0.43, <italic>t</italic>(52) = 3.01, <italic>p</italic> = .004; <xref ref-type="supplementary-material" rid="SD1">Supplementary Results 8.1</xref>). Follow-up contrasts indicated that the training group showed significant gains in MAIA total score from baseline (<italic>EM</italic> = 21.4, <italic>SE</italic> = 0.92) to final timepoints (<italic>EM</italic> = 23.8, <italic>SE</italic> = 0.92; <italic>t</italic>(52) = 4.08, <italic>p</italic> &lt; .001), while the control group did not (baseline <italic>EM</italic> = 23.1, <italic>SE</italic> = 0.95; final <italic>EM</italic> = 22.9, <italic>SE</italic> = 0.95; <italic>t</italic>(52) = -0.25, <italic>p</italic> = .80)</p><p id="P60">To better understand this relationship with MAIA total scores, analogous post-hoc (uncorrected) LMEs were subsequently conducted on each MAIA subscale for interpretive purposes. Here we found significant group by time interactions for Noticing (<italic>β</italic> = 0.26, <italic>SE</italic> = 0.11, <italic>t</italic>(52) = 2.25, <italic>p</italic> = .028; <xref ref-type="supplementary-material" rid="SD1">Supplementary Results 8.2.1</xref>), Emotional Awareness (<italic>β</italic> = 0.24, <italic>SE</italic> = 0.10, <italic>t</italic>(52) = 2.44, <italic>p</italic> = .018; <xref ref-type="supplementary-material" rid="SD1">Supplementary Results 8.2.5</xref>), and Self-Regulation scores (<italic>β</italic> = 0.29, <italic>SE</italic> = 0.12, <italic>t</italic>(52) = 2.47, <italic>p</italic> = .017; <xref ref-type="supplementary-material" rid="SD1">Supplementary Results 8.2.6</xref>). Only random intercepts for each participant were retained in the random-effects structure to produce converging and non-singular model fits.</p><p id="P61">Follow-up contrasts indicated that the training group showed significant gains in Noticing from baseline (<italic>EM</italic> = 3.17, <italic>SE</italic> = 0.18) to final timepoints (<italic>EM</italic> = 3.63, <italic>SE</italic> = 0.18; <italic>t</italic>(52) = 2.94, <italic>p</italic> = .005), while the control group did not (baseline <italic>EM</italic> = 3.04, <italic>SE</italic> = 0.19; final <italic>EM</italic> = 2.99, <italic>SE</italic> = 0.19; <italic>t</italic>(52) = -0.29, <italic>p</italic> = .77). Similarly, the training group showed significant gains in Emotional Awareness (baseline <italic>EM</italic> = 3.15, <italic>SE</italic> = 0.19; final <italic>EM</italic> = 3.50, <italic>SE</italic> = 0.19; <italic>t</italic>(52) = 2.53, <italic>p</italic> = .01), while the control group did not (baseline <italic>EM</italic> = 3.22, <italic>SE</italic> = 0.20; final <italic>EM</italic> = 3.09, <italic>SE</italic> = 0.20; <italic>t</italic>(52) = -0.95, <italic>p</italic> = .35). Finally, the training group showed significant increases in Self-Regulation (baseline <italic>EM</italic> = 2.60, <italic>SE</italic> = 0.21; final <italic>EM</italic> = 3.06, <italic>SE</italic> = 0.21; <italic>t</italic>(52) = 2.77, <italic>p</italic> = .008), while the control group did not (baseline <italic>EM</italic> = 2.85, <italic>SE</italic> = 0.22; final <italic>EM</italic> = 2.72, <italic>SE</italic> = 0.22; <italic>t</italic>(52) = -0.77, <italic>p</italic> = .45).</p><sec id="S23"><title>Relationships with computational parameter estimates</title><p id="P62">Exploratory follow-up correlations revealed that model parameters also showed some correspondence with MAIA scores. In the training group, the change in MAIA total score was positively associated with <italic>pS</italic> (<italic>r</italic>(26) = .45, <italic>p</italic> = .017). Post-hoc correlations with subscales indicated that this relationship to total scores was best explained by greater <italic>pS</italic> in those with decreased Noticing (<italic>r</italic>(26) = -.41, <italic>p</italic> = .030) and decreased Trusting (<italic>r</italic>(26) = -.40, <italic>p</italic> = .033) at the final assessment. In other words, participants who overly endorsed that the tones were in sync with heartbeats also subsequently noticed and trusted bodily signals less after interoceptive training (<xref ref-type="fig" rid="F10">Figure 10</xref>). These effects should be interpreted as hypothesis-generating, given that these analyses were exploratory.</p></sec><sec id="S24"><title>Relationships with anxiety reduction</title><p id="P63">In the training group, similar exploratory correlations indicated that changes in trait anxiety were positively correlated with changes in MAIA total score (<italic>r</italic>(26) = .47, <italic>p</italic> = .010). Post-hoc correlations with subscales indicated that this relationship with total scores was best explained by increases in Attention Regulation in those with reductions in trait anxiety (<italic>r</italic>(26) = -.42, <italic>p</italic> = .026). In both groups pooled, changes in trait anxiety were again positively correlated with change in MAIA total score (<italic>r</italic>(52) = .31, <italic>p</italic> = .025), but post-hoc correlations with subscales indicated no significant associations. Again, these effects should be interpreted as exploratory and hypothesis-generating.</p></sec></sec></sec><sec id="S25" sec-type="discussion"><title>Discussion</title><p id="P64">This study implemented a structured form of cardiac interoceptive training, which significantly enhanced interoceptive accuracy and reduced both trait and state anxiety. A novel computational modelling approach tested several competing hypotheses about the mechanisms that underpin interoceptive learning, and identified computational phenotypes that may explain individual variation in anxiety reduction, over and above conventional interoceptive task measures.</p><p id="P65">The computational model that was most supported by the data posited that cardiac perception involves combining afferent interoceptive signals (weighted by one’s internal estimate of their reliability or precision) with prior biases to produce (Bayesian) posterior beliefs that determine one’s response on each trial of the heartbeat discrimination task. Interoceptive learning under this formulation therefore involves increasing (beliefs about) the precision weighting that should be assigned to afferent signals. Furthermore, noise in afferent cardiac signals themselves was assumed to vary across individuals, with resultant bottom-up effects on rate of interoceptive learning. Estimating the values of model parameters <italic>IP</italic><sub>1</sub> (afferent signal precision), <italic>IP</italic><sub>2</sub> (starting value of interoceptive precision weighting), and <italic>pS</italic> (prior bias) that best reproduced each participant’s responses on the heartbeat discrimination task allowed us to quantify individual differences in the above mechanisms and investigate their relationships with other measures that changed due to interoceptive training. Subsequently, the change in interoceptive precision weighting over the course of training (Δ<italic>IP</italic><sub>2</sub>) was derived using these parameter estimates and the model equations that govern learning.</p><p id="P66">Associations found between computational variables (<italic>IP</italic><sub>1</sub> and Δ<italic>IP</italic><sub>2</sub>) and improvements in heartbeat discrimination task performance support the model’s validity in explaining the dynamics that underpin learning during the training sessions. Furthermore, the association between <italic>IP</italic><sub>1</sub> and mean heartrate across heartbeat discrimination trials supports the assumption made in the model that <italic>IP</italic><sub>1</sub> represents a latent cardiovascular trait associated with afferent signal noise. Computational parameters (<italic>IP</italic><sub>1</sub>, <italic>IP</italic><sub>2</sub>, and <italic>pS</italic>) showed differential patterns of association with confusion matrix indices of task responses, thus appearing to interact to produce the overall pattern of behaviour.</p><sec id="S26"><title>Explaining treatment response</title><p id="P67">Computational variables explained individual variation in anxiety reduction in participants who received interoceptive training, while conventional interoceptive task measures did not. Specifically, state anxiety reduction was explained by the parameter <italic>pS</italic>, such that participants with more balanced prior beliefs (i.e., values of <italic>pS</italic> closer to .5) derived a greater anxiolytic benefit from the interoceptive training. In contrast, participants with the strongest prior biases (towards believing that the stimuli are synchronous) tended to have worsened state anxiety following training. Therefore, biased prior beliefs for interoceptive-exteroceptive integration represent a potential contraindication for interoceptive training.</p><p id="P68">Trait anxiety reduction was explained by Δ<italic>IP</italic><sub>2</sub>, such that participants with the most enhanced interoceptive precision weighting also showed the greatest reduction in trait anxiety. <xref ref-type="fig" rid="F9">Figure 9</xref> <bold>(bottom)</bold> illustrates that participants whose interoceptive precision weighting increased (Δ<italic>IP</italic><sub>2</sub> &gt; 0 or log-transformed Δ<italic>IP</italic><sub>2</sub> &gt; −1.05) tended to also show alleviated trait anxiety, while those whose interoceptive precision weighting diminished (Δ<italic>IP</italic><sub>2</sub> &lt; 0 or log-transformed Δ<italic>IP</italic><sub>2</sub> &lt; −1.05) tended to show worsened trait anxiety. On the other hand, participants with the least reliable cardiac afferent signals (lowest values of <italic>IP</italic><sub>1</sub>; slowest learning) tended to show the greatest reduction in trait anxiety (<xref ref-type="fig" rid="F9">Figure 9</xref>, <bold>middle</bold>). The direction of this effect may initially appear surprising, given the strong positive association between <italic>IP</italic><sub>1</sub> and Δ<italic>IP</italic><sub>2</sub>. However, since these are partial regression effects (from linear mixed models), they represent the effect of <italic>IP</italic><sub>1</sub> while holding Δ<italic>IP</italic><sub>2</sub> (and all other predictors) constant, and vice versa. It should also be noted that slower learning could lead to smoother convergence onto more stably increased precision weightings across the training.</p><p id="P69">Overall, these results present evidence for novel computational mechanisms that could explain anxiolytic responses to interoceptive training. However, this study could not identify computational phenotypes or interoceptive measures derived solely from the baseline assessment session that prospectively predicted subsequent anxiety reduction. This may be due to the lack of feedback during assessment sessions, which could have hindered estimation of parameter values that interact to characterise learning as well as perception. Future work could therefore focus on designing a screening procedure of economical length using the heartbeat discrimination task (ideally with feedback) to prospectively predict treatment response. Success here could allow for personalised treatment allocation of interoceptive training as an intervention for anxiety.</p></sec><sec id="S27"><title>Mechanisms of interoceptive learning and anxiety</title><p id="P70">Our computational modelling approach provided novel insights about the mechanisms that may underlie interoceptive learning, with potential implications for understanding the role of interoceptive disruptions in psychopathology, clinical applications, and future neurocognitive research. Firstly, the present findings lend additional empirical support to Bayesian accounts of interoceptive psychopathology, which propose that anxious symptoms arise from maladaptively low interoceptive precision weighting (i.e., such that priors dominate perception), and that ‘normalising’ precision weighting should be anxiolytic (<xref ref-type="bibr" rid="R35">Owens et al., 2018</xref>; <xref ref-type="bibr" rid="R37">Paulus &amp; Stein, 2006</xref>), at least in the case of trait anxiety.</p><p id="P71">The present findings also provide an empirical illustration of ideas proposed within the clinical psychology literature, such as that learning to intentionally evaluate one’s interoceptive sensations and their potential causes (‘mentalizing interoception’, or using interoceptive sensations to infer one’s own emotions) can be harnessed in psychotherapy (<xref ref-type="bibr" rid="R15">Duquette &amp; Ainley, 2019</xref>; <xref ref-type="bibr" rid="R50">Smith et al., 2018</xref>; <xref ref-type="bibr" rid="R54">Smith &amp; Lane, 2015</xref>). This idea posits that emotional states are inferred as the best explanation for a person’s interoceptive and exteroceptive cues (for supportive simulation work, see <xref ref-type="bibr" rid="R54">Smith, Lane, et al., 2019</xref>; <xref ref-type="bibr" rid="R54">Smith, Parr, et al., 2019</xref>). Accordingly, increasing the precision assigned to interoceptive signals should lead to therapeutic benefit, as supported by the present findings. Further, breaking down maladaptive prior beliefs about associations between interoceptive signals and anxious emotional states is proposed to lead to therapeutic benefit (<xref ref-type="bibr" rid="R15">Duquette &amp; Ainley, 2019</xref>; <xref ref-type="bibr" rid="R25">Khalsa &amp; Feinstein, 2018</xref>). The present intervention may have leveraged a similar mechanism by allowing participants to attend to autonomic arousal in a non-threatening context (self-paced physical activity). This account is supported by associations found in exploratory analyses between anxiety reduction and reduced habitual worrying about bodily sensations, and an increased capacity to attend to them, indexed by the MAIA subscales for Not Worrying and Attention Regulation. Computational parameter estimates were also found to be associated with changes in self-reported interoception. Notably, greater estimates of <italic>pS</italic> (i.e., more biased prior beliefs towards synchronous observations) were correlated with <italic>reduced</italic> scores on the MAIA Trusting and Noticing subscales, again suggesting that biased prior beliefs are a potential contraindication for interoceptive training.</p><p id="P72">The second mechanistic insight offered by our computational modelling approach is that interoceptive learning was best explained by a hierarchical Bayesian model, which allowed cardiac observations to have varying degrees of noise that affected learning, which was controlled by the parameter <italic>IP</italic><sub>1</sub>. Importantly, greater <italic>IP</italic><sub>1</sub> estimates (i.e., less noisy, more precise afferent cardiac signals) were strongly associated with greater heartbeat discrimination task accuracy improvement due to training. This result suggests that learning to detect a signal (and learn from it) depends on the quality or precision of the signal itself, which may differ between individuals.</p><p id="P73">Future research should investigate the (peripheral or central) neural or physiological correlates of <italic>IP</italic><sub>1</sub>. The present findings suggest that <italic>IP</italic><sub>1</sub> could reflect individual differences in cardiovascular function that result in varying noise in the afferent cardiac signal. That said, <italic>IP</italic><sub>1</sub> effectively controls the rate of evidence accumulation or learning, and so may plausibly relate to changes in plasticity as well, such as nucleus tractus solitaris function, consistent with <xref ref-type="bibr" rid="R3">Allen and colleagues’ (2022)</xref> proposal for neural circuits supporting interoceptive inference. Under this model, afferent signals from baroreceptors arrive via the vagus nerve to the nucleus tractus solitaris, which encodes the observed cardiac outcomes before passing inferred interoceptive states to the posterior insula. Inferred states are then thought to be passed on as observations to the anterior insular cortex, which is a candidate for implementing the higher level in our computational model (as also supported by computational architectures posited within neurovisceral integration theory; see <xref ref-type="bibr" rid="R58">Smith et al., 2017</xref>). To elucidate the neural and/or physiological basis of the computational model from this study, future research should measure potential cardiovascular correlates of baroreceptor activation during the heartbeat discrimination task (e.g., blood pressure, pulse wave amplitude, stroke volume), as well as task-related brain activity onto which the computational parameters can be regressed. Hypertensive patients offer a particularly promising clinical group for this research, as they present with chronic alterations to cardiovascular function, along with both lower heartbeat tracking accuracy and attenuated heartbeat-evoked potentials (i.e., where electrophysiological brain responses are time-locked to individual heartbeats; <xref ref-type="bibr" rid="R65">Yoris et al., 2018</xref>).</p><p id="P74">While the winning computational model used in this study posited that <italic>IP</italic><sub>1</sub> is a static individual difference, we also applied this model to data from the assessment sessions for both groups, producing estimates of <italic>IP</italic><sub>1</sub> that varied within-subjects between the baseline, midpoint, and final assessments. This illustrates two approaches for quantifying static vs. dynamic facets of afferent signal precision to identify its physiological correlates. One might speculate that, while there is plausibly a static physiological component of <italic>IP</italic><sub>1</sub>, individuals could feasibly learn to enhance <italic>IP</italic><sub>1</sub> in a state-like manner, perhaps by altering their breathing to amplify heartbeat sensations. Supporting this, breath-holding has been demonstrated to increase cardiac interoceptive precision in related computational modelling studies (<xref ref-type="bibr" rid="R51">Smith, Kuplicki, Feinstein, Forthman, Stewart, Paulus, Tulsa 1000 investigators, et al., 2020</xref>; <xref ref-type="bibr" rid="R51">Smith, Kuplicki, Teed, et al., 2020</xref>) This is consistent with 'active' interoceptive inference theory (<xref ref-type="bibr" rid="R3">Allen et al., 2022</xref>), which posits that agents act to improve the precision of incoming observations, in the aim of minimising prediction errors. That said, given moderate levels of recoverability and fewer available trials in these separate sessions, it is important to acknowledge that some differences could also reflect estimation error.</p><p id="P75">Our results also further link interoception to anxiety. Prior cross-sectional research has highlighted a complex relationship between these constructs, where results appear to be influenced by method of interoceptive testing (<xref ref-type="bibr" rid="R12">Domschke et al., 2010</xref>; <xref ref-type="bibr" rid="R21">Garfinkel et al., 2016</xref>), the nature of the anxiety disorder, and the presence of other comorbidities (<xref ref-type="bibr" rid="R14">Dunn et al., 2010</xref>). Indeed, a recent meta-analysis of 55 studies found no cross-sectional association between interoceptive accuracy measures and either trait or state anxiety (<xref ref-type="bibr" rid="R1">Adams et al., 2022</xref>). The current work instead provides evidence that intervening on cardiac interoceptive accuracy can have an anxiolytic effect and, to our knowledge, is the first interventional study to do so in a subclinical sample with a control group, complementing findings from a prior randomised controlled trial in a sample of autistic adults (<xref ref-type="bibr" rid="R43">Quadt et al., 2021</xref>), and a smaller study without a control group (<xref ref-type="bibr" rid="R61">Sugawara et al., 2020</xref>). The present findings also suggest that gains in interoceptive processing were achieved within four training sessions, as indicated by both computational and conventional accuracy measures. As such, future iterations of interoceptive training would likely benefit from reducing the number of training sessions.</p><p id="P76">The computational modelling approach in this study has some limitations to consider. For example, while the winning model was supported as having the most evidence within model comparison, and its robustness confirmed by recoverability and identifiability analyses, protected exceedance probabilities were not definitive and other modelling approaches could have been considered. The model also did not explicitly account for possible differences in perceptual processing of the tone stimulus in the task (i.e., it modelled the heartbeat and tone as a single combined observation), This could be relevant, as the heartbeat discrimination task assesses interoceptive-exteroceptive integration. An alternative model setup could explicitly include both cardiac and auditory signals that are jointly used to infer higher-level states. The approach taken in this study effectively assumed that auditory signals in the trial were perfectly precise (as supported by related modelling work; see <xref ref-type="bibr" rid="R51">Smith, Kuplicki, Feinstein, Forthman, Stewart, Paulus, Tulsa 1000 investigators, et al., 2020</xref>), such that relevant precisions in the model concerned only cardiac sensations and their integration with auditory signals. Nevertheless, building on recent single-level models (<xref ref-type="bibr" rid="R51">Smith, Kuplicki, Feinstein, Forthman, Stewart, Paulus, Tulsa 1000 investigators, et al., 2020</xref>; <xref ref-type="bibr" rid="R49">Smith, Mayeli, et al., 2021</xref>), this study presents the first use, to our knowledge, of hierarchical Bayesian modelling to characterise interoceptive learning and identify a computational phenotype that captures response to an interoceptive training intervention.</p><p id="P77">Overall, with these considerations in mind, the present findings support a growing body of evidence that interoceptive processes contribute to mental health symptoms (<xref ref-type="bibr" rid="R24">Khalsa et al., 2018</xref>). They also highlight the potential for novel interoceptive therapies for mental health conditions (<xref ref-type="bibr" rid="R34">Nord &amp; Garfinkel, 2022</xref>). This is also the first study to elaborate on mechanisms of an interoception-based intervention using computational modelling, explaining treatment responses and underlying mechanisms. To validate the utility of this approach in the clinical management of anxiety, this behavioural intervention should be extended to patient populations, with the view to develop computational phenotypes that can guide personalised treatment allocation.</p></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary Results</label><media xlink:href="EMS199077-supplement-Supplementary_Results.docx" mimetype="application" mime-subtype="vnd.openxmlformats-officedocument.wordprocessingml.document" id="d80aAcEbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S28"><title>Acknowledgements</title><p>This work was supported by MQ (PsyImpact Grant awarded to HDC), the University of Sussex MSc programmes, and via a donation from the Dr. Mortimer and Theresa Sackler Foundation. CS is supported by a Wellcome Four-year PhD Studentship in Science (UCL Wellcome 4-year PhD in Mental Health Science).</p></ack><ref-list><ref id="R1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adams</surname><given-names>KL</given-names></name><name><surname>Edwards</surname><given-names>A</given-names></name><name><surname>Peart</surname><given-names>C</given-names></name><name><surname>Ellett</surname><given-names>L</given-names></name><name><surname>Mendes</surname><given-names>I</given-names></name><name><surname>Bird</surname><given-names>G</given-names></name><name><surname>Murphy</surname><given-names>J</given-names></name></person-group><article-title>The association between anxiety and cardiac interoceptive accuracy: A systematic review and meta-analysis</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><year>2022</year><volume>140</volume><elocation-id>104754</elocation-id><pub-id pub-id-type="pmid">35798125</pub-id></element-citation></ref><ref id="R2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ainley</surname><given-names>V</given-names></name><name><surname>Apps</surname><given-names>MAJ</given-names></name><name><surname>Fotopoulou</surname><given-names>A</given-names></name><name><surname>Tsakiris</surname><given-names>M</given-names></name></person-group><article-title>‘Bodily precision’: A predictive coding account of individual differences in interoceptive accuracy</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><year>2016</year><volume>371</volume><issue>1708</issue><elocation-id>20160003</elocation-id><pub-id pub-id-type="pmcid">PMC5062093</pub-id><pub-id pub-id-type="pmid">28080962</pub-id><pub-id pub-id-type="doi">10.1098/rstb.2016.0003</pub-id></element-citation></ref><ref id="R3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allen</surname><given-names>M</given-names></name><name><surname>Levy</surname><given-names>A</given-names></name><name><surname>Parr</surname><given-names>T</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><article-title>In the Body’s Eye: The computational anatomy of interoceptive inference</article-title><source>PLOS Computational Biology</source><year>2022</year><volume>18</volume><issue>9</issue><elocation-id>e1010490</elocation-id><pub-id pub-id-type="pmcid">PMC9506608</pub-id><pub-id pub-id-type="pmid">36099315</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1010490</pub-id></element-citation></ref><ref id="R4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allen</surname><given-names>M</given-names></name><name><surname>Poggiali</surname><given-names>D</given-names></name><name><surname>Whitaker</surname><given-names>K</given-names></name><name><surname>Marshall</surname><given-names>TR</given-names></name><name><surname>van Langen</surname><given-names>J</given-names></name><name><surname>Kievit</surname><given-names>RA</given-names></name></person-group><article-title>Raincloud plots: A multi-platform tool for robust data visualization</article-title><source>Wellcome Open Research</source><year>2021</year><volume>4</volume><fpage>63</fpage><pub-id pub-id-type="pmcid">PMC6480976</pub-id><pub-id pub-id-type="pmid">31069261</pub-id><pub-id pub-id-type="doi">10.12688/wellcomeopenres.15191.2</pub-id></element-citation></ref><ref id="R5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashhad</surname><given-names>S</given-names></name><name><surname>Kam</surname><given-names>K</given-names></name><name><surname>Del Negro</surname><given-names>CA</given-names></name><name><surname>Feldman</surname><given-names>JL</given-names></name></person-group><article-title>Breathing Rhythm and Pattern and Their Influence on Emotion</article-title><source>Annual Review of Neuroscience</source><year>2022</year><volume>45</volume><issue>1</issue><fpage>223</fpage><lpage>247</lpage><pub-id pub-id-type="pmcid">PMC9840384</pub-id><pub-id pub-id-type="pmid">35259917</pub-id><pub-id pub-id-type="doi">10.1146/annurev-neuro-090121-014424</pub-id></element-citation></ref><ref id="R6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Avery</surname><given-names>JA</given-names></name><name><surname>Drevets</surname><given-names>WC</given-names></name><name><surname>Moseman</surname><given-names>SE</given-names></name><name><surname>Bodurka</surname><given-names>J</given-names></name><name><surname>Barcalow</surname><given-names>JC</given-names></name><name><surname>Simmons</surname><given-names>WK</given-names></name></person-group><article-title>Major Depressive Disorder Is Associated With Abnormal Interoceptive Activity and Functional Connectivity in the Insula</article-title><source>Biological Psychiatry</source><year>2014</year><volume>76</volume><issue>3</issue><fpage>258</fpage><lpage>266</lpage><pub-id pub-id-type="pmcid">PMC4048794</pub-id><pub-id pub-id-type="pmid">24387823</pub-id><pub-id pub-id-type="doi">10.1016/j.biopsych.2013.11.027</pub-id></element-citation></ref><ref id="R7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bates</surname><given-names>D</given-names></name><name><surname>Mächler</surname><given-names>M</given-names></name><name><surname>Bolker</surname><given-names>B</given-names></name><name><surname>Walker</surname><given-names>S</given-names></name></person-group><article-title>Fitting Linear Mixed-Effects Models Using lme4</article-title><source>Journal of Statistical Software</source><year>2015</year><volume>67</volume><issue>1</issue><pub-id pub-id-type="doi">10.18637/jss.v067.i01</pub-id></element-citation></ref><ref id="R8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brener</surname><given-names>J</given-names></name><name><surname>Kluvitse</surname><given-names>C</given-names></name></person-group><article-title>Heartbeat Detection: Judgments of the Simultaneity of External Stimuli and Heartbeats</article-title><source>Psychophysiology</source><year>1988</year><volume>25</volume><issue>5</issue><fpage>554</fpage><lpage>561</lpage><pub-id pub-id-type="pmid">3186884</pub-id></element-citation></ref><ref id="R9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brewer</surname><given-names>R</given-names></name><name><surname>Cook</surname><given-names>R</given-names></name><name><surname>Bird</surname><given-names>G</given-names></name></person-group><article-title>Alexithymia: A general deficit of interoception</article-title><source>Royal Society Open Science</source><year>2016</year><volume>3</volume><issue>10</issue><elocation-id>150664</elocation-id><pub-id pub-id-type="pmcid">PMC5098957</pub-id><pub-id pub-id-type="pmid">27853532</pub-id><pub-id pub-id-type="doi">10.1098/rsos.150664</pub-id></element-citation></ref><ref id="R10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Critchley</surname><given-names>HD</given-names></name><name><surname>Garfinkel</surname><given-names>SN</given-names></name></person-group><article-title>Interoception and emotion</article-title><source>Current Opinion in Psychology</source><year>2017</year><volume>17</volume><fpage>7</fpage><lpage>14</lpage><pub-id pub-id-type="pmid">28950976</pub-id></element-citation></ref><ref id="R11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Da Costa</surname><given-names>L</given-names></name><name><surname>Parr</surname><given-names>T</given-names></name><name><surname>Sajid</surname><given-names>N</given-names></name><name><surname>Veselic</surname><given-names>S</given-names></name><name><surname>Neacsu</surname><given-names>V</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><article-title>Active inference on discrete state-spaces: A synthesis</article-title><source>Journal of Mathematical Psychology</source><year>2020</year><volume>99</volume><elocation-id>102447</elocation-id><pub-id pub-id-type="pmcid">PMC7732703</pub-id><pub-id pub-id-type="pmid">33343039</pub-id><pub-id pub-id-type="doi">10.1016/j.jmp.2020.102447</pub-id></element-citation></ref><ref id="R12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Domschke</surname><given-names>K</given-names></name><name><surname>Stevens</surname><given-names>S</given-names></name><name><surname>Pfleiderer</surname><given-names>B</given-names></name><name><surname>Gerlach</surname><given-names>AL</given-names></name></person-group><article-title>Interoceptive sensitivity in anxiety and anxiety disorders: An overview and integration of neurobiological findings</article-title><source>Clinical Psychology Review</source><year>2010</year><volume>30</volume><issue>1</issue><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="pmid">19751958</pub-id></element-citation></ref><ref id="R13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dunn</surname><given-names>BD</given-names></name><name><surname>Dalgleish</surname><given-names>T</given-names></name><name><surname>Ogilvie</surname><given-names>AD</given-names></name><name><surname>Lawrence</surname><given-names>AD</given-names></name></person-group><article-title>Heartbeat perception in depression</article-title><source>Behaviour Research and Therapy</source><year>2007</year><volume>45</volume><issue>8</issue><fpage>1921</fpage><lpage>1930</lpage><pub-id pub-id-type="pmid">17087914</pub-id></element-citation></ref><ref id="R14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dunn</surname><given-names>BD</given-names></name><name><surname>Stefanovitch</surname><given-names>I</given-names></name><name><surname>Evans</surname><given-names>D</given-names></name><name><surname>Oliver</surname><given-names>C</given-names></name><name><surname>Hawkins</surname><given-names>A</given-names></name><name><surname>Dalgleish</surname><given-names>T</given-names></name></person-group><article-title>Can you feel the beat? Interoceptive awareness is an interactive function of anxiety- and depression-specific symptom dimensions</article-title><source>Behaviour Research and Therapy</source><year>2010</year><volume>48</volume><issue>11</issue><fpage>1133</fpage><lpage>1138</lpage><pub-id pub-id-type="pmcid">PMC2964892</pub-id><pub-id pub-id-type="pmid">20692645</pub-id><pub-id pub-id-type="doi">10.1016/j.brat.2010.07.006</pub-id></element-citation></ref><ref id="R15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duquette</surname><given-names>P</given-names></name><name><surname>Ainley</surname><given-names>V</given-names></name></person-group><article-title>Working With the Predictable Life of Patients: The Importance of “Mentalizing Interoception” to Meaningful Change in Psychotherapy</article-title><source>Frontiers in Psychology</source><year>2019</year><volume>10</volume><fpage>2173</fpage><pub-id pub-id-type="pmcid">PMC6774393</pub-id><pub-id pub-id-type="pmid">31607993</pub-id><pub-id pub-id-type="doi">10.3389/fpsyg.2019.02173</pub-id></element-citation></ref><ref id="R16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Edwards</surname><given-names>D</given-names></name><name><surname>Pinna</surname><given-names>T</given-names></name></person-group><article-title>A Systematic Review of Associations Between Interoception, Vagal Tone, and Emotional Regulation: Potential Applications for Mental Health, Wellbeing, Psychological Flexibility, and Chronic Conditions</article-title><source>Frontiers in Psychology</source><year>2020</year><volume>11</volume><pub-id pub-id-type="pmcid">PMC7419655</pub-id><pub-id pub-id-type="pmid">32849058</pub-id><pub-id pub-id-type="doi">10.3389/fpsyg.2020.01792</pub-id></element-citation></ref><ref id="R17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ehlers</surname><given-names>A</given-names></name><name><surname>Breuer</surname><given-names>P</given-names></name></person-group><article-title>Increased cardiac awareness in panic disorder</article-title><source>Journal of Abnormal Psychology</source><year>1992</year><volume>101</volume><issue>3</issue><fpage>371</fpage><pub-id pub-id-type="pmid">1500594</pub-id></element-citation></ref><ref id="R18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fox</surname><given-names>J</given-names></name><name><surname>Weisberg</surname><given-names>S</given-names></name></person-group><article-title>Visualizing Fit and Lack of Fit in Complex Regression Models with Predictor Effect Plots and Partial Residuals</article-title><source>Journal of Statistical Software</source><year>2018</year><volume>87</volume><fpage>1</fpage><lpage>27</lpage><pub-id pub-id-type="doi">10.18637/jss.v087.i09</pub-id></element-citation></ref><ref id="R19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Mattout</surname><given-names>J</given-names></name><name><surname>Trujillo-Barreto</surname><given-names>N</given-names></name><name><surname>Ashburner</surname><given-names>J</given-names></name><name><surname>Penny</surname><given-names>W</given-names></name></person-group><article-title>Variational free energy and the Laplace approximation</article-title><source>NeuroImage</source><year>2007</year><volume>34</volume><issue>1</issue><fpage>220</fpage><lpage>234</lpage><pub-id pub-id-type="pmid">17055746</pub-id></element-citation></ref><ref id="R20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garfinkel</surname><given-names>SN</given-names></name><name><surname>Seth</surname><given-names>AK</given-names></name><name><surname>Barrett</surname><given-names>AB</given-names></name><name><surname>Suzuki</surname><given-names>K</given-names></name><name><surname>Critchley</surname><given-names>HD</given-names></name></person-group><article-title>Knowing your own heart: Distinguishing interoceptive accuracy from interoceptive awareness</article-title><source>Biological Psychology</source><year>2015</year><volume>104</volume><fpage>65</fpage><lpage>74</lpage><pub-id pub-id-type="pmid">25451381</pub-id></element-citation></ref><ref id="R21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garfinkel</surname><given-names>SN</given-names></name><name><surname>Tiley</surname><given-names>C</given-names></name><name><surname>O’Keeffe</surname><given-names>S</given-names></name><name><surname>Harrison</surname><given-names>NA</given-names></name><name><surname>Seth</surname><given-names>AK</given-names></name><name><surname>Critchley</surname><given-names>HD</given-names></name></person-group><article-title>Discrepancies between dimensions of interoception in autism: Implications for emotion and anxiety</article-title><source>Biological Psychology</source><year>2016</year><volume>114</volume><fpage>117</fpage><lpage>126</lpage><pub-id pub-id-type="pmid">26724504</pub-id></element-citation></ref><ref id="R22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hart</surname><given-names>N</given-names></name><name><surname>McGowan</surname><given-names>J</given-names></name><name><surname>Minati</surname><given-names>L</given-names></name><name><surname>Critchley</surname><given-names>HD</given-names></name></person-group><article-title>Emotional Regulation and Bodily Sensation: Interoceptive Awareness Is Intact in Borderline Personality Disorder</article-title><source>Journal of Personality Disorders</source><year>2013</year><volume>27</volume><issue>4</issue><fpage>506</fpage><lpage>518</lpage><pub-id pub-id-type="pmid">22928847</pub-id></element-citation></ref><ref id="R23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Katkin</surname><given-names>ES</given-names></name><name><surname>Morell</surname><given-names>MA</given-names></name><name><surname>Goldband</surname><given-names>S</given-names></name><name><surname>Bernstein</surname><given-names>GL</given-names></name><name><surname>Wise</surname><given-names>JA</given-names></name></person-group><article-title>Individual Differences in Heartbeat Discrimination</article-title><source>Psychophysiology</source><year>1982</year><volume>19</volume><issue>2</issue><fpage>160</fpage><lpage>166</lpage><pub-id pub-id-type="pmid">7071294</pub-id></element-citation></ref><ref id="R24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khalsa</surname><given-names>SS</given-names></name><name><surname>Adolphs</surname><given-names>R</given-names></name><name><surname>Cameron</surname><given-names>OG</given-names></name><name><surname>Critchley</surname><given-names>HD</given-names></name><name><surname>Davenport</surname><given-names>PW</given-names></name><name><surname>Feinstein</surname><given-names>JS</given-names></name><name><surname>Feusner</surname><given-names>JD</given-names></name><name><surname>Garfinkel</surname><given-names>SN</given-names></name><name><surname>Lane</surname><given-names>RD</given-names></name><name><surname>Mehling</surname><given-names>WE</given-names></name><name><surname>Meuret</surname><given-names>AE</given-names></name><etal/></person-group><article-title>Interoception and Mental Health: A Roadmap</article-title><source>Biological Psychiatry: Cognitive Neuroscience and Neuroimaging</source><year>2018</year><volume>3</volume><issue>6</issue><fpage>501</fpage><lpage>513</lpage><pub-id pub-id-type="pmcid">PMC6054486</pub-id><pub-id pub-id-type="pmid">29884281</pub-id><pub-id pub-id-type="doi">10.1016/j.bpsc.2017.12.004</pub-id></element-citation></ref><ref id="R25"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Khalsa</surname><given-names>SS</given-names></name><name><surname>Feinstein</surname><given-names>JS</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Tsakiris</surname><given-names>M</given-names></name><name><surname>De Preester</surname><given-names>H</given-names></name></person-group><chapter-title>The somatic error hypothesis of anxiety</chapter-title><source>The Interoceptive Mind: From Homeostasis to Awareness</source><publisher-name>Oxford University Press</publisher-name><year>2018</year><comment>p. 0</comment><pub-id pub-id-type="doi">10.1093/oso/9780198811930.003.0008</pub-id></element-citation></ref><ref id="R26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koch</surname><given-names>A</given-names></name><name><surname>Pollatos</surname><given-names>O</given-names></name></person-group><article-title>Interoceptive sensitivity, body weight and eating behavior in children: A prospective study</article-title><source>Frontiers in Psychology</source><year>2014</year><volume>5</volume><fpage>1003</fpage><pub-id pub-id-type="pmcid">PMC4158976</pub-id><pub-id pub-id-type="pmid">25250006</pub-id><pub-id pub-id-type="doi">10.3389/fpsyg.2014.01003</pub-id></element-citation></ref><ref id="R27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuznetsova</surname><given-names>A</given-names></name><name><surname>Brockhoff</surname><given-names>PB</given-names></name><name><surname>Christensen</surname><given-names>RHB</given-names></name></person-group><article-title>lmerTest Package: Tests in Linear Mixed Effects Models</article-title><source>Journal of Statistical Software</source><year>2017</year><volume>82</volume><issue>13</issue><pub-id pub-id-type="doi">10.18637/jss.v082.i13</pub-id></element-citation></ref><ref id="R28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lavalley</surname><given-names>CA</given-names></name><name><surname>Hakimi</surname><given-names>N</given-names></name><name><surname>Taylor</surname><given-names>S</given-names></name><name><surname>Kuplicki</surname><given-names>R</given-names></name><name><surname>Forthman</surname><given-names>KL</given-names></name><name><surname>Stewart</surname><given-names>JL</given-names></name><name><surname>Paulus</surname><given-names>MP</given-names></name><name><surname>Khalsa</surname><given-names>SS</given-names></name><name><surname>Smith</surname><given-names>R</given-names></name></person-group><article-title>Transdiagnostic failure to adapt interoceptive precision estimates across affective, substance use, and eating disorders: A replication study</article-title><source>medRxiv</source><year>2023</year><elocation-id>2023.10.11.23296870</elocation-id><pub-id pub-id-type="pmcid">PMC11416323</pub-id><pub-id pub-id-type="pmid">38823571</pub-id><pub-id pub-id-type="doi">10.1016/j.biopsycho.2024.108825</pub-id></element-citation></ref><ref id="R29"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Lenth</surname><given-names>RV</given-names></name><name><surname>Bolker</surname><given-names>B</given-names></name><name><surname>Buerkner</surname><given-names>P</given-names></name><name><surname>Giné-Vázquez</surname><given-names>I</given-names></name><name><surname>Herve</surname><given-names>M</given-names></name><name><surname>Jung</surname><given-names>M</given-names></name><name><surname>Love</surname><given-names>J</given-names></name><name><surname>Miguez</surname><given-names>F</given-names></name><name><surname>Riebl</surname><given-names>H</given-names></name><name><surname>Singmann</surname><given-names>H</given-names></name></person-group><source>emmeans: Estimated Marginal Means, aka Least-Squares Means</source><year>2023</year><comment>(Version 1.8.7) [Computer software] <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/web/packages/emmeans/index.html">https://cran.r-project.org/web/packages/emmeans/index.html</ext-link></comment></element-citation></ref><ref id="R30"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Lüdecke</surname><given-names>D</given-names></name></person-group><source>sjPlot: Data Visualization for Statistics in Social Science</source><year>2024</year><comment><ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=sjPlot">https://CRAN.R-project.org/package=sjPlot</ext-link></comment></element-citation></ref><ref id="R31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luke</surname><given-names>SG</given-names></name></person-group><article-title>Evaluating significance in linear mixed-effects models in R</article-title><source>Behavior Research Methods</source><year>2017</year><volume>49</volume><issue>4</issue><fpage>1494</fpage><lpage>1502</lpage><pub-id pub-id-type="pmid">27620283</pub-id></element-citation></ref><ref id="R32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mehling</surname><given-names>WE</given-names></name><name><surname>Price</surname><given-names>C</given-names></name><name><surname>Daubenmier</surname><given-names>JJ</given-names></name><name><surname>Acree</surname><given-names>M</given-names></name><name><surname>Bartmess</surname><given-names>E</given-names></name><name><surname>Stewart</surname><given-names>A</given-names></name></person-group><article-title>The Multidimensional Assessment of Interoceptive Awareness (MAIA)</article-title><source>PLoS ONE</source><year>2012</year><volume>7</volume><issue>11</issue><elocation-id>e48230</elocation-id><pub-id pub-id-type="pmcid">PMC3486814</pub-id><pub-id pub-id-type="pmid">23133619</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0048230</pub-id></element-citation></ref><ref id="R33"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Moritz</surname><given-names>S</given-names></name><name><surname>Cule</surname><given-names>E</given-names></name><name><surname>Frankowski</surname><given-names>D</given-names></name></person-group><source>ridge: Ridge Regression with Automatic Selection of the Penalty Parameter</source><publisher-name>The R Foundation</publisher-name><year>2012</year><comment>[Dataset]</comment><pub-id pub-id-type="doi">10.32614/cran.package.ridge</pub-id></element-citation></ref><ref id="R34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nord</surname><given-names>CL</given-names></name><name><surname>Garfinkel</surname><given-names>SN</given-names></name></person-group><article-title>Interoceptive pathways to understand and treat mental health conditions</article-title><source>Trends in Cognitive Sciences</source><year>2022</year><pub-id pub-id-type="pmid">35466044</pub-id></element-citation></ref><ref id="R35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Owens</surname><given-names>AP</given-names></name><name><surname>Allen</surname><given-names>M</given-names></name><name><surname>Ondobaka</surname><given-names>S</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><article-title>Interoceptive inference: From computational neuroscience to clinic</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><year>2018</year><volume>90</volume><fpage>174</fpage><lpage>183</lpage><pub-id pub-id-type="pmid">29694845</pub-id></element-citation></ref><ref id="R36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paulus</surname><given-names>MP</given-names></name><name><surname>Feinstein</surname><given-names>JS</given-names></name><name><surname>Khalsa</surname><given-names>SS</given-names></name></person-group><article-title>An Active Inference Approach to Interoceptive Psychopathology</article-title><source>Annual Review of Clinical Psychology</source><year>2019</year><volume>15</volume><issue>1</issue><fpage>97</fpage><lpage>122</lpage><pub-id pub-id-type="pmcid">PMC7280559</pub-id><pub-id pub-id-type="pmid">31067416</pub-id><pub-id pub-id-type="doi">10.1146/annurev-clinpsy-050718-095617</pub-id></element-citation></ref><ref id="R37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paulus</surname><given-names>MP</given-names></name><name><surname>Stein</surname><given-names>MB</given-names></name></person-group><article-title>An Insular View of Anxiety</article-title><source>Biological Psychiatry</source><year>2006</year><volume>60</volume><issue>4</issue><fpage>383</fpage><lpage>387</lpage><pub-id pub-id-type="pmid">16780813</pub-id></element-citation></ref><ref id="R38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Payne</surname><given-names>RA</given-names></name><name><surname>Symeonides</surname><given-names>CN</given-names></name><name><surname>Webb</surname><given-names>DJ</given-names></name><name><surname>Maxwell</surname><given-names>SRJ</given-names></name></person-group><article-title>Pulse transit time measured from the ECG: An unreliable marker of beat-to-beat blood pressure</article-title><source>Journal of Applied Physiology</source><year>2006</year><volume>100</volume><issue>1</issue><fpage>136</fpage><lpage>141</lpage><pub-id pub-id-type="pmid">16141378</pub-id></element-citation></ref><ref id="R39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pezzulo</surname><given-names>G</given-names></name><name><surname>Rigoli</surname><given-names>F</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><article-title>Active Inference, homeostatic regulation and adaptive behavioural control</article-title><source>Progress in Neurobiology</source><year>2015</year><volume>134</volume><fpage>17</fpage><lpage>35</lpage><pub-id pub-id-type="pmcid">PMC4779150</pub-id><pub-id pub-id-type="pmid">26365173</pub-id><pub-id pub-id-type="doi">10.1016/j.pneurobio.2015.09.001</pub-id></element-citation></ref><ref id="R40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pollatos</surname><given-names>O</given-names></name><name><surname>Georgiou</surname><given-names>E</given-names></name></person-group><article-title>Normal interoceptive accuracy in women with bulimia nervosa</article-title><source>Psychiatry Research</source><year>2016</year><volume>240</volume><fpage>328</fpage><lpage>332</lpage><pub-id pub-id-type="pmid">27138826</pub-id></element-citation></ref><ref id="R41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pollatos</surname><given-names>O</given-names></name><name><surname>Kurz</surname><given-names>A-L</given-names></name><name><surname>Albrecht</surname><given-names>J</given-names></name><name><surname>Schreder</surname><given-names>T</given-names></name><name><surname>Kleemann</surname><given-names>AM</given-names></name><name><surname>Schöpf</surname><given-names>V</given-names></name><name><surname>Kopietz</surname><given-names>R</given-names></name><name><surname>Wiesmann</surname><given-names>M</given-names></name><name><surname>Schandry</surname><given-names>R</given-names></name></person-group><article-title>Reduced perception of bodily signals in anorexia nervosa</article-title><source>Eating Behaviors</source><year>2008</year><volume>9</volume><issue>4</issue><fpage>381</fpage><lpage>388</lpage><pub-id pub-id-type="pmid">18928900</pub-id></element-citation></ref><ref id="R42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quadt</surname><given-names>L</given-names></name><name><surname>Critchley</surname><given-names>HD</given-names></name><name><surname>Garfinkel</surname><given-names>SN</given-names></name></person-group><article-title>The neurobiology of interoception in health and disease</article-title><source>Annals of the New York Academy of Sciences</source><year>2018</year><volume>1428</volume><issue>1</issue><fpage>112</fpage><lpage>128</lpage><pub-id pub-id-type="pmid">29974959</pub-id></element-citation></ref><ref id="R43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quadt</surname><given-names>L</given-names></name><name><surname>Garfinkel</surname><given-names>SN</given-names></name><name><surname>Mulcahy</surname><given-names>JS</given-names></name><name><surname>Larsson</surname><given-names>DE</given-names></name><name><surname>Silva</surname><given-names>M</given-names></name><name><surname>Jones</surname><given-names>A-M</given-names></name><name><surname>Strauss</surname><given-names>C</given-names></name><name><surname>Critchley</surname><given-names>HD</given-names></name></person-group><article-title>Interoceptive training to target anxiety in autistic adults (ADIE): A single-center, superiority randomized controlled trial</article-title><source>EClinicalMedicine</source><year>2021</year><volume>39</volume><elocation-id>101042</elocation-id><pub-id pub-id-type="pmcid">PMC8350004</pub-id><pub-id pub-id-type="pmid">34401684</pub-id><pub-id pub-id-type="doi">10.1016/j.eclinm.2021.101042</pub-id></element-citation></ref><ref id="R44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rigoux</surname><given-names>L</given-names></name><name><surname>Stephan</surname><given-names>KE</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Daunizeau</surname><given-names>J</given-names></name></person-group><article-title>Bayesian model selection for group studies—Revisited</article-title><source>NeuroImage</source><year>2014</year><volume>84</volume><fpage>971</fpage><lpage>985</lpage><pub-id pub-id-type="pmid">24018303</pub-id></element-citation></ref><ref id="R45"><element-citation publication-type="book"><collab>RStudio Team</collab><source>RStudio: Integrated Development Environment for R</source><publisher-name>RStudio, PBC</publisher-name><year>2022</year><comment><ext-link ext-link-type="uri" xlink:href="http://www.rstudio.com/">http://www.rstudio.com/</ext-link></comment></element-citation></ref><ref id="R46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schandry</surname><given-names>R</given-names></name></person-group><article-title>Heart beat perception and emotional experience</article-title><source>Psychophysiology</source><year>1981</year><volume>18</volume><issue>4</issue><fpage>483</fpage><lpage>488</lpage><pub-id pub-id-type="pmid">7267933</pub-id></element-citation></ref><ref id="R47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schielzeth</surname><given-names>H</given-names></name><name><surname>Dingemanse</surname><given-names>NJ</given-names></name><name><surname>Nakagawa</surname><given-names>S</given-names></name><name><surname>Westneat</surname><given-names>DF</given-names></name><name><surname>Allegue</surname><given-names>H</given-names></name><name><surname>Teplitsky</surname><given-names>C</given-names></name><name><surname>Réale</surname><given-names>D</given-names></name><name><surname>Dochtermann</surname><given-names>NA</given-names></name><name><surname>Garamszegi</surname><given-names>LZ</given-names></name><name><surname>Araya-Ajoy</surname><given-names>YG</given-names></name></person-group><article-title>Robustness of linear mixed-effects models to violations of distributional assumptions</article-title><source>Methods in Ecology and Evolution</source><year>2020</year><volume>11</volume><issue>9</issue><fpage>1141</fpage><lpage>1152</lpage><pub-id pub-id-type="doi">10.1111/2041-210X.13434</pub-id></element-citation></ref><ref id="R48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwartenbeck</surname><given-names>P</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><article-title>Computational Phenotyping in Psychiatry: A Worked Example</article-title><source>Eneuro</source><year>2016</year><volume>3</volume><issue>4</issue><elocation-id>ENEURO.0049-16.2016</elocation-id><pub-id pub-id-type="pmcid">PMC4969668</pub-id><pub-id pub-id-type="pmid">27517087</pub-id><pub-id pub-id-type="doi">10.1523/ENEURO.0049-16.2016</pub-id></element-citation></ref><ref id="R49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>R</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Whyte</surname><given-names>C</given-names></name></person-group><article-title>A Step-by-Step Tutorial on Active Inference and its Application to Empirical Data</article-title><source>PsyArXiv</source><year>2021</year><comment>[Preprint]</comment><pub-id pub-id-type="pmcid">PMC8956124</pub-id><pub-id pub-id-type="pmid">35340847</pub-id><pub-id pub-id-type="doi">10.1016/j.jmp.2021.102632</pub-id></element-citation></ref><ref id="R50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>R</given-names></name><name><surname>Killgore</surname><given-names>WDS</given-names></name><name><surname>Lane</surname><given-names>RD</given-names></name></person-group><article-title>The structure of emotional experience and its relation to trait emotional awareness: A theoretical review</article-title><source>Emotion</source><year>2018</year><volume>18</volume><issue>5</issue><fpage>670</fpage><lpage>692</lpage><pub-id pub-id-type="pmid">29172623</pub-id></element-citation></ref><ref id="R51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>R</given-names></name><name><surname>Kuplicki</surname><given-names>R</given-names></name><name><surname>Feinstein</surname><given-names>J</given-names></name><name><surname>Forthman</surname><given-names>KL</given-names></name><name><surname>Stewart</surname><given-names>JL</given-names></name><name><surname>Paulus</surname><given-names>MP</given-names></name><name><surname>Khalsa</surname><given-names>SS</given-names></name><collab>Investigators, T. 1000</collab></person-group><article-title>An active inference model reveals a failure to adapt interoceptive precision estimates across depression, anxiety, eating, and substance use disorders</article-title><source>medRxiv</source><year>2020</year><elocation-id>2020.06.03.20121343</elocation-id><pub-id pub-id-type="pmcid">PMC7769623</pub-id><pub-id pub-id-type="pmid">33315893</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008484</pub-id></element-citation></ref><ref id="R52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>R</given-names></name><name><surname>Kuplicki</surname><given-names>R</given-names></name><name><surname>Feinstein</surname><given-names>J</given-names></name><name><surname>Forthman</surname><given-names>KL</given-names></name><name><surname>Stewart</surname><given-names>JL</given-names></name><name><surname>Paulus</surname><given-names>MP</given-names></name><collab>Tulsa 1000 investigators</collab><name><surname>Khalsa</surname><given-names>SS</given-names></name></person-group><article-title>A Bayesian computational model reveals a failure to adapt interoceptive precision estimates across depression, anxiety, eating, and substance use disorders</article-title><source>PLOS Computational Biology</source><year>2020</year><volume>16</volume><issue>12</issue><elocation-id>e1008484</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008484</pub-id></element-citation></ref><ref id="R53"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>R</given-names></name><name><surname>Kuplicki</surname><given-names>R</given-names></name><name><surname>Teed</surname><given-names>A</given-names></name><name><surname>Upshaw</surname><given-names>V</given-names></name><name><surname>Khalsa</surname><given-names>SS</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Verbelen</surname><given-names>T</given-names></name><name><surname>Lanillos</surname><given-names>P</given-names></name><name><surname>Buckley</surname><given-names>CL</given-names></name><name><surname>De Boom</surname><given-names>C</given-names></name></person-group><chapter-title>Confirmatory Evidence that Healthy Individuals Can Adaptively Adjust Prior Expectations and Interoceptive Precision Estimates</chapter-title><source>Active Inference</source><publisher-name>Springer International Publishing</publisher-name><year>2020</year><fpage>156</fpage><lpage>164</lpage></element-citation></ref><ref id="R54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>R</given-names></name><name><surname>Lane</surname><given-names>RD</given-names></name></person-group><article-title>The neural basis of one’s own conscious and unconscious emotional states</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><year>2015</year><volume>57</volume><fpage>1</fpage><lpage>29</lpage><pub-id pub-id-type="pmid">26363579</pub-id></element-citation></ref><ref id="R55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>R</given-names></name><name><surname>Lane</surname><given-names>RD</given-names></name><name><surname>Parr</surname><given-names>T</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><article-title>Neurocomputational mechanisms underlying emotional awareness: Insights afforded by deep active inference and their potential clinical relevance</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><year>2019</year><volume>107</volume><fpage>473</fpage><lpage>491</lpage><pub-id pub-id-type="pmid">31518636</pub-id></element-citation></ref><ref id="R56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>R</given-names></name><name><surname>Mayeli</surname><given-names>A</given-names></name><name><surname>Taylor</surname><given-names>S</given-names></name><name><surname>Al Zoubi</surname><given-names>O</given-names></name><name><surname>Naegele</surname><given-names>J</given-names></name><name><surname>Khalsa</surname><given-names>SS</given-names></name></person-group><article-title>Gut inference: A computational modelling approach</article-title><source>Biological Psychology</source><year>2021</year><volume>164</volume><elocation-id>108152</elocation-id><pub-id pub-id-type="pmcid">PMC8429276</pub-id><pub-id pub-id-type="pmid">34311031</pub-id><pub-id pub-id-type="doi">10.1016/j.biopsycho.2021.108152</pub-id></element-citation></ref><ref id="R57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>R</given-names></name><name><surname>Parr</surname><given-names>T</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><article-title>Simulating Emotions: An Active Inference Model of Emotional State Inference and Emotion Concept Learning</article-title><source>Frontiers in Psychology</source><year>2019</year><volume>10</volume><pub-id pub-id-type="pmcid">PMC6931387</pub-id><pub-id pub-id-type="pmid">31920873</pub-id><pub-id pub-id-type="doi">10.3389/fpsyg.2019.02844</pub-id></element-citation></ref><ref id="R58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>R</given-names></name><name><surname>Thayer</surname><given-names>JF</given-names></name><name><surname>Khalsa</surname><given-names>SS</given-names></name><name><surname>Lane</surname><given-names>RD</given-names></name></person-group><article-title>The hierarchical basis of neurovisceral integration</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><year>2017</year><volume>75</volume><fpage>274</fpage><lpage>296</lpage><pub-id pub-id-type="pmid">28188890</pub-id></element-citation></ref><ref id="R59"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Spielberger</surname><given-names>CD</given-names></name><name><surname>Gorsuch</surname><given-names>R</given-names></name><name><surname>Lushene</surname><given-names>R</given-names></name><name><surname>Vagg</surname><given-names>P</given-names></name><name><surname>Jacobs</surname><given-names>G</given-names></name></person-group><source>Manual for the state-trait anxiety inventory</source><publisher-name>Consulting Psychologists</publisher-name><publisher-loc>Palo Alto, CA</publisher-loc><year>1983</year></element-citation></ref><ref id="R60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stanislaw</surname><given-names>H</given-names></name><name><surname>Todorov</surname><given-names>N</given-names></name></person-group><article-title>Calculation of signal detection theory measures</article-title><source>Behavior Research Methods, Instruments, &amp; Computers</source><year>1999</year><volume>31</volume><issue>1</issue><fpage>137</fpage><lpage>149</lpage><pub-id pub-id-type="pmid">10495845</pub-id></element-citation></ref><ref id="R61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sugawara</surname><given-names>A</given-names></name><name><surname>Terasawa</surname><given-names>Y</given-names></name><name><surname>Katsunuma</surname><given-names>R</given-names></name><name><surname>Sekiguchi</surname><given-names>A</given-names></name></person-group><article-title>Effects of interoceptive training on decision making, anxiety, and somatic symptoms</article-title><source>BioPsychoSocial Medicine</source><year>2020</year><volume>14</volume><issue>1</issue><fpage>7</fpage><pub-id pub-id-type="pmcid">PMC7079488</pub-id><pub-id pub-id-type="pmid">32206084</pub-id><pub-id pub-id-type="doi">10.1186/s13030-020-00179-7</pub-id></element-citation></ref><ref id="R62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Trevisan</surname><given-names>DA</given-names></name><name><surname>Altschuler</surname><given-names>MR</given-names></name><name><surname>Bagdasarov</surname><given-names>A</given-names></name><name><surname>Carlos</surname><given-names>C</given-names></name><name><surname>Duan</surname><given-names>S</given-names></name><name><surname>Hamo</surname><given-names>E</given-names></name><name><surname>Kala</surname><given-names>S</given-names></name><name><surname>McNair</surname><given-names>ML</given-names></name><name><surname>Parker</surname><given-names>T</given-names></name><name><surname>Stahl</surname><given-names>D</given-names></name><name><surname>Winkelman</surname><given-names>T</given-names></name><etal/></person-group><article-title>A meta-analysis on the relationship between interoceptive awareness and alexithymia: Distinguishing interoceptive accuracy and sensibility</article-title><source>Journal of Abnormal Psychology</source><year>2019</year><volume>128</volume><issue>8</issue><fpage>765</fpage><lpage>776</lpage><pub-id pub-id-type="pmid">31380655</pub-id></element-citation></ref><ref id="R63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whitehead</surname><given-names>WE</given-names></name><name><surname>Drescher</surname><given-names>VM</given-names></name><name><surname>Heiman</surname><given-names>P</given-names></name><name><surname>Blackwell</surname><given-names>B</given-names></name></person-group><article-title>Relation of heart rate control to heartbeat perception</article-title><source>Biofeedback and Self-Regulation</source><year>1977</year><volume>2</volume><issue>4</issue><fpage>371</fpage><lpage>392</lpage><pub-id pub-id-type="pmid">612350</pub-id></element-citation></ref><ref id="R64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiens</surname><given-names>S</given-names></name><name><surname>Mezzacappa</surname><given-names>ES</given-names></name><name><surname>Katkin</surname><given-names>ES</given-names></name></person-group><article-title>Heartbeat detection and the experience of emotions</article-title><source>Cognition &amp; Emotion</source><year>2000</year><volume>14</volume><issue>3</issue><fpage>417</fpage><lpage>427</lpage><pub-id pub-id-type="doi">10.1080/026999300378905</pub-id></element-citation></ref><ref id="R65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yoris</surname><given-names>A</given-names></name><name><surname>Abrevaya</surname><given-names>S</given-names></name><name><surname>Esteves</surname><given-names>S</given-names></name><name><surname>Salamone</surname><given-names>P</given-names></name><name><surname>Lori</surname><given-names>N</given-names></name><name><surname>Martorell</surname><given-names>M</given-names></name><name><surname>Legaz</surname><given-names>A</given-names></name><name><surname>Alifano</surname><given-names>F</given-names></name><name><surname>Petroni</surname><given-names>A</given-names></name><name><surname>Sánchez</surname><given-names>R</given-names></name><name><surname>Sedeño</surname><given-names>L</given-names></name><etal/></person-group><article-title>Multilevel convergence of interoceptive impairments in hypertension: New evidence of disrupted body–brain interactions</article-title><source>Human Brain Mapping</source><year>2018</year><volume>39</volume><issue>4</issue><fpage>1563</fpage><lpage>1581</lpage><pub-id pub-id-type="pmcid">PMC6866355</pub-id><pub-id pub-id-type="pmid">29271093</pub-id><pub-id pub-id-type="doi">10.1002/hbm.23933</pub-id></element-citation></ref><ref id="R66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zamariola</surname><given-names>G</given-names></name><name><surname>Frost</surname><given-names>N</given-names></name><name><surname>Van Oost</surname><given-names>A</given-names></name><name><surname>Corneille</surname><given-names>O</given-names></name><name><surname>Luminet</surname><given-names>O</given-names></name></person-group><article-title>Relationship between interoception and emotion regulation: New evidence from mixed methods</article-title><source>Journal of Affective Disorders</source><year>2019</year><volume>246</volume><fpage>480</fpage><lpage>485</lpage><pub-id pub-id-type="pmid">30599372</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><p>Illustration of procedure for interoceptive training and (passive) control groups. MAIA: Multidimensional Assessment of Interoceptive Awareness.</p></caption><graphic xlink:href="EMS199077-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><p>Bayesian approach used to model cardiac perception on the heartbeat discrimination task, assuming two hierarchical levels of inference. The generative model is here depicted graphically, such that arrows indicate dependencies between variables. Associated vectors/matrices are also shown. This hidden Markov model was adapted from the commonly used active inference formulation of partially observable Markov decision processes (<xref ref-type="bibr" rid="R11">Da Costa et al., 2020</xref>; Smith, Friston, et al., 2021). Each trial in the heartbeat discrimination task corresponded to a trial in the model, and was divided into three timepoints (<italic>τ</italic>): <italic>τ</italic> = 1 was a placeholder ‘start’ timepoint, while at <italic>τ</italic> = 2 participants listened to the auditory tones and gave responses ‘in sync’ or ‘out of sync’. At <italic>τ</italic> = 3, participants were informed whether their response was correct or incorrect. In a hierarchical model, observations at each timepoint (<italic>o<sub>τ</sub></italic>) depend on lower-level hidden states <inline-formula><mml:math id="M4"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mi>τ</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which in turn depend on higher-level hidden states <inline-formula><mml:math id="M5"><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mi>τ</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> these relationships are specified in the <bold>A</bold><sub><bold>1</bold></sub> and <bold>A</bold><sub><bold>2</bold>,<bold><italic>τ</italic></bold></sub> matrices, respectively. The initial higher-level hidden state depends on the probabilities specified in the vector <bold>D</bold>, while successive hidden states depend on the transition probabilities <inline-formula><mml:math id="M6"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup><mml:mo>∣</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mi>τ</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> specified in the (identity) matrix <bold>B</bold>. In this model, observations corresponded to the (ground-truth) cardiac-auditory sensory signals received during a trial of the heartbeat discrimination task, which could be either synchronous or asynchronous. The higher-level hidden states corresponded to participants’ beliefs (i.e., posterior probability distributions) about whether the cardiac-auditory sensory signals were synchronous or asynchronous, and participants’ responses were assumed to be sampled from these beliefs. On each trial, the participant begins at time <italic>τ</italic> = 1 and receives a placeholder ‘start’ observation (<italic>o</italic><sub><italic>τ</italic>=1</sub>) regardless of the hidden state (asynchronous or synchronous trial condition), and then updates their probabilistic beliefs about hidden states (<italic>Q</italic>(<italic>s</italic><sub><italic>τ</italic></sub>)) based on observations received at timepoint 2 (<italic>o</italic><sub><italic>τ</italic>=2</sub>) and timepoint 3 (<italic>o</italic><sub><italic>τ</italic>=3</sub>). Belief updating was assumed to rely on Bayesian inference, as implemented in the “Heartbeat-tone perception” equation (see <xref ref-type="table" rid="T1">Table 1</xref>). Learning (evidence accumulation and possible forgetting) was hypothesised to occur in the <bold>A<sub>2,<italic>τ</italic></sub></bold> matrix and was controlled by the learning equation (also see <xref ref-type="table" rid="T1">Table 1</xref>). [Note that non-hierarchical models were also considered, in which matrix <bold>A</bold><sub><bold>1</bold></sub> and the lower-level hidden state <inline-formula><mml:math id="M7"><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mi>τ</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> were not present. In these non-hierarchical models, observations <italic>o</italic><sub><italic>t</italic></sub> depend directly on hidden states <inline-formula><mml:math id="M8"><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mi>τ</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>, with this relationship specified in matrix <bold>A<sub>2,<italic>τ</italic></sub></bold>.]</p></caption><graphic xlink:href="EMS199077-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><p>(Top) Pearson correlations between parameter estimates (<italic>IP</italic><sub>1</sub>, <italic>IP</italic><sub>2</sub>, <italic>pS</italic>) in the training group and confusion matrix indices derived from heartbeat discrimination task responses throughout the eight training sessions, showing largely expected relationships. Greater <italic>IP</italic><sub>1</sub> estimates were positively associated with true positive and true negative responses, and negatively associated with false positive and false negative responses. Parameter estimates for <italic>IP</italic><sub>2</sub> unsurprisingly showed weak associations with other measures, since this parameter determines only the starting conditions of the model prior to learning. Note that the few participants shown with starting values for <italic>IP</italic><sub>2</sub> in the .3 - .6 range would be expected to start with largely random (or even somewhat anti-correlated) responses relative to ground truth, but could still improve over time with learning. Greater <italic>pS</italic> estimates (i.e., more bias towards responding ‘in sync’) were associated with more false positives and fewer true negatives (as expected), but interestingly were only weakly associated with true positives and false negatives, suggesting that poorer performance on the task was partly driven by over-endorsement of ‘in sync’ responses. (Bottom) Pairwise Pearson correlations within the parameter estimates and the derived change in interoceptive precision weighting (Δ<italic>IP</italic><sub>2</sub>), along with associated scatterplots and histograms for each variable. Significance indicators are not shown, as these were descriptive analyses to inform parameter face validity, rather than hypothesis tests.</p></caption><graphic xlink:href="EMS199077-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><p>(Top) Pearson correlations (Corr) between parameter estimates in the control group and confusion matrix indices derived from heartbeat discrimination task responses across three assessment sessions. Note that both <italic>IP</italic><sub>2</sub> and <italic>pS</italic> showed qualitatively different patterns of association with behaviour in the control group compared to the training group, likely reflecting the difference in experimental procedure for the data used to estimate parameter values (i.e., no feedback on each trial and fewer trials overall in the control group). (Bottom) Pearson correlations within parameter estimates and the derived change in interoceptive precision weighting in the control group, along with associated scatterplots and histograms for each parameter. Significances of these descriptive patterns were not tested, as these did not reflect hypothesis tests.</p></caption><graphic xlink:href="EMS199077-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><p>Effect plot with partial residuals for significant association between mean heartrate across heartbeat discrimination trials and estimates of the afferent signal precision (<italic>IP</italic><sub>1</sub>) across both groups. The solid line visualises the partial slope for the predictor (i.e., when all other fixed effects are held constant), as estimated using multiple regression. Grey circles represent partial residuals (i.e., the dependent variable adjusted for all other fixed effects), while the dashed grey line visualises the loess smooth of partial residuals. Effect plots were generated using the <italic>Effects</italic> R package (<xref ref-type="bibr" rid="R18">Fox &amp; Weisberg, 2018</xref>).</p></caption><graphic xlink:href="EMS199077-f005"/></fig><fig id="F6" position="float"><label>Figure 6</label><caption><p>Raincloud plots showing heartbeat tracking accuracy (top) and heartbeat discrimination sensitivity (<italic>d’</italic>; bottom) scores for the training and control groups across baseline, mid-point and final assessment sessions. Lines across plots connect the group means at each timepoint. Outliers are indicated by diamonds above and below box and whisker plots. All raincloud plots were produced using the PtitPrince Python package (<xref ref-type="bibr" rid="R4">Allen et al., 2021</xref>).</p></caption><graphic xlink:href="EMS199077-f006"/></fig><fig id="F7" position="float"><label>Figure 7</label><caption><p>Raincloud plots showing <italic>IP</italic><sub>1</sub> (top), <italic>IP</italic><sub>2</sub> (middle) and <italic>pS</italic> (bottom) estimates for the training and control groups across baseline, mid-point, and final sessions.</p></caption><graphic xlink:href="EMS199077-f007"/></fig><fig id="F8" position="float"><label>Figure 8</label><caption><p>(Top) State anxiety showed a non-significant decrease in the training group and a non-significant increase in the control group, resulting in a significant interaction effect. (Bottom) Trait anxiety significantly decreased in the training group, but not in the control group. Note that these anxiety assessments were not gathered at the mid-point visit.</p></caption><graphic xlink:href="EMS199077-f008"/></fig><fig id="F9" position="float"><label>Figure 9</label><caption><p>Effect plots with partial residuals for significant associations between computational parameter estimates and change in anxiety in the interoceptive training group, as estimated by linear mixed effects models. (Top) Lower values of <italic>pS</italic>, representing less biased perceptual priors towards ‘in sync’ percepts, predicted greater state anxiety reduction. (Middle) Lower values of <italic>IP</italic><sub>1</sub>, representing noisier interoceptive signals (and less effective learning) predicted greater trait anxiety reductions. (Bottom) Greater increases in interoceptive precision weighting during training (Δ<italic>IP</italic><sub>2</sub>) predicted greater trait anxiety reduction. The vertical dashed line indicates Δ<italic>IP</italic><sub>2</sub> = 0 (−1.05 on the log-transformed axis), with increased interoceptive precision weighting on the right and decreased interoceptive precision weighting on the left.</p></caption><graphic xlink:href="EMS199077-f009"/></fig><fig id="F10" position="float"><label>Figure 10</label><caption><p>Scatterplots showing the association in the training group between estimates of <italic>pS</italic> and change in self-reported MAIA Trusting (left) and Noticing (right) subscales from baseline to final timepoints. MAIA = Multidimensional Assessment of Interoceptive Awareness.</p></caption><graphic xlink:href="EMS199077-f010"/></fig><table-wrap id="T1" orientation="portrait" position="float"><label>Table 1</label><caption><title>Description of computational model elements and processes.</title></caption><table frame="box" rules="cols"><thead><tr style="border-bottom: solid thin"><th valign="middle" align="left">Model element and definition</th><th valign="top" align="left">Model-specific description</th></tr></thead><tbody><tr><td valign="top" align="left">        <bold><italic>t</italic> and <italic>τ</italic></bold><break/><break/><bold>Timepoint within a trial</bold></td><td valign="top" align="left">There were three timepoints in each trial in the model, which corresponded to trials in the heartbeat discrimination task.<break/><break/>In hierarchical models, for each timepoint of a higher-level trial (denoted by <sup>{2}</sup>), there was a lower-level ‘trial’ (denoted by <sup>{1}</sup>) with one timepoint.<break/><break/>At <italic>t</italic> = 1, the participant was modelled as waiting to infer the synchronicity of heartbeats and tones in a placeholder “start” state. At <italic>t</italic> = 2, either an asynchronous (Async) or synchronous (Sync) tone-heartbeat observation was presented (depending on the ground-truth task condition on that trial), and participants inferred the posterior probability of heartbeats and tones being synchronous. This posterior probability determined whether the participant responded ‘in sync’ or ‘out of sync’ via the response model (see below). At <italic>t</italic> = 3, the participant was modelled as receiving feedback on whether their response was correct at <italic>t</italic> = 2. Formally, this was implemented by again providing the associated Async or Sync observation, but this time passed through a perfectly precise likelihood <bold>A<sub>2</sub></bold> matrix (see below).<break/><break/>The active inference literature distinguishes the timepoints (<italic>t</italic>) <italic>at</italic> which new observations are presented from the timepoints (<italic>τ</italic>) <italic>about</italic> which one holds beliefs. This distinction is important in the model presented here because the agent can receive feedback observations at <italic>t</italic> = 3 and use them to retrospectively update beliefs about whether the state was asynchronous or synchronous at <italic>τ</italic> = 2. This in turn allows the agent to improve their mapping from observations to states at <italic>τ</italic> = <italic>t</italic> = 2 on the next trial.</td></tr><tr style="border-top: solid thin"><td valign="top" align="left">        <bold><italic>o</italic><sub><italic>τ</italic></sub></bold><break/><break/><bold>Observations at time <italic>τ</italic></bold></td><td valign="top" align="left">Observations were categorical and included: <list list-type="simple" id="L1"><list-item><label>1</label><p>Start (placeholder)</p></list-item><list-item><label>2</label><p>Asynchronous</p></list-item><list-item><label>3</label><p>Synchronous</p></list-item></list> These observations corresponded to the ground truth cardiac-auditory stimuli on each trial.</td></tr><tr style="border-top: solid thin"><td valign="top" align="left">        <inline-formula><mml:math id="M9"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mi mathvariant="bold-italic">τ</mml:mi><mml:mrow><mml:mo mathvariant="bold">{</mml:mo><mml:mn mathvariant="bold">1</mml:mn><mml:mo mathvariant="bold">}</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M10"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mi mathvariant="bold-italic">τ</mml:mi><mml:mrow><mml:mo mathvariant="bold">{</mml:mo><mml:mn mathvariant="bold">2</mml:mn><mml:mo mathvariant="bold">}</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula><break/><break/><bold>Hidden states at time <italic>τ</italic></bold></td><td valign="top" align="left">Higher-level hidden states <inline-formula><mml:math id="M11"><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mi>τ</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> were categorical and corresponded to the participant’s perception of the cardiac-auditory condition on each trial: <list list-type="simple" id="L2"><list-item><label>1</label><p>Asynchronous</p></list-item><list-item><label>2</label><p>Synchronous</p></list-item></list> Lower-level hidden states were implicit representations with varying degrees of noise, corresponding to the observations: <list list-type="simple" id="L3"><list-item><label>1</label><p>Start (placeholder)</p></list-item><list-item><label>2</label><p>Asynchronous</p></list-item><list-item><label>3</label><p>Synchronous</p></list-item></list> In non-hierarchical models, lower-level hidden states were not included (and these states are replaced with analogous [ground truth] observations).</td></tr><tr style="border-top: solid thin"><td valign="top" align="left">        <bold>A<sub>2,</sub><sub><italic>τ</italic></sub> matrix</bold><break/><break/>        <bold><inline-formula><mml:math id="M12"><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mi mathvariant="bold-italic">τ</mml:mi><mml:mrow><mml:mo mathvariant="bold">{</mml:mo><mml:mn mathvariant="bold">1</mml:mn><mml:mo mathvariant="bold">}</mml:mo></mml:mrow></mml:msubsup><mml:mo mathvariant="bold">∣</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mi mathvariant="bold-italic">τ</mml:mi><mml:mrow><mml:mo mathvariant="bold">{</mml:mo><mml:mn mathvariant="bold">2</mml:mn><mml:mo mathvariant="bold">}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></bold><break/><break/><bold>A matrix encoding beliefs about the probabilistic relationship between hidden states at level 1 and 2 (i.e., the probability of making specific 1<sup>st</sup>-level states given specific 2<sup>nd</sup>-level states).</bold></td><td valign="top" align="left">In hierarchical models, this encodes the likelihood of each lower-level state <inline-formula><mml:math id="M13"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mi>τ</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> given each higher-level state <inline-formula><mml:math id="M14"><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mi>τ</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>. Columns indicate (from left to right) the asynchronous state and the synchronous higher-level state, and rows (from top to bottom) indicate the ‘start’, asynchronous, and synchronous lower-level states.<break/><break/>In non-hierarchical models, <bold>A</bold><sub><bold>2,<italic>τ</italic></bold></sub> instead encodes beliefs about the mapping between hidden states and (ground-truth) observations, <italic>P</italic>(<italic>o<sub>τ</sub></italic>|<italic>s<sub>τ</sub></italic>).<break/><break/>Importantly, matrix <bold>A</bold><sub><bold>2,<italic>τ</italic></bold></sub> contained different values, or mappings between states and observations, dependent on the timepoint within a trial.<break/><break/>At <italic>τ</italic> = 1, the participant always makes a placeholder ‘start’ observation (top row), regardless of hidden state.<break/><break/>At <italic>τ</italic> = 2, when participants listen to the tones and make their perceptual judgement, the probability of making an observation that matches the hidden state (i.e., perceiving correctly) is encoded by an ‘interoceptive precision’ parameter (<italic>IP</italic><sub>2</sub>).<break/><break/>At <italic>τ</italic> = 3 (i.e., when participants are told whether their response was correct or incorrect), the probability of making the observation that matched the true state was fixed to 1. In other words, the model assumes that, at the feedback stage, participants updated their beliefs based on a perfectly precise mapping between observations and hidden states.<break/><break/>Note that when fitting the model on participant responses from the three assessment sessions, in which no feedback was given, participants instead make uninformative ‘start’ observations at <italic>τ</italic> = 3: <disp-formula id="FD1"><mml:math id="M15"><mml:mrow><mml:msub><mml:mtext mathvariant="bold">A</mml:mtext><mml:mrow><mml:mn mathvariant="bold">2</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">τ</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="bold">3</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> In practice, conditioning this matrix on the timepoint within a trial involved introducing a second hidden state factor for time, with three time-in-trial states corresponding to <italic>τ</italic> = 1, 2, and 3, which selected for one of the possible <bold>A</bold><sub><bold>2,<italic>τ</italic></bold></sub> matrices (stored as slices of a 3 dimensional-tensor). This encoded the contingencies described above. This hidden state factor for time-in-trial served a purely pragmatic purpose for implementation and is not discussed elsewhere for brevity.</td></tr><tr style="border-top: solid thin"><td valign="top" align="left"><bold>Learning in the A</bold><sub><bold>2,<italic>τ</italic></bold></sub> <bold>matrix</bold></td><td valign="top" align="left">To account for improvements in cardiac perception due to the interoceptive training procedure, we considered models with learning. Specifically, we assumed that learning was implemented as trial-by-trial updating of <bold>A</bold><sub><bold>2</bold>,<italic>τ</italic>=2</sub> (i.e., the precision of the higher-level likelihood when participants gave their perceptual judgement response on each trial). Formally, this corresponds to updating the concentration parameters of Dirichlet (<italic>Dir</italic>) priors associated with the <bold>A</bold><sub><bold>2</bold></sub> matrix (<bold>a</bold><sub><bold>2</bold></sub>). At trial 1: <disp-formula id="FD2"><mml:math id="M16"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>a</mml:mi></mml:mstyle><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mn>1</mml:mn></mml:mstyle></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>a</mml:mi></mml:mstyle><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mn>1</mml:mn></mml:mstyle></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>I</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>I</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>I</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>I</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>a</mml:mi></mml:mstyle><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mn>1</mml:mn></mml:mstyle></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mi>τ</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup><mml:mo>∣</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mi>τ</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mi mathvariant="bold-italic">o</mml:mi><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mi mathvariant="bold-italic">m</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>a</mml:mi></mml:mstyle><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula> In subsequent trials, <disp-formula id="FD3"><mml:math id="M17"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>a</mml:mi></mml:mstyle><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>a</mml:mi></mml:mstyle><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>η</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mstyle displaystyle="true"><mml:mi>∑</mml:mi></mml:mstyle><mml:mi>τ</mml:mi></mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⊗</mml:mo><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> This learning equation entails that the probability of an asynchronous observation given an asynchronous state should increase if the participant makes an asynchronous observation while believing that they were in an asynchronous state (and so forth for each combination of observations and state beliefs). Here, ⨂ indicates the cross-product, and <italic>η</italic> – an ‘evidence accumulation rate’ parameter – is a scalar that controls how quickly the concentration parameters increase in value after each trial. In non-hierarchical versions of the model, <inline-formula><mml:math id="M18"><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is replaced by <italic>o</italic><sub><italic>τ</italic>=2</sub> in the learning equation above.<break/><break/>In practice, the learning equation also updates concentration parameters in <bold>a</bold><sub><bold>2,<italic>τ</italic>=1</bold></sub> and <bold>a</bold><sub><bold>2,<italic>τ</italic>=3</bold></sub>. In this case, both were multiplied by a large scalar (1000) to prevent meaningful changes in the specified mapping to the ‘start’ observation at <italic>τ</italic> = 1 and feedback observations at <italic>τ</italic> = 3 (or ‘start’ at <italic>τ</italic> = 3 when fitting assessment session data).</td></tr><tr style="border-top: solid thin"><td valign="top" align="left">        <bold>A</bold><sub><bold>1</bold></sub> <bold>matrix</bold><break/><break/>        <bold><inline-formula><mml:math id="M19"><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">o</mml:mi><mml:mi mathvariant="bold-italic">τ</mml:mi></mml:msub><mml:mo mathvariant="bold">∣</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mi mathvariant="bold-italic">τ</mml:mi><mml:mrow><mml:mo mathvariant="bold">{</mml:mo><mml:mn mathvariant="bold">1</mml:mn><mml:mo mathvariant="bold">}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></bold><break/><break/><bold>A matrix encoding the relationship between observable outcomes and hidden states at a lower hierarchical level, if present.</bold></td><td valign="top" align="left">In hierarchical model variants, the <bold>A</bold><sub><bold>1</bold></sub> matrix encodes the likelihood of making each observation (<italic>o</italic><sub><italic>τ</italic></sub>) given the presence of each lower-level hidden state <inline-formula><mml:math id="M20"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mi>τ</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Lower-level hidden states resultingly incorporate varying degrees of noise when acting as observations for the higher level, controlled by the parameter <italic>IP</italic><sub>1</sub>.<break/><break/>Matrix columns indicate (from left to right) the hidden states ‘start’, asynchronous, and synchronous, while rows (from top to bottom) indicate the lower-level observations ‘start’, asynchronous, and synchronous.<break/><break/>No learning was modelled for state-outcome mappings in <bold>A</bold><sub><bold>1</bold></sub> in any model variant, as this was meant to capture a stable amount of noise (<italic>IP</italic><sub>1</sub>) in the true signal. In practice, this was implemented within the Dirichlet priors associated with the <bold>A</bold><sub><bold>1</bold></sub> matrix, <bold>a</bold><sub><bold>1</bold></sub>, which was multiplied with an arbitrarily large scalar (1000) to prevent meaningful updating by the learning equations (described above). <disp-formula id="FD4"><mml:math id="M21"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>a</mml:mi></mml:mstyle><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mn>1</mml:mn></mml:mstyle></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1000</mml:mn><mml:mo>⋅</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mi>I</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>I</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>I</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>I</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> <disp-formula id="FD5"><mml:math id="M22"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext mathvariant="bold-italic">norm</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>a</mml:mi></mml:mstyle><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> Resultingly, the <bold>A</bold><sub><bold>1</bold></sub> matrix effectively remained constant across trials.<break/><break/>Crucially, as greater values for <italic>IP</italic><sub>1</sub> lead to more precise posterior beliefs over first-level states, which are in turn used for learning at the second level, this has the indirect effect of moderating the rate with which each new observation can update beliefs about <italic>IP</italic><sub>2</sub> (i.e., higher <italic>IP</italic><sub>1</sub> leads to more effective learning).</td></tr><tr style="border-top: solid thin"><td valign="top" align="left">        <bold>B matrix</bold><break/><break/><bold><inline-formula><mml:math id="M23"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup><mml:mo>∣</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mi>τ</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></bold><break/><break/><bold>A matrix encoding beliefs about how hidden states will evolve over time (i.e., the probability that each state at time <italic>τ</italic> would transition into any other state at time <italic>τ</italic> + 1).</bold></td><td valign="top" align="left">Columns indicate (from left to right) the asynchronous state and the synchronous state at time <italic>τ</italic>, and rows (from top to bottom) indicating the asynchronous state and the synchronous state at the subsequent time <italic>τ</italic> + 1.<break/><break/>As trial condition (Async/Sync) is a stable attribute of each trial of the heartbeat discrimination task, this <bold>B</bold> matrix simply encodes identity mappings for the Async and Sync states over time in trial (i.e., a single trial cannot switch between being a Sync to Async trial).<break/><break/>When feedback is provided at <italic>t</italic> = 3, this identify mapping also allows retrospective inference in which posterior beliefs become precise (and accurate) about the state at <italic>τ</italic> = 2, which in turn allows for learning.</td></tr><tr style="border-top: solid thin"><td valign="top" align="left">        <bold>D vector</bold><break/><break/>        <bold><inline-formula><mml:math id="M24"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></bold><break/><break/><bold>A vector encoding prior beliefs about initial hidden states.</bold></td><td valign="top" align="left">Encodes the prior probability that any given trial will be in the synchronous task condition, as controlled by a parameter <italic>pS</italic>.</td></tr><tr style="border-top: solid thin"><td valign="top" align="left">        <bold>Heartbeat-tone perception: Bayesian inference over hidden states</bold></td><td valign="top" align="left">After making each observation, participants update posterior probability distributions over lower-level and higher-level hidden states <inline-formula><mml:math id="M25"><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mi>τ</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M26"><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mi>τ</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, for all timepoints <italic>τ</italic>.<break/><break/>In hierarchical models, the participant is assumed to perform (approximate) Bayesian inference over lower-level states through the following equation: <disp-formula id="FD6"><mml:math id="M27"><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.2em"/><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>D</mml:mi></mml:mstyle><mml:mtext mathvariant="bold">1</mml:mtext></mml:msub><mml:mo>+</mml:mo><mml:mi>l</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.2em"/><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:mn mathvariant="bold">1</mml:mn><mml:mtext>T</mml:mtext></mml:msubsup><mml:msub><mml:mi>o</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="bold">1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> The posterior distribution <inline-formula><mml:math id="M28"><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> here assigns a probability to the presence of the ‘start’, asynchronous, and synchronous lower-level states, and is informed by the associated observation (<italic>o</italic><sub><italic>τ</italic>=1</sub>), the likelihood encoded in <bold>A</bold><sub><bold>1</bold></sub>, and flat priors [1/3 1/3 1/3]<sup>T</sup> encoded in <bold>D</bold><sub><bold>1</bold></sub>. Note that <italic>σ</italic> (·) refers to a softmax (normalized exponential) function that converts vector values into proper probability distributions that sum to 1. In algorithmic terms, the participant is assumed to optimise an approximate posterior over states using variational message passing (for further mathematical detail, see <xref ref-type="bibr" rid="R49">Smith, Friston, et al., 2021</xref>).<break/><break/>At each timepoint of the higher-level trial, the participant is assumed to perform (approximate) Bayesian inference over higher-level states through the following equations: <disp-formula id="FD7"><mml:math id="M29"><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.2em"/><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>D</mml:mi></mml:mstyle><mml:mo>+</mml:mo><mml:mi>l</mml:mi><mml:mi>n</mml:mi><mml:mtext> </mml:mtext><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:mrow><mml:mn mathvariant="bold">2</mml:mn><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mtext>T</mml:mtext></mml:msubsup><mml:mspace width="0.2em"/><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> <disp-formula id="FD8"><mml:math id="M30"><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.2em"/><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>B</mml:mi></mml:mstyle><mml:mspace width="0.2em"/><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>l</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.2em"/><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:mrow><mml:mn mathvariant="bold">2</mml:mn><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mtext>T</mml:mtext></mml:msubsup><mml:mspace width="0.2em"/><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> <disp-formula id="FD9"><mml:math id="M31"><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.2em"/><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>B</mml:mi></mml:mstyle><mml:mspace width="0.2em"/><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>l</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.2em"/><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:mrow><mml:mn mathvariant="bold">2</mml:mn><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mtext>T</mml:mtext></mml:msubsup><mml:mspace width="0.2em"/><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> Here, prior beliefs (ln <bold>D</bold> or ln <inline-formula><mml:math id="M32"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>B</mml:mi></mml:mstyle><mml:mspace width="0.2em"/><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are integrated with the likelihood distribution encoded in the matrix <bold>A</bold><sub><bold>2,<italic>τ</italic></bold></sub> and the lower-level posterior over hidden states <inline-formula><mml:math id="M33"><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mi>τ</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, and then converted into a proper probability distribution via a softmax (as above). In non-hierarchical models, the ground-truth observation <italic>o</italic><sub><italic>τ</italic></sub> replaces <inline-formula><mml:math id="M34"><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mi>τ</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in the equations for inference at the higher level.<break/><break/>While the participant does always make a ‘start’ observation at <italic>τ</italic> = 1, this observation is equally likely in the asynchronous or synchronous hidden states at this time (as specified in the matrix <bold>A</bold><sub><bold>2</bold>,<italic>τ</italic>=1</sub>), and so does not inform posterior beliefs about the hidden state. This ‘start’ state was included for implementation reasons only and has no theoretical significance.<break/><break/>Prior beliefs at <italic>τ</italic> = 1 (P(<italic>s</italic><sub><italic>τ</italic>=1</sub>)) are encoded in the vector <bold>D</bold>. At time <italic>τ</italic> = 2 and <italic>τ</italic> = 3, the posterior belief from the preceding time (<italic>s</italic><sub><italic>t</italic>−1</sub>) is transformed by the matrix <bold>B</bold> (ln <bold>B</bold> <italic>s</italic><sub><italic>t</italic>−1</sub>); however, in this case the posterior is unchanged, as the <bold>B</bold> matrix is an identity matrix, reflecting the fact that the asynchronous/synchronous hidden state does not change within a trial.</td></tr><tr style="border-top: solid thin"><td valign="top" align="left">        <bold>Response model</bold><break/><break/><bold>A function that simulates participant responses by sampling from their posterior beliefs over states</bold></td><td valign="top" align="left">Our response model formally included two actions: responding ‘out of sync’ or responding ‘in sync’. This model assumed that the probability of choosing either action corresponded to the posterior probability assigned to the asynchronous vs. synchronous states at time <italic>τ</italic> = 2 in each trial. <disp-formula id="FD10"><mml:math id="M35"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.2em"/><mml:mo>=</mml:mo><mml:mspace width="0.2em"/><mml:mo>′</mml:mo><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.2em"/><mml:mi>s</mml:mi><mml:mi>y</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mo>′</mml:mo><mml:mspace width="0.2em"/><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mspace width="0.2em"/><mml:mi>s</mml:mi><mml:mi>y</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mspace width="0.2em"/></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> <disp-formula id="FD11"><mml:math id="M36"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.2em"/><mml:mo>=</mml:mo><mml:mspace width="0.2em"/><mml:mo>′</mml:mo><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mspace width="0.2em"/><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.2em"/><mml:mi>s</mml:mi><mml:mi>y</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mo>′</mml:mo><mml:mspace width="0.2em"/><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mspace width="0.2em"/><mml:mi>A</mml:mi><mml:mi>s</mml:mi><mml:mi>y</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mspace width="0.2em"/></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> In other words, a greater posterior probability of a synchronous state at time <italic>τ</italic> = <italic>t</italic> = 2 corresponded to a higher probability of responding ‘in sync’, and a higher posterior probability of the asynchronous state corresponded to a higher probability of responding ‘out of sync’.<break/><break/>This response model was used to fit model parameters to participant data and to simulate participant responses in synthetic datasets for model recoverability and identifiability tests (see text).</td></tr></tbody></table></table-wrap><table-wrap id="T2" orientation="portrait" position="float"><label>Table 2</label><caption><title>Description of computational model parameters estimated for each participant.</title></caption><table frame="box" rules="cols"><thead><tr style="border-bottom: solid thin"><th valign="top" align="center">Model parameter</th><th valign="top" align="left">Model-specific description</th></tr></thead><tbody><tr><td valign="top" align="left">        <bold><italic>IP</italic><sub>1</sub></bold><break/><break/><bold>Lower-level signal precision</bold></td><td valign="top" align="left">Only present in hierarchical models. <italic>IP</italic><sub>1</sub> controls the degree of noise or precision in the ground-truth observations that participants use to make their perceptual judgements. A value of <italic>IP<sub>1</sub></italic> approaching 1 indicates maximally precise observations, while a value of .5 indicates minimally precise (maximally noisy) observations.<break/><break/>Technically, <italic>IP</italic><sub>1</sub> controls the precision of the lower-level matrix <bold>A</bold><sub><bold>1</bold></sub>, and hence the precision of lower-level posteriors over hidden states, which in turn act as the higher-level observations in the heartbeat-tone perception equations. Resultingly, <italic>IP</italic><sub>1</sub> influences the posteriors over higher-level states <inline-formula><mml:math id="M37"><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, in a manner that interacts with higher-level state priors. Greater values of <italic>IP</italic><sub>1</sub> should lead to a more precise <inline-formula><mml:math id="M38"><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, favouring the state corresponding to the true observation, and thus increasing the probability of responding correctly. Lower values for <italic>IP</italic><sub>1</sub> conversely reduce the probability of responding correctly.<break/><break/>Moreover, lower <italic>IP<sub>1</sub></italic> values slow learning within matrix <bold>A</bold><sub><bold>2</bold></sub> by limiting the precision of updates to the associated Dirichlet distribution <italic>Dir</italic>(<bold>a</bold><sub>2</sub>), while greater <italic>IP</italic><sub>1</sub> enhances learning by increasing the precision of these updates.</td></tr><tr style="border-top: solid thin"><td valign="top" align="left">        <bold><italic>IP</italic></bold><sub><bold>2</bold></sub> <bold>and Δ</bold><italic><bold>IP</bold></italic><sub><bold>2</bold></sub><break/><break/><bold>Interoceptive precision weighting and its change after learning</bold></td><td valign="top" align="left">On trial 1, prior to learning, <italic>IP</italic><sub>2</sub> specifies how much evidence a lower-level hidden state (or in non-hierarchical models, an observation) of ‘asynchronous’ or ‘synchronous’ provides for the corresponding higher-level hidden state.<break/><break/>A value of <italic>IP</italic><sub>2</sub> approaching 1 indicates high precision, or reliability of this mapping, such that the probability of an asynchronous observation is high when in the asynchronous state and low when in the synchronous state (and vice-versa for synchronous observations). In contrast, a value of .5 for <italic>IP</italic><sub>2</sub> indicates minimal precision, such that the probabilities of making an asynchronous observation or synchronous observation are both .5 when in either hidden state.<break/><break/>Technically, <italic>IP</italic><sub>2</sub> controls the precision of matrix <bold>A</bold><sub><bold>2</bold>,<italic>τ</italic>=2</sub>, which transforms <inline-formula><mml:math id="M39"><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (or <italic>o</italic><sub><italic>τ</italic></sub><sub>=2</sub> in non-hierarchical models) in the heartbeat-tone perception equations. Thus, <italic>IP</italic><sub>2</sub> also influences the precision of higher-level posteriors over states <inline-formula><mml:math id="M40"><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, with greater <italic>IP</italic><sub>2</sub> values increasing the probability of responding correctly and lower values reducing this probability. Unlike <italic>IP</italic><sub>1</sub>, we assume training may improve <italic>IP</italic><sub>2</sub> through learning. In other words, <italic>IP</italic><sub>2</sub> specifies only the starting precision of <bold>A</bold><sub><bold>2</bold></sub><sub>,<italic>τ</italic>=2</sub>, which evolves trial-by trial as counts in <italic>Dir</italic>(<bold><italic>a</italic></bold><sub><bold>2</bold></sub>) accumulate. In models that assume no learning, IP<sub>2</sub> controls the constant precision of the matrix <bold>A</bold><sub><bold>2</bold>,<italic>τ</italic>=2</sub> throughout all trials.<break/><break/>In models with learning, it is possible to derive the overall change in the interoceptive precision weighting from the first to final trial of training, denoted as Δ<italic>IP</italic><sub>2</sub>. The interoceptive precision weighting at the final training trial was calculated using the normalised Dirichlet concentration parameters associated with the higher-level likelihood matrix (i.e., <bold>norm</bold>(<bold>a</bold><sub><bold>2</bold><italic>τ</italic>=2,<italic>trial</italic>=320</sub>)) by taking the mean of the matrix elements that correspond to <italic>IP</italic><sub>2</sub> (indices 2,1; and 3,2). This final value for interoceptive precision weighting was then subtracted by <italic>IP</italic><sub>2</sub>, which represents the starting value of interoceptive precision weighting. <disp-formula id="FD12"><mml:math id="M41"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>320</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext mathvariant="bold-italic">norm</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>a</mml:mi></mml:mstyle><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>320</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>a</mml:mi></mml:mtd><mml:mtd><mml:mi>c</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>b</mml:mi></mml:mtd><mml:mtd><mml:mi>d</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mtext>Δ</mml:mtext><mml:mi>I</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo>−</mml:mo><mml:mi>I</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></td></tr><tr style="border-top: solid thin"><td valign="top" align="left">        <bold><italic>η</italic></bold><break/><break/><bold>Learning rate</bold></td><td valign="top" align="left">Only present in models with learning in matrix <bold>A</bold><sub><bold>2</bold></sub><sub>,<italic>τ</italic>=2</sub>. The <italic>η</italic> parameter controls how much performing a trial and receiving feedback changes the likelihood mapping specified in <bold>A</bold><sub><bold>2</bold></sub><sub>,<italic>τ</italic>=2</sub>, via the learning equation. Values of <italic>η</italic> approaching 0 indicate a minimal learning rate and maximal reliance on the initial precision specified by <italic>IP</italic><sub>2</sub>, while values approaching 1 indicate minimal reliance on initial values.<break/><break/>The parameters <italic>η</italic> and <italic>IP</italic><sub>1</sub> have partially overlapping effects on scaling learning if both are included in the same model, which can hinder how reliably each can be estimated. Therefore, in hierarchical models that included <italic>IP</italic><sub>1</sub>, <italic>η</italic> was not estimated.</td></tr><tr style="border-top: solid thin"><td valign="top" align="left">        <bold><italic>pS</italic></bold><break/><break/><bold>Prior bias towards synchronous</bold></td><td valign="top" align="left">Encodes beliefs about the probability of starting in the asynchronous higher-level hidden state. Values greater than .5 indicate a prior bias towards synchronous states, while values smaller than .5 indicate a prior bias towards asynchronous states.</td></tr><tr style="border-top: solid thin"><td valign="top" align="left">        <bold><italic>ω</italic></bold><break/><break/><bold>Forgetting between trials</bold></td><td valign="top" align="left">An (inverse) forgetting rate, which reduces confidence over trials in the mapping from higher-level hidden states to lower-level hidden states in <bold>a</bold><sub><bold>2</bold></sub>, which were learned through feedback in training.<break/><break/>Formally, incorporating <italic>ω</italic> involves extending the learning equation for matrix <bold>A</bold><sub><bold>2</bold></sub><sub>,<italic>τ</italic>=2</sub> as follows: <disp-formula id="FD13"><mml:math id="M42"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>a</mml:mi></mml:mstyle><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>ω</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>a</mml:mi></mml:mstyle><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>η</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mstyle displaystyle="true"><mml:mi>∑</mml:mi></mml:mstyle><mml:mi>τ</mml:mi></mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⊗</mml:mo><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> This equation entails that, with lower <italic>ω</italic> values, previously learned concentration parameters decay more quickly over time, allowing a new observation to effectively overwrite previous learning.<break/><break/>To prevent concentration parameters in <bold>a</bold><sub><bold>2</bold></sub> from decaying to implausibly low values, floor values (lower bounds) were set using <bold><italic>IP</italic></bold><sub><bold>2</bold></sub>. Specifically, if any element in <bold>a</bold><sub><bold>2</bold></sub><sub>,<italic>τ</italic>=2</sub> decayed below its starting value (shown below), the element would be reset to its starting value: <disp-formula id="FD14"><mml:math id="M43"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>a</mml:mi></mml:mstyle><mml:mrow><mml:mn mathvariant="bold">2</mml:mn><mml:mi mathvariant="bold">τ</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="bold">2</mml:mn><mml:mo>,</mml:mo><mml:mtext mathvariant="bold-italic">trial</mml:mtext><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>I</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>I</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>I</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>I</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></td></tr><tr style="border-top: solid thin"><td valign="top" align="left">        <bold><italic>ω</italic></bold><sub><bold><italic>Block</italic></bold></sub><break/><break/><bold>Forgetting between sessions</bold></td><td valign="top" align="left">An (inverse) forgetting rate which reduced confidence in <bold>a</bold><sub><bold>2</bold></sub><italic><sub>,trial</sub></italic> between training sessions, rather than on every trial within training sessions.<break/><break/>Formally, <italic>ω</italic><sub><italic>Block</italic></sub> scaled down concentration parameter values on the first trial of each subsequent training session after the first (i.e., every 40 trials). For example: <disp-formula id="FD15"><mml:math id="M44"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>a</mml:mi></mml:mstyle><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>41</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>ω</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>c</mml:mi><mml:mi>k</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>a</mml:mi></mml:mstyle><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>40</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>η</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mstyle displaystyle="true"><mml:mi>∑</mml:mi></mml:mstyle><mml:mi>t</mml:mi></mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⊗</mml:mo><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></td></tr><tr style="border-top: solid thin"><td valign="top" align="left">        <bold><italic>IP</italic></bold><sub><bold>1 <italic>Diff</italic></bold></sub><break/><break/><bold>Activity-induced elevation of lower-level signal precision</bold></td><td valign="top" align="left">Incorporating <italic>IP</italic><sub>1 <italic>Diff</italic></sub> introduces the assumption that the precision of the cardiac observations could vary not only between-subjects, but also within-subjects during trials done at rest vs. trials done immediately following self-paced physical activity. <italic>IP</italic><sub>1 <italic>Diff</italic></sub> additively controls the precision of the lower-level likelihood matrix Al on trials following physical activity only: <disp-formula id="FD16"><mml:math id="M45"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>a</mml:mi></mml:mstyle><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.2em"/><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>∣</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mi>I</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>I</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>I</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>I</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>a</mml:mi></mml:mstyle><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.2em"/><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>∣</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mi>I</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>I</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mspace width="0.2em"/><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>I</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>I</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mspace width="0.2em"/><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>I</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>I</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mspace width="0.2em"/><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>I</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>I</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mspace width="0.2em"/><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mtext mathvariant="bold">A</mml:mtext><mml:mrow><mml:mn mathvariant="bold">1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext mathvariant="bold-italic">norm</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>a</mml:mi></mml:mstyle><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.2em"/><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula> Where <italic>IP</italic><sub>1</sub> + <italic>IP</italic><sub>1 <italic>Diff</italic></sub> ≤ 1. This bounding was maintained during parameter estimation within the generative model, by clamping <italic>IP</italic><sub>1</sub> + <italic>IP</italic><sub>1 <italic>Diff</italic></sub> to 1 whenever it exceeded this upper bound.<break/><break/>As a result, incorporating <italic>IP</italic><sub>1 <italic>Diff</italic></sub> assumes that cardiac observations are more precise on trials following physical activity relative to trials at rest, and thereby learning should also be greater on trials following physical activity.</td></tr><tr style="border-top: solid thin"><td valign="top" align="left">        <bold><italic>η</italic><sub>D</sub></bold><break/><break/><bold>Learning rate for prior expectation for Synchronous state</bold></td><td valign="top" align="left"><italic>η</italic><sub><bold>D</bold></sub> introduces the assumption that participants could also update prior beliefs that any given trial would be in the synchronous or asynchronous conditions. Formally, this corresponds to updating the concentration parameters (<bold>d</bold>) in the vector <bold>D</bold> encoding prior beliefs about initial states on each trial. <disp-formula id="FD17"><mml:math id="M46"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>d</mml:mi></mml:mstyle><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mspace width="0.2em"/><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>p</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>D</mml:mi></mml:mstyle><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>d</mml:mi></mml:mstyle><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula> <disp-formula id="FD18"><mml:math id="M47"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>d</mml:mi></mml:mstyle><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mspace width="0.2em"/><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>d</mml:mi></mml:mstyle><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mtext>D</mml:mtext></mml:msub><mml:mo>×</mml:mo><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> When incorporating <italic>η</italic><sub><bold>D</bold></sub>, <italic>pS</italic> controls the initial values in <bold>d</bold>, which are updated by the posterior distribution over states at time <inline-formula><mml:math id="M48"><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, scaled by <italic>η</italic><sub><bold>D</bold></sub>.</td></tr><tr style="border-top: solid thin"><td valign="top" align="left">        <bold><italic>ζ</italic></bold><break/><break/><bold>‘Faulty memory’ mechanism</bold></td><td valign="top" align="left">This ‘faulty memory’ mechanism assumes that when participants receive feedback at time <italic>t</italic> = 3, they may have forgotten what their cardiac-auditory sensations felt like at the previous time <italic>τ</italic> = 2.<break/><break/>This corresponds to reducing the precision of beliefs about state transitions (<italic>ζ</italic>) between timesteps in a trial, encoded in the matrix <bold>B</bold>: <disp-formula id="FD19"><mml:math id="M49"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>B</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup><mml:mo>∣</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mi>τ</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mi>ζ</mml:mi></mml:mtd><mml:mtd><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>ζ</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>ζ</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mi>ζ</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> The precision parameter ζ controlled how precisely beliefs after feedback at time <italic>t</italic> = 3 ‘propagated back’ to update beliefs about states at time <italic>τ</italic> = 2. Maximal values of ζ entail that states at <italic>τ</italic> = 3 should be identical to states at <italic>τ</italic> = 2; thus, feedback at <italic>t</italic> = 3 about the true asynchronous/synchronous state should lead to a strong update about cardiac state at <italic>τ</italic> = 2, allowing for learning the state-outcome mapping. Lower values of ζ entail that precise beliefs at <italic>τ</italic> = 3 will generate less precise beliefs about cardiac state at <italic>τ</italic> = 2, which will decrease the precision of updates and slow learning.</td></tr></tbody></table></table-wrap><table-wrap id="T3" orientation="portrait" position="float"><label>Table 3</label><caption><title>Computational models compared.</title></caption><table frame="box" rules="all"><thead><tr><th valign="top" align="left">Parameter</th><th valign="top" align="center"><italic>IP</italic><sub>1</sub></th><th valign="top" align="center"><italic>IP</italic><sub>2</sub></th><th valign="top" align="center"><italic>pS</italic></th><th valign="top" align="center"><italic>η</italic></th><th valign="top" align="center">Additional parameters</th></tr></thead><tbody><tr><td valign="top" align="left"><bold>Model 1 <sup><xref ref-type="table-fn" rid="TFN2">a</xref></sup></bold></td><td valign="top" align="center">N</td><td valign="top" align="center">Y</td><td valign="top" align="center">N</td><td valign="top" align="center">N</td><td valign="top" align="center">-</td></tr><tr><td valign="top" align="left"><bold>Model 2 <sup><xref ref-type="table-fn" rid="TFN2">a</xref></sup></bold></td><td valign="top" align="center">N</td><td valign="top" align="center">Y</td><td valign="top" align="center">Y</td><td valign="top" align="center">N</td><td valign="top" align="center">-</td></tr><tr><td valign="top" align="left"><bold>Model 3 <sup><xref ref-type="table-fn" rid="TFN2">a</xref></sup></bold></td><td valign="top" align="center">N</td><td valign="top" align="center">Y</td><td valign="top" align="center">N</td><td valign="top" align="center">Y</td><td valign="top" align="center">-</td></tr><tr><td valign="top" align="left"><bold>Model 4 <sup><xref ref-type="table-fn" rid="TFN2">a</xref></sup></bold></td><td valign="top" align="center">N</td><td valign="top" align="center">Y</td><td valign="top" align="center">Y</td><td valign="top" align="center">Y</td><td valign="top" align="center">-</td></tr><tr><td valign="top" align="left"><bold>Model 5</bold></td><td valign="top" align="center">Y</td><td valign="top" align="center">Y</td><td valign="top" align="center">N</td><td valign="top" align="center">N</td><td valign="top" align="center">-</td></tr><tr><td valign="top" align="left"><bold>Model 6</bold></td><td valign="top" align="center">Y</td><td valign="top" align="center">Y</td><td valign="top" align="center">Y</td><td valign="top" align="center">N</td><td valign="top" align="center">-</td></tr><tr><td valign="top" align="left"><bold>Model 7</bold></td><td valign="top" align="center">Y</td><td valign="top" align="center">Y</td><td valign="top" align="center">N</td><td valign="top" align="center">N</td><td valign="top" align="center">-</td></tr><tr><td valign="top" align="left"><bold>Model 8</bold></td><td valign="top" align="center">Y</td><td valign="top" align="center">Y</td><td valign="top" align="center">Y</td><td valign="top" align="center">N</td><td valign="top" align="center">-</td></tr><tr><td valign="top" align="left"><bold>Model 9 <sup><xref ref-type="table-fn" rid="TFN3">b</xref></sup></bold></td><td valign="top" align="center">Y</td><td valign="top" align="center">Y</td><td valign="top" align="center">Y</td><td valign="top" align="center">N</td><td valign="top" align="center"><italic>ω</italic></td></tr><tr><td valign="top" align="left"><bold>Model 10 <sup><xref ref-type="table-fn" rid="TFN3">b</xref></sup></bold></td><td valign="top" align="center">Y</td><td valign="top" align="center">Y</td><td valign="top" align="center">Y</td><td valign="top" align="center">N</td><td valign="top" align="center">ω<italic><sub>Block</sub></italic></td></tr><tr><td valign="top" align="left"><bold>Model 11</bold></td><td valign="top" align="center">Y</td><td valign="top" align="center">Y</td><td valign="top" align="center">Y</td><td valign="top" align="center">N</td><td valign="top" align="center"><italic>IP</italic><sub>1</sub> <sub><italic>Diff</italic></sub></td></tr><tr><td valign="top" align="left"><bold>Model 12</bold></td><td valign="top" align="center">Y</td><td valign="top" align="center">Y</td><td valign="top" align="center">Y</td><td valign="top" align="center">N</td><td valign="top" align="center"><italic>η</italic><sub><bold>D</bold></sub></td></tr><tr><td valign="top" align="left"><bold>Model 13 <sup><xref ref-type="table-fn" rid="TFN2">a</xref></sup></bold></td><td valign="top" align="center">Y</td><td valign="top" align="center">Y</td><td valign="top" align="center">Y</td><td valign="top" align="center">N</td><td valign="top" align="center"><italic>ζ</italic></td></tr></tbody></table><table-wrap-foot><fn id="TFN1"><p id="P78"><bold>Legend</bold>. Y indicates the parameter was estimated for that model, while N indicates the parameter was not. Models 1 – 4 were non-hierarchical, while models 5 – 13 were hierarchical. Models 1, 2, 5, and 6 assumed no learning occurs in matrix <bold>A</bold><sub><bold>2</bold>,<italic>τ</italic>=2</sub>, while learning was present in all other models. When <italic>IP</italic><sub>1</sub> or <italic>η</italic> were not estimated, they were removed from the model (as mentioned in the main text, <italic>η</italic> was not considered in hierarchical models due to overlapping effects with <italic>IP</italic><sub>1</sub>). When <italic>pS</italic> was not estimated, it was instead fixed to .50 (i.e., no bias in prior beliefs).</p></fn><fn id="TFN2"><label>a</label><p id="P79">Excluded from final model comparison as model was not identifiable.</p></fn><fn id="TFN3"><label>b</label><p id="P80">Excluded from identifiability analysis and model comparison due to unrecoverable parameters.</p></fn></table-wrap-foot></table-wrap><table-wrap id="T4" orientation="portrait" position="float"><label>Table 4</label><caption><title>Tests of parameter recovery for model 8.</title></caption><table frame="box" rules="all"><thead><tr><th valign="middle" align="left">Parameter</th><th valign="top" align="left">Range of generative values (i.e., based on participant estimates)</th><th valign="top" align="left">Correlation between generative values and estimated values</th></tr></thead><tbody><tr><td valign="top" align="left"><bold><italic>IP</italic><sub>1</sub></bold></td><td valign="top" align="left">.61 – .91</td><td valign="top" align="left"><italic>r</italic>(26) = .97, <italic>p &lt;</italic> .001</td></tr><tr><td valign="top" align="left"><bold><italic>IP</italic><sub>2</sub></bold></td><td valign="top" align="left">.33 – .76</td><td valign="top" align="left"><italic>r</italic>(26) = .41, <italic>p</italic> = .03</td></tr><tr><td valign="top" align="left"><bold><italic>pS</italic></bold></td><td valign="top" align="left">.46 – .71</td><td valign="top" align="left"><italic>r</italic>(26) = .93, <italic>p</italic> &lt; .001</td></tr></tbody></table><table-wrap-foot><fn id="TFN4"><p id="P81"><bold>Legend</bold>. Correlation analyses tested the association between generative and estimated parameter values in a synthetic dataset simulated using model 8 and parameter values estimated for study participants.</p></fn></table-wrap-foot></table-wrap></floats-group></article>