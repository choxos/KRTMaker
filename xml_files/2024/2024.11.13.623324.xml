<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS200148</article-id><article-id pub-id-type="doi">10.1101/2024.11.13.623324</article-id><article-id pub-id-type="archive">PPR940551</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">1</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Feature similarity: a sensitive method to capture the functional interaction of brain regions and networks to support flexible behavior</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Xiuyi</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><contrib contrib-type="author"><name><surname>Lyu</surname><given-names>Baihan</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Krieger-Redwood</surname><given-names>Katya</given-names></name><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Souter</surname><given-names>Nicholas E.</given-names></name><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Shafiei</surname><given-names>Golia</given-names></name><xref ref-type="aff" rid="A4">4</xref></contrib><contrib contrib-type="author"><name><surname>Lin</surname><given-names>Nan</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Smallwood</surname><given-names>Jonathan</given-names></name><xref ref-type="aff" rid="A5">5</xref></contrib><contrib contrib-type="author"><name><surname>Jefferies</surname><given-names>Elizabeth</given-names></name><xref ref-type="aff" rid="A3">3</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><contrib contrib-type="author"><name><surname>Du</surname><given-names>Yi</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A6">6</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib></contrib-group><aff id="A1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03j7v5j15</institution-id><institution>Institute of Psychology</institution></institution-wrap>, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/034t30j35</institution-id><institution>Chinese Academy of Sciences</institution></institution-wrap>, <city>Beijing</city>, <postal-code>100101</postal-code>, <country country="CN">China</country></aff><aff id="A2"><label>2</label>Department of Psychology, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/05qbk4x57</institution-id><institution>University of Chinese Academy of Sciences</institution></institution-wrap>, <city>Beijing</city><postal-code>100049</postal-code>, <country country="CN">China</country></aff><aff id="A3"><label>3</label>Department of Psychology, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/04m01e293</institution-id><institution>University of York</institution></institution-wrap>, <addr-line>Heslington</addr-line>, <city>York</city>, <postal-code>YO10 5DD</postal-code>, <country country="GB">United Kingdom</country></aff><aff id="A4"><label>4</label>Department of Psychiatry, Perelman School of Medicine, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/00b30xv10</institution-id><institution>University of Pennsylvania</institution></institution-wrap>, <city>Philadelphia</city>, <postal-code>PA 19104</postal-code>, <country country="US">USA</country></aff><aff id="A5"><label>5</label>Department of Psychology, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/00strmv13</institution-id><institution>Queens University</institution></institution-wrap>, <city>Kingston</city>, <city>Ontario</city>, <country country="CA">Canada</country></aff><aff id="A6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/029819q61</institution-id><institution>Chinese Institute for Brain Research</institution></institution-wrap>, <city>Beijing</city><postal-code>102206</postal-code>, <country country="CN">China</country></aff><author-notes><corresp id="CR1">
<label>*</label>Correspondence: <email>wangxiuyi@psych.ac.cn</email>, <email>beth.jefferies@psych.ac.cn</email>, <email>duyi@psych.ac.cn</email></corresp></author-notes><pub-date pub-type="nihms-submitted"><day>17</day><month>11</month><year>2024</year></pub-date><pub-date pub-type="preprint"><day>14</day><month>11</month><year>2024</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">The brain is a dynamic system where complex behaviours emerge from interactions across distributed regions. Accurately linking brain function to cognition requires tools that are sensitive to these dynamics. We introduce a novel technique - Feature Similarity (FS) - to capture intricate interaction patterns between brain systems. Our results show that FS can capture functional brain organisation: regions within the same functional network have greater FS compared to those in different networks, and FS also identifies the principal gradient that spans from unimodal to transmodal cortices. FS was found to be more sensitive to task modulation than traditional functional connectivity (FC). Specifically, FS reveals interaction patterns missed by FC, such as a double dissociation in Dorsal Attention Network (DAN): greater interaction with Visual network during working memory tasks and greater interaction with default mode network (DMN) during long-term memory tasks. This study highlights FS as a promising tool for understanding flexibility in brain network dynamics.</p></abstract><kwd-group><kwd>fMRI</kwd><kwd>functional interaction</kwd><kwd>feature similarity</kwd></kwd-group></article-meta></front><body><sec id="S1" sec-type="intro"><label>1</label><title>Introduction</title><p id="P2">A central aim of cognitive neuroscience is to understand how brain regions interact to support human flexible behaviour. Currently, there is a great opportunity to address this question because datasets in which participants performed multiple cognitive tasks are rapidly increasing in size and scope. While various methods have been used to study functional interactions in specific contexts, it remains difficult to reliably and sensitively capture how these interactions change across tasks in a hypothesis-free manner. Thus, there is a critical need for new methods to address this gap.</p><p id="P3">Current neuroimaging methods measure functional interactions in specific contexts, but each has limitations that hinder widespread use. For example, within-subject functional connectivity (FC) does not distinguish stimulus-induced correlations from intrinsic or artificial correlations, making it less sensitive to task modulation (<xref ref-type="bibr" rid="R45">Simony et al., 2016</xref>). While inter-subject FC (ISFC) isolates stimulus-dependent correlations, it requires identical stimulus presentation across participants, limiting its use in varied datasets (<xref ref-type="bibr" rid="R45">Simony et al., 2016</xref>). Methods like psycho-physiological interactions (PPI) (<xref ref-type="bibr" rid="R38">O’Reilly et al., 2012</xref>) and dynamic causal model (DCM) (<xref ref-type="bibr" rid="R20">Friston, 2011</xref>) rely on predefined seed regions, restricting data-driven exploration. Additionally, methods like Granger causality (<xref ref-type="bibr" rid="R43">Seth et al., 2015</xref>) assume stationarity, which may not hold for non-stationary brain signals across tasks. Overall, these limitations necessitate a new approach for more flexible, data-driven analysis of functional interactions across tasks.</p><p id="P4">Recent studies have highlighted significant advances in the understanding of time-series features of neural activity, revealing that these features can vary across different cognitive tasks tasks (<xref ref-type="bibr" rid="R26">Golesorkhi et al., 2021</xref>; <xref ref-type="bibr" rid="R55">Wolff et al., 2022</xref>). For instance, timescale of neural responses has been shown to differ depending on the nature of the task being performed tasks (<xref ref-type="bibr" rid="R26">Golesorkhi et al., 2021</xref>; <xref ref-type="bibr" rid="R55">Wolff et al., 2022</xref>). These insights motivated us to utilise feature similarity (FS) to capture how interaction patterns vary across tasks. The core of this method involves extracting a wide range of interpretable features from time-series data, utilizing these features to calculate the FS between brain regions, and then computing how FS varies across tasks (see <xref ref-type="fig" rid="F1">Fig. 1</xref>). The extracted features include distributional properties, entropy, and variability (i.e., the signal variability), temporal autocorrelation, time-delay embeddings, and nonlinear properties of a given time-series, including nonlinear temporal autocorrelation (<xref ref-type="bibr" rid="R21">Fulcher, 2018</xref>; <xref ref-type="bibr" rid="R23">Fulcher et al., 2013</xref>).</p><p id="P5">The development of FS was inspired by observations that certain brain regions possess distinct features, which equip them to support different functions, while regions with similar features tend to support parallel functions, regardless of their FC. For instance, early visual areas and the default mode network (DMN) are situated at opposing ends of the timescale hierarchy — early visual areas have rapid autocorrelation decay, whereas DMN regions show gradual autocorrelation decay (<xref ref-type="bibr" rid="R5">Blank and Fedorenko, 2020</xref>; <xref ref-type="bibr" rid="R28">Honey et al., 2012</xref>; <xref ref-type="bibr" rid="R29">Ito et al., 2020</xref>; <xref ref-type="bibr" rid="R40">Raut et al., 2020</xref>; <xref ref-type="bibr" rid="R45">Simony et al., 2016</xref>). This timescale difference underlies their functional roles: neural representations in early visual areas are minimally influenced by prior knowledge, while the DMN is heavily shaped by it (<xref ref-type="bibr" rid="R27">González-García et al., 2018</xref>). Similarly, transmodal regions like frontoparietal control network (FPCN) and DMN, though often showing negative FC (<xref ref-type="bibr" rid="R51">Wang et al., 2024a</xref>), share long timescales(<xref ref-type="bibr" rid="R40">Raut et al., 2020</xref>) and process inputs over longer periods (i.e., maintaining task goals) (<xref ref-type="bibr" rid="R50">Wang et al., 2021</xref>). These observations suggest that FS can capture functional similarities beyond aspects revealed by FC.</p><p id="P6">Furthermore, features can differ depending on tasks (<xref ref-type="bibr" rid="R26">Golesorkhi et al., 2021</xref>; <xref ref-type="bibr" rid="R55">Wolff et al., 2022</xref>), indicating their potential to depict variations in network interactions. For example, auditory story comprehension shortens the autocorrelation window in transmodal regions, but maintains its duration in unimodal regions. In contrast, motor and working memory tasks exhibit the opposite effect (<xref ref-type="bibr" rid="R26">Golesorkhi et al., 2021</xref>). These shifts in features reflect brain’s dynamic adaptation to task demands, as seen with domain-general control network, which exhibits greater FS with dorsal attention network (DAN) during working memory tasks and with memory control network during long-term memory tasks (<xref ref-type="bibr" rid="R51">Wang et al., 2024a</xref>). These observations led us to develop a hypothesis-free, data-driven FS analysis that extracts comprehensive features to objectively capture the complexity of time-series data. FS has the potential to uncover previously undetected relationships due to the limitations of existing methods. With no reliance on predefined regions of interest or task designs, FS can be applied across multiple datasets, offering a versatile tool for studying functional interactions in cognitive neuroscience.</p><p id="P7">In this study, we demonstrate that FS effectively captures dynamic interaction patterns across tasks. To assess whether FS provides greater sensitivity than FC, we focused on the well-established anti-correlation between two large-scale networks: DAN typically shows strong FC with Visual network and weak FC with DMN, indicating competition between external attention and cognition guided by long-term memory (<xref ref-type="bibr" rid="R19">Fox et al., 2005</xref>; <xref ref-type="bibr" rid="R44">Shine et al., 2019</xref>). However, recent evidence demonstrates that DAN is topographically positioned between the visual network and DMN (<xref ref-type="bibr" rid="R31">Margulies et al., 2016</xref>; <xref ref-type="bibr" rid="R51">Wang et al., 2024a</xref>), allowing it to cooperate with both networks in certain situations (<xref ref-type="bibr" rid="R6">Buckner and DiNicola, 2019</xref>; <xref ref-type="bibr" rid="R7">Buckner and Margulies, 2019</xref>; <xref ref-type="bibr" rid="R31">Margulies et al., 2016</xref>; <xref ref-type="bibr" rid="R34">Mesulam, 1998</xref>; <xref ref-type="bibr" rid="R46">Smallwood et al., 2021</xref>). Tasks that involve working memory and long-term memory are expected to involve distinct interaction patterns between these networks (<xref ref-type="fig" rid="F2">Fig. 2</xref>; <xref ref-type="bibr" rid="R51">Wang et al., 2024a</xref>). Our results show that FS captures this flexibility better than FC. DAN interacts more with visual system in working memory tasks and with DMN in long-term memory tasks in FS, but this distinction is not detected by FC. This underscores FS’s ability to capture nuanced brain dynamics.</p></sec><sec id="S2" sec-type="results"><label>2</label><title>Results</title><p id="P8">The results are divided into three sections. (i) First, we took an existing individualized parcellation of the cortex to identify the parcels of each network and examined whether FS is equally capable of capturing the network structure as FC does. As expected, regions belonging to the same intrinsic functional subnetworks had greater FS compared to regions in different subnetworks. (ii) Next, we examined whether FS could capture the organizational principles of the cortex as is seen in FC. We found FS captured the principal intrinsic connectivity gradient that separates sensory-motor regions from transmodal areas, as well as the second component that separates somatomotor and auditory from visual cortex, which have been previously described using decompositions of FC. (iii), Finally, we examined whether FS is more sensitive to task-induced changes in brain dynamics than FC by examining how these metrics characterise network interactions across working memory and long-term memory tasks. Specifically, we asked whether FS and FC are equal in their capacity to identify differences in the way that DAN interacts with Visual network and DMN during working memory and long-term memory tasks.</p><p id="P9">The FS method consists of the following steps (see <xref ref-type="fig" rid="F1">Fig. 1</xref>):</p><list list-type="simple" id="L1"><list-item><p id="P10">Step 1: Extract a diverse set of interpretable features from the time-series data.</p></list-item><list-item><p id="P11">Step 2: Calculate FS between brain regions by calculating the Pearson correlation coefficients of the extracted features.</p></list-item><list-item><p id="P12">Step 3: Examine how FS varies across different tasks.</p></list-item></list><sec id="S3"><label>2.1</label><title>Regions belonging to the same intrinsic functional network have greater FS compared to regions in different networks</title><p id="P13">We first examined whether parcels within the same network exhibited similar features. We selected Kong et al. ‘s parcellation (2021a) as it allows for individual-specific parcellations with greater homogeneity (<xref ref-type="bibr" rid="R51">Wang et al., 2024a</xref>) while capturing the inherent heterogeneity of large-scale networks like DAN and FPCN. To estimate FC, we computed Pearson correlation coefficients between regional time-series, and for FS, we computed Pearson correlations between regional feature vectors (<xref ref-type="fig" rid="F1">Fig. 1</xref>). Regions were considered similar in terms of features if most time-series features—such as entropy, stationarity, and linear correlation properties—were significantly correlated (<xref ref-type="bibr" rid="R21">Fulcher, 2018</xref>). FS captures regions with similar dynamical properties but not necessarily synchronous activity (<xref ref-type="fig" rid="F1">Fig. 1</xref>). For example, while FPCN-A and DMN both have longer timescales, they often exhibit negative FC (<xref ref-type="bibr" rid="R51">Wang et al., 2024a</xref>).</p><p id="P14">As expected, regions within the same functional network showed higher FC compared to those between networks, both at rest (t = 136.09, p &lt; 0.001) and during tasks (spatial working memory, t = 26.33, p &lt; 0.001; math, t = 26.36, p &lt; 0.001; semantic feature matching, t = 70.02, p &lt; 0.001; semantic association, t = 57.60, p &lt; 0.001) (<xref ref-type="fig" rid="F3">Fig. 3</xref>). Similarly, FS was higher within networks compared to between networks, both at rest (t = 91.24, p &lt; 0.001) and across tasks (spatial working memory, t = 18.35, p &lt; 0.001; math, t = 14.51, p &lt; 0.001; semantic feature matching, t = 42.27, p &lt; 0.001; semantic association, t = 38.04, p &lt; 0.001) (<xref ref-type="fig" rid="F3">Fig. 3</xref>). All p-values were FDR-corrected. These findings suggest that FS can capture intrinsic network structure traditionally measured by FC.</p><p id="P15">We also assessed the similarity between FC and FS by correlating the FC and FS matrices at rest and during tasks. We observed weak but significant positive correlations between FC and FS as indicated by arrows (<xref ref-type="fig" rid="F3">Fig.3</xref>) at rest (r = 0.29, p = 0) and during tasks (spatial working memory, r = 0.37, p = 0; math, r = 0.33, p = 0; semantic feature matching, r = 0.33, p = 0; semantic association, r = 0.33, p = 0). All p-values were FWE-corrected using maximum r values (Method 4.5.4). The positive correlations suggest that regions with similar time-series features exhibited coherent spontaneous fluctuations. However, the largest correlation was 0.37, indicating that these measures also capture different information.</p></sec><sec id="S4"><label>2.2</label><title>FS reveals unique organizational principles beyond FC</title><p id="P16">Next, we investigated whether FS and FC captured similar or different components of connectivity. Firstly, we performed dimension reduction analysis (diffusion embedding) (<xref ref-type="bibr" rid="R31">Margulies et al., 2016</xref>) on the resting state FC matrix for the HCP dataset (<xref ref-type="fig" rid="F3">Fig. 3A</xref>). We focused on the three components with the largest eigenvalues, which explained 28.02% variance in total (see <xref ref-type="fig" rid="F4">Fig. 4I</xref> for scree plot). Consistent with previous studies (<xref ref-type="bibr" rid="R31">Margulies et al., 2016</xref>; <xref ref-type="bibr" rid="R49">Wang et al., 2020</xref>, <xref ref-type="bibr" rid="R51">2022</xref>, <xref ref-type="bibr" rid="R51">2024a</xref>, <xref ref-type="bibr" rid="R52">2024b</xref>), the first component explaining 12.75% of the variance corresponded to the principal gradient described by <xref ref-type="bibr" rid="R31">Margulies et al. (2016)</xref>. This component separated sensory-motor regions (shown in purple-blue in <xref ref-type="fig" rid="F4">Fig. 4A</xref>) from transmodal areas (shown in red-white in <xref ref-type="fig" rid="F4">Fig. 4A</xref>). The second component explained 11.29% of the variance and separated somatomotor and auditory cortex (shown in purple-blue in <xref ref-type="fig" rid="F4">Fig. 4B</xref>) from visual cortex (shown in red-white in <xref ref-type="fig" rid="F4">Fig. 4B</xref>). The third component explained 3.98% of the variance and separated FPCN regions (shown in purple-blue in <xref ref-type="fig" rid="F4">Fig. 4C</xref>) from DMN regions (shown in red-white in <xref ref-type="fig" rid="F4">Fig. 4C</xref>).</p><p id="P17">Similarly, we performed dimension reduction analysis on the resting state FS matrix for the HCP dataset (<xref ref-type="fig" rid="F3">Fig. 3F</xref>), using the procedures above. The three components with the largest eigenvalues explained 23.23% of the variance (see <xref ref-type="fig" rid="F4">Fig. 4I</xref> for scree plot). FS captured two components that were similar to the results for FC, and one not uncovered by FC (<xref ref-type="fig" rid="F4">Fig. 4</xref>). The first principal component of FS explained 12.19% of the variance and had a distinct spatial distribution from the first three components of FC: it did not show significant correlations with any of the components of FC (p &gt; 0.05; <xref ref-type="fig" rid="F4">Fig. 4D</xref>). The next two components of FS were seen in FC data (<xref ref-type="fig" rid="F4">Fig. 4</xref>). The second component of FS (explaining 7.11% of the variance; <xref ref-type="fig" rid="F4">Fig. 4E</xref>) aligned with the principal gradient of FC (<xref ref-type="fig" rid="F4">Fig. 4A</xref>), separating sensory-motor from transmodal cortex, with a strong correlation between components (r = 0.89, p = 0, spin permutation corrected). The third component of FS (explaining the 3.94% variance; <xref ref-type="fig" rid="F4">Fig. 4F</xref>) corresponded to the second component of FC (<xref ref-type="fig" rid="F4">Fig. 4B</xref>), separating somatomotor and auditory cortex from visual cortex, with a strong correlation between components (r = 0.87, p = 0, spin permutation corrected). These findings further confirm that FS captures meaningful information, i.e., organizational principle.</p><p id="P18">To gain insight into the first component of FS, we investigated its correlation with the map of intrinsic timescale, which reflects the temporal duration of ongoing inputs that the brain can process. The first component resembles the distribution of intrinsic timescale reported by <xref ref-type="bibr" rid="R40">Raut et al. (2020)</xref>, which is longest in transmodal regions (<xref ref-type="bibr" rid="R55">Wolff et al., 2022</xref>). We therefore estimated intrinsic timescale for each parcel by measuring the decay of the temporal autocorrelation function and quantifying the time taken for the autocorrelation function to reach a threshold of r= 0.5, which is half of the full width at half maximum (see <xref ref-type="bibr" rid="R35">Murray et al., 2014</xref>; <xref ref-type="bibr" rid="R40">Raut et al., 2020</xref> for similar implementation). Higher values indicate longer processing times for ongoing inputs. Our results align with <xref ref-type="bibr" rid="R40">Raut et al. (2020)</xref>, showing short timescales in the insula and cingulate cortex, and long timescales in the angular gyrus, posterior cingulate cortex, and frontal pole. (<xref ref-type="fig" rid="F4">Fig. 4G</xref>). We found that the first principal component, which explained the most variance in FS, was significantly correlated with the intrinsic timescale map (left hemisphere: r = 0.82, p = 0; right hemisphere: r = 0.80, p = 0; <xref ref-type="fig" rid="F4">Fig. 4H</xref>, corrected for spatial autocorrelation using spin permutation), indicating that FS can capture meaningful information not captured by traditional FC, such as the intrinsic timescale of the brain’s response.</p></sec><sec id="S5"><label>2.3</label><title>FS showed greater variation across tasks than FC</title><p id="P19">The above analyses showed that FS captured similar information to FC but also additional dimensions of cortical organisation. Next, we examined whether FS was more sensitive to task modulation than FC. FC measures the temporal correlation between time-series from different brain regions, focusing on the synchrony of neural activity. In contrast, FS extracts a comprehensive set of features from the time-series, such as entropy, stationarity, and autocorrelation, providing a multidimensional profile of the brain’s activity. Given that tasks impose specific cognitive demands and engage distinct neural processes, the brain’s functional organization undergoes modulation at multiple levels. Temporal correlation (as captured by FC) may remain stable under certain conditions, but the underlying features of the time-series, such as signal complexity, variability, and temporal autocorrelation, may exhibit more sensitivity to these changes. This multidimensional analysis may allow FS to detect subtle changes in brain dynamics during tasks that may be missed by FC.</p><p id="P20">We computed the Pearson correlation coefficients of the task mean FC matrices for every possible combination pair of tasks. For example, we calculated the Pearson correlation coefficients of the FC matrices of the spatial working memory task (<xref ref-type="fig" rid="F3">Fig. 3B</xref>) and math task (<xref ref-type="fig" rid="F3">Fig. 3C</xref>). Similarly, we calculated the Pearson correlation coefficients of the FS matrices of these two tasks (<xref ref-type="fig" rid="F3">Fig. 3G and 3H</xref>). Then we directly compared these two r values. We found correlations for FC were consistently higher than those for FS for every task pair (<xref ref-type="fig" rid="F5">Fig. 5A</xref>; p &lt; 0.05; see <xref ref-type="table" rid="T1">Table 1</xref> for statistics), suggesting that FS may be more sensitive to task differences than FC.</p><p id="P21">The task sensitivity of FS was further confirmed when we compared the correlations of FS with those of FC between two non-semantic tasks for each participant. Since the same participants completed both the spatial working memory task and the math task, we calculated the Pearson correlation coefficients between the FC matrix of the spatial working memory task and that of math task for each participant and transformed the resulting r values to z values using Fisher’s transformation. Similarly, we also calculated the Fisher’s z values between the FS matrices of the two non-semantic tasks for each participant. Finally, we compared the z values of FC with those of FS by conducting paired t-tests. We found that the correlations of FC were greater than the correlations of FS for the non-semantic tasks (<xref ref-type="fig" rid="F5">Fig. 5B</xref>; t = 26.58, p &lt; 0.001). We then conducted the same analysis for the two semantic tasks, semantic feature matching and association, and observed the same pattern (i.e., stronger correlation across tasks for FC than for FS; <xref ref-type="fig" rid="F5">Fig. 5C</xref>, t = 23.29, p &lt; 0.001). The smaller correlation of FS is not because the data of FS are noisier. By contrast, FS carries meaningful task information, as FS matrices correctly classify task labels for non-semantic tasks (accuracy = 0.83, p = 0) and semantic tasks (accuracy = 0.78, p = 0), both significantly above chance level (0.5) (see <xref ref-type="supplementary-material" rid="SD1">SM 2.1</xref> for detailed results). These findings suggest that FS is more sensitive to task modulation than FC, as FS takes into account multiple aspects of time-series similarity, whereas FC reflects only one.</p></sec><sec id="S6"><label>2.4</label><title>FS captured network interaction patterns across tasks not captured by FC</title><p id="P22">After showing that FS was generally more sensitive to task modulation than FC, we examined whether FS could capture the varying network interaction patterns across tasks that missed by FC. We tested the interaction difference between DAN and Visual network versus DAN and DMN, to test the hypothesis that DAN is more similar to Visual network in non-semantic tasks, which rely more on visual features and working memory, and more similar to DMN in semantic tasks, which rely more on long-term memory. We expected that this pattern would be seen more readily in FS, since this metric was more sensitive than FC to task demands above.</p><p id="P23">Since the tasks were presented visually in the current study, we selected DAN-A (<xref ref-type="bibr" rid="R30">Kong et al., 2021</xref>), which is typically engaged together with Visual network and showed greater feature similarity with Visual network than other attention networks (DAN-B, Ventral attention network) in a classification analysis (<xref ref-type="supplementary-material" rid="SD1">Fig. S1</xref>). We compared FC and FS between DAN-A and Visual network versus DAN-A and DMN across tasks, focusing on differences in the strength of these connections. For simplicity, we combined the three visual subnetworks into a single visual network and the three default mode subnetworks into a single DMN. While connectivity differences did not vary across tasks when assessed with FC (<xref ref-type="fig" rid="F6">Fig. 6</xref>, p &gt; 0.05, FWE corrected), there was a difference between non-semantic and semantic tasks for FS (p &lt; 0.001; FWE corrected). DAN-A always showed greater FC with Visual network than with DMN at rest (<xref ref-type="fig" rid="F6">Fig. 6</xref>, t = 53.68, p &lt; 0.001) and for each task (<xref ref-type="fig" rid="F6">Fig. 6</xref>, spatial working memory, t = 16.19, p &lt; 0.001; math, t = 11.73, p &lt; 0.001; semantic feature matching, t = 17.19, p &lt; 0.001; semantic association, t = 14.95, p &lt; 0.001), consistent with previous studies. However, DAN-A showed greater FS with Visual network than with DMN at rest (<xref ref-type="fig" rid="F5">Fig. 5</xref>, t = 10.58, p &lt; 0.001) and in non-semantic tasks (<xref ref-type="fig" rid="F5">Fig. 5</xref>, spatial working memory, t = 3.55, p = 0.004 ; math, t = 3.19, p = 0.003), but showed the opposite pattern in semantic tasks (<xref ref-type="fig" rid="F5">Fig. 5</xref>, semantic feature matching, t = -2.86, p = 0.008; semantic association, t = -2.64, p = 0.01). These findings suggest that FS is more sensitive to dynamic interaction patterns between networks that reflect differing cognitive demands.</p><p id="P24">The task sensitivity of FS was further confirmed when we examined the interaction differences between the domain general control network (FPCN-A) and Visual network versus FPCN-A and DMN. Interaction difference for FPCN-A across tasks were only captured by FS and not by FC (<xref ref-type="supplementary-material" rid="SD1">Fig. S2</xref>; See <xref ref-type="supplementary-material" rid="SD1">SM 2.3</xref> for detailed information). There was no difference in FC across tasks for FPCN-A (p &gt; 0.05, FWE corrected), with FPCN-A always showing greater FC with Visual network than with DMN at rest (t = 2.39, p = 0.02) and for each task (spatial working memory, t = 11.36, p &lt; 0.001; math, t = 11.44, p &lt; 0.001; semantic feature matching, t = 6.50, p &lt; 0.001; semantic association, t = 3.62, p = 0.001). However, FS revealed different patterns across tasks, with a greater difference between FPCN-A and Visual network compared with FPCN-A and DMN for the non-semantic than semantic tasks (p &lt; 0.001; FWE corrected). Specifically, FPCN-A showed similar FS with Visual network and DMN at rest (t = 1.39, p = 0.17) and in the math task (t = -0.73, p = 0.47) but showed greater FS with DMN than with Visual network in the spatial working memory task (t = -4.97, p &lt; 0.001) and semantic tasks (semantic feature matching, t = -9.12, p &lt; 0.001; semantic association, t = -8.25, p &lt; 0.001). These findings support that FS is more sensitive to task modulation than FC.</p></sec></sec><sec id="S7" sec-type="discussion"><label>3</label><title>Discussion</title><p id="P25">In this study, we demonstrate that FS serves as a robust index for unveiling network structures, brain topography, and task modulations. The validation of FS was supported by two observations: (1) regions belonging to the same intrinsic functional network exhibited greater FS compared to regions in distinct networks, and (2) FS captured the principal gradient that organizes neural systems along a spectrum from unimodal to transmodal cortex, with sensory-motor regions situated at one end and transmodal areas at the other. Furthermore, our study expands upon prior research by demonstrating that FS exhibits greater sensitivity to task modulation. Under specific conditions, FS reveals unique interaction patterns that remain undetected by FC. For instance, DAN-A exhibits greater FC with Visual network than DMN during both working memory and long-term memory tasks. However, DAN-A displays greater FS with Visual network than DMN in working memory tasks and the opposite pattern in long-term memory tasks, suggesting a shift in DAN-A features towards DMN in semantic tasks where long-term memory supported by DMN is required. The discrepancies in interaction patterns between FC and FS indicate that certain patterns can only be discerned through FS. The task sensitivity of FS is further substantiated by examining the interaction patterns of the FPCN-A. Collectively, these findings suggest that FS is a promising method for uncovering network interaction patterns and functions.</p><p id="P26">Our findings suggest that FS is a more suitable approach for studying interaction patterns across multiple cognitive domains than FC, given it is more sensitive to task effects. The brain functions as an information processing and transfer system, wherein networks supporting various functions must coordinate with one another to facilitate complex cognitive processes, such as memory retrieval (<xref ref-type="bibr" rid="R44">Shine et al., 2019</xref>). Furthermore, investigating the interaction patterns of brain networks can offer a more refined understanding of the brain’s functional organization, which is not static. Nevertheless, interaction patterns have predominantly been investigated using FC, which may have limited our understanding of the flexible nature of network connectivity, given its limited sensitivity to task modulation. We propose it may be beneficial to reanalyse existing fMRI data using FS and re-evaluate previous findings drawn using FC, to generate novel insights, resolve inconsistencies, revise existing theories, and propose new theoretical frameworks.</p><p id="P27">While we advocate the use of FS for reanalysing existing data, this does not imply that FC is without merit. FS serves as a complementary measure to FC, which remains valuable for comprehending the general functional architecture of the brain, for example, as shaped by neuroanatomy. FC is particularly adept at revealing coupling patterns of intrinsic activity. For instance, DMN regions exhibit greater FC with each other at rest and during various conditions and this functional similarity is thought to be at least partly related to their anatomical location at a maximum distance from primary sensory-motor cortex (<xref ref-type="bibr" rid="R31">Margulies et al., 2016</xref>) and by the strong influence of spatial proximity on connectivity patterns. Yet these observations might underplay the dynamic nature of connectivity patterns and their sensitivity to changes in cognitive state. DMN regions display no ISFC at rest, nor when participants listen to scrambled words or individual words – although they do exhibit ISFC when participants listen to sentences and paragraphs (<xref ref-type="bibr" rid="R45">Simony et al., 2016</xref>). This observation suggests that FC is predominantly influenced by intrinsic activity, while ISFC is driven by stimulus-related activity during states of coherent semantic cognition. Since FC, ISFC and FS convey distinct information, combining these methods can offer a comprehensive understanding of the brain’s functionality.</p><p id="P28">Although this study highlights the increased sensitivity of FS to task modulation, the specific features that change across tasks have yet to be determined. It is imperative for future research to identify and interpret features. For instance, we demonstrated that the DAN-A exhibits greater FS with Visual network than DMN in non-semantic tasks, wherein participants focus more on external visual information. Conversely, DAN-A displays greater FS with DMN than Visual network in semantic tasks, where participants rely on long-term memory. Given that approximately 7,000 features were extracted and employed in calculating FS, future research can pinpoint the specific features that vary across these tasks. While our results demonstrate that FS can exhibit greater sensitivity to task modulation than FC in specific datasets and networks, this finding does not imply that feature similarity is universally superior. Therefore, our study should be viewed as an illustration of the potential advantages of FS, rather than a definitive conclusion about its superiority in all contexts. Future investigations should encompass a more extensive array of diverse tasks.</p></sec><sec id="S8" sec-type="conclusions"><title>Conclusion</title><p id="P29">Our results demonstrate that Feature Similarity (FS) offers a significant methodological advancement in understanding dynamic brain network interactions. While traditional functional connectivity (FC) methods have provided valuable insights, FS is more sensitive and reliable in capturing subtle changes in network interactions, particularly across different cognitive states. Just as motion tracking software has revolutionized the study of animal behaviour by enabling precise analysis of how animals interact in different social contexts, we argue that FS represents a similar breakthrough in neuroimaging—enhancing our ability to assess brain function and cognitive flexibility with greater precision. While experimental designs and neuroimaging hardware continue to improve, FS provides a powerful tool for reanalysing existing fMRI datasets, resolving inconsistencies, and advancing our theoretical understanding of cognitive flexibility. Ultimately, FS could become an essential tool for exploring the adaptive nature of brain network dynamics.</p></sec><sec id="S9" sec-type="materials | methods"><label>4</label><title>Materials and Methods</title><p id="P30">This study included three datasets, one publicly available dataset – the Human Connectome Project (HCP), and two task fMRI datasets collected at the University of York, UK.</p><p id="P31">We analysed the resting state functional MRI (rsfMRI) data of 245 unrelated participants who completed all four resting state scans from the S900 release of HCP dataset to investigate the functional hierarchy, FC, and FS patterns. In addition, to compare whether FC and FS can capture varying interaction patterns to the same extent, we used two types of tasks (tapping working memory and long-term memory retrieval) which are associated with distinct neurocognitive modes (<xref ref-type="bibr" rid="R49">Wang et al., 2020</xref>). To tap working memory, participants completed easy and hard spatial working memory and arithmetic tasks designed to localise domain general control regions (<xref ref-type="bibr" rid="R4">Blank et al., 2014</xref>; <xref ref-type="bibr" rid="R17">Fedorenko et al., 2013</xref>, <xref ref-type="bibr" rid="R16">2011</xref>; <xref ref-type="bibr" rid="R49">Wang et al., 2020</xref>, <xref ref-type="bibr" rid="R50">2021</xref>, <xref ref-type="bibr" rid="R54">2022</xref>, <xref ref-type="bibr" rid="R51">2024a</xref>), which required information to be maintained and manipulated. They also completed two semantic tasks tapping knowledge in long-term memory, a semantic feature matching task that involved linking probe and target concepts (presented as written words) based on colour or shape, and a semantic association task in which participants decided if pairs of words were semantically associated or not (<xref ref-type="bibr" rid="R51">Wang et al., 2024a</xref>, <xref ref-type="bibr" rid="R52">2024b</xref>). These datasets have been previously analysed (<xref ref-type="bibr" rid="R51">Wang et al., 2024a</xref>, <xref ref-type="bibr" rid="R52">2024b</xref>).</p><sec id="S10" sec-type="subjects"><label>4.1</label><title>Participants</title><p id="P32">All participants were right-handed, native English speakers, had normal or corrected-to-normal vision, and had no history of psychiatric or neurological illness. For the HCP dataset, informed consent was obtained, and the study was approved by the Institutional Review Board of Washington University at St. Louis. For the York non-semantic and semantic dataset, the research was approved by the York Neuroimaging Centre and Department of Psychology ethics committees.</p><p id="P33">We analysed the data of 245 neurologically healthy volunteers (130 males, 115 females), aged 23 – 35 years (mean = 28.21, SD = 3.67), from the HCP dataset (<xref ref-type="bibr" rid="R25">Glasser et al., 2013</xref>).</p><p id="P34">31 neurologically healthy adults (26 females; age: mean ± SD = 20.60 ± 1.68, range: 18 – 25 years) performed spatial working memory and math tasks in York. One participant with incomplete data (only one of two sessions) was removed. A functional run was excluded if (i) mean relative root mean square (RMS) framewise displacement was higher than 0.2 mm, (ii) it had more than 15% percentage of total frames with motion exceeding 0.25 mm, or (iii) a participant’s accuracy on the respective task was three standard deviations below the group mean. If only run of one task was left for a given participant after exclusion, the data from this task were removed for this participant. These exclusion criteria resulted in a final sample of 27 participants for both the spatial working memory task and the math task.</p><p id="P35">We also analysed a semantic task dataset collected at the University of York, UK. 31 healthy adults were recruited from the University of York (25 females; age: mean ± SD = 21.26 ± 2.93, range: 19 – 34 years). The same exclusion criteria for functional runs were applied as above. For the feature matching task, this left 23 participants with 4 runs, 4 participants with 3 runs, and 1 participant with 2 runs. For the association task, there were 24 participants with 4 runs, 3 participants with 3 runs, and 3 participants with 2 runs. To select experimental materials, we recruited 30 native English speakers who did not participate in the main fMRI experiment as subjects (21 females; age range: 18 – 24 years). These individuals rated the color and shape similarity as well as the semantic association strength for each word pair.</p></sec><sec id="S11"><label>4.2</label><title>Tasks paradigms</title><sec id="S12"><label>4.2.1</label><title>Spatial working memory task</title><p id="P36">Participants were required to maintain four or eight sequentially presented locations in a 3×4 grid (<xref ref-type="bibr" rid="R16">Fedorenko et al., 2011</xref>), giving rise to easy and hard spatial working memory conditions. Stimuli were presented at the center of the screen across four steps. Each of these steps lasted for 1s and highlighted one location on the grid in the easy condition, and two locations in the hard condition. This was followed by a decision phase, which showed two grids side by side (i.e., two-alternative forced choice (2AFC) paradigm). One grid contained the locations shown on the previous four steps, while the other contained one or two locations in the wrong place. Participants indicated their response via a button press and feedback was immediately provided within in 2.5s. Each run consisted of 12 experimental blocks (6 blocks per condition and 4 trials in a 32 s block) and 4 fixation blocks (each 16 s long), resulting in a total time of 448 s.</p></sec><sec id="S13"><label>4.2.2</label><title>Math task</title><p id="P37">Participants were presented with an addition expression on the screen for 1.45s and, subsequently made a 2AFC decision indicating their solution within 1s. The easy condition used single-digit numbers while the hard condition used two-digit numbers. Each trial ended with a blank screen lasting for 0.1s. Each run consisted of 12 experimental blocks (with 4 trials per block) and 4 fixation blocks, resulting in a total time of 316s.</p></sec><sec id="S14"><label>4.2.3</label><title>Semantic feature matching task</title><p id="P38">Participants were required to make a yes/no decision matching probe and target concepts (presented as words) according to a particular semantic feature (colour or shape), specified at the top of the screen during each trial. The feature prompt, probe word, and target words were presented simultaneously. Half of the trials were matching trials in which participants would be expected to identify shared features; while half of the trials were non-matching trials in which participants would not be expected to identify shared features. For example, in a colour matching trial participants would answer ‘yes’ to the word-pair DALMATIANS – COWS, due to their colour similarity, whereas they would answer ‘no’ to COAL -TOOTH as they do not share a similar colour.</p><p id="P39">This task included four runs and two conditions (two features: colour and shape), presented in a mixed design. Each run consisted of four experimental blocks (two 150s blocks per feature), resulting in a total time of 612s. In each block, 20 trials were presented in a rapid event-related design. In order to maximize the statistical power of the rapid event-related fMRI data analysis, the stimuli were presented with a temporal jitter randomized from trial to trial (<xref ref-type="bibr" rid="R12">Dale, 1999</xref>). The inter-trial interval varied from 3 to 5 s. Each trial started with a fixation, followed by the feature, probe word, and target word presented centrally on the screen, triggering the onset of the decision-making period. The feature, probe word, and target word remained visible until the participant responded, or for a maximum of 3 s. The condition order was counterbalanced across runs and run order was counterbalanced across participants. Half of the participants pressed a button with their right index finger to indicate a matching trial and responded with their right middle finger to indicate a non-matching trial. Half of the participants pressed the opposite buttons.</p></sec><sec id="S15"><label>4.2.4</label><title>Semantic association task</title><p id="P40">Participants were asked to decide if pairs of words were semantically associated or not (i.e., yes/no decision as above) based on their own experience. Overall, there were roughly equal numbers of ‘related’ and ‘unrelated’ responses across participants. The same stimuli were used in the semantic feature matching task and semantic association task. For example, DALMATIANS and COWS are semantically related; COAL and TOOTH are not. The feature and association tasks were often separated by one week. This task included four runs, presented in a rapid event-related design. Each run consisted of 80 trials, with about half being related and half being unrelated trials. The procedure was the same as the feature matching task except only two words were presented on the screen.</p></sec></sec><sec id="S16"><label>4.3</label><title>Image acquisition</title><sec id="S17"><label>4.3.1</label><title>Image acquisition for HCP dataset</title><p id="P41">MRI acquisition protocols of the HCP dataset have been previously described by <xref ref-type="bibr" rid="R3">Barch et al., (2013)</xref> and <xref ref-type="bibr" rid="R25">Glasser et al., (2013)</xref>. Images were acquired using a customized 3T Siemens Connectome scanner having a 100 mT/m SC72 gradient set and using a standard Siemens 32-channel radiofrequency receive head coil. Participants underwent the following scans: structural (at least one T1-weighted (T1w) MPRAGE and one 3D T2-weighted (T2w) SPACE scan at 0.7-mm isotropic resolution), rsfMRI (4 runs ×14 min and 33 s), and task fMRI (7 tasks, 46.6 min in total). Since not all participants completed all scans, we only included 339 unrelated participants from the S900 release. Whole-brain rsfMRI and task fMRI data were acquired using identical multi-band echo planar imaging (EPI) sequence parameters of 2-mm isotropic resolution with a TR = 720 ms. The dMRI data consisted of one 1.25 mm isotropic scan for each participant with 3 shell HARDI type acquisition, including b = 1000, 200, 3000 s/mm<sup>2</sup>, total for 270 non-collinear directions. Spin echo phase reversed images were acquired during the fMRI scanning sessions to enable accurate cross-modal registrations of the T2w and fMRI images to the T1w image in each subject and standard dual gradient echo field maps were acquired to correct T1w and T2w images for readout distortion. Additionally, the spin echo field maps acquired during the fMRI session (with matched geometry and echo spacing to the gradient echo fMRI data) were used to compute a more accurate fMRI bias field correction and to segment regions of gradient echo signal loss.</p><p id="P42">Subjects were considered for data exclusion based on the mean and mean absolute deviation of the relative root-mean-square motion across either four rsfMRI scans, resulting in four summary motion measures. If a subject exceeded 1.5 times the interquartile range (in the adverse direction) of the measurement distribution in two or more of these measures, the subject was excluded. In addition, functional runs were flagged for exclusion if more than 25% of frames exceeded 0.2 mm frame-wise displacement (FD_power). These above exclusion criteria were established before performing the analysis, (for similar implementation, see <xref ref-type="bibr" rid="R15">Faskowitz et al., 2020</xref>; <xref ref-type="bibr" rid="R47">Sporns et al., 2021</xref>). The data of 91 participants was excluded because of excessive head motion and the data of another 3 participants was excluded because their resting data did not have all the time points. In total, the data of 245 participants was analysed after exclusions.</p></sec><sec id="S18"><label>4.3.2</label><title>Image acquisition for York non-semantic dataset</title><p id="P43">MRI acquisition protocols have been described previously (<xref ref-type="bibr" rid="R49">Wang et al., 2020</xref>; <xref ref-type="bibr" rid="R50">2021</xref>; <xref ref-type="bibr" rid="R54">2022</xref>; <xref ref-type="bibr" rid="R51">2024a</xref>; <xref ref-type="bibr" rid="R52">2024b</xref>). Structural and functional data were collected on a Siemens Prisma 3T MRI scanner at the York Neuroimaging Centre. The scanning protocols included a T1-weighted MPRAGE sequence with whole-brain coverage. The structural scan used: acquisition matrix of 176 × 256 × 256 and voxel size 1 × 1 × 1 mm<sup>3</sup>, repetition time (TR) = 2300 ms, and echo time (TE) = 2.26 ms. Functional data were acquired using an EPI sequence with an 800 flip angle and using GRAPPA with an acceleration factor of 2 in 3 × 3 × 4 mm voxels in 64-axial slices. The functional scan used: 55 3-mm-thick slices acquired in an interleaved order (with 33% distance factor), TR = 3000 ms, TE = 15 ms, FoV = 192 mm.</p></sec><sec id="S19"><label>4.3.3</label><title>Image acquisition for York semantic dataset</title><p id="P44">MRI acquisition protocols have been described previously (<xref ref-type="bibr" rid="R51">Wang et al., 2024a</xref>; <xref ref-type="bibr" rid="R52">2024b</xref>). Whole brain structural and functional MRI data were acquired using a 3T Siemens MRI scanner utilising a 64-channel head coil, tuned to 123 MHz at York Neuroimaging Centre, University of York. The functional runs were acquired using a multi-band multi-echo (MBME) EPI sequence, each 11.45 minutes long (TR=1.5 s; TEs = 12, 24.83, 37.66 ms; 48 interleaved slices per volume with slice thickness of 3 mm (no slice gap); FoV = 24 cm (resolution matrix = 3×3×3; 80×80); 75° flip angle; 455 volumes per run; 7/8 partial Fourier encoding and GRAPPA (acceleration factor = 3, 36 ref. lines); multi-band acceleration factor = 2). Structural T1-weighted images were acquired using an MPRAGE sequence (TR = 2.3 s, TE = 2.3 s; voxel size = 1×1×1 isotropic; 176 slices; flip angle = 8°; FoV= 256 mm; interleaved slice ordering). We also collected a high-resolution T2-weighted (T2w) scan using an echo-planar imaging sequence (TR = 3.2 s, TE = 56 ms, flip angle = 120°; 176 slices, voxel size = 1×1×1 isotropic; Fov = 256 mm).</p></sec></sec><sec id="S20"><label>4.4</label><title>Image pre-processing</title><sec id="S21"><label>4.4.1</label><title>Image pre-processing of HCP dataset</title><p id="P45">We used HCP’s minimal pre-processing pipelines (<xref ref-type="bibr" rid="R25">Glasser et al., 2013</xref>). Briefly, for each subject, structural images (T1w and T2w) were corrected for spatial distortions. FreeSurfer v5.3 was used for accurate extraction of cortical surfaces and segmentation of subcortical structures (<xref ref-type="bibr" rid="R13">Dale et al., 1999</xref>; <xref ref-type="bibr" rid="R18">Fischl et al., 1999</xref>). To align subcortical structures across subjects, structural images were registered using non-linear volume registration to the Montreal Neurological Institute (MNI152) space. Functional images (rest and task) were corrected for spatial distortions, head motion, and mapped from volume to surface space using ribbon-constrained volume to surface mapping.</p><p id="P46">Subcortical data were also projected to the set of extracted subcortical structure voxels and combined with the surface data to form the standard CIFTI grayordinate space. Data were smoothed by a 2-mm FWHM kernel in the grayordinates space that avoids mixing data across gyral banks for surface data and avoids mixing areal borders for subcortical data. Rest and task fMRI data were additionally identically cleaned for spatially specific noise using spatial ICA+FIX (<xref ref-type="bibr" rid="R42">Salimi-Khorshidi et al., 2014</xref>) and global structured noise using temporal ICA (<xref ref-type="bibr" rid="R24">Glasser et al., 2018</xref>). For accurate cross-subject registration of cortical surfaces, a multimodal surface matching (MSM) algorithm (<xref ref-type="bibr" rid="R41">Robinson et al., 2014</xref>) was used to optimize the alignment of cortical areas based on features from different modalities. MSMSulc (“sulc”: cortical folds average convexity) was used to initialize MSMAll, which then utilized myelin, resting state network, and rfMRI visuotopic maps. Myelin maps were computed using the ratio of T1w/T2w images (<xref ref-type="bibr" rid="R42">Salimi-Khorshidi et al., 2014</xref>). The HCP’s minimally preprocessed data include cortical thickness maps (generated based on the standardized FreeSurfer pipeline with combined T1-/T2-reconstruction). For this study, the standard-resolution cortical thickness maps (32k mesh) were used.</p></sec><sec id="S22"><label>4.4.2</label><title>Image pre-processing of York non-semantic and semantic dataset</title><p id="P47">The York datasets were preprocessed using fMRIPrep 20.2.1 [(<xref ref-type="bibr" rid="R14">Esteban et al., 2018</xref>), RRID:SCR_016216], with detailed methods previously described in (<xref ref-type="bibr" rid="R51">Wang et al., 2024a</xref>, <xref ref-type="bibr" rid="R52">2024b</xref>). In brief, anatomical preprocessing involved intensity non-uniformity correction, skull stripping, segmentation, and surface reconstruction. Spatial normalization to MNI152 templates was performed through nonlinear registration. For each BOLD run, functional data preprocessing followed standard fMRIPrep procedures. This included generating a reference volume, applying fieldmap correction, and co-registering the BOLD reference to anatomical space. Motion correction and slice-time correction were performed. Resampling was done in the surface space - fsaverage, and final data were output in CIFTI grayordinate space. Post-processing of fMRIPrep outputs was performed using eXtensible Connectivity Pipeline (XCP) (<xref ref-type="bibr" rid="R9">Ciric et al., 2018</xref>). Volumes with framewise displacement greater than 0.3 mm were excluded before nuisance regression. A total of 36 nuisance regressors, including motion parameters, global signal, white matter, and CSF signals, were regressed. Residual time-series were band-pass filtered (0.01-0.08 Hz) and smoothed with a 6.0 mm FWHM Gaussian kernel. Detailed information is provided in Supplementary Materials and Methods, <xref ref-type="supplementary-material" rid="SD1">Section 1.1</xref>.</p></sec></sec><sec id="S23"><label>4.5</label><title>Task fMRI analysis</title><sec id="S24"><label>4.5.1</label><title>Individual-specific parcellation</title><p id="P48">To account for anatomical and functional variability, we used a multi-session hierarchical Bayesian model to estimate individual-specific parcellations, following the methods in <xref ref-type="bibr" rid="R30">Kong et al., (2021</xref>, 2019). This approach defines 400 individualized parcels across 17 networks per participant and the individual-specific parcellation showed greater homogeneity than the parcellation using group atlas (Kong et al., 2021a; <xref ref-type="bibr" rid="R51">Wang et al., 2024a</xref>). All subsequent analyses were based on parcel-specific time-series. Detailed information is provided in Supplementary Materials and Methods, <xref ref-type="supplementary-material" rid="SD1">Section 1.2.1</xref>.</p></sec><sec id="S25"><label>4.5.2</label><title>Constructing fMRI FC matrices</title><p id="P49">To investigate how FC varies across tasks, we computed task-based and resting state FC matrices. We opted not to use the traditional psychophysiological interaction (PPI) method for measuring task-state functional connectivity due to its potential to inflate activation-induced task-state functional connectivity, which may identify regions that are active rather than interacting during the task (<xref ref-type="bibr" rid="R11">Cole et al., 2019</xref>). Since task activations can spuriously inflate task-based functional connectivity estimates, it is necessary to correct for task-timing confounds by removing the first-order effect of task-evoked activations (i.e., mean evoked task-related activity, likely active during the task) prior to estimating task-state functional connectivity (likely interacting during the task) (<xref ref-type="bibr" rid="R11">Cole et al., 2019</xref>). Specifically, we fitted the task timing for each task using a finite impulse response (FIR) model, a method that has been shown to reduce both false positives and false negatives in FC estimation (<xref ref-type="bibr" rid="R10">Cocuzza et al., 2020</xref>; <xref ref-type="bibr" rid="R32">McCormick et al., 2022</xref>; <xref ref-type="bibr" rid="R36">Norman-Haignere et al., 2012</xref>). In semantic tasks, approximately 5 timepoints were modeled for each trial. For the non-semantic task, roughly 2.5 timepoints were modeled for each trial.</p><p id="P50">Following task regression, we demeaned the residual time series for each parcel and quantified the FC using Pearson correlation for each participant, task and run. The Pearson correlation coefficients might be inflated due to the temporal autocorrelation in task fMRI time series data (<xref ref-type="bibr" rid="R2">Allefeld et al., 2008</xref>). To address this, we corrected the Pearson correlation using a correction approach, xDF, which accounts for both autocorrelation within each time series as well as instantaneous and lagged cross-correlations between the time series (<xref ref-type="bibr" rid="R1">Afyouni et al., 2019</xref>). This method provides an effective degrees of freedom estimator that addresses cross-correlations, thereby preventing inflation of Pearson correlation coefficients. Our goal was not to remove temporal autocorrelation, but to enhance the precision and reliability of correlation estimates, reducing false functional connectivity between regions. We calculated xDF-adjusted z-scored correlation coefficients to assess the interregional relationships in BOLD time series, resulting in a 400 × 400 functional connectivity matrix for each participant, task, and run. Finally, we averaged these functional connectivity estimates within networks, and between pairs of networks, to construct a network-by-network functional connectivity matrix. The same method was used to calculate the resting-state functional connectivity of the HCP dataset and construct a corresponding network-by-network functional connectivity matrix, except without the task regression step.</p></sec><sec id="S26"><label>4.5.3</label><title>Feature extraction of the time-series data</title><p id="P51">To investigate how the FS patterns vary across tasks, we calculated task-based and resting state FS using the extracted features. To extract the features of the time-series required for this analysis, we used the time-series analysis toolbox (hctsa) (<xref ref-type="bibr" rid="R23">Fulcher et al., 2013</xref>; <xref ref-type="bibr" rid="R22">Fulcher and Jones, 2017</xref>). With this tool, we transformed each time-series in the dataset into a set of over 7,700 features, which include, but are not limited to, distributional properties, entropy and variability, autocorrelation, time-delay embeddings, and nonlinear properties of a given time-series (see <xref ref-type="fig" rid="F1">Fig. 1</xref>; <xref ref-type="bibr" rid="R21">Fulcher, 2018</xref>; <xref ref-type="bibr" rid="R23">Fulcher et al., 2013</xref>). We extracted features from the parcellated fMRI time-series of each participant, each task, and each run separately. After the feature extraction procedure, we removed the outputs of the operations that produced errors and normalized the remaining features (about 6900 features) across parcels using an outlier-robust sigmoidal transform. The resulting normalized feature matrix (400 parcels × ~7000 features × 4 runs) was used to predict networks labels of parcels to identify the DAN subnetwork with varying interaction patterns across tasks (<xref ref-type="sec" rid="S27">Method 4.5.4</xref>) and to construct FS matrix for further analysis (<xref ref-type="sec" rid="S27">Method 4.5.4</xref>).</p></sec><sec id="S27"><label>4.5.4</label><title>Constructing fMRI FS matrices</title><p id="P52">To investigate how FS patterns vary across tasks, we calculated task-based and resting state FS matrices. Specifically, we calculated Pearson correlation coefficients of the extracted features, which represented the pairwise FS between all possible combinations of brain parcels (see <xref ref-type="fig" rid="F1">Fig. 1</xref>). This resulted in a 400 by 400 FS matrix for each run each task for each participant. Finally, to construct a network-by-network FS matrix, we averaged the estimates of FS within networks and between pairs of networks for further analysis.</p><p id="P53">To investigate whether functionally connected regions display similar features, we calculated Pearson correlations coefficients for FS within and between networks defined by resting state FC. Then we tested whether the correlations for FS within networks were greater than the correlations between networks.</p><p id="P54">Additionally, we estimated the similarity between FC and FS by calculating their correlations at rest and for each task. To control for multiple comparison, we FWE-corrected the p values using permutation-based maximum r values. Specifically, we created a null distribution using permutation for each task and chose the maximum values among all the tasks. We then compared the observed correlation value with the null distribution to examine whether the correlation between FC and FS was significantly greater than that expected from null distribution.</p></sec><sec id="S28"><label>4.5.5</label><title>Dimension reduction analysis of FC and FS</title><p id="P55">To examine whether FC and FS captured similar principal components, we performed dimension reduction analysis on both resting state FC matrix and FS matrix derived from the HCP dataset. For the FC matrix, we first calculated resting state FC for each run of each participant, as detailed in Method section 2.5.2. Subsequently, these individual connectivity matrices were then averaged to calculate a group-level connectivity matrix. We extracted ten group-level gradients from the group-level connectivity matrix (dimension reduction technique = diffusion embedding, kernel = None, sparsity = 0.9), in line with previous studies (<xref ref-type="bibr" rid="R33">Mckeown et al., 2020</xref>; <xref ref-type="bibr" rid="R49">Wang et al., 2020</xref>) using the Brainspace Toolbox (<xref ref-type="bibr" rid="R48">Vos de Wael et al., 2020</xref>). This analysis resulted in ten group-level gradients explaining maximal whole-brain connectivity variance in descending order. A parallel analysis was performed for the FS matrix, employing identical procedures except for the input, which consisted of the FS matrix as delineated in Method Section 2.5.4. This analysis resulted in ten group-level gradients explaining maximal whole-brain FS variance in descending order. We retained the components explaining the most variance by looking at the eigenvalues of each component in the scree plots shown in <xref ref-type="fig" rid="F3">Fig 3</xref>.</p><p id="P56">Finally, we examined the similarities between the first three components captured by FC and FS, respectively via calculating the Pearson correlations between corresponding components. Due to the spatial autocorrelation present in each principal component, we created a null distribution using spin permutation implemented in BrainSMASH (<xref ref-type="bibr" rid="R8">Burt et al., 2020</xref>). This approach simulates brain maps, constrained by empirical data, that preserve the spatial autocorrelation of cortical parcellated brain maps. We then compared the observed correlation value with the null distribution for left hemisphere to examine whether the correlation between two components of parcels in the left hemisphere was significantly greater than that expected from spatial autocorrelation alone. Similarly, we examined the correlation between two components of parcels in the right hemisphere using the same methods. This analysis was performed for the two hemispheres separately because the geodesic distance between parcels was used to generate the spatial-autocorrelation-preserving surrogate maps when creating the null distribution. It was only possible to measure within-hemisphere geodesic distance between parcels because the left and right hemisphere surface maps were not on the same mesh.</p></sec><sec id="S29"><label>4.5.6</label><title>Timescale analysis</title><p id="P57">The first component captured by FS matrix was similar to the timescale gradient map reported by (<xref ref-type="bibr" rid="R40">Raut et al.,2020</xref>), as determined by visual comparison. To further understand this component, we calculated its correlation with the intrinsic timescale gradient map, which represents the temporal duration of ongoing inputs that the brain can process. The intrinsic timescale for each parcel was characterized by the decay of the temporal autocorrelation function, as the time taken for the autocorrelation function to reach a threshold of r = 0.5 (i.e., half of the full width at half maximum), consistent with prior studies (<xref ref-type="bibr" rid="R35">Murray et al., 2014</xref>; <xref ref-type="bibr" rid="R40">Raut et al., 2020</xref>). A higher value of the intrinsic timescale indicates longer ongoing inputs that the parcel can process. Given the spatial autocorrelation present in this component and the timescale gradient map, we created a null distribution using spin permutation implemented in BrainSMASH (<xref ref-type="bibr" rid="R8">Burt et al., 2020</xref>). We subsequently compared the observed correlation value with the null distribution for each hemisphere to determine whether the real correlations were significantly greater than that expected by spatial autocorrelation alone.</p></sec><sec id="S30"><label>4.5.7</label><title>Calculating the correlations across tasks in FC and in FS</title><p id="P58">To test whether FS was more sensitive to task modulation than FC, we calculated correlations across tasks for both measures and compared their sensitivities by assessing if FS showed weaker correlations than FC. We used two methods: (i) we first calculated Pearson correlations (r1) for FC across tasks for each possible pair of tasks at the group level (for instance, between the spatial working memory and math tasks) using the task mean FC matrices. Then, we repeated the process for FS (r2), using the task mean FS matrices. Finally, we then compared the resulting correlation values (r1 versus r2). (ii) We calculated the Pearson correlation coefficients between the FC matrix of the spatial working memory task and the FC matrix of math task at the individual level for each participant given that each participant completed both spatial working memory task and math task. Then we repeated the process for FS, using the FS matrix of each participant. Finally, we converted the r values to z values using Fisher transformation and compared the z values of the FC with the ones of the FS by conducting paired t-tests. The same procedures were applied to the two semantic tasks (semantic feature matching versus association).</p></sec><sec id="S31"><label>4.5.8</label><title>Classification analysis – decoding task labels using FS matrix</title><p id="P59">To determine whether feature similarity captures task information, we conducted classification analyses to predict task labels (spatial working memory versus math) using FS matrices of the non-semantic tasks of all the participants, respectively. We employed scikit-learn’s (<xref ref-type="bibr" rid="R39">Pedregosa et al., 2011</xref>) linear support vector machine classifier (SVC) with 5-fold cross-validation to avoid overfitting and ensure reliable performance. To assess statistical significance, we performed permutation tests by shuffling task labels 1,000 times, creating a null distribution for comparison (<xref ref-type="bibr" rid="R37">Ojala and Garriga, 2010</xref>). The same approach was used for semantic tasks (semantic feature matching versus. semantic association) using feature similarity matrices of semantic tasks.</p></sec><sec id="S32"><label>4.5.9</label><title>Comparing FC difference and FS difference between networks across tasks</title><p id="P60">To investigate whether FS captured varying interaction patterns across tasks that could not be captured by FC, we first calculated the average FC between DAN-A and Visual network and between DAN-A and DMN, across all runs per participant per task. Subsequently, we calculated the relative FC difference by subtracting the FC between DAN-A and DMN from the FC between DAN-A and Visual network. Finally, we conducted paired-t tests for each task to examine the significance of the FC difference between network pairs. We further investigated whether the task influenced the FC difference between network pairs using the maximum/minimum permutation test. We calculated the mean FC difference between DAN-A and Visual network versus DAN-A and DMN for each task and calculated the mean FC difference between each task pair. To access statistical significance, we permutated the task label 10000 times and then calculated the mean FC difference between these two tasks to build a null distribution for each task pair. To control the family-wise error (FWE) rate (p = 0.05, FWE-corrected) given the inclusion of multiple task pairs, we utilized the permutation-based maximum mean FC difference and minimum mean FC difference values in the null distribution for each task pair. To evaluate significance, if the observed mean difference value was positive, we counted the percentage of times that mean difference values in the maximum null distribution were greater than the observed ‘true’ mean difference values. Conversely, if the observed mean difference value was negative, we counted the percentage of times of mean difference values in the minimum null distribution were less than the observed ‘true’ mean difference values.</p><p id="P61">We then examined whether task influences the FS differences between targeted network pairs (DAN-A-Visual versus DAN-A-DMN) using the same procedures but applied to FS. Our results showed that FS is more sensitive to task modulation than FC in the DAN-A-Visual and DAN-A-DMN comparison. To assess whether this holds for other networks, we repeated the analysis, comparing FPCN-A-Visual versus FPCN-A-DMN.</p></sec><sec id="S33"><label>4.5.10</label><title>Classification analysis – decoding network labels of parcels</title><p id="P62">Given heterogeneity of DAN, we used a data-driven approach to identify the subnetwork most likely to vary in interaction patterns during tasks using the extracted features. Specifically, we conducted a classification analysis on a normalized feature matrix (400 parcels by about 7000 features by 4 runs) to decode parcel network labels. After confirming accurate classification, we examined the confusion matrix to identify classification errors (Detailed information is provided in Supplementary Materials and Methods, <xref ref-type="supplementary-material" rid="SD1">Section 1.2.3</xref>). This allowed us to explore network similarity, as functionally similar networks are more likely to be misclassified.</p></sec></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplemental material</label><media xlink:href="EMS200148-supplement-Supplemental_material.pdf" mimetype="application" mime-subtype="pdf" id="d14aAcFbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S34"><title>Acknowledgements</title><p>We are grateful to Pradeepa Ruwan and Antonia De Freitas for piloting the experiment. We would like to thank Ben D Fulcher for providing codes and a guide to help us extract the features using hctsa. X. W. discloses support for the research of this work from National Natural Science Foundation of China (Grant Number. 32300881). Y. D. discloses support for the publication of this work from the STI 2030—Major Projects (Grant Number. 2021ZD0201500), the National Natural Science Foundation of China (Grant No. 31822024), and Scientific Foundation of Institute of Psychology, Chinese Academy of Sciences (Grant Number. E2CX3625CX). E. J. discloses support for the research of this work from a European Research Council Consolidator grant (Project ID: 771863 - FLEXSEM). N. L. discloses support for the research of this work from National Natural Science Foundation of China (Grant Number. 32471111).</p></ack><sec id="S35"><label>4.6</label><title>Data and code Accessibility</title><p id="P63">The HCP data is publicly available (<ext-link ext-link-type="uri" xlink:href="https://www.humanconnectome.org/">https://www.humanconnectome.org/</ext-link>). The data collected at the University of York is not currently available due to insufficient consent. Researchers wishing to access the data should contact the Chair of the Research Ethics Committee of the York Neuroimaging Centre. Data will be released when this is possible under the terms of the UK GDPR. Analysis code for this study is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/Xiuyi-Wang/Feature_similarity_Project">https://github.com/Xiuyi-Wang/Feature_similarity_Project</ext-link>.</p></sec><fn-group><fn fn-type="conflict" id="FN1"><p id="P64"><bold>Declaration of interests</bold></p><p id="P65">The authors declare no competing interests.</p></fn></fn-group><ref-list><ref id="R1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Afyouni</surname><given-names>S</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name><name><surname>Nichols</surname><given-names>TE</given-names></name></person-group><article-title>Effective degrees of freedom of the Pearson’s correlation coefficient under autocorrelation</article-title><source>Neuroimage</source><year>2019</year><volume>199</volume><fpage>609</fpage><lpage>625</lpage><pub-id pub-id-type="pmcid">PMC6693558</pub-id><pub-id pub-id-type="pmid">31158478</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.05.011</pub-id></element-citation></ref><ref id="R2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allefeld</surname><given-names>C</given-names></name><name><surname>Graben</surname><given-names>PB</given-names></name><name><surname>Kurths</surname><given-names>J</given-names></name></person-group><article-title>Advanced Methods of Electrophysiological Signal Analysis and Symbol Grounding</article-title><source>Nova</source><year>2008</year><fpage>276</fpage><lpage>296</lpage></element-citation></ref><ref id="R3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barch</surname><given-names>DM</given-names></name><name><surname>Burgess</surname><given-names>GC</given-names></name><name><surname>Harms</surname><given-names>MP</given-names></name><name><surname>Petersen</surname><given-names>SE</given-names></name><name><surname>Schlaggar</surname><given-names>BL</given-names></name><name><surname>Corbetta</surname><given-names>M</given-names></name><name><surname>Glasser</surname><given-names>MF</given-names></name><name><surname>Curtiss</surname><given-names>S</given-names></name><name><surname>Dixit</surname><given-names>S</given-names></name><name><surname>Feldt</surname><given-names>C</given-names></name><name><surname>Nolan</surname><given-names>D</given-names></name><etal/></person-group><article-title>Function in the human connectome: Task-fMRI and individual differences in behavior</article-title><source>Neuroimage</source><year>2013</year><volume>80</volume><fpage>169</fpage><lpage>189</lpage><pub-id pub-id-type="pmcid">PMC4011498</pub-id><pub-id pub-id-type="pmid">23684877</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.05.033</pub-id></element-citation></ref><ref id="R4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blank</surname><given-names>I</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name><name><surname>Fedorenko</surname><given-names>E</given-names></name></person-group><article-title>A functional dissociation between language and multiple-demand systems revealed in patterns of BOLD signal fluctuations</article-title><source>J Neurophysiol</source><year>2014</year><volume>112</volume><fpage>1105</fpage><lpage>1118</lpage><pub-id pub-id-type="pmcid">PMC4122731</pub-id><pub-id pub-id-type="pmid">24872535</pub-id><pub-id pub-id-type="doi">10.1152/jn.00884.2013</pub-id></element-citation></ref><ref id="R5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blank</surname><given-names>IA</given-names></name><name><surname>Fedorenko</surname><given-names>E</given-names></name></person-group><article-title>No evidence for differences among language regions in their temporal receptive windows</article-title><source>Neuroimage</source><year>2020</year><volume>219</volume><pub-id pub-id-type="pmcid">PMC9392830</pub-id><pub-id pub-id-type="pmid">32407994</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.116925</pub-id></element-citation></ref><ref id="R6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buckner</surname><given-names>RL</given-names></name><name><surname>DiNicola</surname><given-names>LM</given-names></name></person-group><article-title>The brain’s default network: updated anatomy, physiology and evolving insights</article-title><source>Nature Reviews Neuroscience</source><year>2019</year><volume>20</volume><fpage>593</fpage><lpage>608</lpage><comment>2019 20:10</comment><pub-id pub-id-type="pmid">31492945</pub-id></element-citation></ref><ref id="R7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buckner</surname><given-names>RL</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name></person-group><article-title>Macroscale cortical organization and a default-like apex transmodal network in the marmoset monkey</article-title><source>Nat Commun</source><year>2019</year><volume>10</volume><elocation-id>1976</elocation-id><pub-id pub-id-type="pmcid">PMC6488644</pub-id><pub-id pub-id-type="pmid">31036823</pub-id><pub-id pub-id-type="doi">10.1038/s41467-019-09812-8</pub-id></element-citation></ref><ref id="R8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burt</surname><given-names>JB</given-names></name><name><surname>Helmer</surname><given-names>M</given-names></name><name><surname>Shinn</surname><given-names>M</given-names></name><name><surname>Anticevic</surname><given-names>A</given-names></name><name><surname>Murray</surname><given-names>JD</given-names></name></person-group><article-title>Generative modeling of brain maps with spatial autocorrelation</article-title><source>Neuroimage</source><year>2020</year><volume>220</volume><elocation-id>117038</elocation-id><pub-id pub-id-type="pmid">32585343</pub-id></element-citation></ref><ref id="R9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ciric</surname><given-names>R</given-names></name><name><surname>Rosen</surname><given-names>AFG</given-names></name><name><surname>Erus</surname><given-names>G</given-names></name><name><surname>Cieslak</surname><given-names>M</given-names></name><name><surname>Adebimpe</surname><given-names>A</given-names></name><name><surname>Cook</surname><given-names>PA</given-names></name><name><surname>Bassett</surname><given-names>DS</given-names></name><name><surname>Davatzikos</surname><given-names>C</given-names></name><name><surname>Wolf</surname><given-names>DH</given-names></name><name><surname>Satterthwaite</surname><given-names>TD</given-names></name></person-group><article-title>Mitigating head motion artifact in functional connectivity MRI</article-title><source>Nature Protocols</source><year>2018</year><volume>13</volume><fpage>2801</fpage><lpage>2826</lpage><elocation-id>2018 13:12</elocation-id><pub-id pub-id-type="pmcid">PMC8161527</pub-id><pub-id pub-id-type="pmid">30446748</pub-id><pub-id pub-id-type="doi">10.1038/s41596-018-0065-y</pub-id></element-citation></ref><ref id="R10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cocuzza</surname><given-names>CV</given-names></name><name><surname>Ito</surname><given-names>T</given-names></name><name><surname>Schultz</surname><given-names>D</given-names></name><name><surname>Bassett</surname><given-names>DS</given-names></name><name><surname>Cole</surname><given-names>MW</given-names></name></person-group><article-title>Flexible coordinator and switcher hubs for adaptive task control</article-title><source>Journal of Neuroscience</source><year>2020</year><volume>40</volume><fpage>6949</fpage><lpage>6968</lpage><pub-id pub-id-type="pmcid">PMC7470914</pub-id><pub-id pub-id-type="pmid">32732324</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2559-19.2020</pub-id></element-citation></ref><ref id="R11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cole</surname><given-names>MW</given-names></name><name><surname>Ito</surname><given-names>T</given-names></name><name><surname>Schultz</surname><given-names>D</given-names></name><name><surname>Mill</surname><given-names>R</given-names></name><name><surname>Chen</surname><given-names>R</given-names></name><name><surname>Cocuzza</surname><given-names>C</given-names></name></person-group><article-title>Task activations produce spurious but systematic inflation of task functional connectivity estimates</article-title><source>Neuroimage</source><year>2019</year><volume>189</volume><fpage>1</fpage><pub-id pub-id-type="pmcid">PMC6422749</pub-id><pub-id pub-id-type="pmid">30597260</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.12.054</pub-id></element-citation></ref><ref id="R12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dale</surname><given-names>AM</given-names></name></person-group><article-title>Optimal Experimental Design for Event-Related fMRI</article-title><source>Hum Brain Mapping</source><year>1999</year><pub-id pub-id-type="pmcid">PMC6873302</pub-id><pub-id pub-id-type="pmid">10524601</pub-id><pub-id pub-id-type="doi">10.1002/(SICI)1097-0193(1999)8:2/3&amp;#x0003c;109::AID-HBM7&amp;#x0003e;3.0.CO;2-W</pub-id></element-citation></ref><ref id="R13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dale</surname><given-names>AM</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Sereno</surname><given-names>MI</given-names></name></person-group><article-title>Cortical Surface-Based Analysis</article-title><source>Neuroimage</source><year>1999</year><volume>9</volume><fpage>179</fpage><lpage>194</lpage><pub-id pub-id-type="pmid">9931268</pub-id></element-citation></ref><ref id="R14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Esteban</surname><given-names>O</given-names></name><name><surname>Markiewicz</surname><given-names>C</given-names></name><name><surname>Blair</surname><given-names>RW</given-names></name><name><surname>Moodie</surname><given-names>C</given-names></name><name><surname>Isik</surname><given-names>AI</given-names></name><name><surname>Erramuzpe Aliaga</surname><given-names>A</given-names></name><name><surname>Kent</surname><given-names>J</given-names></name><name><surname>Goncalves</surname><given-names>M</given-names></name><name><surname>DuPre</surname><given-names>E</given-names></name><name><surname>Snyder</surname><given-names>M</given-names></name><name><surname>Oya</surname><given-names>H</given-names></name><etal/></person-group><article-title>{fMRIPrep}: a robust preprocessing pipeline for functional {MRI}</article-title><source>Nat Methods</source><year>2018</year><pub-id pub-id-type="pmcid">PMC6319393</pub-id><pub-id pub-id-type="pmid">30532080</pub-id><pub-id pub-id-type="doi">10.1038/s41592-018-0235-4</pub-id></element-citation></ref><ref id="R15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faskowitz</surname><given-names>J</given-names></name><name><surname>Esfahlani</surname><given-names>FZ</given-names></name><name><surname>Jo</surname><given-names>Y</given-names></name><name><surname>Sporns</surname><given-names>O</given-names></name><name><surname>Betzel</surname><given-names>RF</given-names></name></person-group><article-title>Edge-centric functional network representations of human cerebral cortex reveal overlapping system-level architecture</article-title><source>Nat Neurosci</source><year>2020</year><volume>23</volume><fpage>1644</fpage><lpage>1654</lpage><pub-id pub-id-type="pmid">33077948</pub-id></element-citation></ref><ref id="R16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fedorenko</surname><given-names>E</given-names></name><name><surname>Behr</surname><given-names>MK</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name></person-group><article-title>Functional specificity for high-level linguistic processing in the human brain</article-title><source>Proceedings of the National Academy of Sciences</source><year>2011</year><volume>108</volume><fpage>16428</fpage><lpage>16433</lpage><pub-id pub-id-type="pmcid">PMC3182706</pub-id><pub-id pub-id-type="pmid">21885736</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1112937108</pub-id></element-citation></ref><ref id="R17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fedorenko</surname><given-names>E</given-names></name><name><surname>Duncan</surname><given-names>J</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name></person-group><article-title>Broad domain generality in focal regions of frontal and parietal cortex</article-title><source>Proceedings of the National Academy of Sciences</source><year>2013</year><volume>110</volume><fpage>16616</fpage><lpage>16621</lpage><pub-id pub-id-type="pmcid">PMC3799302</pub-id><pub-id pub-id-type="pmid">24062451</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1315235110</pub-id></element-citation></ref><ref id="R18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Sereno</surname><given-names>MI</given-names></name><name><surname>Dale</surname><given-names>AM</given-names></name></person-group><article-title>Cortical surface-based analysis: II. Inflation, flattening, and a surface-based coordinate system</article-title><source>Neuroimage</source><year>1999</year><pub-id pub-id-type="pmid">9931269</pub-id></element-citation></ref><ref id="R19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fox</surname><given-names>MD</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Vincent</surname><given-names>JL</given-names></name><name><surname>Corbetta</surname><given-names>M</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Raichle</surname><given-names>ME</given-names></name></person-group><article-title>The human brain is intrinsically organized into dynamic, anticorrelated functional networks</article-title><source>PNAS</source><year>2005</year><month>July</month><pub-id pub-id-type="pmcid">PMC1157105</pub-id><pub-id pub-id-type="pmid">15976020</pub-id><pub-id pub-id-type="doi">10.1073/pnas.0504136102</pub-id></element-citation></ref><ref id="R20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name></person-group><article-title>Dynamic causal modeling and Granger causality Comments on: the identification of interacting networks in the brain using fMRI: model selection, causality and deconvolution</article-title><source>Neuroimage</source><year>2011</year><volume>58</volume><fpage>303</fpage><lpage>5</lpage><comment>author reply 310-1</comment><pub-id pub-id-type="pmcid">PMC3183826</pub-id><pub-id pub-id-type="pmid">19770049</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.09.031</pub-id></element-citation></ref><ref id="R21"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fulcher</surname><given-names>BD</given-names></name></person-group><source>Feature-Based Time-Series AnalysisFeature Engineering for Machine Learning and Data Analytics</source><publisher-name>CRC Press</publisher-name><year>2018</year><fpage>87</fpage><lpage>116</lpage><pub-id pub-id-type="doi">10.1201/9781315181080-4</pub-id></element-citation></ref><ref id="R22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fulcher</surname><given-names>BD</given-names></name><name><surname>Jones</surname><given-names>NS</given-names></name></person-group><article-title>hctsa: A Computational Framework for Automated Time-Series Phenotyping Using Massive Feature Extraction</article-title><source>Cell Syst</source><year>2017</year><volume>5</volume><fpage>527</fpage><lpage>531</lpage><elocation-id>e3</elocation-id><pub-id pub-id-type="pmid">29102608</pub-id></element-citation></ref><ref id="R23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fulcher</surname><given-names>BD</given-names></name><name><surname>Little</surname><given-names>MA</given-names></name><name><surname>Jones</surname><given-names>NS</given-names></name></person-group><article-title>Highly comparative time-series analysis: the empirical structure of time series and their methods</article-title><source>J R Soc Interface</source><year>2013</year><volume>10</volume><elocation-id>20130048</elocation-id><pub-id pub-id-type="pmcid">PMC3645413</pub-id><pub-id pub-id-type="pmid">23554344</pub-id><pub-id pub-id-type="doi">10.1098/rsif.2013.0048</pub-id></element-citation></ref><ref id="R24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glasser</surname><given-names>MF</given-names></name><name><surname>Coalson</surname><given-names>TS</given-names></name><name><surname>Bijsterbosch</surname><given-names>JD</given-names></name><name><surname>Harrison</surname><given-names>SJ</given-names></name><name><surname>Harms</surname><given-names>MP</given-names></name><name><surname>Anticevic</surname><given-names>A</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name></person-group><article-title>Using temporal ICA to selectively remove global noise while preserving global signal in functional MRI data</article-title><source>Neuroimage</source><year>2018</year><volume>181</volume><fpage>692</fpage><lpage>717</lpage><pub-id pub-id-type="pmcid">PMC6237431</pub-id><pub-id pub-id-type="pmid">29753843</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.04.076</pub-id></element-citation></ref><ref id="R25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glasser</surname><given-names>MF</given-names></name><name><surname>Sotiropoulos</surname><given-names>SN</given-names></name><name><surname>Wilson</surname><given-names>JA</given-names></name><name><surname>Coalson</surname><given-names>TS</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Andersson</surname><given-names>JL</given-names></name><name><surname>Xu</surname><given-names>J</given-names></name><name><surname>Jbabdi</surname><given-names>S</given-names></name><name><surname>Webster</surname><given-names>M</given-names></name><name><surname>Polimeni</surname><given-names>JR</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name><etal/></person-group><article-title>The minimal preprocessing pipelines for the Human Connectome Project</article-title><source>Neuroimage</source><year>2013</year><volume>80</volume><fpage>105</fpage><lpage>124</lpage><pub-id pub-id-type="pmcid">PMC3720813</pub-id><pub-id pub-id-type="pmid">23668970</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.04.127</pub-id></element-citation></ref><ref id="R26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Golesorkhi</surname><given-names>M</given-names></name><name><surname>Gomez-Pilar</surname><given-names>J</given-names></name><name><surname>Zilio</surname><given-names>F</given-names></name><name><surname>Berberian</surname><given-names>N</given-names></name><name><surname>Wolff</surname><given-names>A</given-names></name><name><surname>Yagoub</surname><given-names>MCE</given-names></name><name><surname>Northoff</surname><given-names>G</given-names></name></person-group><article-title>The brain and its time: intrinsic neural timescales are key for input processing</article-title><source>Commun Biol</source><year>2021</year><pub-id pub-id-type="pmcid">PMC8368044</pub-id><pub-id pub-id-type="pmid">34400800</pub-id><pub-id pub-id-type="doi">10.1038/s42003-021-02483-6</pub-id></element-citation></ref><ref id="R27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>González-García</surname><given-names>C</given-names></name><name><surname>Flounders</surname><given-names>MW</given-names></name><name><surname>Chang</surname><given-names>R</given-names></name><name><surname>Baria</surname><given-names>AT</given-names></name><name><surname>He</surname><given-names>BJ</given-names></name></person-group><article-title>Content-specific activity in frontoparietal and default-mode networks during prior-guided visual perception</article-title><source>Elife</source><year>2018</year><volume>7</volume><pub-id pub-id-type="pmcid">PMC6067880</pub-id><pub-id pub-id-type="pmid">30063006</pub-id><pub-id pub-id-type="doi">10.7554/eLife.36068</pub-id></element-citation></ref><ref id="R28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Honey</surname><given-names>CJ</given-names></name><name><surname>Thesen</surname><given-names>T</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name><name><surname>Silbert</surname><given-names>LJ</given-names></name><name><surname>Carlson</surname><given-names>CE</given-names></name><name><surname>Devinsky</surname><given-names>O</given-names></name><name><surname>Doyle</surname><given-names>WK</given-names></name><name><surname>Rubin</surname><given-names>N</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><article-title>Slow Cortical Dynamics and the Accumulation of Information over Long Timescales</article-title><source>Neuron</source><year>2012</year><volume>76</volume><fpage>423</fpage><lpage>434</lpage><pub-id pub-id-type="pmcid">PMC3517908</pub-id><pub-id pub-id-type="pmid">23083743</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2012.08.011</pub-id></element-citation></ref><ref id="R29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ito</surname><given-names>T</given-names></name><name><surname>Hearne</surname><given-names>LJ</given-names></name><name><surname>Cole</surname><given-names>MW</given-names></name></person-group><article-title>A cortical hierarchy of localized and distributed processes revealed via dissociation of task activations, connectivity changes, and intrinsic timescales</article-title><source>Neuroimage</source><year>2020</year><volume>221</volume><elocation-id>117141</elocation-id><pub-id pub-id-type="pmcid">PMC7779074</pub-id><pub-id pub-id-type="pmid">32663642</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117141</pub-id></element-citation></ref><ref id="R30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kong</surname><given-names>R</given-names></name><name><surname>Yang</surname><given-names>Q</given-names></name><name><surname>Gordon</surname><given-names>E</given-names></name><name><surname>Xue</surname><given-names>A</given-names></name><name><surname>Yan</surname><given-names>X</given-names></name><name><surname>Orban</surname><given-names>C</given-names></name><name><surname>Zuo</surname><given-names>X-N</given-names></name><name><surname>Spreng</surname><given-names>N</given-names></name><name><surname>Ge</surname><given-names>T</given-names></name><name><surname>Holmes</surname><given-names>A</given-names></name><name><surname>Eickhoff</surname><given-names>S</given-names></name><etal/></person-group><article-title>Individual-Specific Areal-Level Parcellations Improve Functional Connectivity Prediction of Behavior</article-title><source>Cerebral Cortex</source><year>2021</year><volume>31</volume><fpage>4477</fpage><lpage>4500</lpage><pub-id pub-id-type="pmcid">PMC8757323</pub-id><pub-id pub-id-type="pmid">33942058</pub-id><pub-id pub-id-type="doi">10.1093/cercor/bhab101</pub-id></element-citation></ref><ref id="R31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Ghosh</surname><given-names>SS</given-names></name><name><surname>Goulas</surname><given-names>A</given-names></name><name><surname>Falkiewicz</surname><given-names>M</given-names></name><name><surname>Huntenburg</surname><given-names>JM</given-names></name><name><surname>Langs</surname><given-names>G</given-names></name><name><surname>Bezgin</surname><given-names>G</given-names></name><name><surname>Eickhoff</surname><given-names>SB</given-names></name><name><surname>Castellanos</surname><given-names>FX</given-names></name><name><surname>Petrides</surname><given-names>M</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><etal/></person-group><article-title>Situating the default-mode network along a principal gradient of macroscale cortical organization</article-title><source>Proceedings of the National Academy of Sciences</source><year>2016</year><volume>113</volume><fpage>12574</fpage><lpage>12579</lpage><pub-id pub-id-type="pmcid">PMC5098630</pub-id><pub-id pub-id-type="pmid">27791099</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1608282113</pub-id></element-citation></ref><ref id="R32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McCormick</surname><given-names>EM</given-names></name><name><surname>Arnemann</surname><given-names>KL</given-names></name><name><surname>Ito</surname><given-names>T</given-names></name><name><surname>Hanson</surname><given-names>SJ</given-names></name><name><surname>Cole</surname><given-names>MW</given-names></name></person-group><article-title>Latent functional connectivity underlying multiple brain states</article-title><source>Network Neuroscience</source><year>2022</year><fpage>1</fpage><lpage>42</lpage><pub-id pub-id-type="pmcid">PMC9208020</pub-id><pub-id pub-id-type="pmid">35733420</pub-id><pub-id pub-id-type="doi">10.1162/netn_a_00234</pub-id></element-citation></ref><ref id="R33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mckeown</surname><given-names>B</given-names></name><name><surname>Strawson</surname><given-names>WH</given-names></name><name><surname>Wang</surname><given-names>H-T</given-names></name><name><surname>Karapanagiotidis</surname><given-names>T</given-names></name><name><surname>de Wael</surname><given-names>Vos</given-names></name><name><surname>Benkarim</surname><given-names>O</given-names></name><name><surname>Turnbull</surname><given-names>A</given-names></name><name><surname>Margulies</surname><given-names>D</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>McCall</surname><given-names>C</given-names></name><name><surname>Bernhardt</surname><given-names>B</given-names></name><etal/></person-group><article-title>The relationship between individual variation in macroscale functional gradients and distinct aspects of ongoing thought</article-title><source>Neuroimage</source><year>2020</year><volume>220</volume><elocation-id>117072</elocation-id><pub-id pub-id-type="pmcid">PMC7573534</pub-id><pub-id pub-id-type="pmid">32585346</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117072</pub-id></element-citation></ref><ref id="R34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mesulam</surname><given-names>M-M</given-names></name></person-group><article-title>From sensation to cognition</article-title><source>Brain</source><year>1998</year><pub-id pub-id-type="pmid">9648540</pub-id></element-citation></ref><ref id="R35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murray</surname><given-names>JD</given-names></name><name><surname>Bernacchia</surname><given-names>A</given-names></name><name><surname>Freedman</surname><given-names>DJ</given-names></name><name><surname>Romo</surname><given-names>R</given-names></name><name><surname>Wallis</surname><given-names>JD</given-names></name><name><surname>Cai</surname><given-names>X</given-names></name><name><surname>Padoa-Schioppa</surname><given-names>C</given-names></name><name><surname>Pasternak</surname><given-names>T</given-names></name><name><surname>Seo</surname><given-names>H</given-names></name><name><surname>Lee</surname><given-names>D</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><article-title>A hierarchy of intrinsic timescales across primate cortex</article-title><source>Nat Neurosci</source><year>2014</year><volume>17</volume><fpage>1661</fpage><lpage>1663</lpage><pub-id pub-id-type="pmcid">PMC4241138</pub-id><pub-id pub-id-type="pmid">25383900</pub-id><pub-id pub-id-type="doi">10.1038/nn.3862</pub-id></element-citation></ref><ref id="R36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norman-Haignere</surname><given-names>SV</given-names></name><name><surname>McCarthy</surname><given-names>G</given-names></name><name><surname>Chun</surname><given-names>MM</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name></person-group><article-title>Category-Selective Background Connectivity in Ventral Visual Cortex</article-title><source>Cerebral Cortex</source><year>2012</year><volume>22</volume><fpage>391</fpage><lpage>402</lpage><pub-id pub-id-type="pmcid">PMC3256407</pub-id><pub-id pub-id-type="pmid">21670097</pub-id><pub-id pub-id-type="doi">10.1093/cercor/bhr118</pub-id></element-citation></ref><ref id="R37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ojala</surname><given-names>M</given-names></name><name><surname>Garriga</surname><given-names>GC</given-names></name></person-group><article-title>Permutation tests for studying classifier performance</article-title><source>Journal of Machine Learning Research</source><year>2010</year></element-citation></ref><ref id="R38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Reilly</surname><given-names>JX</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name><name><surname>Johansen-Berg</surname><given-names>H</given-names></name></person-group><article-title>Tools of the trade: Psychophysiological interactions and functional connectivity</article-title><source>Soc Cogn Affect Neurosci</source><year>2012</year><volume>7</volume><fpage>604</fpage><lpage>609</lpage><pub-id pub-id-type="pmcid">PMC3375893</pub-id><pub-id pub-id-type="pmid">22569188</pub-id><pub-id pub-id-type="doi">10.1093/scan/nss055</pub-id></element-citation></ref><ref id="R39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F</given-names></name><name><surname>Michel</surname><given-names>V</given-names></name><name><surname>Grisel</surname><given-names>O</given-names></name><name><surname>Blondel</surname><given-names>M</given-names></name><name><surname>Prettenhofer</surname><given-names>P</given-names></name><name><surname>Weiss</surname><given-names>R</given-names></name><name><surname>Vanderplas</surname><given-names>J</given-names></name><name><surname>Cournapeau</surname><given-names>D</given-names></name><name><surname>Pedregosa</surname><given-names>F</given-names></name><name><surname>Varoquaux</surname><given-names>G</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name><etal/></person-group><article-title>Scikit-learn: Machine Learning in Python Gaël Varoquaux Bertrand Thirion Vincent Dubourg Alexandre Passos PEDREGOSA, VAROQUAUX, GRAMFORT ET AL. Matthieu Perrot</article-title><source>Journal of Machine Learning Research</source><year>2011</year><volume>12</volume><fpage>2825</fpage><lpage>2830</lpage></element-citation></ref><ref id="R40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raut</surname><given-names>RV</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Raichle</surname><given-names>ME</given-names></name></person-group><article-title>Hierarchical dynamics as a macroscopic organizing principle of the human brain</article-title><source>Proc Natl Acad Sci U S A</source><year>2020</year><volume>117</volume><fpage>20890</fpage><lpage>20897</lpage><pub-id pub-id-type="pmcid">PMC7456098</pub-id><pub-id pub-id-type="pmid">32817467</pub-id><pub-id pub-id-type="doi">10.1073/pnas.2003383117</pub-id></element-citation></ref><ref id="R41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robinson</surname><given-names>EC</given-names></name><name><surname>Jbabdi</surname><given-names>S</given-names></name><name><surname>Glasser</surname><given-names>MF</given-names></name><name><surname>Andersson</surname><given-names>J</given-names></name><name><surname>Burgess</surname><given-names>GC</given-names></name><name><surname>Harms</surname><given-names>MP</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Jenkinson</surname><given-names>M</given-names></name></person-group><article-title>MSM: A new flexible framework for Multimodal Surface Matching</article-title><source>Neuroimage</source><year>2014</year><volume>100</volume><fpage>414</fpage><lpage>426</lpage><pub-id pub-id-type="pmcid">PMC4190319</pub-id><pub-id pub-id-type="pmid">24939340</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.05.069</pub-id></element-citation></ref><ref id="R42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salimi-Khorshidi</surname><given-names>G</given-names></name><name><surname>Douaud</surname><given-names>G</given-names></name><name><surname>Beckmann</surname><given-names>CF</given-names></name><name><surname>Glasser</surname><given-names>MF</given-names></name><name><surname>Griffanti</surname><given-names>L</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name></person-group><article-title>Automatic denoising of functional MRI data: Combining independent component analysis and hierarchical fusion of classifiers</article-title><source>Neuroimage</source><year>2014</year><volume>90</volume><fpage>449</fpage><lpage>468</lpage><pub-id pub-id-type="pmcid">PMC4019210</pub-id><pub-id pub-id-type="pmid">24389422</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.11.046</pub-id></element-citation></ref><ref id="R43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seth</surname><given-names>AK</given-names></name><name><surname>Barrett</surname><given-names>AB</given-names></name><name><surname>Barnett</surname><given-names>L</given-names></name></person-group><article-title>Granger causality analysis in neuroscience and neuroimaging</article-title><source>Journal of Neuroscience</source><year>2015</year><volume>35</volume><fpage>3293</fpage><lpage>3297</lpage><pub-id pub-id-type="pmcid">PMC4339347</pub-id><pub-id pub-id-type="pmid">25716830</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4399-14.2015</pub-id></element-citation></ref><ref id="R44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shine</surname><given-names>JM</given-names></name><name><surname>Breakspear</surname><given-names>M</given-names></name><name><surname>Bell</surname><given-names>PT</given-names></name><name><surname>Ehgoetz Martens</surname><given-names>K</given-names></name><name><surname>Shine</surname><given-names>R</given-names></name><name><surname>Koyejo</surname><given-names>O</given-names></name><name><surname>Sporns</surname><given-names>O</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name></person-group><article-title>Human cognition involves the dynamic integration of neural activity and neuromodulatory systems</article-title><source>Nat Neurosci</source><year>2019</year><volume>22</volume><fpage>289</fpage><lpage>296</lpage><pub-id pub-id-type="pmid">30664771</pub-id></element-citation></ref><ref id="R45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simony</surname><given-names>E</given-names></name><name><surname>Honey</surname><given-names>CJ</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Lositsky</surname><given-names>O</given-names></name><name><surname>Yeshurun</surname><given-names>Y</given-names></name><name><surname>Wiesel</surname><given-names>A</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><article-title>Dynamic reconfiguration of the default mode network during narrative comprehension</article-title><source>Nat Commun</source><year>2016</year><volume>7</volume><elocation-id>12141</elocation-id><pub-id pub-id-type="pmcid">PMC4960303</pub-id><pub-id pub-id-type="pmid">27424918</pub-id><pub-id pub-id-type="doi">10.1038/ncomms12141</pub-id></element-citation></ref><ref id="R46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Bernhardt</surname><given-names>BC</given-names></name><name><surname>Leech</surname><given-names>R</given-names></name><name><surname>Bzdok</surname><given-names>D</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name></person-group><article-title>The default mode network in cognition: a topographical perspective</article-title><source>Nat Rev Neurosci</source><year>2021</year><volume>22</volume><fpage>503</fpage><lpage>513</lpage><pub-id pub-id-type="pmid">34226715</pub-id></element-citation></ref><ref id="R47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sporns</surname><given-names>O</given-names></name><name><surname>Faskowitz</surname><given-names>J</given-names></name><name><surname>Teixeira</surname><given-names>AS</given-names></name><name><surname>Cutts</surname><given-names>SA</given-names></name><name><surname>Betzel</surname><given-names>RF</given-names></name></person-group><article-title>Dynamic expression of brain functional systems disclosed by fine-scale analysis of edge time series</article-title><source>Network Neuroscience</source><year>2021</year><volume>5</volume><fpage>405</fpage><lpage>433</lpage><pub-id pub-id-type="pmcid">PMC8233118</pub-id><pub-id pub-id-type="pmid">34189371</pub-id><pub-id pub-id-type="doi">10.1162/netn_a_00182</pub-id></element-citation></ref><ref id="R48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vos de Wael</surname><given-names>R</given-names></name><name><surname>Benkarim</surname><given-names>O</given-names></name><name><surname>Paquola</surname><given-names>C</given-names></name><name><surname>Lariviere</surname><given-names>S</given-names></name><name><surname>Royer</surname><given-names>J</given-names></name><name><surname>Tavakol</surname><given-names>S</given-names></name><name><surname>Xu</surname><given-names>T</given-names></name><name><surname>Hong</surname><given-names>SJ</given-names></name><name><surname>Langs</surname><given-names>G</given-names></name><name><surname>Valk</surname><given-names>S</given-names></name><name><surname>Misic</surname><given-names>B</given-names></name><etal/></person-group><article-title>BrainSpace: a toolbox for the analysis of macroscale gradients in neuroimaging and connectomics datasets</article-title><source>Commun Biol</source><year>2020</year><volume>3</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="pmcid">PMC7058611</pub-id><pub-id pub-id-type="pmid">32139786</pub-id><pub-id pub-id-type="doi">10.1038/s42003-020-0794-7</pub-id></element-citation></ref><ref id="R49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>HT</given-names></name><name><surname>Ho</surname><given-names>NSP</given-names></name><name><surname>Bzdok</surname><given-names>D</given-names></name><name><surname>Bernhardt</surname><given-names>BC</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><article-title>Neurocognitive patterns dissociating semantic processing from executive control are linked to more detailed off-task mental time travel</article-title><source>Sci Rep</source><year>2020</year><volume>10</volume><pub-id pub-id-type="pmcid">PMC7368037</pub-id><pub-id pub-id-type="pmid">32681101</pub-id><pub-id pub-id-type="doi">10.1038/s41598-020-67605-2</pub-id></element-citation></ref><ref id="R50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Gao</surname><given-names>Z</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><article-title>Both Default and Multiple-Demand Regions Represent Semantic Goal Information</article-title><source>The Journal of Neuroscience</source><year>2021</year><volume>41</volume><fpage>3679</fpage><lpage>3691</lpage><pub-id pub-id-type="pmcid">PMC8055078</pub-id><pub-id pub-id-type="pmid">33664130</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1782-20.2021</pub-id></element-citation></ref><ref id="R51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Krieger-Redwood</surname><given-names>K</given-names></name><name><surname>Lyu</surname><given-names>B</given-names></name><name><surname>Lowndes</surname><given-names>R</given-names></name><name><surname>Wu</surname><given-names>G</given-names></name><name><surname>Souter</surname><given-names>NE</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Kong</surname><given-names>R</given-names></name><name><surname>Shafiei</surname><given-names>G</given-names></name><name><surname>Bernhardt</surname><given-names>BC</given-names></name><name><surname>Cui</surname><given-names>Z</given-names></name><etal/></person-group><article-title>The brain’s topographical organization shapes dynamic interaction patterns that support flexible behaviour based on rules and long term knowledge</article-title><source>The Journal of Neuroscience</source><year>2024a</year><elocation-id>e2223232024</elocation-id><pub-id pub-id-type="pmcid">PMC11140685</pub-id><pub-id pub-id-type="pmid">38527807</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2223-23.2024</pub-id></element-citation></ref><ref id="R52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Krieger-Redwood</surname><given-names>K</given-names></name><name><surname>Cui</surname><given-names>Y</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Du</surname><given-names>Y</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name></person-group><article-title>Macroscale brain states support the control of semantic cognition</article-title><source>Commun Biol</source><year>2024b</year><volume>7</volume><pub-id pub-id-type="pmcid">PMC11294576</pub-id><pub-id pub-id-type="pmid">39090387</pub-id><pub-id pub-id-type="doi">10.1038/s42003-024-06630-7</pub-id></element-citation></ref><ref id="R53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name></person-group><article-title>A gradient from long-term memory to novel cognition: Transitions through default mode and executive cortex</article-title><source>Neuroimage</source><year>2020</year><volume>220</volume><pub-id pub-id-type="pmcid">PMC7573535</pub-id><pub-id pub-id-type="pmid">32574804</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117074</pub-id></element-citation></ref><ref id="R54"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Krieger-Redwood</surname><given-names>K</given-names></name><name><surname>Zhang</surname><given-names>M</given-names></name><name><surname>Cui</surname><given-names>Z</given-names></name><name><surname>Xiaokang</surname><given-names>Wang</given-names></name><name><surname>Karapanagiotidis</surname><given-names>T</given-names></name><name><surname>Du</surname><given-names>Y</given-names></name><name><surname>Leech</surname><given-names>R</given-names></name><name><surname>Bernhardt</surname><given-names>BC</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><etal/></person-group><source>Physical distance to sensory-motor landmarks predicts language function</source><year>2022</year><pub-id pub-id-type="pmcid">PMC10110440</pub-id><pub-id pub-id-type="pmid">36066439</pub-id><pub-id pub-id-type="doi">10.1093/cercor/bhac344</pub-id></element-citation></ref><ref id="R55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolff</surname><given-names>A</given-names></name><name><surname>Berberian</surname><given-names>N</given-names></name><name><surname>Golesorkhi</surname><given-names>M</given-names></name><name><surname>Gomez-Pilar</surname><given-names>J</given-names></name><name><surname>Zilio</surname><given-names>F</given-names></name><name><surname>Northoff</surname><given-names>G</given-names></name></person-group><article-title>Intrinsic neural timescales: temporal integration and segregation</article-title><source>Trends Cogn Sci</source><year>2022</year><volume>26</volume><fpage>159</fpage><lpage>173</lpage><pub-id pub-id-type="pmid">34991988</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Fig. 1</label><caption><title>The workflow of the FS and FC analysis.</title><p>(I) Individual-specific parcellation divided the whole brain into 400 parcels across 17 networks (<xref ref-type="bibr" rid="R30">Kong et al., 2021</xref>). (II) Average time series of each parcel. (III) Extraction of features of time series for each parcel. (IV) Pearson correlation coefficients of the extracted features represent the pairwise feature similarity between all possible combinations of brain parcels. (V) Functional connectivity involved calculating Pearson correlation coefficients between the time-series of parcels. (Vis = Visual, Aud = Auditory, SM = Sensory-motor, DAN = Dorsal attention network, VAN = Ventral attention network, FPCN = Fronto-parietal control network, Lang = Language, DMN = Default mode network).</p></caption><graphic xlink:href="EMS200148-f001"/></fig><fig id="F2" position="float"><label>Fig. 2</label><caption><p>The experimental design. To tap working memory, we included two tasks: a spatial working memory task required participants to keep track of sequentially presented locations, while math decisions involved maintaining and manipulating numbers which rely more on working memory. To tap long-term memory, we included two tasks that required controlled retrieval of knowledge; a semantic feature matching task required participants to match probe and target concepts according to a particular semantic feature (color or shape), while a semantic association task involved deciding if pairs of words were linked in meaning. Response periods are indicated by a red box.</p></caption><graphic xlink:href="EMS200148-f002"/></fig><fig id="F3" position="float"><label>Fig. 3</label><caption><p>The FC matrix and FS matrix at rest and for each task. Regions within the same intrinsic functional network exhibited greater FC and FS than regions in different networks at rest and for each task. FC and FS showed positive but weak correlations at rest and for each task. (***: p &lt; 0.0001).</p></caption><graphic xlink:href="EMS200148-f003"/></fig><fig id="F4" position="float"><label>Fig. 4</label><caption><p>The top three principal components of FC and FS. FC and FS captured two similar principal components and one distinct component. The first principal component of FC (A) corresponds to the second principal component of FS (E), as indicated by the arrows denoting a strong correlation (r = 0.89, p = 0, corrected for spatial autocorrelation using spin permutation), which separates sensory-motor regions from transmodal areas. Similarly, the second principal component of FC (B) corresponds to the third principal component of FS (F), with a strong correlation (r = 0.87, p = 0, corrected for spatial autocorrelation using spin permutation), separating somatomotor and auditory cortex from visual cortex. These findings suggest that FS captures similar organizational information to FC. However, the third principal component of FC (C), which separates FPCN regions from DMN regions, was not captured by FS. The first principal component of FS (D), which corresponds to the intrinsic timescale gradient (G), was not captured by FC. (G) The intrinsic timescale map shows short timescales in the insula and cingulate cortex, and long timescales in the angular gyrus, posterior cingulate cortex, and frontal pole. (H) The first principal component of FS was significantly correlated with the intrinsic timescale gradient map in both the left (r = 0.82, p = 0) and right (r = 0.80, p = 0) hemispheres (corrected for spatial autocorrelation using spin permutation). The histograms illustrate the null model distributions. (I) Scree plots showing the eigenvalues for the top eight principal components of FS (orange) and FC (blue).</p></caption><graphic xlink:href="EMS200148-f004"/></fig><fig id="F5" position="float"><label>Fig. 5</label><caption><p>FS showed smaller correlations across tasks than FC. A – The group mean FC matrices showed higher correlations across tasks compared to FS matrices. Each dot represents the correlation coefficient between two tasks, with 10 possible combinations among the four tasks. B – The correlations of FC matrices for spatial working memory and math task were greater than the correlations of FS matrices. Each dot represents the correlation coefficient between the two task-specific matrices of one participant. C – The correlations of FC matrices for semantic feature matching and semantic association task were significantly greater than the correlations of FS matrices for these two tasks. Each dot represents the correlation coefficient between the two task-specific matrices of one participant.</p></caption><graphic xlink:href="EMS200148-f005"/></fig><fig id="F6" position="float"><label>Fig. 6</label><caption><p>FS captured varying interaction patterns for DAN-A across tasks that missed by FC. Top panel: DAN-A always showed greater FC with Visual network than with DMN at rest and for each task and there was no difference across tasks. Bottom panel: The difference between DAN-A and Visual network versus DAN-A and DMN in the non-semantic tasks was greater than in semantic tasks. DAN-A showed greater FS with Visual network than with DMN at rest and for the non-semantic tasks, but showed the opposite pattern in the semantic tasks that relied on long-term memory supported by DMN.</p></caption><graphic xlink:href="EMS200148-f006"/></fig><table-wrap id="T1" orientation="portrait" position="float"><label>Table 1</label><caption><title>FS showed greater variation across tasks than FC.</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top" align="center" style="border-top:solid 1px #000000">Task 1</th><th valign="top" align="center" style="border-top:solid 1px #000000">Task 2</th><th valign="top" align="center" style="border-top:solid 1px #000000">r (FC)</th><th valign="top" align="center" style="border-top:solid 1px #000000">r (FS)</th><th valign="top" align="center" style="border-top:solid 1px #000000">z</th><th valign="top" align="center" style="border-top:solid 1px #000000">p</th></tr></thead><tbody><tr><td valign="top" align="center" style="border-top:solid 1px #000000">Rest</td><td valign="top" align="center" style="border-top:solid 1px #000000">Spatial working memory</td><td valign="top" align="center" style="border-top:solid 1px #000000">0.68</td><td valign="top" align="center" style="border-top:solid 1px #000000">0.33</td><td valign="top" align="center" style="border-top:solid 1px #000000">96.31</td><td valign="top" align="center" style="border-top:solid 1px #000000">0</td></tr><tr><td valign="top" align="center" style="border-top:solid 1px #000000">Rest</td><td valign="top" align="center" style="border-top:solid 1px #000000">Math</td><td valign="top" align="center" style="border-top:solid 1px #000000">0.67</td><td valign="top" align="center" style="border-top:solid 1px #000000">0.38</td><td valign="top" align="center" style="border-top:solid 1px #000000">82.64</td><td valign="top" align="center" style="border-top:solid 1px #000000">0</td></tr><tr><td valign="top" align="center" style="border-top:solid 1px #000000">Rest</td><td valign="top" align="center" style="border-top:solid 1px #000000">Feature matching</td><td valign="top" align="center" style="border-top:solid 1px #000000">0.86</td><td valign="top" align="center" style="border-top:solid 1px #000000">0.68</td><td valign="top" align="center" style="border-top:solid 1px #000000">82.48</td><td valign="top" align="center" style="border-top:solid 1px #000000">0</td></tr><tr><td valign="top" align="center" style="border-top:solid 1px #000000">Rest</td><td valign="top" align="center" style="border-top:solid 1px #000000">Association</td><td valign="top" align="center" style="border-top:solid 1px #000000">0.88</td><td valign="top" align="center" style="border-top:solid 1px #000000">0.68</td><td valign="top" align="center" style="border-top:solid 1px #000000">110.49</td><td valign="top" align="center" style="border-top:solid 1px #000000">0</td></tr><tr><td valign="top" align="center" style="border-top:solid 1px #000000">Spatial working memory</td><td valign="top" align="center" style="border-top:solid 1px #000000">Math</td><td valign="top" align="center" style="border-top:solid 1px #000000">0.75</td><td valign="top" align="center" style="border-top:solid 1px #000000">0.43</td><td valign="top" align="center" style="border-top:solid 1px #000000">103.38</td><td valign="top" align="center" style="border-top:solid 1px #000000">0</td></tr><tr><td valign="top" align="center" style="border-top:solid 1px #000000">Spatial working memory</td><td valign="top" align="center" style="border-top:solid 1px #000000">Feature matching</td><td valign="top" align="center" style="border-top:solid 1px #000000">0.73</td><td valign="top" align="center" style="border-top:solid 1px #000000">0.42</td><td valign="top" align="center" style="border-top:solid 1px #000000">94.50</td><td valign="top" align="center" style="border-top:solid 1px #000000">0</td></tr><tr><td valign="top" align="center" style="border-top:solid 1px #000000">Spatial working memory</td><td valign="top" align="center" style="border-top:solid 1px #000000">Association</td><td valign="top" align="center" style="border-top:solid 1px #000000">0.71</td><td valign="top" align="center" style="border-top:solid 1px #000000">0.42</td><td valign="top" align="center" style="border-top:solid 1px #000000">88.63</td><td valign="top" align="center" style="border-top:solid 1px #000000">0</td></tr><tr><td valign="top" align="center" style="border-top:solid 1px #000000">Math</td><td valign="top" align="center" style="border-top:solid 1px #000000">Feature matching</td><td valign="top" align="center" style="border-top:solid 1px #000000">0.75</td><td valign="top" align="center" style="border-top:solid 1px #000000">0.43</td><td valign="top" align="center" style="border-top:solid 1px #000000">103.38</td><td valign="top" align="center" style="border-top:solid 1px #000000">0</td></tr><tr><td valign="top" align="center" style="border-top:solid 1px #000000">Math</td><td valign="top" align="center" style="border-top:solid 1px #000000">Association</td><td valign="top" align="center" style="border-top:solid 1px #000000">0.73</td><td valign="top" align="center" style="border-top:solid 1px #000000">0.43</td><td valign="top" align="center" style="border-top:solid 1px #000000">93.72</td><td valign="top" align="center" style="border-top:solid 1px #000000">0</td></tr><tr><td valign="top" align="center" style="border-top:solid 1px #000000;border-bottom:solid 1px #000000">Feature matching</td><td valign="top" align="center" style="border-top:solid 1px #000000;border-bottom:solid 1px #000000">Association</td><td valign="top" align="center" style="border-top:solid 1px #000000;border-bottom:solid 1px #000000">0.98</td><td valign="top" align="center" style="border-top:solid 1px #000000;border-bottom:solid 1px #000000">0.94</td><td valign="top" align="center" style="border-top:solid 1px #000000;border-bottom:solid 1px #000000">86.35</td><td valign="top" align="center" style="border-top:solid 1px #000000;border-bottom:solid 1px #000000">0</td></tr></tbody></table></table-wrap></floats-group></article>