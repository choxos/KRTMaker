<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS199280</article-id><article-id pub-id-type="doi">10.1101/2024.10.07.616955</article-id><article-id pub-id-type="archive">PPR920757</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">2</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Animal acoustic communication maintains a universal optimum rhythm</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" equal-contrib="yes"><name><surname>Piette</surname><given-names>T.</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Cathcart</surname><given-names>C.</given-names></name><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Barbieri</surname><given-names>C.</given-names></name><xref ref-type="aff" rid="A3">3</xref><xref ref-type="aff" rid="A4">4</xref><xref ref-type="aff" rid="A5">5</xref></contrib><contrib contrib-type="author"><name><surname>Ming</surname><given-names>K. M.</given-names></name><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Grandjean</surname><given-names>D.</given-names></name><xref ref-type="aff" rid="A5">5</xref></contrib><contrib contrib-type="author"><name><surname>Bickel</surname><given-names>B.</given-names></name><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Déaux</surname><given-names>É.C</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes"><name><surname>Giraud</surname><given-names>A-L.</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A6">6</xref></contrib></contrib-group><aff id="A1"><label>1</label>Department of Basic Neurosciences, Faculty of Medicine, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/01swzsf04</institution-id><institution>University of Geneva</institution></institution-wrap>, <city>Geneva</city>, <country country="CH">Switzerland</country></aff><aff id="A2"><label>2</label>Department of Comparative Language Science, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/02crff812</institution-id><institution>University of Zurich</institution></institution-wrap>, <city>Zurich</city>, <country country="CH">Switzerland</country></aff><aff id="A3"><label>3</label>ISLE Center, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/02crff812</institution-id><institution>University of Zurich</institution></institution-wrap>, <city>Zurich</city>, <country country="CH">Switzerland</country></aff><aff id="A4"><label>4</label>Department of Evolutionary Biology and Environmental Studies, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/02crff812</institution-id><institution>University of Zurich</institution></institution-wrap>, <city>Zurich</city>, <country country="CH">Switzerland</country></aff><aff id="A5"><label>5</label>Department of Life and Environmental Sciences, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/003109y17</institution-id><institution>University of Cagliari</institution></institution-wrap>, <city>Cagliari</city>, <country country="IT">Italy</country></aff><aff id="A6"><label>6</label>Swiss Center for Affective Sciences, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/01swzsf04</institution-id><institution>University of Geneva</institution></institution-wrap>, <city>Geneva</city>, <country country="CH">Switzerland</country></aff><aff id="A7"><label>7</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05f82e368</institution-id><institution>Université Paris Cité</institution></institution-wrap>, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/0495fxg12</institution-id><institution>Institut Pasteur</institution></institution-wrap>, AP-HP, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/02vjkv261</institution-id><institution>Inserm</institution></institution-wrap>, Fondation Pour l'Audition, Institut de l’Audition, IHU reConnect, <postal-code>F-75012</postal-code><city>Paris</city>, <country country="FR">France</country></aff><author-notes><corresp id="CR1">Corresponding authors: Théophane Piette and Anne-Lise Giraud</corresp></author-notes><pub-date pub-type="nihms-submitted"><day>09</day><month>10</month><year>2024</year></pub-date><pub-date pub-type="preprint"><day>07</day><month>10</month><year>2024</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Most animals interact with conspecifics through acoustic signals that are modulated in frequency and rhythm. While small animals vocalize at higher pitch than large ones due to the smaller size of their vocal apparatus, the rules governing vocalization rhythms throughout the animal kingdom remain unknown. Vocal rhythms serve as a natural information parser, and one possibility is that they are constrained by the neural rhythms of transmitter and receiver, known to be relatively conserved across species and independent of their size. In this study, we quantified acoustic rhythms across taxa and investigated their evolutionary history with regard to phylogeny and selective pressure. In 98 species from six classes, we tested the main factors likely to influence their communication rhythms: morphology, physiology, social complexity, mastication and detectability. Phylogenetic modeling did not confirm the influence of these species-specific factors, but rather point to a scenario where acoustic communication rhythms have been maintained around an optimum at around 3Hz in the biological (neuronal) delta range (1-4Hz) well before the mammals split. These results suggest that the rhythm of acoustic communication signals, unlike their pitch, has a universal neural determinant that has been conserved throughout evolution, allowing for intra- and cross-species signaling.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">Acoustic signals allow for effective, instantaneous communication between individuals even at considerable distances. To be functional these signals’ structure must carry adaptive information with the importance of spectral features in doing so being well established<sup><xref ref-type="bibr" rid="R1">1</xref>–<xref ref-type="bibr" rid="R5">5</xref></sup>. Yet, acoustic signals are not only spectrally but also temporally structured, with rhythm having equally important communicative functions. This is particularly well exemplified by human speech, where speech rate is sufficient for comprehension<sup><xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R7">7</xref></sup>. In most languages, syllable production rate ranges between 4 to 9 syllables per second<sup><xref ref-type="bibr" rid="R8">8</xref></sup>. This frequency range corresponds to theta neural oscillations, which flexibly adapt to this rhythm during perception, such that modifying this flow impedes this process and decreases speech intelligibility. Rhythmic patterns allow the identification of syllables, words, and sentences and can help convey meaning, such as emphasis, intonation, and emotional state<sup><xref ref-type="bibr" rid="R9">9</xref>,<xref ref-type="bibr" rid="R10">10</xref></sup>. In animal calls, temporal features are no less important, for instance in vocal recognition<sup><xref ref-type="bibr" rid="R11">11</xref></sup>, mating behavior<sup><xref ref-type="bibr" rid="R12">12</xref></sup>, and predator avoidance<sup><xref ref-type="bibr" rid="R13">13</xref></sup>. Interestingly, calling rate is typically linked to arousal<sup><xref ref-type="bibr" rid="R1">1</xref>,<xref ref-type="bibr" rid="R14">14</xref></sup> with high vocal rhythms eliciting rapid responses, possibly by targeting salience-related brain <sub>networks</sub><sup><xref ref-type="bibr" rid="R15">15</xref>,<xref ref-type="bibr" rid="R16">16</xref></sup><sub>.</sub></p><p id="P3">Thus, the temporal patterning of acoustic sequences bears significant communicative function(s) and is not speech-specific. Yet questions remain as to what influences the evolution of rhythm across the animal kingdom. In this study we quantify rhythm across animal clades, test the most prominent hypotheses of signal structure evolution and build models of the most plausible evolutionary scenario. Four major selective forces may drive rhythm evolution. Firstly, the presence of theta rhythm in vocal productions and mouth movements of non-human primates suggests that this rhythm originates from the natural oscillatory movements of the articulators that are directly inherited from mastication<sup><xref ref-type="bibr" rid="R17">17</xref>–<xref ref-type="bibr" rid="R19">19</xref></sup>. Second, in animals that vocalize, morphological and physiological characteristics, such as breathing rate, heart rate, or metabolism could constrain rhythm range in an analogous manner to spectral features<sup><xref ref-type="bibr" rid="R20">20</xref></sup>. Thirdly, to be effective, acoustic signals must reach the receiver despite constraints from the living environment, which could thus influence not only spectral but also temporal features<sup><xref ref-type="bibr" rid="R21">21</xref></sup>. Additionally, the sociality-complexity hypothesis suggests a positive relationship between the complexity of the social environment and the complexity of a species’ vocal repertoire<sup><xref ref-type="bibr" rid="R22">22</xref></sup>. As rhythm would bear a direct relationship with the amount of information that can be transmitted in a given time unit, social complexity may also influence acoustic rate. Finally, it may be that none of these species-specific selective forces have influenced rhythm and that instead it has evolved through phylogenetic mechanisms of conservation and diversification that are either shared or diverse across lineages.</p><p id="P4">To test these different hypotheses, we quantified rhythm in acoustic sequences from birds, mammals, amphibians, insects, reptiles, and fish. Using Bayesian multilevel models for phylogenetic regression<sup><xref ref-type="bibr" rid="R23">23</xref></sup>, we controlled for phylogenetic relationships and evaluated, in accordance with the previously stated hypotheses, whether weight (as a proxy for breathing rate, heart rate, and metabolism), mastication status, sociality level or ecological characteristics could account for differences in rhythm. Finally, we compared phylogenetic models to assess the most plausible evolutionary scenario of rhythm across animals.</p><sec id="S2"><title>Rhythm computation</title><p id="P5">We analyzed acoustic sequences from 98 species (58 birds, 28 mammals, 4 amphibians, 4 insects, 1 reptile, and 1 fish) to study the evolution of rhythm in animals. We calculated rhythm by analyzing variation in the signal amplitude, allowing broad applicability across species (<xref ref-type="fig" rid="F1">Fig 1a, 1b, 1c, 1d</xref>). Validation against conventional methods showed consistent results (<xref ref-type="fig" rid="F1">Fig 1e</xref>: F2.171=0.33, p=0.72) confirming the robustness of our method. Control of the impact of signal-to-noise ratio (SNR) and sequence length revealed no significant relationship with rhythm (<xref ref-type="supplementary-material" rid="SD1">Supp Fig 1a; Supp Fig 1b</xref>). Additional investigation of the allometric relationship between weight and dominant frequency (<xref ref-type="supplementary-material" rid="SD1">Supp Fig 2</xref>), and of the effect of context on rhythm (<xref ref-type="supplementary-material" rid="SD1">Supp fig 4a</xref>) further confirmed the validity of our vocal database.</p></sec><sec id="S3"><title>Species Specific Selective Pressure</title><p id="P6">To investigate which factors influence the evolution of rhythm, we fitted two phylogenetic regressions in a Bayesian multilevel framework A full model investigating the impact of weight, mastication status, and living environment while controlling for phylogenetic relatedness, and a null model controlling for phylogenetic relatedness only. We compared models via their leave-one-out expected log pointwise density (ELPD) and stacking weight. Due to heteroskedasticity, distributional (scale-location) models better fit the data, leveraging over 90% of the stacking weights (<xref ref-type="supplementary-material" rid="SD1">Sup Fig 3</xref>). Including the predictors did not improve predictive performance (<xref ref-type="fig" rid="F2">Fig 2a</xref>) and the null model leveraged the highest stacking weight (<xref ref-type="fig" rid="F2">Fig 2b</xref>). The posterior distribution of the regression coefficients of the full model revealed that none of our predictors had any decisive effect on rhythm, given that their 95% credible intervals (CI) all contain zero. We observed only very weak evidence for a negative effect of weight on rhythm in masticating species as zero was outside the 85% CI of their interaction coefficient (<xref ref-type="fig" rid="F2">Fig 2c, 2d</xref>).</p><p id="P7">Taken together, these results indicate that inclusion of these predictors does not add decisive explanatory value to phylogenetic history. As vocal complexity, our indicator of social complexity, could not be included in the phylogenetic model due to unavailability for all species, we additionally regressed rhythm on vocal complexity (<xref ref-type="supplementary-material" rid="SD1">Sup Fig 4d</xref>: t=-0.75, p=0.46), revealing no relationship between the two.</p></sec><sec id="S4"><title>Phylogenetic History of Rhythm</title><p id="P8">Visual inspection of the median rhythm of our tested species shows that in every class, acoustic rhythm spans mainly the lower rates, in what is commonly called the delta range (<xref ref-type="fig" rid="F2">Fig 2e</xref>). To understand if rhythm has randomly evolved in this range, favoring species-specific rhythm, or has been maintained around an optimum value, we fitted models of the evolution of vocal rhythm under Brownian Motion (BM) and Ornstein-Uhlenbeck (OU) processes <sup><xref ref-type="bibr" rid="R24">24</xref></sup>, representing each evolutionary scenario respectively.</p><p id="P9">We fitted models of the evolution of vocal rhythm under BM and OU processes. Comparison of ELPD values and model stacking show that the OU model best fit the data (<xref ref-type="fig" rid="F3">Fig 3a</xref>). The result is validated by models (Sup results) fitted separately for mammals and birds alone, with the OU model having the highest stacking weight (birds w<sub>OU</sub> = 1, mammals w<sub>OU</sub> = 0.925). The median posterior estimate of rhythm is 2.9Hz, with 95% CI of [.5, 5.1] Hz and 85% credible interval of [1.1Hz, 4.2] Hz (<xref ref-type="fig" rid="F3">Fig 3b</xref>). This represents both the optimum to which the OU process reverts over time and the likely state at the root of the phylogeny. The posterior distribution of sigma represents the stochastic volatility (<xref ref-type="fig" rid="F3">Fig 3c</xref>) and has a median of 0.69 and a 95% CI of (0.29 1.90). The posterior distribution of alpha represent the strength of attraction (<xref ref-type="fig" rid="F3">Fig 3d</xref>) and has a median of 2.79 and a 95% CI of (0.38 6.76). The proportion of posterior half-life estimates lower than 1 (height of the tree) is 97% (<xref ref-type="fig" rid="F3">Fig 3e</xref>), supporting strong selection with fast reversals to the optimum. Consistent with this, rhythm values close to the optimum are also reconstructed for most interior nodes of the phylogeny (<xref ref-type="fig" rid="F3">Fig 3f</xref>). In summary, the model suggests that there is a phylogeny-wide evolutionary pressure towards an optimal rhythm, to which species that deviate quickly revert to.</p></sec></sec><sec id="S5" sec-type="discussion"><title>Discussion</title><p id="P10">Our finding of an animal-wide optimum rhythm for acoustic communication challenges the idea that it is shaped by biomechanical constraints. The latter would predict distinct rhythms between masticating and non-masticating species, along with a strong negative allometric relationship between rhythm and weight in masticating species. Instead, the weak effect of weight on acoustic rhythms observed in masticatory species indicates that biomechanical constraints only exert a marginal influence. By contrast, our analyses of dominant frequency (<xref ref-type="supplementary-material" rid="SD1">Supp fig 2</xref>) reconfirmed that spectral characteristics primarily depend on the specifics of the production organ, which chiefly vary with weight.<sup><xref ref-type="bibr" rid="R25">25</xref></sup></p><p id="P11">With regards to the emergence of this optimum acoustic rhythm, its widespread evidence among birds and mammals suggests its presence in their last common ancestor, around 340 million years ago. Further, its existence in more remote species in our sample (insects, amphibians, fishes) speaks to even older roots (<xref ref-type="fig" rid="F3">Fig. 3</xref>). Yet, the factors that contributed to the emergence of this rhythm and its persistence throughout evolution remain unclear. Given the diversity of hearing structures (cochlea, otic vesicle, tympanal organs etc.) and production modes (vocalization, stridulation, percussion etc.), it seems unlikely that this common rhythm reflects similarities in anatomical traits<sup><xref ref-type="bibr" rid="R26">26</xref></sup>. Likewise, given the diversity of living and social environments, such factors cannot be the main forces behind this conserved rhythm.</p><p id="P12">By contrast, basic neural mechanisms are remarkably conserved, and could therefore better explain a widespread optimum rhythm. On the production side, vertebrates share a common location for motoneurons responsible for vocalizations in the caudal hindbrain, believed to be involved in call duration and timing, supporting the claim of conserved mechanisms for acoustic rhythmic production<sup><xref ref-type="bibr" rid="R27">27</xref></sup>. In terms of auditory reception, this conserved rhythm around 2.9 Hz (85% interval 1.1Hz-4.2Hz) best matches delta brain oscillations (1–4 Hz), which have been observed across species, including mammals, reptiles, and insects<sup><xref ref-type="bibr" rid="R28">28</xref>–<xref ref-type="bibr" rid="R30">30</xref></sup>. Interestingly, delta oscillations are linked to active sensing, where organisms sample their environment to enhance perception/action cycles<sup><xref ref-type="bibr" rid="R31">31</xref></sup>. Slow oscillations help integrate sensory information and are particularly suited for integrating slow-varying acoustic cues, that are usually the signature of the emitter’s identity, e.g. vocalic cues<sup><xref ref-type="bibr" rid="R32">32</xref></sup>. In sum, this production rhythm best matches a neural rhythm that is important for assigning significance to acoustic signals, which would thus result in an effective communicative design.</p><p id="P13">Yet, speech perception research has revealed that auditory processing relies on (at least) a two-timescale processing<sup><xref ref-type="bibr" rid="R10">10</xref></sup>. Similarly, our control analyses on context show that different call types operate within this conserved rhythm (<xref ref-type="supplementary-material" rid="SD1">Sup Fig 4</xref>), requiring a faster analysis window to be resolved. As such, it is possible to envision a dual receptive strategy relying on slow analyses for signal identification, and fast analyses for signal detectability and discrimination, useful for e.g. distinguishing different call types<sup><xref ref-type="bibr" rid="R33">33</xref>–<xref ref-type="bibr" rid="R36">36</xref></sup>. Though this report does not demonstrate the fast timescale's evolution, an interesting avenue would be to probe for an optimum that combines fast and slow scales during acoustic communication.</p><p id="P14">Finally, these results suggest another interesting aspect. The maintenance throughout evolution of a slow rhythm for acoustic signal production and perception de facto results in a common communication channel across coexisting species. The common low-range (delta scale) could thus permit cross-species identification and offer possibilities for interspecies signaling (e.g. a common danger) and/or eavesdropping, conferring evolutionary advantages.</p><p id="P15">In summary, spectral and temporal features, both key to effective communication, evolve following different trajectories. While spectral traits diversify along with the hearing organ anatomy, rhythm may be primarily shaped by basic neural factors, responsible for both production and perception processes and which lead to a conserved optimal rhythm.</p></sec><sec id="S6" sec-type="methods"><title>Method</title><sec id="S7"><title>Vocal sequences</title><p id="P16">To perform an extensive phylogenetic comparison on a balanced phylogeny, we collected acoustic and biological data for at least one species per infra-order of tetrapods, when data were available, as well as a few species of insects and fishes, to obtain a good representation of rhythm throughout the phylogeny. Acoustic sequences were gathered from public and private databases (Fonozoo, Cisro, Berlin Museum fur Naturkunde and Xeno-canto), online videos platform (Youtube, Dailymotion), and from different research groups that kindly shared audio files.</p></sec><sec id="S8"><title>Weight</title><p id="P17">Weight presents an allometric relationship with morphological features and physiological processes involved in acoustic productions across various species. Thus we collected biological data on the mean weight for each species, to serve as a proxy for heart rate, breathing rate and metabolism. This involved calculating the average weight by considering both the minimum and maximum weights recorded for each species, irrespective of sex. These data were primarily obtained from the handbook of mammals of the world<sup><xref ref-type="bibr" rid="R37">37</xref></sup>, and the handbook of birds of the world<sup><xref ref-type="bibr" rid="R38">38</xref></sup>. When data were unavailable from these sources, we looked for reference articles.</p></sec><sec id="S9"><title>Beak Size</title><p id="P18">Just as masticatory abilities may have influenced rhythm in mammals, a similar proposition could be made regarding beak morphology in birds. Unlike other animals, the morphological traits of a bird's beak do not consistently adhere to an allometric relationship with its weight<sup><xref ref-type="bibr" rid="R39">39</xref></sup>. Thus we collected information on beak length, width and depth of our species. As these measures were not available for all species, we could not include them in the phylogenetic model. We therefore built an additional linear mixed model investigating the variation of rhythm, including group and order as random effects, and beak length, width, depth, and their interactions as fixed effects. Data are available in the study github.</p></sec><sec id="S10"><title>Living environment</title><p id="P19">As environmental conditions can impact vocal communication<sup><xref ref-type="bibr" rid="R21">21</xref></sup>, we also collected data on the typical habitat of each species. We used a five level categorical classification, with habitats being either classified as closed (defined as habitats with heavy tree coverage), semi-closed (defined as habitats with light three coverage or human cities), open (defined as fully open habitat with no three coverage or obstacle), shore (for species living near a significant amount of water such as lakes, rivers or seas) or water (for species living below the water surface). These data were primarily obtained from the handbook of mammals of the world, and the handbook of birds of the world. When data were unavailable from these sources, we looked for reference articles. Data and linked references are available in the study github.</p></sec><sec id="S11"><title>Mastication status</title><p id="P20">As some have proposed that rhythmic communication in vocalizing animals may be linked to mastication regime<sup><xref ref-type="bibr" rid="R17">17</xref>,<xref ref-type="bibr" rid="R19">19</xref></sup>, we also classified each species according to their mastication status (yes or no).</p></sec><sec id="S12"><title>Social complexity</title><p id="P21">As social complexity increases, individuals may need to communicate more information in a given time, and therefore speed up their communication. As communication signals have been linked to social complexity<sup><xref ref-type="bibr" rid="R22">22</xref></sup>, we also gathered species vocal repertoire complexity (number of distinct calls in the species vocal repertoire) when this information was available. As this measure was not available for all species, we could not include it in the phylogenetic model. We therefore built an additional linear mixed model investigating the variation of rhythm, including group and order as random effects, and vocal complexity as fixed effect. These data were primarily obtained from the handbook of birds of the world, and reference articles. Data and linked references are available in the study github.</p></sec><sec id="S13"><title>Acoustic sequence selection and pre-processing</title><p id="P22">Based on a cross-species literature search<sup><xref ref-type="bibr" rid="R40">40</xref>–<xref ref-type="bibr" rid="R43">43</xref></sup>, we defined sequences as recordings of acoustic displays emitted by a single individual, containing more than two calls separated by less than two seconds of silence. For computational purposes, we selected only recordings lasting more than one second. We included in our analysis species for which we had at least five different sequences from five different individuals. Species with fewer sequences were included if they were the only available representatives of their infra-order, resulting in a database of 98 species, including 58 birds, 28 mammals, 4 amphibians, 4 insects, 1 reptile, and 1 fish.</p></sec><sec id="S14"><title>Rhythm analyses</title><p id="P23">To quantify rhythm in these acoustic sequences, we decided to adapt the method developed by Tilsen et al to compute rhythm in human speech production<sup><xref ref-type="bibr" rid="R44">44</xref></sup>. This method uses the signal amplitude to automatically compute the rhythmic component of a sequence, without making any assumption on the components’ size, and is thus widely applicable across all species regardless of variations in unit size or spectral characteristics. First, we denoised the sequences using a first-order Butterworth filter, with a bandpass filter between a minimal frequency (minF), defined as 200 Hz below the minimum frequency of the animal call, and a maximum frequency (maxF), defined as 200 Hz above the maximum frequency of the animal acoustic signal obtained from reference articles. When this information was not available, we applied a large range filter with a 100 Hz minF and 10000 Hz maxF. We then computed the normalized envelope of the denoised sequences using the Hilbert Transform. Next, we low pass-filtered this envelope with a fourth-order Butterworth filter with a 20 Hz cut-off frequency to obtain the slow changes in acoustic energy. Before further analysis, we downsampled the resulting signal at 150 Hz for computational purposes, and then applied a continuous wavelet transform using the Morlet wavelet to obtain a time-frequency representation of the amplitude envelope. We replaced the Fourier transform with a wavelet transform, to allow for more flexibility with regards to the variation in sequence length present in our dataset. We finally analyzed that representation's power spectrum to extract the five frequency peaks of highest amplitude in the power spectrum and used the time-frequency representation to select the main rhythmic component conserved across the entire sequence.</p><p id="P24">To assess the validity of the proposed methodology, we conducted a comparative analysis between the calculated vocal rates of a subset comprising 10% of our database and those derived from two widely accepted conventional approaches: 1) by counting the number of elements per second (Count) and 2) by computing the inter-element interval (IEI). The three methods gave sensibly similar results (<xref ref-type="fig" rid="F1">Figure 1d</xref>: F<sub>2.171</sub>=0.33, p=0.72), hence validating our rhythm quantification method.</p></sec><sec id="S15"><title>Signal to noise ratio (SNR) and Length</title><p id="P25">As further control analyses, we quantified recording durations in seconds and signal-to-noise ratio in decibels. To control for the effect of both factors and their interaction on rhythm, we build a linear mixed model investigating the variation of rhythm including group and order as random effects, and SNR, length and their interaction as fixed effects.</p></sec><sec id="S16"><title>Dominant frequency analyses</title><p id="P26">To determine dominant frequencies, which unlike the fundamental frequency are measurable in all types of communicative signals<sup><xref ref-type="bibr" rid="R25">25</xref></sup>, we isolated the first acoustic unit in each denoised sequence. We then applied a single discrete Fourier transform to compute the power spectrum of these units, and extract the peak of highest amplitude. The obtained results were also visually controlled in Praat, to make sure that the extracted dominant frequency matched the acoustic energy present in the unit. If the first unit had poor signal-to-noise ratio leading to inaccurate computation of the dominant frequency, we selected the next unit in the sequence.</p></sec><sec id="S17"><title>Context effect control</title><p id="P27">While the existing literature highlights the importance of context and its correlated arousal levels on acoustic signal rate<sup><xref ref-type="bibr" rid="R1">1</xref></sup>, for most species we were not able to obtain these data. Nevertheless, whenever possible we selected recordings of different call types for each species. Further, we performed separated analysis of variance (ANOVA) to control for the effect of call type on rhythm in three species: one avian and two mammalian, from which we could obtain different call types, including contact calls, alarm calls, songs, agonistic and antagonistic vocal displays.</p></sec><sec id="S18"><title>Phylogenetic tree sample reconstructed from genetic sequences</title><p id="P28">To test our hypotheses of interest we used phylogenetic comparative methods (PCM), a broad family of methodological tools for characterizing and controlling for the evolutionary dynamics thought to give rise to the data under study. PCMs require a representation of the relatedness of the taxa under study in the form of a phylogenetic tree sample. To represent the tree topology of the species we performed a phylogenetic analysis based on comparable genetic sequences, using a Bayesian framework to infer a posterior tree sample. We first matched each species in the sample with their closest genetic proxies in GenBank<sup><xref ref-type="bibr" rid="R45">45</xref></sup>, and extracted mitochondrial DNA for the corresponding species. For 54 of the 98 species, matching mitochondrial genomes were available from literature and deposited in GenBank. For the 44 remaining species we chose proxies from another closely related species. We took a species within the same genus when possible; if this was not available, we chose species within the family of the target species, after confirming that no more than one species per family was included in the original list. Only for four target species - <italic>Correlophus ciliates</italic> (Squamata), <italic>Galbula ruficauda</italic> (Aves), <italic>Leptosomus discolor</italic> (Aves), <italic>Phaethon rubricauda</italic> (Aves) - we did not find proxies within the family and we had to find a proxy within the order. To choose the best mtDNA proxy with those deposited in GenBank, we considered completeness of the available mitochondrial sequences and comparable average size, weight and environment of the target species. Maximum missing data is 100 base pairs, for an average size of 16706 base pairs. MtDNA genomes were aligned with MAFFT software<sup><xref ref-type="bibr" rid="R46">46</xref></sup> and standard settings. The alignment was manually screened in BioEdit (version 7.2, <ext-link ext-link-type="uri" xlink:href="https://thalljiscience.github.io/">https://thalljiscience.github.io/</ext-link>) for spotting irregularities and potential outlier sequences. Sequences were then cut to keep only the coding region, which is more conserved across species, using the <italic>Homo sapiens</italic> sequence as a reference. The final alignment consisted of 21860 base pairs, which include large INDELs sections to accommodate alignment between the most divergent species (e.g. <italic>Apis mellifera).</italic></p><p id="P29">We used BEAST2 to generate the trees, running 10’000’000 iterations of Markov chain Monte Carlo (MCMC) with a thinning interval of 1000. We used the following settings to approximate the broad evolutionary range of the species considered: assuming an HKY substitution model, a strict clock (Uniform rates across branches), and a Birth-Death tree prior with a Yule birth rate. This resulted in 10’000 trees, of which we use 50 for phylogenetic comparative analyses.</p></sec><sec id="S19"><title>Bayesian multilevel models for phylogenetic regression</title><p id="P30">To assess the impact of several predictors of interest on different properties of variation in (1) vocal rhythm and (2) dominant frequency, we used phylogenetic regression modeling, a comparative method that assesses the effect of predictors on a response while controlling for the phylogenetic relatedness of the taxa. Due to heterogeneity in the number of datapoints and individuals in each species, we employed both non-distributional regression models, which model the mean of the response variable as a function of predictors, and distributional (scale-location) regression models, which model both the mean and standard deviation of the response variable as a function of predictors. We control for species-level idiosyncrasies in both the median and (in some cases) standard deviation of rhythm via phylogenetic random intercepts and slopes (phylogenetic random effects are similar to the standard random effects used in hierarchical regression modeling, but are generated by a Gaussian Process with a covariance kernel that is a function of the phylogenetic patristic distances between species under study rather than independently and identically distributed with diagonal variance).</p><p id="P31">We fitted four phylogenetic regression models using brms<sup><xref ref-type="bibr" rid="R23">23</xref></sup> for each response variable (vocal rhythm, dominant frequency), resulting in eight models. These predictors consisted of average species weight in kilograms, which was log-transformed, centered around zero, and standardized<sup><xref ref-type="bibr" rid="R47">47</xref></sup>, mastication status, and living environment of the species. We also consider the interaction between mastication status and weight.</p><p id="P32">Our distributional models have the following basic generative process (below, α<sup>μ</sup> + β<italic>X<sub>i</sub>,</italic> is shorthand for all model predictors, including fixed and random effects): <disp-formula id="FD1"><mml:math id="M1"><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>~</mml:mo><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mo>μ</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mo>σ</mml:mo><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula> <disp-formula id="FD2"><mml:math id="M2"><mml:msub><mml:mo>μ</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mo>α</mml:mo><mml:mrow><mml:mo>μ</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mo>β</mml:mo><mml:mo>μ</mml:mo></mml:msup><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></disp-formula> <disp-formula id="FD3"><mml:math id="M3"><mml:mrow><mml:msub><mml:mtext>σ</mml:mtext><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mtext>α</mml:mtext><mml:mtext>σ</mml:mtext></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mtext>β</mml:mtext><mml:mtext>σ</mml:mtext></mml:msup><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P33">Non-distributional models have the following structure: <disp-formula id="FD4"><mml:math id="M4"><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>~</mml:mo><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>σ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula> <disp-formula id="FD5"><mml:math id="M5"><mml:msub><mml:mtext>μ</mml:mtext><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mtext>α</mml:mtext><mml:mtext>μ</mml:mtext></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mtext>β</mml:mtext><mml:mtext>μ</mml:mtext></mml:msup><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></disp-formula></p><p id="P34">We employ the default priors of brms.</p><p id="P35">The first of the four models was a full distributional one that modeled both the expected median and variance of the response variable as a function of these predictors, while controlling for species-level idiosyncrasies in both the median and variance of rhythm via phylogenetic random intercepts and slopes. The second was a full non-distributional model that treated only the expected median rhythm as a function of the predictor variables as well as phylogenetic random intercepts and slopes. The third of these was a null distributional model that included only phylogenetic random intercepts and slopes for the expected median and variance. The final model was a null non-distributional that included only phylogenetic random intercepts and slopes for mean rhythm. We ran each of these models for 4000 iterations of the no U-turn sampler over 4 chains with a log-normal link function and discarded the first half of samples, aggregating posterior samples across the retained sampled trees.</p><p id="P36">Models in brms have the following formulae:</p><p id="P37">Full, distributional <preformat preformat-type="computer code"><styled-content style="font-size:15px;">bf(frequency ~ weight*mastication + environment + (1 +
weight*mastication + environment | gr(taxon, cov =
phylo.cov))</styled-content></preformat></p><p id="P38"><preformat preformat-type="computer code"><styled-content style="font-size:15px;">sigma ~ weight*mastication + environment + (1 +
weight*mastication + environment | gr(taxon, cov =
phylo.cov)))</styled-content>
</preformat>
</p><p id="P39">Full, non-distributional <preformat preformat-type="computer code"><styled-content style="font-size:15px;">bf(frequency ~ weight*mastication + environment +	(1	+
weight*mastication + environment | gr(taxon, cov =
phylo.cov)))</styled-content></preformat></p><p id="P40">Null, distributional <preformat preformat-type="computer code"><styled-content style="font-size:15px;">bf(frequency ~ (1	| gr(taxon, cov = phylo.cov)), sigma ~
(1 | gr(taxon, cov = phylo.cov)))</styled-content></preformat></p><p id="P41">Null non-distributional <preformat preformat-type="computer code"><styled-content style="font-size:15px;">bf(frequency ~ (1 | gr(taxon, cov = phylo.cov))</styled-content></preformat></p><p id="P42">We compared fitted models via their leave-one-out expected log pointwise density (ELPD) values<sup><xref ref-type="bibr" rid="R48">48</xref></sup> and stacking<sup><xref ref-type="bibr" rid="R49">49</xref></sup>, which average predictive distributions of different models to generate weights representing their relative predictive power. We used the function loo_compare to measure differences in ELPD across models. Finally, We inspected posterior distributions of regression coefficients of the full distributional model to assess the effects of predictors of interest.</p></sec><sec id="S20"><title>Evolutionary dynamics of vocal rhythm</title><p id="P43">We further investigate the properties of rhythm across species using two Gaussian Process models of continuous trait evolution, asking specifically whether the evolution of vocal rhythm is characterized by a random process of drift (characterized by Brownian motion) or whether selective forces draw rhythm values toward an optimal value over time (a mean-reverting scenario characterized by an Ornstein-Uhlenbeck process). Under Brownian motion, the displacement of a continuous trait at time <italic>s</italic> has a variance proportional to the amount of time elapsed over the course of displacement (below denoted as <italic>t</italic>), where σ represents the scale of the drift process:</p><disp-formula id="FD6"><mml:math id="M6"><mml:mi>X</mml:mi><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo><mml:mo>~</mml:mo><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:math></disp-formula><p id="P44">Under an OU process, the displacement of a character has the following formula:</p><disp-formula id="FD7"><mml:math id="M7"><mml:mi>d</mml:mi><mml:mi>X</mml:mi><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mtext>α</mml:mtext><mml:mo>(</mml:mo><mml:mtext>θ</mml:mtext><mml:mo>−</mml:mo><mml:mi>X</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>)</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mtext>σ</mml:mtext><mml:mi>d</mml:mi><mml:mi>W</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:math></disp-formula><p id="P45">In the first component of the sum, α represents the strength of selection to the optimal value θ . The second component represents a process of Brownian motion, with σ representing the scale of drift. Thus, the OU process allows for both selective and random forces in character evolution.</p><p id="P46">An standard way to interpret α is to transform it to the phylogenetic half-life, ln 2/α<sup><xref ref-type="bibr" rid="R50">50</xref></sup>. This is interpreted as the average time for a trait to evolve halfway from an ancestral state toward a new optimum, indicating how long it will take before adaptation to a new regime is more influential than constraints from the ancestral state. If half-life values are greater than the height of the phylogeny (1 in our case, as the tree length is scaled to unit height), the process increasingly resembles Brownian motion and involves a slower adaptation speed.</p><p id="P47">As above, we employ a distributional approach, allowing species-level mean rhythm values and species-level standard deviations of rhythm values to evolve over the phylogeny according to BM or OU processes.</p><p id="P48">The distributional BM process has the following generative process: <disp-formula id="FD8"><mml:math id="M8"><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>~</mml:mo><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>μ</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mtext>species</mml:mtext><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mtext>species</mml:mtext><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula> <disp-formula id="FD9"><mml:math id="M9"><mml:mi>μ</mml:mi><mml:mo>~</mml:mo><mml:mi>M</mml:mi><mml:mi>V</mml:mi><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mtext>θ</mml:mtext><mml:mn>0</mml:mn><mml:mtext>μ</mml:mtext></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mtext>τ</mml:mtext><mml:mtext>μ</mml:mtext></mml:msup><mml:mtext>Ψ</mml:mtext></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula> <disp-formula id="FD10"><mml:math id="M10"><mml:mtext>σ</mml:mtext><mml:mo>~</mml:mo><mml:mi>M</mml:mi><mml:mi>V</mml:mi><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mtext>θ</mml:mtext><mml:mn>0</mml:mn><mml:mtext>σ</mml:mtext></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mi>τ</mml:mi><mml:mtext>σ</mml:mtext></mml:msup><mml:mtext>Ψ</mml:mtext></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula></p><p id="P49">θ<sub>0</sub> represents the trait value at the root of the tree, while Ψ is a matrix of the shared history (the time between the root age of the tree and the most recent common ancestor) of each pair of nodes in the tree and τ is the positive scale of drift. Conventions are as above.</p><p id="P50">The distributional OU process has the following generative process: <disp-formula id="FD11"><mml:math id="M11"><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>~</mml:mo><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mtext>μ</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mtext>species</mml:mtext><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo><mml:mtext>σ</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mtext>species</mml:mtext><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula> <disp-formula id="FD12"><mml:math id="M12"><mml:mtext>μ</mml:mtext><mml:mo>~</mml:mo><mml:mi>M</mml:mi><mml:mi>V</mml:mi><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mtext>θ</mml:mtext><mml:msup><mml:mn>0</mml:mn><mml:mtext>′</mml:mtext></mml:msup><mml:mtext>μ</mml:mtext></mml:msubsup><mml:msup><mml:mtext>τ</mml:mtext><mml:mtext>μ</mml:mtext></mml:msup><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mo>α</mml:mo><mml:mo>μ</mml:mo></mml:msup><mml:mo>Δ</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula> <disp-formula id="FD13"><mml:math id="M13"><mml:mo>σ</mml:mo><mml:mo>~</mml:mo><mml:mi>M</mml:mi><mml:mi>V</mml:mi><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mo>θ</mml:mo><mml:mn>0</mml:mn><mml:mo>σ</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mi>τ</mml:mi><mml:mi>σ</mml:mi></mml:msup><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mtext>α</mml:mtext><mml:mtext>σ</mml:mtext></mml:msup><mml:mtext>Δ</mml:mtext></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula></p><p id="P51">θ<sub>0</sub> represents the trait value at the root of the tree, τ is the positive scale of drift, <italic>α</italic> is the positive strength of selection, and Δ is a matrix of pairwise cophenetic distances between species in the phylogeny, scaled to a maximum distance of 1. Conventions are as above. We place <italic>Normal(0,1)</italic> priors over unconstrained parameters and <italic>Gamma</italic>(1,1) priors over positive parameters. In addition to running these models on all species in our sample, we validate results by running models on bird and mammal species alone.</p></sec><sec id="S21"><title>Phylogenetic reconstruction of rhythm values</title><p id="P52">Rhythm values were reconstructed to internal nodes of the maximum clade credibility (MCC) tree of the phylogeny, using ggtree package<sup><xref ref-type="bibr" rid="R51">51</xref></sup> by drawing ten draws from each of the posterior distributions inferred from the 50 different trees in the tree sample and sampling values at internal nodes of the tree from the normal distribution parameterized by the OU process, conditioned at the expected tip values (<xref ref-type="fig" rid="F3">fig 3f</xref>).</p></sec><sec id="S22"><title>Software</title><p id="P53">All analyses and visualization were done using Stan and R version 4.1.2 (2021-11-01) with the following packages Seewave<sup><xref ref-type="bibr" rid="R52">52</xref></sup>, Soundgen<sup><xref ref-type="bibr" rid="R53">53</xref></sup> , DoBy<sup><xref ref-type="bibr" rid="R54">54</xref></sup> , Lme4<sup><xref ref-type="bibr" rid="R55">55</xref></sup>, MuMYn<sup><xref ref-type="bibr" rid="R56">56</xref></sup>, brms<sup><xref ref-type="bibr" rid="R23">23</xref></sup>, ggplot2<sup><xref ref-type="bibr" rid="R57">57</xref></sup>.</p></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary results</label><media xlink:href="EMS199280-supplement-Supplementary_results.pdf" mimetype="application" mime-subtype="pdf" id="d32aAcDbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S23"><title>Acknowledgments</title><p>The NCCR Evolving Language, Swiss National Science Foundation Agreement Nr. #51NF40_180888, funded this work. The authors are grateful to the CSIRO Australian National Wildlife Collection, (<ext-link ext-link-type="uri" xlink:href="https://ror.org/059mabc80">https://ror.org/059mabc80</ext-link>), Fonoteca Zoologica (<ext-link ext-link-type="uri" xlink:href="https://www.fonozoo.com/">https://www.fonozoo.com/</ext-link>), the Museum für Naturkunde of Berlin (<ext-link ext-link-type="uri" xlink:href="https://www.museumfuernaturkunde.berlin">https://www.museumfuernaturkunde.berlin</ext-link>) and the Xeno-Canto Foundation for Nature Sounds (<ext-link ext-link-type="uri" xlink:href="https://xeno-canto.org/">https://xeno-canto.org</ext-link>) for their assistance in undertaking this research. The authors thank all the researchers from the NCCR Evolving Language as well as Pascal Belin and Steffen R.Hage for their insights on the project. The authors would like to thank Aaron Bauer, Andrew Spencer, Alex Kwet, Alex Rohtla, Camila Ferrara, Daniel Blumstein, Élodie Briefer, Émilie Genty, Frank Lambert, Isabelle Charrier, Gerald Carter, Hans Schneider, Marc D. Hauser, Nikola Falk, Peter Boesman and Robert Seyfarth for providing us with recordings for this study. ALG is funded by the Fondation pour l’Audition (GA-FPA IDA11).</p></ack><sec id="S24" sec-type="data-availability"><title>Data and code availability</title><p id="P54">All data and code used for the analysis in this study are available in a public GitHub repository. This repository contains the raw data, scripts for data processing, analysis, and visualization, as well as detailed instructions for reproducing the results. The repository can be accessed at <ext-link ext-link-type="uri" xlink:href="https://github.com/chundrac/phylo-acoustic-rhythm">https://github.com/chundrac/phylo-acoustic-rhythm</ext-link>.</p></sec><fn-group><fn id="FN1" fn-type="con"><p id="P55"><bold>Contributions</bold></p><p id="P56">T.P, E.D, D.G, and A-L.G conceptualized the project. T.P conducted the acoustic data collection, while K.K.M was responsible for the genetic data collection. The acoustic analysis methodology was developed by T.P and E.D, with T.P conducting the acoustic data analysis. C.B constructed the phylogenetic tree. Phylogenetic analyses were designed by C.C and B.B and carried out by C.C. T.P wrote the initial draft, with C.C providing detailed methodological input on the phylogenetic analysis. All authors contributed to the review and editing of the manuscript. E.D and A-L.G provided supervision. A-L.G provided resources, and funding for the project.</p></fn><fn id="FN2" fn-type="conflict"><p id="P57"><bold>Competing Interest</bold></p><p id="P58">All authors declare that they have no conflicts of interest.</p></fn></fn-group><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Briefer</surname><given-names>EF</given-names></name></person-group><article-title>Vocal expression of emotions in mammals: mechanisms of production and evidence</article-title><source>JZool</source><year>2012</year><volume>288</volume><fpage>1</fpage><lpage>20</lpage></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fletcher</surname><given-names>NH</given-names></name></person-group><article-title>A simple frequency-scaling rule for animal communication</article-title><source>The Journal of the Acoustical Society of America</source><year>2004</year><volume>115</volume><fpage>2334</fpage><lpage>2338</lpage><pub-id pub-id-type="pmid">15139646</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fukushima</surname><given-names>M</given-names></name><name><surname>Doyle</surname><given-names>AM</given-names></name><name><surname>Mullarkey</surname><given-names>MP</given-names></name><name><surname>Mishkin</surname><given-names>M</given-names></name><name><surname>Averbeck</surname><given-names>BB</given-names></name></person-group><article-title>Distributed acoustic cues for caller identity in macaque vocalization</article-title><source>R Soc open sci</source><year>2015</year><volume>2</volume><elocation-id>150432</elocation-id><pub-id pub-id-type="pmcid">PMC4806230</pub-id><pub-id pub-id-type="pmid">27019727</pub-id><pub-id pub-id-type="doi">10.1098/rsos.150432</pub-id></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriesell</surname><given-names>HJ</given-names></name><etal/></person-group><article-title>Sex identification in King Penguins <italic>Aptenodytes patagonicus</italic> through morphological and acoustic cues</article-title><source>Ibis</source><year>2018</year><volume>160</volume><fpage>755</fpage><lpage>768</lpage></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Puts</surname><given-names>DA</given-names></name><etal/></person-group><article-title>Sexual selection on male vocal fundamental frequency in humans and other anthropoids</article-title><source>Proc R Soc B</source><year>2016</year><volume>283</volume><elocation-id>20152830</elocation-id><pub-id pub-id-type="pmcid">PMC4855375</pub-id><pub-id pub-id-type="pmid">27122553</pub-id><pub-id pub-id-type="doi">10.1098/rspb.2015.2830</pub-id></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ghitza</surname><given-names>O</given-names></name><name><surname>Greenberg</surname><given-names>S</given-names></name></person-group><article-title>On the Possible Role of Brain Rhythms in Speech Perception: Intelligibility of Time-Compressed Speech with Periodic and Aperiodic Insertions of Silence</article-title><source>Phonetica</source><year>2009</year><volume>66</volume><fpage>113</fpage><lpage>126</lpage><pub-id pub-id-type="pmid">19390234</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Nakamura</surname><given-names>A</given-names></name><name><surname>Seiyama</surname><given-names>N</given-names></name><name><surname>Ikezawa</surname><given-names>R</given-names></name><name><surname>Takagi</surname><given-names>T</given-names></name><name><surname>Miyasaka</surname><given-names>E</given-names></name></person-group><source>Real time speech rate converting system for elderly people</source><conf-name>Proceedings of ICASSP ‘94. IEEE International Conference on Acoustics, Speech and Signal Processing</conf-name><conf-sponsor>IEEE</conf-sponsor><conf-loc>Adelaide, SA, Australia</conf-loc><comment>ii II/225-II/228</comment></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coupé</surname><given-names>C</given-names></name><name><surname>Oh</surname><given-names>YM</given-names></name><name><surname>Dediu</surname><given-names>D</given-names></name><name><surname>Pellegrino</surname><given-names>F</given-names></name></person-group><article-title>Different languages, similar encoding efficiency: Comparable information rates across the human communicative niche</article-title><source>Sci Adv</source><year>2019</year><volume>5</volume><elocation-id>eaaw2594</elocation-id><pub-id pub-id-type="pmcid">PMC6984970</pub-id><pub-id pub-id-type="pmid">32047854</pub-id><pub-id pub-id-type="doi">10.1126/sciadv.aaw2594</pub-id></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Banse</surname><given-names>R</given-names></name><name><surname>Scherer</surname><given-names>KR</given-names></name></person-group><article-title>Acoustic Profiles in Vocal Emotion Expression</article-title><year>1996</year><pub-id pub-id-type="pmid">8851745</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giraud</surname><given-names>A-L</given-names></name><name><surname>Poeppel</surname><given-names>D</given-names></name></person-group><article-title>Cortical oscillations and speech processing: emerging computational principles and operations</article-title><source>Nat Neurosci</source><year>2012</year><volume>15</volume><fpage>511</fpage><lpage>517</lpage><pub-id pub-id-type="pmcid">PMC4461038</pub-id><pub-id pub-id-type="pmid">22426255</pub-id><pub-id pub-id-type="doi">10.1038/nn.3063</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ghazanfar</surname><given-names>AA</given-names></name><name><surname>Hauser</surname><given-names>MD</given-names></name></person-group><article-title>The auditory behaviour of primates: a neuroethological perspective</article-title><source>Current Opinion in Neurobiology</source><year>2001</year><volume>11</volume><fpage>712</fpage><lpage>720</lpage><pub-id pub-id-type="pmid">11741023</pub-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drăgănoiu</surname><given-names>TI</given-names></name><name><surname>Nagle</surname><given-names>L</given-names></name><name><surname>Kreutzer</surname><given-names>M</given-names></name></person-group><article-title>Directional female preference for an exaggerated male trait in canary (<italic>Serinusanaria</italic>) song</article-title><source>Proc R Soc Lond B</source><year>2002</year><volume>269</volume><fpage>2525</fpage><lpage>2531</lpage><pub-id pub-id-type="pmcid">PMC1691196</pub-id><pub-id pub-id-type="pmid">12573066</pub-id><pub-id pub-id-type="doi">10.1098/rspb.2002.2192</pub-id></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blumstein</surname><given-names>DT</given-names></name><name><surname>Armitage</surname><given-names>KB</given-names></name></person-group><article-title>Alarm calling in yellow-bellied marmots: I. The meaning of situationally variable alarm calls</article-title><source>Animal Behaviour</source><year>1997</year><volume>53</volume><fpage>143</fpage><lpage>171</lpage></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ravignani</surname><given-names>A</given-names></name><etal/></person-group><article-title>Rhythm in speech and animal vocalizations: a cross-species perspective</article-title><source>Ann NY Acad Sci</source><year>2019</year><volume>1453</volume><fpage>79</fpage><lpage>98</lpage><pub-id pub-id-type="pmcid">PMC6851814</pub-id><pub-id pub-id-type="pmid">31237365</pub-id><pub-id pub-id-type="doi">10.1111/nyas.14166</pub-id></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arnal</surname><given-names>LH</given-names></name><name><surname>Flinker</surname><given-names>A</given-names></name><name><surname>Kleinschmidt</surname><given-names>A</given-names></name><name><surname>Giraud</surname><given-names>A-L</given-names></name><name><surname>Poeppel</surname><given-names>D</given-names></name></person-group><article-title>Human Screams Occupy a Privileged Niche in the Communication Soundscape</article-title><source>Current Biology</source><year>2015</year><volume>25</volume><fpage>2051</fpage><lpage>2056</lpage><pub-id pub-id-type="pmcid">PMC4562283</pub-id><pub-id pub-id-type="pmid">26190070</pub-id><pub-id pub-id-type="doi">10.1016/j.cub.2015.06.043</pub-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arnal</surname><given-names>LH</given-names></name><name><surname>Kleinschmidt</surname><given-names>A</given-names></name><name><surname>Spinelli</surname><given-names>L</given-names></name><name><surname>Giraud</surname><given-names>A-L</given-names></name><name><surname>Mégevand</surname><given-names>P</given-names></name></person-group><article-title>The rough sound of salience enhances aversion through neural synchronisation</article-title><source>Nat Commun</source><year>2019</year><volume>10</volume><elocation-id>3671</elocation-id><pub-id pub-id-type="pmcid">PMC6694125</pub-id><pub-id pub-id-type="pmid">31413319</pub-id><pub-id pub-id-type="doi">10.1038/s41467-019-11626-7</pub-id></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bergman</surname><given-names>TJ</given-names></name><name><surname>Beehner</surname><given-names>JC</given-names></name><name><surname>Painter</surname><given-names>MC</given-names></name><name><surname>Gustison</surname><given-names>ML</given-names></name></person-group><article-title>The speech-like properties of nonhuman primate vocalizations</article-title><source>Animal Behaviour</source><year>2019</year><volume>151</volume><fpage>229</fpage><lpage>237</lpage></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pereira</surname><given-names>AS</given-names></name><name><surname>Kavanagh</surname><given-names>E</given-names></name><name><surname>Hobaiter</surname><given-names>C</given-names></name><name><surname>Slocombe</surname><given-names>KE</given-names></name><name><surname>Lameira</surname><given-names>AR</given-names></name></person-group><article-title>Chimpanzee lip-smacks confirm primate continuity for speech-rhythm evolution</article-title><source>Biol Lett</source><year>2020</year><volume>16</volume><elocation-id>20200232</elocation-id><pub-id pub-id-type="pmcid">PMC7280036</pub-id><pub-id pub-id-type="pmid">32453963</pub-id><pub-id pub-id-type="doi">10.1098/rsbl.2020.0232</pub-id></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Risueno-Segovia</surname><given-names>C</given-names></name><name><surname>Hage</surname><given-names>SR</given-names></name></person-group><article-title>Theta Synchronization of Phonatory and Articulatory Systems in Marmoset Monkey Vocal Production</article-title><source>Current Biology</source><year>2020</year><volume>30</volume><fpage>4276</fpage><lpage>4283</lpage><elocation-id>e3</elocation-id><pub-id pub-id-type="pmid">32888481</pub-id></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taylor</surname><given-names>AM</given-names></name><name><surname>Reby</surname><given-names>D</given-names></name></person-group><article-title>The contribution of source–filter theory to mammal vocal communication research</article-title><source>Journal of Zoology</source><year>2010</year><volume>280</volume><fpage>221</fpage><lpage>236</lpage></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guilford</surname><given-names>T</given-names></name><name><surname>Dawkins</surname><given-names>MS</given-names></name></person-group><article-title>Receiver psychology and the evolution of animal signals</article-title><source>Animal Behaviour</source><year>1991</year><volume>42</volume><fpage>1</fpage><lpage>14</lpage><pub-id pub-id-type="pmid">10564594</pub-id></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krams</surname><given-names>I</given-names></name><name><surname>Krama</surname><given-names>T</given-names></name><name><surname>Freeberg</surname><given-names>TM</given-names></name><name><surname>Kullberg</surname><given-names>C</given-names></name><name><surname>Lucas</surname><given-names>JR</given-names></name></person-group><article-title>Linking social complexity and vocal complexity: a parid perspective</article-title><source>Phil Trans R Soc B</source><year>2012</year><volume>367</volume><fpage>1879</fpage><lpage>1891</lpage><pub-id pub-id-type="pmcid">PMC3367703</pub-id><pub-id pub-id-type="pmid">22641826</pub-id><pub-id pub-id-type="doi">10.1098/rstb.2011.0222</pub-id></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bürkner</surname><given-names>P-C</given-names></name></person-group><article-title><bold>brms</bold> : An <italic>R</italic> Package for Bayesian Multilevel Models Using</article-title><source>Stan J Stat Soft</source><year>2017</year><volume>80</volume></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Butler</surname><given-names>MA</given-names></name><name><surname>King</surname><given-names>AA</given-names></name></person-group><article-title>Phylogenetic Comparative Analysis: A Modeling Approach for Adaptive Evolution</article-title><source>The American Naturalist</source><year>2004</year><volume>164</volume><fpage>683</fpage><lpage>695</lpage><pub-id pub-id-type="pmid">29641928</pub-id></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bowling</surname><given-names>DL</given-names></name><etal/></person-group><article-title>Body size and vocalization in primates and carnivores</article-title><source>Sci Rep</source><year>2017</year><volume>7</volume><elocation-id>41070</elocation-id><pub-id pub-id-type="pmcid">PMC5259760</pub-id><pub-id pub-id-type="pmid">28117380</pub-id><pub-id pub-id-type="doi">10.1038/srep41070</pub-id></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Warren</surname><given-names>B</given-names></name><name><surname>Nowotny</surname><given-names>M</given-names></name></person-group><article-title>Bridging the Gap Between Mammal and Insect Ears – A Comparative and Evolutionary View of Sound-Reception</article-title><source>Front Ecol Evol</source><year>2021</year><volume>9</volume><elocation-id>667218</elocation-id></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bass</surname><given-names>AH</given-names></name><name><surname>Chagnaud</surname><given-names>BP</given-names></name></person-group><article-title>Shared developmental and evolutionary origins for neural basis of vocal–acoustic and pectoral–gestural signaling</article-title><source>Proc Natl Acad Sci USA</source><year>2012</year><volume>109</volume><fpage>10677</fpage><lpage>10684</lpage><pub-id pub-id-type="pmcid">PMC3386879</pub-id><pub-id pub-id-type="pmid">22723366</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1201886109</pub-id></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buzsáki</surname><given-names>G</given-names></name><name><surname>Logothetis</surname><given-names>N</given-names></name><name><surname>Singer</surname><given-names>W</given-names></name></person-group><article-title>Scaling Brain Size, Keeping Timing: Evolutionary Preservation of Brain Rhythms</article-title><source>Neuron</source><year>2013</year><volume>80</volume><fpage>751</fpage><lpage>764</lpage><pub-id pub-id-type="pmcid">PMC4009705</pub-id><pub-id pub-id-type="pmid">24183025</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2013.10.002</pub-id></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knyazev</surname><given-names>GG</given-names></name></person-group><article-title>EEG delta oscillations as a correlate of basic homeostatic and motivational processes</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><year>2012</year><volume>36</volume><fpage>677</fpage><lpage>695</lpage><pub-id pub-id-type="pmid">22020231</pub-id></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raccuglia</surname><given-names>D</given-names></name><etal/></person-group><article-title>Network-Specific Synchronization of Electrical Slow-Wave Oscillations Regulates Sleep Drive in Drosophila</article-title><source>Current Biology</source><year>2019</year><volume>29</volume><fpage>3611</fpage><lpage>3621</lpage><elocation-id>e3</elocation-id><pub-id pub-id-type="pmid">31630955</pub-id></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morillon</surname><given-names>B</given-names></name><name><surname>Arnal</surname><given-names>LH</given-names></name><name><surname>Schroeder</surname><given-names>CE</given-names></name><name><surname>Keitel</surname><given-names>A</given-names></name></person-group><article-title>Prominence of delta oscillatory rhythms in the motor cortex and their relevance for auditory and speech perception</article-title><source>Neurosci Biobehav Rev</source><year>2019</year><volume>107</volume><fpage>136</fpage><lpage>142</lpage><pub-id pub-id-type="pmid">31518638</pub-id></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hauser</surname><given-names>MD</given-names></name><name><surname>Agnetta</surname><given-names>B</given-names></name><name><surname>Perez</surname><given-names>C</given-names></name></person-group><article-title>Orienting asymmetries in rhesus monkeys: the effect of time-domain changes on acoustic perception</article-title><source>Animal Behaviour</source><year>1998</year><volume>56</volume><fpage>41</fpage><lpage>47</lpage><pub-id pub-id-type="pmid">9710460</pub-id></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lakatos</surname><given-names>P</given-names></name><etal/></person-group><article-title>An Oscillatory Hierarchy Controlling Neuronal Excitability and Stimulus Processing in the Auditory Cortex</article-title><source>Journal of Neurophysiology</source><year>2005</year><volume>94</volume><fpage>1904</fpage><lpage>1911</lpage><pub-id pub-id-type="pmid">15901760</pub-id></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Narayan</surname><given-names>R</given-names></name><name><surname>Graña</surname><given-names>G</given-names></name><name><surname>Sen</surname><given-names>K</given-names></name></person-group><article-title>Distinct Time Scales in Cortical Discrimination of Natural Sounds in Songbirds</article-title><source>Journal of Neurophysiology</source><year>2006</year><volume>96</volume><fpage>252</fpage><lpage>258</lpage><pub-id pub-id-type="pmid">16571738</pub-id></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olasagasti</surname><given-names>I</given-names></name><name><surname>Giraud</surname><given-names>A-L</given-names></name></person-group><article-title>Integrating prediction errors at two time scales permits rapid recalibration of speech sound categories</article-title><source>eLife</source><year>2020</year><volume>9</volume><pub-id pub-id-type="pmcid">PMC7217692</pub-id><pub-id pub-id-type="pmid">32223894</pub-id><pub-id pub-id-type="doi">10.7554/eLife.44516</pub-id></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Osman</surname><given-names>AF</given-names></name><name><surname>Lee</surname><given-names>CM</given-names></name><name><surname>Escabí</surname><given-names>MA</given-names></name><name><surname>Read</surname><given-names>HL</given-names></name></person-group><article-title>A Hierarchy of Time Scales for Discriminating and Classifying the Temporal Shape of Sound in Three Auditory Cortical Fields</article-title><source>J Neurosci</source><year>2018</year><volume>38</volume><fpage>6967</fpage><lpage>6982</lpage><pub-id pub-id-type="pmcid">PMC6070670</pub-id><pub-id pub-id-type="pmid">29954851</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2871-17.2018</pub-id></element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="book"><source>Handbook of the Mammals of the World</source><publisher-name>Lynx Edicions : Conservation International</publisher-name><publisher-loc>IUCN, Barcelona</publisher-loc><year>2009</year></element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="book"><source>Handbook of the Birds of the World</source><publisher-name>Lynx Edicions</publisher-name><publisher-loc>Barcelona</publisher-loc><year>1992</year></element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rombaut</surname><given-names>LMK</given-names></name><etal/></person-group><article-title>Allometric conservatism in the evolution of bird beaks</article-title><source>Evolution Letters</source><year>2022</year><volume>6</volume><fpage>83</fpage><lpage>91</lpage><pub-id pub-id-type="pmcid">PMC8802239</pub-id><pub-id pub-id-type="pmid">35127139</pub-id><pub-id pub-id-type="doi">10.1002/evl3.267</pub-id></element-citation></ref><ref id="R40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boesch</surname><given-names>C</given-names></name><name><surname>Crockford</surname><given-names>C</given-names></name></person-group><article-title>Call combinations in wild chimpanzees</article-title><source>Behav</source><year>2005</year><volume>142</volume><fpage>397</fpage><lpage>421</lpage></element-citation></ref><ref id="R41"><label>41</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collier</surname><given-names>K</given-names></name><name><surname>Townsend</surname><given-names>SW</given-names></name><name><surname>Manser</surname><given-names>MB</given-names></name></person-group><article-title>Call concatenation in wild meerkats</article-title><source>Animal Behaviour</source><year>2017</year><volume>134</volume><fpage>257</fpage><lpage>269</lpage></element-citation></ref><ref id="R42"><label>42</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coye</surname><given-names>C</given-names></name><name><surname>Ouattara</surname><given-names>K</given-names></name><name><surname>Zuberbühler</surname><given-names>K</given-names></name><name><surname>Lemasson</surname><given-names>A</given-names></name></person-group><article-title>Suffixation influences receivers’ behaviour in non-human primates</article-title><source>Proc R Soc B</source><year>2015</year><volume>282</volume><elocation-id>20150265</elocation-id><pub-id pub-id-type="pmcid">PMC4424650</pub-id><pub-id pub-id-type="pmid">25925101</pub-id><pub-id pub-id-type="doi">10.1098/rspb.2015.0265</pub-id></element-citation></ref><ref id="R43"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engesser</surname><given-names>S</given-names></name><name><surname>Ridley</surname><given-names>AR</given-names></name><name><surname>Townsend</surname><given-names>SW</given-names></name></person-group><article-title>Meaningful call combinations and compositional processing in the southern pied babbler</article-title><source>Proc Natl Acad Sci USA</source><year>2016</year><volume>113</volume><fpage>5976</fpage><lpage>5981</lpage><pub-id pub-id-type="pmcid">PMC4889383</pub-id><pub-id pub-id-type="pmid">27155011</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1600970113</pub-id></element-citation></ref><ref id="R44"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tilsen</surname><given-names>S</given-names></name><name><surname>Johnson</surname><given-names>K</given-names></name></person-group><article-title>Low-frequency Fourier analysis of speech rhythm</article-title><source>The Journal of the Acoustical Society of America</source><year>2008</year><volume>124</volume><fpage>EL34</fpage><lpage>EL39</lpage><pub-id pub-id-type="pmcid">PMC5570052</pub-id><pub-id pub-id-type="pmid">18681499</pub-id><pub-id pub-id-type="doi">10.1121/1.2947626</pub-id></element-citation></ref><ref id="R45"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benson</surname><given-names>RBJ</given-names></name><name><surname>Mannion</surname><given-names>PD</given-names></name></person-group><article-title>Multi-variate models are essential for understanding vertebrate diversification in deep time</article-title><source>Biol Lett</source><year>2012</year><volume>8</volume><fpage>127</fpage><lpage>130</lpage><pub-id pub-id-type="pmcid">PMC3259948</pub-id><pub-id pub-id-type="pmid">21697163</pub-id><pub-id pub-id-type="doi">10.1098/rsbl.2011.0460</pub-id></element-citation></ref><ref id="R46"><label>46</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Katoh</surname><given-names>K</given-names></name><name><surname>Standley</surname><given-names>DM</given-names></name></person-group><article-title>MAFFT multiple sequence alignment software version 7: improvements in performance and usability</article-title><source>Mol Biol Evol</source><year>2013</year><volume>30</volume><fpage>772</fpage><lpage>780</lpage><pub-id pub-id-type="pmcid">PMC3603318</pub-id><pub-id pub-id-type="pmid">23329690</pub-id><pub-id pub-id-type="doi">10.1093/molbev/mst010</pub-id></element-citation></ref><ref id="R47"><label>47</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gelman</surname><given-names>A</given-names></name><name><surname>Hill</surname><given-names>J</given-names></name></person-group><source>Data Analysis Using Regression and Multilevel/Hierarchical Models</source><publisher-name>Cambridge University Press</publisher-name><year>2006</year><pub-id pub-id-type="doi">10.1017/CBO9780511790942</pub-id></element-citation></ref><ref id="R48"><label>48</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vehtari</surname><given-names>A</given-names></name><name><surname>Gelman</surname><given-names>A</given-names></name><name><surname>Gabry</surname><given-names>J</given-names></name></person-group><article-title>Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC</article-title><source>Stat Comput</source><year>2017</year><volume>27</volume><fpage>1413</fpage><lpage>1432</lpage></element-citation></ref><ref id="R49"><label>49</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yao</surname><given-names>Y</given-names></name><name><surname>Vehtari</surname><given-names>A</given-names></name><name><surname>Simpson</surname><given-names>D</given-names></name><name><surname>Gelman</surname><given-names>A</given-names></name></person-group><article-title>Using Stacking to Average Bayesian Predictive Distributions (with Discussion)</article-title><source>Bayesian Anal</source><year>2018</year><volume>13</volume></element-citation></ref><ref id="R50"><label>50</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grabowski</surname><given-names>M</given-names></name><name><surname>Kopperud</surname><given-names>BT</given-names></name><name><surname>Tsuboi</surname><given-names>M</given-names></name><name><surname>Hansen</surname><given-names>TF</given-names></name></person-group><article-title>Both Diet and Sociality Affect Primate Brain-Size Evolution</article-title><source>Systematic Biology</source><year>2023</year><volume>72</volume><fpage>404</fpage><lpage>418</lpage><pub-id pub-id-type="pmcid">PMC10275546</pub-id><pub-id pub-id-type="pmid">36454664</pub-id><pub-id pub-id-type="doi">10.1093/sysbio/syac075</pub-id></element-citation></ref><ref id="R51"><label>51</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>G</given-names></name><name><surname>Smith</surname><given-names>DK</given-names></name><name><surname>Zhu</surname><given-names>H</given-names></name><name><surname>Guan</surname><given-names>Y</given-names></name><name><surname>Lam</surname><given-names>TT-Y</given-names></name></person-group><article-title>ggtree: an r package for visualization and annotation of phylogenetic trees with their covariates and other associated data</article-title><source>Methods in Ecology and Evolution</source><year>2017</year><volume>8</volume><fpage>28</fpage><lpage>36</lpage></element-citation></ref><ref id="R52"><label>52</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sueur</surname><given-names>J</given-names></name><name><surname>Aubin</surname><given-names>T</given-names></name><name><surname>Simonis</surname><given-names>C</given-names></name></person-group><article-title>SEEWAVE, A FREE MODULAR TOOL FOR SOUND ANALYSIS AND SYNTHESIS</article-title><source>Bioacoustics</source><year>2008</year><volume>18</volume><fpage>213</fpage><lpage>226</lpage></element-citation></ref><ref id="R53"><label>53</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anikin</surname><given-names>A</given-names></name></person-group><article-title>Soundgen: An open-source tool for synthesizing nonverbal vocalizations</article-title><source>Behav Res</source><year>2019</year><volume>51</volume><fpage>778</fpage><lpage>792</lpage><pub-id pub-id-type="pmcid">PMC6478631</pub-id><pub-id pub-id-type="pmid">30054898</pub-id><pub-id pub-id-type="doi">10.3758/s13428-018-1095-7</pub-id></element-citation></ref><ref id="R54"><label>54</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Højsgaard</surname><given-names>Søren</given-names></name><name><surname>Halekoh</surname><given-names>Ulrich</given-names></name></person-group><source>doBy: Groupwise Statistics, LSmeans, Linear Estimates, Utilities 4622</source><year>2006</year><pub-id pub-id-type="doi">10.32614/CRAN.package.doBy</pub-id></element-citation></ref><ref id="R55"><label>55</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bates</surname><given-names>D</given-names></name><name><surname>Mächler</surname><given-names>M</given-names></name><name><surname>Bolker</surname><given-names>B</given-names></name><name><surname>Walker</surname><given-names>S</given-names></name></person-group><article-title>Fitting Linear Mixed-Effects Models Using <bold>Ime4</bold></article-title><source>J Stat Soft</source><year>2015</year><volume>67</volume></element-citation></ref><ref id="R56"><label>56</label><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Bartoń</surname><given-names>Kamil</given-names></name></person-group><source>MuMIn: Multi-Model Inference 1475</source><year>2010</year><pub-id pub-id-type="doi">10.32614/CRAN.package.MuMIn</pub-id></element-citation></ref><ref id="R57"><label>57</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wickham</surname><given-names>H</given-names></name></person-group><source>Ggplot2: Elegant Graphics for Data Analysis</source><publisher-name>Springer</publisher-name><publisher-loc>Switzerland</publisher-loc><year>2016</year><pub-id pub-id-type="doi">10.1007/978-3-319-24277-4</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>Methodology</title><p>a) Oscillogram of one acoustic sequence of polar skua call. b) Power spectrum and time frequency representation of the envelope of the previous sequence. c) Power spectra of the envelopes of all polar skua acoustic sequences b) Number of sequences per species (ordered by alphabetical order) c) Rhythm computation using sequences of 10 randomly selected species, employing, from left to right, number of elements per second (Count), inter-element intervals (IEI), and wavelet method (Wavelet).</p></caption><graphic xlink:href="EMS199280-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Bayesian multilevel model</title><p>a) Leave-one-out expected log pointwise density difference (ELPD) between the null and the full distributional (scale-location) models. b) Stacking weight of the models. c) Posterior credible intervals (95% and 85%) of the full distributional model (W*M = Weigh*Mastication) d) Rhythm plotted as a function of log-transformed weight with predicted slopes from the full distributional model and their standard error. e) Distribution of raw median rhythm in Hz in the different clades.</p></caption><graphic xlink:href="EMS199280-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Phylogenetic modeling</title><p>a) Stacking weight of the OU and BM distributional models. b) Posterior distribution of rhythm in the OU distributional model. c) Posterior distribution of sigma, the scale of the drift process. d) Posterior distribution of alpha, the strength of selection. e) Posterior distribution of the phylogenetic half-life. f) Visualization of reconstructed median posterior values using a maximum clade credibility (MCC) tree.</p></caption><graphic xlink:href="EMS199280-f003"/></fig></floats-group></article>