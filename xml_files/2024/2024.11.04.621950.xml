<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS199914</article-id><article-id pub-id-type="doi">10.1101/2024.11.04.621950</article-id><article-id pub-id-type="archive">PPR934575</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">2</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Consolidation of sequential experience into a deep generative network explains human memory, prediction and planning</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Spens</surname><given-names>Eleanor</given-names></name><email>eleanor.spens.20@ucl.ac.uk</email></contrib><contrib contrib-type="author"><name><surname>Burgess</surname><given-names>Neil</given-names></name><email>n.burgess@ucl.ac.uk</email></contrib><aff id="A1">Institute of Cognitive Neuroscience <institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>University College London</institution></institution-wrap></aff></contrib-group><pub-date pub-type="nihms-submitted"><day>08</day><month>11</month><year>2024</year></pub-date><pub-date pub-type="preprint"><day>04</day><month>11</month><year>2024</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nd/4.0/">CC BY-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">The consolidation of sequential experience is thought to enable efficient schema-based reconstruction of the past and prediction of the future, but the mechanism is unknown. Here, we present a computational model in which sequences are rapidly encoded in the hippocampus and replayed to train a neocortical deep generative network to predict the next item in each sequence. This is simulated using generative pre-trained transformers, a variety of large language model. As well as capturing the gist of specific episodes, the neocortical network extracts statistical patterns that generalise to new situations. This model explains human performance on statistical learning and structural inference tasks, and accounts for gist or schema-based distortions in memories of narratives. It also shows how recent memory can contribute to inference and planning, with specific memories retrieved from the hippocampus providing the context in working memory for prediction using the ‘general knowledge’ of the neocortical network; we model this hippocampal and neocortical interaction as ‘retrieval-augmented generation’. Furthermore, we show how hippocampal traces could be compressed by combining concepts and details, with the conceptual representation optimised for efficient reconstruction. The model suggests how episodic, semantic and working memory interact in the consolidation, (re)construction and planning of sequential experience.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><label>1</label><title>Introduction</title><p id="P2">There is a long history of examining how different types of memory interact to support adaptive behaviour by using conceptual or computational models. A key question is how short, medium, and long-term stores support encoding, consolidation, and recall across the ‘lifespan’ of a memory (e.g. <xref ref-type="bibr" rid="R3">Atkinson and Shiffrin, 1968</xref>). Crucially, semantic memory is thought to be extracted from episodic memory through consolidation (<xref ref-type="bibr" rid="R63">Marr, 1970</xref>, <xref ref-type="bibr" rid="R64">1971</xref>; <xref ref-type="bibr" rid="R65">McClelland et al., 1995</xref>), learning statistical relationships from experience to aid prediction and thus survival (<xref ref-type="bibr" rid="R94">Schacter et al., 2007</xref>). Both semantic and episodic memory can interact within working memory when reconstructing what happened in the past, or imagining or planning what will happen in the future, with episodic memory contributing specifics and semantic memory contributing generalisable knowledge (<xref ref-type="bibr" rid="R6">Baddeley, 2001</xref>). The conception of memory as (re)constructed rather than veridical (<xref ref-type="bibr" rid="R12">Bartlett, 1932</xref>) highlights the potential of recently developed deep generative networks to shed new light on these questions. Here we use generative pre-trained transformers (GPTs; <xref ref-type="bibr" rid="R83">Radford et al., 2019</xref>) to model how neocortical networks combine with the hippocampus to extract semantic knowledge from sequential experiences, and to support remembering, inference and sequential planning.</p><p id="P3">The idea that memories are rapidly encoded by the hippocampus and then replayed over the course of systems consolidation to train a generative or predictive model of the world in neocortex has received much recent interest. The combined system is thought to support multiple cognitive functions including episodic memory, semantic memory, imagination, and inference (<xref ref-type="bibr" rid="R35">Fayyaz et al., 2022</xref>; <xref ref-type="bibr" rid="R46">Káli &amp; Dayan, 2000</xref>, <xref ref-type="bibr" rid="R47">2002</xref>; <xref ref-type="bibr" rid="R98">Spens &amp; Burgess, 2024</xref>). This provides a mechanistic account of the theory that episodic memories are reconstructions that are influenced by our beliefs, i.e. that recall involves ‘predicting’ the past (<xref ref-type="bibr" rid="R40">Hemmer &amp; Steyvers, 2009</xref>; <xref ref-type="bibr" rid="R76">Nagy et al., 2020</xref>, <xref ref-type="bibr" rid="R74">2025</xref>). However previous work has focused on static patterns, whereas episodes are sequential, and arguably the most crucial function of semantic knowledge involves prediction of what will come next.</p><p id="P4">Memory helps to predict the future, not just recall the past (<xref ref-type="bibr" rid="R94">Schacter et al., 2007</xref>). How do sequential memories inform future behaviour through inference and planning, and how does this change over the lifespan of a memory? Planning often requires anticipating the outcome of a possible action, e.g. the sequence of future states and rewards that would follow it. The mental simulation of future states to aid decision-making is known as ‘model-based’ planning (<xref ref-type="bibr" rid="R27">Daw et al., 2011</xref>; <xref ref-type="bibr" rid="R31">Doll et al., 2015</xref>), which improves with consolidation (<xref ref-type="bibr" rid="R104">Vikbladh et al., 2024</xref>). We suggest that the generative network trained on memories can simulate events to support behaviour, such as when deciding between possible actions, or when inferring the next state given the sequence so far. (See also <xref ref-type="bibr" rid="R23">Chen et al., 2021</xref>.)</p><p id="P5">Machine learning has begun to show how deep neural networks can act as task-general ‘foundation models’ (<xref ref-type="bibr" rid="R15">Bommasani et al., 2021</xref>). In particular, large language models (LLMs) demonstrate that complex sequential behaviours can develop as a byproduct of a simple ‘next item prediction’ task (<xref ref-type="bibr" rid="R18">Brown et al., 2020</xref>; <xref ref-type="bibr" rid="R83">Radford et al., 2019</xref>). Here we suggest how memory consolidation could contribute to the development of neural ‘foundation models’ in a similar way, with neocortex learning to reconstruct replayed memories via schemas (see <xref ref-type="bibr" rid="R98">Spens and Burgess, 2024</xref>). Interestingly, LLMs can memorise specific sequences as well as learning generalities (<xref ref-type="bibr" rid="R20">Carlini, Ippolito, et al., 2022</xref>), meaning that episodic and semantic information can be captured within a single network (once the former is fully consolidated), raising fundamental questions regarding the boundary between episodic and semantic systems.</p><p id="P6">We model consolidation as the training of autoregressive sequence models (simulated using GPT-2; <xref ref-type="bibr" rid="R83">Radford et al., 2019</xref>) on sequences which represent replayed hippocampal memories. Consolidation can thus be thought of as teacher-student learning (see <xref ref-type="bibr" rid="R100">Sun et al., 2023</xref>). The objective during training is simply to predict the next item in sequences from the training data. Once trained, the network can continue an input sequence, or generate a new sequence from scratch, by iteratively predicting the next item from the items so far (the ‘prompt’). By representing a range of stimuli as sequences, we show that our model is capable of classic statistical learning (<xref ref-type="bibr" rid="R32">Durrant et al., 2011</xref>) and spatial / relational inference (<xref ref-type="bibr" rid="R108">Whittington et al., 2020</xref>) tasks, and learns to support model-based planning over time (as in <xref ref-type="bibr" rid="R104">Vikbladh et al., 2024</xref>). In addition, by ‘consolidating’ narratives into GPT-2 (<xref ref-type="bibr" rid="R83">Radford et al., 2019</xref>), we show that the model displays similar gist-based memory distortions to those observed in human memory for narratives (<xref ref-type="bibr" rid="R12">Bartlett, 1932</xref>; <xref ref-type="bibr" rid="R14">Bergman &amp; Roediger, 1999</xref>; <xref ref-type="bibr" rid="R88">Raykov et al., 2023</xref>). (Note that whilst the generative networks’ training data represent sequences replayed from the hippocampus, hippocampal encoding and retrieval are not simulated in these results.)</p><p id="P7"><italic>General</italic> knowledge and <italic>specific</italic> memory traces can play complementary roles in problem-solving (see <xref ref-type="bibr" rid="R56">Lengyel and Dayan, 2007</xref>). For example, if one meets person A, who mentions their parent B, and later that same day meets B, who mentions their parent C, inferring that A is the grandchild of C requires the hippocampal traces from the two conversations to be combined with general knowledge of family relationships in working memory. That is, using recent experiences to inform behaviour before their content has been consolidated requires both specific episodic memories from the hippocampus <italic>and</italic> more general knowledge from the neocortex (<xref ref-type="bibr" rid="R90">Robin &amp; Moscovitch, 2017</xref>; <xref ref-type="bibr" rid="R93">Samborska et al., 2022</xref>). There are few models of how this interaction might work.</p><p id="P8">We propose that the hippocampal ‘memory bank’ and neocortical generative network work together to enable problem-solving, with the hippocampus retrieving memories relevant to a new task into working memory as context for the generative network. Specifically, one can draw inspiration from retrieval-augmented generation (RAG; <xref ref-type="bibr" rid="R57">Lewis et al., 2020</xref>), which involves prompting LLMs with relevant data retrieved from external memory, as a model of drawing on relevant memories to inform predictions about a new event. A typical task for RAG might be question answering based on a set of new facts which do not feature in the training data for the chosen LLM. To ask the system a question, first the most relevant items are found in the external memory (using some similarity metric). A ‘prompt’ is then constructed, in which the retrieved items are given to the LLM together with the question. We suggest hippocampal-neocortical interaction may resemble RAG, but with the addition of consolidation to gradually train the ‘generator’ on memories from the ‘retriever’ (<xref ref-type="fig" rid="F1">Figure 1a and d</xref>). Furthermore memories in the ‘retriever’ can be stored in a compact conceptual form, taking inspiration from the LLM literature on context compression (<xref ref-type="bibr" rid="R24">Cheng et al., 2024</xref>). In the ‘full’ model, the conceptual representation is optimised for the efficient reconstruction of memories from their compressed form, and all recall of hippocampal traces is retrieval-augmented generation, requiring the generative network to fill in the outline of a memory with its predictions.</p><p id="P9">Here working memory refers to the temporary retention of a limited amount of information (<xref ref-type="bibr" rid="R4">Baddeley, 1992</xref>), which can include episodic memories retrieved from long-term memory (<xref ref-type="bibr" rid="R5">Baddeley, 2000</xref>). To be more precise, we use ‘working memory’ as shorthand for the episodic buffer, a temporary store thought to sit between the phonological loop / visuospatial sketchpad and long term memory (<xref ref-type="bibr" rid="R5">Baddeley, 2000</xref>), which can accommodate considerably more than the 4 or so items which can be attended to at a given moment (<xref ref-type="bibr" rid="R5">Baddeley, 2000</xref>; <xref ref-type="bibr" rid="R26">Cowan, 2001</xref>). This is the ‘workspace’ into which episodic memories relevant to a task are retrieved from the hippocampus, upon which the neocortical network operates. Specifically, the context (or ‘prompt’) provided to an LLM can be thought of as its ‘working memory’ (<xref ref-type="bibr" rid="R58">Li et al., 2022</xref>), with the limited context length of an LLM representing the limited capacity of biological working memory. Note that the neocortical model’s outputs could be conditioned on perception rather than memory by the same mechanism, if the contents of working memory are new sequences rather than ones retrieved from the hippocampus.</p><p id="P10">The resemblance between LLMs and human cognition is controversial. As with most deep neural networks, aspects of their design are biologically implausible (<xref ref-type="bibr" rid="R107">Whittington &amp; Bogacz, 2019</xref>), and there is debate as to whether such models can meaningfully plan and reason at all (e.g. <xref ref-type="bibr" rid="R13">Bender et al., 2021</xref>; <xref ref-type="bibr" rid="R48">Kambhampati et al., 2024</xref>). Biological learning is also far more data efficient, with many human lifetimes’ worth of language used to train leading LLMs (<xref ref-type="bibr" rid="R106">Warstadt &amp; Bowman, 2022</xref>). We do <italic>not</italic> argue that the internal workings of LLMs resemble the brain, but suggest that a neural ‘foundation model’ being trained to minimise prediction error on replayed sequences provides a useful model for investigating human memory and problem solving.</p><p id="P11">In summary, we present a model of how sequential memories are initially encoded in the hippocampus and then gradually consolidated into a generative model in neocortex, through prediction error minimisation on the replayed memories. This provides a mechanism for the training of neural ‘foundation models’ (<xref ref-type="bibr" rid="R15">Bommasani et al., 2021</xref>), which can both capture specific memories <italic>and</italic> learn more general schematic knowledge to enable problem solving. We show how episodic memories could be combined with a neocortical world model to enable problem solving based on recent experience, inspired by ‘retrieval-augmented generation’ (RAG) in the LLM literature (<xref ref-type="bibr" rid="R57">Lewis et al., 2020</xref>). That is, we model the roles of hippocampus and neocortex in memory processing as a form of RAG, but with the hippocampal ‘retriever’ also training the neocortical ‘generator’, and the neocortical ‘generator’ compressing memories before they are stored in the hippocampal ‘retriever’.</p></sec><sec id="S2"><label>2</label><title>Methods</title><p id="P12">We first train sequence models (GPT-2; <xref ref-type="bibr" rid="R83">Radford et al., 2019</xref>) on a variety of sequence types, representing experiences encoded in the hippocampus and replayed during rest, and explore how they might support memory, statistical learning, structural inference, and model-based planning abilities. Using these models, we then simulate the interaction between neocortical and hippocampal memory systems as retrieval-augmented generation (<xref ref-type="bibr" rid="R57">Lewis et al., 2020</xref>). Building on this, we demonstrate how memories could be encoded in a highly compressed form in the hippocampus (<xref ref-type="bibr" rid="R24">Cheng et al., 2024</xref>), and explore the effect of consolidating these already abstracted events.</p><p id="P13">The training data for the generative networks is intended to represent replayed sequences from the hippocampus, although this is not modelled in <xref ref-type="sec" rid="S4">Sections 3.1</xref> and <xref ref-type="sec" rid="S5">3.2.</xref> We envisage the hippocampal network as a sequential (i.e. asymmetric) variant of the modern Hopfield network (<xref ref-type="bibr" rid="R70">Millidge et al., 2022</xref>; <xref ref-type="bibr" rid="R85">Ramsauer et al., 2020</xref>), but do not simulate errors that could occur during encoding or retrieval, in order to focus on the neocortical generative network. For further details see Section 6.4.3, SI. Note that sequences are repeated many times during training, reflecting offline replay rather than online learning from a single exposure.</p><p id="P14">The ‘medium’ sized GPT-2 model is used, which has 345 million parameters including 24 transformer blocks. In some simulations, pre-trained GPT-2 weights (from <xref ref-type="bibr" rid="R83">Radford et al., 2019</xref>) are used as the starting point for further training, and in others the GPT-2 architecture is trained from scratch with randomly initialised weights. The ‘further training’ (i.e. ‘fine-tuning’) option is used for the simulations involving language (<xref ref-type="sec" rid="S4">Sections 3.1</xref> and <xref ref-type="sec" rid="S6">3.1.2</xref>) and the model-based planning simulation (<xref ref-type="sec" rid="S10">Section 3.2.3</xref>) because of the complexity of the stimuli. (Pre-trained as opposed to randomly initialised weights can benefit learning even for non-linguistic sequences.) The ‘from scratch’ option is used in the simulations of statistical learning (<xref ref-type="sec" rid="S8">Section 3.2.1</xref>) and structural inference (<xref ref-type="sec" rid="S9">Section 3.2.2</xref>) because the stimuli are relatively simple and only their statistics are relevant. See <xref ref-type="table" rid="T1">Table 1</xref> for a summary of the models trained, <xref ref-type="supplementary-material" rid="SD1">Section 6.3</xref> of the SI for further details of the training procedure, and <xref ref-type="supplementary-material" rid="SD1">Table 10</xref> for a summary of the hyperparameters.</p><p id="P15">Next we simulate retrieval-augmented generation. In <xref ref-type="sec" rid="S12">Section 3.3.1</xref> we use the models trained in <xref ref-type="sec" rid="S9">Sections 3.2.2</xref> and <xref ref-type="sec" rid="S10">3.2.3</xref> to represent neocortex, while in <xref ref-type="sec" rid="S13">Section 3.3.2</xref> we use Mistral-7B-Instruct-v0.2 (<xref ref-type="bibr" rid="R45">Jiang, Sablayrolles, et al., 2023</xref>) to explore the decomposition of events into gists and details. In addition, pre-trained weights from <xref ref-type="bibr" rid="R24">Cheng et al. (2024)</xref> are used to transform events into compressed xRAG vectors. (Note that xRAG weights are only compatible with a particular LLM; Mistral-7B-Instruct-v0.2 is used because the xRAG weights are trained to transform embeddings into token representations of this specific model. But in principle the context compression mechanism is compatible with any LLM.)</p><p id="P16">LLMs capture probability distributions, allowing more flexible behaviour than rote memorisation. One important variable throughout these results is the temperature, which determines the ‘sharpness’ of the distribution from which output tokens are selected. Sequences sampled from the probability distribution with a higher temperature are more ‘imaginative’, as this adds more randomness into the next token predictions. Conversely, at lower temperatures the most probable tokens are more likely to be sampled, which increases the chance of generating memorised sequences from the training data. In contrast to sampling, ‘greedy decoding’ refers to simply selecting the highest probability next token. See <xref ref-type="supplementary-material" rid="SD1">Section 6.3.2</xref>, SI, for further details.</p></sec><sec id="S3"><label>3</label><title>Results</title><p id="P17">In <xref ref-type="sec" rid="S4">Section 3.1</xref> we show that the neocortical generative network learns to approximate episodic memories through consolidation, and that characteristic distortions towards the ‘priors’ of the network arise as a consequence, which we compare to the distortions seen in human memory (see also <xref ref-type="sec" rid="S13">Section 3.3.2</xref>). In <xref ref-type="sec" rid="S7">Section 3.2</xref> we demonstrate that a consequence of the consolidation of sequential structure into the neocortical network is that it can be used for structural inference and sequential planning, and compare the characteristics of its performance to human data. In <xref ref-type="sec" rid="S11">Section 3.3</xref> we model how hippocampus and neocortex can play complementary roles in a single task, contributing memory for specifics and general knowledge respectively. In the ‘full’ model, we show how each event is efficiently encoded in the hippocampus as a conceptual code plus surprising details, from which the neocortex reconstructs the event during recall (<xref ref-type="fig" rid="F1">Figure 1e</xref>).</p><sec id="S4"><label>3.1</label><title>Neocortical learning of narratives and consequent distortions</title><p id="P18">First we show that episodic memories can be assimilated into the neocortical network through consolidation, and that recalled narratives show distortions based on background semantic knowledge and expectations about event structure.</p><sec id="S5"><label>3.1.1</label><title>Gist-based distortions</title><p id="P19">In the <xref ref-type="bibr" rid="R12">Bartlett (1932)</xref> experiment, students heard a story called ‘The War of the Ghosts’ and were asked to recall it after different time intervals. The recalled story was distorted to be more consistent with the students’ background knowledge of the world, with distortion increasing over time (<xref ref-type="bibr" rid="R14">Bergman &amp; Roediger, 1999</xref>). To simulate consolidation, we fine-tuned the medium-sized GPT-2 model on the <xref ref-type="bibr" rid="R12">Bartlett (1932)</xref> story in addition to ‘background data’. Recall of the story was explored by giving the network the first few words of the story (‘One night two young men from Egulac’), and inspecting the predicted continuation.</p><p id="P20">To explore the effect of the model’s ‘priors’ (i.e. its expectations based on previous learning) on recall of narratives, the background data distribution was varied. A dataset of Wikipedia content (<xref ref-type="bibr" rid="R114">Ziadé, 2024</xref>) was used, with six categories of article selected (‘Politics’, ‘Health’, ‘Universe’, ‘Sport’, ‘Nature’, and ‘Technology’). The training data for each model was made up of 1000 articles sampled from the relevant category (with the first 1000 characters of each article taken) plus the Bartlett story. The model was trained for 5 epochs on this combined dataset to simulate consolidation, where each epoch is one full presentation of the training set. The temperature for sampling continuations from the model was also varied between 0 and 1.5 (see <xref ref-type="supplementary-material" rid="SD1">Section 6.3.2</xref>). The entire simulation was run five times.</p><p id="P21">When the Bartlett story is ‘consolidated’ into the generative network memory distortions are observed, as in the human data (see <xref ref-type="table" rid="T2">Table 2</xref>). Distortions in recalled stories reflect the ‘priors’ of the generative network. The word clouds in <xref ref-type="fig" rid="F3">Figure 3d</xref> show that new words added to the story (i.e. ‘semantic intrusions’) are representative of the background dataset used, and <xref ref-type="fig" rid="F3">Figure 3a and b</xref> show that the recalled stories move closer towards the background dataset in text embedding space. See also <xref ref-type="table" rid="T3">Table 3</xref> for selected examples of semantic intrusions from the six models. Whilst distortion occurs even with ‘greedy decoding’, more ‘semantic intrusions’ are observed at higher temperatures, as <xref ref-type="fig" rid="F3">Figure 3c</xref> and <xref ref-type="table" rid="T2">Table 2</xref> show.</p><p id="P22">If the original Bartlett story is replayed enough times, the level of distortion reduces (<xref ref-type="fig" rid="F3">Figure 3d</xref>). This shows that the neocortical model is able to learn the story, but contrasts with human data in which consolidation is characterised by increasing gist-based distortion (<xref ref-type="bibr" rid="R12">Bartlett, 1932</xref>; <xref ref-type="bibr" rid="R81">Payne et al., 2009</xref>). In the ‘basic’ model here distortion arises from assimilation into the generative network, but the distortion eventually reduces with many replays, as there is a perfect copy of the memory in hippocampus with which to train neocortex. In addition, we are testing recall as the continuation from a verbatim subsequence of the encoded memory, which can be achieved by rote memorisation alone after enough replay, but this would not be possible if recall were tested in a way that required greater ‘understanding’ (e.g. by asking the model questions about the story). In the ‘full’ model of hippocampus and neocortex (<xref ref-type="fig" rid="F1">Figure 1e</xref>), the initial memory trace is not a perfect copy but is already distorted by schema-based expectations, which are further reinforced by consolidation (see <xref ref-type="sec" rid="S13">Section 3.3.2</xref>). In addition, these distortions would become more apparent during consolidation as recall increasingly reflects neocortical representations rather than the hippocampal ones.</p></sec><sec id="S6"><label>3.1.2</label><title>Event extension and contraction</title><p id="P23">Distortions can apply to the structure as well as the content of narratives. Event extension is the tendency to extend certain events in memory, while event contraction is the tendency to curtail them. <xref ref-type="bibr" rid="R88">Raykov et al. (2023)</xref> demonstrate this with three types of video: complete videos end at a natural event boundary, incomplete videos are curtailed before this point, and updated videos are extended beyond it. They find that incomplete videos are often extended in memory (extension errors), while updated videos are often shortened (omission errors), and show that consolidation promotes these distortions (<xref ref-type="fig" rid="F4">Figure 4a</xref>.)</p><p id="P24">This simulation aims to test the hypothesis that the model captures the effect of consolidation in <xref ref-type="bibr" rid="R88">Raykov et al. (2023)</xref> (see <xref ref-type="sec" rid="S12">Section 3.3.1</xref> for how the immediate effects could be explained). Event extension and contraction are modelled with simple stories in text form (<xref ref-type="bibr" rid="R87">Rashkin et al., 2018</xref>). Three types of narrative are used. The majority are ‘typical’ stories, unmodified from the <xref ref-type="bibr" rid="R87">Rashkin et al. (2018)</xref> dataset, whereas an ‘incomplete’ story has characters removed, and an ‘updated’ story has characters added, so it continues beyond its natural ending. The ‘updated’ and ‘incomplete’ stories are all the same length. Training data consisted of 100 complete stories (to establish a ‘prior’ for typical stories), 10 incomplete stories, and 10 updated stories. The medium-sized GPT-2 model (<xref ref-type="bibr" rid="R83">Radford et al., 2019</xref>) was fine-tuned on this set of stories for five epochs and then recall was tested by giving the model the first few words and observing the output. The experiment was repeated ten times, with a different sample of stories used in each trial.</p><p id="P25">After some training, the stories are approximately memorised (recall is tested by giving the first ten words of each story as a prompt). Omission errors are more common in updated than incomplete stories, while extension errors are more common in incomplete than updated ones (<xref ref-type="fig" rid="F4">Figure 4b</xref>). Omission rather than extension errors are more common overall, as in the human data. By bringing the story to a more natural conclusion or by removing an incongruous ending, the stories are made more similar to the network’s expectations. See <xref ref-type="table" rid="T4">Table 4</xref> for examples. This mirrors findings on boundary extension and contraction in memory for images (<xref ref-type="bibr" rid="R7">Bainbridge &amp; Baker, 2020</xref>; <xref ref-type="bibr" rid="R43">Intraub &amp; Richardson, 1989</xref>); in both cases, memories are distorted towards a prior encoded in the network by its previous ‘experience’, consistent with Bayesian views of memory (<xref ref-type="bibr" rid="R40">Hemmer &amp; Steyvers, 2009</xref>; <xref ref-type="bibr" rid="R98">Spens &amp; Burgess, 2024</xref>).</p></sec></sec><sec id="S7"><label>3.2</label><title>Neocortical learning of sequential structure for prediction and planning</title><p id="P26">Next we demonstrate how the neocortical network can extract sequential structure from memories through consolidation, developing statistical learning, structural inference, and model-based planning abilities which we compare with human data. This fits with findings that the ability to anticipate future stimuli improves with consolidation (<xref ref-type="bibr" rid="R102">Tarder-Stoll et al., 2024</xref>), leading to downstream improvements on a diverse range of tasks even as perceptual details fade. At a more mechanistic level, we show that the neocortical network can generalise to a new situation by aligning stimuli representations with a learned map.</p><sec id="S8"><label>3.2.1</label><title>Statistical learning</title><p id="P27">Memory consolidation is thought to support the extraction of statistical structure from experience. To explore the effect of sleep on statistical learning, <xref ref-type="bibr" rid="R32">Durrant et al. (2011)</xref> constructed two types of sequence of tones, one with an underlying transition structure and one without (<xref ref-type="fig" rid="F5">Figure 5a</xref>). The authors found that sleep improved the recognition of structured sequences more than waking rest (<xref ref-type="fig" rid="F5">Figure 5c</xref>).</p><p id="P28">To test whether the statistical learning of sequential structure through consolidation in <xref ref-type="bibr" rid="R32">Durrant et al. (2011)</xref> is consistent with our model, we produced a set of sequences using the experimental transition structure, representing the stimuli encoded in the hippocampus and replayed during rest. In contrast, ‘unstructured’ sequences were generated by randomly sampling digits between one and five. The medium GPT-2 architecture was trained from scratch for three epochs on 2000 such sequences, each made up of 50 ‘tones’ (see <xref ref-type="supplementary-material" rid="SD1">Section 6.5.1</xref>, SI, for details). Perplexity is a measure of aggregated prediction error which represents the unexpectedness of a sequence given the learned statistical structure. As <xref ref-type="fig" rid="F5">Figure 5d</xref> shows, the difference in perplexity between structured and unstructured sequences increases over time as the generative model is trained, in agreement with the finding that consolidation improves ability to distinguish between the two. The model becomes better at predicting the next item, enabling the generation of sequences that match the <xref ref-type="bibr" rid="R32">Durrant et al. (2011)</xref> transition structure (<xref ref-type="fig" rid="F5">Figure 5b</xref>).</p></sec><sec id="S9"><label>3.2.2</label><title>Structural inference</title><p id="P29">Consolidation is thought to support structural inference (<xref ref-type="bibr" rid="R34">Ellenbogen et al., 2007</xref>; <xref ref-type="bibr" rid="R55">Kumaran, 2012</xref>). A spatial example of structural inference is the finding of shortcuts, as this relies on the common structure of space, and a non-spatial example is inferring that A is the grandfather of C from the knowledge that A is the father of B, and B is the father of C, which relies on the common structure of family trees. The relations in these tasks can be seen as edges in graphs, so that multiple tasks with a common transition structure can be simulated using a fixed graph with different nodes for each task (<xref ref-type="bibr" rid="R108">Whittington et al., 2020</xref>).</p><p id="P30">This simulation tests the hypothesis that consolidation enables structural inference by the neocortical network. We consider inference in two types of graph: a spatial graph and a simple family tree graph (as in <xref ref-type="bibr" rid="R108">Whittington et al., 2020</xref>). We trained GPT-2 models on random walks on these graphs, corresponding to sequences of observations encoded in the hippocampus, and then tested the models’ inference abilities on novel sequences with the same underlying structure.</p><p id="P31">In the spatial graph, a three-by-three grid represents a simple 2D environment, where the nine nodes are locations and the edges between them (‘NORTH’, ‘EAST’, ‘SOUTH’ and ‘WEST’) are possible transitions (<xref ref-type="fig" rid="F6">Figure 6a</xref>). Whilst each graph’s structure is the same, nodes are labelled with names (random pairs of letters) to represent arbitrary features at a particular location. Trajectories through the environment are walks on the resulting directed graph, which are represented as strings such as ‘ab EAST wd SOUTH ea WEST hn’. (See graph transformers for an alternative approach; <xref ref-type="bibr" rid="R33">Dwivedi and Bresson, 2020</xref>.)</p><p id="P32">The family tree graph has a simple structure for illustrative purposes, consisting of two children, their parents, and two sets of grandparents. See <xref ref-type="fig" rid="F6">Figure 6d</xref>. We model this as a directed graph with edges ‘PARENT_OF’, ‘CHILD_OF’, ‘SPOUSE_OF’, ‘SIBLING_OF’, ‘GRANDPARENT_OF’, and ‘GRANDCHILD_OF’. As in the spatial case, all graphs have the same structure, but each graph has different names assigned to its nodes. Walks on the graph are represented by strings such as ‘lk PARENT_OF nd SIBLING_OF re’.</p><p id="P33">In each case, we created 500,000 graphs with the same structure but randomly chosen labels (pairs of letters) for the nodes. Three random walks of 50 transitions were sampled from each graph to create the training data, representing sequences of observations that might be experienced, encoded in the hippocampus, then replayed offline. GPT-2’s medium-sized architecture was then trained from scratch for one epoch (i.e. the full dataset was presented once). After training the models, we tested inference by defining a set of cycles in the graph for which the final destination should be inferred given the sequence so far. For example, the next item after ‘uq NORTH sx EAST tp SOUTH ec WEST’ can be inferred to be ‘uq’ given the structure of spatial graphs, and the next item after ‘qk PARENT_OF xm PARENT_OF vw GRANDCHILD_OF zq SPOUSE_OF’ can be inferred to be ‘qk’ given the structure of family tree graphs. (Only a subset of these tasks were tested as there are a very large number of possible loops, particularly for the family tree task.) These graph cycles were then populated with random pairs of letters, so that none of the graphs used for testing featured in the training data (i.e. the sequences used for testing were sequences of relationships in <italic>new</italic> family trees or spatial grids). Greedy decoding was used to generate predictions given the sequence so far. On some of the family tree inference problems there are multiple possible answers which are consistent with, but cannot be inferred from, the sequence so far (such as the imagined family member ‘ef’ in ‘ab CHILD_OF cd PARENT_OF ef’, whereas ‘ab’ is the expected answer), and these are counted as incorrect, making this quite a harsh performance metric.</p><p id="P34"><xref ref-type="fig" rid="F6">Figure 6c</xref> and f show the ‘loss’ (aggregated error on the training data) of the spatial model and family tree model respectively. In both cases the loss gradually decreases, indicating improved ability to predict the next node on the set of graphs used for training, which corresponds to the consolidation of previous experience. Tables 7 and 8 and <xref ref-type="fig" rid="F6">Figure 6g</xref> show good performance on a range of <italic>novel</italic> structural inference tasks, involving environments which have not been experienced before. Simpler inferences include inferring that going one step west then east takes one back to the original location, e.g. the correct continuation of ‘ab EAST cd WEST’ is ‘ab’. Similarly, a correct continuation of ‘ab PARENT_OF cd CHILD_OF’ is ‘ab’. But surprisingly complex inferences are also possible, e.g. that ‘kh CHILD_OF oi SPOUSE_OF tv CHILD_OF fh SPOUSE_OF xr GRANDPARENT_OF gq SIBLING_OF’ is followed by ‘kh’. Furthermore given a single new item the trained spatial model can ‘imagine’ new trajectories consistent with the learned graph structure (<xref ref-type="fig" rid="F6">Figure 6h</xref>), which explore further from the starting position at higher temperatures (<xref ref-type="fig" rid="F6">Figure 6i</xref>). We also tested inference on larger grids than the model was trained on to show that inference cannot solely be attributed to ‘rote memory’ of sequences of transitions (<xref ref-type="fig" rid="F6">Figure 6j</xref>).</p><p id="P35">To understand how the LLM generalises to a new environment, we inspected representations in its hidden layers. Activations (vectors of length 1024) for each token of a random walk were extracted from the innermost layer (i.e. the 12th of the 24 transformer blocks) of our model, and from the same layer of the pre-trained GPT-2 medium model released by <xref ref-type="bibr" rid="R83">Radford et al. (2019)</xref> as a baseline. Having obtained a vector for each location, we analysed the distances between these representations. We found that the nearer the points in the environment, the closer their hidden representations (<xref ref-type="fig" rid="F7">Figure 7a</xref>). This is not true of the baseline model (<xref ref-type="fig" rid="F7">Figure 7b</xref>). We then ran principal component analysis across representations extracted from random walks in many different environments. <xref ref-type="fig" rid="F7">Figure 7d</xref> shows that our model has learned a shared structure across episodes, whereas this structure is not present in GPT-2 medium (<xref ref-type="fig" rid="F7">Figure 7c</xref>). This mirrors the finding that a shared abstract representation of different spatial environments with the same structure develops in cortex through consolidation, as <xref ref-type="bibr" rid="R9">Baram et al. (2024)</xref> show using cross-map repetition suppression effects in fMRI. Once this abstraction of the task has developed, it supports in-context learning. The correlation between distance in the grid and distance between the representations increases with the length of a random walk on a new graph, but is high from the outset, suggesting the model can rapidly align new stimuli to its learned map (<xref ref-type="fig" rid="F7">Figure 7f</xref>).</p><p id="P36">The results are consistent with the claim that consolidation of sequences into a generative model supports relational inference and generalisation. Furthermore they suggest that models trained on a simple prediction error minimisation objective can learn an abstract transition structure.</p></sec><sec id="S10"><label>3.2.3</label><title>Model-based planning</title><p id="P37">Planning often involves mentally simulating the consequences of a sequence of actions, known as model-based planning. How does the abstraction of structure from experience through consolidation relate to this? The aim of this simulation is to test the hypothesis that generative networks trained through consolidation can support model-based planning by sequential prediction of the next item.</p><p id="P38">In other words we explore whether, as another consequence of being able to (re)generate sequential experience, the network can perform ‘roll-outs’ enabling model-based planning.</p><p id="P39"><xref ref-type="bibr" rid="R104">Vikbladh et al. (2024)</xref> design a task to assess the contribution of different strategies to planning (i.e. model-based, model-free, or successor representation approaches), and explore how this changes with consolidation. As <xref ref-type="fig" rid="F8">Figure 8</xref> summarises, the task is as follows: nine items (red, green or yellow vehicles, animals or fruit) are arranged in a loop. The participants observe clockwise subsequences from the loop, determined by start, stop, and reward conditions. The start condition gives the item the sequence starts at. The stop condition gives the colour the sequence terminates at, e.g. ‘green’ means it stops upon reaching the first green object. The reward condition determines the object type that gives a reward of 2 (while other objects give -1). Given a particular start, stop, and reward combination, participants must decide whether to accept or reject a trial by predicting its total reward.</p><p id="P40">After learning the rules of the task, participants experience nine sequences made up of the stimuli above in a random order with one sequence per start state, each with a random stop and reward condition, making decisions then observing the sequence as feedback. Crucially, each participant sees only one stop and one reward condition for each start state during training. (Note that all participants reached a performance of at least 85% on these training sequences.) They are then tested on all combinations of stop and reward conditions without feedback, requiring them to do transition and/or reward ‘revaluation’ when deciding whether to accept or reject a trial with a new stop or reward condition (see <xref ref-type="bibr" rid="R72">Momennejad et al., 2017</xref>). Performance is tested before and after a seven day delay to assess the effect of consolidation.</p><p id="P41">The task allows model-based, model-free and successor representation strategies to be disentangled, since only model-based planning allows revaluation of both reward and transition statistics, whereas the successor representation allows only reward revaluation, and model-free planning allows neither. <xref ref-type="bibr" rid="R104">Vikbladh et al. (2024)</xref> found a mixture of successor representation and model-based strategies, with the model-based approach increasing with consolidation between day one and day seven (<xref ref-type="fig" rid="F8">Figure 8h</xref>). MEG decoding and analysis of response times indicated that model-based planning was associated with sequential ‘rollouts’ involving the medial temporal lobe on both days and prefrontal cortex on day seven.</p><p id="P42">We test the hypothesis that model-based planning, based on the ‘rollout’ of sequences by the generative network, increases with consolidation in the neocortical network as follows. The stimuli for <xref ref-type="bibr" rid="R104">Vikbladh et al. (2024)</xref> can be represented as sequences of the form ‘START: yellow fruit, STOP: red, REWARD: animal, SEQUENCE: green fruit (-1), red animal (2)’, and it is straightforward to train the medium GPT-2 model on these sequences of text. The task is simulated as follows: i) pre-train the model on different stimuli so that it learns the rules of the task, ii) train on stimuli for a particular task with specific stop and reward conditions for each start item, representing consolidation through hippocampal replay, and iii) compare the generative model’s accept / reject predictions, with new combinations of stop and reward conditions for each start item, to the correct values over the course of consolidation.</p><p id="P43">First we pre-train the model on sequences which mirror the structure but <italic>not</italic> the content of the task stimuli, to simulate learning the rules of the task. The pre-training data consists of the 81 possible start / stop / reward combinations for each of 1000 sets of nine items, giving a total of 81,000 sequences. Each item is a random pairing of one of three random adjectives and one of three random nouns; the start condition is one of the nine items, the reward condition is one of the three nouns, and the stop condition is one of the three adjectives. For example, one sequence might be ‘START: stripy gerbil, STOP: angry, REWARD: cloud, SEQUENCE: busy cloud (2), angry plate (-1)’. The GPT-2 model is fine-tuned on this shuffled dataset for ten epochs. After this stage of training, the model can be given a prompt with randomly chosen stimuli / conditions, and generate a sequence consistent with the rules. But the model knows nothing about the <xref ref-type="bibr" rid="R104">Vikbladh et al. (2024)</xref> task stimuli or their order. This models the participant after rule learning, but before experiencing the task stimuli.</p><p id="P44">To simulate the task itself, the stimuli from <xref ref-type="bibr" rid="R104">Vikbladh et al. (2024)</xref> are used (‘red animal’, ‘green animal’, ‘yellow animal’, ‘red vehicle’, ‘green vehicle’, ‘yellow vehicle’, red fruit’, ‘green fruit’, and ‘yellow fruit’), shuffled into a random order. A single pair of stop and reward words are selected. The training stimuli are then just nine sequences with these stop and reward criteria (one per start item). These nine sequences are oversampled to 1000 items (i.e. 1000 ‘replayed’ samples are taken, so that 9 sequences are presented 1000 times in random order) to prevent overfitting to the order of the sequences. The model is fine-tuned for eight epochs on this dataset (i.e. there are ten iterations of training on the dataset of 1000 samples), representing repeated offline replay of the training stimuli.</p><p id="P45">Three datasets are used to track performance over time: sequences requiring transition revaluation (i.e. with a new stop condition), sequences requiring reward revaluation (i.e. with a new reward condition), and sequences requiring both kinds of revaluation (i.e. with a new stop <italic>and</italic> reward condition). Performance on the accept / reject decision-making task is tested by obtaining the predicted sequence, and extracting the sum of the predicted rewards, accepting any trial with a sum greater than zero (see <xref ref-type="supplementary-material" rid="SD1">Section 6.5.3</xref>, SI). This simulation is run five times, each with a random ordering of the stimuli, reward condition, and stop condition.</p><p id="P46"><xref ref-type="fig" rid="F8">Figure 8f</xref> shows that the performance on all three types of task improves over time. This suggests that the generative model learns the order of the items through ‘consolidation’ such that it can predict the sequence of items and rewards given novel reward and/or stop conditions. In order to explore whether planning becomes more model-based, <xref ref-type="fig" rid="F8">Figure 8g</xref> compares the network’s decisions to the decisions predicted by four strategies: model-free (the accept / reject decision for the same start item from the training data), reward revaluation (the decision given the ability to perform reward revaluation but not transition revaluation), transition revaluation (the decision given the ability to perform transition revaluation but not reward revaluation), and model-based (the correct decision, as deduced from a learned model of transition statistics for the task). The results in <xref ref-type="fig" rid="F8">Figure 8g</xref> show that the network is consistent with the model-based planners’ behaviour in <xref ref-type="fig" rid="F8">Figure 8h</xref>, in that model-based planning ability increases with consolidation. The model’s use of step-by-step prediction is also consistent with the model-based planners’ increase in reaction time with planning depth.</p></sec></sec><sec id="S11"><label>3.3</label><title>Modelling hippocampal-neocortical interaction as retrieval-augmented generation</title><p id="P47">We now demonstrate how hippocampus and neocortex can play complementary roles in a single task, contributing memory for specifics and general knowledge respectively. This explains episodic contributions to inference and planning prior to full consolidation (e.g. <xref ref-type="bibr" rid="R105">Vikbladh et al., 2017</xref>). Furthermore, in the ‘full’ model memories are compressed for more efficient storage (<xref ref-type="bibr" rid="R10">Barlow et al., 1961</xref>; <xref ref-type="bibr" rid="R11">Barlow, 1989</xref>), by generating gists of events in vector form which are encoded together with unexpected details in the hippocampus (<xref ref-type="fig" rid="F1">Figure 1e</xref>). This explains not only conceptual representations in hippocampus (<xref ref-type="bibr" rid="R82">Quiroga, 2012</xref>), but also the fact that memories are schematised from the time of encoding (<xref ref-type="bibr" rid="R29">Deese, 1959</xref>; <xref ref-type="bibr" rid="R91">Roediger &amp; McDermott, 1995</xref>).</p><sec id="S12"><label>3.3.1</label><title>Hippocampal and neocortical contributions to problem-solving</title><p id="P48">Memories can be used to support problem solving immediately after encoding, not just after consolidation. This simulation aims to test the hypothesis that the generative network and hippocampal network could work together to achieve this in a way resembling ‘retrieval-augmented generation’ (RAG; <xref ref-type="bibr" rid="R57">Lewis et al., 2020</xref>). Inference from recent memories is modelled as a process whereby relevant sequences from the hippocampus are retrieved and used as context for the generative model. Whilst the simulations of inference in <xref ref-type="sec" rid="S9">Section 3.2.2</xref> involved prompting the model with the sequence of observations so far, storing all past experience in working memory is not feasible given its low capacity (<xref ref-type="bibr" rid="R5">Baddeley, 2000</xref>; <xref ref-type="bibr" rid="R26">Cowan, 2001</xref>). In general, only a small subset of past episodes are relevant, so RAG provides a way to condition predictions on only the most useful information.</p><p id="P49">We create a ‘toy example’ of retrieval-augmented generation using the two models in the structural inference results above (one trained on spatial graphs, and one on family tree graphs, such that each has learned the structural regularities of the stimuli). In each case, the hippocampus encodes sequences from <italic>new</italic> spatial or family tree graphs, corresponding to observations in a new spatial environment or of a new family’s relationships. Can ‘missing edges’ which were not present in the training data be inferred, by combining the sequences in the hippocampus with long-term knowledge of relational structure? Specifically, 100 new graphs were constructed for each task, each missing a randomly chosen edge. Short walks on each graph, which did not include the missing edge, were stored in the ‘hippocampus’ (simply a list of strings in this example). For each missing edge, a query of the form ‘ab EAST’ or ‘cd PARENT_OF’ was constructed for the spatial and family tree graphs respectively. In other words, if the ‘cd PARENT_OF ef’ edge was omitted from the graph, the test would be the model’s continuation from ‘cd PARENT_OF’. (Greedy decoding was used to generate predictions.)</p><p id="P50">Testing involves two stages, retrieval followed by generation: first the hippocampus is queried for relevant traces, simply by finding sequences containing the node in the query. Then the generative network produces an output conditioned on the retrieved sequence concatenated with the sequence for the task (<xref ref-type="fig" rid="F9">Figure 9a</xref>), i.e. with the retrieved sequence and the current task in the LLM’s prompt. The results show that this supports structural inference immediately after encoding sequences in the hippocampus, whereas relying on either the hippocampal network or generative network alone gives worse results (<xref ref-type="fig" rid="F9">Figure 9b</xref>).</p><p id="P51">Planning based on memories prior to consolidation can also be modelled in this way. In <xref ref-type="sec" rid="S10">Section 3.2.3</xref>, we simulated the task in <xref ref-type="bibr" rid="R104">Vikbladh et al. (2024)</xref> to show that the generative network learns to do model-based planning by extracting the task’s transition structure through consolidation. But human participants can plan prior to consolidation too. As shown for inference, one might hypothesise that planning based on recent memories is a process of ‘retrieval-augmented generation’. We assume the system involves a generative network that ‘knows’ the rules of the task but <italic>not</italic> the task stimuli, and a hippocampus which has encoded the task stimuli. As in <xref ref-type="sec" rid="S10">Section 3.2.3</xref>, only 9 sequences are encoded, one per start position with a single reward and stop condition. Given a new problem (requiring a different reward condition, stop condition, or both) the system first retrieves the most relevant sequence, i.e. the one with the greatest word overlap, and then uses this to provide the context for the generative network. The generative network in <xref ref-type="sec" rid="S10">Section 3.2.3</xref> (following pre-training on the task, but before training on the actual stimuli) is used.</p><p id="P52"><xref ref-type="fig" rid="F9">Figure 9c</xref> shows the accuracy of the accept vs. reject decisions with the RAG approach compared to two baselines. The ‘HPC only’ baseline tests the behaviour of the initial hippocampal network by itself, by copying the accept / reject prediction of the most similar stored sequence, whereas the ‘NC only’ baseline tests the behaviour of the generative network by itself, <italic>prior</italic> to any consolidation of the 9 new sequences. Both baselines are worse than the RAG approach across all three test types, suggesting the model hippocampus and neocortex play complementary roles. This could be seen as a model of episodic contributions to planning, in fitting with the finding that model-based behaviour can be supported by retrieving relevant episodic memories (<xref ref-type="bibr" rid="R105">Vikbladh et al., 2017</xref>).</p><p id="P53">In this simulation, only one trace is retrieved per query. But this mechanism is scalable to cases where many traces are relevant to the query, given sufficient capacity to hold them in working memory, and is thus a potential model of reasoning based on multiple recent memories as well as a single memory.</p></sec><sec id="S13"><label>3.3.2</label><title>Combining gists and details</title><p id="P54">We propose that the hippocampus could store each memory as the combination of a conceptual representation and surprising details, with retrieval-augmented generation used to reconstruct memories from this compressed form. This minimises the hippocampal storage of redundant information that is already well-predicted by the generative network (see also <xref ref-type="bibr" rid="R98">Spens and Burgess, 2024</xref>). In other words, we suggest that this hippocampal representation allows the neocortical network to (re)generate experiences in a more efficient way, and that conceptual representations are optimised to enable generation.</p><p id="P55">We simulate this by drawing on recent LLM research on ‘context compression’, which aims to deal with the practical problems that arise from very long contexts. Approaches include summarisation of the context (<xref ref-type="bibr" rid="R110">Xu et al., 2023</xref>), the removal of redundant information so that only surprising elements are kept (<xref ref-type="bibr" rid="R46">Jiang, Wu, et al., 2023</xref>), and the transformation of the context into a vector capturing its meaning (<xref ref-type="bibr" rid="R24">Cheng et al., 2024</xref>; <xref ref-type="bibr" rid="R38">Ge et al., 2023</xref>). The xRAG approach of <xref ref-type="bibr" rid="R24">Cheng et al. (2024)</xref> is of particular interest, as it aligns with the evidence that hippocampal traces can include conceptual representations, and does not require any special training of the LLM itself - just additional weights that map the embedding of a sequence (i.e. the output of a ‘text embedding’ model) to a token in the input layer of the LLM (see <xref ref-type="fig" rid="F2">Figure 2b</xref>). In brief, these weights are trained so that the embedding of the text reconstructed by the LLM is as close as possible to the embedding of the original. Another advantage is that the underlying idea in <xref ref-type="bibr" rid="R24">Cheng et al. (2024)</xref> is not specific to language but could in principle work for arbitrary types of sequence. Note that we refer to the xRAG vector as the ‘gist vector’ in the subsequent text as xRAG is one implementation of a family of approaches (see also <xref ref-type="bibr" rid="R38">Ge et al., 2023</xref>).</p><p id="P56">In summary, in the ‘full’ model the hippocampus encodes a vector representing the conceptual gist of the event in very compressed form, rather than the sequence in its entirety. Alongside this, details that are not captured by this gist vector are encoded, where the amount of detail depends on a prediction error threshold. Recalling an event involves reconstructing it from its gist vector and details with the generative network.</p><p id="P57">To illustrate how gist, detail, and semantic memory interact in the full model, we simulate the encoding and recall of narrative events as follows (<xref ref-type="fig" rid="F10">Figure 10</xref>), using 100 stories from the ROC Stories dataset (<xref ref-type="bibr" rid="R73">Mostafazadeh et al., 2016</xref>). We use Mistral-7B-Instruct-v0.2 plus xRAG weights (released by <xref ref-type="bibr" rid="R24">Cheng et al., 2024</xref>) to simulate neocortex. To encode a story, its embedding is obtained from the <xref ref-type="bibr" rid="R67">Meng et al. (2024)</xref> text embedding model, from which the xRAG vector is derived via the xRAG weights (i.e. the xRAG weights transform the embedding into the input space of the LLM). Each story is encoded as its xRAG vector plus surprising details. To identify surprising details, all phrases are extracted from the text, then the perplexity of each phrase given the xRAG vector is calculated. In other words, for each phrase, the model is prompted with the xRAG vector and the phrase in question. Then the phrases are ranked in descending order of perplexity, with the top n phrases stored.</p><p id="P58">Given a query as the input to recall, the neocortex ‘searches’ the hippocampus for relevant traces. This is simulated by producing an xRAG vector for the query (as described above), and then by retrieving the trace(s) with the nearest xRAG vector. The context given to the LLM consists of the xRAG vector, the details, and a prompt describing the task. Note that the xRAG vector only occupies the space of a single token in this input. The final recalled story is the output of the LLM.</p><p id="P59"><xref ref-type="fig" rid="F10">Figure 10d</xref> and <xref ref-type="table" rid="T5">Table 5</xref> show examples of encoded and recalled stories. For instance, a story about a girl’s visit to an aquarium is encoded as its gist vector and a surprising detail (that the girl took a nap on the journey). The model neocortex reconstructs an approximation of the original story from the gist vector and the detail, with a few semantic intrusions added to the story, e.g. ‘Melody’s favorite part was the shark tank’; these intrusions are shaped by the expectations of the model neocortex, as in <xref ref-type="bibr" rid="R12">Bartlett (1932)</xref>. This hints at how gist, detail, and semantic memory can interact in recall.</p><p id="P60">The encoding of gist plus details was also compared to three baselines: encoding the story in full detail, encoding only the gist, and simply imagining the continuation (i.e. without using the model hippocampus at all). The mean size per memory (in tokens) and the accuracy of recall (the cosine similarity between the embeddings of the original and recalled story) were compared across the three conditions, showing a trade-off between efficiency and accuracy in memory in <xref ref-type="fig" rid="F10">Figure 10e</xref>. The gist plus details encoding strikes a balance between these objectives.</p><p id="P61">In the full model, how does the level of distortion change with consolidation? An additional simulation was performed to investigate the consolidation of these representations combining gist and details, using Mistral-7B-Instruct-v0.2 (<xref ref-type="bibr" rid="R45">Jiang, Sablayrolles, et al., 2023</xref>). First stories from the ROC Stories dataset (<xref ref-type="bibr" rid="R73">Mostafazadeh et al., 2016</xref>) were encoded in gist plus details form in the model hippocampus. During consolidation, the memories were reconstructed from these traces, and the generative network was trained on the result (using low-rank adaptation; <xref ref-type="bibr" rid="R42">Hu et al., 2021</xref>), see <xref ref-type="supplementary-material" rid="SD1">SI</xref> for further details. The loss (aggregated prediction error) for the original story and for the hippocampal trace’s reconstruction were calculated at the end of each epoch. The loss for the hippocampal trace decreases steadily, but the loss for the original story begins to increase after an initial drop, as the model overfits to the conceptual gist. In summary, in the full model the stored version in the hippocampus is itself an approximation, with more replay strengthening the statistical biases captured by the gist.</p></sec></sec></sec><sec id="S14" sec-type="discussion"><title>Discussion</title><p id="P62">We have presented a model of the construction and consolidation of sequential memories, in which sequences encoded in the hippocampus are replayed to train a generative network to capture the statistics of experience through prediction error minimisation. This model suggests an explanation for several features of human cognition, such as the bidirectional influences between episodic and semantic memory; semantic memory is acquired by learning to reconstruct episodic memories, but also shapes the representation of these episodes, both in terms of their initial encoding, as reflected by the compressed representations observed in hippocampus (<xref ref-type="bibr" rid="R82">Quiroga, 2012</xref>), and their gradual schematisation (<xref ref-type="bibr" rid="R12">Bartlett, 1932</xref>). To support this, we demonstrated how distortions arise in recalled narratives as neocortex learns to approximately reconstruct them, and how these reflect priors in the generative model derived from previous experience (<xref ref-type="sec" rid="S4">Sections 3.1</xref> and <xref ref-type="sec" rid="S6">3.1.2</xref>). Our model also explains how a number of capabilities improve through consolidation, in addition to the memorisation of ‘replayed’ sequences. In particular, the neocortical generative network supports statistical learning of transition probabilities (<xref ref-type="sec" rid="S8">Section 3.2.1</xref>), inferring new relationships from limited observations by learning an implicit structure (<xref ref-type="sec" rid="S9">Section 3.2.2</xref>), and model-based sequential planning (<xref ref-type="sec" rid="S10">Section 3.2.3</xref>).</p><p id="P63">The model suggests a mechanism for how task-relevant episodic memories are integrated with general knowledge. We propose that the neocortical generative network interacts with stored sequences retrieved from the hippocampus as retrieval-augmented generation (<xref ref-type="bibr" rid="R57">Lewis et al., 2020</xref>), but with the ‘generator’ gradually trained on memories from the ‘retriever’ through consolidation, and the ‘retriever’ storing memories in a highly compressed form that can be decoded by the ‘generator’. This is consistent with our ability to use memories for complex tasks such as planning and inference, which cannot be supported by the retrieval of traces alone, even prior to consolidation (e.g. <xref ref-type="bibr" rid="R104">Vikbladh et al., 2024</xref>). Furthermore the stored traces in the hippocampal ‘retriever’ can combine surprising details with gists in vector form, binding together information at different levels of abstraction in memory, with the conceptual representation optimised for reconstruction (<xref ref-type="sec" rid="S9">Section 3.3.2</xref>). This strikes a balance between efficient storage and accurate recall, and explains how neocortical expectations shape memories from their encoding onwards (e.g. <xref ref-type="bibr" rid="R12">Bartlett, 1932</xref>; <xref ref-type="bibr" rid="R88">Raykov et al., 2023</xref>).</p><p id="P64">In recent years, neuroscience has seen a move from a modular view of many semi-independent networks learning particular tasks to a focus on the learning of multipurpose representations. Similarly, there has been a transition in machine learning from task-specific models to larger task-general ones trained through self-supervised learning, sometimes referred to as ‘foundation models’ (<xref ref-type="bibr" rid="R15">Bommasani et al., 2021</xref>). The use of a self-supervised task to train such models is key to their scaling, as external supervision is not required. We can think of the brain as learning neural ‘foundation models’ too, and this paper suggests how memory consolidation could contribute to their development (see also <xref ref-type="bibr" rid="R98">Spens and Burgess, 2024</xref>). This view aligns with the growing consensus that prediction error minimisation is key to biological intelligence (e.g. <xref ref-type="bibr" rid="R37">Friston, 2010</xref>), neuroimaging evidence of large task-general networks (e.g. <xref ref-type="bibr" rid="R84">Raichle et al., 2001</xref>), and the relative lack of external supervision in learning.</p><p id="P65">We note that other types of model like recurrent neural networks (RNNs) could perhaps perform some of the simpler tasks tested in this paper. Using LLMs, despite their greater complexity, has the following advantages. Firstly, linguistic stimuli are commonly used to test episodic and semantic memory, and transformer-based models enable the simulation of these tasks in a way simpler models cannot. Secondly, the concept of ‘retrieval-augmented generation’ (<xref ref-type="bibr" rid="R57">Lewis et al., 2020</xref>) in the LLM literature sheds light on how neocortical and hippocampal networks could work together to solve complex tasks based on a combination of general and specific information. Thirdly, LLMs have rich internal representations that could be compared to neural data (see <xref ref-type="fig" rid="F7">Figure 7</xref>). In short, while RNNs can also generate sequences, the sophistication of LLMs allows a wider range of phenomena to be considered, even though their implementation in the brain would require a more biologically plausible learning rule (see <xref ref-type="sec" rid="S15">Section 4.1</xref>). We do not argue that modern LLMs mirror the brain, but that some kind of neural ‘foundation model’ being trained to minimise prediction error on replayed sequences provides a good model for a wide range of data on memory, consolidation, inference and sequential planning.</p><p id="P66">The following sections discuss limitations of the model and directions for future research.</p><sec id="S15"><label>4.1</label><title>Future work</title><p id="P67">This work is primarily a model of psychological, rather than neural, data. More could be done to bridge the gap between these ideas and the growing understanding of sequence representations at a neural level. For example, the model allows consideration of navigation, which is associated with distinctive cell types such as place, grid and head-direction cells, so the connection between these different levels of explanation could be explored (see <xref ref-type="bibr" rid="R8">Banino et al., 2018</xref>; <xref ref-type="bibr" rid="R95">Schönfeld and Wiskott, 2015</xref>; <xref ref-type="bibr" rid="R97">Sorscher et al., 2023</xref>; <xref ref-type="bibr" rid="R99">Stachenfeld et al., 2017</xref>; <xref ref-type="bibr" rid="R108">Whittington et al., 2020</xref>). Furthermore, progress in ‘mechanistic interpretability’ (e.g. <xref ref-type="bibr" rid="R17">Bricken et al., 2023</xref>) enables the hidden layer activations of LLMs to be compared to neuroimaging data, allowing comparison of representations at a population level as well.</p><p id="P68">Modern language models like GPT-2 are trained on a simple next item prediction task (<xref ref-type="bibr" rid="R83">Radford et al., 2019</xref>), mirroring how prediction error minimisation is thought to drive biological learning (e.g. <xref ref-type="bibr" rid="R37">Friston, 2010</xref>). But even if the objective is shared, the implementations may be very different. In particular, error backpropagation - which calculates each parameter’s ‘responsibility’ for the network’s error - is thought to be implausible because of its non-local nature (<xref ref-type="bibr" rid="R107">Whittington &amp; Bogacz, 2019</xref>). More biologically plausible approximations to error backpropagation do exist (<xref ref-type="bibr" rid="R107">Whittington &amp; Bogacz, 2019</xref>), as well as other families of network that mimic the brain more closely (<xref ref-type="bibr" rid="R28">Dayan et al., 1995</xref>; <xref ref-type="bibr" rid="R37">Friston, 2010</xref>; <xref ref-type="bibr" rid="R86">Rao &amp; Ballard, 1999</xref>), which could be explored in future work.</p><p id="P69">Our model captures the sequential nature of experience, but in reality each moment is ‘high-dimensional’, more like the images in <xref ref-type="bibr" rid="R98">Spens and Burgess (2024)</xref> or <xref ref-type="bibr" rid="R35">Fayyaz et al. (2022)</xref> than the ‘tokens’ used here. Video data, whilst still far simpler than reality, better reflect this: a video is made up of a succession of frames, each of which is rich in data, and recalling it requires ‘filling in the gaps’ of a particular frame as well as predicting successive ones. This could be modelled by reproducing the current item (as in in <xref ref-type="bibr" rid="R35">Fayyaz et al., 2022</xref>; <xref ref-type="bibr" rid="R98">Spens and Burgess, 2024</xref>) as well as predicting the next, which would require changes to the associative and generative networks. Since pattern completion of both the current stimulus and the next stimulus would occur in the associative network, a combination of autoassociative and heteroassociative connectivity might be required (<xref ref-type="bibr" rid="R96">Sompolinsky &amp; Kanter, 1986</xref>). In addition, the generative model could be replaced with one for video data (e.g. <xref ref-type="bibr" rid="R111">Yan et al., 2021</xref> or <xref ref-type="bibr" rid="R39">Ha and Schmidhuber, 2018</xref>), although the time and cost required to train such a model might make this impractical.</p><p id="P70">Previous work suggests that the generative network may involve an encoder in neocortex, inferring a latent representation from sensory inputs, and a decoder returning to sensory cortex via the hippocampal formation (<xref ref-type="bibr" rid="R98">Spens &amp; Burgess, 2024</xref>). This is consistent with the continued dependence on the hippocampal formation for many kinds of episode formation (e.g. <xref ref-type="bibr" rid="R66">McKenzie and Eichenbaum, 2011</xref>; <xref ref-type="bibr" rid="R74">Nadel and Moscovitch, 1997</xref>), and accounts for semantic memory as direct projections from the latent variables. In this paper we do not address the neural substrates of different components of the generative network, but GPT-2 does not have an encoder-decoder architecture, and aligns less closely to our view of the anatomy. In other words, models like GPT-2 do not have explicit latent variables (unlike, for example, variational autoencoders; <xref ref-type="bibr" rid="R49">Kingma and Welling, 2013</xref>), but learn a conceptual representation more implicitly. Current failure modes of LLMs have been linked to the lack of an explicit world model (<xref ref-type="bibr" rid="R13">Bender et al., 2021</xref>), so one might speculate that future variants will capture this more concretely.</p><p id="P71">The full model presented here addresses the mixed composition of memories but only scratches the surface of how this mixture changes over time. Firstly, as the hippocampal trace decays, or becomes redundant through consolidation to neocortex, the contribution of unique details relative to conceptual gist reduces. Secondly, the already distorted hippocampal trace is consolidated, reinforcing the schematic predictions used to encode it. Thirdly, consolidation continues until a trace is approximately, not perfectly, remembered, at which point the schema-congruent content may be learned to a greater degree than the schema-incongruent details (see <xref ref-type="bibr" rid="R103">Tse et al., 2007</xref>). Fourthly, re-encoding the gist of a memory in light of new information introduces further biases (e.g. <xref ref-type="bibr" rid="R59">Loftus and Palmer, 1974</xref>). More extensive simulations could explore the interaction of these factors.</p><p id="P72">Whilst experience is continuous, it is discretised into events in memory (<xref ref-type="bibr" rid="R78">Newtson, 1973</xref>; <xref ref-type="bibr" rid="R79">Newtson &amp; Engquist, 1976</xref>), a process known as event segmentation. Event segmentation is thought to be based on prediction error (<xref ref-type="bibr" rid="R36">Franklin et al., 2020</xref>; <xref ref-type="bibr" rid="R54">Kumar et al., 2023</xref>; <xref ref-type="bibr" rid="R113">Zacks et al., 2007</xref>). Whilst the sequences used in our simulations are ‘pre-segmented’ for simplicity, this is potentially consistent with our model, as the generative network can provide an ongoing measure of ‘surprise’ during perception (<xref ref-type="bibr" rid="R36">Franklin et al., 2020</xref>; <xref ref-type="bibr" rid="R54">Kumar et al., 2023</xref>; <xref ref-type="bibr" rid="R68">Michelmann et al., 2025</xref>), e.g. as quantified by perplexity (<xref ref-type="bibr" rid="R83">Radford et al., 2019</xref>). One complexity is that event segmentation occurs at multiple levels of granularity (<xref ref-type="bibr" rid="R113">Zacks et al., 2007</xref>); this could potentially involve averaging prediction error over different time periods, or alternatively variable error thresholds (so that more fine-grained segmentation occurs when the error exceeds a lower threshold, and more coarse-grained segmentation a higher threshold). However how a hierarchy of segments of varying lengths would be stored is unclear.</p><p id="P73">Human learning can display leaps of insight (e.g. <xref ref-type="bibr" rid="R51">Kounios and Beeman, 2014</xref>), with abrupt improvements thought to correspond to the reorganisation of mental representations (<xref ref-type="bibr" rid="R80">Ohlsson, 1992</xref>). Future work could explore the development of an LLM’s internal representations as a task is learned, comparing this to the corresponding ‘behavioural’ changes, to see if sudden increases in performance correspond to sudden representational changes. This could then be compared to the dynamics of learning in humans.</p><p id="P74">Future research could also explore how retrieval, encoding, and replay processes are orchestrated. We simplify matters by using pre-segmented sequences, encoding every event with a fixed prediction error threshold, and ‘hard-coding’ when the hippocampus is queried. However, one could train a ‘meta-controller’ to co-ordinate these processes with reinforcement learning. This might learn to use different cognitive resources when it was optimal to do so, e.g. prioritising memories for replay to maximise future performance, and only encoding memories when it is worth the cognitive cost. This could build on previous studies like <xref ref-type="bibr" rid="R61">Lu et al. (2022)</xref>, which prototypes these ideas with simpler models.</p><p id="P75">Finally, many aspects of human cognition are inextricably linked to language. Some of the computational modelling approaches in this paper could be applied more broadly to studies involving narratives (e.g. <xref ref-type="bibr" rid="R16">Bransford et al., 1972</xref>; <xref ref-type="bibr" rid="R59">Loftus and Palmer, 1974</xref>). A number of mental health symptoms and conditions are thought to relate to maladaptive processing of narratives, such as rumination (<xref ref-type="bibr" rid="R77">Nejad et al., 2013</xref>), delusion (<xref ref-type="bibr" rid="R25">Coltheart et al., 2011</xref>), and confabulation (<xref ref-type="bibr" rid="R50">Kopelman, 2010</xref>), so this may be fruitful from a computational psychiatry perspective.</p></sec><sec id="S16"><label>4.2</label><title>Episodic and semantic memory</title><p id="P76">Generative networks such as large language models (LLMs) can memorise ‘event-unique’ specifics as well as generalities in a single network (<xref ref-type="bibr" rid="R20">Carlini, Ippolito, et al., 2022</xref>), raising questions for the common assumption that episodic and semantic memory must depend on different computational processes. If a series of narratives representing ‘episodes’ are ‘consolidated’ into an LLM, the resulting LLM could support both memory for specific episodes and for semantic ‘facts’, with the latter learned as a side-effect of reconstructing the former. Not only are ‘beliefs’ influenced by ‘episodes’ the network was trained on, but the ‘episodes’ are reshaped by the ‘beliefs’, as we saw in a range of memory distortion simulations. This can be the case even for the initial hippocampal encoding of episodes in the full model, as demonstrated in <xref ref-type="sec" rid="S13">Section 3.3.2</xref>.</p><p id="P77">How do we distinguish remote memory from imagination, if both consist largely of schema-based predictions from a generative model? The generative model’s prediction error for sequences from the training data tends to be lower than for novel sequences (<xref ref-type="bibr" rid="R20">Carlini, Chien, et al., 2022</xref>), so the generative network could provide a measure of recognition memory even if the original hippocampal trace has faded away. However this might correspond to a ‘sense of familiarity’ rather than definitive knowledge that a stimulus was experienced. Thus, the presence of similar real memories (<xref ref-type="bibr" rid="R29">Deese, 1959</xref>; <xref ref-type="bibr" rid="R91">Roediger &amp; McDermott, 1995</xref>), or the rehearsal of imagined events (<xref ref-type="bibr" rid="R60">Loftus &amp; Pickrell, 1995</xref>), can induce false memory, presumably from a ‘sense of familiarity’ in the generative network. This could align with hippocampal amnesics’ deficits in recognition memory but preserved ability to make relative judgements of familiarity (<xref ref-type="bibr" rid="R69">Migo et al., 2009</xref>).</p><p id="P78">On the other hand, episodic memories arguably need to include some details from a hippocampal trace to be recognised confidently (see <xref ref-type="bibr" rid="R112">Yonelinas et al., 2005</xref>). Memories may retain some limited trace in the hippocampus proper for a long time, so the retrieval of event-unique details which have not yet been consolidated could help to distinguish real memories from imagination. The neocortical network may contain many semantic facts relating to one’s personal history, e.g. that one went on a holiday to a particular place as a child, and could thus construct events consistent with these facts. However, if the feeling of episodic recollection requires retrieval of unique details encoded during the event, then even an accurate reconstruction would not qualify as a episodic memory, with the implication that a memory could lose its ‘episodic’ status without its reported content changing.</p></sec><sec id="S17" sec-type="conclusions"><label>4.3</label><title>Conclusion</title><p id="P79">We have proposed a model in which hippocampal replay trains a neocortical generative network to support the (re)construction of sequences in memory, extending previous work on static images (<xref ref-type="bibr" rid="R35">Fayyaz et al., 2022</xref>; <xref ref-type="bibr" rid="R98">Spens &amp; Burgess, 2024</xref>) to sequential experiences, and shedding light on how memory enables prediction of the future (<xref ref-type="bibr" rid="R94">Schacter et al., 2007</xref>). We show that, by simply learning to predict the next item, the neocortical network can support statistical learning, inference, and model-based sequential planning, while capturing the schema-based distortions in memory for narratives. Inspired by ‘retrieval-augmented generation’ (<xref ref-type="bibr" rid="R57">Lewis et al., 2020</xref>), we show how the hippocampal and neocortical networks could jointly contribute to problem solving, allowing memories retrieved from the hippocampus to provide the context for prediction using the ‘general knowledge’ of the neocortical network. Furthermore, to efficiently encode sequential experiences, the hippocampal network combines unique details with conceptual representations which capture the gist of events. These representations are optimised for neocortical reconstruction, allowing the generative network to fill in the outline of a memory with its predictions.</p></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary Materials</label><media xlink:href="EMS199914-supplement-Supplementary_Materials.pdf" mimetype="application" mime-subtype="pdf" id="d35aAcEbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S18"><title>Acknowledgements</title><p>We thank Oliver Vikbladh for his advice on the planning simulations, and Misun Kim, Steve Fleming, Kris Jensen, and Mathias Sablé-Meyer for their insightful comments on the manuscript.</p><p>Funding support for this work was received from a Wellcome Principal Research Fellowship ‘Neural mechanisms of memory and prediction: Finding structure in experience’ (222457/Z/21/Z) (N.B.) and a Wellcome Collaborative Award ‘Organising knowledge for flexible behaviour in the prefrontal-hippocampal circuitry’ (214314/Z/18/Z) (N.B.).</p></ack><ref-list><ref id="R1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alammar</surname><given-names>J</given-names></name></person-group><article-title>The illustrated transformer</article-title><year>2018</year><date-in-citation>Accessed on March 19, 2024</date-in-citation><comment><ext-link ext-link-type="uri" xlink:href="https://jalammar.github.io/illustrated-transformer/">https://jalammar.github.io/illustrated-transformer/</ext-link></comment></element-citation></ref><ref id="R2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alammar</surname><given-names>J</given-names></name></person-group><article-title>The illustrated GPT-2</article-title><year>2019</year><date-in-citation>Accessed on March 19, 2024</date-in-citation><comment><ext-link ext-link-type="uri" xlink:href="https://jalammar.github.io/illustrated-gpt2/">https://jalammar.github.io/illustrated-gpt2/</ext-link></comment></element-citation></ref><ref id="R3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Atkinson</surname><given-names>RC</given-names></name><name><surname>Shiffrin</surname><given-names>RM</given-names></name></person-group><article-title>Human memory: A proposed system and its control processes</article-title><source>The psychology of learning and motivation</source><year>1968</year><volume>2</volume></element-citation></ref><ref id="R4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baddeley</surname><given-names>A</given-names></name></person-group><article-title>Working memory</article-title><source>Science</source><year>1992</year><volume>255</volume><issue>5044</issue><fpage>556</fpage><lpage>559</lpage><pub-id pub-id-type="pmid">1736359</pub-id></element-citation></ref><ref id="R5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baddeley</surname><given-names>A</given-names></name></person-group><article-title>The episodic buffer: A new component of working memory?</article-title><source>Trends in cognitive sciences</source><year>2000</year><volume>4</volume><issue>11</issue><fpage>417</fpage><lpage>423</lpage><pub-id pub-id-type="pmid">11058819</pub-id></element-citation></ref><ref id="R6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baddeley</surname><given-names>A</given-names></name></person-group><article-title>The concept of episodic memory</article-title><source>Philosophical Transactions of the Royal Society of London Series B: Biological Sciences</source><year>2001</year><volume>356</volume><issue>1413</issue><fpage>1345</fpage><lpage>1350</lpage><pub-id pub-id-type="pmcid">PMC1088518</pub-id><pub-id pub-id-type="pmid">11571026</pub-id><pub-id pub-id-type="doi">10.1098/rstb.2001.0957</pub-id></element-citation></ref><ref id="R7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bainbridge</surname><given-names>WA</given-names></name><name><surname>Baker</surname><given-names>CI</given-names></name></person-group><article-title>Boundaries extend and contract in scene memory depending on image properties</article-title><source>Current Biology</source><year>2020</year><volume>30</volume><issue>3</issue><fpage>537</fpage><lpage>543</lpage><pub-id pub-id-type="pmcid">PMC7187786</pub-id><pub-id pub-id-type="pmid">31983637</pub-id><pub-id pub-id-type="doi">10.1016/j.cub.2019.12.004</pub-id></element-citation></ref><ref id="R8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Banino</surname><given-names>A</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Uria</surname><given-names>B</given-names></name><name><surname>Blundell</surname><given-names>C</given-names></name><name><surname>Lillicrap</surname><given-names>T</given-names></name><name><surname>Mirowski</surname><given-names>P</given-names></name><name><surname>Pritzel</surname><given-names>A</given-names></name><name><surname>Chadwick</surname><given-names>MJ</given-names></name><name><surname>Degris</surname><given-names>T</given-names></name><name><surname>Modayil</surname><given-names>J</given-names></name><etal/></person-group><article-title>Vector-based navigation using grid-like representations in artificial agents</article-title><source>Nature</source><year>2018</year><volume>557</volume><issue>7705</issue><fpage>429</fpage><lpage>433</lpage><pub-id pub-id-type="pmid">29743670</pub-id></element-citation></ref><ref id="R9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baram</surname><given-names>A</given-names></name><name><surname>Nili</surname><given-names>H</given-names></name><name><surname>Barreiros</surname><given-names>I</given-names></name><name><surname>Samborska</surname><given-names>V</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name><name><surname>Garvert</surname><given-names>MM</given-names></name></person-group><article-title>An abstract relational map emerges in the human medial prefrontal cortex with consolidation</article-title><source>bioRxiv</source><year>2024</year><fpage>2024</fpage><lpage>10</lpage></element-citation></ref><ref id="R10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barlow</surname><given-names>HB</given-names></name><etal/></person-group><article-title>Possible principles underlying the transformation of sensory messages</article-title><source>Sensory communication</source><year>1961</year><volume>1</volume><issue>01</issue><fpage>217</fpage><lpage>233</lpage></element-citation></ref><ref id="R11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barlow</surname><given-names>HB</given-names></name></person-group><article-title>Unsupervised learning</article-title><source>Neural computation</source><year>1989</year><volume>1</volume><issue>3</issue><fpage>295</fpage><lpage>311</lpage></element-citation></ref><ref id="R12"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bartlett</surname><given-names>FC</given-names></name></person-group><source>Remembering: A study in experimental and social psychology</source><publisher-name>Cambridge university press</publisher-name><year>1932</year></element-citation></ref><ref id="R13"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bender</surname><given-names>EM</given-names></name><name><surname>Gebru</surname><given-names>T</given-names></name><name><surname>McMillan-Major</surname><given-names>A</given-names></name><name><surname>Shmitchell</surname><given-names>S</given-names></name></person-group><source>On the dangers of stochastic parrots: Can language models be too big?</source><conf-name>Proceedings of the 2021 ACM conference on fairness, accountability, and transparency</conf-name><year>2021</year><fpage>610</fpage><lpage>623</lpage></element-citation></ref><ref id="R14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bergman</surname><given-names>ET</given-names></name><name><surname>Roediger</surname><given-names>HL</given-names></name></person-group><article-title>Can Bartlett’s repeated reproduction experiments be replicated?</article-title><source>Memory &amp; cognition</source><year>1999</year><volume>27</volume><issue>6</issue><fpage>937</fpage><lpage>947</lpage><pub-id pub-id-type="pmid">10586570</pub-id></element-citation></ref><ref id="R15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bommasani</surname><given-names>R</given-names></name><name><surname>Hudson</surname><given-names>DA</given-names></name><name><surname>Adeli</surname><given-names>E</given-names></name><name><surname>Altman</surname><given-names>R</given-names></name><name><surname>Arora</surname><given-names>S</given-names></name><name><surname>von Arx</surname><given-names>S</given-names></name><name><surname>Bernstein</surname><given-names>MS</given-names></name><name><surname>Bohg</surname><given-names>J</given-names></name><name><surname>Bosselut</surname><given-names>A</given-names></name><name><surname>Brunskill</surname><given-names>E</given-names></name><etal/></person-group><article-title>On the opportunities and risks of foundation models</article-title><source>arXiv</source><year>2021</year><elocation-id>arXiv:2108.07258</elocation-id></element-citation></ref><ref id="R16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bransford</surname><given-names>JD</given-names></name><name><surname>Barclay</surname><given-names>JR</given-names></name><name><surname>Franks</surname><given-names>JJ</given-names></name></person-group><article-title>Sentence memory: A constructive versus interpretive approach</article-title><source>Cognitive psychology</source><year>1972</year><volume>3</volume><issue>2</issue><fpage>193</fpage><lpage>209</lpage></element-citation></ref><ref id="R17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bricken</surname><given-names>T</given-names></name><name><surname>Templeton</surname><given-names>A</given-names></name><name><surname>Batson</surname><given-names>J</given-names></name><name><surname>Chen</surname><given-names>B</given-names></name><name><surname>Jermyn</surname><given-names>A</given-names></name><name><surname>Conerly</surname><given-names>T</given-names></name><name><surname>Turner</surname><given-names>N</given-names></name><name><surname>Anil</surname><given-names>C</given-names></name><name><surname>Denison</surname><given-names>C</given-names></name><name><surname>Askell</surname><given-names>A</given-names></name><name><surname>Lasenby</surname><given-names>R</given-names></name><etal/></person-group><article-title>Towards monose-manticity: Decomposing language models with dictionary learning</article-title><source>Transformer Circuits Thread</source><year>2023</year><comment>[<ext-link ext-link-type="uri" xlink:href="https://transformer-circuits.pub/2023/monosemantic-features/index.html">https://transformer-circuits.pub/2023/monosemantic-features/index.html</ext-link>]</comment></element-citation></ref><ref id="R18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>T</given-names></name><name><surname>Mann</surname><given-names>B</given-names></name><name><surname>Ryder</surname><given-names>N</given-names></name><name><surname>Subbiah</surname><given-names>M</given-names></name><name><surname>Kaplan</surname><given-names>JD</given-names></name><name><surname>Dhariwal</surname><given-names>P</given-names></name><name><surname>Neelakantan</surname><given-names>A</given-names></name><name><surname>Shyam</surname><given-names>P</given-names></name><name><surname>Sastry</surname><given-names>G</given-names></name><name><surname>Askell</surname><given-names>A</given-names></name><etal/></person-group><article-title>Language models are few-shot learners</article-title><source>Advances in neural information processing systems</source><year>2020</year><volume>33</volume><fpage>1877</fpage><lpage>1901</lpage></element-citation></ref><ref id="R19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burgess</surname><given-names>N</given-names></name><name><surname>Hitch</surname><given-names>GJ</given-names></name></person-group><article-title>Memory for serial order: A network model of the phonological loop and its timing</article-title><source>Psychological review</source><year>1999</year><volume>106</volume><issue>3</issue><fpage>551</fpage></element-citation></ref><ref id="R20"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Carlini</surname><given-names>N</given-names></name><name><surname>Chien</surname><given-names>S</given-names></name><name><surname>Nasr</surname><given-names>M</given-names></name><name><surname>Song</surname><given-names>S</given-names></name><name><surname>Terzis</surname><given-names>A</given-names></name><name><surname>Tramer</surname><given-names>F</given-names></name></person-group><source>Membership inference attacks from first principles</source><conf-name>2022 IEEE Symposium on Security and Privacy (SP)</conf-name><year>2022</year><fpage>1897</fpage><lpage>1914</lpage></element-citation></ref><ref id="R21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carlini</surname><given-names>N</given-names></name><name><surname>Ippolito</surname><given-names>D</given-names></name><name><surname>Jagielski</surname><given-names>M</given-names></name><name><surname>Lee</surname><given-names>K</given-names></name><name><surname>Tramer</surname><given-names>F</given-names></name><name><surname>Zhang</surname><given-names>C</given-names></name></person-group><article-title>Quantifying memorization across neural language models</article-title><source>arXiv</source><year>2022</year><elocation-id>arXiv:2202.07646</elocation-id></element-citation></ref><ref id="R22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chaudhry</surname><given-names>HT</given-names></name><name><surname>Zavatone-Veth</surname><given-names>JA</given-names></name><name><surname>Krotov</surname><given-names>D</given-names></name><name><surname>Pehlevan</surname><given-names>C</given-names></name></person-group><article-title>Long sequence Hopfield memory</article-title><source>arXiv</source><year>2023</year><elocation-id>arXiv:2306.04532</elocation-id></element-citation></ref><ref id="R23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>L</given-names></name><name><surname>Lu</surname><given-names>K</given-names></name><name><surname>Rajeswaran</surname><given-names>A</given-names></name><name><surname>Lee</surname><given-names>K</given-names></name><name><surname>Grover</surname><given-names>A</given-names></name><name><surname>Laskin</surname><given-names>M</given-names></name><name><surname>Abbeel</surname><given-names>P</given-names></name><name><surname>Srinivas</surname><given-names>A</given-names></name><name><surname>Mordatch</surname><given-names>I</given-names></name></person-group><article-title>Decision transformer: Reinforcement learning via sequence modeling</article-title><source>Advances in neural information processing systems</source><year>2021</year><volume>34</volume><fpage>15084</fpage><lpage>15097</lpage></element-citation></ref><ref id="R24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheng</surname><given-names>X</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Zhang</surname><given-names>X</given-names></name><name><surname>Ge</surname><given-names>T</given-names></name><name><surname>Chen</surname><given-names>SQ</given-names></name><name><surname>Wei</surname><given-names>F</given-names></name><name><surname>Zhang</surname><given-names>H</given-names></name><name><surname>Zhao</surname><given-names>D</given-names></name></person-group><article-title>Xrag: Extreme context compression for retrieval-augmented generation with one token</article-title><source>arXiv</source><year>2024</year><elocation-id>arXiv:2405.13792</elocation-id></element-citation></ref><ref id="R25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coltheart</surname><given-names>M</given-names></name><name><surname>Langdon</surname><given-names>R</given-names></name><name><surname>McKay</surname><given-names>R</given-names></name></person-group><article-title>Delusional belief</article-title><source>Annual review of psychology</source><year>2011</year><volume>62</volume><fpage>271</fpage><lpage>298</lpage><pub-id pub-id-type="pmid">20731601</pub-id></element-citation></ref><ref id="R26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cowan</surname><given-names>N</given-names></name></person-group><article-title>The magical number 4 in short-term memory: A reconsideration of mental storage capacity</article-title><source>Behavioral and brain sciences</source><year>2001</year><volume>24</volume><issue>1</issue><fpage>87</fpage><lpage>114</lpage><pub-id pub-id-type="pmid">11515286</pub-id></element-citation></ref><ref id="R27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Seymour</surname><given-names>B</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>Model-based influences on humans’ choices and striatal prediction errors</article-title><source>Neuron</source><year>2011</year><volume>69</volume><issue>6</issue><fpage>1204</fpage><lpage>1215</lpage><pub-id pub-id-type="pmcid">PMC3077926</pub-id><pub-id pub-id-type="pmid">21435563</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2011.02.027</pub-id></element-citation></ref><ref id="R28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Hinton</surname><given-names>GE</given-names></name><name><surname>Neal</surname><given-names>RM</given-names></name><name><surname>Zemel</surname><given-names>RS</given-names></name></person-group><article-title>The Helmholtz machine</article-title><source>Neural computation</source><year>1995</year><volume>7</volume><issue>5</issue><fpage>889</fpage><lpage>904</lpage><pub-id pub-id-type="pmid">7584891</pub-id></element-citation></ref><ref id="R29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deese</surname><given-names>J</given-names></name></person-group><article-title>On the prediction of occurrence of particular verbal intrusions in immediate recall</article-title><source>Journal of experimental psychology</source><year>1959</year><volume>58</volume><issue>1</issue><fpage>17</fpage><pub-id pub-id-type="pmid">13664879</pub-id></element-citation></ref><ref id="R30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Devlin</surname><given-names>J</given-names></name><name><surname>Chang</surname><given-names>MW</given-names></name><name><surname>Lee</surname><given-names>K</given-names></name><name><surname>Toutanova</surname><given-names>K</given-names></name></person-group><article-title>Bert: Pre-training of deep bidirectional transformers for language understanding</article-title><source>arXiv</source><year>2018</year><elocation-id>arXiv:1810.04805</elocation-id></element-citation></ref><ref id="R31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doll</surname><given-names>BB</given-names></name><name><surname>Duncan</surname><given-names>KD</given-names></name><name><surname>Simon</surname><given-names>DA</given-names></name><name><surname>Shohamy</surname><given-names>D</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name></person-group><article-title>Model-based choices involve prospective neural activity</article-title><source>Nature neuroscience</source><year>2015</year><volume>18</volume><issue>5</issue><fpage>767</fpage><lpage>772</lpage><pub-id pub-id-type="pmcid">PMC4414826</pub-id><pub-id pub-id-type="pmid">25799041</pub-id><pub-id pub-id-type="doi">10.1038/nn.3981</pub-id></element-citation></ref><ref id="R32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Durrant</surname><given-names>SJ</given-names></name><name><surname>Taylor</surname><given-names>C</given-names></name><name><surname>Cairney</surname><given-names>S</given-names></name><name><surname>Lewis</surname><given-names>PA</given-names></name></person-group><article-title>Sleep-dependent consolidation of statistical learning</article-title><source>Neuropsychologia</source><year>2011</year><volume>49</volume><issue>5</issue><fpage>1322</fpage><lpage>1331</lpage><pub-id pub-id-type="pmid">21335017</pub-id></element-citation></ref><ref id="R33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dwivedi</surname><given-names>VP</given-names></name><name><surname>Bresson</surname><given-names>X</given-names></name></person-group><article-title>A generalization of transformer networks to graphs</article-title><source>arXiv</source><year>2020</year><elocation-id>arXiv:2012.09699</elocation-id></element-citation></ref><ref id="R34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ellenbogen</surname><given-names>JM</given-names></name><name><surname>Hu</surname><given-names>PT</given-names></name><name><surname>Payne</surname><given-names>JD</given-names></name><name><surname>Titone</surname><given-names>D</given-names></name><name><surname>Walker</surname><given-names>MP</given-names></name></person-group><article-title>Human relational memory requires time and sleep</article-title><source>Proceedings of the National Academy of Sciences</source><year>2007</year><volume>104</volume><issue>18</issue><fpage>7723</fpage><lpage>7728</lpage><pub-id pub-id-type="pmcid">PMC1863467</pub-id><pub-id pub-id-type="pmid">17449637</pub-id><pub-id pub-id-type="doi">10.1073/pnas.0700094104</pub-id></element-citation></ref><ref id="R35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fayyaz</surname><given-names>Z</given-names></name><name><surname>Altamimi</surname><given-names>A</given-names></name><name><surname>Zoellner</surname><given-names>C</given-names></name><name><surname>Klein</surname><given-names>N</given-names></name><name><surname>Wolf</surname><given-names>OT</given-names></name><name><surname>Cheng</surname><given-names>S</given-names></name><name><surname>Wiskott</surname><given-names>L</given-names></name></person-group><article-title>A model of semantic completion in generative episodic memory</article-title><source>Neural Computation</source><year>2022</year><volume>34</volume><issue>9</issue><fpage>1841</fpage><lpage>1870</lpage><pub-id pub-id-type="pmid">35896150</pub-id></element-citation></ref><ref id="R36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Franklin</surname><given-names>NT</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Ranganath</surname><given-names>C</given-names></name><name><surname>Zacks</surname><given-names>JM</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name></person-group><article-title>Structured event memory: A neuro-symbolic model of event cognition</article-title><source>Psychological Review</source><year>2020</year><volume>127</volume><issue>3</issue><fpage>327</fpage><pub-id pub-id-type="pmid">32223284</pub-id></element-citation></ref><ref id="R37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name></person-group><article-title>The free-energy principle: A unified brain theory?</article-title><source>Nature reviews neuroscience</source><year>2010</year><volume>11</volume><issue>2</issue><fpage>127</fpage><lpage>138</lpage><pub-id pub-id-type="pmid">20068583</pub-id></element-citation></ref><ref id="R38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ge</surname><given-names>T</given-names></name><name><surname>Hu</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Chen</surname><given-names>SQ</given-names></name><name><surname>Wei</surname><given-names>F</given-names></name></person-group><article-title>In-context autoencoder for context compression in a large language model</article-title><source>arXiv</source><year>2023</year><elocation-id>arXiv:2307.06945</elocation-id></element-citation></ref><ref id="R39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ha</surname><given-names>D</given-names></name><name><surname>Schmidhuber</surname><given-names>J</given-names></name></person-group><article-title>World models</article-title><source>arXiv</source><year>2018</year><elocation-id>arXiv:1803.10122</elocation-id></element-citation></ref><ref id="R40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hemmer</surname><given-names>P</given-names></name><name><surname>Steyvers</surname><given-names>M</given-names></name></person-group><article-title>A Bayesian account of reconstructive memory</article-title><source>Topics in Cognitive Science</source><year>2009</year><volume>1</volume><issue>1</issue><fpage>189</fpage><lpage>202</lpage><pub-id pub-id-type="pmid">25164805</pub-id></element-citation></ref><ref id="R41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howard</surname><given-names>MW</given-names></name><name><surname>Kahana</surname><given-names>MJ</given-names></name></person-group><article-title>A distributed representation of temporal context</article-title><source>Journal of mathematical psychology</source><year>2002</year><volume>46</volume><issue>3</issue><fpage>269</fpage><lpage>299</lpage></element-citation></ref><ref id="R42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hu</surname><given-names>EJ</given-names></name><name><surname>Shen</surname><given-names>Y</given-names></name><name><surname>Wallis</surname><given-names>P</given-names></name><name><surname>Allen-Zhu</surname><given-names>Z</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Chen</surname><given-names>W</given-names></name></person-group><article-title>Lora: Low-rank adaptation of large language models</article-title><source>arXiv</source><year>2021</year><elocation-id>arXiv:2106.09685</elocation-id></element-citation></ref><ref id="R43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Intraub</surname><given-names>H</given-names></name><name><surname>Richardson</surname><given-names>M</given-names></name></person-group><article-title>Wide-angle memories of close-up scenes</article-title><source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source><year>1989</year><volume>15</volume><issue>2</issue><fpage>179</fpage><pub-id pub-id-type="pmid">2522508</pub-id></element-citation></ref><ref id="R44"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>AQ</given-names></name><name><surname>Sablayrolles</surname><given-names>A</given-names></name><name><surname>Mensch</surname><given-names>A</given-names></name><name><surname>Bamford</surname><given-names>C</given-names></name><name><surname>Chaplot</surname><given-names>DS</given-names></name><name><surname>de las Casas</surname><given-names>D</given-names></name><name><surname>Bressand</surname><given-names>F</given-names></name><name><surname>Lengyel</surname><given-names>G</given-names></name><name><surname>Lample</surname><given-names>G</given-names></name><name><surname>Saulnier</surname><given-names>L</given-names></name><name><surname>Lavaud</surname><given-names>LR</given-names></name><etal/></person-group><source>Mistral 7b</source><year>2023</year><comment><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2310.06825">https://arxiv.org/abs/2310.06825</ext-link></comment></element-citation></ref><ref id="R45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>H</given-names></name><name><surname>Wu</surname><given-names>Q</given-names></name><name><surname>Lin</surname><given-names>CY</given-names></name><name><surname>Yang</surname><given-names>Y</given-names></name><name><surname>Qiu</surname><given-names>L</given-names></name></person-group><article-title>Llmlingua: Compressing prompts for accelerated inference of large language models</article-title><source>arXiv</source><year>2023</year><elocation-id>arXiv:2310.05736</elocation-id></element-citation></ref><ref id="R46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Káli</surname><given-names>S</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><article-title>Hippocampally-dependent consolidation in a hierarchical model of neocortex</article-title><source>Advances in Neural Information Processing Systems</source><year>2000</year><volume>13</volume></element-citation></ref><ref id="R47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Káli</surname><given-names>S</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><article-title>Replay, repair and consolidation</article-title><source>Advances in Neural Information Processing Systems</source><year>2002</year><volume>15</volume></element-citation></ref><ref id="R48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kambhampati</surname><given-names>S</given-names></name><name><surname>Valmeekam</surname><given-names>K</given-names></name><name><surname>Guan</surname><given-names>L</given-names></name><name><surname>Stechly</surname><given-names>K</given-names></name><name><surname>Verma</surname><given-names>M</given-names></name><name><surname>Bhambri</surname><given-names>S</given-names></name><name><surname>Saldyt</surname><given-names>L</given-names></name><name><surname>Murthy</surname><given-names>A</given-names></name></person-group><article-title>Llms can’t plan, but can help planning in llm-modulo frameworks</article-title><source>arXiv</source><year>2024</year><elocation-id>arXiv:2402.01817</elocation-id></element-citation></ref><ref id="R49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kingma</surname><given-names>DP</given-names></name><name><surname>Welling</surname><given-names>M</given-names></name></person-group><article-title>Auto-encoding variational Bayes</article-title><source>arXiv</source><year>2013</year><elocation-id>arXiv:1312.6114</elocation-id></element-citation></ref><ref id="R50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kopelman</surname><given-names>MD</given-names></name></person-group><article-title>Varieties of confabulation and delusion</article-title><source>Cognitive neuropsychiatry</source><year>2010</year><volume>15</volume><issue>1-3</issue><fpage>14</fpage><lpage>37</lpage><pub-id pub-id-type="pmid">19753493</pub-id></element-citation></ref><ref id="R51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kounios</surname><given-names>J</given-names></name><name><surname>Beeman</surname><given-names>M</given-names></name></person-group><article-title>The cognitive neuroscience of insight</article-title><source>Annual review of psychology</source><year>2014</year><volume>65</volume><issue>1</issue><fpage>71</fpage><lpage>93</lpage><pub-id pub-id-type="pmid">24405359</pub-id></element-citation></ref><ref id="R52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krotov</surname><given-names>D</given-names></name><name><surname>Hopfield</surname><given-names>J</given-names></name></person-group><article-title>Large associative memory problem in neurobiology and machine learning</article-title><source>arXiv</source><year>2020</year><elocation-id>arXiv:2008.06996</elocation-id></element-citation></ref><ref id="R53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krotov</surname><given-names>D</given-names></name><name><surname>Hopfield</surname><given-names>JJ</given-names></name></person-group><article-title>Dense associative memory for pattern recognition</article-title><source>Advances in neural information processing systems</source><year>2016</year><volume>29</volume></element-citation></ref><ref id="R54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumar</surname><given-names>M</given-names></name><name><surname>Goldstein</surname><given-names>A</given-names></name><name><surname>Michelmann</surname><given-names>S</given-names></name><name><surname>Zacks</surname><given-names>JM</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><article-title>Bayesian surprise predicts human event segmentation in story listening</article-title><source>Cognitive science</source><year>2023</year><volume>47</volume><issue>10</issue><elocation-id>e13343</elocation-id><pub-id pub-id-type="pmcid">PMC11654724</pub-id><pub-id pub-id-type="pmid">37867379</pub-id><pub-id pub-id-type="doi">10.1111/cogs.13343</pub-id></element-citation></ref><ref id="R55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumaran</surname><given-names>D</given-names></name></person-group><article-title>What representations and computations underpin the contribution of the hippocampus to generalization and inference?</article-title><source>Frontiers in Human Neuroscience</source><year>2012</year><volume>6</volume><fpage>157</fpage><pub-id pub-id-type="pmcid">PMC3366348</pub-id><pub-id pub-id-type="pmid">22675298</pub-id><pub-id pub-id-type="doi">10.3389/fnhum.2012.00157</pub-id></element-citation></ref><ref id="R56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lengyel</surname><given-names>M</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><article-title>Hippocampal contributions to control: The third way</article-title><source>Advances in neural information processing systems</source><year>2007</year><volume>20</volume></element-citation></ref><ref id="R57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewis</surname><given-names>P</given-names></name><name><surname>Perez</surname><given-names>E</given-names></name><name><surname>Piktus</surname><given-names>A</given-names></name><name><surname>Petroni</surname><given-names>F</given-names></name><name><surname>Karpukhin</surname><given-names>V</given-names></name><name><surname>Goyal</surname><given-names>N</given-names></name><name><surname>Küttler</surname><given-names>H</given-names></name><name><surname>Lewis</surname><given-names>M</given-names></name><name><surname>Yih</surname><given-names>Wt</given-names></name><name><surname>Rocktäschel</surname><given-names>T</given-names></name><etal/></person-group><article-title>Retrieval-augmented generation for knowledge-intensive nlp tasks</article-title><source>Advances in Neural Information Processing Systems</source><year>2020</year><volume>33</volume><fpage>9459</fpage><lpage>9474</lpage></element-citation></ref><ref id="R58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>D</given-names></name><name><surname>Rawat</surname><given-names>AS</given-names></name><name><surname>Zaheer</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Lukasik</surname><given-names>M</given-names></name><name><surname>Veit</surname><given-names>A</given-names></name><name><surname>Yu</surname><given-names>F</given-names></name><name><surname>Kumar</surname><given-names>S</given-names></name></person-group><article-title>Large language models with controllable working memory</article-title><source>arXiv</source><year>2022</year><elocation-id>arXiv:2211.05110</elocation-id></element-citation></ref><ref id="R59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Loftus</surname><given-names>EF</given-names></name><name><surname>Palmer</surname><given-names>JC</given-names></name></person-group><article-title>Reconstruction of automobile destruction: An example of the interaction between language and memory</article-title><source>Journal of verbal learning and verbal behavior</source><year>1974</year><volume>13</volume><issue>5</issue><fpage>585</fpage><lpage>589</lpage></element-citation></ref><ref id="R60"><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Loftus</surname><given-names>EF</given-names></name><name><surname>Pickrell</surname><given-names>JE</given-names></name></person-group><source>The formation of false memories</source><year>1995</year></element-citation></ref><ref id="R61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>Q</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><article-title>A neural network model of when to retrieve and encode episodic memories</article-title><source>elife</source><year>2022</year><volume>11</volume><elocation-id>e74445</elocation-id><pub-id pub-id-type="pmcid">PMC9000961</pub-id><pub-id pub-id-type="pmid">35142289</pub-id><pub-id pub-id-type="doi">10.7554/eLife.74445</pub-id></element-citation></ref><ref id="R62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mangrulkar</surname><given-names>S</given-names></name><name><surname>Gugger</surname><given-names>S</given-names></name><name><surname>Debut</surname><given-names>L</given-names></name><name><surname>Belkada</surname><given-names>Y</given-names></name><name><surname>Paul</surname><given-names>S</given-names></name><name><surname>Bossan</surname><given-names>B</given-names></name></person-group><article-title>Peft: State-of-the-art parameter-efficient fine-tuning methods</article-title><year>2022</year></element-citation></ref><ref id="R63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marr</surname><given-names>D</given-names></name></person-group><article-title>A theory for cerebral neocortex</article-title><source>Proceedings of the Royal society of London Series B Biological sciences</source><year>1970</year><volume>176</volume><issue>1043</issue><fpage>161</fpage><lpage>234</lpage><pub-id pub-id-type="pmid">4394740</pub-id></element-citation></ref><ref id="R64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marr</surname><given-names>D</given-names></name></person-group><article-title>Simple memory: A theory for archicortex</article-title><source>Philosophical Transactions of the Royal Society of London B, Biological Sciences</source><year>1971</year><volume>262</volume><issue>841</issue><fpage>23</fpage><lpage>81</lpage><pub-id pub-id-type="pmid">4399412</pub-id></element-citation></ref><ref id="R65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McClelland</surname><given-names>JL</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>O’Reilly</surname><given-names>RC</given-names></name></person-group><article-title>Why there are complementary learning systems in the hippocampus and neocortex: Insights from the successes and failures of connectionist models of learning and memory</article-title><source>Psychological review</source><year>1995</year><volume>102</volume><issue>3</issue><fpage>419</fpage><pub-id pub-id-type="pmid">7624455</pub-id></element-citation></ref><ref id="R66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McKenzie</surname><given-names>S</given-names></name><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><article-title>Consolidation and reconsolidation: Two lives of memories?</article-title><source>Neuron</source><year>2011</year><volume>71</volume><issue>2</issue><fpage>224</fpage><lpage>233</lpage><pub-id pub-id-type="pmcid">PMC3145971</pub-id><pub-id pub-id-type="pmid">21791282</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2011.06.037</pub-id></element-citation></ref><ref id="R67"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Meng</surname><given-names>R</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Joty</surname><given-names>SR</given-names></name><name><surname>Xiong</surname><given-names>C</given-names></name><name><surname>Zhou</surname><given-names>Y</given-names></name><name><surname>Yavuz</surname><given-names>S</given-names></name></person-group><source>Sfr-embedding-mistral:enhance text retrieval with transfer learning</source><year>2024</year><comment><ext-link ext-link-type="uri" xlink:href="https://www.salesforce.com/blog/sfr-embedding/">https://www.salesforce.com/blog/sfr-embedding/</ext-link></comment></element-citation></ref><ref id="R68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Michelmann</surname><given-names>S</given-names></name><name><surname>Kumar</surname><given-names>M</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Toneva</surname><given-names>M</given-names></name></person-group><article-title>Large language models can segment narrative events similarly to humans</article-title><source>Behavior Research Methods</source><year>2025</year><volume>57</volume><issue>1</issue><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="pmcid">PMC11810054</pub-id><pub-id pub-id-type="pmid">39751673</pub-id><pub-id pub-id-type="doi">10.3758/s13428-024-02569-z</pub-id></element-citation></ref><ref id="R69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Migo</surname><given-names>E</given-names></name><name><surname>Montaldi</surname><given-names>D</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Quamme</surname><given-names>J</given-names></name><name><surname>Mayes</surname><given-names>A</given-names></name></person-group><article-title>The contribution of familiarity to recognition memory is a function of test format when using similar foils</article-title><source>Quarterly Journal of Experimental Psychology</source><year>2009</year><volume>62</volume><issue>6</issue><fpage>1198</fpage><lpage>1215</lpage><pub-id pub-id-type="pmcid">PMC3001278</pub-id><pub-id pub-id-type="pmid">19096990</pub-id><pub-id pub-id-type="doi">10.1080/17470210802391599</pub-id></element-citation></ref><ref id="R70"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Millidge</surname><given-names>B</given-names></name><name><surname>Salvatori</surname><given-names>T</given-names></name><name><surname>Song</surname><given-names>Y</given-names></name><name><surname>Lukasiewicz</surname><given-names>T</given-names></name><name><surname>Bogacz</surname><given-names>R</given-names></name></person-group><source>Universal Hopfield networks: A general framework for single-shot associative memory models</source><conf-name>International Conference on Machine Learning</conf-name><year>2022</year><fpage>15561</fpage><lpage>15583</lpage></element-citation></ref><ref id="R71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Millidge</surname><given-names>B</given-names></name><name><surname>Seth</surname><given-names>A</given-names></name><name><surname>Buckley</surname><given-names>CL</given-names></name></person-group><article-title>Predictive coding: A theoretical and experimental review</article-title><source>arXiv</source><year>2021</year><elocation-id>arXiv:2107.12979</elocation-id></element-citation></ref><ref id="R72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Momennejad</surname><given-names>I</given-names></name><name><surname>Russek</surname><given-names>EM</given-names></name><name><surname>Cheong</surname><given-names>JH</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name></person-group><article-title>The successor representation in human reinforcement learning</article-title><source>Nature human behaviour</source><year>2017</year><volume>1</volume><issue>9</issue><fpage>680</fpage><lpage>692</lpage><pub-id pub-id-type="pmcid">PMC6941356</pub-id><pub-id pub-id-type="pmid">31024137</pub-id><pub-id pub-id-type="doi">10.1038/s41562-017-0180-8</pub-id></element-citation></ref><ref id="R73"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Mostafazadeh</surname><given-names>N</given-names></name><name><surname>Chambers</surname><given-names>N</given-names></name><name><surname>He</surname><given-names>X</given-names></name><name><surname>Parikh</surname><given-names>D</given-names></name><name><surname>Batra</surname><given-names>D</given-names></name><name><surname>Vanderwende</surname><given-names>L</given-names></name><name><surname>Kohli</surname><given-names>P</given-names></name><name><surname>Allen</surname><given-names>J</given-names></name></person-group><source>A corpus and cloze evaluation for deeper understanding of commonsense stories</source><conf-name>Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</conf-name><year>2016</year><fpage>839</fpage><lpage>849</lpage></element-citation></ref><ref id="R74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nadel</surname><given-names>L</given-names></name><name><surname>Moscovitch</surname><given-names>M</given-names></name></person-group><article-title>Memory consolidation, retrograde amnesia and the hippocampal complex</article-title><source>Current opinion in neurobiology</source><year>1997</year><volume>7</volume><issue>2</issue><fpage>217</fpage><lpage>227</lpage><pub-id pub-id-type="pmid">9142752</pub-id></element-citation></ref><ref id="R75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nagy</surname><given-names>DG</given-names></name><name><surname>Orban</surname><given-names>G</given-names></name><name><surname>Wu</surname><given-names>CM</given-names></name></person-group><article-title>Interplay of episodic and semantic memory arises from adaptive compression</article-title><year>2025</year></element-citation></ref><ref id="R76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nagy</surname><given-names>DG</given-names></name><name><surname>Török</surname><given-names>B</given-names></name><name><surname>Orbán</surname><given-names>G</given-names></name></person-group><article-title>Optimal forgetting: Semantic compression of episodic memories</article-title><source>PLoS Computational Biology</source><year>2020</year><volume>16</volume><issue>10</issue><elocation-id>e1008367</elocation-id><pub-id pub-id-type="pmcid">PMC7591090</pub-id><pub-id pub-id-type="pmid">33057380</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008367</pub-id></element-citation></ref><ref id="R77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nejad</surname><given-names>AB</given-names></name><name><surname>Fossati</surname><given-names>P</given-names></name><name><surname>Lemogne</surname><given-names>C</given-names></name></person-group><article-title>Self-referential processing, rumination, and cortical midline structures in major depression</article-title><source>Frontiers in human neuroscience</source><year>2013</year><volume>7</volume><fpage>666</fpage><pub-id pub-id-type="pmcid">PMC3794427</pub-id><pub-id pub-id-type="pmid">24124416</pub-id><pub-id pub-id-type="doi">10.3389/fnhum.2013.00666</pub-id></element-citation></ref><ref id="R78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newtson</surname><given-names>D</given-names></name></person-group><article-title>Attribution and the unit of perception of ongoing behavior</article-title><source>Journal of personality and social psychology</source><year>1973</year><volume>28</volume><issue>1</issue><fpage>28</fpage></element-citation></ref><ref id="R79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newtson</surname><given-names>D</given-names></name><name><surname>Engquist</surname><given-names>G</given-names></name></person-group><article-title>The perceptual organization of ongoing behavior</article-title><source>Journal of Experimental Social Psychology</source><year>1976</year><volume>12</volume><issue>5</issue><fpage>436</fpage><lpage>450</lpage></element-citation></ref><ref id="R80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ohlsson</surname><given-names>S</given-names></name></person-group><article-title>Information-processing explanations of insight and related phenomena</article-title><source>Advances in the psychology of thinking</source><year>1992</year><volume>1</volume><fpage>1</fpage><lpage>44</lpage></element-citation></ref><ref id="R81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Payne</surname><given-names>JD</given-names></name><name><surname>Schacter</surname><given-names>DL</given-names></name><name><surname>Propper</surname><given-names>RE</given-names></name><name><surname>Huang</surname><given-names>LW</given-names></name><name><surname>Wamsley</surname><given-names>EJ</given-names></name><name><surname>Tucker</surname><given-names>MA</given-names></name><name><surname>Walker</surname><given-names>MP</given-names></name><name><surname>Stickgold</surname><given-names>R</given-names></name></person-group><article-title>The role of sleep in false memory formation</article-title><source>Neurobiology of learning and memory</source><year>2009</year><volume>92</volume><issue>3</issue><fpage>327</fpage><lpage>334</lpage><pub-id pub-id-type="pmcid">PMC2789473</pub-id><pub-id pub-id-type="pmid">19348959</pub-id><pub-id pub-id-type="doi">10.1016/j.nlm.2009.03.007</pub-id></element-citation></ref><ref id="R82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quiroga</surname><given-names>RQ</given-names></name></person-group><article-title>Concept cells: The building blocks of declarative memory functions</article-title><source>Nature Reviews Neuroscience</source><year>2012</year><volume>13</volume><issue>8</issue><fpage>587</fpage><lpage>597</lpage><pub-id pub-id-type="pmid">22760181</pub-id></element-citation></ref><ref id="R83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Radford</surname><given-names>A</given-names></name><name><surname>Wu</surname><given-names>J</given-names></name><name><surname>Child</surname><given-names>R</given-names></name><name><surname>Luan</surname><given-names>D</given-names></name><name><surname>Amodei</surname><given-names>D</given-names></name><name><surname>Sutskever</surname><given-names>I</given-names></name><etal/></person-group><article-title>Language models are unsupervised multitask learners</article-title><source>OpenAI blog</source><year>2019</year><volume>1</volume><issue>8</issue><fpage>9</fpage></element-citation></ref><ref id="R84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raichle</surname><given-names>ME</given-names></name><name><surname>MacLeod</surname><given-names>AM</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Powers</surname><given-names>WJ</given-names></name><name><surname>Gusnard</surname><given-names>DA</given-names></name><name><surname>Shulman</surname><given-names>GL</given-names></name></person-group><article-title>A default mode of brain function</article-title><source>Proceedings of the national academy of sciences</source><year>2001</year><volume>98</volume><issue>2</issue><fpage>676</fpage><lpage>682</lpage><pub-id pub-id-type="pmcid">PMC14647</pub-id><pub-id pub-id-type="pmid">11209064</pub-id><pub-id pub-id-type="doi">10.1073/pnas.98.2.676</pub-id></element-citation></ref><ref id="R85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramsauer</surname><given-names>H</given-names></name><name><surname>Schäfl</surname><given-names>B</given-names></name><name><surname>Lehner</surname><given-names>J</given-names></name><name><surname>Seidl</surname><given-names>P</given-names></name><name><surname>Widrich</surname><given-names>M</given-names></name><name><surname>Adler</surname><given-names>T</given-names></name><name><surname>Gruber</surname><given-names>L</given-names></name><name><surname>Holzleitner</surname><given-names>M</given-names></name><name><surname>Pavlović</surname><given-names>M</given-names></name><name><surname>Sandve</surname><given-names>GK</given-names></name><etal/></person-group><article-title>Hopfield networks is all you need</article-title><source>arXiv</source><year>2020</year><elocation-id>arXiv:2008.02217</elocation-id></element-citation></ref><ref id="R86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rao</surname><given-names>RP</given-names></name><name><surname>Ballard</surname><given-names>DH</given-names></name></person-group><article-title>Predictive coding in the visual cortex: A functional interpretation of some extra-classical receptive-field effects</article-title><source>Nature neuroscience</source><year>1999</year><volume>2</volume><issue>1</issue><fpage>79</fpage><lpage>87</lpage><pub-id pub-id-type="pmid">10195184</pub-id></element-citation></ref><ref id="R87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rashkin</surname><given-names>H</given-names></name><name><surname>Bosselut</surname><given-names>A</given-names></name><name><surname>Sap</surname><given-names>M</given-names></name><name><surname>Knight</surname><given-names>K</given-names></name><name><surname>Choi</surname><given-names>Y</given-names></name></person-group><article-title>Modeling naive psychology of characters in simple commonsense stories</article-title><source>arXiv</source><year>2018</year><elocation-id>arXiv:1805.06533</elocation-id></element-citation></ref><ref id="R88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raykov</surname><given-names>PP</given-names></name><name><surname>Varga</surname><given-names>D</given-names></name><name><surname>Bird</surname><given-names>CM</given-names></name></person-group><article-title>False memories for ending of events</article-title><source>Journal of Experimental Psychology: General</source><year>2023</year><pub-id pub-id-type="pmcid">PMC10694998</pub-id><pub-id pub-id-type="pmid">37650821</pub-id><pub-id pub-id-type="doi">10.1037/xge0001462</pub-id></element-citation></ref><ref id="R89"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Reimers</surname><given-names>N</given-names></name><name><surname>Gurevych</surname><given-names>I</given-names></name></person-group><source>Sentence-bert: Sentence embeddings using siamese bert-networks</source><conf-name>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing</conf-name><year>2019</year><comment><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1908.10084">https://arxiv.org/abs/1908.10084</ext-link></comment></element-citation></ref><ref id="R90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robin</surname><given-names>J</given-names></name><name><surname>Moscovitch</surname><given-names>M</given-names></name></person-group><article-title>Details, gist and schema: Hippocampal–neocortical interactions underlying recent and remote episodic and spatial memory</article-title><source>Current opinion in behavioral sciences</source><year>2017</year><volume>17</volume><fpage>114</fpage><lpage>123</lpage></element-citation></ref><ref id="R91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roediger</surname><given-names>HL</given-names></name><name><surname>McDermott</surname><given-names>KB</given-names></name></person-group><article-title>Creating false memories: Remembering words not presented in lists</article-title><source>Journal of experimental psychology: Learning, Memory, and Cognition</source><year>1995</year><volume>21</volume><issue>4</issue><fpage>803</fpage></element-citation></ref><ref id="R92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salvatori</surname><given-names>T</given-names></name><name><surname>Song</surname><given-names>Y</given-names></name><name><surname>Hong</surname><given-names>Y</given-names></name><name><surname>Sha</surname><given-names>L</given-names></name><name><surname>Frieder</surname><given-names>S</given-names></name><name><surname>Xu</surname><given-names>Z</given-names></name><name><surname>Bogacz</surname><given-names>R</given-names></name><name><surname>Lukasiewicz</surname><given-names>T</given-names></name></person-group><article-title>Associative memories via predictive coding</article-title><source>Advances in Neural Information Processing Systems</source><year>2021</year><volume>34</volume><fpage>3874</fpage><lpage>3886</lpage><pub-id pub-id-type="pmcid">PMC7612799</pub-id><pub-id pub-id-type="pmid">35664437</pub-id></element-citation></ref><ref id="R93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Samborska</surname><given-names>V</given-names></name><name><surname>Butler</surname><given-names>JL</given-names></name><name><surname>Walton</surname><given-names>ME</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name><name><surname>Akam</surname><given-names>T</given-names></name></person-group><article-title>Complementary task representations in hippocampus and prefrontal cortex for generalizing the structure of problems</article-title><source>Nature Neuroscience</source><year>2022</year><volume>25</volume><issue>10</issue><fpage>1314</fpage><lpage>1326</lpage><pub-id pub-id-type="pmcid">PMC9534768</pub-id><pub-id pub-id-type="pmid">36171429</pub-id><pub-id pub-id-type="doi">10.1038/s41593-022-01149-8</pub-id></element-citation></ref><ref id="R94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schacter</surname><given-names>DL</given-names></name><name><surname>Addis</surname><given-names>DR</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name></person-group><article-title>Remembering the past to imagine the future: The prospective brain</article-title><source>Nature reviews neuroscience</source><year>2007</year><volume>8</volume><issue>9</issue><fpage>657</fpage><lpage>661</lpage><pub-id pub-id-type="pmid">17700624</pub-id></element-citation></ref><ref id="R95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schönfeld</surname><given-names>F</given-names></name><name><surname>Wiskott</surname><given-names>L</given-names></name></person-group><article-title>Modeling place field activity with hierarchical slow feature analysis</article-title><source>Frontiers in computational neuroscience</source><year>2015</year><volume>9</volume><fpage>51</fpage><pub-id pub-id-type="pmcid">PMC4441153</pub-id><pub-id pub-id-type="pmid">26052279</pub-id><pub-id pub-id-type="doi">10.3389/fncom.2015.00051</pub-id></element-citation></ref><ref id="R96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sompolinsky</surname><given-names>H</given-names></name><name><surname>Kanter</surname><given-names>I</given-names></name></person-group><article-title>Temporal association in asymmetric neural networks</article-title><source>Physical review letters</source><year>1986</year><volume>57</volume><issue>22</issue><elocation-id>2861</elocation-id><pub-id pub-id-type="pmid">10033885</pub-id></element-citation></ref><ref id="R97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sorscher</surname><given-names>B</given-names></name><name><surname>Mel</surname><given-names>GC</given-names></name><name><surname>Ocko</surname><given-names>SA</given-names></name><name><surname>Giocomo</surname><given-names>LM</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name></person-group><article-title>A unified theory for the computational and mechanistic origins of grid cells</article-title><source>Neuron</source><year>2023</year><volume>111</volume><issue>1</issue><fpage>121</fpage><lpage>137</lpage><pub-id pub-id-type="pmid">36306779</pub-id></element-citation></ref><ref id="R98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spens</surname><given-names>E</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><article-title>A generative model of memory construction and consolidation</article-title><source>Nature Human Behaviour</source><year>2024</year><fpage>1</fpage><lpage>18</lpage><pub-id pub-id-type="pmcid">PMC10963272</pub-id><pub-id pub-id-type="pmid">38242925</pub-id><pub-id pub-id-type="doi">10.1038/s41562-023-01799-z</pub-id></element-citation></ref><ref id="R99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stachenfeld</surname><given-names>KL</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name></person-group><article-title>The hippocampus as a predictive map</article-title><source>Nature neuroscience</source><year>2017</year><volume>20</volume><issue>11</issue><fpage>1643</fpage><lpage>1653</lpage><pub-id pub-id-type="pmid">28967910</pub-id></element-citation></ref><ref id="R100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>W</given-names></name><name><surname>Advani</surname><given-names>M</given-names></name><name><surname>Spruston</surname><given-names>N</given-names></name><name><surname>Saxe</surname><given-names>A</given-names></name><name><surname>Fitzgerald</surname><given-names>JE</given-names></name></person-group><article-title>Organizing memories for generalization in complementary learning systems</article-title><source>Nature neuroscience</source><year>2023</year><volume>26</volume><issue>8</issue><fpage>1438</fpage><lpage>1448</lpage><pub-id pub-id-type="pmcid">PMC10400413</pub-id><pub-id pub-id-type="pmid">37474639</pub-id><pub-id pub-id-type="doi">10.1038/s41593-023-01382-9</pub-id></element-citation></ref><ref id="R101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tang</surname><given-names>M</given-names></name><name><surname>Barron</surname><given-names>H</given-names></name><name><surname>Bogacz</surname><given-names>R</given-names></name></person-group><article-title>Sequential memory with temporal predictive coding</article-title><source>arXiv</source><year>2023</year><elocation-id>arXiv:2305.11982</elocation-id><pub-id pub-id-type="pmcid">PMC7615819</pub-id><pub-id pub-id-type="pmid">38606302</pub-id></element-citation></ref><ref id="R102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tarder-Stoll</surname><given-names>H</given-names></name><name><surname>Baldassano</surname><given-names>C</given-names></name><name><surname>Aly</surname><given-names>M</given-names></name></person-group><article-title>Consolidation enhances sequential multi-step anticipation but diminishes access to perceptual features</article-title><source>Psychological Science</source><year>2024</year><elocation-id>09567976241256617</elocation-id><pub-id pub-id-type="pmcid">PMC11532645</pub-id><pub-id pub-id-type="pmid">39110746</pub-id><pub-id pub-id-type="doi">10.1177/09567976241256617</pub-id></element-citation></ref><ref id="R103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tse</surname><given-names>D</given-names></name><name><surname>Langston</surname><given-names>RF</given-names></name><name><surname>Kakeyama</surname><given-names>M</given-names></name><name><surname>Bethus</surname><given-names>I</given-names></name><name><surname>Spooner</surname><given-names>PA</given-names></name><name><surname>Wood</surname><given-names>ER</given-names></name><name><surname>Witter</surname><given-names>MP</given-names></name><name><surname>Morris</surname><given-names>RG</given-names></name></person-group><article-title>Schemas and memory consolidation</article-title><source>Science</source><year>2007</year><volume>316</volume><issue>5821</issue><fpage>76</fpage><lpage>82</lpage><pub-id pub-id-type="pmid">17412951</pub-id></element-citation></ref><ref id="R104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vikbladh</surname><given-names>O</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name><name><surname>Russek</surname><given-names>E</given-names></name></person-group><article-title>Systems consolidation of sequential dynamics in model-based planning</article-title><source>bioRxiv</source><year>2024</year></element-citation></ref><ref id="R105"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Vikbladh</surname><given-names>O</given-names></name><name><surname>Shohamy</surname><given-names>D</given-names></name><name><surname>Daw</surname><given-names>N</given-names></name></person-group><source>Episodic contributions to model-based reinforcement learning</source><conf-name>Annual conference on cognitive computational neuroscience, CCN</conf-name><year>2017</year></element-citation></ref><ref id="R106"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Warstadt</surname><given-names>A</given-names></name><name><surname>Bowman</surname><given-names>SR</given-names></name></person-group><chapter-title>What artificial neural networks can tell us about human language acquisition</chapter-title><source>Algebraic structures in natural language</source><publisher-name>CRC Press</publisher-name><year>2022</year><fpage>17</fpage><lpage>60</lpage></element-citation></ref><ref id="R107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whittington</surname><given-names>JC</given-names></name><name><surname>Bogacz</surname><given-names>R</given-names></name></person-group><article-title>Theories of error back-propagation in the brain</article-title><source>Trends in cognitive sciences</source><year>2019</year><volume>23</volume><issue>3</issue><fpage>235</fpage><lpage>250</lpage><pub-id pub-id-type="pmcid">PMC6382460</pub-id><pub-id pub-id-type="pmid">30704969</pub-id><pub-id pub-id-type="doi">10.1016/j.tics.2018.12.005</pub-id></element-citation></ref><ref id="R108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whittington</surname><given-names>JC</given-names></name><name><surname>Muller</surname><given-names>TH</given-names></name><name><surname>Mark</surname><given-names>S</given-names></name><name><surname>Chen</surname><given-names>G</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name></person-group><article-title>The Tolman-Eichenbaum machine: Unifying space and relational memory through generalization in the hippocampal formation</article-title><source>Cell</source><year>2020</year><volume>183</volume><issue>5</issue><fpage>1249</fpage><lpage>1263</lpage><pub-id pub-id-type="pmcid">PMC7707106</pub-id><pub-id pub-id-type="pmid">33181068</pub-id><pub-id pub-id-type="doi">10.1016/j.cell.2020.10.024</pub-id></element-citation></ref><ref id="R109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolf</surname><given-names>T</given-names></name><name><surname>Debut</surname><given-names>L</given-names></name><name><surname>Sanh</surname><given-names>V</given-names></name><name><surname>Chaumond</surname><given-names>J</given-names></name><name><surname>Delangue</surname><given-names>C</given-names></name><name><surname>Moi</surname><given-names>A</given-names></name><name><surname>Cistac</surname><given-names>P</given-names></name><name><surname>Rault</surname><given-names>T</given-names></name><name><surname>Louf</surname><given-names>R</given-names></name><name><surname>Funtowicz</surname><given-names>M</given-names></name><etal/></person-group><article-title>HuggingFace’s transformers: State-of-the-art natural language processing</article-title><source>arXiv</source><year>2019</year><elocation-id>arXiv:1910.03771</elocation-id></element-citation></ref><ref id="R110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>F</given-names></name><name><surname>Shi</surname><given-names>W</given-names></name><name><surname>Choi</surname><given-names>E</given-names></name></person-group><article-title>Recomp: Improving retrieval-augmented lms with compression and selective augmentation</article-title><source>arXiv</source><year>2023</year><elocation-id>arXiv:2310.04408</elocation-id></element-citation></ref><ref id="R111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yan</surname><given-names>W</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Abbeel</surname><given-names>P</given-names></name><name><surname>Srinivas</surname><given-names>A</given-names></name></person-group><article-title>VideoGPT: Video generation using VQ-VAE and transformers</article-title><source>arXiv</source><year>2021</year><elocation-id>arXiv:2104.10157</elocation-id><pub-id pub-id-type="arxiv">2104.10157</pub-id></element-citation></ref><ref id="R112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yonelinas</surname><given-names>AP</given-names></name><name><surname>Otten</surname><given-names>LJ</given-names></name><name><surname>Shaw</surname><given-names>KN</given-names></name><name><surname>Rugg</surname><given-names>MD</given-names></name></person-group><article-title>Separating the brain regions involved in recollection and familiarity in recognition memory</article-title><source>Journal of Neuroscience</source><year>2005</year><volume>25</volume><issue>11</issue><fpage>3002</fpage><lpage>3008</lpage><pub-id pub-id-type="pmcid">PMC6725129</pub-id><pub-id pub-id-type="pmid">15772360</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5295-04.2005</pub-id></element-citation></ref><ref id="R113"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zacks</surname><given-names>JM</given-names></name><name><surname>Speer</surname><given-names>NK</given-names></name><name><surname>Swallow</surname><given-names>KM</given-names></name><name><surname>Braver</surname><given-names>TS</given-names></name><name><surname>Reynolds</surname><given-names>JR</given-names></name></person-group><article-title>Event perception: A mind-brain perspective</article-title><source>Psychological bulletin</source><year>2007</year><volume>133</volume><issue>2</issue><fpage>273</fpage><pub-id pub-id-type="pmcid">PMC2852534</pub-id><pub-id pub-id-type="pmid">17338600</pub-id><pub-id pub-id-type="doi">10.1037/0033-2909.133.2.273</pub-id></element-citation></ref><ref id="R114"><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Ziadé</surname><given-names>T</given-names></name></person-group><source>Wikipedia topics</source><year>2024</year><date-in-citation>Accessed: 2024-05-31</date-in-citation></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>Summary of model.</title><p>a) Episodic memories are first encoded in the hippocampus, then replayed during rest to train a generative network (simulated by an LLM). Semantic memory is acquired as a byproduct. The hippocampus (‘retriever’) and neocortex (‘generator’) can interact to play complementary roles during problem solving, resembling an adaptive variant of ‘retrieval-augmented generation’ (RAG; <xref ref-type="bibr" rid="R57">Lewis et al., 2020</xref>) in which the ‘generator’ is trained by the ‘retriever’. Relevant hippocampal traces are retrieved into working memory and then used to condition (or ‘prompt’) the neocortical network. b) Sequences are first encoded in the hippocampus. c) Memories are replayed from the hippocampus during rest, and the generative network learns to capture their statistics through prediction error minimisation. Once a sequence is consolidated, the generative network can retrieve the rest of a sequence given its start, without requiring the hippocampal trace. d) Even prior to consolidation, the neocortical and hippocampal networks can work together to solve problems via RAG. e) In the ‘full’ model, sequence ‘gists’ are encoded together with unexpected details. Specifically, a vector from which the sequence can be approximately decoded is stored for each event (<xref ref-type="bibr" rid="R24">Cheng et al., 2024</xref>), together with the subsequences that were most surprising given this compressed version of the event.</p></caption><graphic xlink:href="EMS199914-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><p>a) Retrieval-augmented generation (RAG; <xref ref-type="bibr" rid="R57">Lewis et al., 2020</xref>). When the neocortical generative network (‘generator’) is prompted with a query, e.g. ‘What is replay for?’, related information is retrieved from hippocampal memory (‘retriever’). The retrieval process finds stored information with similar vectors to the query (all text is converted into vectors by a ‘text embedding model’). A combined prompt is then created from the query and the retrieved information or ‘context’, improving the output from the generator. b) Retrieval-augmented generation with context compression using xRAG (<xref ref-type="bibr" rid="R24">Cheng et al., 2024</xref>). This approach trains a small network to map vectors from a text embedding model into a single token representation. This allows the context to be represented as a single token, which is fed into the first layer of an LLM together with the tokens of the query. This means the context document itself does not need to be stored in external memory; storing its vector is enough.</p></caption><graphic xlink:href="EMS199914-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>The effect of prior knowledge on narrative distortions.</title><p>a) GPT-2 is fine-tuned on Wikipedia content (<xref ref-type="bibr" rid="R114">Ziadé, 2024</xref>) from each of six categories plus the <xref ref-type="bibr" rid="R12">Bartlett (1932)</xref> story. The embeddings of the training data plus the recalled story for each model (at a temperature of 0.5) are obtained, using ‘all-MiniLM-L6-v2’ from <xref ref-type="bibr" rid="R89">Reimers and Gurevych (2019)</xref>. These embeddings are projected into 2D with PCA, showing that recall moves each story (see legend) towards its training data (points of the same colour). b) The cosine distance between the mean embedding for each category and the original story (purple) and recalled stories (orange). Recalled stories become more similar to the background dataset. Error bars give the SEM for the five recalled stories sampled (but are zero for the original stories, as there is only one). c) The effect of temperature when sampling continuations on the number of new words in the recalled Bartlett stories (‘semantic intrusions’). Error bars give the SEM. All results are for the final model at epoch five. d) The effect of epoch on the number of new words in the recalled Bartlett stories, where an epoch is one presentation of the entire training dataset. This shows the effect of increased learning of the original story. Error bars give the SEM. All results use a temperature of 0.5. e) Word clouds showing ‘semantic intrusions’ for the six models (produced with the ‘wordcloud’ Python package, with common words, i.e. ‘stopwords’, excluded) at a temperature of 0.5, aggregated across five trials. This demonstrates that distortions reflect the model’s expectations. See also <xref ref-type="table" rid="T3">Table 3</xref>.</p></caption><graphic xlink:href="EMS199914-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><p>a) Event extension and contraction results, showing omission errors and extension errors after long (left) and short (right) retention intervals, adapted from <xref ref-type="bibr" rid="R88">Raykov et al. (2023)</xref> with permission. b) The mean proportion of stories recalled with omission and extension errors, averaged across ten trials, modeling performance after consolidation (cf. long delay in a). Omission errors are more common for updated than for incomplete stories, while the reverse is true for extension errors. As in part a, error bars give the 95% confidence intervals of the mean.</p></caption><graphic xlink:href="EMS199914-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>Statistical learning of sequential structure.</title><p>a) In structured sequences of tones, the preceding two tones determine the next according to the transition matrix (left), except for 10% of transitions which are random to avoid repetition. That is, white squares indicate a 90% probability of a certain tone coming next in the sequence. In unstructured sequences, all transitions are random. Adapted from <xref ref-type="bibr" rid="R32">Durrant et al. (2011)</xref> with permission. b) The learned transition structure when GPT-2 is trained from scratch on data from <xref ref-type="bibr" rid="R32">Durrant et al. (2011)</xref>, with transition probabilities extracted from data generated by the trained model (with a temperature of 0.1). c) The improvement in accuracy between immediate and delayed recall for the wake and sleep groups, adapted from <xref ref-type="bibr" rid="R32">Durrant et al. (2011)</xref> with permission. Two variants are tested: an overnight asleep vs. daytime awake delay (Experiment 1), and a daytime nap vs. daytime awake delay (Experiment 2). d) Perplexity (a measure of prediction error) over time for structured vs. unstructured sequences, for a model trained on structured sequences. The ability to distinguish the two types based on their perplexity increases over time. Error bars give the SEM.</p></caption><graphic xlink:href="EMS199914-f005"/></fig><fig id="F6" position="float"><label>Figure 6</label><caption><title>Learning structural regularities in graphs.</title><p>a) The spatial graph task. Spatial trajectories are modelled as walks on the graph, and represented as strings as shown. b) Testing structural inference, modelled as the ability to complete sequences on unseen graphs based on structural regularities. For example, it is possible to infer that the next location in the sequence shown is ‘j’, given the structural regularities of spatial graphs. c) The training and validation losses of GPT-2 trained for one epoch on sequences from 500,000 spatial graphs, where the loss is a measure of aggregated prediction error. d) The family tree graph task. Relationships between family members are modelled as walks on the graph, and represented as strings as shown. e) Testing structural inference in the family tree graph. For example, it is possible to infer that the next person in the sequence shown is ‘o’, given the structural regularities of family tree graphs. f) The training and validation losses of GPT-2 trained for one epoch on sequences from 500,000 family tree graphs. g) Loop completion performance for the spatial and family tree models, grouped by the number of edges (‘hops’) in the template. Error bars give the SEM. See Tables 7 and 8, <xref ref-type="supplementary-material" rid="SD1">SI</xref>, for the accuracies for each template. h) The fraction of ‘imagined’ spatial trajectories which are structurally valid, at a range of temperatures. A sequence is marked as invalid if different locations are found at the same inferred co-ordinates, e.g. in ‘sz WEST eq EAST zr’ both ‘sz’ and ‘zr’ occur at the same co-ordinates, which is contradictory. i) The maximum Manhattan distance travelled from the origin for ‘imagined’ trajectories of length 50 tokens (with individual data points plotted, and error bars giving the SEM). j) Accuracy by grid size. The spatial inference model - trained on paths in a 3x3 grid of locations - was tested on a range of grid sizes. (The ‘Grid size’ axis gives the height and width of the grid in nodes, i.e. the grid size is 3 for environments in the training data.) Templates in which the final location can be inferred were populated with random locations, i.e. the test data are paths in novel environments not featuring in the training data.</p></caption><graphic xlink:href="EMS199914-f006"/></fig><fig id="F7" position="float"><label>Figure 7</label><caption><title>Exploring hidden representations in the spatial graph task.</title><p>a) Activations for each token of a random walk were extracted from layer 12 of our model, in order to obtain a vector for each location (aggregating across multiple tokens where necessary). b) As above but for pre-trained GPT-2 medium as a baseline. c-d) We ran principal component analysis with two components across representations extracted from random walks in many different environments (upper row), colouring each location by its co-ordinates in the environment, so that points with the same colour are different locations which occupy the same position in the 3x3 grid (see examples in lower row). Results are shown for GPT-2 medium in c and our model in d. e) The Pearson correlation between Manhattan distance in the environment and Euclidean distance in each layer of our model (red) and GPT-2 medium (blue). f) The Pearson correlation between Manhattan distance in the environment and Euclidean distance in L12 for differing context lengths, for our model (red) and GPT-2 medium (blue).</p></caption><graphic xlink:href="EMS199914-f007"/></fig><fig id="F8" position="float"><label>Figure 8</label><caption><p>Parts a-e show the task design, adapted from <xref ref-type="bibr" rid="R104">Vikbladh et al. (2024)</xref> with permission: a) Training takes place on day one, with tests of reward and transition revaluation on days one and seven. b) The stimuli are nine items arranged in a clockwise ‘loop’. c) The task is to decide whether to accept or reject a trial given a start item and reward and stop conditions, based on the expected rewards obtained from the sequence. d) The participant sees only a single reward and stop condition per start item during training, and revaluation tests performance when the reward and/or stop conditions change. e) Model-based planning (left) and the successor representation approach (right) allow different kinds of revaluation for the trial shown in d. f) Accuracy of accept vs. reject choices over the course of training on a particular trial, for three types of problem. In each case the model pre-trained on the rules of the task was further trained on just nine unique sequences for 8 epochs. The mean across five trials is taken. Errors bars give the SEM. g) Heatmaps showing regression coefficients, capturing which ‘strategy’ best explains the results over the course of training. The network’s decisions after simulating ‘consolidation’ of the nine sequences are compared to the decisions if each of four strategies were used. Linear regression is used to predict the observed accept / reject decisions, with accept / reject decisions given each strategy as the regressors (i.e. multiple regression is run). h) Planning behaviour over time, adapted from <xref ref-type="bibr" rid="R104">Vikbladh et al. (2024)</xref> with permission. Left: Regression coefficients were obtained for model-based (MB), reward revaluation only (RR), and model-free strategies. Participants were split into two groups - sequential planners (SPs) and non-sequential planners (nSPs) - based on their beta value for the model-based strategy. SPs become more model-based with consolidation. Right: planning depth is correlated with reaction time for SPs.</p></caption><graphic xlink:href="EMS199914-f008"/></fig><fig id="F9" position="float"><label>Figure 9</label><caption><title>Retrieval-augmented generation (RAG; <xref ref-type="bibr" rid="R57">Lewis et al., 2020</xref>) applied to inference and planning tasks.</title><p>a) The procedure for the simulations. First sequences are encoded in the hippocampus, then (before consolidation of these memories) a new task is encountered. With the RAG approach, relevant sequences are first retrieved from the hippocampus, and then provided as input to the generative network together with the new task. Specifically, in the spatial and family tree inference tasks the system encodes 100 walks from 100 different graphs (with a simplified structure, and each missing a single edge). Each encoded walk visits three nodes and two edges. The task is then for the system to infer the missing edge, e.g. predict the next location after ‘ab NORTH’ or ‘cd SIBLING_OF’ as shown, prior to any consolidation of the new graph. The models trained in <xref ref-type="sec" rid="S9">Section 3.2.2</xref> are used. To model planning <italic>prior</italic> to consolidation in the <xref ref-type="bibr" rid="R104">Vikbladh et al. (2024)</xref> task, the system encodes the nine task stimuli. When given a new task requiring revaluation, the RAG approach retrieves the most relevant sequence (the one with the same start state), and then uses this to condition the generative network. The model in <xref ref-type="sec" rid="S10">Section 3.2.3</xref> (following pre-training on the task, but before training on the actual stimuli) is used. b) Inference accuracy for the spatial and family tree inference tasks with RAG, and a ‘HPC only’ and ‘NC only’ baseline for comparison. The ‘HPC only’ baseline randomly selects one of the locations / people in the retrieved sequence. The ‘NC only’ baseline conditions the generative network on the task alone, without retrieving sequences from the hippocampus. c) Accuracy of the accept vs. reject decisions in the planning task with RAG, and a ‘HPC only’ and ‘NC only’ baseline for comparison. The ‘HPC only’ baseline retrieves the most similar sequence from the hippocampus and predicts the corresponding accept / reject decision. The ‘NC only’ baseline conditions the generative network on the task alone, without retrieving sequences from the hippocampus.</p></caption><graphic xlink:href="EMS199914-f009"/></fig><fig id="F10" position="float"><label>Figure 10</label><caption><title>A model of hippocampal-neocortical interactions as retrieval-augmented generation with stories.</title><p>a) The neocortex generates a gist vector for the narrative, which is encoded in the hippocampus together with unpredictable details. b) Given a query as the input to recall, the neocortex searches the hippocampus for relevant traces, e.g. by finding gist vectors in this simulation. c) The generative network in neocortex produces an ‘answer’ conditioned on the retrieved hippocampal trace(s). d) The stages of encoding and recall are shown for an example story from the ROC Stories dataset (<xref ref-type="bibr" rid="R73">Mostafazadeh et al., 2016</xref>), with Mistral-7B-Instruct-v0.2 used to simulate the neocortex, and xRAG vectors (<xref ref-type="bibr" rid="R24">Cheng et al., 2024</xref>) representing the conceptual gist. e) The size of the memory trace stored in the model hippocampus (in tokens) and recall accuracy (cosine similarity between original and recalled stories’ embeddings with ‘all-MiniLM-L6-v2’; <xref ref-type="bibr" rid="R89">Reimers and Gurevych, 2019</xref>) for five variants. From left to right: simply imagining the event, storing only the gist vector, storing the gist vector with one surprising detail, storing the gist vector with five surprising details, and storing the event in full. f) When the gist plus details representation is consolidated into the model neocortex (here, Mistral-7B-Instruct-v0.2), the loss of the encoded story steadily decreases, but the loss of the original story increases after an initial drop. Here the loss is a measure of aggregated prediction error (which can be thought of as ‘surprise’).</p></caption><graphic xlink:href="EMS199914-f010"/></fig><table-wrap id="T1" orientation="portrait" position="float"><label>Table 1</label><caption><title>Summary of models trained.</title><p>See <xref ref-type="sec" rid="S2">Section 2</xref> for further details of the training methods and model sizes, and <xref ref-type="sec" rid="S2">Section 3</xref> for further details of the tasks and training data.</p></caption><table frame="box" rules="groups"><thead><tr><th valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">Simulation</th><th valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">Section</th><th valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">Training method</th><th valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">Model</th><th valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid">Training data</th></tr></thead><tbody><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">Gist-based distortions</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid"><xref ref-type="sec" rid="S4">3.1</xref></td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">Further training</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">GPT-2 medium</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">English language text from <xref ref-type="bibr" rid="R12">Bartlett (1932</xref>) and Wikipedia (<xref ref-type="bibr" rid="R114">Ziadé, 2024</xref>)</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">Event extension and contraction</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid"><xref ref-type="sec" rid="S6">3.1.2</xref></td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">Further training</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">GPT-2 medium</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">English language text from ROC Stories dataset (<xref ref-type="bibr" rid="R73">Mostafazadeh et al., 2016</xref>)</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">Statistical learning</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid"><xref ref-type="sec" rid="S8">3.2.1</xref></td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">From scratch</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">GPT-2 medium</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">Sequences of tones from <xref ref-type="bibr" rid="R32">Durrant et al. (2011</xref>) represented by ‘2,2,3,1,…’</td></tr><tr><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">Structural inference (spatial)</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid"><xref ref-type="sec" rid="S9">3.2.2</xref></td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">From scratch</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">GPT-2 medium</td><td valign="top" align="left" style="border:solid 1px #000000">Walks on a graph of form ‘mv SOUTH sz WEST li EAST sz …’</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Structural inference (family trees)</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid"><xref ref-type="sec" rid="S9">3.2.2</xref></td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">From scratch</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">GPT-2 medium</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">Walks on a graph of form ‘yu GRANDPARENT_OF mi SIBLING_OF vb …’</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">Model-based planning</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid"><xref ref-type="sec" rid="S10">3.2.3</xref></td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">Further training</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">GPT-2 medium</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">Tasks from <xref ref-type="bibr" rid="R104">Vikbladh et al. (2024</xref>) represented by ‘START: yellow vehicle, STOP: green, REWARD: animal, SEQUENCE: red animal (2), green vehicle (-1)’</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">Encoding gists</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid"><xref ref-type="sec" rid="S13">3.3.2</xref></td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">N/A (used pre-trained model)</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Mistral-7B-Instruct-v0.2 plus xRAG weights</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid">N/A (used pre-trained model)</td></tr><tr><td valign="top" align="left" style="border:solid 1px #000000">Consolidating gists</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid"><xref ref-type="sec" rid="S13">3.3.2</xref></td><td valign="top" align="left" style="border:solid 1px #000000">Further training</td><td valign="top" align="left" style="border:solid 1px #000000">Mistral-7B-<break/>Instruct-v0.2</td><td valign="top" align="left" style="border:solid 1px #000000">ROC Stories dataset<break/>(<xref ref-type="bibr" rid="R73">Mostafazadeh et al., 2016</xref>)</td></tr></tbody></table></table-wrap><table-wrap id="T2" orientation="portrait" position="float"><label>Table 2</label><caption><p>Recalled stories for different temperatures, for a model trained for five epochs with the ‘Sports’ category of Wikipedia data (<xref ref-type="bibr" rid="R114">Ziadé, 2024</xref>) as the background data distribution, and prompted with ‘One night two young men from Egulac’.</p></caption><table frame="box" rules="groups"><thead><tr><th valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Type</th><th valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">Recalled story example</th></tr></thead><tbody><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">Original</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">One night two young men from Egulac went down to the river to hunt seals and while they were there it became foggy and calm. Then they heard war-cries, and they thought: “Maybe this is a war-party”. They escaped to the shore, and hid behind a log. Now canoes came up, and they heard the noise of paddles, and saw one canoe coming up to them. There were five men in the canoe, and they said: …</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">Temperature of 0</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">One night two young men from Egulac went down to the river to hunt seals and while they were there it became foggy and calm. Then they heard war-cries, and they thought: “Maybe this is a war-party”. They escaped to the shore, and hid behind a log. Now the war-party started, and they heard the noise of paddles, and saw one canoe coming up to them. There were five men in the canoe, and they said: …</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">Temperature of 0.5</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">One night two young men from Egulac went out to the river to hunt seals and while they were there they were robbed by the men from Egulac. The men ran back to Egulac and hid behind a log. When they came out they discovered a canoe coming up to them and they jumped up and began to fight. The canoe came down to the ground and they began to wrestle. The men said they had been robbed by the thieves. …</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid">Temperature of 1</td><td valign="top" align="left" style="border: 1px solid #000000">One night two young men from Egulac went up to the river and they saw a canoe coming up to them. It was full speed, and they could not believe their luck when they saw it coming up the river. They jumped on the canoe and started to paddle, but the canoe was not there. And they could not feel their feet on the canoe; they thought they were sinking. When they reached the shore, they saw one canoe …</td></tr></tbody></table></table-wrap><table-wrap id="T3" orientation="portrait" position="float"><label>Table 3</label><caption><p>Extracts from recalled stories for different categories, showing how semantic intrusions reflect the ‘priors’ of the generative network. Examples are selected from a range of temperatures.</p></caption><table frame="box" rules="groups"><thead><tr><th valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Category</th><th valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">Recalled story extract</th></tr></thead><tbody><tr><td valign="middle" align="left" rowspan="2" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>Nature</bold></td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">The young man went… up the river to the summit of the glen to make a fire</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">When the sun rose high above the scrub and moorland, …</td></tr><tr><td valign="middle" align="left" rowspan="2" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>Politics</bold></td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">they had been active in the local militia</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">He was … convicted for violating the law</td></tr><tr><td valign="middle" align="left" rowspan="2" style="border-top: 1px solid #000000;border-left: 1px solid"><bold>Health</bold></td><td valign="top" align="left" style="border:solid 1px #000000">one of their companions, a young man from the neighbouring town, fell seriously ill</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">“We will not go along until you are strong enough to fight”</td></tr><tr><td valign="middle" align="left" rowspan="2" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>Universe</bold></td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">the sun rose up in the east, and the clouds became tinged with the yellow of dawn</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">A large, ferocious cataclysmic storm came out of the water and many were killed</td></tr><tr><td valign="middle" align="left" rowspan="2" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>Sport</bold></td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">But one of the warriors [gave] him a lesson in hand-to-hand fighting</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">[They] had been training for this event for weeks</td></tr><tr><td valign="middle" align="left" rowspan="2" style="border:solid 1px #000000"><bold>Technology</bold></td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">young men from Egulac went to a bar in San Francisco, California</td></tr><tr><td valign="top" align="left" style="border: 1px solid #000000">[He] went on to become one of the chief hunters of the seals that year.</td></tr></tbody></table></table-wrap><table-wrap id="T4" orientation="portrait" position="float"><label>Table 4</label><caption><title>Event extension and contraction examples.</title><p>The selected incomplete and updated stories (which are of the same length) display extension and omission errors respectively. The model is prompted with the first ten words of each story.</p></caption><table frame="box" rules="groups"><thead><tr><th valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Type</th><th valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Original</th><th valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">Recalled</th></tr></thead><tbody><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid"><bold>Typical</bold></td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">Stephen wanted a cardigan for his birthday. Sally bought one for him. She wrapped it up. She wrote a note. She gave it to him! The end.</td><td valign="top" align="left" style="border:solid 1px #000000">Stephen wanted a cardigan for his birthday. Sally bought one for him. She wrapped it up. She wrote a note. She gave it to him! The end.</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid"><bold>Incomplete</bold></td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">Floyd was enjoying a summer day of inspecting cicada shells. He found many of them and hung them on his shirt like decorations. He squatted at a large tree’s roots when he spotted a really nice one. When he picked it up, t The end.</td><td valign="top" align="left" style="border:solid 1px #000000">Floyd was enjoying a summer day of inspecting cicada shells. He found many of them and hung them on his shirt like decorations. He squatted at a large tree’s roots when he spotted a really nice one. He plucked it out and hung it on his shirt like a necklace. The end.</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid"><bold>Updated</bold></td><td valign="top" align="left" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid #000000">Kris lost her job. She was sad at first. She looked for a new job. She got an interview. Kris got a new job! Jack had always wanted his own dinosaur. He asked Santa Claus for one every year. He never would get one and beca The end.</td><td valign="top" align="left" style="border: 1px solid">Kris lost her job. She was sad at first. She looked for a new job. She got a new job! Now she makes a decent amount of money. The end.</td></tr></tbody></table></table-wrap><table-wrap id="T5" orientation="portrait" position="float"><label>Table 5</label><caption><title>Narrative examples of retrieval-augmented generation with compression as a model of hippocampal-neocortical interaction, using Mistral-7B-Instruct-v0.2 plus xRAG weights to simulate neocortex.</title><p>The ‘Original’ column gives the story ‘experienced’ by the system. The ‘Gist only’ column gives the reconstruction from just the xRAG vector, i.e. when the xRAG vector is retrieved from the hippocampus and used to condition the generative network. The ‘Stored detail’ column lists the most surprising detail given the xRAG vector. Specifically, all phrases are extracted from the text, then the perplexity of each phrase given the xRAG vector is calculated. In other words, for each phrase, the model is prompted with the xRAG vector and the phrase in question. Then the phrases are ranked in descending order of perplexity, with the top phrase used as the ‘Stored detail’. The text embedding (from which the xRAG vector is derived) and details for each memory are encoded together in the model hippocampus. The ‘Gist + detail’ column gives the reconstruction of the memory from this representation.</p></caption><table frame="box" rules="groups"><thead><tr><th valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Original</th><th valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Gist only</th><th valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Stored detail</th><th valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">Gist + detail</th></tr></thead><tbody><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">Sarah has a bad habit. All Sarah eats is candy and sweets. She starts to notice a sharp pain in her teeth. The dentist tells her she has 6 cavities! Sarah decides she needs to start eating healthier.</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Sarah has a bad habit of only eating candy and not eating healthy foods. This is a problem because she is not getting the nutrients she needs to stay healthy. Her dentist told her that she has cavities and needs to start eating more fruits and vegetables …</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">The dentist tells her<break/>she has 6 cavities.</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">Sarah has a bad habit of eating only candy. The dentist tells her she has 6 cavities. Sarah’s bad habit of eating only candy has led to her having 6 cavities. The dentist told her this when she went for a check-up. Sarah needs to change her eating habits …</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Stan and his best friend have been friends for 8 years. They met when Stan was in first grade. They play games together, ate together, and watched movies together. Their favorite time of day is when Stan gets home from school. Stan’s best friend is always waiting for him with a wagging tail.</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Stan and his best friend have been friends for 8 years. They met in kindergarten and have been inseparable ever since. They do everything together, from playing in the park to watching movies at home. They even have a special handshake they use to greet each other. Stan’s friend is always there for him, no matter what. …</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">Stan’s best friend is always waiting for him with a wagging tail.</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">Stan and his best friend have been friends for 8 years. They met when Stan was walking home from school and his friend was wagging his tail and barking at him. Stan approached the dog and petted him, and they have been friends ever since. They spend a lot of time together, playing, going for walks, and just hanging out. …</td></tr><tr><td valign="top" align="left" style="border:solid 1px #000000">Gina prepared food for the family. She cooked lasagna, grilled chicken and garlic bread. As soon as we started to eat, her mom became nauseous. Afterwards, everyone started to feel queasy. They eventually threw away the food and ordered Chinese food.</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid">Gina prepared food for the family. She cooked lasagna. However, she got sick and threw up. The family ate the lasagna, but they all got sick and threw up. They went to the hospital and were diagnosed with food poisoning. The food was later found to be contaminated with <italic>E. coli.</italic></td><td valign="top" align="left" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid">Her mom became nauseous.</td><td valign="top" align="left" style="border: 1px solid">Gina prepared food for the family. She cooked lasagna. However, her mom became nauseous and threw up after eating it. Gina then realized that she had used spoiled ground beef for the lasagna. The rest of the family also became sick after eating it.</td></tr></tbody></table></table-wrap></floats-group></article>