<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS200159</article-id><article-id pub-id-type="doi">10.1101/2024.11.15.623853</article-id><article-id pub-id-type="archive">PPR940858</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">1</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Neural correlates of unconscious and conscious visual processing</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Menétrey</surname><given-names>Maëlan Q.</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Herzog</surname><given-names>Michael H.</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Pascucci</surname><given-names>David</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref></contrib></contrib-group><aff id="A1"><label>1</label>Laboratory of Psychophysics, Brain Mind Institute, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/02s376052</institution-id><institution>École Polytechnique Fédérale de Lausanne (EPFL)</institution></institution-wrap>, <city>Lausanne</city>, <country country="CH">Switzerland</country></aff><aff id="A2"><label>2</label>Psychophysics and Neural Dynamics Lab, Department of Radiology, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/05a353079</institution-id><institution>Lausanne University Hospital (CHUV)</institution></institution-wrap> and <institution-wrap><institution-id institution-id-type="ror">https://ror.org/019whta54</institution-id><institution>University of Lausanne (UNIL)</institution></institution-wrap>, <city>Lausanne</city>, <country country="CH">Switzerland</country></aff><aff id="A3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01eas9a07</institution-id><institution>The Sense Innovation and Research Center</institution></institution-wrap>, <city>Lausanne</city>, <country country="CH">Switzerland</country></aff><author-notes><corresp id="CR1">Corresponding author: <email>maelan.menetrey@gmail.com</email></corresp></author-notes><pub-date pub-type="nihms-submitted"><day>18</day><month>11</month><year>2024</year></pub-date><pub-date pub-type="preprint"><day>17</day><month>11</month><year>2024</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Postdictive effects, where later events influence the perception of earlier ones, suggest that conscious perception is not a continuous stream but occurs at discrete moments, preceded by extended periods of unconscious processing. This is evident in the Sequential Metacontrast Paradigm (SQM), where a stream of lines and vernier offsets is unconsciously integrated over several hundred milliseconds before conscious perception emerges: regardless of whether one or multiple verniers are shown, only a single offset is perceived from the first to the last line. Postdictive phenomena offer a unique opportunity to study the neural correlates of unconscious and conscious stages of perception because unconscious and conscious processing are well separated in time. Using EEG recordings during the SQM, we identified two distinct stages of neural activity. Early occipital EEG activity patterns (~200 ms after the initial vernier presentation) capture unconscious processing, while later centro-parietal EEG patterns (~400- 600 ms after the onset of the stimulus stream) are associated with conscious perception, aligning closely with behavioral reports. We propose that the transition between these distinct neural topographies reflects the discrete moments when conscious perception emerges.</p></abstract><kwd-group><kwd>consciousness</kwd><kwd>unconscious processing</kwd><kwd>two-stage model</kwd><kwd>neural correlates</kwd><kwd>EEG</kwd></kwd-group></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">Consciousness feels like a continuous stream; we see the world at each moment of time. However, several visual phenomena challenge this idea. For instance, in the color phi illusion, two dots of different colors are flashed at separate locations with a brief delay (<xref ref-type="bibr" rid="R26">Kolers &amp; Von Grünau, 1976</xref>). Rather than perceiving two distinct flashes, we perceive a single moving dot that changes color midway. This color change can only be perceived after the second dot is presented, implying that later events influence how we perceive earlier ones. Postdictive effects, like the color phi illusion, suggest that conscious perception is not continuous but is preceded by a period of unconscious processing: consciousness is temporally discrete (<xref ref-type="bibr" rid="R23">Herzog et al., 2016</xref>, <xref ref-type="bibr" rid="R22">2020</xref>). The discrete nature of consciousness provides a unique opportunity to study the neural correlates of both conscious and unconscious processing, as well as the transitions between the two, using high-temporal resolution imaging techniques like electroencephalography (EEG).</p><p id="P3">A prime tool for studying these processes is the Sequential Metacontrast (SQM) paradigm (<xref ref-type="fig" rid="F1">Figures 1A and 1B</xref>). In this paradigm, a sequence of vertical lines is presented, creating the illusion of two diverging motion streams expanding from a central point (<xref ref-type="bibr" rid="R38">Otto et al., 2009</xref>, <xref ref-type="bibr" rid="R39">2010</xref>). When one of the lines contains a horizontal vernier offset, all the other lines are perceived as having the same offset, even though they are actually straight. Observers can easily report the vernier offset (left vs. right) but cannot identify which specific line carries the offset (<xref ref-type="bibr" rid="R37">Otto, 2006</xref>). When the stream contains two vernier stimuli with opposite offsets, the offsets <italic>mandatorily</italic> integrate, and only one integrated offset is perceived in the entire sequence —it is impossible to report the individual offsets separately (<xref ref-type="bibr" rid="R16">Drissi-Daoudi et al., 2019</xref>). The mandatory integration period spans approximately 330-450 ms, depending on the observer and the condition (<xref ref-type="bibr" rid="R55">Vogelsang et al., 2023</xref>). When two offsets are separated by longer intervals, observers can distinguish and report the individual offsets separately (<xref ref-type="bibr" rid="R16">Drissi-Daoudi et al., 2019</xref>; <xref ref-type="bibr" rid="R55">Vogelsang et al., 2023</xref>). Thus, the brain integrates events within a relatively long-lasting window of unconscious processing, followed by a discrete conscious percept. Then, the next window starts, encompassing a new unconscious period that leads to a discrete conscious percept. The existence of such long-lasting integration windows has been demonstrated not only in visual perception (<xref ref-type="bibr" rid="R47">Scharnowski et al., 2009</xref>; <xref ref-type="bibr" rid="R34">Mudrik et al., 2011</xref>; <xref ref-type="bibr" rid="R31">Marti &amp; Dehaene, 2017</xref>; <xref ref-type="bibr" rid="R48">Sergent, 2018</xref>), but also in auditory perception (<xref ref-type="bibr" rid="R32">McWalter &amp; McDermott, 2019</xref>) and across different sensory modalities (<xref ref-type="bibr" rid="R18">Fiebelkorn et al., 2010</xref>; <xref ref-type="bibr" rid="R51">Stiles et al., 2018</xref>; <xref ref-type="bibr" rid="R44">Rimsky-Robert et al., 2019</xref>).</p><p id="P4">In this study, we used EEG decoding to investigate the neural mechanisms involved in both the unconscious processing of vernier offsets and the subsequent emergence of conscious perception, with the following rationale. In the SQM, independently of the exact temporal location or number of verniers in the stream, all offsets are accurately but unconsciously integrated. Only a single, integrated offset is consciously perceived. Consequently, neural activity patterns that can differentiate the position or number of offsets are attributed to unconscious mechanisms. In contrast, conscious perception emerges after unconscious processing and should reflect the integrated offset. To investigate this, we calibrated vernier offset sizes so that, in some trials where a vernier was presented alone in the stream, participants failed to consciously perceive the offset (incorrect trials), while in others, they correctly perceived it (correct trials). Thus, neural activity patterns that can distinguish between correct and incorrect trials within the same condition are likely associated with the conscious perception of the vernier.</p></sec><sec id="S2" sec-type="results"><title>Results</title><sec id="S3"><title>Unconscious feature integration within the SQM stream</title><p id="P5">Participants consistently integrated the vernier offsets with all the lines in the stream, regardless of how many offsets were present, i.e., individual elements in the SQM stream could not be perceived separately (<xref ref-type="fig" rid="F1">Figure 1A</xref>; <xref ref-type="bibr" rid="R16">Drissi-Daoudi et al., 2019</xref>; <xref ref-type="bibr" rid="R55">Vogelsang et al., 2023</xref>). For example, in the conditions with only a single vernier (V conditions), the offset was perceived as extending across the entire sequence of lines (<xref ref-type="bibr" rid="R37">Otto, 2006</xref>; <xref ref-type="bibr" rid="R39">Otto et al., 2010</xref>; <xref ref-type="fig" rid="F1">Figure 1B</xref>), and offset discrimination performance was significantly above 50%. This effect was consistent regardless of where the offset appeared in the stream. When the offset occurred in the first central line or in the second or fourth flanking lines, the mean accuracy remained high (70% ± 7%). Paired t-tests comparing each of these V conditions with a no-vernier (NV) control condition resulted all in significant differences (all <italic>p</italic> &lt; .001, Cohen’s <italic>d’</italic> &gt; 3.3; <xref ref-type="fig" rid="F1">Figure 1D</xref>, left panel).</p><p id="P6">In contrast, when two opposite vernier offsets (a vernier and an anti-vernier) were included in the stream (V-AV condition, <xref ref-type="fig" rid="F1">Figure 1C</xref>), the offsets were mandatorily integrated. Mean accuracy in reporting the first offset was 47% ± 9%, comparable to the NV condition (paired t-tests between the V-AV and NV conditions: all <italic>p</italic> &gt; .05; <xref ref-type="fig" rid="F1">Figure 1D</xref>, right panel). Thus, conscious perception does not depend on the position and number of offsets in the stream, as there is no conscious access to individual elements.</p></sec><sec id="S4"><title>Neural representations preserve the chronology of events in the SQM stream</title><p id="P7">Even though conscious perception in the SQM results from the integration of all elements, we hypothesized that underlying neural activity patterns might still carry information about individual elements and their temporal sequence. To test this hypothesis, we applied Linear Discriminant Analysis (LDA) to decode the presence of vernier offsets and their temporal positions in the stream from EEG activity patterns.</p><p id="P8">We ran separate LDA classifiers to discriminate between trials with no offset (NV condition) and trials with a single vernier offset presented at different temporal positions in the stream (V0: 0 ms, V2: 100 ms, V4: 200 ms, <xref ref-type="fig" rid="F1">Figure 1C</xref>). The classifiers successfully discriminated the presence of a vernier offset in all V conditions (Area Under the Curve, AUC &gt; 0.5, cluster-based permutation test, <italic>p</italic> &lt; .05; <xref ref-type="fig" rid="F2">Figures 2A and 2B</xref>). Crucially, the decoding results revealed systematic delays that corresponded to the actual position of the vernier offset in the stream—decoding was successful at 240 ms for V0 vs. NV, at 330 ms for V2 vs. NV, and at 370 ms for V4 vs. NV (<xref ref-type="fig" rid="F2">Figure 2B</xref>). Hence, the presence of an offset was decoded approximately 200 ms (170-240 ms) after the vernier’s physical onset, despite participants perceiving the offset as present along the entire stream from the beginning (e.g., starting at 0 ms). This result was further supported by a temporal generalization analysis, in which we trained the classifier on data from each time point and tested it across all other time points (see Methods). This analysis revealed similar patterns across conditions, with decoders generalizing only over short time windows, as indicated by higher decoder performance when both training and testing occurred at the same time points (i.e., the diagonal elements of the temporal generalization matrices), and decoding latencies shifted depending on the vernier offset location (<xref ref-type="fig" rid="F2">Figure 2A</xref>).</p><p id="P9">We then applied cross-condition decoding, training a classifier on discriminating V2 vs. NV or V4 vs. NV and testing it on V0 vs. NV. This revealed shared neural representations of the single vernier across conditions, but shifted along the diagonal in the cross-condition temporal generalization matrix (<xref ref-type="fig" rid="F2">Figure 2C</xref>). Specifically, a decoder trained to detect the vernier in the V2 or V4 condition successfully decoded it in V0 (AUC &gt; 0.5, cluster-based permutation test, <italic>p</italic> &lt; .05), but with earlier onsets of approximately 100 and 200 ms, respectively. This delay decreased over time, with neural representations of the vernier offset in V0 gradually aligning with the temporal dynamics of V2 or V4 at longer latencies (e.g., after ~600 ms).</p><p id="P10">Decoding the single vernier versus no vernier conditions was significant in windows ranging from 240 to 710 ms in V0 vs. NV, 330 to 750 ms in V2 vs. NV, and 370 to 840 ms in V4 vs. NV). In these time windows, we found two distinct EEG activation patterns—i.e., topographies of EEG activity associated with the decoder results (see Methods and <xref ref-type="fig" rid="F3">Figure 3A</xref>). The first topography displayed stronger activation over occipital electrodes, with increasing duration as the vernier offset occurred later in the stream (<xref ref-type="fig" rid="F3">Figure 3B</xref>). The second topography, which showed increased activation over parietal electrode sites, had a shorter duration when the vernier offset occurred later (<xref ref-type="fig" rid="F3">Figure 3B</xref>). The time course of these topographies, estimated by back-projecting activation patterns onto the original EEG time series, revealed a clear transition between the two patterns, with evident temporal shifts across conditions (i.e., the transition occurred around 360 ms in V0 vs. NV, 460 ms in V2 vs. NV, and 570 ms in V4 vs. NV; <xref ref-type="fig" rid="F3">Figure 3C</xref>).</p></sec><sec id="S5"><title>Neural correlates of unconscious processing</title><p id="P11">Up to this point, we have focused on conditions featuring a single vernier, where the vernier is consciously perceived throughout the entire stream. Even though the location of the vernier was not consciously perceived, it could still be decoded via two distinct EEG topographies. Next, we explored conditions involving two opposite vernier offsets, separated by varying intervals (V0-AV2: 50 ms, V0-AV4: 150 ms; <xref ref-type="fig" rid="F1">Figure 1C</xref>), using LDA to distinguish these conditions from a condition featuring only straight lines (NV).</p><p id="P12">In the V-AV conditions, behavioral performance was around 50%, indicating mandatory integration of the two opposite offsets (<xref ref-type="fig" rid="F1">Figure 1D</xref>). If the two topographies found when decoding the V conditions from the NV condition reflected only the neural correlates of conscious perception, then we would expect no significant decoding for V-AV trials compared to NV trials. However, if one or both topographies are associated with unconscious processing, i.e., before the offsets integrate, we would expect significant decoding.</p><p id="P13">Consistent with the latter hypothesis, the decoder successfully discriminated V0-AV2 and V0-AV4 trials from NV trials (AUC &gt; 0.5, cluster-based permutation test, <italic>p</italic> &lt; .05; <xref ref-type="fig" rid="F4">Figure 4A</xref>). The significant decoding window (170-1000 ms) exhibited the same sequence of EEG activation patterns (<xref ref-type="fig" rid="F4">Figure 4B</xref>) as observed in the V0 vs. NV decoding analysis. The significant decoding onset, topographies, and transition dynamics around 370 ms (<xref ref-type="fig" rid="F4">Figures 4A, 4C, and 4D</xref>) also closely mirrored those found in V0 vs. NV conditions (<xref ref-type="fig" rid="F3">Figures 3B and 3C</xref> for comparison). Thus, EEG activation patterns distinguished the presence of two offsets from no offsets, even though the individual offsets were not consciously perceived.</p><p id="P14">Importantly, we also found that the two V-AV conditions, where the second offset occurred at different times (V0-AV2 vs. V0-AV4), could be decoded from V0 trials, where only a single vernier was shown and consciously perceived (AUC &gt; 0.5, cluster-based permutation test, <italic>p</italic> &lt; .05; <xref ref-type="fig" rid="F4">Figure 4A</xref>). This indicates that neural representations of the second vernier offset were detectable from EEG patterns, even though this second offset was not consciously perceived. The decoding windows (from 300 ms for V0-AV2 vs. V0, and from 340 ms for V0-AV4 vs. V0) were compatible with the latencies observed in single vernier decoding, supporting the idea that neural representations of the second vernier were present.</p><p id="P15">Moreover, the two V-AV conditions, despite yielding identical conscious percepts, were reliably discriminated from each other (AUC &gt; 0.5, cluster-based permutation test, <italic>p</italic> &lt; .05; <xref ref-type="fig" rid="F4">Figure 4A</xref>). That is, EEG activation patterns contained information about the temporal order of the second vernier, which was completely inaccessible to conscious report but decodable starting from 420 ms. Together, these results demonstrate the involvement of one EEG topography (<xref ref-type="fig" rid="F4">Figure 4C</xref>), highly similar to the first occipital topography identified when decoding conditions with one or two offsets from trials without any offset (<xref ref-type="fig" rid="F3">Figures 3B</xref> and <xref ref-type="fig" rid="F4">4C</xref>).</p><p id="P16">Based on these findings, we interpret the first topography as the neural correlate of unconscious processing of the vernier stimuli, occurring before the emergence of a conscious percept. Conversely, the presence of the second topography with a centro-parietal pattern when discriminating V-AV from NV trials (<xref ref-type="fig" rid="F4">Figure 4C</xref>) suggests a second stage in which the integrated percept becomes available to consciousness. As previously suggested (<xref ref-type="bibr" rid="R33">Menétrey et al., 2023</xref>), one of the two vernier offsets might dominate the integrated percept in the V-AV condition. Thus, despite chance-level performance, percepts in the V-AV conditions differ from those in the NV condition (i.e., a straight line moving from the center to the periphery). The latencies and sequence of topographies when decoding two opposite verniers from none, which are similar to those observed in the single vernier condition (<xref ref-type="fig" rid="F3">Figure 3B</xref>), support this non-uniform integration in V-AV, likely leading to the conscious perception of a smaller integrated vernier in the stream (see also <xref ref-type="supplementary-material" rid="SD1">Supplementary Figure 1</xref> for additional cross-condition generalization evidence between V and V-AV conditions).</p></sec><sec id="S6"><title>Neural correlates of conscious perception</title><p id="P17">To directly assess the involvement of the second topography in conscious perception, we applied LDA to decode correct versus incorrect reports of the offset direction in the condition featuring only a single vernier (V conditions). As shown in <xref ref-type="fig" rid="F5">Figure 5</xref>, the classifiers successfully decoded behavioral performance in all single-vernier conditions (<xref ref-type="fig" rid="F5">Figure 5A</xref>; AUC &gt; 0.5, cluster-based permutation test, <italic>p</italic> &lt; .05). However, significant decoding emerged at later latencies —480 ms for V0, 460 ms for V2, and 570 ms for V4—compared to the earlier latencies observed when decoding V or V-AV against the no-vernier (NV) condition.</p><p id="P18">The decoding of the correctly reported direction was characterized by the contribution of a single EEG activation pattern, which perfectly aligned with the second topography identified in previous analyses (<xref ref-type="fig" rid="F3">Figures 3B</xref> and <xref ref-type="fig" rid="F4">4C</xref>). This finding suggests that the later centro-parietal topography represents the neural correlate of the emergence of a consciously integrated percept, one that becomes available for report. The delayed decoding of correct versus incorrect responses, compared to the earlier decoding of vernier presence, indicates that this second topography is specifically linked to conscious awareness of the vernier offset, rather than its initial unconscious processing.</p></sec></sec><sec id="S7" sec-type="discussion"><title>Discussion</title><p id="P19">Conscious perception is preceded by a period of unconscious processing (<xref ref-type="bibr" rid="R23">Herzog et al., 2016</xref>, <xref ref-type="bibr" rid="R22">2020</xref>). This is evident in the SQM, where a sequence of lines and offsets is mandatorily and unconsciously integrated for up to 450 milliseconds before a conscious percept emerges (<xref ref-type="bibr" rid="R16">Drissi-Daoudi et al., 2019</xref>; <xref ref-type="bibr" rid="R55">Vogelsang et al., 2023</xref>). Here, we used time-resolved decoding analysis to investigate the EEG correlates of both unconscious and conscious processing within the SQM paradigm.</p><p id="P20">Conscious perception does not depend on the specific temporal location of the offsets in the stream, still, our findings show that unconscious neural representations retain the exact chronological order of vernier offset presentations, delayed by approximately 200 ms (<xref ref-type="fig" rid="F2">Figure 2</xref>). This suggests that the brain retains detailed timing information about the offsets, even though this information remains inaccessible to conscious awareness, and contrasts with the unified conscious experience of a single moving offset. This conclusion is further supported by the fact that the temporal onset of individual verniers remained decodable in conditions with two opposite verniers, where the offsets mandatorily integrate and cannot be consciously perceived as separate (<xref ref-type="fig" rid="F4">Figure 4</xref>). Thus, even when individual vernier offsets cannot be consciously perceived, their presence can still be inferred from EEG.</p><p id="P21">These decoding results were driven by early post-stimulus EEG activity, predominantly involving occipital signals (<xref ref-type="fig" rid="F3">Figure 3</xref>). The corresponding EEG topography is consistent with findings from previous studies on the unconscious accumulation and integration of visual information (<xref ref-type="bibr" rid="R17">Fahrenfort et al., 2017</xref>; <xref ref-type="bibr" rid="R33">Menétrey et al., 2023</xref>) and aligns with the N170/VAN ERP component, which is associated with preconscious processes that engage attention for conscious perception (<xref ref-type="bibr" rid="R25">Koivisto &amp; Revonsuo, 2010</xref>; <xref ref-type="bibr" rid="R20">Harris et al., 2013</xref>; <xref ref-type="bibr" rid="R8">Cohen et al., 2023</xref>). Interestingly, this topography was also observed when discriminating between conditions that resulted in a similar integrated conscious percept (i.e., a vernier offset moving along the entire stream) but involving different sequences of unconsciously processed events (i.e., one or two verniers; see <xref ref-type="fig" rid="F4">Figure 4</xref>). Since these conditions differ in the location or even the number of physical offsets, this suggests that the early occipital topography reflects differences in the sequence of unconsciously processed events, supporting its role as a neural correlate of unconscious processing.</p><p id="P22">Following this early occipital activity, we found a second, more centro-parietal topography. This topography contributed to the decoding of conditions where one or more vernier offset were compared against the condition with no offset, but was not observed when discriminating between one and two offsets. This suggests that this later topography is involved in the conscious perception of the vernier offset, whether it results from a single offset or the integration of two, compared to straight lines. In line with this, the same centro-parietal topography emerged after 460 ms and lasted several hundred milliseconds when decoding correct versus incorrect behavioral reports of the offset in conditions with a single vernier (see <xref ref-type="fig" rid="F5">Figure 5</xref>). This late topography resembles the P300 ERP component, often linked to conscious access (<xref ref-type="bibr" rid="R49">Sergent et al., 2005</xref>; <xref ref-type="bibr" rid="R43">Polich, 2007</xref>; <xref ref-type="bibr" rid="R46">Rutiku et al., 2015</xref>; <xref ref-type="bibr" rid="R50">Silverstein et al., 2015</xref>), and is thought to signal the availability of information for conscious report (<xref ref-type="bibr" rid="R4">Baars, 2002</xref>). Since this centro-parietal topography only appeared when decoding the conscious perception of a single offset and correct reports, we interpret it as the neural correlate of conscious perception. Supporting this interpretation, similar topographies obtained through EEG decoding have also been associated with consciousness in attentional blink and masking paradigms (<xref ref-type="bibr" rid="R56">Weaver et al., 2019</xref>; <xref ref-type="bibr" rid="R36">Noorman et al., 2024</xref>). Alternatively, the second topography may not directly reflect the emergence of conscious perception, but rather cognitive processes associated with it, such as decision-making. However, its later occurrence and its relationship with correct reports suggest that, by the time this topography appears, the final percept of the entire sequence—resulting from the integration of unconsciously processed events—is available.</p><p id="P23">Our findings support a two-stage model of perception, in which a prolonged period of unconscious processing precedes a discrete conscious percept (<xref ref-type="bibr" rid="R23">Herzog et al., 2016</xref>, <xref ref-type="bibr" rid="R22">2020</xref>). During the first stage, information is processed with high precision, preserving the temporal order and spatial details of events. In this phase, representations of each vernier offset are stored in a high-capacity buffer, where they interact unconsciously (<xref ref-type="bibr" rid="R40">Pang &amp; Elntib, 2021</xref>, <xref ref-type="bibr" rid="R41">2023</xref>). At the end of this unconscious processing window, the buffered information is collapsed into a conscious percept, reflecting the integrated structure of the entire event.</p><p id="P24">We show that these two stages involve distinct EEG topographies and underlying brain dynamics, with transitions closely aligning with the duration of unconscious processing windows previously reported from behavioral data (e.g., between 330 and 450 ms; <xref ref-type="bibr" rid="R16">Drissi-Daoudi et al., 2019</xref>; <xref ref-type="bibr" rid="R55">Vogelsang et al., 2023</xref>). Importantly, the duration of each stage and their transition dynamics are not fixed but depend on the timing of the first offset in the SQM stream. This was most evident when decoding a single vernier against no vernier (<xref ref-type="fig" rid="F3">Figure 3</xref>). The first topography lasted slightly longer when the offset was presented later in the stream, while the second topography exhibited a temporal compression, shortening as the offset occurred later (see <xref ref-type="fig" rid="F3">Figure 3A</xref>). It is possible that the occurrence of a vernier offset contributes to the beginning of an unconscious processing window, while the end of the SQM stream may accelerate the collapsing of the sequence into a unified conscious percept. Indeed, offsets presented closer to the end of the entire stream (conditions V2, V4) might have accelerated the transition from unconscious to conscious processing. Although the nature of this stimulus-dependent temporal dynamic remains to be fully understood, these results suggest that the temporal structure of neural processing stages is flexible and influenced by subtle details of the stimulus sequence, in contrast to standard ERP analyses that often treat the latencies of processing stages as fixed.</p><p id="P25">Our results address the important question of when consciousness emerges. Most theories, with the exception of the global neuronal workspace theory (<xref ref-type="bibr" rid="R12">Dehaene et al., 2006</xref>; <xref ref-type="bibr" rid="R11">Dehaene &amp; Changeux, 2011</xref>), do not clearly disentangle unconscious from conscious processing stages (for reviews, see <xref ref-type="bibr" rid="R3">Aru et al., 2012</xref>; <xref ref-type="bibr" rid="R52">Storm et al., 2017</xref>). In this respect, the two-stage nature of conscious perception —unconscious processing followed by a discrete percept— and the underlying neural mechanisms may provide strong constraints for these theories, leading to testable predictions. In particular, our results are of quantitative nature and thus allow precise testing of theories.</p><p id="P26">In sum, consciousness is not a continuous flow but is determined by transitions from extended periods of unconscious processing to moments of conscious perception. We demonstrate that during unconscious processing, the brain retains detailed temporal information about external stimuli, which is then integrated into a unified conscious percept where such temporal detail is no longer accessible. This transition between different functional brain states holds critical implications for future research aimed at characterizing the neural correlates of consciousness.</p></sec><sec id="S8" sec-type="methods"><title>Methods</title><sec id="S9" sec-type="subjects"><title>Participants</title><p id="P27">A total of 18 naive, healthy participants (9 females; age range: 18-23 years old) were recruited for the experiment. Participants had normal or corrected to normal vision, as assessed through the Freiburg acuity test (threshold for inclusion: &gt;1; <xref ref-type="bibr" rid="R5">Bach, 1996</xref>). All participants signed informed consent before the experiment and received monetary compensation upon its completion. The experiment was conducted in accordance with the local ethics commission and complied with the Declaration of Helsinki (except for pre-registration).</p></sec><sec id="S10"><title>Apparatus</title><p id="P28">The stimuli were presented on an ASUS VG248QE LCD monitor with a resolution of 1920 x 1080 pixels, a screen size of 24.5 inches, and a refresh rate of 144 Hz. MATLAB R2022b (MathWorks Inc., Natick, MA, USA) along with Psychtoolbox (<xref ref-type="bibr" rid="R7">Brainard, 1997</xref>) was used to generate the stimuli. During the experiment, participants were seated at a distance of 1.5 meters from the screen in a dimly lit room. The stimuli appeared as white with a luminance of 100 cd/m<sup>2</sup>, displayed against a uniform black background with a luminance of 1 cd/m<sup>2</sup></p></sec><sec id="S11"><title>Stimuli and experimental procedure</title><p id="P29">We used the sequential metacontrast paradigm (SQM), introduced in <xref ref-type="bibr" rid="R37">Otto et al. (2006)</xref>, which creates the perception of two motion streams diverging from the center (<xref ref-type="fig" rid="F1">Figures 1A and 1B</xref>). The sequence always began with the presentation of a central vertical line, comprising an upper and a lower segment (the length of each segment is 26.6 arcmin, with a width of 1.2 arcmin) separated by a small vertical gap (2.5 arcmin). Next, pairs of flanking lines appeared progressively further away from the center (horizontal separation between each line is 5 arcmin). The central line and all subsequent pairs of lines were presented for 27.8 ms each, with an interstimulus interval (ISI) of 20.8 ms separating each presentation. The entire stimulus sequence consisted of one central and 5 flanking lines, lasting a total duration of 270.8 ms (<xref ref-type="fig" rid="F1">Figure 1A</xref>).</p><p id="P30">Participants were instructed to always covertly attend to the right stream. In a randomized order, 6 different conditions were presented (<xref ref-type="fig" rid="F1">Figure 1C</xref>): In the <italic>no vernier</italic> control condition (NV), all lines were straight. In three experimental conditions, one line of the attended stream was offset, with the lower segment shifted either towards the right or the left relative to the upper segment (referred to as a <italic>vernier offset</italic> or V). In these conditions, the vernier offset was presented either in the 1<sup>st</sup> central line (V0 condition), in the 2<sup>nd</sup> flanker line (V2 condition; 100 ms after stimulus onset) or in the 4<sup>th</sup> flanker line (V4 condition; 200 ms after stimulus onset). In the two last conditions, the central line always had a vernier offset, while another line in the right stream was offset in the opposite direction (referred to as an <italic>anti-vernier</italic> or AV). In these conditions, the opposite vernier was presented either in the 2<sup>nd</sup> flanker line (V0-AV2 condition) or in the 4<sup>th</sup> flanker line (V0-AV4 condition).</p><p id="P31">In all conditions, participants were asked to indicate whether they perceived a left or right offset along the stream (<xref ref-type="fig" rid="F1">Figure 1B</xref>), even when no vernier was presented (usually observers perceive the offset at the last line, even though the line was always straight). Observers were informed that one or two verniers could be presented in the stream and were instructed to report the 1<sup>st</sup> one in case they perceived both.</p><p id="P32">Participants completed a total of 12 blocks, with each block consisting of 96 trials (192 trials per condition). Before each trial, a central fixation point was presented for 250 ms, followed by an inter-stimulus interval of 750 ms. After the SQM presentation, participants had 3 seconds to give their response by clicking one of two hand-held buttons. If no response was made within this time, the trial was discarded and repeated at the end of the block. In order to eliminate potential early responses that occurred before the complete presentation of the stimulus sequence, we also excluded trials with reaction times below 300 ms after SQM onset. The inter-trial interval was set at 1 second.</p></sec><sec id="S12"><title>Offset calibration</title><p id="P33">Before the experiment proper, the offset sizes (i.e., the horizontal displacement between their upper and lower segments) were determined to achieve comparable performance levels across participants. Streams of straight lines with one single vernier were presented, and a parameter estimation by sequential testing (PEST) procedure (<xref ref-type="bibr" rid="R54">Taylor &amp; Creelman, 1967</xref>) was used to adaptively determine offset sizes leading to around 70% to 80% performance. This was performed with a vernier offset separately at the three different positions tested in the main experiment: the central line (V0), the 2<sup>nd</sup> flanker line (V2), or the 4<sup>th</sup> flanker line (V4).</p></sec><sec id="S13"><title>Behavioral analysis</title><p id="P34">Performance was determined as the proportion of responses that matched the direction of the 1<sup>st</sup> presented vernier offset (<xref ref-type="fig" rid="F1">Figure 1D</xref>). We compared performance between the NV condition and each V or V-AV conditions by means of paired t-tests. The NV condition served as a baseline condition; in this condition performance was determined by comparing the response (left or right reported offset) to a randomly chosen notional offset (mean accuracy was 49% ± 4%). All statistical comparisons were Bonferroni-Holm corrected for multiple comparisons (bonf_holm()). When the vernier is presented without an anti-vernier, vernier discrimination should be approximately 75%, in line with the calibration performance. Conversely, when an anti-vernier follows the central vernier, the central vernier discrimination should be around 50%, given the integration of the two verniers. Additionally, we anticipated no performance differences related to the specific locations of the verniers and anti-verniers, as they fell within the same integration window (<xref ref-type="bibr" rid="R16">Drissi-Daoudi et al., 2019</xref>). Behavioral performance aligned with this expectation (see Results section).</p><p id="P35">Across the six tested conditions, average reaction times ranged from 885 ms to 920 ms, with no statistically significant difference between conditions (one-way ANOVA, F(5, 102) = 0.08, <italic>p</italic> = .99).</p></sec><sec id="S14"><title>EEG recordings and preprocessing</title><p id="P36">The EEG data were recorded using a Biosemi Active Two system (Biosemi, Amsterdam, the Netherlands) with a total of 128 Ag–AgCl active electrodes, providing comprehensive scalp coverage. The positioning of the cap was adjusted individually to ensure the Cz electrode was equidistant from the inion and nasion, as well as equidistant from each ear. In addition, the electrooculogram (EOG) was recorded with 4 electrodes positioned 1 cm above and below the right eye and 1 cm lateral to the outer canthi. The recording was referenced to the CMS-DRL ground, maintaining the montage potential close to amplifier zero through a feedback loop. The sampling rate during recording was set at 2048 Hz.</p><p id="P37">For EEG preprocessing, EEGLAB was utilized (version v2021.1; <xref ref-type="bibr" rid="R14">Delorme et al.,2011</xref>; <xref ref-type="bibr" rid="R13">Delorme &amp; Makeig, 2004</xref>). The EEG data were first downsampled to 250 Hz. To remove linear trends, detrending was applied (de Cheveigné &amp; Arzounian, 2018), followed by a lowpass filter with a cutoff frequency of 40 Hz. The EEG data were then epoched from -1 s to 1.5 s relative to the onset of the SQM. To ensure data quality, a visual inspection was conducted to identify and exclude epochs (pre-selected with <italic>pop_jointprob</italic> function) or channels with significant noise or artifacts. Then, an ICA decomposition (<italic>pop_runica</italic> function with Picard algorithm; <xref ref-type="bibr" rid="R1">Ablin et al., 2017a</xref>, <xref ref-type="bibr" rid="R2">2017b</xref>) was performed, with a temporary interpolation of the removed channels to maintain a consistent 128-channel configuration across all participants. The ICA decomposition also included “fake” vertical and horizontal EOG recordings, computed from the 4 EOG channels (differences between the channels located above and below the right eye, and between the channels located on the lateral side of each eye). The visually identified independent components associated with eye or muscular artifacts (pre-selected with <italic>pop_icflag</italic> function) were subsequently removed. Lastly, a final interpolation of the removed channels was conducted, along with an average reference including only the EEG channels.</p><p id="P38">In total, 6.8% of the electrodes were interpolated, while 3.2% of the epochs and 9.1% of the independent components were removed during the preprocessing procedure.</p></sec><sec id="S15"><title>EEG analysis</title><p id="P39">We aimed to investigate whether brain activity reflects unconscious or conscious processing by decoding differences in EEG dynamics in two configurations of the SQM: 1) when only a single vernier is presented at different locations within the stream (V conditions), with all these conditions resulting in the same percept (i.e., one perceived vernier); and 2) when two opposing verniers are presented (V-AV conditions), yet there is no conscious access to the individual offsets as they integrate.</p></sec><sec id="S16"><title>EEG decoding</title><p id="P40">Linear discriminant analysis (LDA) with temporal or cross-condition generalization was used to investigate neural representations related to different SQM conditions or percepts. We implemented LDA with custom-made functions written in MATLAB, based on the recommended settings for EEG data (<xref ref-type="bibr" rid="R53">Subasi &amp; Ismail Gursoy, 2010</xref>; <xref ref-type="bibr" rid="R19">Grootswagers et al., 2017</xref>). For each participant, LDA with temporal generalization was conducted with a leave-one-pseudo-trial-out cross-validation routine (500 iterations). In each iteration, 80% of the trials were sampled and combined into pseudo-trials (average of 20 trials) for the two classes, i.e., the SQM conditions, that were decoded. The mean of the training set was removed to both testing and training sets, and classifier weights were estimated using a regularized covariance (<xref ref-type="bibr" rid="R29">Ledoit &amp; Wolf, 2004</xref>; <xref ref-type="bibr" rid="R21">Haufe et al., 2014</xref>; <xref ref-type="bibr" rid="R24">Kayser et al., 2016</xref>). The classifier weights, obtained from the training set for each time point, were applied to predict the classes in the EEG data of the testing set. Performance was evaluated using the area under the curve (AUC). This process was repeated for each time point (cross-temporal decoding, i.e., each classifier is tested on all time points), ranging from -200 to 1000 ms, with a sliding window of 7 samples corresponding to a resolution of 70 ms (<xref ref-type="bibr" rid="R19">Grootswagers et al., 2017</xref>). LDA with cross-condition generalization was performed similarly and with identical parameters, except that the classes used in the training sets differed from those used in the testing sets. For all decoding analyses, EEG data were resampled at 100Hz and z-scored.</p><p id="P41">We started by examining V conditions, where the presentation of a single vernier in the stream results in a clear perception of an offset. We used LDA with temporal generalization to discriminate between trials from the control condition (NV) and trials from conditions presenting one single vernier (V0, V2, or V4), irrespective of the behavioral responses (i.e., correct or incorrect report of the vernier offset). The classifiers successfully decoded the presence of information regarding the vernier, indicative of either unconscious or conscious processing (<xref ref-type="fig" rid="F2">Figures 2A and 2B</xref>). We also showed some cross-condition generalization between V conditions. Using classifiers trained with V2 or V4 vs. NV conditions, we decoded V0 vs. NV conditions (<xref ref-type="fig" rid="F2">Figure 2C</xref>).</p><p id="P42">Second, we explored the neural representations in the V-AV conditions, where the two opposite verniers integrate with each other. LDA with temporal generalization was used to classify between trials from the NV condition and all trials presenting two opposite verniers (V0-AV2 and V0-AV4 together), irrespective of the behavioral responses (i.e., correct or incorrect report of the 1<sup>st</sup> vernier offset). If V-AV and NV conditions cannot be discriminated, it might suggest that significant decoding reflects only neural correlates of a clearly visible vernier offset: as the two opposite verniers cancel each other out, only a straight line would be perceived, akin to the NV condition. This does not appear to be the case as the decoder successfully discriminated between these conditions (<xref ref-type="fig" rid="F4">Figure 4A</xref>; see also <xref ref-type="supplementary-material" rid="SD1">Supplementary Figure 1</xref> for a demonstration of cross-condition generalization between V and V-AV conditions). However, we were able to decode between V0 and V0-AV2 or V0-AV4 conditions, as well as between the two V-AV conditions, indicating that unconscious processing also contributes to this significant decoding (<xref ref-type="fig" rid="F4">Figure 4A</xref>).</p><p id="P43">Lastly, we conducted an LDA analysis with temporal generalization to decode between correct and incorrect reports of the offset within each condition presenting one vernier (V0, V2, and V4; <xref ref-type="fig" rid="F5">Figure 5A</xref>). This analysis aimed to specifically identify neural correlates that reflect conscious perception. All parameters remained consistent with those listed above, except for the averaging of trials for pseudo-trials, which was adjusted to 4 due to the reduced number of available trials, especially the incorrect trials (comprising only ~30% of the total for each condition).</p></sec><sec id="S17"><title>Statistical evaluation of decoding analyses</title><p id="P44">For all decoding analyses, either with temporal or cross-condition generalization, the statistical evaluation of the 2D matrices of cross-temporal decoding results (subjects x time x time) employed cluster-based permutation approaches and surrogate analysis, following established methodologies (<xref ref-type="bibr" rid="R35">Nichols &amp; Holmes, 2002</xref>; <xref ref-type="bibr" rid="R30">Maris &amp; Oostenveld, 2007</xref>; <xref ref-type="bibr" rid="R24">Kayser et al., 2016</xref>). Clusters were defined as consecutive time points where the decoding successfully exceeded chance levels (chance = 0.5, paired t-test with α = 0.05). The cumulative t-values within each cluster were then compared to the maximum sum derived from surrogate clusters (permutations = 10’000). Time points were considered statistically significant if the probability in the surrogate data was &lt;0.05 for the corresponding clusters.</p></sec><sec id="S18"><title>EEG activation patterns</title><p id="P45">We estimated activation patterns from the LDA classifiers by projecting the EEG data onto the decoder weights and normalizing the result by the dot product of the weights (<xref ref-type="bibr" rid="R21">Haufe et al., 2014</xref>; <xref ref-type="bibr" rid="R19">Grootswagers et al., 2017</xref>; <xref ref-type="bibr" rid="R42">Park &amp; Kayser, 2019</xref>). We assessed the temporal dynamics of the activation patterns in the context of each decoding analysis (V0, V2, or V4 vs. NV, <xref ref-type="fig" rid="F3">Figure 3A</xref>; V0-AV2/V0-AV4 vs. NV, V0-AV2/V0-AV4 vs. V0, V0-AV2 vs. V0-AV4, <xref ref-type="fig" rid="F4">Figure 4A</xref>; correct vs. incorrect reports in V0, V2, and V4, <xref ref-type="fig" rid="F5">Figure 5A</xref>). For each subject, we extracted the activation patterns over the significant time points. We then computed dissimilarity matrices between these activation patterns using the following procedure. First, we averaged the activation maps across subjects and standardized the average maps (z-scored). Next, we computed a map dissimilarity index at each time point by estimating the dissimilarity between the map at that time point and the maps at all other time points within the significant window. Dissimilarity was quantified using Euclidean distance, defined as the square root of the sum of squared differences between the corresponding z-scored activation maps. This process was repeated across all time points to generate a time-by-time dissimilarity matrix. To identify stable patterns—highly similar and persistent maps across time points—we employed a generalization of the Louvain community detection algorithm (<xref ref-type="bibr" rid="R6">Blondel et al., 2008</xref>; <xref ref-type="bibr" rid="R45">Rubinov &amp; Sporns, 2010</xref>). This approach was applied to an adjacency matrix derived from the dissimilarity results, with edges defined as pairs of time points where the dissimilarity between two maps was less than the median value of the entire matrix. In this context, the Louvain community detection algorithm was used to detect clusters of time points within a graph representation of the dissimilarity matrices, where EEG maps exhibited similar activation patterns (<xref ref-type="fig" rid="F3">Figures 3A</xref> and <xref ref-type="fig" rid="F4">4B</xref>).</p><p id="P46">Topographies of the main activation patterns were then generated by averaging over temporal windows corresponding to the identified clusters (<xref ref-type="fig" rid="F3">Figures 3B</xref> and <xref ref-type="fig" rid="F4">4C</xref>), or over the entire significant decoding window if no cluster was found (<xref ref-type="fig" rid="F4">Figures 4C</xref> and <xref ref-type="fig" rid="F5">5B</xref>). Finally, when two different topographies were found, we correlated the spatial patterns of the topographies and the temporal dynamics of EEG activation patterns (back-projected time courses) to assess their temporal relationship and their contributions to the overall temporal dynamics (<xref ref-type="fig" rid="F3">Figures 3C</xref> and <xref ref-type="fig" rid="F4">4D</xref>).</p></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary Material</label><media xlink:href="EMS200159-supplement-Supplementary_Material.pdf" mimetype="application" mime-subtype="pdf" id="d65aAcEbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S19"><title>Acknowledgments</title><p>This work was supported by the Swiss National Science Foundation (grant number 325130_204898; grant numbers PZ00P1_179988 and PZ00P1_179988/2; and grant number TMSGI1_218247).</p></ack><sec id="S20" sec-type="data-availability"><title>Data and Code Availability</title><p id="P47">The data supporting the findings of this study are available on the Open Science Framework (<ext-link ext-link-type="uri" xlink:href="https://osf.io/d83vs/">https://osf.io/d83vs/</ext-link>)</p></sec><fn-group><fn id="FN1" fn-type="conflict"><p id="P48"><bold>Conflict of interest</bold></p><p id="P49">The authors declare no competing financial interests.</p></fn><fn id="FN2" fn-type="con"><p id="P50"><bold>Authors contribution statements</bold></p><p id="P51">M.Q.M, M.H.H. and D.P. conceived the study; M.Q.M collected the data; M.Q.M and D.P. analyzed the data; M.Q.M, M.H.H. and D.P. interpreted the results; M.Q.M, M.H.H., and D.P. wrote the manuscript.</p></fn></fn-group><ref-list><ref id="R1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ablin</surname><given-names>P</given-names></name><name><surname>Cardoso</surname><given-names>J-F</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name></person-group><article-title>Faster ICA under orthogonal constraint</article-title><year>2017a</year><pub-id pub-id-type="doi">10.48550/ARXIV.1711.10873</pub-id></element-citation></ref><ref id="R2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ablin</surname><given-names>P</given-names></name><name><surname>Cardoso</surname><given-names>J-F</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name></person-group><article-title>Faster independent component analysis by preconditioning with Hessian approximations</article-title><year>2017b</year><pub-id pub-id-type="doi">10.48550/ARXIV.1706.08171</pub-id></element-citation></ref><ref id="R3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aru</surname><given-names>J</given-names></name><name><surname>Bachmann</surname><given-names>T</given-names></name><name><surname>Singer</surname><given-names>W</given-names></name><name><surname>Melloni</surname><given-names>L</given-names></name></person-group><article-title>Distilling the neural correlates of consciousness</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><year>2012</year><volume>36</volume><issue>2</issue><fpage>737</fpage><lpage>746</lpage><pub-id pub-id-type="pmid">22192881</pub-id></element-citation></ref><ref id="R4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baars</surname><given-names>BJ</given-names></name></person-group><article-title>The conscious access hypothesis: Origins and recent evidence</article-title><source>Trends in Cognitive Sciences</source><year>2002</year><volume>6</volume><issue>1</issue><fpage>47</fpage><lpage>52</lpage><pub-id pub-id-type="pmid">11849615</pub-id></element-citation></ref><ref id="R5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bach</surname><given-names>M</given-names></name></person-group><article-title>The Freiburg Visual Acuity Test—Automatic Measurement of Visual Acuity: Optometry and Vision Science</article-title><year>1996</year><volume>73</volume><issue>1</issue><fpage>49</fpage><lpage>53</lpage><pub-id pub-id-type="pmid">8867682</pub-id></element-citation></ref><ref id="R6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blondel</surname><given-names>VD</given-names></name><name><surname>Guillaume</surname><given-names>J-L</given-names></name><name><surname>Lambiotte</surname><given-names>R</given-names></name><name><surname>Lefebvre</surname><given-names>E</given-names></name></person-group><article-title>Fast unfolding of communities in large networks</article-title><source>Journal of Statistical Mechanics: Theory and Experiment</source><year>2008</year><volume>2008</volume><issue>10</issue><elocation-id>P10008</elocation-id><pub-id pub-id-type="doi">10.1088/1742-5468/2008/10/P10008</pub-id></element-citation></ref><ref id="R7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname><given-names>DH</given-names></name></person-group><article-title>The Psychophysics Toolbox</article-title><source>Spatial Vision</source><year>1997</year><volume>10</volume><issue>4</issue><fpage>433</fpage><lpage>436</lpage><pub-id pub-id-type="pmid">9176952</pub-id></element-citation></ref><ref id="R8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>MA</given-names></name><name><surname>Keefe</surname><given-names>J</given-names></name><name><surname>Brady</surname><given-names>TF</given-names></name></person-group><article-title>Perceptual Awareness Occurs Along a Graded Continuum: No Evidence of All-or-None Failures in Continuous Reproduction Tasks</article-title><source>Psychological Science</source><year>2023</year><volume>34</volume><issue>9</issue><fpage>1033</fpage><lpage>1047</lpage><pub-id pub-id-type="pmid">37650455</pub-id></element-citation></ref><ref id="R9"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Dainton</surname><given-names>B</given-names></name></person-group><source>Temporal Consciousness</source><year>2023</year><comment><ext-link ext-link-type="uri" xlink:href="https://plato.stanford.edu/archives/spr2023/entries/consciousness-temporal/">https://plato.stanford.edu/archives/spr2023/entries/consciousness-temporal/</ext-link></comment></element-citation></ref><ref id="R10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Cheveigné</surname><given-names>A</given-names></name><name><surname>Arzounian</surname><given-names>D</given-names></name></person-group><article-title>Robust detrending, rereferencing, outlier detection, and inpainting for multichannel data</article-title><source>NeuroImage</source><year>2018</year><volume>172</volume><fpage>903</fpage><lpage>912</lpage><pub-id pub-id-type="pmcid">PMC5915520</pub-id><pub-id pub-id-type="pmid">29448077</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.01.035</pub-id></element-citation></ref><ref id="R11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Changeux</surname><given-names>J-P</given-names></name></person-group><article-title>Experimental and Theoretical Approaches to Conscious Processing</article-title><source>Neuron</source><year>2011</year><volume>70</volume><issue>2</issue><fpage>200</fpage><lpage>227</lpage><pub-id pub-id-type="pmid">21521609</pub-id></element-citation></ref><ref id="R12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Changeux</surname><given-names>J-P</given-names></name><name><surname>Naccache</surname><given-names>L</given-names></name><name><surname>Sackur</surname><given-names>J</given-names></name><name><surname>Sergent</surname><given-names>C</given-names></name></person-group><article-title>Conscious, preconscious, and subliminal processing: A testable taxonomy</article-title><source>Trends in Cognitive Sciences</source><year>2006</year><volume>10</volume><issue>5</issue><fpage>204</fpage><lpage>211</lpage><pub-id pub-id-type="pmid">16603406</pub-id></element-citation></ref><ref id="R13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delorme</surname><given-names>A</given-names></name><name><surname>Makeig</surname><given-names>S</given-names></name></person-group><article-title>EEGLAB: An open source toolbox for analysis of singletrial EEG dynamics including independent component analysis</article-title><source>Journal of Neuroscience Methods</source><year>2004</year><volume>134</volume><issue>1</issue><fpage>9</fpage><lpage>21</lpage><pub-id pub-id-type="pmid">15102499</pub-id></element-citation></ref><ref id="R14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delorme</surname><given-names>A</given-names></name><name><surname>Mullen</surname><given-names>T</given-names></name><name><surname>Kothe</surname><given-names>C</given-names></name><name><surname>Akalin Acar</surname><given-names>Z</given-names></name><name><surname>Bigdely-Shamlo</surname><given-names>N</given-names></name><name><surname>Vankov</surname><given-names>A</given-names></name><name><surname>Makeig</surname><given-names>S</given-names></name></person-group><article-title>EEGLAB, SIFT, NFT, BCILAB, and ERICA: New Tools for Advanced EEG Processing</article-title><source>Computational Intelligence and Neuroscience</source><year>2011</year><volume>2011</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="pmcid">PMC3114412</pub-id><pub-id pub-id-type="pmid">21687590</pub-id><pub-id pub-id-type="doi">10.1155/2011/130714</pub-id></element-citation></ref><ref id="R15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doerig</surname><given-names>A</given-names></name><name><surname>Scharnowski</surname><given-names>F</given-names></name><name><surname>Herzog</surname><given-names>MH</given-names></name></person-group><article-title>Building perception block by block: A response to Fekete <italic>et al</italic></article-title><source>Neuroscience of Consciousness</source><year>2019</year><volume>2019</volume><issue>1</issue><pub-id pub-id-type="pmcid">PMC6349944</pub-id><pub-id pub-id-type="pmid">30723552</pub-id><pub-id pub-id-type="doi">10.1093/nc/niy012</pub-id></element-citation></ref><ref id="R16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drissi-Daoudi</surname><given-names>L</given-names></name><name><surname>Doerig</surname><given-names>A</given-names></name><name><surname>Herzog</surname><given-names>MH</given-names></name></person-group><article-title>Feature integration within discrete time windows</article-title><source>Nature Communications</source><year>2019</year><volume>10</volume><issue>1</issue><elocation-id>4901</elocation-id><pub-id pub-id-type="pmcid">PMC6814726</pub-id><pub-id pub-id-type="pmid">31653844</pub-id><pub-id pub-id-type="doi">10.1038/s41467-019-12919-7</pub-id></element-citation></ref><ref id="R17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fahrenfort</surname><given-names>JJ</given-names></name><name><surname>Van Leeuwen</surname><given-names>J</given-names></name><name><surname>Olivers</surname><given-names>CNL</given-names></name><name><surname>Hogendoorn</surname><given-names>H</given-names></name></person-group><article-title>Perceptual integration without conscious access</article-title><source>Proceedings of the National Academy of Sciences</source><year>2017</year><volume>114</volume><issue>14</issue><fpage>3744</fpage><lpage>3749</lpage><pub-id pub-id-type="pmcid">PMC5389292</pub-id><pub-id pub-id-type="pmid">28325878</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1617268114</pub-id></element-citation></ref><ref id="R18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiebelkorn</surname><given-names>IC</given-names></name><name><surname>Foxe</surname><given-names>JJ</given-names></name><name><surname>Schwartz</surname><given-names>TH</given-names></name><name><surname>Molholm</surname><given-names>S</given-names></name></person-group><article-title>Staying within the lines: The formation of visuospatial boundaries influences multisensory feature integration</article-title><source>European Journal of Neuroscience</source><year>2010</year><volume>31</volume><issue>10</issue><fpage>1737</fpage><lpage>1743</lpage><pub-id pub-id-type="pmid">20584177</pub-id></element-citation></ref><ref id="R19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grootswagers</surname><given-names>T</given-names></name><name><surname>Wardle</surname><given-names>SG</given-names></name><name><surname>Carlson</surname><given-names>TA</given-names></name></person-group><article-title>Decoding Dynamic Brain Patterns from Evoked Responses: A Tutorial on Multivariate Pattern Analysis Applied to Time Series Neuroimaging Data</article-title><source>Journal of Cognitive Neuroscience</source><year>2017</year><volume>29</volume><issue>4</issue><fpage>677</fpage><lpage>697</lpage><pub-id pub-id-type="pmid">27779910</pub-id></element-citation></ref><ref id="R20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>JA</given-names></name><name><surname>McMahon</surname><given-names>AR</given-names></name><name><surname>Woldorff</surname><given-names>MG</given-names></name></person-group><article-title>Disruption of Visual Awareness during the Attentional Blink Is Reflected by Selective Disruption of Late-stage Neural Processing</article-title><source>Journal of Cognitive Neuroscience</source><year>2013</year><volume>25</volume><issue>11</issue><fpage>1863</fpage><lpage>1874</lpage><pub-id pub-id-type="pmcid">PMC4422875</pub-id><pub-id pub-id-type="pmid">23859644</pub-id><pub-id pub-id-type="doi">10.1162/jocn_a_00443</pub-id></element-citation></ref><ref id="R21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haufe</surname><given-names>S</given-names></name><name><surname>Meinecke</surname><given-names>F</given-names></name><name><surname>Görgen</surname><given-names>K</given-names></name><name><surname>Dähne</surname><given-names>S</given-names></name><name><surname>Haynes</surname><given-names>J-D</given-names></name><name><surname>Blankertz</surname><given-names>B</given-names></name><name><surname>Bießmann</surname><given-names>F</given-names></name></person-group><article-title>On the interpretation of weight vectors of linear models in multivariate neuroimaging</article-title><source>NeuroImage</source><year>2014</year><volume>87</volume><fpage>96</fpage><lpage>110</lpage><pub-id pub-id-type="pmid">24239590</pub-id></element-citation></ref><ref id="R22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herzog</surname><given-names>MH</given-names></name><name><surname>Drissi-Daoudi</surname><given-names>L</given-names></name><name><surname>Doerig</surname><given-names>A</given-names></name></person-group><article-title>All in Good Time: Long-Lasting Postdictive Effects Reveal Discrete Perception</article-title><source>Trends in Cognitive Sciences</source><year>2020</year><volume>24</volume><issue>10</issue><fpage>826</fpage><lpage>837</lpage><pub-id pub-id-type="pmid">32893140</pub-id></element-citation></ref><ref id="R23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herzog</surname><given-names>MH</given-names></name><name><surname>Kammer</surname><given-names>T</given-names></name><name><surname>Scharnowski</surname><given-names>F</given-names></name></person-group><article-title>Time Slices: What Is the Duration of a Percept?</article-title><source>PLOS Biology</source><year>2016</year><volume>14</volume><issue>4</issue><elocation-id>e1002433</elocation-id><pub-id pub-id-type="pmcid">PMC4829156</pub-id><pub-id pub-id-type="pmid">27070777</pub-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1002433</pub-id></element-citation></ref><ref id="R24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kayser</surname><given-names>SJ</given-names></name><name><surname>McNair</surname><given-names>SW</given-names></name><name><surname>Kayser</surname><given-names>C</given-names></name></person-group><article-title>Prestimulus influences on auditory perception from sensory representations and decision processes</article-title><source>Proceedings of the National Academy of Sciences</source><year>2016</year><volume>113</volume><issue>17</issue><fpage>4842</fpage><lpage>4847</lpage><pub-id pub-id-type="pmcid">PMC4855557</pub-id><pub-id pub-id-type="pmid">27071110</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1524087113</pub-id></element-citation></ref><ref id="R25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koivisto</surname><given-names>M</given-names></name><name><surname>Revonsuo</surname><given-names>A</given-names></name></person-group><article-title>Event-related brain potential correlates of visual awareness</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><year>2010</year><volume>34</volume><issue>6</issue><fpage>922</fpage><lpage>934</lpage><pub-id pub-id-type="pmid">20005249</pub-id></element-citation></ref><ref id="R26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kolers</surname><given-names>PA</given-names></name><name><surname>Von Grünau</surname><given-names>M</given-names></name></person-group><article-title>Shape and color in apparent motion</article-title><source>Vision Research</source><year>1976</year><volume>16</volume><issue>4</issue><fpage>329</fpage><lpage>335</lpage><pub-id pub-id-type="pmid">941407</pub-id></element-citation></ref><ref id="R27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lamme</surname><given-names>VAF</given-names></name></person-group><article-title>Towards a true neural stance on consciousness</article-title><source>Trends in Cognitive Sciences</source><year>2006</year><volume>10</volume><issue>11</issue><fpage>494</fpage><lpage>501</lpage><pub-id pub-id-type="pmid">16997611</pub-id></element-citation></ref><ref id="R28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lamme</surname><given-names>VAF</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name></person-group><article-title>The distinct modes of vision offered by feedforward and recurrent processing</article-title><source>Trends in Neurosciences</source><year>2000</year><volume>23</volume><issue>11</issue><fpage>571</fpage><lpage>579</lpage><pub-id pub-id-type="pmid">11074267</pub-id></element-citation></ref><ref id="R29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ledoit</surname><given-names>O</given-names></name><name><surname>Wolf</surname><given-names>M</given-names></name></person-group><article-title>A well-conditioned estimator for large-dimensional covariance matrices</article-title><source>Journal of Multivariate Analysis</source><year>2004</year><volume>88</volume><issue>2</issue><fpage>365</fpage><lpage>411</lpage><pub-id pub-id-type="doi">10.1016/S0047-259X(03)00096-4</pub-id></element-citation></ref><ref id="R30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maris</surname><given-names>E</given-names></name><name><surname>Oostenveld</surname><given-names>R</given-names></name></person-group><article-title>Nonparametric statistical testing of EEG- and MEG-data</article-title><source>Journal of Neuroscience Methods</source><year>2007</year><volume>164</volume><issue>1</issue><fpage>177</fpage><lpage>190</lpage><pub-id pub-id-type="pmid">17517438</pub-id></element-citation></ref><ref id="R31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marti</surname><given-names>S</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><article-title>Discrete and continuous mechanisms of temporal selection in rapid visual streams</article-title><source>Nature Communications</source><year>2017</year><volume>8</volume><issue>1</issue><elocation-id>1955</elocation-id><pub-id pub-id-type="pmcid">PMC5717232</pub-id><pub-id pub-id-type="pmid">29208892</pub-id><pub-id pub-id-type="doi">10.1038/s41467-017-02079-x</pub-id></element-citation></ref><ref id="R32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McWalter</surname><given-names>R</given-names></name><name><surname>McDermott</surname><given-names>JH</given-names></name></person-group><article-title>Illusory sound texture reveals multi-second statistical completion in auditory scene analysis</article-title><source>Nature Communications</source><year>2019</year><volume>10</volume><issue>1</issue><elocation-id>5096</elocation-id><pub-id pub-id-type="pmcid">PMC6841952</pub-id><pub-id pub-id-type="pmid">31704913</pub-id><pub-id pub-id-type="doi">10.1038/s41467-019-12893-0</pub-id></element-citation></ref><ref id="R33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Menétrey</surname><given-names>MQ</given-names></name><name><surname>Herzog</surname><given-names>MH</given-names></name><name><surname>Pascucci</surname><given-names>D</given-names></name></person-group><article-title>Pre-stimulus alpha activity modulates long-lasting unconscious feature integration</article-title><source>NeuroImage</source><year>2023</year><volume>278</volume><elocation-id>120298</elocation-id><pub-id pub-id-type="pmid">37517573</pub-id></element-citation></ref><ref id="R34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mudrik</surname><given-names>L</given-names></name><name><surname>Breska</surname><given-names>A</given-names></name><name><surname>Lamy</surname><given-names>D</given-names></name><name><surname>Deouell</surname><given-names>LY</given-names></name></person-group><article-title>Integration Without Awareness: Expanding the Limits of Unconscious Processing</article-title><source>Psychological Science</source><year>2011</year><volume>22</volume><issue>6</issue><fpage>764</fpage><lpage>770</lpage><pub-id pub-id-type="pmid">21555524</pub-id></element-citation></ref><ref id="R35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nichols</surname><given-names>TE</given-names></name><name><surname>Holmes</surname><given-names>AP</given-names></name></person-group><article-title>Nonparametric permutation tests for functional neuroimaging: A primer with examples</article-title><source>Human Brain Mapping</source><year>2002</year><volume>15</volume><issue>1</issue><fpage>1</fpage><lpage>25</lpage><pub-id pub-id-type="pmcid">PMC6871862</pub-id><pub-id pub-id-type="pmid">11747097</pub-id><pub-id pub-id-type="doi">10.1002/hbm.1058</pub-id></element-citation></ref><ref id="R36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Noorman</surname><given-names>S</given-names></name><name><surname>Stein</surname><given-names>T</given-names></name><name><surname>Fahrenfort</surname><given-names>JJ</given-names></name><name><surname>Van Gaal</surname><given-names>S</given-names></name></person-group><article-title>Distinct neural mechanisms underlying perceptual and attentional impairments of conscious access</article-title><year>2024</year><pub-id pub-id-type="doi">10.7554/eLife.97900.1</pub-id></element-citation></ref><ref id="R37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Otto</surname><given-names>TU</given-names></name></person-group><article-title>The flight path of the phoenixVThe visible trace of invisible elements in human vision</article-title><source>Journal of Vision</source><year>2006</year><volume>8</volume><pub-id pub-id-type="pmid">17132079</pub-id></element-citation></ref><ref id="R38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Otto</surname><given-names>TU</given-names></name><name><surname>Ögmen</surname><given-names>H</given-names></name><name><surname>Herzog</surname><given-names>MH</given-names></name></person-group><article-title>Feature integration across space, time, and orientation</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><year>2009</year><volume>35</volume><issue>6</issue><fpage>1670</fpage><lpage>1686</lpage><pub-id pub-id-type="pmcid">PMC3277857</pub-id><pub-id pub-id-type="pmid">19968428</pub-id><pub-id pub-id-type="doi">10.1037/a0015798</pub-id></element-citation></ref><ref id="R39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Otto</surname><given-names>TU</given-names></name><name><surname>Ogmen</surname><given-names>H</given-names></name><name><surname>Herzog</surname><given-names>MH</given-names></name></person-group><article-title>Attention and non-retinotopic feature integration</article-title><source>Journal of Vision</source><year>2010</year><volume>10</volume><issue>12</issue><fpage>8</fpage><pub-id pub-id-type="pmcid">PMC3248829</pub-id><pub-id pub-id-type="pmid">21047740</pub-id><pub-id pub-id-type="doi">10.1167/10.12.8</pub-id></element-citation></ref><ref id="R40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pang</surname><given-names>DKF</given-names></name><name><surname>Elntib</surname><given-names>S</given-names></name></person-group><article-title>Strongly masked content retained in memory made accessible through repetition</article-title><source>Scientific Reports</source><year>2021</year><volume>11</volume><issue>1</issue><elocation-id>10284</elocation-id><pub-id pub-id-type="pmcid">PMC8119432</pub-id><pub-id pub-id-type="pmid">33986370</pub-id><pub-id pub-id-type="doi">10.1038/s41598-021-89512-w</pub-id></element-citation></ref><ref id="R41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pang</surname><given-names>DKF</given-names></name><name><surname>Elntib</surname><given-names>S</given-names></name></person-group><article-title>Further evidence and theoretical framework for a subliminal sensory buffer store (SSBS)</article-title><source>Consciousness and Cognition</source><year>2023</year><volume>107</volume><elocation-id>103452</elocation-id><pub-id pub-id-type="pmid">36508898</pub-id></element-citation></ref><ref id="R42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>H</given-names></name><name><surname>Kayser</surname><given-names>C</given-names></name></person-group><article-title>Shared neural underpinnings of multisensory integration and trial-by-trial perceptual recalibration in humans</article-title><source>eLife</source><year>2019</year><volume>8</volume><elocation-id>e47001</elocation-id><pub-id pub-id-type="pmcid">PMC6660215</pub-id><pub-id pub-id-type="pmid">31246172</pub-id><pub-id pub-id-type="doi">10.7554/eLife.47001</pub-id></element-citation></ref><ref id="R43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Polich</surname><given-names>J</given-names></name></person-group><article-title>Updating P300: An integrative theory of P3a and P3b</article-title><source>Clinical Neurophysiology</source><year>2007</year><volume>118</volume><issue>10</issue><fpage>2128</fpage><lpage>2148</lpage><pub-id pub-id-type="pmcid">PMC2715154</pub-id><pub-id pub-id-type="pmid">17573239</pub-id><pub-id pub-id-type="doi">10.1016/j.clinph.2007.04.019</pub-id></element-citation></ref><ref id="R44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rimsky-Robert</surname><given-names>D</given-names></name><name><surname>Störmer</surname><given-names>V</given-names></name><name><surname>Sackur</surname><given-names>J</given-names></name><name><surname>Sergent</surname><given-names>C</given-names></name></person-group><article-title>Retrospective auditory cues can improve detection of near-threshold visual targets</article-title><source>Scientific Reports</source><year>2019</year><volume>9</volume><issue>1</issue><elocation-id>18966</elocation-id><pub-id pub-id-type="pmcid">PMC6908653</pub-id><pub-id pub-id-type="pmid">31831788</pub-id><pub-id pub-id-type="doi">10.1038/s41598-019-55261-0</pub-id></element-citation></ref><ref id="R45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rubinov</surname><given-names>M</given-names></name><name><surname>Sporns</surname><given-names>O</given-names></name></person-group><article-title>Complex network measures of brain connectivity: Uses and interpretations</article-title><source>NeuroImage</source><year>2010</year><volume>52</volume><issue>3</issue><fpage>1059</fpage><lpage>1069</lpage><pub-id pub-id-type="pmid">19819337</pub-id></element-citation></ref><ref id="R46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rutiku</surname><given-names>R</given-names></name><name><surname>Martin</surname><given-names>M</given-names></name><name><surname>Bachmann</surname><given-names>T</given-names></name><name><surname>Aru</surname><given-names>J</given-names></name></person-group><article-title>Does the P300 reflect conscious perception or its consequences?</article-title><source>Neuroscience</source><year>2015</year><volume>298</volume><fpage>180</fpage><lpage>189</lpage><pub-id pub-id-type="pmid">25907442</pub-id></element-citation></ref><ref id="R47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scharnowski</surname><given-names>F</given-names></name><name><surname>Ruter</surname><given-names>J</given-names></name><name><surname>Jolij</surname><given-names>J</given-names></name><name><surname>Hermens</surname><given-names>F</given-names></name><name><surname>Kammer</surname><given-names>T</given-names></name><name><surname>Herzog</surname><given-names>MH</given-names></name></person-group><article-title>Long-lasting modulation of feature integrationby transcranial magnetic stimulation</article-title><source>Journal of Vision</source><year>2009</year><volume>9</volume><issue>6</issue><fpage>1</fpage><pub-id pub-id-type="pmid">19761292</pub-id></element-citation></ref><ref id="R48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sergent</surname><given-names>C</given-names></name></person-group><article-title>The offline stream of conscious representations</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><year>2018</year><volume>373</volume><issue>1755</issue><elocation-id>20170349</elocation-id><pub-id pub-id-type="pmcid">PMC6074088</pub-id><pub-id pub-id-type="pmid">30061463</pub-id><pub-id pub-id-type="doi">10.1098/rstb.2017.0349</pub-id></element-citation></ref><ref id="R49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sergent</surname><given-names>C</given-names></name><name><surname>Baillet</surname><given-names>S</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><article-title>Timing of the brain events underlying access to consciousness during the attentional blink</article-title><source>Nature Neuroscience</source><year>2005</year><volume>8</volume><issue>10</issue><fpage>1391</fpage><lpage>1400</lpage><pub-id pub-id-type="pmid">16158062</pub-id></element-citation></ref><ref id="R50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silverstein</surname><given-names>BH</given-names></name><name><surname>Snodgrass</surname><given-names>M</given-names></name><name><surname>Shevrin</surname><given-names>H</given-names></name><name><surname>Kushwaha</surname><given-names>R</given-names></name></person-group><article-title>P3b, consciousness, and complex unconscious processing</article-title><source>Cortex</source><year>2015</year><volume>73</volume><fpage>216</fpage><lpage>227</lpage><pub-id pub-id-type="pmid">26474391</pub-id></element-citation></ref><ref id="R51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stiles</surname><given-names>NRB</given-names></name><name><surname>Li</surname><given-names>M</given-names></name><name><surname>Levitan</surname><given-names>CA</given-names></name><name><surname>Kamitani</surname><given-names>Y</given-names></name><name><surname>Shimojo</surname><given-names>S</given-names></name></person-group><article-title>What you saw is what you will hear: Two new illusions with audiovisual postdictive effects</article-title><source>PLOS ONE</source><year>2018</year><volume>13</volume><issue>10</issue><elocation-id>e0204217</elocation-id><pub-id pub-id-type="pmcid">PMC6169875</pub-id><pub-id pub-id-type="pmid">30281629</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0204217</pub-id></element-citation></ref><ref id="R52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Storm</surname><given-names>JF</given-names></name><name><surname>Boly</surname><given-names>M</given-names></name><name><surname>Casali</surname><given-names>AG</given-names></name><name><surname>Massimini</surname><given-names>M</given-names></name><name><surname>Olcese</surname><given-names>U</given-names></name><name><surname>Pennartz</surname><given-names>CMA</given-names></name><name><surname>Wilke</surname><given-names>M</given-names></name></person-group><article-title>Consciousness Regained: Disentangling Mechanisms, Brain Systems, and Behavioral Responses</article-title><source>The Journal of Neuroscience</source><year>2017</year><volume>37</volume><issue>45</issue><fpage>10882</fpage><lpage>10893</lpage><pub-id pub-id-type="pmcid">PMC5678021</pub-id><pub-id pub-id-type="pmid">29118218</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1838-17.2017</pub-id></element-citation></ref><ref id="R53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Subasi</surname><given-names>A</given-names></name><name><surname>Ismail Gursoy</surname><given-names>M</given-names></name></person-group><article-title>EEG signal classification using PCA, ICA, LDA and support vector machines</article-title><source>Expert Systems with Applications</source><year>2010</year><volume>37</volume><issue>12</issue><fpage>8659</fpage><lpage>8666</lpage><pub-id pub-id-type="doi">10.1016/j.eswa.2010.06.065</pub-id></element-citation></ref><ref id="R54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taylor</surname><given-names>MM</given-names></name><name><surname>Creelman</surname><given-names>CD</given-names></name></person-group><article-title>PEST: Efficient Estimates on Probability Functions</article-title><source>The Journal of the Acoustical Society of America</source><year>1967</year><volume>41</volume><issue>4A</issue><fpage>782</fpage><lpage>787</lpage><pub-id pub-id-type="doi">10.1121/L1910407</pub-id></element-citation></ref><ref id="R55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vogelsang</surname><given-names>L</given-names></name><name><surname>Drissi-Daoudi</surname><given-names>L</given-names></name><name><surname>Herzog</surname><given-names>MH</given-names></name></person-group><article-title>Processing load, and not stimulus evidence, determines the duration of unconscious visual feature integration</article-title><source>Communications Psychology</source><year>2023</year><volume>1</volume><issue>1</issue><fpage>8</fpage><pub-id pub-id-type="pmcid">PMC11041769</pub-id><pub-id pub-id-type="pmid">38665247</pub-id><pub-id pub-id-type="doi">10.1038/s44271-023-00011-2</pub-id></element-citation></ref><ref id="R56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weaver</surname><given-names>MD</given-names></name><name><surname>Fahrenfort</surname><given-names>JJ</given-names></name><name><surname>Belopolsky</surname><given-names>A</given-names></name><name><surname>Van Gaal</surname><given-names>S</given-names></name></person-group><article-title>Independent Neural Activity Patterns for Sensory- and Confidence-Based Information Maintenance during Category-Selective Visual Processing</article-title><source>Eneuro</source><year>2019</year><volume>6</volume><issue>1</issue><elocation-id>ENEURO.0268-18.2018</elocation-id><pub-id pub-id-type="pmcid">PMC6397950</pub-id><pub-id pub-id-type="pmid">30834301</pub-id><pub-id pub-id-type="doi">10.1523/ENEURO.0268-18.2018</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><p>A) The Sequential Metacontrast paradigm (SQM). A central line, here with a vernier offset, is followed by pairs of flanking lines eliciting a percept of two diverging streams (B). Observers attend to one stream, in which all offsets are integrated. C) In V conditions, only one vernier is presented, either in the central line (V0), in the 2nd (V2), or in the 4th (V4) flanking line. In V-AV conditions, the central line is offset, and one of the flanking is offset in the opposite direction (anti-vernier; V0-AV2 or V0-AV4). In the control condition (NV), only straight lines are shown. The red and blue offset colors in the figure are for illustration purposes only; in the experiment, all lines were the same color. D) Participants attended to the right stream and were asked to report the perceived offset direction (right/left) of the 1<sup>st</sup> presented vernier offset by pressing hand-held push-buttons. In V conditions, participants could accurately report the offset direction. In V-AV conditions, participants could not perceive the individual vernier offsets, and hence performance is at 50%. This indicates that both vernier offsets contribute equally. When no vernier was presented or perceived, participants were guessing. In NV condition, performance is determined by comparing the response to a randomly chosen offset.</p></caption><graphic xlink:href="EMS200159-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Linear discriminant analysis (LDA) with temporal and cross-condition generalization in V conditions.</title><p>A) Temporal generalization matrices, obtained by training a classifier on data at every time point and testing it at all other time points, showing that classifiers can successfully discriminate between the conditions (V0, V2, and V4 vs. NV). Significant clusters are highlighted (AUC above 0.5, cluster-based permutation test, <italic>p</italic> &lt; .05). B) Diagonal elements of the temporal generalization matrices, representing decoding results when training and testing at the same time point (group average AUC and 95% CI). Significant time windows are highlighted by the horizontal lines at the bottom. Temporal delays in the decoding results, relative to the actual onset of the vernier in the stream, are indicated by the dashed rectangles. C) Cross-condition generalization matrices demonstrate that classifiers trained with V2 or V4 vs. NV successfully discriminate V0 vs NV but with earlier onsets corresponding to the effective stimulus delay between V0 and V2 (i.e., 100 ms later) and V4 (i.e., 200 ms later). Significant clusters are highlighted (AUC above 0.5, cluster-based permutation test, <italic>p</italic> &lt; .05).</p></caption><graphic xlink:href="EMS200159-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>EEG activation patterns contributing to decoding in V conditions.</title><p>A) Analysis of dissimilarity matrices between the EEG activation patterns extracted from significant time points (diagonal elements of the temporal generalization matrices for V0, V2, or V4 vs. NV; see <xref ref-type="fig" rid="F2">Figure 2B</xref>) reveals two main activation patterns (outlined by black squares) for each decoding analysis. B) Topographies, averaged across participants, are derived from the two main activations patterns identified with the analysis of dissimilarity matrices. Each decoding analysis shows similar topographical maps but with variations in their transition dynamics. C) Temporal correlations between the two identified topographies and the back-projected time course of EEG activation patterns for each decoding analysis. Blue and red lines represent the 1<sup>st</sup> and 2<sup>nd</sup> maps, respectively. Shaded areas indicate SEM.</p></caption><graphic xlink:href="EMS200159-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Linear discriminant analysis (LDA) with temporal and cross-condition generalization in V-AV conditions.</title><p>A) Temporal generalization matrices showing that classifiers successfully discriminate the conditions (V0-AV2/V0-AV4 vs. NV, V0-AV2 vs. V0, V0-AV4 vs. V0, and V0-AV2 vs. V0-AV4). Significant clusters are highlighted (AUC above 0.5, cluster-based permutation test, <italic>p</italic> &lt; .05). B) Analysis of dissimilarity matrices between the EEG activation patterns extracted from significant time points (diagonal elements of the temporal generalization matrices; see <xref ref-type="fig" rid="F1">Figure 1A</xref>) reveals two different activation patterns (outlined by black squares) only for V0-AV2/V0-AV4 vs. NV. C) Topographies, averaged across participants, are derived from the two main activation patterns found in V0-AV2/V0-AV4 vs. NV. The topographies for V0-AV2 vs. V0, V0-AV4 vs. V0, and V0-AV2 vs. V0-AV4 are derived from the averaged activation pattern over the entire significant window. D) Temporal correlation between the two identified topographies and the back-projected time course of EEG activation patterns for V0-AV2/V0-AV4 vs. NV. Blue and red lines represent the 1<sup>st</sup> and 2<sup>nd</sup> maps, respectively. Shaded areas indicate SEM.</p></caption><graphic xlink:href="EMS200159-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>Linear discriminant analysis (LDA) with temporal generalization in V conditions (correct vs. incorrect reports).</title><p>A) Temporal generalization matrices showing that classifiers ≈correct from incorrected offset reports in all V conditions (V0, V2 or V4). Significant clusters are highlighted (AUC above 0.5, cluster-based permutation test, <italic>p</italic> &lt; .05). B) The topographies, averaged across participants, are derived from the averaged activation pattern over the entire significant window of each decoding analysis.</p></caption><graphic xlink:href="EMS200159-f005"/></fig></floats-group></article>