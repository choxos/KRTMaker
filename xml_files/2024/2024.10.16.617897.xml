<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS199519</article-id><article-id pub-id-type="doi">10.1101/2024.10.16.617897</article-id><article-id pub-id-type="archive">PPR926343</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">1</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Domain Specific AI Segmentation of IMPDH2 Rod/Ring Structures in Mouse Embryonic Stem Cells</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><name><surname>Ball</surname><given-names>Samuel T.M.</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Hennessy</surname><given-names>Meagan J.</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Tan</surname><given-names>Yuhan</given-names></name><xref ref-type="aff" rid="A2">3</xref></contrib><contrib contrib-type="author"><name><surname>Hoettges</surname><given-names>Kai F.</given-names></name><xref ref-type="aff" rid="A2">3</xref></contrib><contrib contrib-type="author"><name><surname>Perkins</surname><given-names>Neil D.</given-names></name><xref ref-type="aff" rid="A3">4</xref></contrib><contrib contrib-type="author"><name><surname>Wilkinson</surname><given-names>David J.</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>White</surname><given-names>Michael R.H.</given-names></name><xref ref-type="aff" rid="A4">5</xref></contrib><contrib contrib-type="author"><name><surname>Zheng</surname><given-names>Yalin</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Turner</surname><given-names>David A.</given-names></name><xref ref-type="corresp" rid="CR1">*</xref><xref ref-type="aff" rid="A1">1</xref></contrib><aff id="A1"><label>1</label>Institute of Life Course and Medical Sciences, Faculty of Health and Life Sciences, William Henry Duncan Building, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/04xs57h96</institution-id><institution>University of Liverpool</institution></institution-wrap>, <city>Liverpool</city>, <country country="GB">UK</country></aff><aff id="A2"><label>3</label>Department of Electrical and Electronic Engineering, Faculty of Science and Engineering, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/04xs57h96</institution-id><institution>University of Liverpool</institution></institution-wrap>, <city>Liverpool</city>, <country country="GB">UK</country></aff><aff id="A3"><label>4</label>Biosciences Institute, Faculty of Medical Sciences, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/01kj2bm70</institution-id><institution>University of Newcastle</institution></institution-wrap>, <city>Newcastle</city>, <country country="GB">UK</country></aff><aff id="A4"><label>5</label>Faculty of Biology, Medicine and Health, School of Biological Sciences, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/027m9bs27</institution-id><institution>University of Manchester</institution></institution-wrap>; <city>Manchester</city>, <country country="GB">UK</country></aff></contrib-group><author-notes><corresp id="CR1">
<label>*</label>Author for correspondence. <email>david.turner@liverpool.ac.uk</email>
</corresp></author-notes><pub-date pub-type="nihms-submitted"><day>19</day><month>10</month><year>2024</year></pub-date><pub-date pub-type="preprint"><day>17</day><month>10</month><year>2024</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0 International license</ext-link>.</license-p></license></permissions><abstract><sec id="S1"><title>Background</title><p id="P1">Inosine monophosphate dehydrogenase 2 (IMPDH2) is an enzyme that catalyses the rate limiting step of guanine nucleotides. In mouse embryonic stem cells (ESCs) IMPDH2 is held as large multi-protein complexes known as rod-ring (RR) structures that dissociate when ESCs differentiate. Manual analysis of RR structures from confocal microscopy images, although possible, is not feasible on a large scale due to the quantity of RR structures present in each field of view. To address this analysis bottleneck, we have created a fully automatic RR image classification pipeline to segment, characterise and measure feature distributions of these structures in ESCs.</p></sec><sec id="S2"><title>Results</title><p id="P2">We find that this model can automatically segment images with a Dice score of over 80% for both rods and rings for in-domain images compared to expert annotation, with a slight drop to 70% for datasets out of domain. Important feature measurements derived from these segmentations show high agreement with the measurements derived from expert annotation, achieving an <italic>R</italic><sup>2</sup> score of over 90% for counting the number of rings and rods over the dataset.</p></sec><sec id="S3"><title>Conclusions</title><p id="P3">We have established for the first time a quantitative baseline for RR distribution in pluripotent ESCs and have made a pipeline available for training to be applied to other models in which RR remain an open topic of study.</p></sec></abstract><kwd-group><kwd>IMPDH2</kwd><kwd>Loukoumasomes</kwd><kwd>Cytoophidia</kwd><kwd>Nematosomes</kwd><kwd>Rods and Rings</kwd><kwd>AI Segmentation</kwd><kwd>Embryonic Stem Cells</kwd></kwd-group></article-meta></front><body><sec id="S4" sec-type="intro"><title>Background</title><sec id="S5" sec-type="intro"><title>Introduction</title><p id="P4">Multiparameter fluorescence microscopy is a powerful and versatile tool in modern biology, which allows both qualitative and quantitative measurement of biological processes in fixed or live samples [<xref ref-type="bibr" rid="R1">1</xref>]. Despite the rapid expanse in both the availability and technological innovation seen in the field of quantitative microscopy, adequately analysing the data generated from the microscope remains a major bottleneck [<xref ref-type="bibr" rid="R2">2</xref>]. Artificial Intelligence (AI) however, and notably the recent advances in the application of AI based technologies, stands as a useful yet underutilised tool that could address this issue.</p><p id="P5">One potential application for deep learning techniques can be seen in the study of Inosine Monophosphate Dehydrogenase 2 (IMPDH2), the enzyme that catalyses the rate limiting step in the synthesis of guanine nucleotides, and is a critical component of cell homeostasis and metabolism [<xref ref-type="bibr" rid="R3">3</xref>]. IMPDH2 can exist in two major conformational classes depending on the metabolic requirements of the cell. The first is homogeneously distributed throughout the cytoplasm, usually found in in cells with a low metabolic demand (e.g. HeLa, MCF7) [<xref ref-type="bibr" rid="R4">4</xref>]. However, in cells that are rapidly proliferating with a high demand for nucleotides (e.g. HEp-2, mouse embryonic stem cells), IMPDH2 forms large, macromolecular complexes resembling rod or ring (RR) structures (<xref ref-type="fig" rid="F1">Fig. 1</xref>; and [<xref ref-type="bibr" rid="R5">5</xref>, <xref ref-type="bibr" rid="R6">6</xref>]). Interestingly, similar rod-ring structures been identified for other metabolic enzymes such as cytidine triphosphate synthase 1 (CTPS1) [<xref ref-type="bibr" rid="R5">5</xref>, <xref ref-type="bibr" rid="R7">7</xref>], glutamate synthase [<xref ref-type="bibr" rid="R8">8</xref>] and GDP-mannose pyrophosphorylase [<xref ref-type="bibr" rid="R8">8</xref>]. This has led to the suggestion that higher-order molecular confirmations may be important for fine-tuning enzymatic kinetics independent of transcription regulation [<xref ref-type="bibr" rid="R8">8</xref>, <xref ref-type="bibr" rid="R9">9</xref>].</p><p id="P6">Mouse ESCs are a useful model system to study the regulation of these structures, as the IMPDH2 conformation differs depending on their state (<xref ref-type="fig" rid="F1">Fig. 1</xref>; and [<xref ref-type="bibr" rid="R5">5</xref>, <xref ref-type="bibr" rid="R6">6</xref>]). When ESCs are maintained in pluripotent conditions IMPDH2 is mostly in the rod-ring conformation. During differentiation however, these structures break down and IMPDH2 becomes more homogenously cytoplasmic. As these structures have a clear morphology, single instances of rods and rings are relatively straightforward to analyse, and manual quantification similar to our previously published protocols [<xref ref-type="bibr" rid="R10">10</xref>, <xref ref-type="bibr" rid="R11">11</xref>] or simple thresholding using, for example ImageJ/FIJI is possible [<xref ref-type="bibr" rid="R12">12</xref>–<xref ref-type="bibr" rid="R14">14</xref>]. However, within a single field of view there can be dozens to over a hundred rods and rings, rendering manual quantification impractical, especially if one is to analyse enough structures for meaningful statistical analysis.</p></sec><sec id="S6"><title>Software Requirements</title><p id="P7">Due to the number of these structures within each image (<xref ref-type="fig" rid="F1">Fig. 1</xref>) and the impractical nature of current analysis methods, it is clear that any software that could tackle our analysis requirements would need to: <list list-type="order" id="L1"><list-item><p id="P8">Identify rods or rings with a high degree of accuracy, consistently over multiple experimental replicates, conditions, and fluorescence intensities compared with manual identification;</p></list-item><list-item><p id="P9">Be automated, requiring little to no adjustments or corrections;</p></list-item><list-item><p id="P10">Run through datasets at least an order of magnitude quicker than manual analysis;</p></list-item><list-item><p id="P11">Be user-friendly, and able to export the data in a format that can be interrogated by third party graphing/analysis packages.</p></list-item></list></p><p id="P12">We therefore set out to develop a deep learning approach to establish a numerical baseline for IMPDH2 rod and ring distribution in mice. Since these rod-ring structures are present in multiple contexts (e.g. IMPDH2 [<xref ref-type="bibr" rid="R5">5</xref>], CTPS1 cytoophidia [<xref ref-type="bibr" rid="R5">5</xref>, <xref ref-type="bibr" rid="R7">7</xref>], Louk-oumasomes [<xref ref-type="bibr" rid="R15">15</xref>]), the solution we develop is expected be of use to multiple groups for the quantitative analysis of similar cellular structures.</p></sec><sec id="S7"><title>Related work and Background Theory</title><p id="P13">Image segmentation is a commonly investigated computer vision task, with models for object detection via bounding boxes [<xref ref-type="bibr" rid="R16">16</xref>], prompt based segmentation [<xref ref-type="bibr" rid="R17">17</xref>] and semantic segmentation [<xref ref-type="bibr" rid="R18">18</xref>]. The methodology for using these models is typically split into two cases: in the first; pretrained models are used directly on new datasets to detect objects or segment images. In the second, these model architectures are partially, or fully retrained on the new data to achieve greater results.</p><p id="P14">Commonly used applied models such as YOLO [<xref ref-type="bibr" rid="R16">16</xref>] or SegFormer [<xref ref-type="bibr" rid="R18">18</xref>] come with labels for general use (e.g. dog, person, train), but are inappropriate for rod ring segmentation as there is no “rod” or “ring” output in the pretrained model outputs. The large size of these models, combined with the relatively small size of some microscopy imaging datasets typically result in these larger architectures being outperformed by simpler models at a smaller scale [<xref ref-type="bibr" rid="R19">19</xref>]. Other models, such as Segment Anything [<xref ref-type="bibr" rid="R17">17</xref>] or Cellpose [<xref ref-type="bibr" rid="R20">20</xref>] take a label-free approach to segmentation, using user prompting to infer structure in the image. While these models cannot achieve end-to-end segmentation like those above, they are still used to increase the speed of segmentation and annotation for many biomedical imaging tasks.</p><p id="P15">Training bespoke, application specific models allow for specific considerations to be made for the type of data being analysed, such as preprocessing or model design. By training a model on a specific dataset, higher performance is usually achieved compared to generalised models due to a smaller domain space; however, performance out-of-domain (i.e. on data sufficiently dissimilar to the training data) is typically much worse.</p></sec></sec><sec id="S8"><title>Implementation</title><sec id="S9"><title>AI Methods</title><sec id="S10"><title>Training</title><p id="P16">For training the microscopy AI models, we used 5 UNet models [<xref ref-type="bibr" rid="R21">21</xref>] in an ensemble model (<xref ref-type="fig" rid="F2">Fig. 2A</xref>). Each input image is scaled to 512×512 pixels, and the output logits of the UNet models are averaged to give an aggregate logit map of the output. For downstream binary classification tasks, the output was thresholded at a value of 0.2; chosen due to the ensemble model’s propensity to over-classify negative classes (i.e. empty space) in the image. The dataset totalled 287 training images, each with an accompanying annotation mask for rings and rods (<xref ref-type="fig" rid="F2">Fig. 2B</xref>). This was split into 5 disjoint folds, where each model was trained on 4 of these folds and tested on the last one, with each model testing on a different fold. This ensured complete testing coverage of the entire dataset, and repeated training to ensure reliability of the protocol.</p><p id="P17">Training was performed on a system with a NVIDIA GeForce RTX 3090 equipped using the Adam optimizer [<xref ref-type="bibr" rid="R16">16</xref>, <xref ref-type="bibr" rid="R22">22</xref>] with an initial learning rate of 0.001 which decayed exponentially at a rate of 99.9% per epoch. During training, the loss for the training was recorded along with the loss on the testing dataset, although the latter was not used for hyperparameter optimisation to avoid overfitting and preserve integrity of the experiment.</p></sec><sec id="S11"><title>Post-processing</title><p id="P18">After the models were trained, the masks were used to construct polygons for the rings and rods using a simple contour fitting algorithm [<xref ref-type="bibr" rid="R23">23</xref>]. For each image, several measurements were taken which were deemed biologically relevant (e.g. the number of rods/rings, the average perimeter and area of the rod/rings, the ratio of area to perimeter of rods and rings) to study the utility of the model in the biological context.</p></sec><sec id="S12"><title>Testing</title><p id="P19">For testing the models on the original data, the final testing folds for each cross-validation set were predicted and compared against the ground truth binary masks provided by an expert annotator using both the Dice coefficient score and the per-pixel F1 score for pixel classification. In addition to the main dataset, we also tested the model on two further datasets: firstly, a time course dataset recorded with the same microscope as the primary dataset but in the context of an experiment examining the effect of differentiation media (N2B27) on the cell line. Here, the dataset is comprised of 306 images files at 11 different time-points including two control points. In this case, the density of rings and rods quickly diminishes over time <xref ref-type="fig" rid="F3">Fig. 3</xref>. Testing the AI’s performance on this dataset not only tests its ability to segment images out of the training domain, but also serves as a simulation into how this model could be used in practice.</p><p id="P20">The final testing dataset examines the effect of a different microscope on the AI’s performance. In this case, we have 90 images recorded on a different microscope to what was used on the primary dataset. This dataset tests multiple out-of-domain factors including image scaling and different hardware image processing pipelines that are previously unseen in the primary dataset. For this set, two preprocessing pipelines were used for comparison, as the new microscope’s resolution was different to the original. The first, where the objective magnification was kept constant with the primary microscope, and the second, where the image was cropped so the resolution of the cells (i.e. the average pixel width) was kept constant to the original microscope <xref ref-type="fig" rid="F4">Fig. 4</xref>.</p><p id="P21">For the time course and domain shift evaluations, since this data was not previously seen by the model; the ensemble model approach was used on the entire dataset, again recording the per-pixel F1 score and Dice coefficients per image. In both cases, the logit maps were also used to construct receiver operating characteristic (ROC) curves for each image, then averaged over the image set, giving a mean ROC curve along with a standard deviation range. Finally, for each model output, the summary metrics after post-processing were compared with those calculated from the ground truth; to test for overall utility of the model in a biological context. This was achieved by calculating the <italic>R</italic><sup>2</sup> score for each measurement to test for the strength of correlation of the measurements from the ground truth to the model output.</p></sec><sec id="S13"><title>Image Processing Pipeline</title><p id="P22">Images from the Andor Dragonfly Microscope were exported as .ims files, and maximum intensity projections were created (1024 × 1024 pixels) before being converted to .jpgs for rod ring prediction to be made off from the model. For instances in which annotations were required, OpenCV [<xref ref-type="bibr" rid="R24">24</xref>] was used to draw initial contours off single channel maximum projection images. These were then manually cleaned and separated into rod and ring label layers in napari [<xref ref-type="bibr" rid="R25">25</xref>] which were exported as binary masks for training.</p></sec></sec><sec id="S14"><title>Biological Methods</title><sec id="S15"><title>Routine mouse embryonic stem cell culture and differentiation</title><p id="P23">Wild-type E14-Tg2A mESCs were seeded at a density of 1.2×104 cells/cm2 on 0.1% (v/v) gelatin-coated flasks in ESL medium which is comprised of GMEM (Gibco) supplemented with 15% Foetal Bovine Serum (Gibco Cat. No. 10270-106), Non-Essential Amino Acids (Gibco), Sodium Pyruvate (Gibco), Glutamax™ (ThermoFisher, Cat. No. 35050038), β-mercaptoethanol (Gibco, Cat. No. 31350010; final concentration 0.05 mM), and LIF (QKine; QK018) in a humidified incubator maintained at 37°C with 5% CO<sub>2</sub>. Cells were passaged every other day using TrypleE as a dissociation reagent. The culture medium was changed on non-passage days. For differentiation assays, cells were seeded directly in N2B27 [<xref ref-type="bibr" rid="R26">26</xref>, <xref ref-type="bibr" rid="R27">27</xref>] and medium changed each day [<xref ref-type="bibr" rid="R28">28</xref>]. N2B27 was kept at 4°C protected from light and was used within three weeks. Cells were tested monthly and certified negative for mycoplasma.</p></sec><sec id="S16"><title>Immunofluorescence</title><p id="P24">Cells were seeded at a density of 3.0×104 cells/cm2 in 8-chambered Ibidi slides in ESL for 24h [<xref ref-type="bibr" rid="R26">26</xref>, <xref ref-type="bibr" rid="R27">27</xref>]. For samples that were gathered for the differentiation time course experiment, ESL media was exchanged for N2B27 at 24 hours and cells were fixed at the defined intervals. Samples were then processed for immunofluorescence as previously described [<xref ref-type="bibr" rid="R10">10</xref>]. Prior to fixing cells were washed with phosphate buffered saline without Calcium and Magnesium (PBS<sup>-/-</sup>). Single time point experiments were fixed for 30 mint at room temperature with 4% formaldehyde (Thermo Scientific/Pierce). Samples part of the differentiation time course were fixed at the defined intervals with 4% formaldehyde for 10 minutes at 37°C. After fixation, cells washed multiple times (10 min each) with PBS<sup>-/-</sup>-supplemented with 10% FBS and 0.2% Triton X100 (PBSFT), followed by three hour-long washes in PBSFT to block and permeabilise the cells. Cells were then incubated with an antibody raised against IMPDH2 (12948-1-AP, Proteintech) diluted 1:2000 in PBSFT at 4°C over-night. Cells were then rinsed three times with PBSFT and exposed to three lots of one-hour washes in PBSFT before incubation over night with alexa-488 conjugated secondary antibody diluted 1:500 in PBSFT with Hoechst (1:1000) to mark nuclei at 4°C. Cells were then rinsed with PBS supplemented with 0.2% FBS and 0.2% Triton X100 (PBT) three times before three hour-long PBT incubations at room temperature. After the final rinse, cells were mounted in ProLong Antifade (P36980, Thermo Fisher Scientific) and stored at 4°C until imaging.</p></sec><sec id="S17"><title>Confocal Microscopy</title><p id="P25">Fixed and stained cells were primarily imaged on an Andor Dragonfly spinning disc confocal microscope mounted on an inverted Leica DMi8 base using a 40x 1.4 NA oil-immersion objective. Hoechst and Alexa-647 were sequentially excited with 405 and 637nm laser diodes respectively, and emitted light reflected through 450/50 nm and 700/25nm bandpass filters respectively. An iXon 888 EM-CCD camera was used to collect emitted light, and data were captured using Fusion version 5.5 (Bitplane). For microscope comparison tests, samples were imaged on a Zeiss LSM800 Airyscan confocal microscope mounted on an inverted Axio Observer Z1 base using a Plan-Apochromat 63x 1.40NA Oil-immersion objective. Alexa-647 was excited with 640nm laser diode, with emitted light reflected through a variable secondary dichroic beamsplitter set between 656-700nm. Emitted light was directed to a GaAsP photomultiplier tube, and data captured using Zen Blue version 2.6.</p></sec></sec></sec><sec id="S18" sec-type="results"><title>Results</title><sec id="S19"><title>Primary dataset</title><p id="P26">The model training progress shows convergence of the models on the training datasets while still not overfitting <xref ref-type="fig" rid="F5">Fig. 5A</xref>. After training, the models were tested on each testing fold using the Dice and F1 scores (<xref ref-type="fig" rid="F5">Fig. 5B</xref>), and the logit maps were used to construct ROC curves <xref ref-type="fig" rid="F5">Fig. 5D</xref>. In both cases, we see high performance from the model, achieving an overall average Dice scores of 0.806±0.054 and 0.809±0.035 for rods and rings respectively and F1 scores of 0.806±0.054 and 0.809±0.036 for rods and rings respectively. We also see a strong performance in the ROC curve analysis, achieving a mean AUC of 0.8965 and 0.9063 for rods and rings (<xref ref-type="fig" rid="F5">Fig. 5D</xref>). In representative examples of model outputs (<xref ref-type="fig" rid="F5">Fig. 5C</xref>), the model clearly segments the images well, apart from in a few select areas of disagreement that may be a result of annotation bias (the correlation of derived measurements in are also shown (<xref ref-type="fig" rid="F5">Fig. 5E,F</xref>; and Supplemental <xref ref-type="supplementary-material" rid="SD1">Fig. S1</xref>). Overall, we see a strong correlation between the researcher derived measurements and those produced by the model for the number of rods and rings (<italic>R</italic><sup>2</sup> of 0.7255 and 0.8572), but much lower for the other measurements (Supplemental <xref ref-type="supplementary-material" rid="SD1">Fig. S1</xref>), showing that the output of the AI can be used to track some biologically meaningful information within the domain of the dataset.</p></sec><sec id="S20"><title>Time Course Dataset</title><p id="P27">To test the model’s performance at predicting data outside of the training domain, an additional dataset was recorded that examined the effect of differentiation media on the rid-ring structures over time, which permitted us to test the out of domain performance of the model. In this case, we again record the Dice and F1 scores (<xref ref-type="fig" rid="F6">Fig. 6A</xref>) and show similar performance to the testing dataset albeit with some reduction in images with low numbers of rods and rings, with average dice scores of 0.7189±0.0659 and 0.7338±0.0484 for rods and rings respectively and F1 scores of 0.7186±0.0660 and 0.7334±0.0484 for rods and rings respectively. ROC curve analysis shows similarly high AUC scores for rods and rings compared to the primary dataset, with AUCs of 0.734 and 0.856 for rods and rings (<xref ref-type="fig" rid="F6">Fig. 6B</xref>).</p><p id="P28">There is a high correlation between the ground truth expert-annotated masks and the output of the ensemble model, with <italic>R</italic><sup>2</sup> of 0.9030 and 0.9544 for rod and ring counts respectively (<xref ref-type="fig" rid="F6">Fig. 6C,D</xref>). This indicates that the model is robust to changes in rod ring morphology due to biological changes in the experimental conditions. The plots of several measurements split by their time point can be seen in (<xref ref-type="supplementary-material" rid="SD1">Fig. S2</xref>). We show that the model is successfully able to find similar patterns in the time course experiment as the human annotations.</p></sec><sec id="S21"><title>Microscopy Change Dataset</title><p id="P29">The model was tested on a dataset recorded by a different microscope to examine the robustness of the model to changes in the nature of the images. These data were pre-processed in two ways as the microscope resolutions differ: one pipeline to keep the magnification constant with the primary dataset and another to keep the pixel height and width constant (<xref ref-type="fig" rid="F4">Fig. 4</xref>). When examining the performance of the model, we see relatively low Dice scores of 0.2795 ± 0.101 and 0.3483 ± 0.127 and F1 scores of 0.3480 ± 0.127 and 0.2798 ± 0.101 for rods and rings respectively (<xref ref-type="fig" rid="F7">Fig. 7A,B</xref>). Additionally, ROC analysis for the constant magnification dataset shows similarly disappointing results (<xref ref-type="fig" rid="F7">Fig. 7B</xref>), with AUCs of 0.5047 and 0.5471 for rods and rings respectively. Representative examples qualitatively show that the model has unsuccessfully read these images as there are significant artefacts with the output masks (<xref ref-type="supplementary-material" rid="SD1">Fig. S3</xref>).</p><p id="P30">Interestingly, for the pixel height and width constant preprocessing pipeline, we see much better results (<xref ref-type="fig" rid="F7">Fig. 7C</xref>), with higher Dice scores of 0.719±0.066 and 0.733±0.048 and F1 scores of 0.718±0.066 and 0.733±0.048 for rods and rings respectively. Furthermore, in this case the ROC analysis shows much greater performance (<xref ref-type="fig" rid="F7">Fig. 7D</xref>), with AUCs of 0.8271 and 0.8556 for rods and rings. Lastly, for the pixel height and width constant preprocessing pipelines, we also measure the correlation between expert-annotated mask measurements and the AI model output mask measurements (<xref ref-type="fig" rid="F7">Fig. 7E,F</xref>). We see a strong correlation between the two, with an <italic>R</italic><sup>2</sup> score of 0.8418 and 0.8381 for rod and rings counts.</p></sec></sec><sec id="S22" sec-type="discussion"><title>Discussion</title><p id="P31">In this work, we have developed a fully automatic end-to-end image segmentation pipeline for rod ring microscopy images that can derive biologically relevant measurements over the course of an experiment. However, we still feel like there are several open questions for this work:</p><sec id="S23"><title>Comparison to Existing Models</title><p id="P32">Pre-trained transformer-based models such as Segment Anything (SAM) [<xref ref-type="bibr" rid="R17">17</xref>], You Only Look Once (YOLO) [<xref ref-type="bibr" rid="R16">16</xref>] and Segformer [<xref ref-type="bibr" rid="R10">10</xref>] are all state-of-the-art models in their respective fields, however all have significant drawbacks in this domain. SAM still requires some user input in detecting objects for segmentation; so, inclusion of the model alone in the pipeline would lose the automatic nature of the work. Since the throughput of microscopy can be high, this is crucial to the utility of the model. Furthermore, <xref ref-type="fig" rid="F8">Fig. 8</xref> shows examples of images segmented with SAM showing significant errors in its segmentations. Cellpose is a similar solution, designed to be general to cellular applications, however we find similar issues with the model’s ability to segment rods and rings (<xref ref-type="fig" rid="F8">Fig. 8</xref>). Similar issues exist for YOLO and Segformer. Both of these models segment without user input, but use a pre-defined set of labels that do not include rods and rings. In development, retraining or finetuning these models was unsuccessful due to overfitting, perhaps due to the large size of these models compared with the relatively small size of our dataset.</p></sec><sec id="S24"><title>Measurement Variance</title><p id="P33">Measuring correlation with expert annotations is dangerous for several reasons: firstly, it assumes that the expert annotation is a completely accurate source of truth (see below). Secondly, it is also (with the methods discussed in this work) weak to high variance measurements: for example, due to the resolution of the data, large changes in some measurements can occur when only small changes are made in the annotation. In this work, the model showed strong correlation between expert annotation and model output for ring and rod counts. This measurement shows lower variance when the sample size (i.e. the number of rings and rods available) is high. Since the microscope has a fixed resolution, this occurs when there are a large number of small, low-pixel count rings and rods available. Unfortunately, measuring the area or perimeter of the rings and rods is difficult in this case.</p><p id="P34">When the rods and rings have a small number of pixels, an additional pixel labelled by the model results in a large change in the area and perimeter measurements. Additionally, the low resolution of these objects results in only a few possible values; leading to discontinuities in histograms when performing downstream analysis (<xref ref-type="fig" rid="F9">Fig. 9</xref>). The solution to the above problem is to take images where fewer rings and rods are visible, but at a much higher resolution, where the area and perimeters can be measured with a higher precision for analysis. However, this reduces the number of rings and rods visible, which itself increases variance for these measurements given the same number of images taken.</p></sec><sec id="S25"><title>Expert Bias</title><p id="P35">In the recording of metrics for this work, we encounter a common problem in using AI for biological or medical tasks which was the lack of an objective ground truth. While the results in this work are promising, these are metrics based on a comparison to expert annotation that may include biases and variances between and within the datasets that make annotations inconsistent. Some objects close to the edge of the image or objects slightly dimmed compared with other objects, might be labelled as a ring or a rod by the expert but not by the AI model; or vice versa. This leads to some slight inconsistencies with the metrics, and it is arguable as to whether areas the model was marked as incorrect were incorrect at all (<xref ref-type="fig" rid="F10">Fig. 10</xref>).</p></sec><sec id="S26"><title>Microscope Resolution</title><p id="P36">In testing for the effect of changing the microscope on the AI model performance, we see that the effective method to preserve model performance is to preprocess the data in a bespoke way that preserves the real-life height and width of a pixel in space. For other microscopes, this can be calculated easily but is crucial for model inference as shown above. Furthermore, we see a trade-off within the measurements we take, and the resolution of the images taken from microscopy: if the microscope is at a lower magnification, the resulting image will contain a high number of objects, but at low resolution. This results in a lower variance in the “object-aggregate” measurements such as the count of rods or rings, but a lower accuracy in the “within-object” measurements such as area or perimeter. This is because at a low resolution, each object may only take a small number of pixels in the image, and therefore the resulting area may be under 5 pixels large. On the other hand, if the magnification is significantly high (and the model retrained to account for this) – we would see much more accurate reporting of measurements such as area and perimeter; however, the number of objects identified would be far fewer; increasing variance in this way.</p></sec><sec id="S27"><title>WebApp</title><p id="P37">Crucial to the development of this model was the development of an accompanying webapp, allowing feedback from expert biologist in how to improve the model in the biological context. Supplemental <xref ref-type="supplementary-material" rid="SD1">Fig. S4</xref> shows a screenshot of this model in practice, and we have made the webapp code available for use by research teams in an easy to deploy manner.</p></sec><sec id="S28" sec-type="conclusions"><title>Conclusion</title><p id="P38">We have developed an AI tool with an accompanying webapp to identify, classify, and quantitatively analyse IMPDH2 RR structures from confocal microscopy images. Furthermore, we’ve shown that our model works out of domain when images are taken on different microscopes, and when the size and conformation of RR structures differ (e.g. during differentiation).</p><p id="P39">The RR conformation is not unique to IMPDH2, nor are these structures limited to mammalian cells: depending on the biological context, different metabolic enzymes can form these structures which can vary in size, frequency, and topology. Examples include CTPS in yeast [<xref ref-type="bibr" rid="R8">8</xref>, <xref ref-type="bibr" rid="R29">29</xref>], IMPDH2 in zebrafish teeth [<xref ref-type="bibr" rid="R30">30</xref>], and various filamentous RR proteins in drosophila and yeast [<xref ref-type="bibr" rid="R8">8</xref>]. Additionally, other RR-like structures, distinct from both IMPDH2 RRs and CTPS1 cytoophidia have been identified such as nematosomes [<xref ref-type="bibr" rid="R31">31</xref>, <xref ref-type="bibr" rid="R32">32</xref>] and loukoumasomes [<xref ref-type="bibr" rid="R15">15</xref>, <xref ref-type="bibr" rid="R33">33</xref>], the latter enriched cytoskeletal proteins. Therefore, the pipeline we have developed can be of broader significance to multiple groups, allowing them to train their own datasets and quantitatively analyse these structures.</p><p id="P40">Finally, biological systems do not exist in static form, and many proteins are highly dynamic. Indeed, temporal imaging of fluorescent CTPS1 and IMPDH2 has shown that RRs are dynamic structures, coalescing into rods and rings, and increasing/decreasing their size over time [<xref ref-type="bibr" rid="R7">7</xref>, <xref ref-type="bibr" rid="R34">34</xref>]. Our model at present does not cater for time-lapse tracking of live RRs in real-time, but as segmentation and classification is usually the bottleneck, tracking segmented RRs could be a feasible modification for future pipeline developments.</p></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary Material</label><media xlink:href="EMS199519-supplement-Supplementary_Material.pdf" mimetype="application" mime-subtype="pdf" id="d77aAcEbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S29"><title>Acknowledgement</title><p>We would like to thank Anna Bigas for the kind gift of the E14-Tg2A mouse ESCs used in this study. We are indebted to the University of Liverpool’s (UoL) Centre for Cell Imaging (CCI) facility for provision of state of the art imaging equipment funded through grants awarded by the MRC (MR/K015931/1) and the BBSRC (BB/M012441/1, BB/R01390X/1). We would also like to thank Thomas Waring from the CCI for excellent technical support, assistance, and training. Additional thanks are extended to members of the DAT lab for useful discussions and support.</p><p>DAT was funded in this work by the BBSRC (a DTP PhD studentship <ext-link ext-link-type="uri" xlink:href="https://gtr.ukri.org/projects?ref=BB%2FT008695%2F1">BB/T008695/1</ext-link>, project reference 2599454 supporting MJH, and a New Investigator Grant <ext-link ext-link-type="uri" xlink:href="https://gtr.ukri.org/projects?ref=BB%2FX000907%2F1">BB/X000907/1</ext-link>), the NC3Rs (<ext-link ext-link-type="uri" xlink:href="https://gtr.ukri.org/projects?ref=NC%2FP001467%2F1">NC/P001467/1</ext-link>), The Royal Society (RGS/R2/202075), a Wellcome Trust non-clinical ISSF, and UoL’s Technology Directorate voucher scheme. KFJ was supported in this work by core funding from Department of Electrical and Electronic Engineering for YT. SB and YZ were funded by the Wellcome Trust’s Investigator Award in Science Programme. Grant Number: 222530/Z/21/Z. None of the funding bodies had any input in the design of the study or data collection, analysis, and interpretation, or in writing the manuscript.</p></ack><sec id="S30" sec-type="data-availability"><title>Data Availability Statement</title><p id="P41">All software, and code generated or analysed during this study are included in this published article’s supplementary information files and have been deposited in github <ext-link ext-link-type="uri" xlink:href="https://github.com/gastruloids/gandalf">https://github.com/gastruloids/gandalf</ext-link>. Test images use to train the data are also included.</p></sec><glossary><title>List of Abbreviations</title><def-list><def-item><term>AI</term><def><p>Artificial Intelligence</p></def></def-item><def-item><term>CTPS1</term><def><p>Cytidine Triphosphate Synthase 1</p></def></def-item><def-item><term>ESC</term><def><p>Embryonic stem cell</p></def></def-item><def-item><term>FBS</term><def><p>Foetal Bovine Serum</p></def></def-item><def-item><term>GMP/GTP</term><def><p>Guanine monophosphate/Guanine Triphosphate</p></def></def-item><def-item><term>IMPDH2</term><def><p>Inositol monophosphate dehydrogenase 2</p></def></def-item><def-item><term>PBS<sup>-/-</sup></term><def><p>Phosphate buffered saline without calcium or magnesium ions</p></def></def-item><def-item><term>PBSFT</term><def><p>PBS supplemented with 10% FBS and 0.2% Triton X100</p></def></def-item><def-item><term>PBT</term><def><p>PBS supplemented with 0.2% FBS and 0.2% Triton X100</p></def></def-item><def-item><term>RR</term><def><p>Rod and Ring</p></def></def-item></def-list></glossary><fn-group><fn id="FN1" fn-type="con"><p id="P42"><bold>Author Contributions:</bold> STMB conceived the AI approach, developed, trained, and tested the software, analysed microscopy images, and co-wrote the first draft of the manuscript with MJH. MJH performed the experimental work and the associated microscopy, analysed the data, and annotated all microscopy images for training the model. KFH conceived the preliminary AI study and with DAT, and supervised YT who contributed to an initial feasibility study as part of his 3rd year research project. MRHW, NDP, and DJW had intellectual input into the underlying biological study and provided secondary supervision to MJH. YZ provided significant intellectual input into the AI methodology and provided comments on the manuscript. DAT conceived and obtained funding for the experimental study, led and managed the project, and wrote the manuscript. All authors read and approved the final manuscript.</p></fn><fn id="FN2" fn-type="conflict"><p id="P43"><bold>Competing Interests:</bold> The authors declare no conflicts of interest.</p></fn></fn-group><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spiller</surname><given-names>DG</given-names></name><name><surname>Wood</surname><given-names>CD</given-names></name><name><surname>Rand</surname><given-names>DA</given-names></name><name><surname>White</surname><given-names>MR</given-names></name></person-group><article-title>Measurement of single-cell dynamics</article-title><source>Nature</source><year>2010</year><volume>465</volume><issue>7299</issue><fpage>736</fpage><lpage>745</lpage><pub-id pub-id-type="pmid">20535203</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bagheri</surname><given-names>N</given-names></name><name><surname>Carpenter</surname><given-names>AE</given-names></name><name><surname>Lundberg</surname><given-names>E</given-names></name><name><surname>Plant</surname><given-names>AL</given-names></name><name><surname>Horwitz</surname><given-names>R</given-names></name></person-group><article-title>The new era of quantitative cell imaging-challenges and opportunities</article-title><source>Mol Cell</source><year>2022</year><volume>82</volume><issue>2</issue><fpage>241</fpage><lpage>247</lpage><pub-id pub-id-type="pmcid">PMC10339817</pub-id><pub-id pub-id-type="pmid">35063094</pub-id><pub-id pub-id-type="doi">10.1016/j.molcel.2021.12.024</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burrell</surname><given-names>AL</given-names></name><name><surname>Kollman</surname><given-names>JM</given-names></name></person-group><article-title>IMPDH dysregulation in disease: a mini review</article-title><source>Biochem Soc Trans</source><year>2022</year><volume>50</volume><issue>1</issue><fpage>71</fpage><lpage>82</lpage><pub-id pub-id-type="pmcid">PMC9022972</pub-id><pub-id pub-id-type="pmid">35191957</pub-id><pub-id pub-id-type="doi">10.1042/BST20210446</pub-id></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ji</surname><given-names>Y</given-names></name><name><surname>Gu</surname><given-names>J</given-names></name><name><surname>Makhov</surname><given-names>AM</given-names></name><name><surname>Griffith</surname><given-names>JD</given-names></name><name><surname>Mitchell</surname><given-names>BS</given-names></name></person-group><article-title>Regulation of the interaction of inosine monophosphate dehydrogenase with mycophenolic Acid by GTP</article-title><source>J Biol Chem</source><year>2006</year><volume>281</volume><issue>1</issue><fpage>206</fpage><lpage>212</lpage><pub-id pub-id-type="pmid">16243838</pub-id></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carcamo</surname><given-names>WC</given-names></name><name><surname>Satoh</surname><given-names>M</given-names></name><name><surname>Kasahara</surname><given-names>H</given-names></name><name><surname>Terada</surname><given-names>N</given-names></name><name><surname>Hamazaki</surname><given-names>T</given-names></name><name><surname>Chan</surname><given-names>JY</given-names></name><name><surname>Yao</surname><given-names>B</given-names></name><name><surname>Tamayo</surname><given-names>S</given-names></name><name><surname>Covini</surname><given-names>G</given-names></name><name><surname>von Muhlen</surname><given-names>CA</given-names></name><etal/></person-group><article-title>Induction of cytoplasmic rods and rings structures by inhibition of the CTP and GTP synthetic pathway in mammalian cells</article-title><source>PLoS One</source><year>2011</year><volume>6</volume><issue>12</issue><elocation-id>e29690</elocation-id><pub-id pub-id-type="pmcid">PMC3248424</pub-id><pub-id pub-id-type="pmid">22220215</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0029690</pub-id></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peng</surname><given-names>M</given-names></name><name><surname>Keppeke</surname><given-names>GD</given-names></name><name><surname>Tsai</surname><given-names>LK</given-names></name><name><surname>Chang</surname><given-names>CC</given-names></name><name><surname>Liu</surname><given-names>JL</given-names></name><name><surname>Sung</surname><given-names>LY</given-names></name></person-group><article-title>The IMPDH cytoophidium couples metabolism and fetal development in mice</article-title><source>Cell Mol Life Sci</source><year>2024</year><volume>81</volume><issue>1</issue><fpage>210</fpage><pub-id pub-id-type="pmcid">PMC11078715</pub-id><pub-id pub-id-type="pmid">38717553</pub-id><pub-id pub-id-type="doi">10.1007/s00018-024-05233-z</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gou</surname><given-names>KM</given-names></name><name><surname>Chang</surname><given-names>CC</given-names></name><name><surname>Shen</surname><given-names>QJ</given-names></name><name><surname>Sung</surname><given-names>LY</given-names></name><name><surname>Liu</surname><given-names>JL</given-names></name></person-group><article-title>CTP synthase forms cytoophidia in the cytoplasm and nucleus</article-title><source>Exp Cell Res</source><year>2014</year><volume>323</volume><issue>1</issue><fpage>242</fpage><lpage>253</lpage><pub-id pub-id-type="pmid">24503052</pub-id></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Noree</surname><given-names>C</given-names></name><name><surname>Sato</surname><given-names>BK</given-names></name><name><surname>Broyer</surname><given-names>RM</given-names></name><name><surname>Wilhelm</surname><given-names>JE</given-names></name></person-group><article-title>Identification of novel filament-forming proteins in Saccharomyces cerevisiae and Drosophila melanogaster</article-title><source>J Cell Biol</source><year>2010</year><volume>190</volume><issue>4</issue><fpage>541</fpage><lpage>551</lpage><pub-id pub-id-type="pmcid">PMC2928026</pub-id><pub-id pub-id-type="pmid">20713603</pub-id><pub-id pub-id-type="doi">10.1083/jcb.201003001</pub-id></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simonet</surname><given-names>JC</given-names></name><name><surname>Burrell</surname><given-names>AL</given-names></name><name><surname>Kollman</surname><given-names>JM</given-names></name><name><surname>Peterson</surname><given-names>JR</given-names></name></person-group><article-title>Freedom of assembly: metabolic enzymes come together</article-title><source>Mol Biol Cell</source><year>2020</year><volume>31</volume><issue>12</issue><fpage>1201</fpage><lpage>1205</lpage><pub-id pub-id-type="pmcid">PMC7353150</pub-id><pub-id pub-id-type="pmid">32463766</pub-id><pub-id pub-id-type="doi">10.1091/mbc.E18-10-0675</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turner</surname><given-names>DA</given-names></name><name><surname>Rue</surname><given-names>P</given-names></name><name><surname>Mackenzie</surname><given-names>JP</given-names></name><name><surname>Davies</surname><given-names>E</given-names></name><name><surname>Martinez Arias</surname><given-names>A</given-names></name></person-group><article-title>Brachyury cooperates with Wnt/beta-catenin signalling to elicit primitive-streak-like behaviour in differentiating mouse embryonic stem cells</article-title><source>BMC Biol</source><year>2014</year><volume>12</volume><fpage>63</fpage><pub-id pub-id-type="pmcid">PMC4171571</pub-id><pub-id pub-id-type="pmid">25115237</pub-id><pub-id pub-id-type="doi">10.1186/s12915-014-0063-7</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turner</surname><given-names>DA</given-names></name><name><surname>Trott</surname><given-names>J</given-names></name><name><surname>Hayward</surname><given-names>P</given-names></name><name><surname>Rue</surname><given-names>P</given-names></name><name><surname>Martinez Arias</surname><given-names>A</given-names></name></person-group><article-title>An interplay between extracellular signalling and the dynamics of the exit from pluripotency drives cell fate decisions in mouse ES cells</article-title><source>Biol Open</source><year>2014</year><volume>3</volume><issue>7</issue><fpage>614</fpage><lpage>626</lpage><pub-id pub-id-type="pmcid">PMC4154298</pub-id><pub-id pub-id-type="pmid">24950969</pub-id><pub-id pub-id-type="doi">10.1242/bio.20148409</pub-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rueden</surname><given-names>CT</given-names></name><name><surname>Schindelin</surname><given-names>J</given-names></name><name><surname>Hiner</surname><given-names>MC</given-names></name><name><surname>DeZonia</surname><given-names>BE</given-names></name><name><surname>Walter</surname><given-names>AE</given-names></name><name><surname>Arena</surname><given-names>ET</given-names></name><name><surname>Eliceiri</surname><given-names>KW</given-names></name></person-group><article-title>ImageJ2: ImageJ for the next generation of scientific image data</article-title><source>BMC Bioinformatics</source><year>2017</year><volume>18</volume><issue>1</issue><fpage>529</fpage><pub-id pub-id-type="pmcid">PMC5708080</pub-id><pub-id pub-id-type="pmid">29187165</pub-id><pub-id pub-id-type="doi">10.1186/s12859-017-1934-z</pub-id></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schindelin</surname><given-names>J</given-names></name><name><surname>Arganda-Carreras</surname><given-names>I</given-names></name><name><surname>Frise</surname><given-names>E</given-names></name><name><surname>Kaynig</surname><given-names>V</given-names></name><name><surname>Longair</surname><given-names>M</given-names></name><name><surname>Pietzsch</surname><given-names>T</given-names></name><name><surname>Preibisch</surname><given-names>S</given-names></name><name><surname>Rueden</surname><given-names>C</given-names></name><name><surname>Saalfeld</surname><given-names>S</given-names></name><name><surname>Schmid</surname><given-names>B</given-names></name><etal/></person-group><article-title>Fiji: an open-source platform for biological-image analysis</article-title><source>Nat Methods</source><year>2012</year><volume>9</volume><issue>7</issue><fpage>676</fpage><lpage>682</lpage><pub-id pub-id-type="pmcid">PMC3855844</pub-id><pub-id pub-id-type="pmid">22743772</pub-id><pub-id pub-id-type="doi">10.1038/nmeth.2019</pub-id></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneider</surname><given-names>CA</given-names></name><name><surname>Rasband</surname><given-names>WS</given-names></name><name><surname>Eliceiri</surname><given-names>KW</given-names></name></person-group><article-title>NIH Image to ImageJ: 25 years of image analysis</article-title><source>Nat Methods</source><year>2012</year><volume>9</volume><issue>7</issue><fpage>671</fpage><lpage>675</lpage><pub-id pub-id-type="pmcid">PMC5554542</pub-id><pub-id pub-id-type="pmid">22930834</pub-id><pub-id pub-id-type="doi">10.1038/nmeth.2089</pub-id></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramer</surname><given-names>MS</given-names></name><name><surname>Cruz Cabrera</surname><given-names>MA</given-names></name><name><surname>Alan</surname><given-names>N</given-names></name><name><surname>Scott</surname><given-names>AL</given-names></name><name><surname>Inskip</surname><given-names>JA</given-names></name></person-group><article-title>A new organellar complex in rat sympathetic neurons</article-title><source>PLoS One</source><year>2010</year><volume>5</volume><issue>5</issue><elocation-id>e10872</elocation-id><pub-id pub-id-type="pmcid">PMC2877718</pub-id><pub-id pub-id-type="pmid">20531934</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0010872</pub-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Redmon</surname><given-names>J</given-names></name><name><surname>Farhadi</surname><given-names>A</given-names></name></person-group><article-title>YOLOv3: An Incremental Improvement</article-title><source>arXiv</source><year>2018</year></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kirillov</surname><given-names>A</given-names></name><name><surname>Mintun</surname><given-names>E</given-names></name><name><surname>Ravi</surname><given-names>N</given-names></name><name><surname>Mao</surname><given-names>H</given-names></name><name><surname>Rolland</surname><given-names>C</given-names></name><name><surname>Gustafson</surname><given-names>L</given-names></name><name><surname>Xiao</surname><given-names>T</given-names></name><name><surname>Whitehead</surname><given-names>S</given-names></name><name><surname>Berg</surname><given-names>AC</given-names></name><name><surname>Lo</surname><given-names>W-Y</given-names></name><etal/></person-group><source>Segment Anything</source><conf-name>2023 IEEE/CVF International Conference on Computer Vision (ICCV)</conf-name><conf-loc>Paris</conf-loc><year>2023</year><fpage>3992</fpage><lpage>4003</lpage></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xie</surname><given-names>E</given-names></name><name><surname>Wang</surname><given-names>W</given-names></name><name><surname>Yu</surname><given-names>Z</given-names></name><name><surname>Anandkumar</surname><given-names>A</given-names></name><name><surname>Alvarez</surname><given-names>JM</given-names></name><name><surname>Luo</surname><given-names>P</given-names></name></person-group><article-title>SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers</article-title><source>arXiv</source><year>2021</year></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dosovitskiy</surname><given-names>A</given-names></name><name><surname>Beyer</surname><given-names>L</given-names></name><name><surname>Kolesnikov</surname><given-names>A</given-names></name><name><surname>Weissenborn</surname><given-names>D</given-names></name><name><surname>Zhai</surname><given-names>X</given-names></name><name><surname>Unterthiner</surname><given-names>T</given-names></name><name><surname>Dehghani</surname><given-names>M</given-names></name><name><surname>Minderer</surname><given-names>M</given-names></name><name><surname>Heigold</surname><given-names>G</given-names></name><name><surname>Gelly</surname><given-names>S</given-names></name><etal/></person-group><article-title>An Image is Worth 16×16 Words: Transformers for Image Recognition at Scale</article-title><source>arXiv</source><year>2020</year></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stringer</surname><given-names>C</given-names></name><name><surname>Wang</surname><given-names>T</given-names></name><name><surname>Michaelos</surname><given-names>M</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name></person-group><article-title>Cellpose: a generalist algorithm for cellular segmentation</article-title><source>Nat Methods</source><year>2021</year><volume>18</volume><issue>1</issue><fpage>100</fpage><lpage>106</lpage><pub-id pub-id-type="pmid">33318659</pub-id></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Ronneberger</surname><given-names>O</given-names></name><name><surname>Fischer</surname><given-names>P</given-names></name><name><surname>Brox</surname><given-names>T</given-names></name></person-group><source>U-Net: Convolutional Networks for Biomedical Image Segmentation</source><conf-name>Medical Image Computing and Computer-Assisted Intervention; 18th International Conference</conf-name><conf-sponsor>Springer</conf-sponsor><conf-loc>Munich, Germany</conf-loc><year>2015</year><fpage>234</fpage><lpage>241</lpage></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kingma</surname><given-names>DP</given-names></name><name><surname>Ba</surname><given-names>J</given-names></name></person-group><article-title>Adam: A Method for Stochastic Optimization</article-title><source>arXiv</source><year>2017</year></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Walt</surname><given-names>S</given-names></name><name><surname>Schonberger</surname><given-names>JL</given-names></name><name><surname>Nunez-Iglesias</surname><given-names>J</given-names></name><name><surname>Boulogne</surname><given-names>F</given-names></name><name><surname>Warner</surname><given-names>JD</given-names></name><name><surname>Yager</surname><given-names>N</given-names></name><name><surname>Gouillart</surname><given-names>E</given-names></name><name><surname>Yu</surname><given-names>T</given-names></name></person-group><article-title>scikit-image c: scikit-image: image processing in Python</article-title><source>PeerJ</source><year>2014</year><volume>2</volume><elocation-id>e453</elocation-id><pub-id pub-id-type="pmcid">PMC4081273</pub-id><pub-id pub-id-type="pmid">25024921</pub-id><pub-id pub-id-type="doi">10.7717/peerj.453</pub-id></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bradski</surname><given-names>G</given-names></name></person-group><article-title>Open Source Computer Vision Library</article-title><source>Dr Dobb’s Journal of Software Tools: Itseez</source><year>2000</year></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Sofroniew</surname><given-names>N</given-names></name><name><surname>Lambert</surname><given-names>T</given-names></name><name><surname>Bokota</surname><given-names>G</given-names></name><name><surname>Nunez-Iglesias</surname><given-names>J</given-names></name><name><surname>Sobolewski</surname><given-names>P</given-names></name><name><surname>Sweet</surname><given-names>A</given-names></name><name><surname>Gaifas</surname><given-names>L</given-names></name><name><surname>Evans</surname><given-names>K</given-names></name><name><surname>Burt</surname><given-names>A</given-names></name><name><surname>Doncila Pop</surname><given-names>S</given-names></name><etal/></person-group><source>napari: a multi-dimensional image viewer for Python</source><year>2024</year><comment>0.5.4 edn</comment></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ying</surname><given-names>QL</given-names></name><name><surname>Smith</surname><given-names>AG</given-names></name></person-group><article-title>Defined conditions for neural commitment and differentiation</article-title><source>Methods Enzymol</source><year>2003</year><volume>365</volume><fpage>327</fpage><lpage>341</lpage><pub-id pub-id-type="pmid">14696356</pub-id></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ying</surname><given-names>QL</given-names></name><name><surname>Stavridis</surname><given-names>M</given-names></name><name><surname>Griffiths</surname><given-names>D</given-names></name><name><surname>Li</surname><given-names>M</given-names></name><name><surname>Smith</surname><given-names>A</given-names></name></person-group><article-title>Conversion of embryonic stem cells into neuroectodermal precursors in adherent monoculture</article-title><source>Nat Biotechnol</source><year>2003</year><volume>21</volume><issue>2</issue><fpage>183</fpage><lpage>186</lpage><pub-id pub-id-type="pmid">12524553</pub-id></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mulas</surname><given-names>C</given-names></name><name><surname>Kalkan</surname><given-names>T</given-names></name><name><surname>von Meyenn</surname><given-names>F</given-names></name><name><surname>Leitch</surname><given-names>HG</given-names></name><name><surname>Nichols</surname><given-names>J</given-names></name><name><surname>Smith</surname><given-names>A</given-names></name></person-group><article-title>Defined conditions for propagation and manipulation of mouse embryonic stem cells</article-title><source>Development</source><year>2019</year><volume>146</volume><issue>6</issue><pub-id pub-id-type="pmcid">PMC6451320</pub-id><pub-id pub-id-type="pmid">30914406</pub-id><pub-id pub-id-type="doi">10.1242/dev.173146</pub-id></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Liu</surname><given-names>JL</given-names></name></person-group><article-title>Temperature-sensitive cytoophidium assembly in Schizosaccharomyces pombe</article-title><source>J Genet Genomics</source><year>2019</year><volume>46</volume><issue>9</issue><fpage>423</fpage><lpage>432</lpage><pub-id pub-id-type="pmcid">PMC6868507</pub-id><pub-id pub-id-type="pmid">31611173</pub-id><pub-id pub-id-type="doi">10.1016/j.jgg.2019.09.002</pub-id></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keppeke</surname><given-names>GD</given-names></name><name><surname>Chang</surname><given-names>CC</given-names></name><name><surname>Antos</surname><given-names>CL</given-names></name><name><surname>Peng</surname><given-names>M</given-names></name><name><surname>Sung</surname><given-names>LY</given-names></name><name><surname>Andrade</surname><given-names>LEC</given-names></name><name><surname>Liu</surname><given-names>JL</given-names></name></person-group><article-title>IMPDH forms the cytoophidium in zebrafish</article-title><source>Dev Biol</source><year>2021</year><volume>478</volume><fpage>89</fpage><lpage>101</lpage><pub-id pub-id-type="pmid">34048735</pub-id></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ockleford</surname><given-names>CD</given-names></name><name><surname>Nevard</surname><given-names>CH</given-names></name><name><surname>Indans</surname><given-names>I</given-names></name><name><surname>Jones</surname><given-names>CJ</given-names></name></person-group><article-title>Structure and function of the nematosome</article-title><source>J Cell Sci</source><year>1987</year><volume>87</volume><issue>Pt 1</issue><fpage>27</fpage><lpage>44</lpage><pub-id pub-id-type="pmid">2822737</pub-id></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Willingham</surname><given-names>MC</given-names></name><name><surname>Richert</surname><given-names>ND</given-names></name><name><surname>Rutherford</surname><given-names>AV</given-names></name></person-group><article-title>A novel fibrillar structure in cultured cells detected by a monoclonal antibody</article-title><source>Exp Cell Res</source><year>1987</year><volume>171</volume><issue>2</issue><fpage>284</fpage><lpage>295</lpage><pub-id pub-id-type="pmid">3305048</pub-id></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Noble</surname><given-names>JW</given-names></name><name><surname>Hunter</surname><given-names>DV</given-names></name><name><surname>Roskelley</surname><given-names>CD</given-names></name><name><surname>Chan</surname><given-names>EK</given-names></name><name><surname>Mills</surname><given-names>J</given-names></name></person-group><article-title>Loukoumasomes Are Distinct Subcellular Structures from Rods and Rings and Are Structurally Associated with MAP2 and the Nuclear Envelope in Retinal Cells</article-title><source>PLoS One</source><year>2016</year><volume>11</volume><issue>10</issue><elocation-id>e0165162</elocation-id><pub-id pub-id-type="pmcid">PMC5087950</pub-id><pub-id pub-id-type="pmid">27798680</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0165162</pub-id></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>CC</given-names></name><name><surname>Keppeke</surname><given-names>GD</given-names></name><name><surname>Sung</surname><given-names>LY</given-names></name><name><surname>Liu</surname><given-names>JL</given-names></name></person-group><article-title>Interfilament interaction between IMPDH and CTPS cytoophidia</article-title><source>FEBS J</source><year>2018</year><volume>285</volume><issue>20</issue><fpage>3753</fpage><lpage>3768</lpage><pub-id pub-id-type="pmcid">PMC6220823</pub-id><pub-id pub-id-type="pmid">30085408</pub-id><pub-id pub-id-type="doi">10.1111/febs.14624</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>IMPDH2 rod-ring structures in pluripotent mouse embryonic stem cells.</title><p>A representative maximum intensity projection of fixed mouse embryonic stem cells (left) showing DAPI (grey) which marks the nuclei, and IMPDH2 (cyan). Magnified examples of rods (top right) and rings (bottom right) are shown. The number of rods-rings in this image is in excess of 200. Scale bar indicates 30 µm.</p></caption><graphic xlink:href="EMS199519-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Training and inference protocol, and example training labels for rod ring segmentation.</title><p>(<bold>A</bold>) Training and inference protocol used in this work. The training datasets were split into 5 disjoint sets, with a UNet model trained on each combination of 4 sets, testing on the final test set each time. After the training and testing on the primary dataset is complete, this gives us 5 UNet models that are used in ensemble for inference, with the output logits being averaged and thresholded to gain the final segmentation. (<bold>B</bold>) Shows a sample of the raw images (left) along with the expert annotations for Rods and Rings used for training. It is worth noting that although these labels are provided by a highly skilled expert in the field, they are by no means an “absolute” ground truth; and contain some implicit biases and variations between the images.</p></caption><graphic xlink:href="EMS199519-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Differentiation of mouse ESCs and the loss of IMPDH2 RR structures.</title><p>Examples of control cells at the start (0h) at 24h in pluripotency media (left), and cells over a period of 33h, sampled at the indicated time-points following transition into differentiation media (N2B27).</p></caption><graphic xlink:href="EMS199519-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Preprocessing pipelines for datasets.</title><p>In general, we found through development that very little preprocessing needed to be applied to the raw images before inputting into the model, with normalisation harming the segmentation results rather than helping. For the experiment with a change of microscope, two pipelines were developed due to a change in output resolution of the image: one fixing the objective magnification to that of the training data; and one fixing the real pixel size with that of the dataset. We find that the latter far outperforms the former.</p></caption><graphic xlink:href="EMS199519-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>Model Training.</title><p>(<bold>A</bold>) shows the training and testing losses of each of the models over time. We see that the models similarly converged over time, showing there were no training folds significantly different to others for training. (<bold>B</bold>) shows the mean Dice and F1 scores for the models tested on the holdout test set for the rod and ring mask recovery. (<bold>C</bold>) Shows a representative example outputs along with the relative labels for the rods and ring masks. (<bold>D</bold>) Shows the per-pixel AUC curve for each of the mask. (<bold>E</bold>) and (<bold>F</bold>) show the correlation of the derived measurements from the model segmentations versus the segmentation provided by an expert annotator. A strong correlation here shows not only an accurate segmentation, but also a biologically helpful model that can be used for downstream analysis.</p></caption><graphic xlink:href="EMS199519-f005"/></fig><fig id="F6" position="float"><label>Figure 6</label><caption><title>Time-course metrics.</title><p>For the time-course dataset, the model trained on the primary dataset was applied via an ensemble mechanism with the resulting metrics to test for out-of-domain performance. (<bold>A</bold>) shows the Dice and F1 scores for rods and rings for each image compared with expert annotation. (<bold>B</bold>) shows the per-pixel AUC scores for both the rods and rings. (<bold>C</bold>) and (<bold>D</bold>) show the correlation between derived features from the segmentations for both the expert analysis and the model. As with the previous primary dataset, correlation here shows the model can recover meaningful biological information as well as pixel-wise accuracy.</p></caption><graphic xlink:href="EMS199519-f006"/></fig><fig id="F7" position="float"><label>Figure 7</label><caption><title>Microscopy experiment metrics.</title><p>Data from a different microscope was used to test for application of the model out-of-domain. We find that when preprocessing fixes the objective magnification of the input data, the model performance is fairly poor. The Dice and F1 scores for rod and ring segmentation compared to expert analysis are shown (A), as well as the pixel-wise AUCs for rods and rings (B). By preprocessing the data to preserve the real pixel size compared to the primary dataset, we see much better model performance. (C) shows the Dice and F1 scores for the rod and ring segmentations after this preprocessing step and (D) shows the AUC scores. (E) and (F) show the correlation of the latter preprocessing pipeline model with the expert annotations. We again see a strong correlation with the expert annotation showing strong biological relevance of the model.</p></caption><graphic xlink:href="EMS199519-f007"/></fig><fig id="F8" position="float"><label>Figure 8</label><caption><title>Example Segmentations from Segment Anything and Cellpose.</title><p>(<bold>A</bold>) Segment anything provides context-free segmentations using user prompts to drive the segmentation process, however we find that using the different modes for SAM we get poor results for our specific datasets. (i) shows the segmentation using the box-prompt mode and (ii) show the segmentation using the point prompt mode. The representative example (ii) showing the model unable to differentiate between a rod and a ring object. (iii) shows the “Whole picture” approach which fails to single out individual objects in the image. (<bold>B</bold>) The original image (i) and predicted outcomes (ii) using Cellpose showing an inability to segment rods and rings correctly.</p></caption><graphic xlink:href="EMS199519-f008"/></fig><fig id="F9" position="float"><label>Figure 9</label><caption><title>Perimeter to Area Ratio for the Time Course Experiment.</title><p>For each of the detected polygons, the perimeter and area were calculated, to account for changes due to the change in media. However, due to the pixel size of the objects in the microscopy images, we see common ratios appear due to noisy segmentation. In future work, if this ratio is to be used, a higher resolution is needed for each of the objects to allow for more granularity in the perimeter and area calculations.</p></caption><graphic xlink:href="EMS199519-f009"/></fig><fig id="F10" position="float"><label>Figure 10</label><caption><title>Comparison of model labelling rings potentially missed by experts.</title><p>Examples of ground truth labelling done by out microscopy expert, the model logit “fuzzy” output mask, the binary mask for the images, and the original image with increased exposure. We see that a ring-like structure visible in the original image (in red) is picked up by the model but not annotated by the expert annotator.</p></caption><graphic xlink:href="EMS199519-f010"/></fig></floats-group></article>