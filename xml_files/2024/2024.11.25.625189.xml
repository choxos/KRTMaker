<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS201278</article-id><article-id pub-id-type="doi">10.1101/2024.11.25.625189</article-id><article-id pub-id-type="archive">PPR945203</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">1</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Distinct decision processes for 3D and motion stimuli in both humans and monkeys revealed by computational modelling</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Rangotis</surname><given-names>Revan</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Nowakowska</surname><given-names>Sabina</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Dayan</surname><given-names>Peter</given-names></name><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Parker</surname><given-names>Andrew J.</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A4">4</xref><xref ref-type="aff" rid="A5">5</xref></contrib><contrib contrib-type="author"><name><surname>Kakaei</surname><given-names>Ehsan</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Akande</surname><given-names>Abibat</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Krug</surname><given-names>Kristine</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A4">4</xref><xref ref-type="aff" rid="A5">5</xref></contrib></contrib-group><aff id="A1"><label>1</label>Institute of Biology, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/00ggpsq73</institution-id><institution>Otto-von-Guericke-University Magdeburg</institution></institution-wrap>, <city>Magdeburg</city>, <country country="DE">Germany</country></aff><aff id="A2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/021ft0n22</institution-id><institution>University Medical Centre Göttingen</institution></institution-wrap>, Institute for Auditory Neuroscience, <city>Göttingen</city>, <country country="DE">Germany</country></aff><aff id="A3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/026nmvv73</institution-id><institution>Max Planck Institute for Biological Cybernetics</institution></institution-wrap> &amp; <institution-wrap><institution-id institution-id-type="ror">https://ror.org/03a1kwz48</institution-id><institution>University of Tübingen</institution></institution-wrap>, <city>Tübingen</city>, <country country="DE">Germany</country></aff><aff id="A4"><label>4</label>Department of Physiology Anatomy and Genetics, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>University of Oxford</institution></institution-wrap>, <city>Oxford</city>, <country country="GB">United Kingdom</country></aff><aff id="A5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01zwmgk08</institution-id><institution>Leibniz Institute for Neurobiology</institution></institution-wrap>, <city>Magdeburg</city>, <country country="DE">Germany</country></aff><pub-date pub-type="nihms-submitted"><day>27</day><month>11</month><year>2024</year></pub-date><pub-date pub-type="preprint"><day>25</day><month>11</month><year>2024</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Decision-making models distil principles of information processing that underlie a range of cognitive functions. For the cases of motion detection in random-dot kinematograms and decisions about the rotation of 3D structure-from-motion cylinders, contributing neural processes have been localized to specific circuits in extrastriate area V5/MT on the basis of both causal and correlative evidence, suggesting a common decision path. Here, we arranged for humans and rhesus monkeys to make perceptual choices about these two stimulus types, indicating their decision with either hand or eye movements. In both species, the parameter distributions of a hierarchical Drift Diffusion Model (DDM) revealed systematic differences for stimulus type but not the different modes of response. States in a hidden Markov model also indicated distinct decision strategies, again for the two stimulus types but not for response mode. Although physiological evidence points to area V5/MT as a vehicle for relevant perceptual signals for both stimulus types, computational modelling of the present results reveal distinct decision processes, therefore predicting that different neural processes underlie judgements about motion and 3D-depth, consistently for humans and monkeys.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">The framework of sequential sampling has provided a powerful collection of models of sensory, affective and memory-based decision-making. The principal goal of these models is to use behavioural data, in particular response accuracy and reaction time (RT), to make inferences about aspects of the neural computations and mechanisms that underlie critical cognitive processes (<xref ref-type="bibr" rid="R46">Ratcliff &amp; McKoon, 2008</xref>). Substrates linked to model parameters have been proposed in humans (e.g. <xref ref-type="bibr" rid="R25">Heekeren et al., 2004</xref>) and macaque monkeys (e.g. <xref ref-type="bibr" rid="R48">Roitman &amp; Shadlen, 2002</xref>).</p><p id="P3">There is a variety of popular models (<xref ref-type="bibr" rid="R13">Brown &amp; Heathcote, 2008</xref>; <xref ref-type="bibr" rid="R28">Krajbich et al., 2010</xref>; <xref ref-type="bibr" rid="R54">Usher &amp; McClelland, 2001</xref>), many of which are based on a noisy evidence accumulation process, which terminates once a threshold, or “bound”, is reached (<xref ref-type="bibr" rid="R19">Forstmann et al., 2016</xref>). In particular, the drift diffusion model (DDM) has become widely used for two-alternative forced choice tasks (2AFC) (<xref ref-type="bibr" rid="R6">Bogacz et al., 2006</xref>; <xref ref-type="bibr" rid="R44">Ratcliff, 1978</xref>, <xref ref-type="bibr" rid="R47">Ratcliff et al., 2016</xref>). While DDMs have been used extensively in different species (e.g., (<xref ref-type="bibr" rid="R18">Fan et al., 2018</xref>)), few studies have directly compared model performance across decision tasks or across species on the same task (but see (<xref ref-type="bibr" rid="R55">Voss et al., 2004</xref>)). Such comparisons are essential if we are to generalise our understanding of cognitive processes within single brains and between species, especially from animal models to humans (<xref ref-type="bibr" rid="R36">Nestler &amp; Hyman, 2010</xref>). The models propose a pipeline from sensory input, through evidence inference and integration, to action selection and execution. There is a need to understand which neural elements are shared between tasks and which elements or processes are specific to particular tasks.</p><p id="P4">An assumption that is embedded in the use of the DDM is that the detailed strategy employed by a subject is fixed across an experimental session. There is ample empirical evidence that this is not true, e.g., (<xref ref-type="bibr" rid="R10">Braun et al., 2018</xref>; <xref ref-type="bibr" rid="R43">Purcell &amp; Kiani, 2016</xref>; <xref ref-type="bibr" rid="R49">Roy et al., 2021</xref>), suggesting problems for parameter inference when using the DDM alone. Models have been developed in which the current strategy is characterized as a latent state that determines response properties. Strategies may then be altered spontaneously (<xref ref-type="bibr" rid="R2">Ashwood et al., 2022</xref>) or in reaction to experimental circumstances (<xref ref-type="bibr" rid="R33">Mohammadi et al., 2024</xref>). In one prominent example (<xref ref-type="bibr" rid="R2">Ashwood et al., 2022</xref>), the responses made during the dominance of any single strategy are described by a psychometric function derived from the parameters of a generalized linear model (GLM), and the switching process is described by a hidden Markov model (HMM). Here, we use a combination of the DDM and the GLM-HMM to elucidate the cognitive processes and strategies that govern two perceptual decision tasks in monkeys and humans.</p><p id="P5">Noisy random dot kinematograms (RDK) have been extensively used to investigate mechanisms underlying motion perception (<xref ref-type="bibr" rid="R12">Britten et al., 1992</xref>), perceptual decision-making (<xref ref-type="bibr" rid="R48">Roitman &amp; Shadlen, 2002</xref>), and perceptual learning (<xref ref-type="bibr" rid="R59">Zohary, Celebrini, et al., 1994</xref>). Similarly, 3D structure-from-motion (SfM) cylinders have been employed to examine the eponymous processes. A SfM cylinder is a bistable stimulus with competing, mutually-exclusive rotational percepts, which flip stochastically and can be disambiguated by the addition of 3D depth in the form of binocular disparity (<xref ref-type="bibr" rid="R40">Parker &amp; Krug, 2003</xref>).</p><p id="P6">Examining the processing of these two stimulus classes should offer useful clues to the structure of the decision-making pipeline, since perceptual signals for motion and binocular disparity, as well as the combination of these two visual cues, have been identified in single neurons in the visual cortical area V5/MT of the dorsal stream in the primate (<xref ref-type="bibr" rid="R7">Born &amp; Bradley, 2005</xref>; <xref ref-type="bibr" rid="R8">Bradley et al., 1998</xref>; <xref ref-type="bibr" rid="R17">Dodd et al., 2001</xref>; <xref ref-type="bibr" rid="R29">Krug, 2004</xref>). Causal evidence for the role of V5/MT in both tasks is provided by focal micro-stimulation, which reliably drives perceptual decisions for both RDK (<xref ref-type="bibr" rid="R50">Salzman et al., 1990</xref>) and SfM cylinders (<xref ref-type="bibr" rid="R31">Krug et al., 2013</xref>). Also for both the RDK (<xref ref-type="bibr" rid="R11">Britten et al., 1996</xref>) and the SfM cylinder (<xref ref-type="bibr" rid="R17">Dodd et al., 2001</xref>), there is correlative evidence of trial-by-trial neural activity predictive of future behavioural decisions. This predictive relationship is summarized by choice probability (CP), a measure of how reliably behavioural decisions can be predicted from neural activity. CP is higher in V5/MT for decisions about the SfM cylinder (<xref ref-type="bibr" rid="R17">Dodd et al., 2001</xref>) than the RDK (<xref ref-type="bibr" rid="R11">Britten et al., 1996</xref>); this higher CP is also associated with higher interneuronal correlations (<xref ref-type="bibr" rid="R3">Bair et al., 2001</xref>; <xref ref-type="bibr" rid="R56">Wasmuht et al., 2019</xref>; <xref ref-type="bibr" rid="R59">Zohary, Shadlen, et al., 1994</xref>). These differences in neuronal signalling are suggestive of distinct neuronal mechanisms existing within the same cortical area.</p><p id="P7">While the neural substrate for perceptual decisions about both motion and depth has been linked to V5/MT, neurophysiological results also indicate distinct circuitry for evidence accumulation depending on how the outcome of the perceptual decision is reported (<xref ref-type="bibr" rid="R22">Gold &amp; Shadlen, 2007</xref>). Several candidate regions have been investigated, predominantly those involved in the selection and preparation of eye movements, including the superior colliculus (<xref ref-type="bibr" rid="R26">Horwitz &amp; Newsome, 2001</xref>), dlPFC (<xref ref-type="bibr" rid="R27">Kim &amp; Shadlen, 1999</xref>), LIP (<xref ref-type="bibr" rid="R52">Shadlen &amp; Newsome, 2001</xref>), and FEF (<xref ref-type="bibr" rid="R21">Gold &amp; Shadlen, 2000</xref>). In parietal cortex, lateral intraparietal area (LIP) shows signals related to evidence accumulation for both hand and eye responses, but the medial intraparietal area (MIP) shows more pronounced rising activity when hand responses are performed (<xref ref-type="bibr" rid="R15">de Lafuente et al., 2015</xref>). The processing in different cortical areas could indicate differences in decision processes.</p><p id="P8">Here, we investigate the perceptual decision processes underpinned by incoming sensory evidence for the cases of pure motion direction (RDK) or combinations of binocular disparity and motion (SfM). For each stimulus type, we modelled decisions that were reported either by eye movements or by hand responses (<xref ref-type="fig" rid="F1">Figure 1</xref>). We employed DDMs and GLM-HMMs to model the underlying decision processes and strategies for behavioural data from both monkeys and humans. We address two questions. Firstly, are there different perceptual decision processes depending on the visual cues to be judged and how the response is delivered, by an eye movement or a hand movement? Secondly, do the analytical models yield comparable results for humans and monkeys carrying out the same decision task?</p></sec><sec id="S2" sec-type="results"><title>Results</title><p id="P9">20 humans and 2 rhesus monkeys (m133 and m134) made perceptual decisions about the direction of motion of an RDK and about the rotation direction of a 3D SfM cylinder. Subjects reported their decision with either an eye or a hand movement. The human participants carried out all four combinations of stimulus and response in a counterbalanced fashion. The monkeys performed the RDK task with hand responses and the cylinder task with saccade responses.</p><sec id="S3"><title>Perceptual performance broadly comparable between humans and monkeys</title><p id="P10">We fitted behavioural responses from the RDK and cylinder tasks with cumulative Gaussian functions to determine the threshold and bias (<xref ref-type="fig" rid="F2">Figure 2A</xref>). For the cylinder task, human participants performed similarly whether reporting by hand (mean threshold = 0.0086°, standard deviation (STD) = ±0.004°) or by eye (mean = 0.0084°, STD = ±0.005°) (n = 20, paired t-test, p = 0.7). This was also true for the RDK task (mean = 11.2%, STD = ±3.9% vs. mean = 13.3%, STD = ±5.0%) (n = 20, paired t-test, p = 0.1). Like humans, both monkeys had smooth psychophysical functions on both tasks. For the cylinder task, both monkeys had significantly higher thresholds than most humans (threshold m134 = 0.020°, m133 = 0.026°: single sample t-test, p = 0.0378 and p = 0.003, using methods described in (<xref ref-type="bibr" rid="R14">Crawford &amp; Howell, 1998</xref>)). On the RDK task, monkey m134 showed similar accuracy to that of the humans (threshold = 12.3%, single sample t-test, p = 0.785), but m133’s threshold was considerably higher (threshold = 24.7%, single sample t-test, p = 0.003). However, m133’s threshold was still close to that of some human participants (<xref ref-type="fig" rid="F2">Figure 2A</xref>).</p><p id="P11">Looking at the reaction time (RT) distributions (<xref ref-type="fig" rid="F2">Figure 2B</xref>), while human and monkey participants carried out the perceptual tasks well, the monkeys tended generally to be faster but less accurate. A striking difference was that both monkeys were much faster responding with eye movements on the cylinder task than the human participants (mean RT = 0.252s, STD = ± 0.038s vs mean RT = 0.551s, STD = ± 0.234s; independent t-test, <italic>p</italic> &lt; 0.0001), as previously observed for other saccade tasks (<xref ref-type="bibr" rid="R32">Middlebrooks &amp; Schall, 2014</xref>). The monkeys, in particular, showed even faster error trials for the cylinder task (<xref ref-type="supplementary-material" rid="SD1">Supplementary Figure 2-1</xref>). Otherwise, the distributions of reaction times appeared broadly comparable.</p><p id="P12">For hand responses, monkeys could use either or both paws on the touch screen, while humans used the fingers of the preferred hand for button presses. Nevertheless, the monkeys were also somewhat faster than the humans on the RDK task, when responding by hand (mean RT = 0.631s, STD = ± 0.215s vs. mean RT = 0.724s, STD = ± 0.355s; independent t-test, <italic>p</italic> &lt; 0.0001). A closer look at the reaction times across different stimulus levels shows the typical pattern of longer reaction times for stimuli that are more difficult to judge (<xref ref-type="supplementary-material" rid="SD1">Supplementary Figure 2-1</xref>). This difference was more pronounced for the RDK than for the flatter cylinder reaction times, especially for the human data. Notable is also m133 who showed a bias in the RDK task with different reaction times for right and left choices, which most likely indicates a hand bias.</p></sec><sec id="S4"><title>Visual stimulus but not response mode produces systematic differences in drift constant and boundary separation in drift diffusion modelling</title><p id="P13">We constructed hierarchical DDM models for the pooled data from the 20 human participants across all four task combinations and for each macaque separately across the two available task combinations, yielding a total of 8 fitted models (four fits from the 20 humans and two fits from each monkey). To compare performance across the two different tasks with different visual stimuli, human psychometric data sets were normalized by dividing each stimulus value by the average threshold of the group of human participants for this task. For the monkey data, we normalized by their individual thresholds across sessions. We utilized the open-source Bayesian hierarchical DDM method (<xref ref-type="bibr" rid="R57">Wiecki et al., 2013</xref>), which assumes the individual data sets come from a population distribution and estimates the model parameters using the Monte Carlo Markov Chain (MCMC) method. We treated each human participant as a member of a population and, similarly, all experimental sessions for each monkey on a given task as members of a population. This latter approach was used due to the small number of monkeys (<xref ref-type="bibr" rid="R57">Wiecki et al., 2013</xref>). The models were constructed with 5 parameters: boundary separation <italic>a</italic>, drift constant (a form of sensitivity) <italic>k</italic>, drift intercept <italic>v</italic><sub>0</sub>, non-decision time <italic>t</italic>, and starting point bias <italic>z</italic> (see <xref ref-type="fig" rid="F1">Figure 1C</xref>). We ran the Monte Carlo Markov Chain (MCMC) of the DDM five separate times for each model to assess convergence as well as for further analysis. The Gelman-Rubin statistic (<xref ref-type="bibr" rid="R20">Gelman &amp; Rubin, 1992</xref>) was calculated to lie between 0.99 and 1.01 in all cases except one (1.013), showing excellent convergence.</p><p id="P14">A pair-wise comparison between the 3D cylinder task and the RDK task of the distribution of fitted DDM parameters reveals systematic differences for the drift constant <italic>k</italic> and for the boundary separation <italic>a</italic> (<xref ref-type="fig" rid="F3">Figure 3</xref>, panels surrounded by dashed black boxes) (Kolmogorov-Smirnov test p &lt; 0.0001 (test statistic 0.825) for drift constant <italic>k</italic>, p &lt; 0.001 (test statistic 0.45) for boundary separation <italic>a</italic>). This is the case for humans and monkeys, regardless of the mode of response. For the goodness-of-fit see <xref ref-type="supplementary-material" rid="SD1">Supplementary Figure 3-1</xref>. The value of <italic>a</italic> was lower in the cylinder task than for the RDK task in both species, indicating a shorter distance to evidence threshold. The human participants had a larger drift constant <italic>k</italic> for the RDK tasks, suggesting that the RDK sensory signal was integrated into evidence at a steeper rate than the disparity information. While the monkeys also showed a strong difference in drift constant <italic>k</italic> between the cylinder and the RDK task, the monkeys showed a larger drift constant <italic>k</italic> for the cylinder task.</p><p id="P15">Because the monkey data were obtained from only two subjects, individual differences are more apparent in the data set. In contrast, the human data were obtained from 20 individuals for which the parameter values are more spread out and appear normally distributed. Nevertheless, the data clearly indicate systematic differences in two key DDM parameters, <italic>k</italic> and <italic>a</italic>, across both species. These differences depend on the type of visual stimulus (binocular depth defined rotation or direction of motion) about which decisions are made, regardless of the mode of response (hand or eye).</p></sec><sec id="S5"><title>Dimensionality reduction confirms a systematic difference by visual task</title><p id="P16">To tease apart the factors contributing to the differences in DDM parameters for humans and monkeys, we implemented a supervised dimensionality reduction method, linear discriminant analysis (LDA), on the DDM model parameters shown in <xref ref-type="fig" rid="F3">Figure 3</xref>. Using the estimated parameter distribution derived from the 5 runs of the MCMC model on the human data, we reduced the space to three linear discriminant dimensions (LD) which optimally distinguished the four groups (combinations of stimulus type and response mode). We visualized this by projecting the human estimated parameters onto the first two LDs. Subsequently, we projected the estimated parameters for the monkey, also combined from 5 MCMC runs, onto this same space derived from the analysis of the human parameters (<xref ref-type="fig" rid="F4">Figure 4</xref>).</p><p id="P17">Immediately apparent are the separate clusters along LD1 for the two visual stimuli (RDK motion direction or cylinder). Along LD2, mode of response was a poor separator for the human data, but somewhat better for the monkeys. Each LD was a weighted combination of the 5 original DDM parameters. For LD1, which shows the highest discriminability, <italic>k</italic> contributed 69%, <italic>a</italic> 17%, v<sub>0</sub> 6% and whereas <italic>t</italic> and <italic>z</italic> showed negligible contribution (less than 5 %). For LD2 <italic>k</italic> contributed 26%, <italic>a</italic> 34%, <italic>t</italic> 21%, <italic>z</italic> 19% and <italic>v<sub>0</sub></italic> showed virtually no contribution. The DDM parameter space is therefore distinct for perceptual decisions about the RDK stimulus and the rotating cylinder. Overall, the DDM suggests distinct decision processing for the two different visual stimuli, but not for the saccade or hand response. The estimated parameters for the monkey data are largely comparable in this respect with those for the human data, except for m133 on the RDK task, for which the monkey showed a bias in the RT for different directions.</p></sec><sec id="S6"><title>Hidden Markov Model reveals different strategies for the two visual tasks</title><p id="P18">Looking at choice only, we probed whether the observed differences in decision-making between the two visual tasks were related to distinct behavioural strategies when judging the two visual stimuli. We employed a generalized linear model (GLM) with a logistic function as the link function, translating the sensory input into the probability of choosing “rightwards direction” (RDK) or “counter-clockwise rotation” (cylinder), and 3 covariates, namely normalised <italic>stimulus</italic> strength, previous <italic>choice</italic>, and <italic>bias</italic> (<xref ref-type="bibr" rid="R2">Ashwood et al., 2022</xref>). The human data were grouped by the type of stimulus to be judged. We then modelled a number of distinct “behavioural states” as different states in a Hidden Markov model (HMM) by estimating weights for each of the covariates using an expectation-maximization algorithm with 5-fold cross-validation for humans and <italic>K</italic>-fold for monkeys depending on the number of sessions <italic>K</italic> (<xref ref-type="bibr" rid="R2">Ashwood et al., 2022</xref>).</p><p id="P19">We compared the rise in log-likelihood (LL) per trial averaged across the five hold-out sets. Each behavioural state is described by a distinct set of weights attributed to the three covariates, which describe the behavioural strategy of the animal on these trials (<xref ref-type="fig" rid="F5">Figure 5</xref>). By identifying the steepest rise in LL, we found that three states were optimal to describe the human data for each stimulus type (<xref ref-type="supplementary-material" rid="SD1">Supplementary Figure 5-1</xref>). Based on the pattern of weights for the two most distinguishing covariates, <italic>stimulus</italic> (indicating the task engagement by linking stimulus strength to choice) and <italic>bias</italic>, these states were <italic>post-hoc</italic> termed “Strongly engaged”, “Moderately engaged with bias” and “Disengaged” for the 3D SfM cylinder and “Engaged”, “Engaged with left bias” and “Disengaged” for the RDK task (<xref ref-type="fig" rid="F5">Figure 5A</xref>).</p><p id="P20">The 3D cylinder showed the overall strongest task engagement in the “Strongly engaged” state. Participants spent the majority of their time in this state (<xref ref-type="fig" rid="F5">Figure 5B top, 5C top</xref>). In contrast, participants judging the RDK spent roughly equal time in two “engaged” states with an influence of the <italic>stimulus</italic> on choices, which was similar to that found for the “moderately engaged state with bias” for the cylinder (<xref ref-type="fig" rid="F5">Figure 5C bottom</xref>). One of these two RDK engaged states showed a bias, but not the other. When judging the 3D cylinder, human participants spent considerably more time in an engaged state without a behavioural bias than for discriminating motion direction of the RDK. Finally, for both stimuli, we identified a “disengaged state”, during which <italic>stimulus</italic> only weakly controlled the responses.</p><p id="P21">The covariate <italic>previous choice</italic> seemed to have a smaller influence on the individual states, but there was a pattern of 3D cylinder states tending to stay with a previous choice (<italic>previous choice</italic> +1), while RDK states tended to favour switch away from the previous choice (<italic>previous choice</italic> -0.5). When we re-grouped the human data according to the mode of response, again three states were sufficient. However, the states appeared almost indistinguishable between responses with eye or hand movements (<xref ref-type="fig" rid="F5">Figure 5D</xref>).</p><p id="P22">For the monkey data, grouped individually by animal and task, the LL suggested that two states were slightly better for both tasks for each animal (<xref ref-type="supplementary-material" rid="SD1">Supplementary Figure 5-2</xref>). This conclusion could also supported for a small number of the human participants, based on further analysing the individual trial occupancies (<xref ref-type="supplementary-material" rid="SD1">Supplementary Figures 5-3 and 5-4</xref>). For the monkeys, the identified states corresponded broadly to a subset of those found in humans for the same tasks, particularly the fit for m134 was very similar to the global fit for the human data (see <xref ref-type="supplementary-material" rid="SD1">Supplementary Figure 5-2</xref> for states and <xref ref-type="supplementary-material" rid="SD1">Supplementary Figures 5-5 and 5-6</xref> for the individual trial resolved data).</p><p id="P23">Overall, the analysis of behavioural strategy for the human participants complemented the findings of the DDM, in that the two visual stimuli did exhibit different state distributions, whereas changes of state did not associate with the two modes of response. It also emerged that different periods of time were spent in distinct behavioural states when judgements were made about the two types of visual stimuli and there was some similarity in this regard between the humans and the monkeys</p><p id="P24">In order to test whether both modelling approaches pick up consistently on the same differences between the two visual tasks, we identified for the humans the GLM-HMM states with the largest number of trials (“3D cylinder: strongly engaged”, n=17 participants, “RDK: moderately engaged” n=12, and “RDK: moderately engaged with left bias” n=7) and performed a second DDM run, including data from participants with a minimum number of contributing trials. When we compared the DDM parameters for these three states, they also showed the distinct separation in drift constant <italic>k</italic> and boundary separation <italic>a</italic> between the two stimulus types (<xref ref-type="supplementary-material" rid="SD1">Supplementary Figure 5-7</xref>). This suggests that the two modelling approaches pick up on corresponding differences in processing. The behavioural state for the RDK influenced by a bias shows a strong drift rate intercept.</p><p id="P25">In summary, both models distinguish consistently behavioural differences in judging the two visual stimuli but less so or not all for the modes of response. The DDM suggests differences in sensitivity (<italic>k</italic>) to the sensory information and time available for the decision process (<italic>α</italic>). The GLM-HMM also points to distinct behavioural strategies or brain states for decisions about each of the two types of visual stimuli. These differences might be related to the strong, stable percept that subsumes all stimulus elements (dots) of the cylinder stimulus, even in the bistable version. In contrast, decisions about the more overtly noisy RDK stimulus need to discount the noise dots and the perceptual process might be consequently less stable. Ultimately, the differences in perception point to differences in the brain processes responsible for perceptual decision-making in the two tasks.</p></sec></sec><sec id="S7" sec-type="discussion"><title>Discussion</title><p id="P26">We systematically analysed perceptual decisions in a multi-factorial psychophysical design for combinations of two distinct visual cues to be judged with two modes of perceptual report by humans and macaque monkeys. These cues of motion and binocular disparity were presented in the form of stimuli (RDK and 3-D cylinders) that have been extensively studied electrophysiologically and causally linked through microstimulation to macaque area V5/MT. The two analyses (DDM and GLM-HMM) offered complementary and consistent findings.</p><p id="P27">Firstly, we tested whether the computational models could underpin distinct processing for the two visual tasks and the different motor responses. Both the DDM and GLM-HMM identified clear separation in the parameter space of the fitted models for judgements of motion direction in RDK versus perceived rotation of 3D SfM cylinders. Conversely, for the type of motor response, there was only a weak difference in the DDM and none in the GLM-HMM. Secondly, we set out to compare humans and monkeys in the same modelling frameworks. Like humans, the monkeys showed a clear distinction between the two visual decision tasks. However, some of the details of the fitted models were different on this small sample. We propose that perceptual decisions might be affected by different integration windows for incoming visual information about motion and about 3D depth.</p><sec id="S8"><title>HDDM and GLM-HMM point to different neuronal mechanisms and behavioural strategies for the two visual tasks</title><p id="P28">The DDM parameter space showed a clear separation of the models for the different visual stimulus cues. For the human as well as the monkey data, the separation of the bounds (α) was lower for the cylinder than for the RDK. In the human data, this was also accompanied by lower drift constant (<italic>k</italic>) for the cylinder stimulus. This implies that a shorter integration window was needed to commit to clockwise or counter-clockwise rotation in comparison to the time needed for decisions about left- or rightwards motion in the RDK. The outcome is most evident for the more ambiguous versions of the stimuli (see <xref ref-type="supplementary-material" rid="SD1">Supplementary Figure 2-1</xref>). At the same time, the lower drift constant for the cylinder task compared with that for the RDK task in the human data suggests that binocular depth matching is a fundamentally more difficult task in terms of translating the signal into evidence.</p><p id="P29">In the decision task, the bottom-up visual input leads to the selective activation of the relevantly tuned neuronal populations in visual area V5/MT for both stimulus types (<xref ref-type="bibr" rid="R12">Britten et al., 1992</xref>; <xref ref-type="bibr" rid="R17">Dodd et al., 2001</xref>; <xref ref-type="bibr" rid="R30">Krug, 2020</xref>). In the case of the 3D cylinder, we propose that this would activate circuits whose positive feedback activity in the sensory cortex stabilizes the network of neurons favouring one direction of rotation over the other. Such reverberations could theoretically stabilize the network faster than for the corresponding case with the RDK, leading to lower effective separation of the bounds.</p><p id="P30">The reaction times on more difficult trials are almost as fast for the cylinder as the easiest trials with a strong signal – in contrast to the RDK RTs. This may also be attributable to greater positive feedback within the local network dynamics during perceptual decisions about the cylinder. The two monkeys, however, showed the opposite tendency: The drift constant for monkeys for SfM cylinders is higher than for the RDK stimulus. This outcome might be attributable to perceptual learning, given that the macaques underwent far more extensive training on the cylinder task than the humans prior to data collection and learned the cylinder task after the initial training on the RDK task. Further data are needed, preferably conducted with electrophysiological recordings during the training period.</p><p id="P31">The GLM-HMM matched choice data to hypothesized “brain states”, which are manifest as different weights for the parameters that contribute to decision-making processes. These parameters include the stimulus to be judged, the choice made on the preceding trial, and internal biases. When the human data were grouped according to the motor response, the states identified for hand and eye responses came out very similar in terms of their GLM weights. Clear differences emerged when the same data were grouped based on the visual stimulus to be judged. Most striking, when judging the SfM cylinder, human participants tended to stay in one “strongly engaged” state far more than in the other two states (“moderately engaged with a bias” and “disengaged”).</p><p id="P32">By comparison, when deciding about the motion direction of an RDK, human participants tended to switch between two distinct “engaged” states (one of them with a strong bias). We see evidence of this not only from the fractional occupancy of the three states but also in the trial-resolved data (see <xref ref-type="fig" rid="F5">Figure 5</xref>). Moreover, weighting of the previous choice differed in sign between all the RDK states (negative) and the cylinder states (positive), which means the participants tended to switch from their previous choice when viewing RDKs but tended to stay with their previous choice when viewing cylinders. These observations might be potentially be ascribed to features of the neuronal network underpinning the cylinder task which might make it harder to “snap out” of a particular state, for example to a stronger local feedback loop within the neuronal circuitry supporting a stable 3D cylinder percept. Conversely, the behaviour of the RDK-subserving network might be better explained by sensory adaptation carrying over from one trial to the next.</p></sec><sec id="S9"><title>Potential neural substrate and mechanisms</title><p id="P33">For both perceptual decision tasks, extrastriate visual area V5/MT is firmly implicated as a potential neural substrate, based on a robust experimental framework linking single neurons to perception (<xref ref-type="bibr" rid="R4">Barlow, 1972</xref>; <xref ref-type="bibr" rid="R41">Parker &amp; Newsome, 1998</xref>). Electrical microstimulation of focal sites in V5/MT cortex alters direction of motion and 3D SfM cylinder percepts in a predictable and constructive way (<xref ref-type="bibr" rid="R50">Salzman et. al., 1990</xref>; <xref ref-type="bibr" rid="R31">Krug et al., 2013</xref>). Single V5/MT neurons of macaque monkeys show steep neurometric functions for the RDK task, matching those of the psychometric functions of the animals (<xref ref-type="bibr" rid="R12">Britten et al., 1992</xref>; <xref ref-type="bibr" rid="R37">Newsome et al., 1989</xref>). An above-chance relationship was also established between the trial-by-trial fluctuations in the activity of the V5/MT neurons and the perceptual decisions made by the animal about RDK stimulus, independent of the strength of visual stimulation; this relationship is termed choice probability (CP) (<xref ref-type="bibr" rid="R11">Britten et al., 1996</xref>). CP is defined as the probability with which an independent observer could predict the choices of the animal from the neuronal activity alone, given knowledge of the tuning curves.</p><p id="P34">CPs above chance level for different tasks have been found across extrastriate visual areas (<xref ref-type="bibr" rid="R38">Nienborg et al., 2012</xref>), with two broad interpretations with regards to their origin: bottom-up and top-down input. The former can be formalised as a feedforward neural network model wherein the final choice is determined by comparing two pools of activity of neurons with opposite tuning and, the activity within the pools is correlated (<xref ref-type="bibr" rid="R51">Shadlen et al., 1996</xref>), see also (<xref ref-type="bibr" rid="R23">Haefner et al., 2016</xref>). However, experimental data apparently at odds with this model have been obtained, giving rise to the latter explanation, that top-down control from downstream areas contributes to shared variability of activity, which is revealed as raised levels of interneuronal correlation (<xref ref-type="bibr" rid="R39">Nienborg &amp; Cumming, 2009</xref>). Experimentally derived CPs and interneuronal correlations from visual area V5/MT of macaque monkeys making perceptual decisions about the 3D SfM cylinder were both higher (CP = 0.67, interneuronal correlation r = 0.37) (<xref ref-type="bibr" rid="R17">Dodd et al., 2001</xref>; <xref ref-type="bibr" rid="R56">Wasmuht et al., 2019</xref>)(Krug et al., 2016) than those reported for the RDK task (CP = 0.56, r = 0.17) (<xref ref-type="bibr" rid="R3">Bair et al., 2001</xref>; <xref ref-type="bibr" rid="R11">Britten et al., 1996</xref>; <xref ref-type="bibr" rid="R59">Zohary, Shadlen, et al., 1994</xref>). These data suggest differences in neuronal processing within the local circuitry of V5/MT may underlie the psychophysical differences found here for the two stimuli.</p><p id="P35">Previous studies have investigated the network dynamics of V5/MT, both experimentally as well as theoretically. Wasmuht and colleagues (2019) concluded that the interneuronal correlations underlying the CP were dependent on interactions at longer timescales (100 – 400 ms) for ambiguous cylinders than RDKs, suggesting a stronger feedback component to the emergence of CP. A recent computational model accounts for the sustained CP observed experimentally whereby a bottom-up component of the interneuronal correlations explains the initial period of the decision time and a top-down component contributes to a second, later time period (<xref ref-type="bibr" rid="R58">Wimmer et al., 2015</xref>). However, if this top-down signal contributes to decision-formation, this would break a fundamental assumption of the DDM model, since this model accumulates only external evidence to form the decision. Nevertheless, one prediction of such a feedback or top-down mechanism is a shorter effective information integration window during which the bottom-up component can most effectively steer the decision process. This should lead to a flatter distribution of RT as a function of difficulty in the 3D cylinder task compared to the RDK task (<xref ref-type="bibr" rid="R58">Wimmer et al., 2015</xref>), as we observed in <xref ref-type="supplementary-material" rid="SD1">Supplementary Figure 2-1</xref>.</p><p id="P36">In the cylinder task, electrophysiological measures show that interneuronal correlation is weaker when the bottom-up task-relevant input, the magnitude of binocular disparity in the stimulus, is greatest. The strongest interneuronal correlations arise for the ambiguous cylinder, when the top-down decision signal may be at its strongest. Wasmuht and colleagues (2019) also showed that CP from V5/MT of macaque monkeys performing the cylinder task was positively correlated with interneuronal correlations and specifically associated with their long timescale component. This finding is consistent with the interpretation that feedback connections establish an increase in interneuronal correlations and a rise in CP in V5/MT, resulting in a stabilization of the percept. For the RDK stimulus with the weaker perceptual coherence, weaker CPs and interneuronal correlation suggested that the feedback or top-down modulation was not nearly as powerful. We suggest that the SfM cylinder task involves network dynamics with more rapidly rising and stronger top-down feedback, which consequently generates higher interneuronal correlations between neurons with similar preference as well as higher CPs.</p><p id="P37">About the mechanisms that result in a shorter integration window within the same neuronal circuitry, we can, at present, only speculate. It is clearly essential to perform direct electrophysiological measurements of multiple single neurons during perceptual decision-making with both the cylinder and the RDK tasks. However, we tentatively offer the following explanation. It has been suggested in (<xref ref-type="bibr" rid="R17">Dodd et al., 2001</xref>) that the percept of the ambiguous cylinder rotating in one direction is very different from the same cylinder rotating in the other direction, but the percept of the ambiguous RDK with one selected direction of global motion is much more similar to the percept of the same RDK with a choice in the other direction. In this interpretation, the two perceptual decisions are much farther apart in neuronal feature space for the case of the cylinder compared with the RDK. This greater separation in feature space may be linked to the presence of two separate but synergistic processes that must be recruited in the cylinder task, namely depth-from-motion (kinetic depth) and depth-from-disparity (dynamic stereopsis) (<xref ref-type="bibr" rid="R35">Nawrot &amp; Blake, 1993</xref>).</p></sec></sec><sec id="S10" sec-type="conclusions"><title>Conclusion</title><p id="P38">Computational models in systems neuroscience provide a powerful and robust framework for predicting neural mechanisms underlying cognitive processes. We systematically investigated two perceptual decision tasks with two distinct motor reports using the established DDM and the more recent GLM-HMM and interpreted our results in the context of a large body of existing electrophysiological literature. Both models clearly showed distinct decision processing for the two visual cues, direction of motion and 3D depth, but not for the two modes of response, hand or eye movement. The results were broadly similar between humans and monkeys on these tasks. We propose that these results reflect distinct processing for decision-making about the two stimulus types, with a shorter integration window for bottom-up input for 3D signals in the SFM cylinder than for motion direction in the RDK stimulus. To understand these mechanisms underlying perceptual decisions at a biologically plausible level of description across primates, the next steps should be to combine multisite neurophysiological recordings with models of neural dynamics at the level of microcircuits (<xref ref-type="bibr" rid="R24">Hanks &amp; Summerfield, 2017</xref>). The circuits of extrastriate visual area V5/MT with its columnar architecture for direction of motion and 3D depth and specific long-range interconnectivity are a likely substrate (<xref ref-type="bibr" rid="R1">Ahmed et al., 2012</xref>; <xref ref-type="bibr" rid="R16">DeAngelis &amp; Newsome, 1999</xref>).</p></sec><sec id="S11" sec-type="materials | methods"><title>Materials and methods</title><sec id="S12"><title>Human participants</title><p id="P39">We collected data from 23 adults of which 20 completed the study (13 females, 7 males; aged between 18 and 40, mean age of 29.6 years). Except one female, all were right-handed. All participants passed a test for normal or corrected-to-normal visual acuity (Snellen chart with 6/9 or better). Additionally, all participants passed a test of static stereoscopic vision (TNO, Lameris Ootech) using random-dots stereograms and red-green glasses with a minimum threshold of 240 arc seconds. Ethical approval was obtained from the Coordination Center for clinical studies (KKS) at the Medical Faculty of the Otto-von-Guericke University Magdeburg (OVGU). The study was conducted in accordance with the data protection principles (Datenschutz-Grundverordnung: DS-GVO) and the Declaration of Helsinki (2013). All participants gave informed consent.</p></sec><sec id="S13"><title>Animals</title><p id="P40">We collected data from two male adult rhesus macaques, m133 and m134. Each animal was first trained on the RDK task with a touchscreen and then subsequently on the cylinder task while head-fixed and responding through saccades. All procedures were conducted under licenses from the United Kingdom Home Office in accordance with the Animals (Scientific Procedures) Act 1986 and the European Union guidelines (EU Directive 2010/63/EU).</p></sec><sec id="S14"><title>Human experimental set-up and visual stimuli</title><p id="P41">Data were collected at a psychophysical laboratory at the Institute for Biology of the OVGU. The laboratory was darkened with blinds and shutters blocking all external light and additionally with black-painted dividers around the visual set-up. Visual stimuli were presented using a Wheatstone stereoscope on two EIZO FlexScan L550 monitors (refresh rate 60 Hz, 338 mm width, 270 mm height, resolution of 1280 by 1024 pixels) at viewing distance of 56 cm. Anti-aliasing was implemented to decrease the minimal effective disparity that could be displayed. Participants indicated their decisions using either two buttons on a response box or by making a saccade to a visual target. Eye movements were tracked throughout experimental trials using EyeLink 1000 Plus (SR Research EyeLink, Canada) at 1000 Hz sampling rate.</p><p id="P42">Visual stimuli were coded in MATLAB using Psychtoolbox (<xref ref-type="bibr" rid="R9">Brainard, 1997</xref>) and displayed on mid-grey background. The circular RDK patch had a diameter 6° and was made up of 180 black and white dots. Dot diameter was 0.1° and moved at the speed of 3°/s. Dots moved in random directions with a given percentage moving either left or right on a given trial, referred to as coherence. All human participants viewed the same coherence levels in a randomised order: -50%, -25%, -12.5%, -6.25%, -3.125%, 0 %, +3.125%, +6.25%, +12.5%, +25%, +50% (the sign indicates opposite directions). The 3D SfM cylinder is a projection of a 3D cylinder on a 2D screen (<xref ref-type="bibr" rid="R17">Dodd et al., 2001</xref>). Like the RDK, it was also made up of 180 black and white dots in on a mid-grey background. Dots were distributed on two superimposed, transparent planes. Dots on the two planes moved in opposite directions (right or left) with as sinusoidal velocity profile. Cylinder size was 6° by 6° and dot diameter 0.1°. Binocular disparity applied to the two sets of dots was used to separate the two transparent planes and disambiguate the cylinder rotation direction. Cylinder disparities were -0.08°, -0.04°, -0.02°, -0.013°, -0.007°, 0°, +0.007°, +0.013°, +0.02°, +0.04°, +0.08° between the centre of the back and front surface, randomly interleaved. To prevent dot tracking, 1 % of the dots was removed and replaced every frame (16.6 ms) for both stimuli.</p><p id="P43">For each participant, experimental sessions were spread over four separate days, most participants completed all four sessions within two weeks. Each session consisted of eight experimental blocks of 110 trials each with a 2-minute mandatory break between each block; longer breaks were taken as requested by participants. At the beginning of each session, participants were given training blocks to ensure stable performance, with their threshold being lower than at least the largest disparity presented on those training blocks. A typical experimental session lasted 1.5 – 2 hours. Participants conducted the study in 1 of 4 possible combinations with different stimuli and responses, listed in <xref ref-type="table" rid="T1">Table 1</xref>. We employed a balanced design and the assignment to groups was random.</p><p id="P44">At the beginning of each session, participants were briefed on the set-up and the task. To start each trial, participants fixated on a central dot (radius 0.13°) flashing black and white at 5 Hz, which then turned white. They were required to maintain fixation within a 1.7-degree radius around the fixation point. After acquisition of the fixation point, the stimulus appeared in the centre of the screen. Participants were instructed to report the direction of motion or the direction of rotation as fast and as accurate as possible. In sessions when an eye movement response was required, two small saccade targets (diameter = 0.5°) were displayed 6° to the left and the right on each side of the fixation dot. When a hand movement response was required, participants pressed with one of two buttons (<xref ref-type="fig" rid="F1">Figure 1A</xref>). Participants had to indicate their choice within 3s, otherwise the trial was aborted. Auditory feedback was given with a high-pitch tone for correct choices and a low-pitch tone for incorrect choices. Randomly one of the two tones was played for responses to ambiguous stimuli. The inter-trial interval was 1.5 seconds.</p></sec><sec id="S15"><title>Monkey experimental set-up and visual stimuli</title><p id="P45">Both monkeys underwent first training on the RDK task. For this study, they performed 11 consecutive sessions, each on a different day, within the span of 3 weeks. Monkeys were positioned in a monkey chair in front of a touchscreen (Elo Touch Solutions, LCD Touch Monitor, 60 Hz, Leuven, Belgium) with a viewing distance of 20 cm. Visual stimuli were coded in MATLAB using Psychtoolbox (<xref ref-type="bibr" rid="R9">Brainard, 1997</xref>) and were displayed on mid-grey background. Each trial started when the monkey touched a flashing dot on the bottom half of the screen. Then the RDK appeared above the dot together with two white targets in the form of a circle and a cross (diameter = 6.75°) to the left and the right. The RDK patch (diameter = 17.38°) was composed of 150 black and white dots (dot diameter = 0.5°). Dots moved in random directions with a certain percentage coherently moving left or right at a speed of 17.38°/s. m133 judged motion coherence levels of -50%, -40%, -30%, -25%, -20%, -12.5%, -10%, -6.25%, -3.125%, 0%, +3.125%, +6.25%, +10%, +12.5%, +20%, +25%, +30%, +40%, +50% (the sign indicates opposite directions). m134 judged coherence levels of 50%, -25%, -12.5%, -6.25%, -3.125%, 0%, +3.125%, +6.25%, +12.5%, +25%, +50%. Monkeys were rewarded with juice when they touched the correct target corresponding to the global motion direction. They were rewarded at random for ambiguous stimuli.</p><p id="P46">Subsequently, the same two monkeys underwent training for the 3D SfM cylinder paradigm. Monkeys were head-fixed during this task with an implanted titanium headpost. Visual stimuli were presented using a Wheatstone stereoscope on two EIZO FlexScan F78 CRT monitors (refresh rate 85 Hz, 392 mm width, 294 mm height, resolution of 1600 by 1200 pixels) at a viewing distance of 84 cm. Eye movements were tracked using the IVIEW X Hi-Speed Primate Eye Tracker (SensoMotoric Instruments SMI, Germany). Each trial was started with the monkey fixating on a dot (radius 0.13°) located -2° down from the centre of the screen. Fixation within a radius of 1.7° rendered the black and white at 5 Hz flashing fixation dot white and the cylinder appeared 5° vertically above it. Simultaneously two white choice targets appeared on each side +4.5° from the cylinder stimulus in the form of a circle and a cross (diameter = 1.5°). The cylinder was made up of 180 black and white dots placed on two transparent planes. The cylinder size was 6° by 6° and the dot diameter 0.2°. The cylinder disparities used to disambiguate the direction of rotation were: -0.03°, -0.02°, -0.015°, -0.01°, -0.005°, 0.00°, +0.005°, +0.01°, +0.015°, +0.02°, +0.03°. To prevent dot tracking, the mean dot lifetime was 45 frames (750 ms). Monkeys reported the rotation percept with a saccade to one of the two choice targets within a 2 second window. Correct trials were rewarded with juice. For ambiguous trials, only about half of the trials were rewarded. This was unintentionally only the rightward choices. Because the ambiguous trials are embedded within a large set of sub-threshold trials and are not distinguishable from these or even near-threshold trials (<xref ref-type="bibr" rid="R35">Nawrot &amp; Blake, 1993</xref>), this did not lead to a bias in behaviour. Overall, both monkeys made only about 55% rightward choices on ambiguous trials.</p></sec><sec id="S16"><title>Behavioural data and analysis</title><p id="P47">We implemented outlier removal for the reaction time data, as is common practice when fitting DDM and other models (<xref ref-type="bibr" rid="R5">Berger &amp; Kiefer, 2021</xref>; <xref ref-type="bibr" rid="R46">Ratcliff &amp; McKoon, 2008</xref>). The cut-off points were based on pre-existing literature as well as examination of the behavioural performance within certain time intervals, such as 150 – 190 ms (<xref ref-type="supplementary-material" rid="SD1">Supplementary figures 2-2 and 2-3</xref>; <xref ref-type="table" rid="T2">Table 2</xref>). Furthermore, 5% outlier removal was implemented within these boundaries in the HDDM fitting procedure to exclude the trials least likely to have been generated by a sequential sampling process for each model (<xref ref-type="bibr" rid="R46">Ratcliff &amp; McKoon, 2008</xref>).</p><p id="P48">Psychometric curves (<xref ref-type="fig" rid="F2">Figure 2</xref>) were fitted according to <xref ref-type="disp-formula" rid="FD1">Equation 1</xref>, describing a cumulative Gaussian distribution, where <italic>x</italic> is the level of signal, for example binocular disparity in degrees, <italic>μ</italic> is the mean of the distribution, equivalent to the bias, and <italic>σ</italic> is the standard deviation of the distribution, equivalent to the threshold. We used a nonlinear least-squares solver implemented in MATLAB (<italic>lsqcurvefit</italic>), which minimises the sum of squared errors, to estimate the two parameters. <disp-formula id="FD1"><label>(1)</label><mml:math id="M1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:mo>μ</mml:mo></mml:mrow><mml:mrow><mml:mo>σ</mml:mo><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:math></disp-formula></p></sec><sec id="S17"><title>DDM fitting</title><p id="P49">We used the hierarchical DDM (HDDM), a python toolbox for hierarchical Bayesian parameter estimation, to fit the model to our data (<xref ref-type="bibr" rid="R57">Wiecki et al., 2013</xref>). The HDDM allows simultaneous estimation of subject and group parameters, where individual subjects are assumed to be drawn from a group distribution. There are a number of different implementations of the DDM fitting frameworks, broadly comparable in performance (<xref ref-type="bibr" rid="R45">Ratcliff &amp; Childers, 2015</xref>; <xref ref-type="bibr" rid="R53">Shinn et al., 2020</xref>). HDDM was chosen as it implements a Bayesian framework and estimates distribution of parameters instead of point estimates allowing better exploration of parameter space and statistical analysis of parameters. The HDDM was also a good design for our multi-condition experiments across individual subjects due to its suitability for estimating parameters with fewer data points.</p><p id="P50">In these models, a time-dependent decision variable (DV) is driven by the sensory samples and represents the current amount of available evidence. The value of <italic>DV</italic> is described by a Wiener diffusion process, in which <italic>DV</italic> evolves via the stochastic differential equation <inline-formula><mml:math id="M2"><mml:mfrac><mml:mi>d</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mi>D</mml:mi><mml:mi>V</mml:mi><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> where <italic>v</italic> is the drift rate. The marginal distribution over <italic>DV</italic> at any given time <italic>t</italic> is described by <italic>N(vt, σ<sup>2</sup>t</italic>). The choices and corresponding RTs are treated as random variables described by the first passage times for this Wiener process (<xref ref-type="bibr" rid="R34">Navarro &amp; Fuss, 2009</xref>). We can expand the drift rate parameter to its intercept <italic>v<sub>0</sub></italic> and the scaling factor <italic>k</italic> which translates the signed normalised evidence signal strength according to <xref ref-type="disp-formula" rid="FD2">Equation 2</xref>. <disp-formula id="FD2"><label>(2)</label><mml:math id="M3"><mml:mi>v</mml:mi><mml:mo>=</mml:mo><mml:mi>k</mml:mi><mml:mo>⋅</mml:mo><mml:mtext>signal</mml:mtext><mml:mo>+</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></disp-formula></p><p id="P51">In our case, momentary motion or disparity evidence is integrated over time until it reaches one of two equidistant thresholds. The distance between these thresholds is governed by the boundary separation <italic>a</italic>. The starting point <italic>z</italic> determines whether the decision variable starts off closer to one threshold or the other. The influence of the perceptual evidence depends on the signed signal strength and a drift constant <italic>k</italic> according to <xref ref-type="disp-formula" rid="FD3">Equation 3</xref>. <disp-formula id="FD3"><label>(3)</label><mml:math id="M4"><mml:mfrac><mml:mi>d</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mi>D</mml:mi><mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:mi>k</mml:mi><mml:mo>⋅</mml:mo><mml:mtext>signal</mml:mtext><mml:mo>+</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mi>d</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mi>W</mml:mi></mml:math></disp-formula></p><p id="P52">A Monte Carlo Markov Chain (MCMC) was run for 5000 iterations for each model with the first 200 iterations being discarded. The posterior probability distributions therefore reflect the 4800 iterations. Subsequently, 4 more repetitions were run to assess convergence of the chains, both qualitatively as well as using the formal Gelman-Rubin statistic (<xref ref-type="bibr" rid="R20">Gelman &amp; Rubin, 1992</xref>). This lay between 0.99 and 1.01 in all cases except one (1.013), showing overall excellent convergence.</p><p id="P53">To simulate the data for a posterior predictive check, we used the built-in code within the HDDM package which simulates RT using discretized Wiener diffusion. We sampled 100 times from the MCMC trace of one model for each stimulus value and subsequently fed the parameters at those iterations into the function which estimated the first passage times of the Wiener process using an algorithm provided by (<xref ref-type="bibr" rid="R34">Navarro &amp; Fuss, 2009</xref>). A second DDM run was performed on trials identified by the GLM-HMM with the highest posterior probability for each state where the number of trials was qualitatively deemed sufficient per difficulty (at least 50).</p></sec><sec id="S18"><title>Dimensionality reduction</title><p id="P54">A supervised dimensionality reduction method was utilised to identify the main differences in the estimated DDM parameter space between the experimental conditions. We used the estimated parameter distribution derived from the 5 runs of the MCMC for the human data as input data. LDA produces <italic>C</italic> − 1 dimensions for <italic>C</italic> classes which optimally discriminate between them by simultaneously minimising within-class variance and maximising between-class variance. Numerically, this comprises diagonalisation of the within-class and subsequent between-class covariance matrices. A Python-based implementation of this procedure is available using the <italic>Scikit-learn</italic> package (<xref ref-type="bibr" rid="R42">Pedregosa et al., 2011</xref>).</p></sec><sec id="S19"><title>GLM-HMM</title><p id="P55">We followed closely the procedure outlined in (<xref ref-type="bibr" rid="R2">Ashwood et al., 2022</xref>) using the open-source Python-based code. Briefly, we created a GLM with the logistic function as link function predicting rightward choices and including several covariates; we explored the previously used covariates bias, previous choice, stimulus strength and based on log-likelihood analysis included all three. We used 5-fold cross-validation for humans and <italic>K</italic>-fold cross-validation for monkeys, based on the <italic>K</italic> number of sessions for each animal, and derived the log-likelihood from averaging over the log-likelihood obtained in each hold-out set for all iterations for the different models with a varying number of states to determine the best one. The log-likelihood itself was used by the expectation-maximisation algorithm as a means to estimate the posterior probability of the GLM-HMM parameters given the data by virtue of maximum likelihood estimation (MLE). It refers to the likelihood of observing the specified dataset (choice) given the set of parameters. In order to understand this quantity more meaningfully, we divided this quantity by the number of trials in order to obtain the log-likelihood per trial. On the basis of steepest change in log-likelihood, we used three states for the global fits. The model itself is fitted with the expectation-maximisation algorithm. Different initializations converged on the same three states almost without exception. Only the first 1029 trials were included in the human data GLM-HMM analysis due to a shortage of trials for some participants. As a control for any imbalance in the saccade/hand trials, we fitted separately each of the four human data groups (cylinder/saccade; cylinder/hand; RDK/saccades; RDK/hand). We found that the fitted states were almost identical for each pair with the same stimulus/different motor responses and confirmed the main difference between the two stimuli to be judged (<xref ref-type="supplementary-material" rid="SD1">Supplementary Figure 58</xref>).</p></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary Material</label><media xlink:href="EMS201278-supplement-Supplementary_Material.pdf" mimetype="application" mime-subtype="pdf" id="d14aAcFbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S20"><title>Acknowledgments</title><p>We thank Sarah Kriener for producing the stimulus videos, Jochen Braun for statistical analysis consultation, Nela Cicmil and Maria Rüsseler for animal training and behavioural data, Bashir Ahmed and Jackson Smith for help with the headpost implantation. This work was funded by the DFG (Heisenberg Professorship Project-ID 406269671; grants with Project-IDs 406679869 and 425899996 to K.K.) and the Wellcome Trust (101092/Z/13/Z; KK and AJP). KK is a PI in the SFB1436. Funding was also from the Max Planck Society and the Humboldt Foundation (PD). PD is a member of the Machine Learning Cluster of Excellence, EXC number 2064/1 – Project number 39072764 and of the Else Kröner Medical Scientist Kolleg "ClinbrAIn: Artificial Intelligence for Clinical Brain Research”.</p></ack><sec id="S21" sec-type="data-availability"><title>Code availability</title><p id="P56">All code used in the preparation of this article can be found at github.com/Revanchist317/DDM rangotis et al.</p></sec><ref-list><ref id="R1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahmed</surname><given-names>B</given-names></name><name><surname>Cordery</surname><given-names>PM</given-names></name><name><surname>McLelland</surname><given-names>D</given-names></name><name><surname>Bair</surname><given-names>W</given-names></name><name><surname>Krug</surname><given-names>K</given-names></name></person-group><article-title>Long-range clustered connections within extrastriate visual area V5/MT of the rhesus macaque</article-title><source>Cerebral Cortex (New York, NY: 1991)</source><year>2012</year><volume>22</volume><issue>1</issue><fpage>60</fpage><lpage>73</lpage><pub-id pub-id-type="pmid">21571693</pub-id></element-citation></ref><ref id="R2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashwood</surname><given-names>ZC</given-names></name><name><surname>Roy</surname><given-names>NA</given-names></name><name><surname>Stone</surname><given-names>IR</given-names></name><collab>International Brain Laboratory</collab><name><surname>Urai</surname><given-names>AE</given-names></name><name><surname>Churchland</surname><given-names>AK</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name><name><surname>Pillow</surname><given-names>JW</given-names></name></person-group><article-title>Mice alternate between discrete strategies during perceptual decision-making</article-title><source>Nature Neuroscience</source><year>2022</year><volume>25</volume><issue>2</issue><fpage>201</fpage><lpage>212</lpage><pub-id pub-id-type="pmcid">PMC8890994</pub-id><pub-id pub-id-type="pmid">35132235</pub-id><pub-id pub-id-type="doi">10.1038/s41593-021-01007-z</pub-id></element-citation></ref><ref id="R3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bair</surname><given-names>W</given-names></name><name><surname>Zohary</surname><given-names>E</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><article-title>Correlated firing in macaque visual area MT: Time scales and relationship to behavior</article-title><source>The Journal of Neuroscience: The Official Journal of the Society for Neuroscience</source><year>2001</year><volume>21</volume><issue>5</issue><fpage>1676</fpage><lpage>1697</lpage><pub-id pub-id-type="pmcid">PMC6762960</pub-id><pub-id pub-id-type="pmid">11222658</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.21-05-01676.2001</pub-id></element-citation></ref><ref id="R4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barlow</surname><given-names>HB</given-names></name></person-group><article-title>Single units and sensation: A neuron doctrine for perceptual psychology?</article-title><source>Perception</source><year>1972</year><volume>1</volume><issue>4</issue><fpage>371</fpage><lpage>394</lpage><pub-id pub-id-type="pmid">4377168</pub-id></element-citation></ref><ref id="R5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berger</surname><given-names>A</given-names></name><name><surname>Kiefer</surname><given-names>M</given-names></name></person-group><article-title>Comparison of Different Response Time Outlier Exclusion Methods: A Simulation Study</article-title><source>Frontiers in Psychology</source><year>2021</year><volume>12</volume><elocation-id>675558</elocation-id><pub-id pub-id-type="pmcid">PMC8238084</pub-id><pub-id pub-id-type="pmid">34194371</pub-id><pub-id pub-id-type="doi">10.3389/fpsyg.2021.675558</pub-id></element-citation></ref><ref id="R6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogacz</surname><given-names>R</given-names></name><name><surname>Brown</surname><given-names>E</given-names></name><name><surname>Moehlis</surname><given-names>J</given-names></name><name><surname>Holmes</surname><given-names>P</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><article-title>The physics of optimal decision making: A formal analysis of models of performance in two-alternative forced-choice tasks</article-title><source>Psychological Review</source><year>2006</year><volume>113</volume><issue>4</issue><fpage>700</fpage><lpage>765</lpage><pub-id pub-id-type="pmid">17014301</pub-id></element-citation></ref><ref id="R7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Born</surname><given-names>RT</given-names></name><name><surname>Bradley</surname><given-names>DC</given-names></name></person-group><article-title>Structure and function of visual area MT</article-title><source>Annual Review of Neuroscience</source><year>2005</year><volume>28</volume><fpage>157</fpage><lpage>189</lpage><pub-id pub-id-type="pmid">16022593</pub-id></element-citation></ref><ref id="R8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bradley</surname><given-names>DC</given-names></name><name><surname>Chang</surname><given-names>GC</given-names></name><name><surname>Andersen</surname><given-names>RA</given-names></name></person-group><article-title>Encoding of three-dimensional structure-from-motion by primate area MT neurons</article-title><source>Nature</source><year>1998</year><volume>392</volume><issue>6677</issue><fpage>714</fpage><lpage>717</lpage><pub-id pub-id-type="pmid">9565031</pub-id></element-citation></ref><ref id="R9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname><given-names>DH</given-names></name></person-group><article-title>The Psychophysics Toolbox</article-title><source>Spatial Vision</source><year>1997</year><volume>10</volume><issue>4</issue><fpage>433</fpage><lpage>436</lpage><pub-id pub-id-type="pmid">9176952</pub-id></element-citation></ref><ref id="R10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Braun</surname><given-names>A</given-names></name><name><surname>Urai</surname><given-names>AE</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><article-title>Adaptive History Biases Result from Confidence-Weighted Accumulation of past Choices</article-title><source>The Journal of Neuroscience: The Official Journal of the Society for Neuroscience</source><year>2018</year><volume>38</volume><issue>10</issue><fpage>2418</fpage><lpage>2429</lpage><pub-id pub-id-type="pmcid">PMC5858589</pub-id><pub-id pub-id-type="pmid">29371318</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2189-17.2017</pub-id></element-citation></ref><ref id="R11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Britten</surname><given-names>KH</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Celebrini</surname><given-names>S</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><article-title>A relationship between behavioral choice and the visual responses of neurons in macaque MT</article-title><source>Visual Neuroscience</source><year>1996</year><volume>13</volume><issue>1</issue><fpage>87</fpage><lpage>100</lpage><pub-id pub-id-type="pmid">8730992</pub-id></element-citation></ref><ref id="R12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Britten</surname><given-names>KH</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><article-title>The analysis of visual motion: A comparison of neuronal and psychophysical performance</article-title><source>The Journal of Neuroscience: The Official Journal of the Society for Neuroscience</source><year>1992</year><volume>12</volume><issue>12</issue><fpage>4745</fpage><lpage>4765</lpage><pub-id pub-id-type="pmcid">PMC6575768</pub-id><pub-id pub-id-type="pmid">1464765</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.12-12-04745.1992</pub-id></element-citation></ref><ref id="R13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>SD</given-names></name><name><surname>Heathcote</surname><given-names>A</given-names></name></person-group><article-title>The simplest complete model of choice response time: Linear ballistic accumulation</article-title><source>Cognitive Psychology</source><year>2008</year><volume>57</volume><issue>3</issue><fpage>153</fpage><lpage>178</lpage><pub-id pub-id-type="pmid">18243170</pub-id></element-citation></ref><ref id="R14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crawford</surname><given-names>JR</given-names></name><name><surname>Howell</surname><given-names>DC</given-names></name></person-group><article-title>Comparing an Individual’s Test Score Against Norms Derived from Small Samples</article-title><source>The Clinical Neuropsychologist</source><year>1998</year><volume>12</volume><issue>4</issue><fpage>482</fpage><lpage>486</lpage><pub-id pub-id-type="doi">10.1076/clin.12.4.482.7241</pub-id></element-citation></ref><ref id="R15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Lafuente</surname><given-names>V</given-names></name><name><surname>Jazayeri</surname><given-names>M</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><article-title>Representation of accumulating evidence for a decision in two parietal areas</article-title><source>The Journal of Neuroscience: The Official Journal of the Society for Neuroscience</source><year>2015</year><volume>35</volume><issue>10</issue><fpage>4306</fpage><lpage>4318</lpage><pub-id pub-id-type="pmcid">PMC4355201</pub-id><pub-id pub-id-type="pmid">25762677</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2451-14.2015</pub-id></element-citation></ref><ref id="R16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeAngelis</surname><given-names>GC</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><article-title>Organization of disparity-selective neurons in macaque area MT</article-title><source>The Journal of Neuroscience: The Official Journal of the Society for Neuroscience</source><year>1999</year><volume>19</volume><issue>4</issue><fpage>1398</fpage><lpage>1415</lpage><pub-id pub-id-type="pmcid">PMC6786027</pub-id><pub-id pub-id-type="pmid">9952417</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.19-04-01398.1999</pub-id></element-citation></ref><ref id="R17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dodd</surname><given-names>JV</given-names></name><name><surname>Krug</surname><given-names>K</given-names></name><name><surname>Cumming</surname><given-names>BG</given-names></name><name><surname>Parker</surname><given-names>AJ</given-names></name></person-group><article-title>Perceptually bistable three-dimensional figures evoke high choice probabilities in cortical area MT</article-title><source>The Journal of Neuroscience: The Official Journal of the Society for Neuroscience</source><year>2001</year><volume>21</volume><issue>13</issue><fpage>4809</fpage><lpage>4821</lpage><pub-id pub-id-type="pmcid">PMC6762355</pub-id><pub-id pub-id-type="pmid">11425908</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.21-13-04809.2001</pub-id></element-citation></ref><ref id="R18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fan</surname><given-names>Y</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Ding</surname><given-names>L</given-names></name></person-group><article-title>Ongoing, rational calibration of reward-driven perceptual biases</article-title><source>eLife</source><year>2018</year><volume>7</volume><elocation-id>e36018</elocation-id><pub-id pub-id-type="pmcid">PMC6203438</pub-id><pub-id pub-id-type="pmid">30303484</pub-id><pub-id pub-id-type="doi">10.7554/eLife.36018</pub-id></element-citation></ref><ref id="R19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Forstmann</surname><given-names>BU</given-names></name><name><surname>Ratcliff</surname><given-names>R</given-names></name><name><surname>Wagenmakers</surname><given-names>E-J</given-names></name></person-group><article-title>Sequential Sampling Models in Cognitive Neuroscience: Advantages, Applications, and Extensions</article-title><source>Annual Review of Psychology</source><year>2016</year><volume>67</volume><fpage>641</fpage><lpage>666</lpage><pub-id pub-id-type="pmcid">PMC5112760</pub-id><pub-id pub-id-type="pmid">26393872</pub-id><pub-id pub-id-type="doi">10.1146/annurev-psych-122414-033645</pub-id></element-citation></ref><ref id="R20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gelman</surname><given-names>A</given-names></name><name><surname>Rubin</surname><given-names>DB</given-names></name></person-group><article-title>Inference from Iterative Simulation Using Multiple Sequences</article-title><source>Statistical Science</source><year>1992</year><volume>7</volume><issue>4</issue><fpage>457</fpage><lpage>472</lpage></element-citation></ref><ref id="R21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><article-title>Representation of a perceptual decision in developing oculomotor commands</article-title><source>Nature</source><year>2000</year><volume>404</volume><issue>6776</issue><fpage>390</fpage><lpage>394</lpage><pub-id pub-id-type="pmid">10746726</pub-id></element-citation></ref><ref id="R22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><article-title>The neural basis of decision making</article-title><source>Annual Review of Neuroscience</source><year>2007</year><volume>30</volume><fpage>535</fpage><lpage>574</lpage><pub-id pub-id-type="pmid">17600525</pub-id></element-citation></ref><ref id="R23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haefner</surname><given-names>RM</given-names></name><name><surname>Berkes</surname><given-names>P</given-names></name><name><surname>Fiser</surname><given-names>J</given-names></name></person-group><article-title>Perceptual Decision-Making as Probabilistic Inference by Neural Sampling</article-title><source>Neuron</source><year>2016</year><volume>90</volume><issue>3</issue><fpage>649</fpage><lpage>660</lpage><pub-id pub-id-type="pmid">27146267</pub-id></element-citation></ref><ref id="R24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanks</surname><given-names>TD</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name></person-group><article-title>Perceptual Decision Making in Rodents, Monkeys, and Humans</article-title><source>Neuron</source><year>2017</year><volume>93</volume><issue>1</issue><fpage>15</fpage><lpage>31</lpage><pub-id pub-id-type="pmid">28056343</pub-id></element-citation></ref><ref id="R25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heekeren</surname><given-names>HR</given-names></name><name><surname>Marrett</surname><given-names>S</given-names></name><name><surname>Bandettini</surname><given-names>PA</given-names></name><name><surname>Ungerleider</surname><given-names>LG</given-names></name></person-group><article-title>A general mechanism for perceptual decision-making in the human brain</article-title><source>Nature</source><year>2004</year><volume>431</volume><issue>7010</issue><fpage>859</fpage><lpage>862</lpage><pub-id pub-id-type="pmid">15483614</pub-id></element-citation></ref><ref id="R26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horwitz</surname><given-names>GD</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><article-title>Target selection for saccadic eye movements: Prelude activity in the superior colliculus during a direction-discrimination task</article-title><source>Journal of Neurophysiology</source><year>2001</year><volume>86</volume><issue>5</issue><fpage>2543</fpage><lpage>2558</lpage><pub-id pub-id-type="pmid">11698541</pub-id></element-citation></ref><ref id="R27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>JN</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><article-title>Neural correlates of a decision in the dorsolateral prefrontal cortex of the macaque</article-title><source>Nature Neuroscience</source><year>1999</year><volume>2</volume><issue>2</issue><fpage>176</fpage><lpage>185</lpage><pub-id pub-id-type="pmid">10195203</pub-id></element-citation></ref><ref id="R28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krajbich</surname><given-names>I</given-names></name><name><surname>Armel</surname><given-names>C</given-names></name><name><surname>Rangel</surname><given-names>A</given-names></name></person-group><article-title>Visual fixations and the computation and comparison of value in simple choice</article-title><source>Nature Neuroscience</source><year>2010</year><volume>13</volume><issue>10</issue><fpage>1292</fpage><lpage>1298</lpage><pub-id pub-id-type="pmid">20835253</pub-id></element-citation></ref><ref id="R29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krug</surname><given-names>K</given-names></name></person-group><article-title>A common neuronal code for perceptual processes in visual cortex? Comparing choice and attentional correlates in V5/MT</article-title><source>Philosophical Transactions of the Royal Society of London Series B, Biological Sciences</source><year>2004</year><volume>359</volume><issue>1446</issue><fpage>929</fpage><lpage>941</lpage><pub-id pub-id-type="pmcid">PMC1693376</pub-id><pub-id pub-id-type="pmid">15306408</pub-id><pub-id pub-id-type="doi">10.1098/rstb.2003.1415</pub-id></element-citation></ref><ref id="R30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krug</surname><given-names>K</given-names></name></person-group><article-title>Coding Perceptual Decisions: From Single Units to Emergent Signaling Properties in Cortical Circuits</article-title><source>Annual Review of Vision Science</source><year>2020</year><volume>6</volume><fpage>387</fpage><lpage>409</lpage><pub-id pub-id-type="pmid">32600168</pub-id></element-citation></ref><ref id="R31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krug</surname><given-names>K</given-names></name><name><surname>Cicmil</surname><given-names>N</given-names></name><name><surname>Parker</surname><given-names>AJ</given-names></name><name><surname>Cumming</surname><given-names>BG</given-names></name></person-group><article-title>A causal role for V5/MT neurons coding motion-disparity conjunctions in resolving perceptual ambiguity</article-title><source>Current Biology: CB</source><year>2013</year><volume>23</volume><issue>15</issue><fpage>1454</fpage><lpage>1459</lpage><pub-id pub-id-type="pmcid">PMC3739008</pub-id><pub-id pub-id-type="pmid">23871244</pub-id><pub-id pub-id-type="doi">10.1016/j.cub.2013.06.023</pub-id></element-citation></ref><ref id="R32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Middlebrooks</surname><given-names>PG</given-names></name><name><surname>Schall</surname><given-names>JD</given-names></name></person-group><article-title>Response inhibition during perceptual decision making in humans and macaques</article-title><source>Atten Percept Psychophys</source><year>2014</year><volume>76</volume><fpage>353</fpage><lpage>66</lpage><pub-id pub-id-type="pmcid">PMC4141461</pub-id><pub-id pub-id-type="pmid">24306985</pub-id><pub-id pub-id-type="doi">10.3758/s13414-013-0599-6</pub-id></element-citation></ref><ref id="R33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mohammadi</surname><given-names>Z</given-names></name><name><surname>Ashwood</surname><given-names>ZC</given-names></name><name><surname>Laboratory</surname><given-names>TIB</given-names></name><name><surname>Pillow</surname><given-names>JW</given-names></name></person-group><article-title>Identifying the factors governing internal state switches during nonstationary sensory decision-making</article-title><source>bioRxiv</source><year>2024</year><elocation-id>2024.02.02.578482</elocation-id><pub-id pub-id-type="doi">10.1101/2024.02.02.578482</pub-id></element-citation></ref><ref id="R34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Navarro</surname><given-names>DJ</given-names></name><name><surname>Fuss</surname><given-names>IG</given-names></name></person-group><article-title>Fast and accurate calculations for first-passage times in Wiener diffusion models</article-title><source>Journal of Mathematical Psychology</source><year>2009</year><volume>53</volume><issue>4</issue><fpage>222</fpage><lpage>230</lpage><pub-id pub-id-type="doi">10.1016/j.jmp.2009.02.003</pub-id></element-citation></ref><ref id="R35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nawrot</surname><given-names>M</given-names></name><name><surname>Blake</surname><given-names>R</given-names></name></person-group><article-title>On the perceptual identity of dynamic stereopsis and kinetic depth</article-title><source>Vision Research</source><year>1993</year><volume>33</volume><issue>11</issue><fpage>1561</fpage><lpage>1571</lpage><pub-id pub-id-type="pmid">8351828</pub-id></element-citation></ref><ref id="R36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nestler</surname><given-names>EJ</given-names></name><name><surname>Hyman</surname><given-names>SE</given-names></name></person-group><article-title>Animal models of neuropsychiatric disorders</article-title><source>Nature Neuroscience</source><year>2010</year><volume>13</volume><issue>10</issue><fpage>1161</fpage><lpage>1169</lpage><pub-id pub-id-type="pmcid">PMC3750731</pub-id><pub-id pub-id-type="pmid">20877280</pub-id><pub-id pub-id-type="doi">10.1038/nn.2647</pub-id></element-citation></ref><ref id="R37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newsome</surname><given-names>WT</given-names></name><name><surname>Britten</surname><given-names>KH</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><article-title>Neuronal correlates of a perceptual decision</article-title><source>Nature</source><year>1989</year><volume>341</volume><issue>6237</issue><fpage>52</fpage><lpage>54</lpage><pub-id pub-id-type="pmid">2770878</pub-id></element-citation></ref><ref id="R38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nienborg</surname><given-names>H</given-names></name><name><surname>Cohen</surname><given-names>MR</given-names></name><name><surname>Cumming</surname><given-names>BG</given-names></name></person-group><article-title>Decision-related activity in sensory neurons: Correlations among neurons and with behavior</article-title><source>Annual Review of Neuroscience</source><year>2012</year><volume>35</volume><fpage>463</fpage><lpage>483</lpage><pub-id pub-id-type="pmid">22483043</pub-id></element-citation></ref><ref id="R39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nienborg</surname><given-names>H</given-names></name><name><surname>Cumming</surname><given-names>BG</given-names></name></person-group><article-title>Decision-related activity in sensory neurons reflects more than a neuron’s causal effect</article-title><source>Nature</source><year>2009</year><volume>459</volume><issue>7243</issue><fpage>89</fpage><lpage>92</lpage><pub-id pub-id-type="pmcid">PMC2917918</pub-id><pub-id pub-id-type="pmid">19270683</pub-id><pub-id pub-id-type="doi">10.1038/nature07821</pub-id></element-citation></ref><ref id="R40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parker</surname><given-names>AJ</given-names></name><name><surname>Krug</surname><given-names>K</given-names></name></person-group><article-title>Neuronal mechanisms for the perception of ambiguous stimuli</article-title><source>Current Opinion in Neurobiology</source><year>2003</year><volume>13</volume><issue>4</issue><fpage>433</fpage><lpage>439</lpage><pub-id pub-id-type="pmid">12965290</pub-id></element-citation></ref><ref id="R41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parker</surname><given-names>AJ</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><article-title>Sense and the single neuron: Probing the physiology of perception</article-title><source>Annual Review of Neuroscience</source><year>1998</year><volume>21</volume><fpage>227</fpage><lpage>277</lpage><pub-id pub-id-type="pmid">9530497</pub-id></element-citation></ref><ref id="R42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F</given-names></name><name><surname>Varoquaux</surname><given-names>G</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Michel</surname><given-names>V</given-names></name><name><surname>Thirion</surname><given-names>B</given-names></name><name><surname>Grisel</surname><given-names>O</given-names></name><name><surname>Blondel</surname><given-names>M</given-names></name><name><surname>Prettenhofer</surname><given-names>P</given-names></name><name><surname>Weiss</surname><given-names>R</given-names></name><name><surname>Dubourg</surname><given-names>V</given-names></name><name><surname>Vanderplas</surname><given-names>J</given-names></name><etal/></person-group><article-title>Scikit-learn: Machine Learning in Python</article-title><source>Journal of Machine Learning Research</source><year>2011</year><volume>12</volume><issue>85</issue><fpage>2825</fpage><lpage>2830</lpage></element-citation></ref><ref id="R43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Purcell</surname><given-names>BA</given-names></name><name><surname>Kiani</surname><given-names>R</given-names></name></person-group><article-title>Hierarchical decision processes that operate over distinct timescales underlie choice and changes in strategy</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><year>2016</year><volume>113</volume><issue>31</issue><fpage>E4531</fpage><lpage>4540</lpage><pub-id pub-id-type="pmcid">PMC4978308</pub-id><pub-id pub-id-type="pmid">27432960</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1524685113</pub-id></element-citation></ref><ref id="R44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratcliff</surname><given-names>R</given-names></name></person-group><article-title>A theory of memory retrieval</article-title><source>Psychological Review</source><year>1978</year><volume>85</volume><issue>2</issue><fpage>59</fpage><lpage>108</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.85.2.59</pub-id></element-citation></ref><ref id="R45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratcliff</surname><given-names>R</given-names></name><name><surname>Childers</surname><given-names>R</given-names></name></person-group><article-title>Individual Differences and Fitting Methods for the Two-Choice Diffusion Model of Decision Making</article-title><source>Decision (Washington, DC)</source><year>2015</year><volume>2015</volume><pub-id pub-id-type="pmcid">PMC4517692</pub-id><pub-id pub-id-type="pmid">26236754</pub-id><pub-id pub-id-type="doi">10.1037/dec0000030</pub-id></element-citation></ref><ref id="R46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratcliff</surname><given-names>R</given-names></name><name><surname>McKoon</surname><given-names>G</given-names></name></person-group><article-title>The diffusion decision model: Theory and data for two-choice decision tasks</article-title><source>Neural Computation</source><year>2008</year><volume>20</volume><issue>4</issue><fpage>873</fpage><lpage>922</lpage><pub-id pub-id-type="pmcid">PMC2474742</pub-id><pub-id pub-id-type="pmid">18085991</pub-id><pub-id pub-id-type="doi">10.1162/neco.2008.12-06-420</pub-id></element-citation></ref><ref id="R47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratcliff</surname><given-names>R</given-names></name><name><surname>Smith</surname><given-names>PL</given-names></name><name><surname>Brown</surname><given-names>SD</given-names></name><name><surname>McKoon</surname><given-names>G</given-names></name></person-group><article-title>Diffusion Decision Model: Current Issues and History</article-title><source>Trends in Cognitive Sciences</source><year>2016</year><volume>20</volume><issue>4</issue><fpage>260</fpage><lpage>281</lpage><pub-id pub-id-type="pmcid">PMC4928591</pub-id><pub-id pub-id-type="pmid">26952739</pub-id><pub-id pub-id-type="doi">10.1016/j.tics.2016.01.007</pub-id></element-citation></ref><ref id="R48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roitman</surname><given-names>JD</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><article-title>Response of neurons in the lateral intraparietal area during a combined visual discrimination reaction time task</article-title><source>The Journal of Neuroscience: The Official Journal of the Society for Neuroscience</source><year>2002</year><volume>22</volume><issue>21</issue><fpage>9475</fpage><lpage>9489</lpage><pub-id pub-id-type="pmcid">PMC6758024</pub-id><pub-id pub-id-type="pmid">12417672</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.22-21-09475.2002</pub-id></element-citation></ref><ref id="R49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roy</surname><given-names>NA</given-names></name><name><surname>Bak</surname><given-names>JH</given-names></name><name><surname>Akrami</surname><given-names>A</given-names></name><collab>International Brain Laboratory</collab><name><surname>Brody</surname><given-names>CD</given-names></name><name><surname>Pillow</surname><given-names>JW</given-names></name></person-group><article-title>Extracting the dynamics of behavior in sensory decision-making experiments</article-title><source>Neuron</source><year>2021</year><volume>109</volume><issue>4</issue><fpage>597</fpage><lpage>610</lpage><elocation-id>e6</elocation-id><pub-id pub-id-type="pmcid">PMC7897255</pub-id><pub-id pub-id-type="pmid">33412101</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2020.12.004</pub-id></element-citation></ref><ref id="R50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salzman</surname><given-names>CD</given-names></name><name><surname>Britten</surname><given-names>KH</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><article-title>Cortical microstimulation influences perceptual judgements of motion direction</article-title><source>Nature</source><year>1990</year><volume>346</volume><issue>6280</issue><fpage>174</fpage><lpage>177</lpage><pub-id pub-id-type="pmid">2366872</pub-id></element-citation></ref><ref id="R51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Britten</surname><given-names>KH</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><article-title>A computational analysis of the relationship between neuronal and behavioral responses to visual motion</article-title><source>The Journal of Neuroscience: The Official Journal of the Society for Neuroscience</source><year>1996</year><volume>16</volume><issue>4</issue><fpage>1486</fpage><lpage>1510</lpage><pub-id pub-id-type="pmcid">PMC6578557</pub-id><pub-id pub-id-type="pmid">8778300</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.16-04-01486.1996</pub-id></element-citation></ref><ref id="R52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><article-title>Neural basis of a perceptual decision in the parietal cortex (area LIP) of the rhesus monkey</article-title><source>Journal of Neurophysiology</source><year>2001</year><volume>86</volume><issue>4</issue><fpage>1916</fpage><lpage>1936</lpage><pub-id pub-id-type="pmid">11600651</pub-id></element-citation></ref><ref id="R53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shinn</surname><given-names>M</given-names></name><name><surname>Lam</surname><given-names>NH</given-names></name><name><surname>Murray</surname><given-names>JD</given-names></name></person-group><article-title>A flexible framework for simulating and fitting generalized drift-diffusion models</article-title><source>eLife</source><year>2020</year><volume>9</volume><elocation-id>e56938</elocation-id><pub-id pub-id-type="pmcid">PMC7462609</pub-id><pub-id pub-id-type="pmid">32749218</pub-id><pub-id pub-id-type="doi">10.7554/eLife.56938</pub-id></element-citation></ref><ref id="R54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Usher</surname><given-names>M</given-names></name><name><surname>McClelland</surname><given-names>JL</given-names></name></person-group><article-title>The time course of perceptual choice: The leaky, competing accumulator model</article-title><source>Psychological Review</source><year>2001</year><volume>108</volume><issue>3</issue><fpage>550</fpage><lpage>592</lpage><pub-id pub-id-type="pmid">11488378</pub-id></element-citation></ref><ref id="R55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Voss</surname><given-names>A</given-names></name><name><surname>Rothermund</surname><given-names>K</given-names></name><name><surname>Voss</surname><given-names>J</given-names></name></person-group><article-title>Interpreting the parameters of the diffusion model: An empirical validation</article-title><source>Memory &amp; Cognition</source><year>2004</year><volume>32</volume><issue>7</issue><fpage>1206</fpage><lpage>1220</lpage><pub-id pub-id-type="pmid">15813501</pub-id></element-citation></ref><ref id="R56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wasmuht</surname><given-names>DF</given-names></name><name><surname>Parker</surname><given-names>AJ</given-names></name><name><surname>Krug</surname><given-names>K</given-names></name></person-group><article-title>Interneuronal correlations at longer time scales predict decision signals for bistable structure-from-motion perception</article-title><source>Scientific Reports</source><year>2019</year><volume>9</volume><issue>1</issue><elocation-id>11449</elocation-id><pub-id pub-id-type="pmcid">PMC6686021</pub-id><pub-id pub-id-type="pmid">31391489</pub-id><pub-id pub-id-type="doi">10.1038/s41598-019-47786-1</pub-id></element-citation></ref><ref id="R57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiecki</surname><given-names>TV</given-names></name><name><surname>Sofer</surname><given-names>I</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><article-title>HDDM: Hierarchical Bayesian estimation of the Drift-Diffusion Model in Python</article-title><source>Frontiers in Neuroinformatics</source><year>2013</year><volume>7</volume><fpage>14</fpage><pub-id pub-id-type="pmcid">PMC3731670</pub-id><pub-id pub-id-type="pmid">23935581</pub-id><pub-id pub-id-type="doi">10.3389/fninf.2013.00014</pub-id></element-citation></ref><ref id="R58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wimmer</surname><given-names>K</given-names></name><name><surname>Compte</surname><given-names>A</given-names></name><name><surname>Roxin</surname><given-names>A</given-names></name><name><surname>Peixoto</surname><given-names>D</given-names></name><name><surname>Renart</surname><given-names>A</given-names></name><name><surname>de la Rocha</surname><given-names>J</given-names></name></person-group><article-title>Sensory integration dynamics in a hierarchical network explains choice probabilities in cortical area MT</article-title><source>Nature Communications</source><year>2015</year><volume>6</volume><elocation-id>6177</elocation-id><pub-id pub-id-type="pmcid">PMC4347303</pub-id><pub-id pub-id-type="pmid">25649611</pub-id><pub-id pub-id-type="doi">10.1038/ncomms7177</pub-id></element-citation></ref><ref id="R59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zohary</surname><given-names>E</given-names></name><name><surname>Celebrini</surname><given-names>S</given-names></name><name><surname>Britten</surname><given-names>KH</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><article-title>Neuronal plasticity that underlies improvement in perceptual performance</article-title><source>Science (New York, NY)</source><year>1994</year><volume>263</volume><issue>5151</issue><fpage>1289</fpage><lpage>1292</lpage><pub-id pub-id-type="pmid">8122114</pub-id></element-citation></ref><ref id="R60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zohary</surname><given-names>E</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><article-title>Correlated neuronal discharge rate and its implications for psychophysical performance</article-title><source>Nature</source><year>1994</year><volume>370</volume><issue>6485</issue><fpage>140</fpage><lpage>143</lpage><pub-id pub-id-type="pmid">8022482</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>Task design and theoretical framework.</title><p><bold>A.</bold> Illustration of the trajectory of the decision process within the DDM framework with the key parameters and the distributions of reaction times for each decision. Non-decision time <italic>t</italic> is the mean minimum time for a participant to respond, related to stimulus encoding and motor processes. The evidence accumulation process, parametrised by the drift rate <italic>v</italic>, describing its slope, is given by the equation <italic>v = ko signal</italic> + v<sub>0</sub> where “signal” is the normalised strength of the stimulus information, such as percentage coherence, and <italic>v<sub>0</sub></italic> is the intercept of the drift rate. <italic>a</italic> is the separation of the two decision boundaries, defining how much evidence is required before a decision is made. If <italic>z</italic> = 0.5, the decision boundaries are symmetrical around the starting point. The blue line represents evidence accumulation on one trial, the dashed orange line the average drift rate for one level of signed signal strength. <bold>B.</bold> We investigate the decision processes and behavioural strategies in perceptual judgements about the direction of motion in a random dot kinematogram (RDK) and about the rotation direction of a 3D structure-from-motion (SfM) cylinder in a reaction time (RT) task. In different experimental sessions, human and monkey participants reported their decisions on one of the two stimuli and with either a saccadic eye movement or a hand movement. We varied the stimulus information, i.e., motion coherence in the RDK and binocular disparity in the cylinder, across trials. <bold>C.</bold> This schematic illustrates the task design for eye movement responses. Upon successful fixation, an RDK or a 3D SfM cylinder stimulus was presented together with two choice targets, placed to the left and right of the stimulus. For hand movement responses, RDKs for the monkeys were also presented with two choice targets on a touchscreen, but for humans there were no choice targets on the screen as button presses were used to report instead.</p></caption><graphic xlink:href="EMS201278-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Psychophysical performance of humans and monkeys.</title><p><bold>A.</bold> We fitted cumulative Gaussian functions to the psychophysical response data separately for individual humans and for individual monkeys (m133, m134) for each perceptual decision task (3D SfM cylinder rotation; RDK direction of motion). For the cylinder, the binocular disparity units are degrees visual angle (DVA), while the RDK coherence is the percentage of the dots moving coherently in a specific direction. Overall, the performance of the humans (black) and monkeys (colored) is broadly comparable, but the monkeys’ thresholds were at the high end in comparison with the human sample. Individual data points correspond to proportions of choices pooled across sessions (monkeys) or across participants (humans) and the errors bars depict the SEM. <bold>B.</bold> Reaction time (RT) distributions for humans and monkeys. Negative reaction times represent incorrect responses. Solid lines show the pooled human participants (20), whereas the dashed lines show distribution for each of the monkeys pooled across all of their sessions. Again, the results are broadly comparable, but the monkeys made faster decisions, especially when they reported the rotation direction of the 3D SfM cylinder with an eye movement. For full RTs by stimulus strength see <xref ref-type="supplementary-material" rid="SD1">Supplementary Figures 2-1</xref> and for outlier removal <xref ref-type="supplementary-material" rid="SD1">Supplementary Figures 2-2 and 2-3</xref>.</p></caption><graphic xlink:href="EMS201278-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Pair-wise comparison of estimated parameters for the DDM.</title><p>DDM Parameters are shown separately for humans (n = 20, upper panel) and monkeys (n = 2, bottom panel) as scatterplots with kernel density estimates on the diagonal. There are statistically significant differences (panels with dashed black outlines) between the parameter distributions for boundary separation <italic>a</italic> and drift constant <italic>k</italic>, for both monkeys and humans, between the different stimulus types (3D SfM cylinder vs RDK motion—see main text for statistics). The boundary separation <italic>a</italic> is lower for the cylinder rotation task determined by binocular depth than for the direction discrimination task with the RDK in both species, regardless of the type of motor response. The drift constant <italic>k</italic> also differs systematically for the two stimuli. It is higher for humans judging RDK motion direction. There is also a clear difference for the monkeys but here the pattern is reversed with the cylinder task showing a higher drift constant <italic>k</italic>. There is no systematic difference with response mode. The monkey data also reflect some of the individual differences between the animals, for instance m133 showed different reaction times when responding left or right on the touch screen (see <xref ref-type="supplementary-material" rid="SD1">Supplementary Figure 3-1</xref>). This is reflected in the bias <italic>z</italic>.</p></caption><graphic xlink:href="EMS201278-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Linear discriminant analysis (LDA) confirms differences with visual stimulus type.</title><p>The first two linear discriminant dimensions of the LDA for the estimated DDM parameters were plotted along the abscissa and ordinate, respectively. The estimated parameters for the human data are depicted as contour plots (representing iso-proportions of probability density), red and orange for the 3D SfM cylinder task and blue and green for the RDK direction discrimination task. LD1 clearly discriminates the clusters by stimulus type, with a smaller difference but considerable overlap on LD2 by response mode. The estimated parameters for the monkey data were projected in the form of scatter points onto this space by transforming it with the vectors derived using the human data. The two monkeys also show along LD1 a clear segregation of the DDM parameters by stimulus type about which perceptual decisions are made, although with a sign reversal to the humans. They show some differentiation by response mode along LD2, but with sizeable individual differences.</p></caption><graphic xlink:href="EMS201278-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>The GLM-HMM analysis reveals distinct behavioral states for perceptual decisions.</title><p><bold>A</bold>. The global fits for the human participants (n = 20) show three distinct states for each stimulus type. The three states between which the participants switch vary for judgements about RDK direction of motion and 3D SfM cylinders, especially in the engagement level (influence of the stimulus) and the direction of the effect of previous choices on the current choice. <bold>B</bold>. The posterior probability of being in each state for an example participant performing the cylinder and the RDK task fluctuates more between the three states for the RDK stimulus than for the SfM cylinder (see <xref ref-type="supplementary-material" rid="SD1">Supplementary Figures 5-3, 5-4</xref> for all individual participants). The dash-dotted line separates trials with the hand responses on the left side and the saccadic response on the right side (see <xref ref-type="sec" rid="S11">Methods</xref>). <bold>C</bold>. The fractional occupancies, or the proportion of trials in which the posterior probability was highest for a certain state, show that for the cylinder stimulus, human participants spent most of the time in a strongly engaged state without much evidence for a behavioural or perceptual bias. In contrast, for judgements of the RDK stimulus, humans switched between two engaged states, one with a strong bias influencing perceptual decision-making. <bold>D</bold>. When the human data was grouped for the mode of response, the three states appeared qualitatively very similar between the hand- and eye-responses.</p></caption><graphic xlink:href="EMS201278-f005"/></fig><table-wrap id="T1" position="float" orientation="portrait"><label>Table 1</label><caption><title>The four experimental orders the human participants were randomly assigned to, forming balanced groups of 5.</title><p>C = Cylinder; R = RDK; S = Saccades; B = Buttons</p></caption><table frame="box" rules="all"><thead><tr><th align="left" valign="middle">Experimental order</th><th align="left" valign="middle">Sequence of sessions</th></tr></thead><tbody><tr><td align="left" valign="middle">1</td><td align="left" valign="middle">CS, RS, CB, RB</td></tr><tr><td align="left" valign="middle">2</td><td align="left" valign="middle">CB, RB, CS, Rs</td></tr><tr><td align="left" valign="middle">3</td><td align="left" valign="middle">RS, CS, RB, CB</td></tr><tr><td align="left" valign="middle">4</td><td align="left" valign="middle">RB, CB, RS, CS</td></tr></tbody></table></table-wrap><table-wrap id="T2" position="float" orientation="portrait"><label>Table 2</label><caption><title>The outlier removal used in data pre-processing.</title><p>The 98<sup>th</sup> and 99<sup>th</sup> percentile as the upper outlier boundaries were chosen to best capture the bulk of the distribution in each case since the distributions differed in their skewness. Because the trials of the cylinder task for each monkey were more numerous as well as more compactly distributed (with a shorter right tail), we opted to include one more percentile than for the RDK data.</p></caption><table frame="box" rules="all"><thead><tr><th align="left" valign="middle"/><th align="left" valign="middle" colspan="2">Humans</th><th align="left" valign="middle" colspan="2">monkeys</th></tr><tr><th align="left" valign="middle"/><th align="left" valign="middle">RDK</th><th align="left" valign="middle">Cylinder</th><th align="left" valign="middle">RDK</th><th align="left" valign="middle">Cylinder</th></tr></thead><tbody><tr><td align="left" valign="middle">Lower outlier boundary</td><td align="left" valign="top">250 ms</td><td align="left" valign="top">250 ms</td><td align="left" valign="top">250 ms</td><td align="left" valign="top">190 ms</td></tr><tr><td align="left" valign="middle">Upper outlier boundary</td><td align="left" valign="top">95<sup>th</sup> percentile</td><td align="left" valign="top">95<sup>th</sup> percentile</td><td align="left" valign="top">98<sup>th</sup> percentile</td><td align="left" valign="top">99<sup>th</sup> percentile</td></tr></tbody></table></table-wrap></floats-group></article>