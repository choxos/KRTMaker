<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS199988</article-id><article-id pub-id-type="doi">10.1101/2024.11.07.622453</article-id><article-id pub-id-type="archive">PPR937304</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">2</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Neural Representation of Time across Complementary Reference Frames</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Xu</surname><given-names>Yangwen</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><contrib contrib-type="author"><name><surname>Sartorato</surname><given-names>Nicola</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A3">3</xref><xref ref-type="aff" rid="A4">4</xref></contrib><contrib contrib-type="author"><name><surname>Dutriaux</surname><given-names>Léo</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A5">5</xref></contrib><contrib contrib-type="author"><name><surname>Bottini</surname><given-names>Roberto</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><aff id="A1"><label>1</label>Center for Mind/Brain Sciences, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/05trd4x28</institution-id><institution>University of Trento</institution></institution-wrap>, <city>Trento</city>, <country country="IT">Italy</country></aff><aff id="A2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0387jng26</institution-id><institution>Max Planck Institute for Human Cognitive and Brain Sciences</institution></institution-wrap>, <city>Leipzig</city>, <country country="GE">Germany</country></aff><aff id="A3"><label>3</label>Institute of Neurobiology, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/03a1kwz48</institution-id><institution>University of Tübingen</institution></institution-wrap>, <city>Tübingen</city>, <country country="GE">Germany</country></aff><aff id="A4"><label>4</label>Werner-Reichardt Centre for Integrative Neuroscience, Tübingen, Germany</aff><aff id="A5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0061rmm93</institution-id><institution>Laboratoire d’Études des Mécanismes Cognitifs</institution></institution-wrap>, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/03rth4p18</institution-id><institution>Université Lumière Lyon 2</institution></institution-wrap>, <city>Lyon</city>,<country country="FR">France</country></aff></contrib-group><author-notes><corresp id="CR1">
<label>*</label>Correspondence: <email>yangwen.xu@unitn.it</email>; <email>roberto.bottini@unitn.it</email>
</corresp></author-notes><pub-date pub-type="nihms-submitted"><day>10</day><month>11</month><year>2024</year></pub-date><pub-date pub-type="preprint"><day>07</day><month>11</month><year>2024</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Humans conceptualize time in terms of space, allowing flexible time construals from various perspectives. We can travel internally through a timeline to remember the past and imagine the future (i.e., mental time travel) or watch from an external standpoint to have a panoramic view of history (i.e., mental time watching). However, the neural mechanisms that support these flexible temporal construals remain unclear. To investigate this, we asked participants to learn a fictional religious ritual of 15 events. During fMRI scanning, they were guided to consider the event series from either an internal or external perspective in different tasks. Behavioral results confirmed the success of our manipulation, showing the expected symbolic distance effect in the internal-perspective task and the reverse effect in the external-perspective task. We found that the activation level in the posterior parietal cortex correlated positively with sequential distance in the external-perspective task but negatively in the internal-perspective task. In contrast, the activation level in the anterior hippocampus positively correlated with sequential distance regardless of the observer’s perspectives. These results suggest that the hippocampus stores the memory of the event sequences allocentrically in a perspective-agnostic manner. Conversely, the posterior parietal cortex retrieves event sequences egocentrically from the optimal perspective for the current task context. Such complementary allocentric and egocentric representations support both the stability of memory storage and the flexibility of time construals.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">How the brain represents time remains mysterious. In prospective timing, a starting point is defined beforehand, and the neural activity tracks the elapsed time like a stopwatch. This neural stopwatch is manifested in various forms, including ramping activity, sequential activity, and neural trajectories. (e.g., see reviews by <xref ref-type="bibr" rid="R25">Buonomano &amp; Laje, 2010</xref>; <xref ref-type="bibr" rid="R108">Wittmann, 2013</xref>; <xref ref-type="bibr" rid="R41">Eichenbaum, 2014</xref>; <xref ref-type="bibr" rid="R97">Tsao et al., 2022</xref>). However, a stopwatch can only track duration in real time. How can we escape from the present, being able to remember the past or imagine the future?</p><p id="P3">One solution, which might be unique to humans, is to conceptualize time in terms of space (i.e., the spatial construals of time, e.g., <xref ref-type="bibr" rid="R105">Whorf, 1941</xref>; <xref ref-type="bibr" rid="R96">Traugott, 1978</xref>; see reviews by <xref ref-type="bibr" rid="R68">Núñez &amp; Cooperrider, 2013</xref>; <xref ref-type="bibr" rid="R87">Sinha &amp; Gärdenfors, 2014</xref>). This is achieved by segmenting time into events—the basic temporal entities the observer conceives to have a beginning and an end (<xref ref-type="bibr" rid="R111">Zacks &amp; Tversky, 2001</xref>)—and ordering these temporal entities in space so that events occurring at different times can be easily maintained in the working memory (<xref ref-type="bibr" rid="R1">Abrahamse et al., 2014</xref>; <xref ref-type="fig" rid="F1">Figure 1A</xref>). This reconstructive process consists of two core time concepts: duration (or interval) and sequence (or order).</p><p id="P4">Unlike prospective timing tracking the continuous passage of time, durations in time construals are event-based (<xref ref-type="bibr" rid="R97">Tsao et al., 2022</xref>): the intervals’ boundaries are constituted by events (<xref ref-type="bibr" rid="R87">Sinha &amp; Gärdenfors, 2014</xref>), and the duration of events reflect their span (<xref ref-type="bibr" rid="R68">Núñez &amp; Cooperrider, 2013</xref>; <xref ref-type="fig" rid="F1">Figure 1A</xref>). Neurocognitive evidence suggests that prospective and retrospective timing involve separate brain systems. The motor system, especially the supplementary motor area, serves for prospective timing (e.g., <xref ref-type="bibr" rid="R74">Protopapa et al., 2019</xref>; <xref ref-type="bibr" rid="R67">Nani et al., 2019</xref>; <xref ref-type="bibr" rid="R36">De Kock et al., 2021</xref>; <xref ref-type="bibr" rid="R78">Robbe, 2023</xref>), whereas the hippocampus contributes to the retrospective one, especially when the duration is embedded within the event sequence (e.g., <xref ref-type="bibr" rid="R10">Barnett et al., 2014</xref>; <xref ref-type="bibr" rid="R94">Thavabalasingam et al., 2018</xref>; see a comprehensive review by <xref ref-type="bibr" rid="R58">Lee et al., 2020</xref>).</p><p id="P5">As for event sequence, one century ago, the philosopher John McTaggart proposed the distinction between two core time construals: the A-series and the B-series (<xref ref-type="bibr" rid="R62">McTaggart, 1908</xref>). The A-series assumes a deictic center of time—the observer’s subjective now—as the reference, and orders events as being in the past or the future according to this deictic center. The B-series concerns the order of events in a sequence regardless of the observer’s subjective now. The distinction between A- and B-series has been widely echoed in various accounts of the temporal frames of reference under different names in the cognitive linguistic analyses (see reviews by <xref ref-type="bibr" rid="R15">Bender &amp; Beller, 2014</xref>). Roughly speaking, the A-series corresponds to the egocentric reference frame, whereas the B-series corresponds to the allocentric one.</p><p id="P6">These two complementary reference frames can be constructed and perceived from two perspectives: one internal, the other external (<xref ref-type="bibr" rid="R68">Núñez &amp; Cooperrider, 2013</xref>; <xref ref-type="bibr" rid="R100">Tversky &amp; Jamalian, 2021</xref>; <xref ref-type="fig" rid="F1">Figure 1A</xref>). An internal perspective on time series is akin to the “route” perspective in the spatial domain (<xref ref-type="bibr" rid="R85">Siegel &amp; White, 1975</xref>). It relates to the cognitive process called “mental time travel” (<xref ref-type="bibr" rid="R98">Tulving, 1984</xref>, <xref ref-type="bibr" rid="R99">2002</xref>; <xref ref-type="bibr" rid="R92">Suddendorf et al., 2009</xref>). The traveler can project themself into any event in the timeline and redefine past and future according to their self-location (i.e., the travel’s subjective now). In this sense, the brain is no longer a stopwatch but a time machine, taking the traveler back and forth in time (<xref ref-type="bibr" rid="R24">Buonomano, 2017</xref>). In contrast, an external viewpoint on time series is akin to the “survey” perspective in the spatial domain (<xref ref-type="bibr" rid="R85">Siegel &amp; White, 1975</xref>). It relates to the cognitive process called “mental time watching” (Stocker, 2011, <xref ref-type="bibr" rid="R90">2014</xref>). The watcher can have a panoramic view of multiple events at different times and localize them according to external self-position or temporal landmarks in parallel (e.g., sunrise and sunset in a day or historical events in the long term). In this sense, the brain is more like a dimensional ascension device, taking the watcher out of the one-dimensional timeline to an external viewpoint in higher-dimensional space.</p><p id="P7">The correspondence between reference frames and perspective-taking is not as straightforward as it seems. In the spatial domain, the conventional assumption suggests that the egocentric reference frame is constructed from the internal route perspective, whereas the allocentric one is from the external survey perspective (e.g., <xref ref-type="bibr" rid="R69">O’Keefe &amp; Nadel, 1978</xref>; <xref ref-type="bibr" rid="R5">Arzy &amp; Schacter, 2019</xref>). However, as many scholars have pointed out, even from a survey perspective (e.g., when looking at a map), we still have egocentric reference frames (e.g., up, down, left, and right); an allocentric perspective does not exist (e.g., <xref ref-type="bibr" rid="R109">Wolbers &amp; Wiener, 2014</xref>; <xref ref-type="bibr" rid="R44">Ekstrom et al., 2014</xref>; <xref ref-type="bibr" rid="R45">Filimon, 2015</xref>). Going back to the definition, the fundamental distinction between allocentric and egocentric reference frames should lie in whether they change as a function of the perspective taken (<xref ref-type="bibr" rid="R55">Klatzky, 1998</xref>): The egocentric representation varies according to perspectives, whereas the allocentric representation remains the same regardless of the perspectives taken. In this vein, the A series can be constructed from both internal and external perspectives as long as there is a fixed self-position as the deictic center (<xref ref-type="bibr" rid="R68">Núñez &amp; Cooperrider, 2013</xref>). The B series, per se, is independent of the perspective taken, although an external perspective is usually adopted to construct the B series of time (<xref ref-type="bibr" rid="R68">Núñez &amp; Cooperrider, 2013</xref>).</p><p id="P8">Recent studies have already begun to investigate the neural representation of the memorized event sequence (e.g., <xref ref-type="bibr" rid="R38">Deuker et al., 2016</xref>; <xref ref-type="bibr" rid="R94">Thavabalasingam et al., 2018</xref>; <xref ref-type="bibr" rid="R12">Bellmund et al., 2019</xref>, <xref ref-type="bibr" rid="R13">2022</xref>; see reviews by <xref ref-type="bibr" rid="R34">Cohn-Sheehy &amp; Ranganath, 2017</xref>; <xref ref-type="bibr" rid="R14">Bellmund et al., 2020</xref>). However, the brain bases underlying the two distinct construals of event sequence remain untouched. Some insights can be drawn from research in the spatial domain. According to an influential neurocomputational model (<xref ref-type="bibr" rid="R27">Byrne et al., 2007</xref>; <xref ref-type="bibr" rid="R17">Bicanski &amp; Burgess, 2018</xref>; <xref ref-type="bibr" rid="R18">Bicanski &amp; Burgess, 2020</xref>), allocentric and egocentric spatial representations are dissociable in the brain—they are respectively implemented in the medial temporal lobe (MTL) and the parietal cortex. Various egocentric representations in the parietal cortex derived from different viewpoints could be transformed into one common allocentric representation and stored in the MTL (i.e., bottom-up process). In return, the allocentric representation in the MTL offers a template from which diverse egocentric representations can be generated in the parietal cortex (i.e., top-down process). Several authors have recently suggested that such mutually engaged egocentric and allocentric reference frames (in the parietal cortex and the medial temporal lobe, respectively) proposed in the spatial domain might also apply to the temporal one (e.g., <xref ref-type="bibr" rid="R46">Gauthier &amp; van Wassenhove, 2016a</xref><xref ref-type="bibr" rid="R47">b</xref>; <xref ref-type="bibr" rid="R48">Gauthier et al., 2019</xref>, <xref ref-type="bibr" rid="R49">2020</xref>; <xref ref-type="bibr" rid="R21">Bottini &amp; Doeller, 2020</xref>). Nonetheless, there is still a lack of neural evidence indicating the parallel involvement of the hippocampal-parietal network in temporal reference frames.</p><p id="P9">This functional magnetic resonance imaging (fMRI) study aimed to directly test this hypothesis by systematically investigating the neural mechanisms underlying the time construals of event sequence and duration. The event series was a fictional religious ritual of 15 events that participants learned the day before scanning (<xref ref-type="fig" rid="F1">Figure 1B</xref>). Such a ritual had all the core temporal elements: the constituent events followed a specific sequence, endured particular durations, and happened on predetermined parts of the day (i.e., the external temporal landmarks). Participants learned these core temporal elements by reading the description and imagining going through the events one after another. The post-learning test suggests that all participants learned the temporal structure of the ritual before scanning (see <xref ref-type="sec" rid="S9">Methods</xref> for details of the learning and testing procedure).</p><p id="P10">During the fMRI scanning, participants performed two tasks guiding them to consider the event series from internal and external perspectives (i.e., mental time travel vs. mental time watching; <xref ref-type="fig" rid="F1">Figure 1C</xref>). In each trial, participants saw two sequential event phrases. The first was the reference event, and the second was the target event. In the external-perspective task, participants judged whether the target event happened in the same or different part of the day as the reference event. In the internal-perspective task, participants were instructed to project themselves into the reference event and judge whether the target event happened in the future or the past of the reference event (see <xref ref-type="sec" rid="S9">Methods</xref> for details of the scanning procedure). We compared the neural correlates of event sequence and duration from external and internal perspectives. The egocentric representation of the event series was supposed to vary across the two perspectives, while the allocentric representation was supposed to remain the same.</p></sec><sec id="S2" sec-type="results"><title>Results</title><sec id="S3"><title>Time was processed differently from internal and external perspectives</title><p id="P11">Participants had significantly greater accuracy in the external-perspective task than the internal-perspective task (external-perspective task: M = 93.5%, SD = 4.7%; internal-perspective task: M = 89.5%, SD = 8.1%; paired t(31) = 3.33, p = 0.002). The reaction time (RT) of the corrected trials in the external-perspective task was also significantly shorter than the internal-perspective task (external-perspective task: M = 1475 ms, SD = 529 ms; internal-perspective task: M = 1578 ms, SD = 587 ms; fixed effect of <italic>Task Type</italic> in a random-intercept-and-slope linear mixed model with <italic>Participant</italic> as the random-effect grouping factor: F(1, 31) = 27.44, p &lt; 0.001).</p><p id="P12">To further explore the factors affecting the RT of the correct trials, we built a random-intercept linear mixed model with <italic>Participant</italic> as the random effects grouping factor. Fixed effects variables included <italic>Sequential Distance</italic> (i.e., number of events between the reference and the target events), <italic>Duration</italic> (i.e., duration of the target events), <italic>Syllable Length</italic> (i.e., number of syllables of the phrase of the target events), <italic>Task Type</italic> (i.e., external-vs. internal-perspective tasks), and the interaction between <italic>Task Type</italic> and all the other variables (<xref ref-type="table" rid="T1">Table 1</xref>). As a sanity check, we found a significant main effect of <italic>Syllable Length</italic> (F(1, 6918) = 35.59, p &lt; 0.001) since it was expected that participants spent longer time reading longer phrases. Intriguingly, we also found significant interaction effects between <italic>Task Type</italic> and <italic>Sequential Distance</italic> (F(1, 6918) = 28.22, p &lt; 0.001) and <italic>Task Type</italic> and <italic>Duration</italic> (F(1, 6918) = 12.81, p &lt; 0.001).</p><p id="P13"><italic>Sequential Distance</italic> was correlated positively with RT in the external-perspective task (z = 3.80, p &lt; 0.001) but negatively in the internal-perspective task (z = -3.71, p &lt; 0.001). The negative correlation between RT and egocentric distance has been consistently observed in previous studies in which participants engaged in temporal self-projection: participants make more effort to differentiate past and future for the events close to their own temporal position (e.g., <xref ref-type="bibr" rid="R8">Arzy et al., 2008</xref>; <xref ref-type="bibr" rid="R6">Arzy et al., 2009a</xref><xref ref-type="bibr" rid="R7">b</xref>; <xref ref-type="bibr" rid="R46">Gauthier &amp; Wassenhove, 2016a</xref><xref ref-type="bibr" rid="R47">b</xref>; <xref ref-type="bibr" rid="R48">Gauthier et al., 2019</xref>). This pattern can broadly be attributed to the symbolic distance (SD) effect (<xref ref-type="bibr" rid="R64">Moyer &amp; Landauer, 1967</xref>; <xref ref-type="bibr" rid="R63">Moyer &amp; Bayer, 1976</xref>; Shepard &amp; Judd, 1979), which refers to the fact that “time needed to compare two symbols varies inversely with the distance between their referents on the judged dimension” (<xref ref-type="bibr" rid="R63">Moyer &amp; Bayer, 1976</xref>, p. 229). The positive correlation between RT and sequential distance from an external perspective was predicted by <xref ref-type="bibr" rid="R46">Gauthier &amp; van Wassenhove (2016a)</xref>. This prediction was inspired by classic studies on mental scanning using visual imagery (e.g., Shepard &amp; Metzler, 1971; <xref ref-type="bibr" rid="R57">Kosslyn et al., 1978</xref>): From an external perspective, people might compare two referents by mentally traversing the intermediate states between them, resulting in longer times to scan longer sequential distances.</p><p id="P14">As for <italic>Duration</italic>, it had a significantly negative trend with RT in the external-perspective task (z = -4.44, p &lt; 0.001) but not in the internal-perspective task (z = 0.66, p = 0.51). A possible explanation is that events with longer durations were more salient and thus easier to be compared with external landmarks.</p><p id="P15">The behavioral results suggest that our attempt to induce different perspectives on the event series was successful. The two tasks induced RT as distinct functions of sequential distance, in line with the predicted SD effect for the internal perspective and reverse-SD effect for the external perspective.</p></sec><sec id="S4"><title>Internal-compared to external-perspective task activated different brain networks</title><p id="P16">We first directly contrasted the activity level between external- and internal-perspective tasks in the time window of the target events (<xref ref-type="fig" rid="F2">Figure 2A</xref>; <xref ref-type="table" rid="T2">Table 2</xref>; see <xref ref-type="supplementary-material" rid="SD1">Supplementary Figure 1A</xref> for a surface view; voxel level p &lt; 0.001, cluster-level FWE corrected p &lt; 0.05). Compared with the external-perspective task, the internal-perspective task specifically activated the regions in the default network (DN) in the right hemisphere. They were the precuneus (PreC), the retrosplenial cortex (RSC), the superior frontal gyrus (SFG), and the angular gyrus (AG). This finding aligned with evidence indicating that the DN plays a crucial role in self-projection (see the review by <xref ref-type="bibr" rid="R23">Buckner &amp; Carroll, 2007</xref>). In <xref ref-type="supplementary-material" rid="SD1">Supplementary Figure 1</xref>, we also compared the significant clusters in the internal-perspective task with the two subnetworks of the DN: DN-A and DN-B (e.g., <xref ref-type="bibr" rid="R22">Braga &amp; Buckner, 2017</xref>; Reznik et al., 2013). The internal-perspective mostly engages DN-A rather than DN-B. This observation is consistent with existing evidence suggesting that DN-A is more closely associated with episodic memory, whereas DN-B is primarily involved in social processing (e.g., <xref ref-type="bibr" rid="R60">Lin et al., 2018</xref>; <xref ref-type="bibr" rid="R39">DiNicola et al., 2020</xref>).</p><p id="P17">Compared with the internal-perspective task, the external-perspective task specifically activated the supplementary motor area (SMA) and the supramarginal gyrus (SMG) in the right hemisphere (<xref ref-type="fig" rid="F2">Figure 2A</xref>; <xref ref-type="table" rid="T2">Table 2</xref>; voxel level p &lt; 0.001, cluster-level FWE corrected p &lt; 0.05). This finding is open to interpretation. The area found in the right SMG was centered at the junction region between the posterior part of the SMG and the posterior part of the superior temporal gyrus. Previous evidence has shown that this temporoparietal junction area relates to the out-of-body experience (e.g., see reviews by <xref ref-type="bibr" rid="R20">Blanke et al., 2004</xref>; <xref ref-type="bibr" rid="R19">Blanke &amp; Arzy, 2005</xref>) or plays a role in overcoming egocentric emotion bias towards others (e.g., <xref ref-type="bibr" rid="R86">Silani et al., 2013</xref>). Thus, the right SMG region found here may be important for the mental construction of an external perspective.</p></sec><sec id="S5"><title>The right posterior parietal cortex implemented opposite representations of sequential distance across external and internal perspectives</title><p id="P18">Next, we used the parametric modulation method to detect neural correlates of the temporal information (i.e., <italic>Sequential Distance</italic> and <italic>Duration</italic>) across external- and internal-perspective tasks. We built a single general linear model (GLM) in which the target events were simultaneously modulated by their duration and their sequential distances to the reference events. The target events in external- and internal-perspective tasks were treated separately. To detect whether the temporal information was represented differently from different perspectives, we first examined the interaction effect between each temporal information and the task type. If the interaction effect was not significant, we also examined the main effect combining both tasks.</p><p id="P19">As a sanity check, we investigated whether the employed parametric modulation method could successfully reveal the effect of the word length in the visual cortex, given that our stimuli were visually presented. To do so, we used <italic>Syllable Length</italic> as the parameter to modulate the condition of both the reference and the target events in the above GLM. We found not only the visual cortex but also the left superior temporal gyrus in the language network, of which the activity level positively correlated with the number of syllables (<xref ref-type="fig" rid="F2">Figure 2B</xref>; voxel level p &lt; 0.001, cluster-level FWE corrected p &lt; 0.05). This result confirmed our prediction and validated our methodology.</p><p id="P20">To detect the regions in which the activation level was modulated by <italic>Sequential Distance</italic> (i.e., the number of events between the reference and the target events), we first searched regions with a significant interaction effect between <italic>Task Type</italic> (i.e., external-vs. internal-perspective tasks) and <italic>Sequential Distance</italic> (<xref ref-type="fig" rid="F3">Figure 3A-C</xref>). The only significant region we could find across the whole cortex was localized in the border area between the angular gyrus and the superior division of the lateral occipital cortex in the right hemisphere (i.e., the boundary area between Broadman area 7, 19, and 39; <xref ref-type="fig" rid="F3">Figure 3A</xref>; voxel level p &lt; 0.001, cluster-level FWE corrected p &lt; 0.05). More specifically, this region is mostly at the lateral wall of the posterior intraparietal sulcus (hIP5: 56.2%, hIP6: 9.5%, hIP4: 5.9%; <xref ref-type="bibr" rid="R76">Richter et al., 2019</xref>) and the posterior part of the angular gyrus (PGp: 21.4%; <xref ref-type="bibr" rid="R30">Caspers et al., 2006</xref>, <xref ref-type="bibr" rid="R29">2008</xref>) (assignment based on maximum probability map; <xref ref-type="bibr" rid="R43">Eickhoff et al., 2005</xref>). The MNI coordinate of the center voxel is 38, -69, 35. For convenience, we will refer to this region as the posterior parietal cortex (PPC) in the following text. <xref ref-type="fig" rid="F3">Figure 3B</xref> further shows the beta estimates of <italic>Sequential Distance</italic> in the parametric modulation analysis in the right PPC. The activation level in this region correlated with sequential distance positively in the external-perspective task (t(31) = 2.97, P = 0.006) but negatively in the internal-perspective task (t(31) =-4.19, P &lt; 0.001).</p><p id="P21">The alignment of the changes in the activity levels in the PPC with RT suggests a potential domain-general task difficulty effect. To eliminate this possibility, we controlled for trial-by-trial RT using the parametric modulation method in our first-level analysis (see <xref ref-type="sec" rid="S9">Methods</xref>). Notably, the same PPC region remained the only area in the entire brain showing a significant interaction effect between <italic>Task Type</italic> and <italic>Sequential Distance</italic> (voxel-level p &lt; 0.001, cluster-level FWE corrected p &lt; 0.05). This indicates that the PPC activity cannot be fully attributed to RT.</p><p id="P22">To provide a direct illustration of how the activation level in the right PPC varied according to the sequential distances in the two perspectives, we built another GLM with each sequential distance (i.e., 1 to 5) in each task as a separate condition. <xref ref-type="fig" rid="F3">Figure 3C</xref> confirms that the activation level in the external-perspective task went up as the sequential distance increased, and the activation level in the internal-perspective task went down as the target event moved far away from the reference event where participants self-projected themselves.</p><p id="P23">These results suggest that the parietal cortex implements an egocentric representation of the event sequence, which varies with different perspectives.</p></sec><sec id="S6"><title>The right hippocampal head implemented consistent representations of sequential distance across external and internal perspectives</title><p id="P24">We did not find any regions in the hippocampus showing a significant interaction effect between <italic>Task Type</italic> and <italic>Sequential Distance</italic>. Instead, we found a region in the right hippocampal head in which the activation level positively correlated with the sequential distance when we combined external- and internal-perspective tasks (<xref ref-type="fig" rid="F3">Figure 3D</xref>; voxel level p &lt; 0.001, cluster-level FWE corrected p &lt; 0.05). The MNI coordinate of the center voxel was 25, -11, -15. <xref ref-type="fig" rid="F3">Figure 3E</xref> further shows that we did not find that such a positive correlation with the sequential distance significantly differed in the external- and internal-perspective tasks (paired t(31) = -0.906, p = 0.372).</p><p id="P25">We also illustrate the activation level in this hippocampal region of each sequential distance in external- and internal-perspective tasks, respectively (<xref ref-type="fig" rid="F3">Figure 3F</xref>): the activation level in the right hippocampus tended to go up as the sequential distance increased regardless of the tasks.</p><p id="P26">These results suggest that the hippocampus implements an allocentric representation of the event sequence independent of the perspectives, contrary to the egocentric representation in the posterior parietal cortex.</p></sec><sec id="S7"><title>The right hippocampal body implemented the representation of event duration in the internal-perspective task</title><p id="P27">In the cortex, we did not detect any regions where the activation level showed a significant interaction effect between <italic>Task Type</italic> and <italic>Duration</italic> or a positive main effect of <italic>Duration</italic>. In the hippocampus, we also found no regions where the activation level showed a significant interaction effect between <italic>Task Type</italic> and <italic>Duration</italic>. Instead, we found a region in the right hippocampal body where the activation level showed a significantly positive correlation with <italic>Duration</italic> when combining two tasks (<xref ref-type="fig" rid="F4">Figure 4A</xref>; voxel level p &lt; 0.001, cluster-level FWE corrected p &lt; 0.05). The MNI coordinate of the center voxel is 39, -24, -12. However, <xref ref-type="fig" rid="F4">Figure 4B</xref> shows that directly comparing the beta estimates in the two tasks reveals a significant result (paired t(31) = 3.07, p = 0.004). The mean activation level in this area positively correlated with <italic>Duration</italic> only in the internal-perspective task (t(31) = 5.54, p &lt; 0.001), not in the external-perspective task (t(31) = 0.68, p = 0.502). This later analysis is circular, as the ROI was defined as the voxels showing a significantly positive correlation with <italic>Duration</italic> combining two tasks in the first place. Nevertheless, it illustrated that this positive correlation in the voxel-level analysis was driven only by the internal-perspective task. Due to the stringent threshold of multiple comparisons across voxels, this interaction effect between <italic>Task Type</italic> and <italic>Duration</italic> was not found in the voxel-level analysis.</p><p id="P28"><xref ref-type="fig" rid="F4">Figure 4C</xref> directly illustrates how the activation level in this hippocampal region varied according to duration: the activation level in the right hippocampal body went up as the duration increased only in the internal-perspective task but not in the external-perspective task.</p><p id="P29">A possible explanation for the difference between these two tasks might be that the hippocampus is preferentially involved in memory for durations embedded within event sequences (see review by <xref ref-type="bibr" rid="R58">Lee et al., 2020</xref>). Since the external-perspective task in the current study encouraged the participants to compare the event sequence with the external parallel temporal landmarks, duration representation in the hippocampus may be dampened.</p><p id="P30">We also implemented a post hoc analysis to fully illustrate the <italic>Sequential Distance</italic> and <italic>Duration</italic> effects in the internal-perspective task within the regions of interest of the hippocampal <italic>Head</italic> and the <italic>Body</italic> (<xref ref-type="fig" rid="F4">Figure 4D</xref>). These two regions were defined as the regions where activation level significantly positively correlates with <italic>Sequential Distance</italic> and <italic>Duration</italic>, respectively. No significant evidence shows that the hippocampal head also represented <italic>Duration</italic> (t(31) = 0.506, p = 0.616), and no significant evidence shows that the hippocampal body also represented <italic>Sequential Distance</italic> (t(31) = -0.616, p = 0.543). Further confirmatory analyses are needed to verify such a double dissociation pattern between the neural representation of sequence and duration in the head and the body of the hippocampus.</p></sec></sec><sec id="S8" sec-type="discussion"><title>Discussion</title><p id="P31">This study investigated the neural correlates of sequence and duration in task contexts where participants took internal or external perspectives on event series, thereby testing the complementary allocentric and egocentric reference frames in the temporal domain. We found that both the right PPC and the right hippocampal head represented the sequential distance between the reference and the target events. However, the representation in the right PPC varied with the perspective taken; its activity level correlated with sequential distance positively in the external perspective task and negatively in the internal perspective task. In contrast, the activation level in the right hippocampal head positively correlated with sequential distance regardless of the perspective taken. Moreover, we found that the activation level in the right hippocampal body positively correlated with the event duration in the internal-perspective task.</p><p id="P32">The negative correlation between the activation level in the right PPC and sequential distance has already been observed in a previous fMRI study (<xref ref-type="bibr" rid="R47">Gauthier &amp; van Wassenhove, 2016b</xref>). The authors found a similar region (the reported MNI coordinate of the peak voxel was 42, -70, 40, and the MNI coordinate of the peak voxel in the present study was 39, -70, 35), of which the activation level went up when the target event got closer to the self-positioned event. This finding aligns with the evidence suggesting that the posterior parietal cortex implements egocentric representations. For example, neuropsychological studies have demonstrated that patients with lesions in the PPC have “egocentric disorientation” (<xref ref-type="bibr" rid="R2">Aguirre &amp; D’Esposito, 1999</xref>): they are unable to localize objects in relation with themselves (e.g., Case 2: <xref ref-type="bibr" rid="R59">Levine et al., 1985</xref>; Patient DW: <xref ref-type="bibr" rid="R88">Stark, 1996</xref>; Patient MU: Wilson et al., 1997, 2005). Consistently, we found in a recent fMRI experiment that the distributed activity pattern in the bilateral PPC could encode egocentric but not allocentric coordinates of the target objects during memory retrieval (<xref ref-type="bibr" rid="R40">Dutriaux et al., 2024</xref>).</p><p id="P33">What is novel here is that the correlation between the activation level of the right PPC and sequential distance was reversed to a positive one when an external perspective was used. Since an external perspective is often associated with the allocentric reference frame (e.g., <xref ref-type="bibr" rid="R69">O’Keefe &amp; Nadel, 1978</xref>; <xref ref-type="bibr" rid="R5">Arzy &amp; Schacter, 2019</xref>), our results seem to challenge the view that the parietal cortex implements egocentric representation. However, the conflict is more apparent than real. Perspective-taking, whether internal or external, by definition, must be egocentric, as mental images must be constructed from a specific viewpoint (see similar arguments by <xref ref-type="bibr" rid="R102">Vogeley &amp; Fink, 2003</xref>; <xref ref-type="bibr" rid="R45">Filimon, 2015</xref>). Therefore, a brain region that implements egocentric representation should vary its activity with the perspectives taken, as shown in the right PPC. This finding is crucial; it suggests that the distance coding in the right PPC is not a “perspective agnostic” magnitude effect, a possibility that previous fMRI studies could not definitively rule out.</p><p id="P34">Several previous studies have already quested the nature of the PPC’s function (e.g., see reviews by <xref ref-type="bibr" rid="R4">Andersen et al., 1997</xref>; <xref ref-type="bibr" rid="R33">Cohen &amp; Andersen, 2002</xref>; <xref ref-type="bibr" rid="R103">Wagner et al., 2005</xref>; <xref ref-type="bibr" rid="R1">Abrahamse et al., 2014</xref>; <xref ref-type="bibr" rid="R32">Ciaramelli et al., 2008</xref>; <xref ref-type="bibr" rid="R28">Cabeza et al., 2008</xref>; <xref ref-type="bibr" rid="R51">Hutchinson et al., 2009</xref>; <xref ref-type="bibr" rid="R104">Whitlock, 2017</xref>; <xref ref-type="bibr" rid="R83">Sestieri et al., 2017</xref>; <xref ref-type="bibr" rid="R93">Summerfield et al., 2020</xref>; <xref ref-type="bibr" rid="R21">Bottini &amp; Doeller, 2020</xref>). Here, we want to highlight three crucial findings. First, neuropsychological studies indicate that lesions in the bilateral PPC or lateral occipitoparietal cortex will lead to not only egocentric disorientation but also simultanagnosia, one of the key components of Bálint’s syndrome (<xref ref-type="bibr" rid="R9">Bálint, 1909</xref>; Rizzo &amp; Vecera, 2001; <xref ref-type="bibr" rid="R31">Chechlacz &amp; Humphreys, 2014</xref>; e.g., WF: <xref ref-type="bibr" rid="R50">Holmes and Horax, 1919</xref>; MVV: <xref ref-type="bibr" rid="R53">Kase et al., 1977</xref>; MU: Wilson et al., 1997, 2005). Patients with simultanagnosia cannot perceive multiple entities as a whole and comprehend the overall meaning of a scene. Second, electrophysiological recordings in the lateral intraparietal area of the macaque cortex find the gain-field neurons, which can be used to transform the reference frames anchored to different body parts (e.g., <xref ref-type="bibr" rid="R3">Andersen et al., 1985</xref>; <xref ref-type="bibr" rid="R112">Zipser &amp; Andersen, 1988</xref>; <xref ref-type="bibr" rid="R4">Andersen et al., 1997</xref>; <xref ref-type="bibr" rid="R33">Cohen &amp; Andersen, 2002</xref>). Third, the fMRI studies in humans show that the particular PPC area found in our study (i.e., the hIP5 area in the lateral wall of the intraparietal sulcus and the dorsal PGp in the angular gyrus) are more engaged in episodic memory retrieval, in contrast to the medial wall of the intraparietal sulcus and dorsal part of the PPC more involved in perceptual attention (e.g., <xref ref-type="bibr" rid="R51">Hutchinson et al., 2009</xref>; <xref ref-type="bibr" rid="R82">Sestieri et al., 2010</xref>; <xref ref-type="bibr" rid="R83">Sestieri et al., 2017</xref>). Taking all these findings together, the PPC area identified in this study might contribute to memory retrieval in egocentric reference frames, which maintains relations among multiple memorized entities in the working memory from a perspective optimal for the current task context (<xref ref-type="bibr" rid="R1">Abrahamse et al., 2014</xref>). Such relational schema, constructed from stereotypical perspectives, is also represented in the PPC as a template to guide attention (<xref ref-type="bibr" rid="R93">Summerfield et al., 2020</xref>; <xref ref-type="bibr" rid="R21">Bottini &amp; Doeller, 2020</xref>). It is thus not surprising that the two most common perspectives for time construals—mental time travel and mental time watching—involve the PPC.</p><p id="P35">In contrast to the PPC, we observed that the activation level in the head of the right hippocampus positively correlated with the sequential distance, regardless of the perspectives. Previous studies have already shown that the hippocampal activation level correlates with distance (e.g., Morgan et al., 2011; Howard et al., 2014; <xref ref-type="bibr" rid="R95">Theves et al., 2019</xref>, <xref ref-type="bibr" rid="R101">Viganò et al., 2023</xref>), and the distributed activity in the hippocampus can encode distance (e.g., <xref ref-type="bibr" rid="R38">Deuker et al., 2016</xref>; Park et al., 2021). However, our study is novel in showing that this distance coding in the hippocampus is independent of perspectives, indicating an allocentric representation of the event series. This finding aligns with the hypothesis in the spatial domain suggesting the hippocampus as an allocentric cognitive map (e.g., <xref ref-type="bibr" rid="R69">O’keefe &amp; Nadel, 1978</xref>; <xref ref-type="bibr" rid="R27">Byrne et al., 2007</xref>; <xref ref-type="bibr" rid="R17">Bicanski &amp; Burgess, 2018</xref>; <xref ref-type="bibr" rid="R18">Bicanski &amp; Burgess, 2020</xref>; <xref ref-type="bibr" rid="R21">Bottini &amp; Doeller, 2020</xref>). The positive correlation between the sequential distance and the hippocampal activation level might be mediated by adaptation (e.g., Grill-Spector &amp; Malach, 2001): the longer the distance, the less the adaptation, and the greater the hippocampal activation. One way to interpret such perspective-agnostic representation in the hippocampus is to view it as the associations among memorized entities (e.g., <xref ref-type="bibr" rid="R65">Muller et al., 1996</xref>; <xref ref-type="bibr" rid="R41">Eichenbaum, 2014</xref>, <xref ref-type="bibr" rid="R42">2017</xref>; <xref ref-type="bibr" rid="R26">Buzsáki &amp; Tingley, 2018</xref>; Quiroga, 2019). As a result, the allocentric representation in the hippocampus may not require a “reference frame” because there is no fixed reference point. Each entity is represented among the relations to others, contrasting with the egocentric representation in the parietal cortex, where the reference point is clearly the self.</p><p id="P36">In this context, the distinction between the allocentric and the egocentric representations of an event series can also be understood in terms of memory storage and retrieval (also see <xref ref-type="bibr" rid="R27">Byrne et al., 2007</xref>). The hippocampus stores event series in a static and perspective-agnostic manner, while the PPC flexibly retrieves memory by constructing egocentric images tied to variable perspectives. Supporting this hypothesis is evidence that bilateral hippocampal lesions result in memory deficit for event series (e.g., <xref ref-type="bibr" rid="R37">Dede et al., 2016</xref>), whereas bilateral PPC lesions impair free recall but do not cause memory loss (e.g., <xref ref-type="bibr" rid="R16">Berryhill et al., 2007</xref>). Patients can still recall details of past events when prompted with cues or questions but struggle to access memories spontaneously.</p><p id="P37">Finally, the study indicates that the event durations were represented in the right hippocampal body, in line with previous studies suggesting that the hippocampus contributes to the retrospective durations that are embedded within the event sequence (e.g., <xref ref-type="bibr" rid="R10">Barnett et al., 2014</xref>; <xref ref-type="bibr" rid="R94">Thavabalasingam et al., 2018</xref>; <xref ref-type="bibr" rid="R58">Lee et al., 2020</xref>). Notably, the post hoc analysis reveals a double dissociation pattern: the hippocampal head represented sequential distances between events, whereas the hippocampal body represented the duration of individual events. This novel finding echoes the evidence suggesting that the anterior hippocampus (or the ventral rodent hippocampus) implements global and gist-like representations (e.g., larger receptive fields), whereas the posterior hippocampus (or the dorsal rodent hippocampus) implements local and detailed ones (e.g., finer receptive fields) (e.g., <xref ref-type="bibr" rid="R52">Jung et al., 1994</xref>; <xref ref-type="bibr" rid="R54">Kjelstrup et al., 2008</xref>; <xref ref-type="bibr" rid="R35">Collin et al., 2015</xref>; see reviews by <xref ref-type="bibr" rid="R72">Poppenk et al., 2013</xref>; <xref ref-type="bibr" rid="R80">Robin &amp; Moscovitch, 2017</xref>; see <xref ref-type="bibr" rid="R91">Strange et al., 2014</xref> for a different opinion). Thus, the hippocampus likely represents the sequence of events hierarchically along its longitudinal axis: from the gist event sequence to the event sequence constituting a gist event, down to unitary time bin sequence constituting an event as its duration. This view unifies the hippocampus’s role in sequence representation and explains why it only represents durations embedded within event sequences. Future studies are required to confirm this hypothesis and investigate whether such hierarchical structures along the longitude axis of the hippocampus can also be used to represent the events at different time scales (e.g., from years to seconds). It would also be intriguing to examine whether the parietal cortex has a similar hierarchical structure or plays a role in zoom-in and zoom-out events at different scales to maintain an appropriate working memory load.</p><p id="P38">To conclude, this study reveals the neural correlates of sequence and duration in time construals. The hippocampal head represents the event sequence allocentrically, irrespective of the observer’s perspectives (i.e., the B series), whereas the hippocampal body represents the event duration embedded in the event sequence. The posterior parietal cortex flexibly constructs the egocentric representation of the event series that varies according to the observer’s perspectives (i.e., the A series), which could be internal (i.e., mental time travel) or external (i.e., mental time watching). Such allocentric and egocentric representations of event series can be interpreted in terms of memory storage and retrieval.</p></sec><sec id="S9" sec-type="methods"><title>Methods</title><sec id="S10" sec-type="subjects"><title>Participants</title><p id="P39">Thirty-five native Italian speakers with no history of neurobiological or psychiatric disorders participated in the experiment. The ethical committee of the University of Trento approved the experimental protocol, and all participants provided written informed consent and were paid for their time. Three participants were excluded. Two were due to poor behavioral performance during scanning; their accuracy was below 1.5 times the interquartile range below the lower quartile across participants. One was due to excessive head motion during scanning; this participant’s mean frame displacement index (<xref ref-type="bibr" rid="R73">Power et al., 2014</xref>) was above 1.5 times the interquartile range above the upper quartile across participants. The remaining 32 participants entered the analysis (19 females, 13 males; age: 19-34; M = 24.0; SD = 3.8; all participants except one were right-handed).</p></sec><sec id="S11"><title>Stimuli</title><p id="P40">We created a fictional religious ritual as the stimulus. Like most rituals, it follows a specific sequence, endures particular durations, and happens on predetermined parts of the day (<xref ref-type="fig" rid="F1">Figure 1A</xref>). This created ritual comprised 15 events, falling into three parts of the day, i.e., morning, afternoon, and evening. Each part of the day included five events and lasted six hours in total: two events lasted for half an hour, one for one hour, and the other two for two hours. We instantiated each event with an event phrase. To minimize the potential confounding between the time information of the events and the semantic information of the phrases, we randomly assigned 15 phrases to the events twice, generating two versions for even and odd numbers of participants.</p></sec><sec id="S12" sec-type="methods"><title>Procedures</title><p id="P41">The day before fMRI scanning, participants learned the temporal information of the ritual: the sequence, the durations, and the parts of the day. The learning procedure included two phases. The first was the reading phase, and the second was the imagination phase. The two phases combined were performed twice.</p><p id="P42">In the reading phase, participants read a narrative describing the whole ritual on a computer screen twice. The computer screen presented one sentence at a time, and each sentence provided information on one event. The presentation sequence was identical to the event sequence of the fictional ritual, and the sentences described the duration and the parts of the day of each event. Participants read the sentences at their own pace by pressing the spacebar to read the following sentence.</p><p id="P43">In the imagination phase, participants imagined themselves performing the whole ritual one event after another, guided by the prerecorded auditory instructions delivered through the headphones. Each event started with a voice telling the event to be imagined (e.g., “light some candle”). A single beep was then played to indicate the start of the imagination, and a double beep sound indicated the end of the imagination. The imagining sequence was the same as the actual sequence, the imagining duration (i.e., the interval between the single and the double beep) was proportional to the actual duration (30 seconds / 1 hour), and the parts of the day were indicated in the instruction (e.g., “the morning starts”). Participants were told to close their eyes to avoid distractions and imagined the whole ritual four times in each imagining phase (i.e., eight times in total).</p><p id="P44">After learning, participants’ knowledge of the ritual was assessed with three tests. In the event-sequence test, participants judged whether one event happened in the past or the future of another event. In the event-duration test, participants imagined the ritual in a self-paced manner and pressed the button when finishing the imagination of each event. In the parts-of-the-day test, participants judged whether two events happened in the same or different parts of the day. All participants’ performance was greater than 80% in both the event-sequence and parts-of-the-day tests. In the event-duration test, Pearson’s correlation between the self-paced imagining duration and the actual duration across 15 events was greater than 0.6 in all participants.</p><p id="P45">The scanning consisted of six runs, each with one external-perspective task block and one internal-perspective task block. The order of these two task blocks was interleaved across the six runs within each participant, and the order of these two task blocks in the first run was counterbalanced across participants. That means half the participants followed the order “EI-IE-EI-IE-EI-IE”, and half of the participants followed the order “IE-EI-IE-EI-IE-EI” (“E” indicating the external-perspective task block and “I” indicating the internal-perspective task block). Each task block started with a 5s task prompt indicating the task of this block and a 3s countdown presentation (i.e., the screen presenting “3”, “2”, “1”). The task block had 20 trials that were identical in the two task blocks within the same run but were presented in a randomized order.</p><p id="P46">In each trial, the phrases of two events were visually presented one after the other (<xref ref-type="fig" rid="F1">Figure 1C</xref>). Participants first saw a 0.5s fixation cross, the phrase of the reference event for 0.8s, and a blank screen for 3.2s (75% trials) or 7.2s (25% trials). They then saw another 0.5s fixation cross and the phrase of the target event. Each event phrase was presented in the center of a grey screen in two rows (black color, Calibri font): in the first row was the verb of the phrase (i.e., “light”), and in the second row was the object of this verb “some candle”). When presenting the target event phrase, we also presented two possible answers under the target event phrase; they were smaller in font size and colored differently depending on the task (i.e., red for the external-perspective task and blue for the internal-perspective task). In the external-perspective task block, the participants judged whether the target event happened in the same or different part of the day of the reference event, and the two option words were “same” and “different”. In the internal-perspective task block, the participants were instructed to project themselves into the reference event and judge whether the target event happened in the past or will happen in the future, and the two option words were “past” and “future”.</p><p id="P47">Participants were instructed to perform the two tasks once they saw the target event phrase by pressing two buttons with their right index and middle fingers, corresponding to the left and the right options on the screen, respectively. To ensure that the behavior output did not correlate with the finger movement, we counterbalanced the locations of the two options on the screen across the trials within both external- and internal-perspective blocks. The reaction time was calculated as the duration between the onset of the target event phrase and the button press. A blank screen would replace the target event presentation once the response was given, and the total duration of the target event and the blank screen was maintained as 4s. On 75% of occasions, the subsequent trial started immediately; On the other 25%, there would be another 4s blank screen between trials.</p><p id="P48">We carefully chose two sets of 20 pairs of events from the possible 210 pairs of events. These two sets were assigned to odd and even runs of the fMRI experiment, respectively. Using the brute-force search method, we searched 20 pairs with weak correlation between the sequential distance and the position information of both the reference event and the target event (i.e., from 1 to 15) (all the correlation coefficients &lt; 0.2). At the same time, we also balanced the corrected choice ratio during both the external-perspective task (Same/Different = 11/9, 12/8) and the internal-perspective task (Future/Past = 12/8, 8/12). Given the criteria, sequential distances in both sets fell within the range between 1 and 5.</p></sec><sec id="S13"><title>Behavior analysis</title><p id="P49">Behavior analyses were conducted using JASP 0.18.3. To investigate the factors affecting trial-by-trial RT of the correct trials, we built linear mixed models (LMM) with <italic>Participant</italic> as the random effects grouping factor. We fit the maximal model including the random intercept and all the random slopes consistent with the experimental design (as recommended by <xref ref-type="bibr" rid="R11">Barr et al., 2013</xref>). In the case of overfitting (singular fit), we removed the random slopes but kept the random intercept (<xref ref-type="bibr" rid="R61">Matuschek et al., 2017</xref>).</p></sec><sec id="S14"><title>MRI acquisition</title><p id="P50">MRI data were acquired using a MAGNETOM Prisma 3T MR scanner (Siemens) with a 64-channel head-neck coil at the Centre for Mind/Brain Sciences, University of Trento. Functional images were acquired using the simultaneous multislice echoplanar imaging sequence: the scanning plane was parallel to the long axis of the hippocampus, the phase encoding direction was from anterior to posterior, repetition time (TR) = 1000 ms, echo time (TE) = 28 ms, flip angle (FA) = 59°, field of view (FOV) = 200 mm × 200 mm, matrix size = 66 × 66, 65 axial slices, slices thickness (ST) = 3 mm, no gap, voxel size = 3.03 × 3.03 × 3 mm, multiband factor = 5.</p><p id="P51">Field maps were acquired between each pair of functional runs to correct for geometric distortions of these two runs. Each set of field maps included three images, one phase-drift image between two slightly different echo times and two magnitude images for each of these two echo times: the scanning plane was parallel to the long axis of the hippocampus, the phase encoding direction was from anterior to posterior, TR = 1030 ms, shorter TE = 4.92 ms, longer TE = 7.38 ms, FA = 60°, FOV = 210 mm × 210 mm, matrix size = 70 × 70, 66 axial slices, ST = 3 mm, no gap, voxel size = 3 × 3 × 3 mm.</p><p id="P52">Three-dimensional T1-weighted images were acquired using the magnetization-prepared rapid gradient-echo sequence, sagittal plane, TR = 2530 ms, TE = 1.69 ms, inversion time = 1100 ms, FA = 7°, FOV = 256 mm × 256 mm, matrix size = 256 × 256, 176 continuous sagittal slices, ST = 1 mm, voxel size = 1 × 1 × 1 mm.</p></sec><sec id="S15"><title>MRI preprocessing</title><p id="P53">We preprocessed the brain images using SPM12 (<ext-link ext-link-type="uri" xlink:href="https://www.fil.ion.ucl.ac.uk/spm/software/spm12/">https://www.fil.ion.ucl.ac.uk/spm/software/spm12/</ext-link>). The functional images were first realigned to the first image in the first run, generating six rigid head motion parameters for each time point and a mean functional image across all the runs. We then used the field maps to calculate the voxel displacement maps and coregistered them to this mean functional image. Since we acquired the field maps between each pair of functional runs, we applied each voxel displacement map to its two closet functional runs to correct their geometric distortions. The resulting functional images were next normalized to the MNI space with the acquired T1-weighted image using the unified segmentation method. In the final step, we spatially smoothed the normalized functional images, and the full width at half maximum of the 3D Gaussian smoothing kernel was 4 mm.</p></sec><sec id="S16"><title>First-level fMRI analysis</title><p id="P54">We performed the first-level analysis using SPM12 (<ext-link ext-link-type="uri" xlink:href="https://www.fil.ion.ucl.ac.uk/spm/software/spm12/">https://www.fil.ion.ucl.ac.uk/spm/software/spm12/</ext-link>). General linear models (GLMs) were built to predict each participant’s blood-oxygen-level-dependent (BOLD) signal. The GLMs in the primary analysis included six conditions: the task prompt and the countdown at the beginning of each block, the reference event and the target event in the external-perspective task, and the reference event and the target event in the internal-perspective task. The duration of the task prompt and the countdown were set as the duration of the actual presentation (i.e., 5s and 3s, respectively). The duration of the four event conditions was set as 0. The resulting boxcar and stick functions were convolved with a canonical hemodynamic response function (HRF). Head motion parameters and constant variables indicating each of the six runs were included as nuisance regressors. A high-pass filter with a cutoff of 128s was used to remove the low-frequency noise and slow signal drifts.</p><p id="P55">We used the parametric modulation method to investigate the two core temporal variables: sequence (i.e., the number of events between the reference event and the target event) and duration (i.e., the duration of the target events in terms of hours). The z-scores of these parameters across the events in each run were set as parameters modulating the target events in both external- and internal-perspective tasks. The option for orthogonalizing modulations in the SPM was turned off (<xref ref-type="bibr" rid="R66">Mumford et al., 2015</xref>).</p><p id="P56">As a sanity check, we investigated whether the parametric modulation method in this study can successfully detect the visual cortex whose activation should be modulated by the number of syllables of the visually presented event phrase. To this end, we built a stick function with the sticks located on the onsets of both reference and target events and the “height” of the stick as the z score of the number of syllables across the event phrases in each run. This stick function was convolved with a canonical HRF as an additional regressor involved in the GLM.</p><p id="P57">To detect the specific activations for external- and internal-perspective tasks, we directly contrasted the target event in the external-perspective task and the target event in the internal-perspective task. To investigate how the neural activation was modulated by each of the temporal information across different perspectives, we looked at its interaction effect with the task (i.e., contrast the effect between external- and internal-perspective tasks, i.e., contrast weights vector: 1, -1) and the main effect regardless of tasks (i.e., contrast weights vector: 1, 1).</p><p id="P58">To validate whether any significant effects were explained by the RT, we also built the same GLM incorporating trial-by-trial RT as a covariate. To do so, we created a stick function with the sticks positioned at the onset of the target events in both external- and internal-perspective tasks, and the height of each stick was set to the z-score of the corresponding RT. These sticks were convolved with a canonical HRF to serve as a regressor in the GLM.</p><p id="P59">To directly illustrate how the activation level varied with the sequential distance, we built an independent GLM with each distance (i.e., from 1 to 5) in each task as a separate condition (i.e., ten conditions in total). To directly illustrate how the activation level varied with duration, we built another GLM with each duration (i.e., 0.5, 1, and 2 hours) in each task as a separate condition (i.e., six conditions in total). In both GLMs, we involved the task prompt and the countdown as conditions of no interest. The duration of the task prompt and the countdown were set as the duration of the actual presentation (i.e., 5s and 3s, respectively). The duration of all the other conditions was set as 0. The resulting boxcar and stick functions were convolved with the canonical HRF. Head motion parameters and constant variables indicating each of the six runs were included as nuisance regressors. A high-pass filter with a cutoff of 128s was used to remove the low-frequency noise and slow signal drifts.</p></sec><sec id="S17"><title>Second-level fMRI analysis</title><p id="P60">We performed the group-level one-sample test on the first-level beta images from the univariate contrast and parametric modulation analyses. The statistical inference was performed using the permutation method with PALM toolbox (<ext-link ext-link-type="uri" xlink:href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/PALM">https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/PALM</ext-link>). Five thousand sign flips were performed (<xref ref-type="bibr" rid="R107">Winkler et al., 2014</xref>), and a generalized Pareto distribution was fit to model the tail of the permutation distribution for the P values below 0.1 (<xref ref-type="bibr" rid="R56">Knijnenburg et al., 2009</xref>; <xref ref-type="bibr" rid="R106">Winkler et al., 2016</xref>). We controlled the family-wise error rate using a conventional cluster-forming threshold (i.e., voxel-wise p &lt; 0.001, cluster-level FWE corrected p &lt; 0.05) (<xref ref-type="bibr" rid="R110">Woo et al., 2014</xref>). Given that the hippocampus is our primary region of interest, its elongated and thin shape limits the number of contiguous voxels, restricting the formation of large clusters, and functionally independent clusters within the hippocampus may naturally be small, we performed multiple comparison corrections separately for the cortex and the hippocampus. We used the Automated Anatomical Labelling Atlas 3 to define these masks (<xref ref-type="bibr" rid="R81">Rolls et al., 2020</xref>). The cortical mask was defined as all the cortical regions in both hemispheres combined, and the hippocampal mask was defined as the hippocampus in both hemispheres combined (i.e., the No.41 and the No. 42 areas combined).</p></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary Materials</label><media xlink:href="EMS199988-supplement-Supplementary_Materials.pdf" mimetype="application" mime-subtype="pdf" id="d32aAcEbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S18"><title>Acknowledgments</title><p>This work was supported by the European Research Council (ERC-StG, NOAM 804422) and the Italian Ministry of University and Research (MUR-FARE, MODGET R18WJMSNZF) attributed to R.B. We thank Mattia Silvestri for the help with data collection and Simone Viganò for the discussion.</p></ack><ref-list><ref id="R1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abrahamse</surname><given-names>E</given-names></name><name><surname>Van Dijck</surname><given-names>JP</given-names></name><name><surname>Majerus</surname><given-names>S</given-names></name><name><surname>Fias</surname><given-names>W</given-names></name></person-group><article-title>Finding the answer in space: The mental whiteboard hypothesis on serial order in working memory</article-title><source>Frontiers in Human Neuroscience</source><year>2014</year><volume>8</volume><fpage>932</fpage><pub-id pub-id-type="pmcid">PMC4243569</pub-id><pub-id pub-id-type="pmid">25505394</pub-id><pub-id pub-id-type="doi">10.3389/fnhum.2014.00932</pub-id></element-citation></ref><ref id="R2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aguirre</surname><given-names>GK</given-names></name><name><surname>D’Esposito</surname><given-names>M</given-names></name></person-group><article-title>Topographical disorientation: a synthesis and taxonomy</article-title><source>Brain</source><year>1999</year><volume>122</volume><issue>9</issue><fpage>1613</fpage><lpage>1628</lpage><pub-id pub-id-type="pmid">10468502</pub-id></element-citation></ref><ref id="R3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andersen</surname><given-names>RA</given-names></name><name><surname>Essick</surname><given-names>GK</given-names></name><name><surname>Siegel</surname><given-names>RM</given-names></name></person-group><article-title>Encoding of spatial location by posterior parietal neurons</article-title><source>Science</source><year>1985</year><volume>230</volume><issue>4724</issue><fpage>456</fpage><lpage>458</lpage><pub-id pub-id-type="pmid">4048942</pub-id></element-citation></ref><ref id="R4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andersen</surname><given-names>RA</given-names></name><name><surname>Snyder</surname><given-names>LH</given-names></name><name><surname>Bradley</surname><given-names>DC</given-names></name><name><surname>Xing</surname><given-names>J</given-names></name></person-group><article-title>Multimodal representation of space in the posterior parietal cortex and its use in planning movements</article-title><source>Annual Review of Neuroscience</source><year>1997</year><volume>20</volume><issue>1</issue><fpage>303</fpage><lpage>330</lpage><pub-id pub-id-type="pmid">9056716</pub-id></element-citation></ref><ref id="R5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arzy</surname><given-names>S</given-names></name><name><surname>Schacter</surname><given-names>DL</given-names></name></person-group><article-title>Self-agency and self-ownership in cognitive mapping</article-title><source>Trends in Cognitive Sciences</source><year>2019</year><volume>23</volume><issue>6</issue><fpage>476</fpage><lpage>487</lpage><pub-id pub-id-type="pmcid">PMC6584024</pub-id><pub-id pub-id-type="pmid">31064702</pub-id><pub-id pub-id-type="doi">10.1016/j.tics.2019.04.003</pub-id></element-citation></ref><ref id="R6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arzy</surname><given-names>S</given-names></name><name><surname>Adi-Japha</surname><given-names>E</given-names></name><name><surname>Blanke</surname><given-names>O</given-names></name></person-group><article-title>The mental time line: An analogue of the mental number line in the mapping of life events</article-title><source>Consciousness and Cognition</source><year>2009a</year><volume>18</volume><issue>3</issue><fpage>781</fpage><lpage>785</lpage><pub-id pub-id-type="pmid">19553141</pub-id></element-citation></ref><ref id="R7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arzy</surname><given-names>S</given-names></name><name><surname>Collette</surname><given-names>S</given-names></name><name><surname>Ionta</surname><given-names>S</given-names></name><name><surname>Fornari</surname><given-names>E</given-names></name><name><surname>Blanke</surname><given-names>O</given-names></name></person-group><article-title>Subjective mental time: the functional architecture of projecting the self to past and future</article-title><source>European Journal of Neuroscience</source><year>2009b</year><volume>30</volume><issue>10</issue><fpage>2009</fpage><lpage>2017</lpage><pub-id pub-id-type="pmid">19912333</pub-id></element-citation></ref><ref id="R8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arzy</surname><given-names>S</given-names></name><name><surname>Molnar-Szakacs</surname><given-names>I</given-names></name><name><surname>Blanke</surname><given-names>O</given-names></name></person-group><article-title>Self in time: imagined self-location influences neural activity related to mental time travel</article-title><source>Journal of Neuroscience</source><year>2008</year><volume>28</volume><issue>25</issue><fpage>6502</fpage><lpage>6507</lpage><pub-id pub-id-type="pmcid">PMC6670885</pub-id><pub-id pub-id-type="pmid">18562621</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5712-07.2008</pub-id></element-citation></ref><ref id="R9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bálint</surname><given-names>R</given-names><suffix>Dr</suffix></name></person-group><article-title>Seelenlähmung des “Schauens”, optische Ataxie, räumliche Störung der Aufmerksamkeit</article-title><source>European Neurology</source><year>1909</year><volume>25</volume><issue>1</issue><fpage>51</fpage><lpage>66</lpage><comment>51–66</comment></element-citation></ref><ref id="R10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barnett</surname><given-names>AJ</given-names></name><name><surname>O’Neill</surname><given-names>EB</given-names></name><name><surname>Watson</surname><given-names>HC</given-names></name><name><surname>Lee</surname><given-names>AC</given-names></name></person-group><article-title>The human hippocampus is sensitive to the durations of events and intervals within a sequence</article-title><source>Neuropsychologia</source><year>2014</year><volume>64</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="pmid">25223466</pub-id></element-citation></ref><ref id="R11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barr</surname><given-names>DJ</given-names></name><name><surname>Levy</surname><given-names>R</given-names></name><name><surname>Scheepers</surname><given-names>C</given-names></name><name><surname>Tily</surname><given-names>HJ</given-names></name></person-group><article-title>Random effects structure for confirmatory hypothesis testing: Keep it maximal</article-title><source>Journal of Memory and Language</source><year>2013</year><volume>68</volume><issue>3</issue><fpage>255</fpage><lpage>278</lpage><pub-id pub-id-type="pmcid">PMC3881361</pub-id><pub-id pub-id-type="pmid">24403724</pub-id><pub-id pub-id-type="doi">10.1016/j.jml.2012.11.001</pub-id></element-citation></ref><ref id="R12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bellmund</surname><given-names>JL</given-names></name><name><surname>Deuker</surname><given-names>L</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name></person-group><article-title>Mapping sequence structure in the human lateral entorhinal cortex</article-title><source>Elife</source><year>2019</year><volume>8</volume><elocation-id>e45333</elocation-id><pub-id pub-id-type="pmcid">PMC6684227</pub-id><pub-id pub-id-type="pmid">31383256</pub-id><pub-id pub-id-type="doi">10.7554/eLife.45333</pub-id></element-citation></ref><ref id="R13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bellmund</surname><given-names>JL</given-names></name><name><surname>Deuker</surname><given-names>L</given-names></name><name><surname>Montijn</surname><given-names>ND</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name></person-group><article-title>Mnemonic construction and representation of temporal structure in the hippocampal formation</article-title><source>Nature Communications</source><year>2022</year><volume>13</volume><issue>1</issue><elocation-id>3395</elocation-id><pub-id pub-id-type="pmcid">PMC9226117</pub-id><pub-id pub-id-type="pmid">35739096</pub-id><pub-id pub-id-type="doi">10.1038/s41467-022-30984-3</pub-id></element-citation></ref><ref id="R14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bellmund</surname><given-names>JL</given-names></name><name><surname>Polti</surname><given-names>I</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name></person-group><article-title>Sequence memory in the hippocampal–entorhinal region</article-title><source>Journal of Cognitive Neuroscience</source><year>2020</year><volume>32</volume><issue>11</issue><fpage>2056</fpage><lpage>2070</lpage><pub-id pub-id-type="pmid">32530378</pub-id></element-citation></ref><ref id="R15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bender</surname><given-names>A</given-names></name><name><surname>Beller</surname><given-names>S</given-names></name></person-group><article-title>Mapping spatial frames of reference onto time: A review of theoretical accounts and empirical findings</article-title><source>Cognition</source><year>2014</year><volume>132</volume><issue>3</issue><fpage>342</fpage><lpage>382</lpage><pub-id pub-id-type="pmid">24873738</pub-id></element-citation></ref><ref id="R16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berryhill</surname><given-names>ME</given-names></name><name><surname>Phuong</surname><given-names>L</given-names></name><name><surname>Picasso</surname><given-names>L</given-names></name><name><surname>Cabeza</surname><given-names>R</given-names></name><name><surname>Olson</surname><given-names>IR</given-names></name></person-group><article-title>Parietal lobe and episodic memory: bilateral damage causes impaired free recall of autobiographical memory</article-title><source>Journal of Neuroscience</source><year>2007</year><volume>27</volume><issue>52</issue><fpage>14415</fpage><lpage>14423</lpage><pub-id pub-id-type="pmcid">PMC6673454</pub-id><pub-id pub-id-type="pmid">18160649</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4163-07.2007</pub-id></element-citation></ref><ref id="R17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bicanski</surname><given-names>A</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><article-title>A neural-level model of spatial memory and imagery</article-title><source>Elife</source><year>2018</year><volume>7</volume><elocation-id>e33752</elocation-id><pub-id pub-id-type="pmcid">PMC6122954</pub-id><pub-id pub-id-type="pmid">30176988</pub-id><pub-id pub-id-type="doi">10.7554/eLife.33752</pub-id></element-citation></ref><ref id="R18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bicanski</surname><given-names>A</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><article-title>Neuronal vector coding in spatial cognition</article-title><source>Nature Reviews Neuroscience</source><year>2020</year><volume>21</volume><issue>9</issue><fpage>453</fpage><lpage>470</lpage><pub-id pub-id-type="pmid">32764728</pub-id></element-citation></ref><ref id="R19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blanke</surname><given-names>O</given-names></name><name><surname>Arzy</surname><given-names>S</given-names></name></person-group><article-title>The out-of-body experience: disturbed self-processing at the temporoparietal junction</article-title><source>The Neuroscientist</source><year>2005</year><volume>11</volume><issue>1</issue><fpage>16</fpage><lpage>24</lpage><pub-id pub-id-type="pmid">15632275</pub-id></element-citation></ref><ref id="R20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blanke</surname><given-names>O</given-names></name><name><surname>Landis</surname><given-names>T</given-names></name><name><surname>Spinelli</surname><given-names>L</given-names></name><name><surname>Seeck</surname><given-names>M</given-names></name></person-group><article-title>Out-of-body experience and autoscopy of neurological origin</article-title><source>Brain</source><year>2004</year><volume>127</volume><issue>2</issue><fpage>243</fpage><lpage>258</lpage><pub-id pub-id-type="pmid">14662516</pub-id></element-citation></ref><ref id="R21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bottini</surname><given-names>R</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name></person-group><article-title>Knowledge across reference frames: Cognitive maps and image spaces</article-title><source>Trends in Cognitive Sciences</source><year>2020</year><volume>24</volume><issue>8</issue><fpage>606</fpage><lpage>619</lpage><pub-id pub-id-type="pmid">32586649</pub-id></element-citation></ref><ref id="R22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Braga</surname><given-names>RM</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name></person-group><article-title>Parallel interdigitated distributed networks within the individual estimated by intrinsic functional connectivity</article-title><source>Neuron</source><year>2017</year><volume>95</volume><issue>2</issue><fpage>457</fpage><lpage>471</lpage><pub-id pub-id-type="pmcid">PMC5519493</pub-id><pub-id pub-id-type="pmid">28728026</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.038</pub-id></element-citation></ref><ref id="R23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buckner</surname><given-names>RL</given-names></name><name><surname>Carroll</surname><given-names>DC</given-names></name></person-group><article-title>Self-projection and the brain</article-title><source>Trends in Cognitive Sciences</source><year>2007</year><volume>11</volume><issue>2</issue><fpage>49</fpage><lpage>57</lpage><pub-id pub-id-type="pmid">17188554</pub-id></element-citation></ref><ref id="R24"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Buonomano</surname><given-names>D</given-names></name></person-group><source>Your brain is a time machine: The neuroscience and physics of time</source><publisher-name>WW Norton &amp; Company</publisher-name><year>2017</year></element-citation></ref><ref id="R25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buonomano</surname><given-names>DV</given-names></name><name><surname>Laje</surname><given-names>R</given-names></name></person-group><article-title>Population clocks: motor timing with neural dynamics</article-title><source>Trends in Cognitive Sciences</source><year>2010</year><volume>14</volume><issue>12</issue><fpage>520</fpage><lpage>527</lpage><pub-id pub-id-type="pmcid">PMC2991437</pub-id><pub-id pub-id-type="pmid">20889368</pub-id><pub-id pub-id-type="doi">10.1016/j.tics.2010.09.002</pub-id></element-citation></ref><ref id="R26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buzsáki</surname><given-names>G</given-names></name><name><surname>Tingley</surname><given-names>D</given-names></name></person-group><article-title>Space and time: the hippocampus as a sequence generator</article-title><source>Trends in Cognitive Sciences</source><year>2018</year><volume>22</volume><issue>10</issue><fpage>853</fpage><lpage>869</lpage><pub-id pub-id-type="pmcid">PMC6166479</pub-id><pub-id pub-id-type="pmid">30266146</pub-id><pub-id pub-id-type="doi">10.1016/j.tics.2018.07.006</pub-id></element-citation></ref><ref id="R27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Byrne</surname><given-names>P</given-names></name><name><surname>Becker</surname><given-names>S</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><article-title>Remembering the past and imagining the future: a neural model of spatial memory and imagery</article-title><source>Psychological Review</source><year>2007</year><volume>114</volume><issue>2</issue><fpage>340</fpage><pub-id pub-id-type="pmcid">PMC2678675</pub-id><pub-id pub-id-type="pmid">17500630</pub-id><pub-id pub-id-type="doi">10.1037/0033-295X.114.2.340</pub-id></element-citation></ref><ref id="R28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cabeza</surname><given-names>R</given-names></name><name><surname>Ciaramelli</surname><given-names>E</given-names></name><name><surname>Olson</surname><given-names>IR</given-names></name><name><surname>Moscovitch</surname><given-names>M</given-names></name></person-group><article-title>The parietal cortex and episodic memory: an attentional account</article-title><source>Nature Reviews Neuroscience</source><year>2008</year><volume>9</volume><issue>8</issue><fpage>613</fpage><lpage>625</lpage><pub-id pub-id-type="pmcid">PMC2692883</pub-id><pub-id pub-id-type="pmid">18641668</pub-id><pub-id pub-id-type="doi">10.1038/nrn2459</pub-id></element-citation></ref><ref id="R29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caspers</surname><given-names>S</given-names></name><name><surname>Eickhoff</surname><given-names>SB</given-names></name><name><surname>Geyer</surname><given-names>S</given-names></name><name><surname>Scheperjans</surname><given-names>F</given-names></name><name><surname>Mohlberg</surname><given-names>H</given-names></name><name><surname>Zilles</surname><given-names>K</given-names></name><name><surname>Amunts</surname><given-names>K</given-names></name></person-group><article-title>The human inferior parietal lobule in stereotaxic space</article-title><source>Brain Structure and Function</source><year>2008</year><volume>212</volume><fpage>481</fpage><lpage>495</lpage><pub-id pub-id-type="pmid">18651173</pub-id></element-citation></ref><ref id="R30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caspers</surname><given-names>S</given-names></name><name><surname>Geyer</surname><given-names>S</given-names></name><name><surname>Schleicher</surname><given-names>A</given-names></name><name><surname>Mohlberg</surname><given-names>H</given-names></name><name><surname>Amunts</surname><given-names>K</given-names></name><name><surname>Zilles</surname><given-names>K</given-names></name></person-group><article-title>The human inferior parietal cortex: cytoarchitectonic parcellation and interindividual variability</article-title><source>Neuroimage</source><year>2006</year><volume>33</volume><issue>2</issue><fpage>430</fpage><lpage>448</lpage><pub-id pub-id-type="pmid">16949304</pub-id></element-citation></ref><ref id="R31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chechlacz</surname><given-names>M</given-names></name><name><surname>Humphreys</surname><given-names>GW</given-names></name></person-group><article-title>The enigma of Bálint’s syndrome: neural substrates and cognitive deficits</article-title><source>Frontiers in Human Neuroscience</source><year>2014</year><volume>8</volume><fpage>123</fpage><pub-id pub-id-type="pmcid">PMC3945799</pub-id><pub-id pub-id-type="pmid">24639641</pub-id><pub-id pub-id-type="doi">10.3389/fnhum.2014.00123</pub-id></element-citation></ref><ref id="R32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ciaramelli</surname><given-names>E</given-names></name><name><surname>Grady</surname><given-names>CL</given-names></name><name><surname>Moscovitch</surname><given-names>M</given-names></name></person-group><article-title>Top-down and bottom-up attention to memory: a hypothesis (AtoM) on the role of the posterior parietal cortex in memory retrieval</article-title><source>Neuropsychologia</source><year>2008</year><volume>46</volume><issue>7</issue><fpage>1828</fpage><lpage>1851</lpage><pub-id pub-id-type="pmid">18471837</pub-id></element-citation></ref><ref id="R33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>YE</given-names></name><name><surname>Andersen</surname><given-names>RA</given-names></name></person-group><article-title>A common reference frame for movement plans in the posterior parietal cortex</article-title><source>Nature Reviews Neuroscience</source><year>2002</year><volume>3</volume><issue>7</issue><fpage>553</fpage><lpage>562</lpage><pub-id pub-id-type="pmid">12094211</pub-id></element-citation></ref><ref id="R34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohn-Sheehy</surname><given-names>BI</given-names></name><name><surname>Ranganath</surname><given-names>C</given-names></name></person-group><article-title>Time regained: how the human brain constructs memory for time</article-title><source>Current Opinion in Behavioral Sciences</source><year>2017</year><volume>17</volume><fpage>169</fpage><lpage>177</lpage><pub-id pub-id-type="pmcid">PMC6345531</pub-id><pub-id pub-id-type="pmid">30687774</pub-id><pub-id pub-id-type="doi">10.1016/j.cobeha.2017.08.005</pub-id></element-citation></ref><ref id="R35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collin</surname><given-names>SH</given-names></name><name><surname>Milivojevic</surname><given-names>B</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name></person-group><article-title>Memory hierarchies map onto the hippocampal long axis in humans</article-title><source>Nature Neuroscience</source><year>2015</year><volume>18</volume><issue>11</issue><fpage>1562</fpage><lpage>1564</lpage><pub-id pub-id-type="pmcid">PMC4665212</pub-id><pub-id pub-id-type="pmid">26479587</pub-id><pub-id pub-id-type="doi">10.1038/nn.4138</pub-id></element-citation></ref><ref id="R36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Kock</surname><given-names>R</given-names></name><name><surname>Gladhill</surname><given-names>KA</given-names></name><name><surname>Ali</surname><given-names>MN</given-names></name><name><surname>Joiner</surname><given-names>WM</given-names></name><name><surname>Wiener</surname><given-names>M</given-names></name></person-group><article-title>How movements shape the perception of time</article-title><source>Trends in Cognitive Sciences</source><year>2021</year><volume>25</volume><issue>11</issue><fpage>950</fpage><lpage>963</lpage><pub-id pub-id-type="pmcid">PMC9991018</pub-id><pub-id pub-id-type="pmid">34531138</pub-id><pub-id pub-id-type="doi">10.1016/j.tics.2021.08.002</pub-id></element-citation></ref><ref id="R37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dede</surname><given-names>AJ</given-names></name><name><surname>Frascino</surname><given-names>JC</given-names></name><name><surname>Wixted</surname><given-names>JT</given-names></name><name><surname>Squire</surname><given-names>LR</given-names></name></person-group><article-title>Learning and remembering real-world events after medial temporal lobe damage</article-title><source>Proceedings of the National Academy of Sciences</source><year>2016</year><volume>113</volume><issue>47</issue><fpage>13480</fpage><lpage>13485</lpage><pub-id pub-id-type="pmcid">PMC5127365</pub-id><pub-id pub-id-type="pmid">27821761</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1617025113</pub-id></element-citation></ref><ref id="R38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deuker</surname><given-names>L</given-names></name><name><surname>Bellmund</surname><given-names>JL</given-names></name><name><surname>Navarro Schröder</surname><given-names>T</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name></person-group><article-title>An event map of memory space in the hippocampus</article-title><source>Elife</source><year>2016</year><volume>5</volume><elocation-id>e16534</elocation-id><pub-id pub-id-type="pmcid">PMC5053807</pub-id><pub-id pub-id-type="pmid">27710766</pub-id><pub-id pub-id-type="doi">10.7554/eLife.16534</pub-id></element-citation></ref><ref id="R39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DiNicola</surname><given-names>LM</given-names></name><name><surname>Braga</surname><given-names>RM</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name></person-group><article-title>Parallel distributed networks dissociate episodic and social functions within the individual</article-title><source>Journal of Neurophysiology</source><year>2020</year><volume>123</volume><issue>3</issue><fpage>1144</fpage><lpage>1179</lpage><pub-id pub-id-type="pmcid">PMC7099479</pub-id><pub-id pub-id-type="pmid">32049593</pub-id><pub-id pub-id-type="doi">10.1152/jn.00529.2019</pub-id></element-citation></ref><ref id="R40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dutriaux</surname><given-names>L</given-names></name><name><surname>Xu</surname><given-names>Y</given-names></name><name><surname>Sartorato</surname><given-names>N</given-names></name><name><surname>Lhuillier</surname><given-names>S</given-names></name><name><surname>Bottini</surname><given-names>R</given-names></name></person-group><article-title>Disentangling reference frames in the neural compass</article-title><source>Imaging Neuroscience</source><year>2024</year><volume>2</volume><fpage>1</fpage><lpage>18</lpage></element-citation></ref><ref id="R41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><article-title>Time cells in the hippocampus: a new dimension for mapping memories</article-title><source>Nature Reviews Neuroscience</source><year>2014</year><volume>15</volume><issue>11</issue><fpage>732</fpage><lpage>744</lpage><pub-id pub-id-type="pmcid">PMC4348090</pub-id><pub-id pub-id-type="pmid">25269553</pub-id><pub-id pub-id-type="doi">10.1038/nrn3827</pub-id></element-citation></ref><ref id="R42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><article-title>On the integration of space, time, and memory</article-title><source>Neuron</source><year>2017</year><volume>95</volume><issue>5</issue><fpage>1007</fpage><lpage>1018</lpage><pub-id pub-id-type="pmcid">PMC5662113</pub-id><pub-id pub-id-type="pmid">28858612</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.036</pub-id></element-citation></ref><ref id="R43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eickhoff</surname><given-names>SB</given-names></name><name><surname>Stephan</surname><given-names>KE</given-names></name><name><surname>Mohlberg</surname><given-names>H</given-names></name><name><surname>Grefkes</surname><given-names>C</given-names></name><name><surname>Fink</surname><given-names>GR</given-names></name><name><surname>Amunts</surname><given-names>K</given-names></name><name><surname>Zilles</surname><given-names>K</given-names></name></person-group><article-title>A new SPM toolbox for combining probabilistic cytoarchitectonic maps and functional imaging data</article-title><source>Neuroimage</source><year>2005</year><volume>25</volume><issue>4</issue><fpage>1325</fpage><lpage>1335</lpage><pub-id pub-id-type="pmid">15850749</pub-id></element-citation></ref><ref id="R44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ekstrom</surname><given-names>AD</given-names></name><name><surname>Arnold</surname><given-names>AE</given-names></name><name><surname>Iaria</surname><given-names>G</given-names></name></person-group><article-title>A critical review of the allocentric spatial representation and its neural underpinnings: toward a network-based perspective</article-title><source>Frontiers in Human Neuroscience</source><year>2014</year><volume>8</volume><fpage>803</fpage><pub-id pub-id-type="pmcid">PMC4193251</pub-id><pub-id pub-id-type="pmid">25346679</pub-id><pub-id pub-id-type="doi">10.3389/fnhum.2014.00803</pub-id></element-citation></ref><ref id="R45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Filimon</surname><given-names>F</given-names></name></person-group><article-title>Are all spatial reference frames egocentric? Reinterpreting evidence for allocentric, object-centered, or world-centered reference frames</article-title><source>Frontiers in Human Neuroscience</source><year>2015</year><volume>9</volume><fpage>648</fpage><pub-id pub-id-type="pmcid">PMC4673307</pub-id><pub-id pub-id-type="pmid">26696861</pub-id><pub-id pub-id-type="doi">10.3389/fnhum.2015.00648</pub-id></element-citation></ref><ref id="R46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gauthier</surname><given-names>B</given-names></name><name><surname>van Wassenhove</surname><given-names>V</given-names></name></person-group><article-title>Cognitive mapping in mental time travel and mental space navigation</article-title><source>Cognition</source><year>2016a</year><volume>154</volume><fpage>55</fpage><lpage>68</lpage><pub-id pub-id-type="pmid">27239750</pub-id></element-citation></ref><ref id="R47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gauthier</surname><given-names>B</given-names></name><name><surname>van Wassenhove</surname><given-names>V</given-names></name></person-group><article-title>Time is not space: core computations and domain-specific networks for mental travels</article-title><source>Journal of Neuroscience</source><year>2016b</year><volume>36</volume><issue>47</issue><fpage>11891</fpage><lpage>11903</lpage><pub-id pub-id-type="pmcid">PMC6604919</pub-id><pub-id pub-id-type="pmid">27881776</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1400-16.2016</pub-id></element-citation></ref><ref id="R48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gauthier</surname><given-names>B</given-names></name><name><surname>Pestke</surname><given-names>K</given-names></name><name><surname>van Wassenhove</surname><given-names>V</given-names></name></person-group><article-title>Building the arrow of time… over time: a sequence of brain activity mapping imagined events in time and space</article-title><source>Cerebral Cortex</source><year>2019</year><volume>29</volume><issue>10</issue><fpage>4398</fpage><lpage>4414</lpage><pub-id pub-id-type="pmid">30566689</pub-id></element-citation></ref><ref id="R49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gauthier</surname><given-names>B</given-names></name><name><surname>Prabhu</surname><given-names>P</given-names></name><name><surname>Kotegar</surname><given-names>KA</given-names></name><name><surname>van Wassenhove</surname><given-names>V</given-names></name></person-group><article-title>Hippocampal contribution to ordinal psychological time in the human brain</article-title><source>Journal of Cognitive Neuroscience</source><year>2020</year><volume>32</volume><issue>11</issue><fpage>2071</fpage><lpage>2086</lpage><pub-id pub-id-type="pmid">32459130</pub-id></element-citation></ref><ref id="R50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holmes</surname><given-names>G</given-names></name><name><surname>Horrax</surname><given-names>G</given-names></name></person-group><article-title>Disturbances of spatial orientation and visual attention, with loss of stereoscopic vision</article-title><source>Archives of Neurology &amp; Psychiatry</source><year>1919</year><volume>1</volume><issue>4</issue><fpage>385</fpage><lpage>407</lpage></element-citation></ref><ref id="R51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hutchinson</surname><given-names>JB</given-names></name><name><surname>Uncapher</surname><given-names>MR</given-names></name><name><surname>Wagner</surname><given-names>AD</given-names></name></person-group><article-title>Posterior parietal cortex and episodic retrieval: convergent and divergent effects of attention and memory</article-title><source>Learning &amp; Memory</source><year>2009</year><volume>16</volume><issue>6</issue><fpage>343</fpage><lpage>356</lpage><pub-id pub-id-type="pmcid">PMC2704099</pub-id><pub-id pub-id-type="pmid">19470649</pub-id><pub-id pub-id-type="doi">10.1101/lm.919109</pub-id></element-citation></ref><ref id="R52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jung</surname><given-names>MW</given-names></name><name><surname>Wiener</surname><given-names>SI</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><article-title>Comparison of spatial firing characteristics of units in dorsal and ventral hippocampus of the rat</article-title><source>Journal of Neuroscience</source><year>1994</year><volume>14</volume><issue>12</issue><fpage>7347</fpage><lpage>7356</lpage><pub-id pub-id-type="pmcid">PMC6576902</pub-id><pub-id pub-id-type="pmid">7996180</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.14-12-07347.1994</pub-id></element-citation></ref><ref id="R53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kase</surname><given-names>CS</given-names></name><name><surname>Troncoso</surname><given-names>JF</given-names></name><name><surname>Court</surname><given-names>JE</given-names></name><name><surname>Tapia</surname><given-names>JF</given-names></name><name><surname>Mohr</surname><given-names>JP</given-names></name></person-group><article-title>Global spatial disorientation: clinico-pathologic correlations</article-title><source>Journal of the Neurological Sciences</source><year>1977</year><volume>34</volume><issue>2</issue><fpage>267</fpage><lpage>278</lpage><pub-id pub-id-type="pmid">925713</pub-id></element-citation></ref><ref id="R54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kjelstrup</surname><given-names>KB</given-names></name><name><surname>Solstad</surname><given-names>T</given-names></name><name><surname>Brun</surname><given-names>VH</given-names></name><name><surname>Hafting</surname><given-names>T</given-names></name><name><surname>Leutgeb</surname><given-names>S</given-names></name><name><surname>Witter</surname><given-names>MP</given-names></name><etal/><name><surname>Moser</surname><given-names>MB</given-names></name></person-group><article-title>Finite scale of spatial representation in the hippocampus</article-title><source>Science</source><year>2008</year><volume>321</volume><issue>5885</issue><fpage>140</fpage><lpage>1</lpage><pub-id pub-id-type="pmid">18599792</pub-id></element-citation></ref><ref id="R55"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Klatzky</surname><given-names>RL</given-names></name></person-group><chapter-title>Allocentric and egocentric spatial representations: Definitions, distinctions, and interconnections</chapter-title><source>Spatial cognition: An interdisciplinary approach to representing and processing spatial knowledge</source><publisher-name>Springer Berlin Heidelberg</publisher-name><publisher-loc>Berlin, Heidelberg</publisher-loc><year>1998</year><fpage>1</fpage><lpage>17</lpage></element-citation></ref><ref id="R56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knijnenburg</surname><given-names>TA</given-names></name><name><surname>Wessels</surname><given-names>LF</given-names></name><name><surname>Reinders</surname><given-names>MJ</given-names></name><name><surname>Shmulevich</surname><given-names>I</given-names></name></person-group><article-title>Fewer permutations, more accurate P-values</article-title><source>Bioinformatics</source><year>2009</year><volume>25</volume><issue>12</issue><fpage>i161</fpage><lpage>i168</lpage><pub-id pub-id-type="pmcid">PMC2687965</pub-id><pub-id pub-id-type="pmid">19477983</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/btp211</pub-id></element-citation></ref><ref id="R57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kosslyn</surname><given-names>SM</given-names></name><name><surname>Ball</surname><given-names>TM</given-names></name><name><surname>Reiser</surname><given-names>BJ</given-names></name></person-group><article-title>Visual images preserve metric spatial information: evidence from studies of image scanning</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><year>1978</year><volume>4</volume><issue>1</issue><fpage>47</fpage><pub-id pub-id-type="pmid">627850</pub-id></element-citation></ref><ref id="R58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>AC</given-names></name><name><surname>Thavabalasingam</surname><given-names>S</given-names></name><name><surname>Alushaj</surname><given-names>D</given-names></name><name><surname>Çavdaroğlu</surname><given-names>B</given-names></name><name><surname>Ito</surname><given-names>R</given-names></name></person-group><article-title>The hippocampus contributes to temporal duration memory in the context of event sequences: A cross-species perspective</article-title><source>Neuropsychologia</source><year>2020</year><volume>137</volume><elocation-id>107300</elocation-id><pub-id pub-id-type="pmid">31836410</pub-id></element-citation></ref><ref id="R59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levine</surname><given-names>DN</given-names></name><name><surname>Warach</surname><given-names>J</given-names></name><name><surname>Farah</surname><given-names>M</given-names></name></person-group><article-title>Two visual systems in mental imagery: Dissociation of “what” and “where” in imagery disorders due to bilateral posterior cerebral lesions</article-title><source>Neurology</source><year>1985</year><volume>35</volume><issue>7</issue><fpage>1010</fpage><comment>1010</comment><pub-id pub-id-type="pmid">4010939</pub-id></element-citation></ref><ref id="R60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>N</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Xu</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Hua</surname><given-names>H</given-names></name><name><surname>Zhao</surname><given-names>Y</given-names></name><name><surname>Li</surname><given-names>X</given-names></name></person-group><article-title>Fine subdivisions of the semantic network supporting social and sensory–motor semantic processing</article-title><source>Cerebral Cortex</source><year>2018</year><volume>28</volume><issue>8</issue><fpage>2699</fpage><lpage>2710</lpage><pub-id pub-id-type="pmid">28633369</pub-id></element-citation></ref><ref id="R61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Matuschek</surname><given-names>H</given-names></name><name><surname>Kliegl</surname><given-names>R</given-names></name><name><surname>Vasishth</surname><given-names>S</given-names></name><name><surname>Baayen</surname><given-names>H</given-names></name><name><surname>Bates</surname><given-names>D</given-names></name></person-group><article-title>Balancing Type I error and power in linear mixed models</article-title><source>Journal of Memory and Language</source><year>2017</year><volume>94</volume><fpage>305</fpage><lpage>315</lpage></element-citation></ref><ref id="R62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McTaggart</surname><given-names>JE</given-names></name></person-group><article-title>The unreality of time</article-title><source>Mind</source><year>1908</year><fpage>457</fpage><lpage>474</lpage></element-citation></ref><ref id="R63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moyer</surname><given-names>RS</given-names></name><name><surname>Bayer</surname><given-names>RH</given-names></name></person-group><article-title>Mental comparison and the symbolic distance effect</article-title><source>Cognitive Psychology</source><year>1976</year><volume>8</volume><issue>2</issue><fpage>228</fpage><lpage>246</lpage></element-citation></ref><ref id="R64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moyer</surname><given-names>RS</given-names></name><name><surname>Landauer</surname><given-names>TK</given-names></name></person-group><article-title>Time required for judgements of numerical inequality</article-title><source>Nature</source><year>1967</year><volume>215</volume><issue>5109</issue><fpage>1519</fpage><lpage>1520</lpage><pub-id pub-id-type="pmid">6052760</pub-id></element-citation></ref><ref id="R65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muller</surname><given-names>RU</given-names></name><name><surname>Stead</surname><given-names>M</given-names></name><name><surname>Pach</surname><given-names>J</given-names></name></person-group><article-title>The hippocampus as a cognitive graph</article-title><source>The Journal of General Physiology</source><year>1996</year><volume>107</volume><issue>6</issue><fpage>663</fpage><pub-id pub-id-type="pmcid">PMC2219396</pub-id><pub-id pub-id-type="pmid">8783070</pub-id><pub-id pub-id-type="doi">10.1085/jgp.107.6.663</pub-id></element-citation></ref><ref id="R66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mumford</surname><given-names>JA</given-names></name><name><surname>Poline</surname><given-names>JB</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name></person-group><article-title>Orthogonalization of regressors in fMRI models</article-title><source>PLOS One</source><year>2015</year><volume>10</volume><issue>4</issue><elocation-id>e0126255</elocation-id><pub-id pub-id-type="pmcid">PMC4412813</pub-id><pub-id pub-id-type="pmid">25919488</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0126255</pub-id></element-citation></ref><ref id="R67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nani</surname><given-names>A</given-names></name><name><surname>Manuello</surname><given-names>J</given-names></name><name><surname>Liloia</surname><given-names>D</given-names></name><name><surname>Duca</surname><given-names>S</given-names></name><name><surname>Costa</surname><given-names>T</given-names></name><name><surname>Cauda</surname><given-names>F</given-names></name></person-group><article-title>The neural correlates of time: a meta-analysis of neuroimaging studies</article-title><source>Journal of Cognitive Neuroscience</source><year>2019</year><volume>31</volume><issue>12</issue><fpage>1796</fpage><lpage>1826</lpage><pub-id pub-id-type="pmid">31418337</pub-id></element-citation></ref><ref id="R68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Núñez</surname><given-names>R</given-names></name><name><surname>Cooperrider</surname><given-names>K</given-names></name></person-group><article-title>The tangle of space and time in human cognition</article-title><source>Trends in Cognitive Sciences</source><year>2013</year><volume>17</volume><issue>5</issue><fpage>220</fpage><lpage>229</lpage><pub-id pub-id-type="pmid">23608363</pub-id></element-citation></ref><ref id="R69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’keefe</surname><given-names>J</given-names></name><name><surname>Nadel</surname><given-names>L</given-names></name></person-group><source>The hippocampus as a cognitive map</source><year>1978</year></element-citation></ref><ref id="R70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parkinson</surname><given-names>C</given-names></name><name><surname>Liu</surname><given-names>S</given-names></name><name><surname>Wheatley</surname><given-names>T</given-names></name></person-group><article-title>A common cortical metric for spatial, temporal, and social distance</article-title><source>Journal of Neuroscience</source><year>2014</year><volume>34</volume><issue>5</issue><fpage>1979</fpage><lpage>1987</lpage><pub-id pub-id-type="pmcid">PMC6827593</pub-id><pub-id pub-id-type="pmid">24478377</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2159-13.2014</pub-id></element-citation></ref><ref id="R71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peer</surname><given-names>M</given-names></name><name><surname>Salomon</surname><given-names>R</given-names></name><name><surname>Goldberg</surname><given-names>I</given-names></name><name><surname>Blanke</surname><given-names>O</given-names></name><name><surname>Arzy</surname><given-names>S</given-names></name></person-group><article-title>Brain system for mental orientation in space, time, and person</article-title><source>Proceedings of the National Academy of Sciences</source><year>2015</year><volume>112</volume><issue>35</issue><fpage>11072</fpage><lpage>11077</lpage><pub-id pub-id-type="pmcid">PMC4568229</pub-id><pub-id pub-id-type="pmid">26283353</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1504242112</pub-id></element-citation></ref><ref id="R72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poppenk</surname><given-names>J</given-names></name><name><surname>Evensmoen</surname><given-names>HR</given-names></name><name><surname>Moscovitch</surname><given-names>M</given-names></name><name><surname>Nadel</surname><given-names>L</given-names></name></person-group><article-title>Long-axis specialization of the human hippocampus</article-title><source>Trends in Cognitive sciences</source><year>2013</year><volume>17</volume><issue>5</issue><fpage>230</fpage><lpage>240</lpage><pub-id pub-id-type="pmid">23597720</pub-id></element-citation></ref><ref id="R73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Power</surname><given-names>JD</given-names></name><name><surname>Mitra</surname><given-names>A</given-names></name><name><surname>Laumann</surname><given-names>TO</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Schlaggar</surname><given-names>BL</given-names></name><name><surname>Petersen</surname><given-names>SE</given-names></name></person-group><article-title>Methods to detect, characterize, and remove motion artifact in resting state fMRI</article-title><source>Neuroimage</source><year>2014</year><volume>84</volume><fpage>320</fpage><lpage>341</lpage><pub-id pub-id-type="pmcid">PMC3849338</pub-id><pub-id pub-id-type="pmid">23994314</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.08.048</pub-id></element-citation></ref><ref id="R74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Protopapa</surname><given-names>F</given-names></name><name><surname>Hayashi</surname><given-names>MJ</given-names></name><name><surname>Kulashekhar</surname><given-names>S</given-names></name><name><surname>van der Zwaag</surname><given-names>W</given-names></name><name><surname>Battistella</surname><given-names>G</given-names></name><name><surname>Murray</surname><given-names>MM</given-names></name><etal/><name><surname>Bueti</surname><given-names>D</given-names></name></person-group><article-title>Chronotopic maps in human supplementary motor area</article-title><source>PLOS Biology</source><year>2019</year><volume>17</volume><issue>3</issue><elocation-id>e3000026</elocation-id><pub-id pub-id-type="pmcid">PMC6428248</pub-id><pub-id pub-id-type="pmid">30897088</pub-id><pub-id pub-id-type="doi">10.1371/journal.pbio.3000026</pub-id></element-citation></ref><ref id="R75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reznik</surname><given-names>D</given-names></name><name><surname>Trampel</surname><given-names>R</given-names></name><name><surname>Weiskopf</surname><given-names>N</given-names></name><name><surname>Witter</surname><given-names>MP</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name></person-group><article-title>Dissociating distinct cortical networks associated with subregions of the human medial temporal lobe using precision neuroimaging</article-title><source>Neuron</source><year>2023</year><volume>111</volume><issue>17</issue><fpage>2756</fpage><lpage>2772</lpage><pub-id pub-id-type="pmid">37390820</pub-id></element-citation></ref><ref id="R76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Richter</surname><given-names>M</given-names></name><name><surname>Amunts</surname><given-names>K</given-names></name><name><surname>Mohlberg</surname><given-names>H</given-names></name><name><surname>Bludau</surname><given-names>S</given-names></name><name><surname>Eickhoff</surname><given-names>SB</given-names></name><name><surname>Zilles</surname><given-names>K</given-names></name><name><surname>Caspers</surname><given-names>S</given-names></name></person-group><article-title>Cytoarchitectonic segregation of human posterior intraparietal and adjacent parieto-occipital sulcus and its relation to visuomotor and cognitive functions</article-title><source>Cerebral Cortex</source><year>2019</year><volume>29</volume><issue>3</issue><fpage>1305</fpage><lpage>1327</lpage><pub-id pub-id-type="pmcid">PMC6373694</pub-id><pub-id pub-id-type="pmid">30561508</pub-id><pub-id pub-id-type="doi">10.1093/cercor/bhy245</pub-id></element-citation></ref><ref id="R77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rizzo</surname><given-names>M</given-names></name><name><surname>Vecera</surname><given-names>SP</given-names></name></person-group><article-title>Psychoanatomical substrates of Balint’s syndrome</article-title><source>Journal of Neurology, Neurosurgery &amp; Psychiatry</source><year>2002</year><volume>72</volume><issue>2</issue><fpage>162</fpage><lpage>178</lpage><pub-id pub-id-type="pmcid">PMC1737727</pub-id><pub-id pub-id-type="pmid">11796765</pub-id><pub-id pub-id-type="doi">10.1136/jnnp.72.2.162</pub-id></element-citation></ref><ref id="R78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robbe</surname><given-names>D</given-names></name></person-group><article-title>Lost in time: Relocating the perception of duration outside the brain</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><year>2023</year><elocation-id>105312</elocation-id><pub-id pub-id-type="pmid">37467906</pub-id></element-citation></ref><ref id="R79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roberts</surname><given-names>WA</given-names></name><name><surname>Feeney</surname><given-names>MC</given-names></name></person-group><article-title>The comparative study of mental time travel</article-title><source>Trends in Cognitive Sciences</source><year>2009</year><volume>13</volume><issue>6</issue><fpage>271</fpage><lpage>277</lpage><pub-id pub-id-type="pmid">19447669</pub-id></element-citation></ref><ref id="R80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robin</surname><given-names>J</given-names></name><name><surname>Moscovitch</surname><given-names>M</given-names></name></person-group><article-title>Details, gist and schema: hippocampal–neocortical interactions underlying recent and remote episodic and spatial memory</article-title><source>Current Opinion in Behavioral Sciences</source><year>2017</year><volume>17</volume><fpage>114</fpage><lpage>123</lpage></element-citation></ref><ref id="R81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rolls</surname><given-names>ET</given-names></name><name><surname>Huang</surname><given-names>CC</given-names></name><name><surname>Lin</surname><given-names>CP</given-names></name><name><surname>Feng</surname><given-names>J</given-names></name><name><surname>Joliot</surname><given-names>M</given-names></name></person-group><article-title>Automated anatomical labelling atlas 3</article-title><source>Neuroimage</source><year>2020</year><volume>206</volume><elocation-id>116189</elocation-id><pub-id pub-id-type="pmid">31521825</pub-id></element-citation></ref><ref id="R82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sestieri</surname><given-names>C</given-names></name><name><surname>Shulman</surname><given-names>GL</given-names></name><name><surname>Corbetta</surname><given-names>M</given-names></name></person-group><article-title>Attention to memory and the environment: functional specialization and dynamic competition in human posterior parietal cortex</article-title><source>Journal of Neuroscience</source><year>2010</year><volume>30</volume><issue>25</issue><fpage>8445</fpage><lpage>8456</lpage><pub-id pub-id-type="pmcid">PMC2906749</pub-id><pub-id pub-id-type="pmid">20573892</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4719-09.2010</pub-id></element-citation></ref><ref id="R83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sestieri</surname><given-names>C</given-names></name><name><surname>Shulman</surname><given-names>GL</given-names></name><name><surname>Corbetta</surname><given-names>M</given-names></name></person-group><article-title>The contribution of the human posterior parietal cortex to episodic memory</article-title><source>Nature Reviews Neuroscience</source><year>2017</year><volume>18</volume><issue>3</issue><fpage>183</fpage><lpage>192</lpage><pub-id pub-id-type="pmcid">PMC5682023</pub-id><pub-id pub-id-type="pmid">28209980</pub-id><pub-id pub-id-type="doi">10.1038/nrn.2017.6</pub-id></element-citation></ref><ref id="R84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shepard</surname><given-names>RN</given-names></name><name><surname>Judd</surname><given-names>SA</given-names></name></person-group><article-title>Perceptual illusion of rotation of three-dimensional objects</article-title><source>Science</source><year>1976</year><volume>191</volume><issue>4230</issue><fpage>952</fpage><lpage>954</lpage><pub-id pub-id-type="pmid">1251207</pub-id></element-citation></ref><ref id="R85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Siegel</surname><given-names>AW</given-names></name><name><surname>White</surname><given-names>SH</given-names></name></person-group><article-title>The development of spatial representations of large-scale environments</article-title><source>Advances in Child Development and Behavior</source><year>1975</year><volume>10</volume><fpage>9</fpage><lpage>55</lpage><pub-id pub-id-type="pmid">1101663</pub-id></element-citation></ref><ref id="R86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silani</surname><given-names>G</given-names></name><name><surname>Lamm</surname><given-names>C</given-names></name><name><surname>Ruff</surname><given-names>CC</given-names></name><name><surname>Singer</surname><given-names>T</given-names></name></person-group><article-title>Right supramarginal gyrus is crucial to overcome emotional egocentricity bias in social judgments</article-title><source>Journal of Neuroscience</source><year>2013</year><volume>33</volume><issue>39</issue><fpage>15466</fpage><lpage>15476</lpage><pub-id pub-id-type="pmcid">PMC6618458</pub-id><pub-id pub-id-type="pmid">24068815</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1488-13.2013</pub-id></element-citation></ref><ref id="R87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sinha</surname><given-names>C</given-names></name><name><surname>Gärdenfors</surname><given-names>P</given-names></name></person-group><article-title>Time, space, and events in language and cognition: a comparative view</article-title><source>Annals of the New York Academy of Sciences</source><year>2014</year><volume>1326</volume><issue>1</issue><fpage>72</fpage><lpage>81</lpage><pub-id pub-id-type="pmid">25098724</pub-id></element-citation></ref><ref id="R88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stark</surname><given-names>M</given-names></name></person-group><article-title>Impairment of an egocentric map of locations: Implications for perception and action</article-title><source>Cognitive Neuropsychology</source><year>1996</year><volume>13</volume><issue>4</issue><fpage>481</fpage><lpage>524</lpage></element-citation></ref><ref id="R89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stocker</surname><given-names>K</given-names></name></person-group><article-title>The time machine in our mind</article-title><source>Cognitive Science</source><year>2012</year><volume>36</volume><issue>3</issue><fpage>385</fpage><lpage>420</lpage><pub-id pub-id-type="pmid">22268721</pub-id></element-citation></ref><ref id="R90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stocker</surname><given-names>K</given-names></name></person-group><article-title>The theory of cognitive spacetime</article-title><source>Metaphor and Symbol</source><year>2014</year><volume>29</volume><issue>2</issue><fpage>71</fpage><lpage>93</lpage></element-citation></ref><ref id="R91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Strange</surname><given-names>BA</given-names></name><name><surname>Witter</surname><given-names>MP</given-names></name><name><surname>Lein</surname><given-names>ES</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><article-title>Functional organization of the hippocampal longitudinal axis</article-title><source>Nature Reviews Neuroscience</source><year>2014</year><volume>15</volume><issue>10</issue><fpage>655</fpage><lpage>669</lpage><pub-id pub-id-type="pmid">25234264</pub-id></element-citation></ref><ref id="R92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suddendorf</surname><given-names>T</given-names></name><name><surname>Addis</surname><given-names>DR</given-names></name><name><surname>Corballis</surname><given-names>MC</given-names></name></person-group><article-title>Mental time travel and the shaping of the human mind</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><year>2009</year><volume>364</volume><issue>1521</issue><fpage>1317</fpage><lpage>1324</lpage><pub-id pub-id-type="pmcid">PMC2666704</pub-id><pub-id pub-id-type="pmid">19528013</pub-id><pub-id pub-id-type="doi">10.1098/rstb.2008.0301</pub-id></element-citation></ref><ref id="R93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Summerfield</surname><given-names>C</given-names></name><name><surname>Luyckx</surname><given-names>F</given-names></name><name><surname>Sheahan</surname><given-names>H</given-names></name></person-group><article-title>Structure learning and the posterior parietal cortex</article-title><source>Progress in Neurobiology</source><year>2020</year><volume>184</volume><elocation-id>101717</elocation-id><pub-id pub-id-type="pmid">31669186</pub-id></element-citation></ref><ref id="R94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thavabalasingam</surname><given-names>S</given-names></name><name><surname>O’Neill</surname><given-names>EB</given-names></name><name><surname>Lee</surname><given-names>AC</given-names></name></person-group><article-title>Multivoxel pattern similarity suggests the integration of temporal duration in hippocampal event sequence representations</article-title><source>NeuroImage</source><year>2018</year><volume>178</volume><fpage>136</fpage><lpage>146</lpage><pub-id pub-id-type="pmid">29775662</pub-id></element-citation></ref><ref id="R95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Theves</surname><given-names>S</given-names></name><name><surname>Fernandez</surname><given-names>G</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name></person-group><article-title>The hippocampus encodes distances in multidimensional feature space</article-title><source>Current Biology</source><year>2019</year><volume>29</volume><issue>7</issue><fpage>1226</fpage><lpage>1</lpage><pub-id pub-id-type="pmid">30905602</pub-id></element-citation></ref><ref id="R96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Traugott</surname><given-names>EC</given-names></name></person-group><article-title>On the expression of spatio-temporal relations in language</article-title><source>Universals of Human Language</source><year>1978</year><volume>3</volume><issue>369-400</issue></element-citation></ref><ref id="R97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsao</surname><given-names>A</given-names></name><name><surname>Yousefzadeh</surname><given-names>SA</given-names></name><name><surname>Meck</surname><given-names>WH</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><article-title>The neural bases for timing of durations</article-title><source>Nature Reviews Neuroscience</source><year>2022</year><volume>23</volume><issue>11</issue><fpage>646</fpage><lpage>665</lpage><pub-id pub-id-type="pmid">36097049</pub-id></element-citation></ref><ref id="R98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tulving</surname><given-names>E</given-names></name></person-group><article-title>Precis of elements of episodic memory</article-title><source>Behavioral and Brain Sciences</source><year>1984</year><volume>7</volume><issue>2</issue><fpage>223</fpage><lpage>238</lpage></element-citation></ref><ref id="R99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tulving</surname><given-names>E</given-names></name></person-group><article-title>Episodic memory: From mind to brain</article-title><source>Annual review of psychology</source><year>2002</year><volume>53</volume><issue>1</issue><fpage>1</fpage><lpage>25</lpage><pub-id pub-id-type="pmid">11752477</pub-id></element-citation></ref><ref id="R100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tversky</surname><given-names>B</given-names></name><name><surname>Jamalian</surname><given-names>A</given-names></name></person-group><article-title>Thinking tools: Gestures change thought about time</article-title><source>Topics in Cognitive Science</source><year>2021</year><volume>13</volume><issue>4</issue><fpage>750</fpage><lpage>776</lpage><pub-id pub-id-type="pmid">34298590</pub-id></element-citation></ref><ref id="R101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Viganò</surname><given-names>S</given-names></name><name><surname>Bayramova</surname><given-names>R</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name><name><surname>Bottini</surname><given-names>R</given-names></name></person-group><article-title>Mental search of concepts is supported by egocentric vector representations and restructured grid maps</article-title><source>Nature Communications</source><year>2023</year><volume>14</volume><issue>1</issue><elocation-id>8132</elocation-id><pub-id pub-id-type="pmcid">PMC10709434</pub-id><pub-id pub-id-type="pmid">38065931</pub-id><pub-id pub-id-type="doi">10.1038/s41467-023-43831-w</pub-id></element-citation></ref><ref id="R102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vogeley</surname><given-names>K</given-names></name><name><surname>Fink</surname><given-names>GR</given-names></name></person-group><article-title>Neural correlates of the first-person-perspective</article-title><source>Trends in Cognitive Sciences</source><year>2003</year><volume>7</volume><issue>1</issue><fpage>38</fpage><lpage>42</lpage><pub-id pub-id-type="pmid">12517357</pub-id></element-citation></ref><ref id="R103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wagner</surname><given-names>AD</given-names></name><name><surname>Shannon</surname><given-names>BJ</given-names></name><name><surname>Kahn</surname><given-names>I</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name></person-group><article-title>Parietal lobe contributions to episodic memory retrieval</article-title><source>Trends in Cognitive Sciences</source><year>2005</year><volume>9</volume><issue>9</issue><fpage>445</fpage><lpage>453</lpage><pub-id pub-id-type="pmid">16054861</pub-id></element-citation></ref><ref id="R104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whitlock</surname><given-names>JR</given-names></name></person-group><article-title>Posterior parietal cortex</article-title><source>Current Biology</source><year>2017</year><volume>27</volume><issue>14</issue><fpage>R691</fpage><lpage>R695</lpage><pub-id pub-id-type="pmid">28743011</pub-id></element-citation></ref><ref id="R105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whorf</surname><given-names>BL</given-names></name></person-group><source>The relation of habitual thought and behavior to language</source><year>1941</year></element-citation></ref><ref id="R106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winkler</surname><given-names>AM</given-names></name><name><surname>Ridgway</surname><given-names>GR</given-names></name><name><surname>Douaud</surname><given-names>G</given-names></name><name><surname>Nichols</surname><given-names>TE</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name></person-group><article-title>Faster permutation inference in brain imaging</article-title><source>Neuroimage</source><year>2016</year><volume>141</volume><fpage>502</fpage><lpage>516</lpage><pub-id pub-id-type="pmcid">PMC5035139</pub-id><pub-id pub-id-type="pmid">27288322</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.05.068</pub-id></element-citation></ref><ref id="R107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winkler</surname><given-names>AM</given-names></name><name><surname>Ridgway</surname><given-names>GR</given-names></name><name><surname>Webster</surname><given-names>MA</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name><name><surname>Nichols</surname><given-names>TE</given-names></name></person-group><article-title>Permutation inference for the general linear model</article-title><source>Neuroimage</source><year>2014</year><volume>92</volume><fpage>381</fpage><lpage>397</lpage><pub-id pub-id-type="pmcid">PMC4010955</pub-id><pub-id pub-id-type="pmid">24530839</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.01.060</pub-id></element-citation></ref><ref id="R108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wittmann</surname><given-names>M</given-names></name></person-group><article-title>The inner sense of time: how the brain creates a representation of duration</article-title><source>Nature Reviews Neuroscience</source><year>2013</year><volume>14</volume><issue>3</issue><fpage>217</fpage><lpage>223</lpage><pub-id pub-id-type="pmid">23403747</pub-id></element-citation></ref><ref id="R109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolbers</surname><given-names>T</given-names></name><name><surname>Wiener</surname><given-names>JM</given-names></name></person-group><article-title>Challenges for identifying the neural mechanisms that support spatial navigation: the impact of spatial scale</article-title><source>Frontiers in Human Neuroscience</source><year>2014</year><volume>8</volume><fpage>571</fpage><pub-id pub-id-type="pmcid">PMC4121531</pub-id><pub-id pub-id-type="pmid">25140139</pub-id><pub-id pub-id-type="doi">10.3389/fnhum.2014.00571</pub-id></element-citation></ref><ref id="R110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woo</surname><given-names>CW</given-names></name><name><surname>Krishnan</surname><given-names>A</given-names></name><name><surname>Wager</surname><given-names>TD</given-names></name></person-group><article-title>Cluster-extent based thresholding in fMRI analyses: pitfalls and recommendations</article-title><source>Neuroimage</source><year>2014</year><volume>91</volume><fpage>412</fpage><lpage>419</lpage><pub-id pub-id-type="pmcid">PMC4214144</pub-id><pub-id pub-id-type="pmid">24412399</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.12.058</pub-id></element-citation></ref><ref id="R111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zacks</surname><given-names>JM</given-names></name><name><surname>Tversky</surname><given-names>B</given-names></name></person-group><article-title>Event structure in perception and conception</article-title><source>Psychological Bulletin</source><year>2001</year><volume>127</volume><issue>1</issue><fpage>3</fpage><pub-id pub-id-type="pmid">11271755</pub-id></element-citation></ref><ref id="R112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zipser</surname><given-names>D</given-names></name><name><surname>Andersen</surname><given-names>RA</given-names></name></person-group><article-title>A back-propagation programmed network that simulates response properties of a subset of posterior parietal neurons</article-title><source>Nature</source><year>1988</year><volume>331</volume><issue>6158</issue><fpage>679</fpage><lpage>684</lpage><pub-id pub-id-type="pmid">3344044</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>Spatial construal of time and experimental design.</title><p>(A) The schematic diagram of spatial construal of time. It illustrates two core time concepts (sequence and duration) and two major perspectives on event series (mental time travel and watching). (B) Stimulus: a fictional religious ritual of 15 events following a specific sequence, enduring particular durations, and happening on predetermined parts of the day. The event phrases were randomly assigned to the events twice, generating two versions for even and odd numbers of participants. Only one version was illustrated here. (C) Task paradigm. In the external-perspective task, participants judged whether the target events happened in the same part of the day as the reference event. In the internal-perspective task, participants imagined themselves doing the reference events and judged whether the target event happened in the past or will happen in the future.</p></caption><graphic xlink:href="EMS199988-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Neural correlates of specific perspectives and syllable length.</title><p>(A) Univariate contrast between external-perspective and internal-perspective tasks (voxel-level p &lt; 0.001, cluster-level FWE corrected p &lt; 0.05). All the significant areas were in the right hemisphere. PreC: precuneus; RSC: the retrosplenial cortex; SFG: the superior frontal gyrus; AG: angular gyrus; SMA: supplementary motor area; SMG: supramarginal gyrus. (B) Parametric modulation of syllable length as a sanity check (voxel-level p &lt; 0.001, cluster-level FWE corrected p &lt; 0.05). The activation level in the anterior part of the left superior temporal gyrus and the visual cortex positively correlated with syllable length.</p></caption><graphic xlink:href="EMS199988-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Neural correlates of event sequence.</title><p>A-C: Interaction effect between <italic>Task Type</italic> (i.e., external-vs. internal-perspective tasks) and <italic>Sequential Distance</italic>. (A) The only cortical region showing a significant interaction effect was localized in the right posterior parietal cortex (voxel-level p &lt; 0.001, cluster-level FWE corrected p &lt; 0.05). (B) Regions of interest analysis shows that the activation level in the right posterior parietal cortex correlated with sequential distance positively in the external-perspective task and negatively in the internal-perspective task. (C) A further illustration of the relations between the activation level in the right posterior parietal cortex and sequential distance in the two tasks. The error bar indicates the standard error relative to the mean, and the shaded band around the linear regression line indicates 95% confidence interval. D-F: main effect of <italic>Sequential Distance</italic>. (D) The right hippocampal head shows a significant main effect of <italic>Sequential Distance</italic> within the mask of the bilateral hippocampus (voxel-level p &lt; 0.001, cluster-level FWE corrected p &lt; 0.05; voxel-level p &lt; 0.05 for illustration purposes). (E) Regions of interest analysis shows that the correlation between the activation level in the right hippocampal head and the sequential distance was independent of perspectives. (F) A further illustration of the relations between the activation level in the right hippocampal head and sequential distance in the two tasks. The error bar indicates the standard error relative to the mean, and the shaded band around the linear regression line indicates 95% confidence interval. **: p &lt; 0.01; ***: p &lt; 0.001</p></caption><graphic xlink:href="EMS199988-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Neural correlates of event duration.</title><p>(A) The right hippocampal body shows a significant main effect of <italic>Duration</italic> within the mask of the bilateral hippocampus (voxel-level p &lt; 0.001, cluster-level FWE corrected p &lt; 0.05; voxel-level p &lt; 0.05 for illustration purposes). (B) However, regions of interest analysis shows that the correlation between the activation level in the right hippocampal body and <italic>Duration</italic> significantly differs in the internal- and the external-perspective task. (C) A further illustration of the relations between the activation level in the right hippocampal body and duration in the two tasks. The error bar indicates the standard error relative to the mean, and the shaded band around the linear regression line indicates 95% confidence interval. (D) Directly comparing the effects of <italic>Sequential Distance</italic> and <italic>Duration</italic> in the head and the body of the hippocampus shows a double dissociation pattern: the hippocampal head represented <italic>Sequential Distance</italic> but not <italic>Duration</italic>, while the hippocampal body represented <italic>Duration</italic> but not <italic>Sequential Distance</italic>. ***: p &lt; 0.001</p></caption><graphic xlink:href="EMS199988-f004"/></fig><table-wrap id="T1" orientation="portrait" position="float"><label>Table 1</label><caption><title>The reaction time of the corrected trials indicates that time was differently processed under internal and external perspectives<sup><xref ref-type="fn" rid="TFN1">1</xref></sup>.</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="middle" align="center" style="border-top:solid 1px #000000;background:#D9D9D9">Fixed Effects<sup><xref ref-type="fn" rid="TFN3">2</xref></sup></th><th valign="middle" align="center" style="border-top:solid 1px #000000;background:#D9D9D9">df</th><th valign="middle" align="center" style="border-top:solid 1px #000000;background:#D9D9D9">F</th><th valign="middle" align="center" style="border-top:solid 1px #000000;background:#D9D9D9">p</th></tr></thead><tbody><tr><td valign="middle" align="left" style="border-top:solid 1px #000000">Sequential Distance</td><td valign="middle" align="center" style="border-top:solid 1px #000000">1, 6918</td><td valign="middle" align="center" style="border-top:solid 1px #000000">2.575 × 10<sup>-4</sup></td><td valign="middle" align="center" style="border-top:solid 1px #000000">0.987</td></tr><tr><td valign="middle" align="left">Duration</td><td valign="middle" align="center">1, 6918</td><td valign="middle" align="center">6.914</td><td valign="middle" align="center">0.009</td></tr><tr><td valign="middle" align="left" style="background:#FBE4D5">Syllable Length</td><td valign="middle" align="center" style="background:#FBE4D5">1, 6918</td><td valign="middle" align="center" style="background:#FBE4D5">35.585</td><td valign="middle" align="center" style="background:#FBE4D5">&lt; 0.001</td></tr><tr><td valign="middle" align="left">Task Type</td><td valign="middle" align="center">1, 6918</td><td valign="middle" align="center">4.357</td><td valign="middle" align="center">0.037</td></tr><tr><td valign="middle" align="left" style="background:#FBE4D5">Task Type × Sequential Distance</td><td valign="middle" align="center" style="background:#FBE4D5">1, 6918</td><td valign="middle" align="center" style="background:#FBE4D5">28.224</td><td valign="middle" align="center" style="background:#FBE4D5">&lt; 0.001</td></tr><tr><td valign="middle" align="left" style="background:#FBE4D5">Task Type × Duration</td><td valign="middle" align="center" style="background:#FBE4D5">1, 6918</td><td valign="middle" align="center" style="background:#FBE4D5">12.808</td><td valign="middle" align="center" style="background:#FBE4D5">&lt; 0.001</td></tr><tr><td valign="middle" align="left" style="border-bottom:solid 1px #000000">Task Type × Syllable Length</td><td valign="middle" align="center" style="border-bottom:solid 1px #000000">1, 6918</td><td valign="middle" align="center" style="border-bottom:solid 1px #000000">0.065</td><td valign="middle" align="center" style="border-bottom:solid 1px #000000">0.799</td></tr></tbody></table><table-wrap-foot><fn id="TFN1"><label>1</label><p id="P61">Linear Mixed Model Formula: RT ~ 1 + Task Type * (Sequential Distance + Duration + Syllable Length)</p></fn><fn id="TFN2"><p id="P62">+ (1 | Participant)</p></fn><fn id="TFN3"><label>2</label><p id="P63">The significant effects were highlighted. We did not highlight the significant main effects if the corresponding interaction effects were also significant.</p></fn></table-wrap-foot></table-wrap><table-wrap id="T2" orientation="portrait" position="float"><label>Table 2</label><caption><title>Univariate contrast between internal- and external-perspective tasks (p &lt; 0.001, cluster-level FWE corrected p &lt; 0.05 across the whole cortex).</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="middle" align="center" rowspan="2" style="border-top:solid 1px #000000;background:#D9D9D9">Anatomical Label</th><th valign="middle" align="center" colspan="3" style="border-top:solid 1px #000000;background:#D9D9D9">Center MNI Coordinate<sup><xref ref-type="fn" rid="TFN4">1</xref></sup></th><th valign="middle" align="center" rowspan="2" style="border-top:solid 1px #000000;background:#D9D9D9">Cluster Size<break/>Number of Voxels<sup><xref ref-type="fn" rid="TFN5">2</xref></sup></th></tr><tr><th valign="middle" align="center" style="border-top:solid 1px #000000;background:#D9D9D9">X</th><th valign="middle" align="center" style="border-top:solid 1px #000000;background:#D9D9D9">Y</th><th valign="middle" align="center" style="border-top:solid 1px #000000;background:#D9D9D9">Z</th></tr></thead><tbody><tr><td valign="middle" align="left" style="border-top:solid 1px #000000;background:#FFE599">Internal &gt; External-Perspective Task</td><td valign="middle" align="left" style="border-top:solid 1px #000000;background:#FFE599"/><td valign="middle" align="left" style="border-top:solid 1px #000000;background:#FFE599"/><td valign="middle" align="left" style="border-top:solid 1px #000000;background:#FFE599"/><td valign="middle" align="left" style="border-top:solid 1px #000000;background:#FFE599"/></tr><tr><td valign="middle" align="left" style="background:#FFF2CC">Supplementary Motor Area (R)</td><td valign="middle" align="center" style="background:#FFF2CC">10</td><td valign="middle" align="center" style="background:#FFF2CC">-22</td><td valign="middle" align="center" style="background:#FFF2CC">69</td><td valign="middle" align="center" style="background:#FFF2CC">34</td></tr><tr><td valign="middle" align="left" style="background:#FFF2CC">Supramarginal Gyrus (R)</td><td valign="middle" align="center" style="background:#FFF2CC">61</td><td valign="middle" align="center" style="background:#FFF2CC">-36</td><td valign="middle" align="center" style="background:#FFF2CC">26</td><td valign="middle" align="center" style="background:#FFF2CC">98</td></tr><tr><td valign="middle" align="left" style="border-top:solid 1px #000000;background:#BDD6EE">Internal &gt; External-Perspective Task</td><td valign="middle" align="left" style="border-top:solid 1px #000000;background:#BDD6EE"/><td valign="middle" align="left" style="border-top:solid 1px #000000;background:#BDD6EE"/><td valign="middle" align="left" style="border-top:solid 1px #000000;background:#BDD6EE"/><td valign="middle" align="left" style="border-top:solid 1px #000000;background:#BDD6EE"/></tr><tr><td valign="middle" align="left" style="background:#DEEAF6">Precuneus (R)</td><td valign="middle" align="center" style="background:#DEEAF6">4</td><td valign="middle" align="center" style="background:#DEEAF6">-61</td><td valign="middle" align="center" style="background:#DEEAF6">45</td><td valign="middle" align="center" style="background:#DEEAF6">79</td></tr><tr><td valign="middle" align="left" style="background:#DEEAF6">Retrosplenial Cortex (R)</td><td valign="middle" align="center" style="background:#DEEAF6">16</td><td valign="middle" align="center" style="background:#DEEAF6">-56</td><td valign="middle" align="center" style="background:#DEEAF6">19</td><td valign="middle" align="center" style="background:#DEEAF6">45</td></tr><tr><td valign="middle" align="left" style="background:#DEEAF6">Superior Frontal Gyrus (R)</td><td valign="middle" align="center" style="background:#DEEAF6">27</td><td valign="middle" align="center" style="background:#DEEAF6">12</td><td valign="middle" align="center" style="background:#DEEAF6">56</td><td valign="middle" align="center" style="background:#DEEAF6">95</td></tr><tr><td valign="middle" align="left" style="border-bottom:solid 1px #000000;background:#DEEAF6">Angular Gyrus (R)</td><td valign="middle" align="center" style="border-bottom:solid 1px #000000;background:#DEEAF6">45</td><td valign="middle" align="center" style="border-bottom:solid 1px #000000;background:#DEEAF6">-66</td><td valign="middle" align="center" style="border-bottom:solid 1px #000000;background:#DEEAF6">30</td><td valign="middle" align="center" style="border-bottom:solid 1px #000000;background:#DEEAF6">78</td></tr></tbody></table><table-wrap-foot><fn id="TFN4"><label>1</label><p id="P64">The average Montreal Neurological Institute coordinates of all the significant voxels of each cluster. The precuneus and the retrosplenial cortex were connected as one cluster under the threshold p &lt; 0.001 (z &gt; 3.09). In this case, we increased the threshold to the point when the precuneus and the retrosplenial cortex were separate (z &gt; 3.3) and calculated the average coordinates of each cluster.</p></fn><fn id="TFN5"><label>2</label><p id="P65">The voxel size is 3 × 3 × 3 mm<sup>3</sup>.</p></fn></table-wrap-foot></table-wrap></floats-group></article>