<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS199918</article-id><article-id pub-id-type="doi">10.1101/2024.11.04.621878</article-id><article-id pub-id-type="archive">PPR934590</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">1</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Brain-wide population activity during reaching integrates action-mediated goal expectation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Peng</surname><given-names>Yangfan</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Lindersson</surname><given-names>Carl</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A5">5</xref><xref ref-type="fn" rid="FN1">*</xref></contrib><contrib contrib-type="author"><name><surname>Tinelli</surname><given-names>Sasha</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Stedehouder</surname><given-names>Jeffrey</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A5">5</xref></contrib><contrib contrib-type="author"><name><surname>Shah</surname><given-names>Rahul S</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Lak</surname><given-names>Armin</given-names></name><xref ref-type="aff" rid="A4">4</xref></contrib><contrib contrib-type="author"><name><surname>Stagg</surname><given-names>Charlotte J</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A5">5</xref></contrib><contrib contrib-type="author"><name><surname>Sharott</surname><given-names>Andrew</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib></contrib-group><aff id="A1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01tfjyv98</institution-id><institution>MRC Brain Network Dynamics Unit</institution></institution-wrap>, Nuffield Department of Clinical Neurosciences, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>University of Oxford</institution></institution-wrap>, <city>Oxford</city>, <country country="GB">United Kingdom</country></aff><aff id="A2"><label>2</label>Department of Neurology, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/001w7jn25</institution-id><institution>Charité – Universitätsmedizin Berlin</institution></institution-wrap>, <city>Berlin</city>, <country country="DE">Germany</country></aff><aff id="A3"><label>3</label>Neuroscience Research Center, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/001w7jn25</institution-id><institution>Charité – Universitätsmedizin Berlin</institution></institution-wrap>, <city>Berlin</city>, <country country="DE">Germany</country></aff><aff id="A4"><label>4</label>Department of Physiology, Anatomy and Genetics, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>University of Oxford</institution></institution-wrap>, <city>Oxford</city>, United Kingdom Oxford, <country country="GB">United Kingdom</country></aff><aff id="A5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0172mzb45</institution-id><institution>Wellcome Centre for Integrative Neuroimaging</institution></institution-wrap>, Nuffield Department of Clinical Neurosciences, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>University of Oxford</institution></institution-wrap></aff><author-notes><fn fn-type="present-address" id="FN1"><label>*</label><p id="P1">Present address: Department of Experimental Psychology, University of Oxford, Oxford, United Kingdom</p></fn></author-notes><pub-date pub-type="nihms-submitted"><day>08</day><month>11</month><year>2024</year></pub-date><pub-date pub-type="preprint"><day>04</day><month>11</month><year>2024</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P2">Large scale recordings have revealed that neurons encoding motor and non-motor variables are highly distributed across the brain. While these neurons generate population level dynamics during spontaneous behavior, it remains unclear how these latent subspaces relate to the simultaneous motor and cognitive demands during ongoing goal-directed behavior. Here, we show that continuously anticipated action outcome, in addition to movement, drives ubiquitous latent dynamics during goal-directed movements. We used multiple Neuropixels probes to simultaneously record spiking activity from cortical and subcortical regions during a reaching task in head-fixed mice. Task-related population dynamics covaried within a common latent subspace across regions and was conserved across recording days and animals. These latent dynamics preceded movement onset and were modulated by reach distance and reward availability. Furthermore, their temporal progression continuously scaled with the timing of reward consumption and their activity decreased afterwards, despite ongoing stereotypical re-reaches. Our findings thus provide evidence for a brain-wide latent subspace for continuous representation of action-mediated proximity to goal, which could provide the basis for ubiquitous temporal difference learning based on predicted action outcome.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P3">The brain generates movement to achieve specific goals. The neural correlates of movements have been mostly studied in the motor cortex, where neurons can be tuned to movement kinematics, such as direction<sup><xref ref-type="bibr" rid="R1">1</xref></sup>, distance<sup><xref ref-type="bibr" rid="R2">2</xref></sup>, or speed<sup><xref ref-type="bibr" rid="R3">3</xref></sup>. However, large-scale brain-wide recordings have revealed that movement-related activity is highly distributed across the brain, both for task-related and spontaneous behavior<sup><xref ref-type="bibr" rid="R4">4</xref>–<xref ref-type="bibr" rid="R7">7</xref></sup>. While these neurons are broadly tuned to movement onset, ongoing movement kinematics account for only a small fraction of the variance in single neuron activity<sup><xref ref-type="bibr" rid="R6">6</xref></sup>. As it can be challenging to relate single-neuron responses to behavioral variables due to their mixed and diverse representations<sup><xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R9">9</xref></sup>, an alternative approach is to link behavioral variables to latent subspaces within the population-level activity<sup><xref ref-type="bibr" rid="R10">10</xref></sup>. By performing dimensionality reduction on the population-level activity, latent subspaces that define the dominant patterns of covarying population activity can be identified<sup><xref ref-type="bibr" rid="R11">11</xref></sup>. Behaviorally relevant latent subspaces have been found across different brain regions, and studies have highlighted their emergent computational properties<sup><xref ref-type="bibr" rid="R12">12</xref>–<xref ref-type="bibr" rid="R15">15</xref></sup>, such as the representation of motor timing<sup><xref ref-type="bibr" rid="R16">16</xref></sup>.</p><p id="P4">In the motor cortex, goal-directed movements are represented in distinct latent subspaces that separate movement preparation, initiation, and execution<sup><xref ref-type="bibr" rid="R17">17</xref>–<xref ref-type="bibr" rid="R19">19</xref></sup>. Multi-region recordings have further shown that distributed low-dimensional latent dynamics correlate with spontaneous facial movements at the timescale of seconds<sup><xref ref-type="bibr" rid="R20">20</xref>,<xref ref-type="bibr" rid="R21">21</xref></sup>. However, these studies reported that movement explained 30-50% of the variance in the lowest 16 dimensions, while higher dimensions exhibited coherent fluctuations at faster timescales that appeared unrelated to motor behavior. This suggests that a substantial amount of brain-wide activity during movement reflects sub-second fluctuations of internal non-motor representations that could be tightly linked to ongoing behavior. This is especially relevant for goal-directed actions, where animals not only process sensorimotor signals, but also must continuously adapt their internal representation of the goal based on the predicted and actual outcome of the action<sup><xref ref-type="bibr" rid="R22">22</xref></sup>. Yet, it is unknown to what extent internal goal representations drive brain-wide latent dynamics and how they relate to the ongoing movement at the millisecond timescale<sup><xref ref-type="bibr" rid="R23">23</xref></sup>.</p><p id="P5">In this study, we recorded the simultaneous spiking activity of over a thousand neurons across motor and non-motor brain regions during a reaching task in head-fixed mice. We found task-related stereotypical population activity in a latent subspace that was preserved across animals and shared between all recorded cortical and subcortical regions. By showing modulation of these dynamics by reach distance and timing of reward consumption, our results indicate that population activity across the brain is not only modulated by movement, but strongly driven by action-mediated goal expectation.</p></sec><sec id="S2" sec-type="results"><title>Results</title><sec id="S3"><title>To study movement-related neuronal population dynamics, we performed high-density Neuropixels recordings in head-fixed mice performing a forelimb reaching task</title><p id="P6">To initiate a trial, the animal had to rest its left paw on a metal bar for a holding period of 3-6 seconds to trigger the presentation of a 4-5 μl sucrose water droplet which was signaled by an 80 ms long cue tone (<xref ref-type="fig" rid="F1">Fig. 1a</xref>, task adapted from previous study<sup><xref ref-type="bibr" rid="R24">24</xref></sup>). The animal then immediately reached towards the droplet, grabbed it, and brought the droplet to the mouth (<xref ref-type="fig" rid="F1">Fig. 1a</xref>). Using electrical detectors (pyControl<sup><xref ref-type="bibr" rid="R25">25</xref></sup>) and automated pose estimation in 3D space (DeepLabCut<sup><xref ref-type="bibr" rid="R26">26</xref></sup> with Argus3D<sup><xref ref-type="bibr" rid="R27">27</xref></sup>), we were able to extract the times of reach onset (bar release), droplet consumption (reward) and the movement trajectory of the forelimb joints at high temporal and spatial resolution (<xref ref-type="fig" rid="F1">Fig. 1b</xref>, <xref ref-type="supplementary-material" rid="SD5">Fig. S1</xref>, <xref ref-type="supplementary-material" rid="SD1">Suppl. Video 1</xref>). After training (see <xref ref-type="sec" rid="S5">Methods</xref>), the animal learned to reach up to 200 times within a 30-minute recording session. In total, we recorded 5738 cued reaches across 38 sessions (mean: 151 trials per session, SD: 59) from 7 animals (<xref ref-type="supplementary-material" rid="SD5">Fig. S2</xref>). Reaches were highly consistent across trials, sessions, and animals, as demonstrated by similar reaction times (median: 234 ms, interquartile range: [170-390 ms]), movement times (bar to spout: 133 ms [83-211 ms]) and similar movement trajectories (<xref ref-type="supplementary-material" rid="SD5">Fig. S1, S2</xref>).</p><p id="P7">To simultaneously record neuron spiking activity, we inserted two to three Neuropixels probes into the brain (probe-1: premotor cortex corresponding to rostral forelimb area, medial prefrontal cortex, orbitofrontal cortex, olfactory areas; probe-2: primary motor cortex corresponding to caudal forelimb area, dorsolateral striatum; probe-3 in mice 5-7: hippocampus, thalamic nuclei, hypothalamus; <xref ref-type="fig" rid="F1">Fig. 1c</xref>). After spike sorting, quality control, and region assignment (<xref ref-type="supplementary-material" rid="SD5">Fig. S3, S4</xref>, see <xref ref-type="sec" rid="S5">Methods</xref>), we obtained a pooled dataset of 37,567 neurons exhibiting a wide range of activity patterns during cued reaches (<xref ref-type="fig" rid="F1">Fig. 1d</xref>). We included a mean of 2,691 neurons per region (range: 728 to 6,616, <xref ref-type="fig" rid="F1">Fig. 1f</xref>, <xref ref-type="supplementary-material" rid="SD5">Fig. S5</xref>). To broadly characterize their task-related modulation, we determined the relative change in trial-averaged firing rate 500 ms after the cue relative to 250 ms baseline before the cue (modulation index, see <xref ref-type="sec" rid="S5">Methods</xref>). While we observed highly heterogenous and skewed distributions of modulation across all recorded brain regions (<xref ref-type="fig" rid="F1">Fig. 1e</xref>, <xref ref-type="supplementary-material" rid="SD5">Fig. S5</xref>), region-specific differences were evident when analyzed at the session-level (<xref ref-type="fig" rid="F1">Fig. 1f</xref>): The fraction of significantly task-related neurons and their mean modulation index was calculated for each region and session (mean 17 sessions per region, range 4 to 36). Sensory, interlaminar and mediodorsal thalamus showed the highest fraction of positively modulated neurons (~ 50%), with lower fractions in non-thalamic cortical and subcortical regions. The strongest positive modulation was found in the premotor, motor, and medial prefrontal cortex (3.4- to 4-fold increase). Negatively modulated neurons were found across all recorded regions. While the fraction was lower compared to positively modulated neurons in most regions, the hippocampus showed the highest fraction of negatively modulated neurons (29%, <xref ref-type="fig" rid="F1">Fig. 1f</xref>).</p><p id="P8">To better interpret the heterogeneity of single neuron responses, we next analyzed the neuronal population activity using a dynamical systems framework<sup><xref ref-type="bibr" rid="R12">12</xref></sup>. Previous studies have shown that movement-related latent population dynamics can exhibit stable patterns despite heterogeneity of individual neuronal activity, reflecting the capability of the neural network to maintain functional coherence despite diverse cellular responses<sup><xref ref-type="bibr" rid="R13">13</xref>,<xref ref-type="bibr" rid="R17">17</xref>,<xref ref-type="bibr" rid="R28">28</xref>,<xref ref-type="bibr" rid="R29">29</xref></sup>. To identify these stable neuronal population trajectories in our data, we performed principal component analysis (PCA)<sup><xref ref-type="bibr" rid="R11">11</xref></sup> on the activity of simultaneously recorded neurons from each session (<xref ref-type="supplementary-material" rid="SD5">Fig. S6a-d</xref>). We only included cued reach trials and aligned them to reach onset (bar release). The PCA was performed on the trial-averaged and normalized firing rate (z-score) around reach onset (-1.5 s to 3 s) from all neurons of each session (989 ± 261 neurons per session, we report mean ± standard deviation across 38 sessions unless stated otherwise). The first principal component (PC1) explained 22 ± 5% of the variance (<xref ref-type="supplementary-material" rid="SD5">Fig. S6e</xref>), which exhibited a unimodal dynamic that increased 216 ms before (95% CI: -286 to -146 ms) and peaked 293 ms (95% CI: 250 to 335 ms) after reach onset (<xref ref-type="fig" rid="F2">Fig. 2a</xref>). The second principal component (PC2) explained 14 ± 3% of the variance and exhibited a bimodal dynamic peaking 45 ms (95% CI: -167 to 77 ms) before reach onset. The neural state space trajectory of these two top components exhibited a rotational structure (<xref ref-type="fig" rid="F2">Fig. 2a</xref>), reminiscent of previously described latent dynamics within the primate motor cortex<sup><xref ref-type="bibr" rid="R17">17</xref></sup>. The change in explained variance (or eigenvalues) across principal components was non-linear (<xref ref-type="supplementary-material" rid="SD5">Fig. S6e</xref>). We found that the eigenvalues across PC dimensions exhibited a power law relationship with an exponent of 1.096 (95% CI: 1.088 to 1.104, <xref ref-type="supplementary-material" rid="SD5">Fig. S6e</xref>). An exponent close to 1 suggests that the decay of eigenvalues exhibits a scale-invariant pattern across recording sessions<sup><xref ref-type="bibr" rid="R30">30</xref></sup>.</p><p id="P9">To quantify the robustness of the observed population activity, we performed pairwise comparisons of the temporal dynamics of the top three PCs from different recording sessions (<xref ref-type="fig" rid="F2">Fig. 2b</xref>, <xref ref-type="supplementary-material" rid="SD5">Fig. S6g</xref>). We found high Pearson correlation coefficients between the different sessions when comparing respective PC dimensions (R<sub>PC1</sub> = 0.83 ± 0.13, R<sub>PC2</sub> = 0.69 ± 0.23, R<sub>PC3</sub> = 0.6 ± 0.23). Correlation was much lower for comparisons between dynamics of different components (R = 0.23 ± 0.2, <xref ref-type="fig" rid="F2">Fig. 2b</xref>). While the high within-component correlation was especially pronounced among sessions from the same animal (R<sub>PC1</sub> = 0.92 ± 0.08, R<sub>PC2</sub> = 0.82 ± 0.18, R<sub>PC3</sub> = 0.75 ± 0.17), we also found high correlation among latent dynamics when comparing sessions from different animals (RPC1 = 0.82 ± 0.13, R<sub>PC2</sub> = 0.67 ± 0.23, RPC3 = 0.58 ± 0.17, <xref ref-type="fig" rid="F2">Fig. 2b</xref>). These results suggest that movement-related population activity across different sessions and animals are dominated by similar temporal dynamics with a consistent low-dimensional structure. This is remarkable considering that each recording session is sampling from putatively different neurons. Thus, latent dynamics represent a stereotypical population activity that is highly preserved across animals.</p><p id="P10">Movement-related latent dynamics have been mostly described in motor cortices but have also been shown in other regions<sup><xref ref-type="bibr" rid="R17">17</xref>,<xref ref-type="bibr" rid="R20">20</xref>,<xref ref-type="bibr" rid="R31">31</xref></sup>. We thus asked whether the latent dynamics extracted from our data are mainly driven by a subset of motor regions or are globally distributed across cortical and subcortical regions. We found a broad distribution of positive and negative PC coefficients in neurons across all recorded regions (<xref ref-type="fig" rid="F2">Fig. 2d</xref>). However, we also identified region-specific differences: Thalamic nuclei (motor, sensory, interlaminar, mediodorsal) exhibited a high proportion of neurons with high PC1 coefficients. This corresponded to a task-related firing rate increase in most of these neurons (<xref ref-type="fig" rid="F2">Fig. 2c</xref>). Premotor and motor cortex included more neurons with positive than negative PC1 coefficients which reflects the larger fraction of positively modulated neurons (<xref ref-type="fig" rid="F2">Fig. 2d</xref>). Orbitofrontal and medial prefrontal cortex exhibited neurons with either positive or negative coefficients (<xref ref-type="fig" rid="F2">Fig. 2d</xref>). Similarly, the striatum, hippocampus, olfactory areas, and the pulvinar contained mostly neurons with negative coefficients. This was reflected in their large fractions of neurons that decrease their firing rate (<xref ref-type="fig" rid="F2">Fig. 2c</xref>). We next projected region-specific activity onto the PC1 dimension by multiplying the firing rate of each neuron with its PC1 coefficient and averaging across simultaneously recorded neurons from the same region. Notably, we found that the global PC1 dynamic was expressed in each region and was largely consistent across different recording sessions (<xref ref-type="fig" rid="F2">Fig. 2e</xref>). To estimate to what extent the global PC1 dynamic reflects the dominant local population activity, we performed PCA only on simultaneously recorded neurons from each region (local PCA) and found that local PC1 coefficients of each neuron strongly correlated with their coefficients for the global PC1, with some region-specific differences (<xref ref-type="fig" rid="F2">Fig. 2f</xref>, <xref ref-type="supplementary-material" rid="SD5">Fig. S7</xref>). Together, these results indicate that the identified reach-related global latent dynamic reflects a population co-activity pattern in a common subspace that is shared across sessions, animals, as well as motor and non-motor brain regions.</p><p id="P11">To disentangle the contribution of cue, movement, and reward to this global activity, we compared cued reaches to distinct spontaneous movements. Leveraging the continuous 3D position data at high temporal and spatial resolution, we classified 5816 reaches as cued (reach within 1 second after cue, <xref ref-type="supplementary-material" rid="SD1">Suppl. Video 1</xref>). We further detected 7853 spontaneous forelimb movements of at least 2 mm towards the spout starting from the bar that occurred later than 1 second after the cue (see <xref ref-type="sec" rid="S5">Methods</xref>). We classified these spontaneous movements either as a “spontaneous reach” (n = 7245, <xref ref-type="supplementary-material" rid="SD2">Suppl. Video 2</xref>-<xref ref-type="supplementary-material" rid="SD3">3</xref>) or “grooming” (n = 608, <xref ref-type="supplementary-material" rid="SD4">Suppl. Video 4</xref>). Spontaneous reaches exhibited similar movement trajectories and reach distances compared to cued reaches (<xref ref-type="fig" rid="F3">Fig. 3a</xref>). We subdivided all cued and spontaneous reaches based on their maximum reach distance within 500 ms (short: &lt; 5 mm, mid: 5-15 mm, long: &gt; 15 mm), and spontaneous reaches were further subdivided into those performed with or without the presence of reward, depending on whether the droplet was collected by the previous reach (19% “with reward” vs 81% “without reward”, <xref ref-type="fig" rid="F3">Fig. 3a</xref>, <xref ref-type="supplementary-material" rid="SD2">Suppl. Video 2</xref>-<xref ref-type="supplementary-material" rid="SD3">3</xref>). We found that both cued and spontaneous reaches led to consistent population activity along the global PC1 dimension (“PC1 activity”) across sessions with similar temporal dynamics (<xref ref-type="fig" rid="F3">Fig. 3b-d</xref>). Spontaneous long reaches with reward showed a similar PC1 peak amplitude (maximum PC1 activity within 500 ms after reach onset) compared to long cued reaches (0.97 ± 0.22 normalized to peak of long cued reaches, <xref ref-type="fig" rid="F3">Fig. 3d</xref>). Since the PC1 dimension was derived from PCA applied to trial-averaged activity exclusively from the cued trials, these results support the validity of our PCA approach in capturing population dynamics outside the cued task window.</p><p id="P12">We found that spontaneous reaches performed without a reward peaked at lower amplitudes at 0.6 ± 0.2, suggesting a significant modulation of PC1 activity by the availability of reward (<xref ref-type="fig" rid="F3">Fig. 3c-d</xref>). In all reach types, the PC1 activity was strongly dependent on the spatial reach distance (<xref ref-type="fig" rid="F3">Fig. 3c-d</xref>). To statistically quantify the contribution of these different task variables, we calculated a linear mixed effect model (LME) based on session averages of normalized peak PC1 activity which was able to account for 54% of the variance (see <xref ref-type="sec" rid="S5">Methods</xref>). The strongest predictor of global PC1 peak activity was the reach distance, reducing it by 49% when the reach was aborted (p &lt; 0.001). Across all distances, the absence of the auditory cue reduced PC1 peak activity by 16% (p &lt; 0.001) while the absence of reward led to a decrease by 26% (p &lt; 0.001). We also compared the reaching movements to grooming movements, which consisted of forepaw movements across similar AP distances, and which could display highly similar forepaw trajectories (<xref ref-type="fig" rid="F3">Fig. 3a</xref>, grey). In contrast to reaches, grooming movements, predominantly lasting over 2 s, only elicited a short transient increase in PC1 activity lasting around 500 ms (<xref ref-type="fig" rid="F3">Fig. 3c</xref>). This further supports that PC1 activation reflects goal-specific actions rather than pure forepaw movement kinematics over analogous distances and trajectories. Overall, these results show that reach-related global population dynamic is significantly modulated by cue, movement, and reward.</p><p id="P13">In our task, auditory cue, reach distance, and droplet presence could all be interpreted as factors that impact the animal’s momentary expectation of proximity to and probability of achieving the goal, which is the retrieval and consumption of the water droplet. We thus hypothesized that global PC1 activity could relate to the fluctuating expectation of goal proximity, which is dependent on the performed action. Such action-mediated representations have been referred to as “actionable representations”<sup><xref ref-type="bibr" rid="R32">32</xref></sup>. If PC1 activity represents such a dynamic expression of ‘actionable goal expectation’, we hypothesized that PC1 should (1) exhibit dynamic changes during moment-to-moment goal-directed movements and (2) be modulated by sudden changes in reward availability. To address this, we leveraged the fact that within a single trial in our task, mice performed not only a singular reach to retrieve the droplet but performed multiple “re-reaches” going back and forth between spout and mouth. Importantly, the droplet was often not retrieved by the first reach, but only after a variable number of re-reaches (<xref ref-type="fig" rid="F4">Fig. 4a</xref>). We segmented these re-reaches and identified the time of droplet consumption (reward) based the 3D movement trajectory relative to the labeled position of the water droplet (see <xref ref-type="sec" rid="S5">Methods</xref>). Resolving behavior and reward availability at the temporal scale of 20 ms bins allowed us to go beyond trial-averaged activity and focus on the dynamic PC1 changes on the single-trial level.</p><p id="P14">We found that PC1 dynamics closely followed the sub-second and millimetre resolution change of forepaw position during the reaching period (<xref ref-type="fig" rid="F4">Fig. 4a</xref>, <xref ref-type="supplementary-material" rid="SD1">Suppl. Video 1</xref>-<xref ref-type="supplementary-material" rid="SD3">3</xref>). To establish that PC1 activity is dependent on the temporal dynamics of the behavior in relation to achieving the goal, which in this task corresponds to consuming the rewarded droplet, we assigned all cued reaches of each session into four quartile bins based on the time delay between cue and reward. When aligned to cue, all reaches had similar PC1 onset times while trials with later droplet consumption showed a slower decay after the peak (<xref ref-type="fig" rid="F4">Fig. 4b, e</xref>). When we aligned PC1 activity to the time of reward, we found that this event coincided with PC1 peak while the subsequent decay trajectory was consistent across different trial quartiles, regardless of ongoing movement (<xref ref-type="fig" rid="F4">Fig. 4b, e</xref>). Notably, trials with long cue-to-reward delays maintained high PC1 activity until reward, suggesting that PC1 increased upon cue but that the time of PC1 peak is dependent on the time when the goal is achieved. We confirmed this on the session level by showing that the time from cue to PC1 peak is significantly correlated with the time of cue to reward (Pearson corelation: r = 0.46, p &lt; 0.001; LME model: R<sup>2</sup> = 0.35, p &lt; 0.001; <xref ref-type="fig" rid="F4">Fig. 4f</xref>). We also analysed the spatial distribution of PC1 activity based on the movement trajectory of the paw in the horizontal plane (0.5 x 0.5 mm bins). We found that peak PC1 activity in the spatial dimension was close to the location of the droplet and mouth (<xref ref-type="fig" rid="F4">Fig. 4d, g</xref>). Overall, these results suggest a strong relationship between PC1 dynamics and the time-varying proximity to reward consumption, the goal of the action.</p><p id="P15">Conversely, if PC1 activity mainly reflects movements that increase the likelihood of achieving the goal, we would expect that its activity should decrease when the goal expectation is decreasing. To test this hypothesis, we used the 3D movement trajectories to segment each cued trial into individual re-reaches and temporally align them to the start of the re-reach (see <xref ref-type="sec" rid="S5">methods</xref>). The movement trajectories of re-reaches were stereotypical and similar across subsequent re-reaches and independent whether they were performed in the presence of a droplet (n = 12,665) or – when the droplet was obtained in the previous re-reach – in the absence of a droplet (n = 11,670, <xref ref-type="fig" rid="F4">Fig. 4h-i</xref>). Focusing on the first ten re-reaches (n = 16,747), we found that PC1 activity decreased across subsequent re-reaches (0.1 per re-reach, p &lt; 0.001, LME model), despite similar movement trajectories (<xref ref-type="fig" rid="F4">Fig. 4h-i</xref>). Furthermore, any re-reach performed in the absence of a droplet exhibited a decrease in PC1 activity by 0.29 (p &lt; 0.001, LME model). This modulation by reward availability is comparable to our previous result from trial-averaged analysis of reaches with and without reward (<xref ref-type="fig" rid="F3">Fig. 3</xref>). These results further support the notion that the millisecond-scale temporal dynamic of global population activity is not simply a reflection of any movement, but rather specific to movements that increase the probability and proximity to goal attainment.</p><p id="P16">We further examined these results of actionable goal expectation at the regional level. We obtained region-specific PC1 activity by calculating the sum of the firing rate of simultaneously recorded neurons from each region, multiplied by their global PC1 coefficient. To ensure robust within-region population dynamics, we used a broader parcellation and only included regions and sessions with at least 20 simultaneously recorded neurons. We quantified the modulation by behavior using LME models for each region and found that cortex exhibited the strongest modulation by reach distance (0.49 ± 0.03), compared to lower estimates for the hippocampus (0.25 ± 0.09) and hypothalamus (0.26 ± 0.07) (coefficient ± standard error, coefficients are significant after False Discovery Rate (FDR) correction at p &lt; 0.05, <xref ref-type="fig" rid="F5">Fig. 5a-b</xref>). Reward-modulation was highest in striatum (0.38 ± 0.05) and not significant in the hippocampus (0.11 ± 0.09). We further confirmed that the time of PC1 peak significantly correlated to the time of reward across individual regions (<xref ref-type="fig" rid="F5">Fig. 5c</xref>, see <xref ref-type="sec" rid="S5">Methods</xref>). Thus, while we observed region-specific differences in PC1 modulation by cue, movement, and reward, the temporal relationship between PC1 activity and time of goal attainment was preserved across all recorded regions, suggesting distributed population encoding of goal proximity.</p></sec></sec><sec id="S4" sec-type="discussion"><title>Discussion</title><p id="P17">Through simultaneous large-scale recordings of neurons across multiple brain regions during a goal-directed reaching task (<xref ref-type="fig" rid="F1">Fig. 1</xref>), we show movement-related latent dynamics in regions beyond the classical motor cortical and thalamic regions<sup><xref ref-type="bibr" rid="R17">17</xref>,<xref ref-type="bibr" rid="R18">18</xref>,<xref ref-type="bibr" rid="R33">33</xref></sup>. These dynamics traverse a common subspace shared across all recorded brain regions and were preserved across individual animals and recording sessions (<xref ref-type="fig" rid="F2">Fig. 2</xref>). While we found mixed contributions of movement, cue, and reward on the trial level (<xref ref-type="fig" rid="F3">Fig. 3</xref>), we applied high resolution single-trial analyses of millisecond-timescale and naturalistic variation in reward timings to show that these global dynamics scale with continuous approach to the rewarded goal (<xref ref-type="fig" rid="F4">Fig. 4</xref>).</p><p id="P18">Brain-wide distribution of single neuron task-encoding could reflect inter-region communication in common latent subspaces. Encoding of stimulus, choice, action, outcome, and motivation at the single neuron level have been reported across the brain<sup><xref ref-type="bibr" rid="R4">4</xref>,<xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R34">34</xref>,<xref ref-type="bibr" rid="R35">35</xref></sup>. On a population level, these responses could underlie movement-related latent dynamics which have been observed in single or paired regions, both in cortical and subcortical regions<sup><xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R20">20</xref>,<xref ref-type="bibr" rid="R21">21</xref>,<xref ref-type="bibr" rid="R36">36</xref></sup>. We found shared and highly preserved population dynamics across many simultaneously recorded brain regions during goal-directed behavior. Our results suggest that the distributed task-encoding found at the single neuron level could reflect the contribution of these neurons to shared brain-wide latent dynamics during behavior. Preserved latent dynamics in motor cortex and striatum has previously been shown across individual subjects<sup><xref ref-type="bibr" rid="R36">36</xref></sup>. In line with a recent study<sup><xref ref-type="bibr" rid="R37">37</xref></sup>, we extend these findings by showing that preserved movement-related dynamics across subjects are not restricted to these motor regions but can be generalized to other non-motor brain regions, such as various thalamic nuclei and the hippocampus.</p><p id="P19">The widespread and highly conserved nature of these latent dynamics raises the question to what extent they are specific to the preparation and execution of goal-directed movement. Preparatory activity has been found in motor and other cortices and is dependent on thalamic input (<xref ref-type="fig" rid="F5">Fig. 5c-d</xref>)<sup><xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R33">33</xref>,<xref ref-type="bibr" rid="R37">37</xref>–<xref ref-type="bibr" rid="R40">40</xref></sup>. However, the strong modulation of the latent dynamic by the presence of reward and the time of goal attainment, together with low modulation during grooming movements, indicates that the coupling of latent dynamics to movement is strongly modulated by internal representations (<xref ref-type="fig" rid="F3">Fig. 3</xref>, <xref ref-type="fig" rid="F5">Fig. 5a-b</xref>). This could explain why movement kinematics could not fully explain behavior-related latent dynamics in previous studies<sup><xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R17">17</xref>,<xref ref-type="bibr" rid="R20">20</xref>,<xref ref-type="bibr" rid="R21">21</xref></sup>. A key factor in all tasks in which animals perform a goal-directed action, whether reaching for a target or licking for a reward, is the immediate and concurrent change in likelihood to achieve the goal. Consequently, we propose that the ubiquitous and highly conserved latent population dynamics across regions, animals, and tasks is strongly shaped by the fluctuating proximity to a goal which is dependent on the ongoing movement.</p><p id="P20">The identified goal representation could represent action-mediated reward expectation. Neural representations of upcoming or past reward across the brain are well established but mostly described through tuning properties of individual neurons<sup><xref ref-type="bibr" rid="R18">18</xref>,<xref ref-type="bibr" rid="R41">41</xref>–<xref ref-type="bibr" rid="R45">45</xref></sup>, and during static task epochs after the movement<sup><xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R7">7</xref></sup>. For example, L2-3 neurons in the mouse motor cortex are tuned to the outcome of a reach after the movement<sup><xref ref-type="bibr" rid="R46">46</xref></sup>. Our study focused on outcome or reward expectation during movement, which was enabled through the high temporal resolution of the recordings combined with analysis of re-reaches and reward timings. Importantly, we allowed the animal to adapt its goal representation based on its intrinsic anticipation of motor outcome, by not experimentally controlling the exact time or probability of reward during the reaching period (droplet is dispensed at cue). We showed that the temporal dynamics of latent population activity is scaled to the speed of approach to successful goal attainment (<xref ref-type="fig" rid="F4">Fig. 4f</xref>) and that the coupling between latent dynamics and movement is dependent on the availability of reward and when the goal is achieved (<xref ref-type="fig" rid="F4">Fig. 4h-i</xref>). As the temporal evolution of latent dynamics is especially suited to represent prospective timing<sup><xref ref-type="bibr" rid="R16">16</xref>,<xref ref-type="bibr" rid="R47">47</xref>–<xref ref-type="bibr" rid="R49">49</xref></sup>, we propose that this dominant neural activity across the brain can serve as an internal representation of dynamic fluctuating goal expectation that is continuously adapted by goal-directed movement.</p><p id="P21">The action-mediated goal representation identified here resembles the process of goal encoding during spatial navigation<sup><xref ref-type="bibr" rid="R50">50</xref></sup>. Previous studies have extended the hippocampus’ established role in representing the location of the animal to encoding of the location and distance of spatial goals<sup><xref ref-type="bibr" rid="R50">50</xref>–<xref ref-type="bibr" rid="R53">53</xref></sup>. Consequently, the hippocampus has been hypothesized to generate a predictive map that represents future states given the current state<sup><xref ref-type="bibr" rid="R54">54</xref></sup>. In line with this, the brain-wide latent dynamics observed in our study could serve as a predictive representation of goal proximity that is continuously adapted to sensory cues and the spatial position of the forelimb relative to the rewarding droplet. Thus, our results support theoretical predictions that flexible internal representations are actionable, meaning that they predict the consequences of their actions, rather than just encoding them<sup><xref ref-type="bibr" rid="R32">32</xref></sup>. The previous reports of widespread movement-related activity already highlighted the importance of accounting for movement when relating neuronal activity to sensory or cognitive processes<sup><xref ref-type="bibr" rid="R55">55</xref></sup>. Our observation that increasing proximity to goal could drive brain-wide activity further complicates this matter, as they are intricately linked to movement, but not perfectly aligned. By extracting the dominant dimension of trial-averaged activity during rewarded reaches, and not specific dimensions that distinguish between different trial conditions<sup><xref ref-type="bibr" rid="R19">19</xref></sup>, we have focused on a task-specific subspace that encompasses movement and reward availability. Other cognitive variables or internal states beyond the control of our experiments, such as attention<sup><xref ref-type="bibr" rid="R56">56</xref></sup>, vigor<sup><xref ref-type="bibr" rid="R57">57</xref></sup>, or thirst<sup><xref ref-type="bibr" rid="R34">34</xref></sup>, likely contribute to fluctuations in latent dynamics<sup><xref ref-type="bibr" rid="R58">58</xref></sup>. Future studies are needed to determine whether different cognitive variables can be distinguished in “multiplexed” global subspaces and how these latent subspaces are modulated by neuromodulators<sup><xref ref-type="bibr" rid="R59">59</xref>,<xref ref-type="bibr" rid="R60">60</xref></sup>.</p><p id="P22">While single neuron tuning to sensory, decision, or motor variables are widely distributed, they do exhibit region-specific differences in selectivity and timing<sup><xref ref-type="bibr" rid="R4">4</xref>,<xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R61">61</xref>,<xref ref-type="bibr" rid="R62">62</xref></sup>. Our result is not contradictory to these observations, as we also found region-specific differences in the contribution to the latent dynamic (<xref ref-type="fig" rid="F2">Fig. 2c</xref>). However, the identification of a task-related latent dimension that aligns population activity across all regions introduces a global shared subspace to jointly process action-mediated proximity to goal. Other shared subspaces likely exist for different computation that could lead to region-specific and mixed representation at the single neuron level<sup><xref ref-type="bibr" rid="R9">9</xref>,<xref ref-type="bibr" rid="R61">61</xref></sup>. More generally, the observation that goal representation is broadcasted through a global subspace would enable all regions to process information based on the principles of reinforcement learning or predictive coding<sup><xref ref-type="bibr" rid="R63">63</xref>–<xref ref-type="bibr" rid="R65">65</xref></sup>. In conclusion, our findings support the emerging perspective that sensory, cognitive, and motor processes are integrated within distributed and shared subspaces that capture dynamic changes of internal representations during ongoing movement<sup><xref ref-type="bibr" rid="R66">66</xref></sup>.</p></sec><sec id="S5" sec-type="methods"><title>Methods</title><sec id="S6"><title>Mice</title><p id="P23">All experiments were conducted in accordance with institutional guidelines and the UK Animal Scientific Procedures Act (1986) and its associated guidelines. Experiments were performed on eight adult male C57BL/6 mice aged between 3 to 4 months (Charles River). Mice were housed in individually ventilated cages on a 12-hour light/dark cycle. One animal was excluded due to complications during recording sessions, see below.</p></sec><sec id="S7"><title>Surgery</title><sec id="S8"><title>Headplate implantation</title><p id="P24">Before habituation and training, mice were implanted with a custom-made titanium headplate (Get It Made Ltd, London, 0.7 g) under isoflurane anesthesia (induction 4%, maintenance 1 - 2%). Analgesia was provided using Vetergesic (0.08 mg/kg) administered subcutaneously after induction of anesthesia. The skin on the dorsal surface of the skull was removed. The surrounding skin was secured to the skull using Vetbond (3M, Minnesota, USA). The skull was etched using H<sub>2</sub>O<sub>2</sub> and a bone scraper to increase adhesion of the headplate that was secured using dental cement (Super Bond C&amp;B, Parkell). A reference screw was wrapped in silver wire and screwed into a craniotomy over the contralateral cerebellum and was fixed in place using a small amount of dental cement (Jet Denture Repair Powder: Lang Dental, Illinois, USA; Meadway Repair Liquid: MR. Dental, Surrey). A custom-designed, 3D-printed shield was glued to the top of the headplate to prevent the animal from reaching recording probes. After implantation, mice recovered for at least a week.</p></sec><sec id="S9"><title>Craniotomy surgery</title><p id="P25">One day prior to recording, craniotomies (~1.5 mm diameter) were performed under isoflurane anesthesia using a dental bur over the right rostral forelimb area (RFA) (2.5 mm anterior, 1 mm lateral from Bregma), the right caudal forelimb area (CFA) (1.3 mm anterior, 0.4 mm lateral from Bregma) and, in a subset of four animals, at a site directed towards the thalamus (2.5 mm posterior, 1 mm lateral from Bregma). Following surgery, the craniotomies were covered with DuraGel (Cambridge Neurotech) and overlaid with silicone (Body Double, Smooth-On) to form a barrier and protective layer over the exposed brain tissue. During the craniotomy surgery, the hair on the left forelimb was shaved to improve pose estimation of the joints.</p></sec></sec><sec id="S10"><title>Behavior</title><sec id="S11"><title>Reaching task</title><p id="P26">Before training and recording, mice were habituated to head-fixation over multiple days, beginning with up to 5 minutes of head-fixation and increasing by 5-10 minutes per day. After habituation, mice were trained to perform head-fixed reaches for water droplets (4-5 μl containing 10-15% sucrose) using the left forearm based on a previous study<sup><xref ref-type="bibr" rid="R24">24</xref></sup> Mice had controlled access to water during training and recording, receiving a minimum of 1 ml water per day and enough to maintain a body weight above 85 % of the pre-surgical weight. Training incorporated two components: 1) Mice learned to reach for a droplet upon auditory cue and 2) mice learned to hold the bar for a random interval of 3 to 6 seconds. First, mice were prompted to groom with the left forelimb by application of a small droplet on the left whisker pad which was paired with an auditory cue (3.6 kHz, 80 ms) and a droplet at the spout (4-5 μl). The spout location was initially close to the mouth, allowing mice to lick the droplet. The spout was gradually moved beyond the reach of the tongue, prompting the mice to transition from a grooming motion to a forelimb reaching motion. After mice learn to successfully reach for a water droplet (position: ~5 mm anterior, ~5 mm ventral, ~5 mm lateral to the nose tip), they were trained to hold the metal bar with the left forepaw prior to reaching. Gradually the length of bar-holding time was increased from less than 200 ms to a random interval between 3- and 6-seconds after which the auditory cue and droplet were automatically presented. If mice released the bar prematurely before the cue and droplet presentation, the random interval timer was reset. If mice held the bar until the cue but did not reach or missed the droplet on the reach, the random interval timer was reset after a 10 s timeout. Within 1-2 weeks, mice learned this task and performed over 100 reaches in 30 min. After reaching this threshold, mice underwent craniotomy surgery and subsequent electrophysiological recordings (one recording session per day for 4-7 days).</p></sec><sec id="S12"><title>Setup _for behavior</title><p id="P27">We developed a custom-built rig for head-fixed training and recording using Thorlabs parts. The design was inspired by the rig of the International Brain Laboratory (IBL)<sup><xref ref-type="bibr" rid="R67">67</xref></sup>. The 3D printed headplate holder (Formlabs, Rigid 10k resin) was also adapted from the IBL design. We used the pyControl system for automated control of the task<sup><xref ref-type="bibr" rid="R25">25</xref></sup>. Specifically, we used the “Lickometer” to electrically detect bar and spout touches. To avoid electrical artifacts during recordings, we integrated a “Comparator Dual Lick Port Detector” (Janelia Experimental Technologies) into the detection circuit. Water droplets (4-5 μl) were dispensed through a gravitation-based system that was controlled by a miniature solenoid valve (Lee Company, LFVA1220210H). Cue tones (3.6 kHz, 80 ms) were delivered via a speaker located at ~10 cm from the animal. Custom scripts and the pyControl GUI were used to log the behavioral events (bar, spout touch) and automatically trigger the speaker and the solenoid valve.</p></sec></sec><sec id="S13"><title>Electrophysiology</title><sec id="S14"><title>Probe preparation</title><p id="P28">Neuropixels 1.0 probes were sharpened using a repurposed hard drive disk. The ground and reference pads of the probes were shortened and soldered to a wire that connected to the animal and ground. Each probe was labelled with fluorescent DiI (1mg/ml in isopropyl alcohol) before every insertion for <italic>post hoc</italic> probe localization.</p></sec><sec id="S15"><title>Neuropixels insertion</title><p id="P29">We used linear motors (Scientifica IVM) mounted on stereotaxic manipulators (Kopf Instruments 1363A, 3108B) to hold and insert Neuropixels 1.0 probes<sup><xref ref-type="bibr" rid="R68">68</xref></sup>. Two probes (npx1 and npx2) were held at defined spatial offsets on a custom-printed dual-probe holder (Formlabs, 10k Rigid resin) above the rostral forelimb area (npx 1: 2.5 mm AP, 1 mm ML) and caudal forelimb area (npx2: 1.3 mm AP, 0.4 mm ML) with an DV offset of 0.55 mm. They were inserted simultaneously at 3 μm/s up to a depth of ~3.5 mm. In animals with thalamic recordings, we inserted a third probe (npx3) to target hippocampus, thalamus, and hypothalamus, inserted at -2.5 mm AP and 1 mm ML with a 14° AP tilt. The speed of insertion was 5 μm/s until ~4.3 mm depth and then at a speed of 3 μm/s to a total depth of ~5.3 mm. Once all probes were inserted, they were retracted by 100 μm and allowed to rest in this final position for ~5 minutes before recording. After each recording session, probes were cleaned using Terg-a-zyme (1%, Sigma Aldrich), isopropyl alcohol and dH<sub>2</sub>O.</p></sec><sec id="S16"><title>Data acquisition</title><p id="P30">Electrophysiological data were acquired using OpenEphys software in binary format. Default settings were used for gain (AP band 500x, LFP band 250x), sampling rate (AP band 30 kHz, LFP band 2.5 kHz), and channel mapping (384 electrodes from tip). Recordings were referenced to the tip of the probe. Data were synced using random TTL pulses generated by pyControl. The Rsync module of pyControl was used to synchronize the electrophysiological data, behavioral events and the triggered video frames for downstream analyses.</p></sec><sec id="S17"><title>Histology and imaging</title><p id="P31">After recordings, mice were anesthetized with a terminal intraperitoneal injection of pentobarbital (200 mg/kg). Each mouse was transcardially perfused with 0.1 M phosphate buffered saline (PBS), followed by 4 % paraformaldehyde solution (PFA) in PB. The brains were removed, post-fixed for 2 hours in 4 % PFA in PB at room temperature, then washed with and stored in 0.1 M PB overnight at 4 ° in the dark. The following day, brains were transferred into 10 % sucrose in 0.1 M PB for storage at 4 ° overnight and finally transferred to 30 % sucrose in 0.1 M PB until sectioning. Brains were sectioned coronally at 50 μm per slice using a freezing microtome (Epredia HM 450) and stored in PB-Azide until mounting for imaging. Brightfield and DiI images were acquired using the Cy3 imaging protocol (Zen Blue software, excitation using 532 nm laser line) on an epifluorescent microscope (Zeiss Axio Imager M2) and a 5x objective.</p></sec><sec id="S18"><title>Region assignment</title><p id="P32">Probe tracks were reconstructed using the SHARP-Track toolbox<sup><xref ref-type="bibr" rid="R69">69</xref></sup>. Selected images were processed and aligned to the matching coordinates of the Allen mouse brain reference atlas. Probe tracks were then manually traced based on fluorescent tracks. Different probe trajectories were assigned to recording sessions based on matching of the reconstructed and the experimentally documented (manipulator coordinates) entry point into the brain. In cases of fewer recovered probe tracks than experimentally performed insertions, the most proximal trajectory was assigned. Adapted SHARP-Track code was used to map Allen Mouse Brain Common Coordinate Framework (Allen CCF) region labels to channels along the length of the Neuropixels probe. For the initial assignment, the “probe_length” parameter was based on the final coordinates of the linear motor. No scaling factor was applied.</p><p id="P33">To further align the region boundaries based on electrophysiological landmarks along the Neuropixels probe<sup><xref ref-type="bibr" rid="R70">70</xref></sup>, we designed a custom GUI to visualize relevant spike- or LFP-related data along the length of the probe: Spike raster, firing rate, cell count, waveform peak amplitude, AP band activity (number of crossing below -100 μV in 30 s interval), raw LFP (after subtracting median across channels), LFP power (Welch’s power spectral density estimate), LFP power normalized across channels, LFP power relative change across channels, LFP cross correlation across channels (see <xref ref-type="supplementary-material" rid="SD5">Fig. S3e</xref> for subset of those parameters). We visually inspected each probe insertion and shifted the probe to align region boundaries to characteristic electrophysiological landmarks as reported previously<sup><xref ref-type="bibr" rid="R70">70</xref></sup>: On Neuropixel-1 (npx-1: premotor cortex, medial prefrontal cortex, orbitofrontal cortex, olfactory areas), we aligned the boundary between cortex and olfactory areas to the sharp and consistent increase in low-frequency LFP power (<xref ref-type="supplementary-material" rid="SD5">Fig. S3e</xref>). On npx-2 (primary motor cortex and dorsal striatum), we aligned the boundary between white matter and caudaputamen (CP) to the sharp and consistent increase of high frequency LFP power (<xref ref-type="supplementary-material" rid="SD5">Fig. S3e</xref>).</p><p id="P34">Here, the corpus callosum and associated fibers are often demarked by a drop in cell count and overall LFP power. On npx-3, we aligned the boundary between hippocampus and thalamus to the sudden disappearance of within-hippocampal cross-correlation (molecular layer above and below pyramidal layer of dentate gyrus). This shift also aligned the “cross” of the LFP cross correlation to the center of the dentate gyrus pyramidal layer and corresponded to an increased spike amplitude in thalamic nuclei.</p><p id="P35">Overall, we found that a shifting of the region boundaries was sufficient so that other region boundaries also showed consistent and aligned changes in different parameters. To account for the expected imprecision, we grouped CCF region labels into broader region groups (see <xref ref-type="supplementary-material" rid="SD5">Fig. S3a</xref>) for the analysis performed in <xref ref-type="fig" rid="F1">Fig. 1</xref> and <xref ref-type="fig" rid="F2">Fig. 2</xref>. For region-level analysis in <xref ref-type="fig" rid="F5">Fig. 5</xref>, an even broader regional classification was chosen (cortex, thalamus, striatum, hippocampus, olfactory areas, hypothalamus). White matter regions and channels outside the brain were assigned as “Other” and excluded from analysis (only visualized in <xref ref-type="fig" rid="F2">Fig. 2c</xref>).</p></sec><sec id="S19"><title>Session curation</title><p id="P36">We initially recorded 42 sessions from 8 mice (<xref ref-type="supplementary-material" rid="SD5">Fig. S4a</xref>). After visual inspection of all data, we excluded four sessions due to the following technical reasons: One session was missing video files, one session had faulty bar hold detection, one animal only had two recording sessions, as we had to abort the recordings due to experimental complications. Due to the low number of sessions and incomplete data in the second recording session, we excluded this animal. The remaining data (38 recording sessions from 7 mice, 4-7 sessions per animal) were used throughout all analyses.</p></sec><sec id="S20"><title>Spike sorting and quality control</title><p id="P37">Automated spike sorting was carried out using KiloSort 3.0<sup><xref ref-type="bibr" rid="R71">71</xref></sup>. Using default parameters on the included 38 recording sessions of ~30 min duration each, we obtained a total of 87,935 isolated clusters of which 44,479 were labeled as “good” by Kilosort (51%, <xref ref-type="supplementary-material" rid="SD5">Fig. S4a</xref>). We only included the “good” labelled units for further analysis and imported them into the CellExplorer framework<sup><xref ref-type="bibr" rid="R72">72</xref></sup> for visual inspection of event-aligned spike raster, waveform, and auto-correlograms of individual units. To conduct spike sorting quality control in a feasible manner, we developed one inspection-motivated filtering step and calculated spike sorting quality metrics.</p><p id="P38">We used CellExplorer to visually inspect a subset of neurons, focusing on those that represented either typical or extreme values in the parameter distributions. Most inspected single units were well isolated, exhibiting physiological waveforms and appropriate modulation of spiking activity during the task (<xref ref-type="fig" rid="F5">Fig. 5</xref>). However, we identified a subset of “unstable” units, characterized by sudden abrupt onset or cessation of spiking activity throughout the trials (<xref ref-type="supplementary-material" rid="SD5">Fig. S4c</xref>). This unphysiological and likely drift-induced behavior could potentially bias population activity across different trials, motivating us to develop a principled approach to exclude them. Our analysis of the spike time coefficient of variance (CV2<sup><xref ref-type="bibr" rid="R73">73</xref></sup>) and the firing rate instability (mean absolute change of firing rate relative to the mean, <ext-link ext-link-type="uri" xlink:href="https://cellexplorer.org/datastructure/standard-cell-metrics/">https://cellexplorer.org/datastructure/standard-cell-metrics/</ext-link>) showed that ~85% of units exhibited a log-log relationship between these two metrics (<xref ref-type="supplementary-material" rid="SD5">Fig. S4b</xref>). However, a distinct subset exhibited high CV2 despite lower firing rate instability. These units showed unstable firing patterns both across trials (<xref ref-type="supplementary-material" rid="SD5">Fig. S4c</xref>) and throughout the session (<xref ref-type="supplementary-material" rid="SD5">Fig. S4e</xref>). We classified units with a CV2-to-instability ratio above 6 as “unstable” (n = 6,912) and excluded them from further analysis (<xref ref-type="supplementary-material" rid="SD5">Fig. S4a</xref>). These represented a minor fraction of units across all recorded sessions (<xref ref-type="supplementary-material" rid="SD5">Fig. S4f</xref>). Given that electrical noise was minimized using the lick comparator (see above) and considering that latent population dynamics can be robustly estimated even without spike sorting<sup><xref ref-type="bibr" rid="R74">74</xref></sup>, we decided against further curation. Consequently, our final analysis dataset included 37,567 “good” and “stable” units with 989 ± 261 units per session (mean ± SD). The high quality of these units was confirmed using the Bombcell toolbox<sup><xref ref-type="bibr" rid="R75">75</xref></sup>, with 95-99% of units classified as “good” by Bombcell’s default thresholds (<xref ref-type="supplementary-material" rid="SD5">Fig. S4g</xref>).</p></sec></sec><sec id="S21"><title>Video data</title><sec id="S22"><title>Video recording</title><p id="P39">Front and side videos were recorded at 100 frames per second using high-speed near infrared enhanced cameras (Ximea MQ013RG-ON or Pixelink PL-D721P). Two LED illuminators (BW 48 LED) were used for infrared lighting. Cameras frames were triggered by the pyControl board at 100 Hz, ensuring synchronization to the pyControl clock. Video data was acquired using StreamPix9 software (Norpix) and encoded in H.264. In one cohort (4 animals), we identified intermittent but systematic frame dropping that caused a consistent drift in the video data relative to the behavioral events. Through <italic>post hoc</italic> comparison of bar release times (measured with pyControl) and paw movement onsets (extracted from Video data using pose estimation described below), we were able to reliably calculate the drift rate and correct for it.</p></sec><sec id="S23"><title>Training automated pose estimation model</title><p id="P40">Using DeepLabCut 2.3.0<sup><xref ref-type="bibr" rid="R26">26</xref></sup>, we trained one model (ResNet50) per camera (side and front). The side view model was trained on 444 labelled frames and the front view model was trained on 550 labelled frames. The following left forelimb joints were labelled: Shoulder, elbow, wrist, the metacarpophalangeal joint, the proximal interphalangeal joint, and the tip of each digit, excluding the first digit, as it was too small to see. Further labels included the spout, the water droplet, and the proximal interphalangeal joint on the second digit of the right paw. Frames from each animal were included to capture the variance between individual mice. To ensure that the subset of labelled frames reflected most of the positional variance within a session, k-means clustering was applied to the frames in each video and a subset of frames from each cluster was chosen. To further improve generalization and prevent overfitting, the training dataset was also augmented using blurring, flipping, stretching, and partial occlusion of frames. The data was split into training (95%) and test data (5%), and the model trained until the loss plateaued<sup><xref ref-type="bibr" rid="R26">26</xref>,<xref ref-type="bibr" rid="R76">76</xref></sup>. After training, each model was visually inspected and refined through manual labeling of additional frames of underrepresented poses and relabeling of previously labeled frames to increase consistency. The side view model was refined over four training iterations and the front view model was refined over two training iterations. The final side view model had a training root mean squared error (RMSE) of 2.23 pixels and a test RMSE of 2.52 pixels. The last front view model had a training RMSE of 2.18 pixels and a test RMSE of 6.07 pixels. For comparison, human-level performance was previously reported as 2.7 pixels<sup><xref ref-type="bibr" rid="R26">26</xref>,<xref ref-type="bibr" rid="R76">76</xref></sup>.</p></sec><sec id="S24"><title>3D triangulation</title><p id="P41">The trained ResNet50 models were used to label the frames from each video. Each label’s position in 3D space was calculated by direct linear transform (DLT) triangulation with sparse bundle adjustment (SBA) using a wand-based procedure in Argus 3D (Jackson et al. 2016). The intrinsic and extrinsic camera parameters were calibrated using a checkerboard of known spatial dimensions, providing 3D-projections at millimeter scale. Validation through manually labeled frames of checkerboard images yielded a mean scaling offset by -0.017 mm. A 90° corner of the checkerboard was 91.2° in the 3D projection.</p></sec><sec id="S25"><title>Video data curation</title><p id="P42">We visually inspected all triangulated 3D reach trajectories and implemented an automatic filter to exclude mislabeled frames. Estimated coordinates were excluded if they fell in either of these categories: DLC likelihood on front or side camera below 0.5, acceleration exceeding 5 mm/s<sup>2</sup> (indicates outlier, 95% percentile of physiological acceleration mostly within 1 mm/s<sup>2</sup>), spatial position outside expected boundaries (in mm: AP [-20 15], DV [-10 15], ML [-10 20]). Linear interpolation was applied to reconstruct excluded coordinates. Further smoothing was applied using a Savitzky-Golay filter with a window size of 5 frames (50 ms). All sessions were visually inspected after automatic curation (<xref ref-type="supplementary-material" rid="SD5">Fig. S1</xref>).</p></sec><sec id="S26"><title>Video-based detection of behavioral times and reach types</title><p id="P43">All video-based analyses use the proximal interphalangeal joint of the left second digit as the position of the paw, also referred to as the movement trajectory.</p><sec id="S27"><title>Reach onset</title><p id="P44">We used movement trajectory to detect reach onset times, which proved to be more reliable than using the electrical bar release detection, as the comparator occasionally introduced drifts in the detection threshold. We detected the bar holding position as the location with the highest occupancy throughout the session (maximum frequency in AP-ML plane, binned at 0.5 x 0.5 mm). Reach onsets were subsequently detected whenever the paw crossed a threshold of 3 mm anterior to the holding position.</p></sec><sec id="S28"><title>Droplet retrieval</title><p id="P45">We trained the DeepLabCut model for the side view to detect the water droplet, generating a likelihood value for each frame. To detect the time when the animal has successfully retrieved the droplet, we identified instances where the droplet likelihood fell below 0.9 for 3 subsequent time points (20 ms bins) by applying a convolutional kernel to the likelihood timeseries.</p><p id="P46">Goal-directed approaches: To analyse movements irrespective of the trial structure, we detected all movements of the paw towards the droplets throughout the ~30 min session. We first calculated the 3D Euclidian distance between the paw (proximal interphalangeal joint of the left second digit) and the water droplet as extracted by the triangulated pose estimation coordinates. We then detected all periods when this distance was decreasing, indicating a goal-directed “approach” of the paw towards the droplet.</p></sec><sec id="S29"><title>Droplet consumption (reward)</title><p id="P47">The end of an approach was determined by the start of the next approach. This represented the time when the paw stopped after moving away from the droplet before re-approaching. In a successful approach that included the retrieval of the droplet, this time point represents the moment when the droplet has reached the mouth. We defined this moment as droplet consumption, or time of reward.</p><p id="P48">To compare different reach types, we excluded very small (distance &lt; 2 mm) and slow approaches (average speed &lt; 0.25 mm/s), and only focused on those that started from the bar (starting point less than 3 mm from holding position). For classification, we attributed different properties to each approach:</p></sec><sec id="S30"><title>Cued</title><p id="P49">If the approach was performed within 1 second of a cue, it was classified as “cued”. Otherwise, it was “spontaneous”.</p></sec><sec id="S31"><title>Reward</title><p id="P50">If the droplet was present during the approach, the reach was classified as “drop present”. Otherwise, it was “without drop”.</p></sec><sec id="S32"><title>Grooming</title><p id="P51">We also detected periods when the animal was performing a grooming movement, instead of a goal-directed reach for a water droplet. These periods could be well-isolated based on the paw moving more dorsal than the typical reach trajectory (<xref ref-type="fig" rid="F3">Fig. 3a</xref>). When this threshold was crossed within 2 seconds of a reach onset, this approach was classified as a grooming movement.</p></sec><sec id="S33"><title>Reach distance</title><p id="P52">We calculated the reach distance by detecting the maximum distance travelled by an approach within 500 ms after reach onset in the AP dimension. To categorize reach distances like the other properties, we divided them into three groups: 0-5 mm, 5-15 mm, &gt; 15 mm.</p></sec><sec id="S34"><title>Re-reaches</title><p id="P53">Re-reaches are defined as successive movements towards the location of the droplet after the initial reach from the bar, where the limb moved between the spout and the mouth without returning to the bar holding position. We detected re-reaches as approaches that started more than 3 mm anterior to the bar. We counted these “re-reaches” from the first complete reach that started from the bar holding position. This index was reset when the next reach started from the bar.</p></sec></sec></sec><sec id="S35"><title>Data analysis</title><sec id="S36"><title>Data integration</title><p id="P54">All data were integrated into the CellExplorer data framework for further analysis. The Rsync module by pyControl was used to synchronize video data, behavioral data, and spike times, using the time of the electrophysiological data as reference. A custom MATLAB-based data analysis pipeline was developed for data integration, processing, analysis, and visualization. Data were visualized using the gramm toolbox<sup><xref ref-type="bibr" rid="R77">77</xref></sup> or custom-written code. A large language model (ChatGPT4) was used to assist coding, mainly to refine human-generated code. Implemented AI-generated code was reviewed by the authors and validated through further analyses.</p></sec><sec id="S37"><title>Modulation index</title><p id="P55">The modulation index was calculated by the CellExplorer processing module<sup><xref ref-type="bibr" rid="R72">72</xref></sup>. It represents the relative increase in trial-averaged mean firing rate within 500 ms after the cue relative to the mean baseline firing rate within 250 ms before the cue. The p-value was calculated using a two-sample Kolmogorov-Smirnov test between the firing rate distribution and the post-cue and baseline period across trials. Significantly tuned neurons were identified after Bonferroni correction for multiple comparisons (alpha = 0.05): Given 37,567 comparisons (neurons), the corrected threshold for significance was established at p &lt; 1.3×10<sup>-06</sup>.</p></sec><sec id="S38"><title>Principal component analysis</title><p id="P56">Firing rates of each neuron were binned at 20 ms and smoothed using a Gaussian kernel with a standard deviation of 20 ms. To focus on the activity related to a cued reach for the droplet, we concatenated the firing rate timeseries 1.5 seconds before to 3 seconds after the time of reach onset from all cued trials of a session. Due to occasional multiple reach onsets after a cue, we aligned the trials to the last reach onset before the spout touch. Principal component analysis was performed separately for all simultaneously recorded neurons in each session (global PCA). The input matrix was defined by <italic>n</italic> × <italic>t</italic>, where rows corresponded to each neuron <italic>n</italic>, and columns <italic>t</italic> corresponded to different time bins. The values in the matrix represented the trial-averaged and normalized firing rate (normalized over time for each neuron). This approach captures the dominant patterns of covariation across the recorded population that are consistent across cued trials and the time of reach onset. Note that this approach does not “fit” the dimensions to distinguish any specific behavioral events beyond the correlated activity around a cued reach onset. We inverted the PC1 dynamics of four sessions and the PC2 dynamics of 12 sessions, as the sign of a principal component is arbitrary. The aim was to ensure a positive dynamic upon reach onset, facilitating comparisons across sessions.</p></sec><sec id="S39"><title>Comparison of latent dynamics across sessions and animals</title><p id="P57">For comparing global PCA dynamics across sessions and animals (<xref ref-type="fig" rid="F1">Fig. 1a-b</xref>), we directly used the latent variable output from the MATLAB “pca” function (-1.5 to 3 s around reach onset). To compare the temporal dynamics of the latents across the lowest three dimensions and all sessions, we performed pair-wise Pearson’s correlation coefficients between their timeseries (<xref ref-type="supplementary-material" rid="SD5">Fig. S2g</xref>). As the sign of a principal component is arbitrary, we reported the absolute value of correlation coefficients. The significance level was adjusted for 8,664 comparisons using Bonferroni correction (p &lt; 10<sup>-6</sup>).</p></sec><sec id="S40"><title>Comparison of latent dynamics across regions</title><p id="P58">We obtained the time-varying weighted contribution of each neuron to the global PC1 dynamic by multiplying the PC1 coefficient of each neuron by its continuous and normalized firing rate. The average of these weighted contributions from all simultaneously recorded neurons represents the “global PC1 activity” over time (<xref ref-type="fig" rid="F4">Fig. 4a</xref>). Averaging the weighted contributions of simultaneously recorded neurons from the same region provides the regional expression of this global PC1 activity (<xref ref-type="fig" rid="F2">Fig. 2e</xref>). To further compare the global dynamics with the dominant latent population dynamics within a region, we performed PCA on matrices restricted to neurons from individual region group (local PCA). As the sign of a principal component is arbitrary, we inverted the sign of PC1 coefficients when the correlation was negative.</p></sec><sec id="S41"><title>Comparing latent dynamic amplitudes across reach types</title><p id="P59">To compare expression of the global PC1 across different reach types (<xref ref-type="fig" rid="F2">Fig. 2</xref>, <xref ref-type="fig" rid="F4">Fig. 4</xref>, <xref ref-type="fig" rid="F5">Fig. 5</xref>), we segmented the continuous global PC1 activity into different trials that were categorized based on the presence of cue, reach distance and availability of reward (see above). We measured the peak amplitude of PC1 within 500 ms after reach onset across all types of trials. To compare reach type-specific differences across sessions, we aligned each session’s PC1 activity to its mean baseline in cued reaches (1 second before the cue) and normalized the peak amplitudes to the peak of cued reaches (amplitude = 1).</p><p id="P60">We calculated the mean normalized PC1 peak amplitude (PC1 peak<sub>normalized</sub>) for each reach type and session, aggregating trials that shared the same properties (reach distance, cue, reward). Region-specific PC1 activity was computed by averaging the weighted contributions of neurons recorded simultaneously from the same region. To ensure statistical robustness, we excluded data from any region within a session if fewer than 20 neurons were recorded, and data from sessions that had fewer than five trials of any specific reach type.</p><p id="P61">Linear mixed effect (LME) models were used to statistically evaluate the effect of behavioral predictors on PC1 peak at the session level. To account for inter-animal variability, the models included random intercepts for each animal. To reflect the ordinal scale of reach distances, we transformed them to a range from 0 to 1: distances of 0-5 mm were coded as 0, 5-15 mm as 0.5, and distances greater than 15 mm as 1 (full reaches). Normalizing both reach distances and PC1 peak amplitudes to a scale of 0 to 1 improves the interpretability of the model’s coefficients. For example, a coefficient of 0.52 for movement can be understood as a predicted 48% reduction of PC1 activity during an aborted reach (0-5 mm, normalized to 0) compared to the PC1 peak observed in a complete cued reach (PC1 = 1, distance &gt; 15 mm = 1). We calculated the variance inflation factor and found no strong multicollinearity among the predictors (distance: 1, reward: 1.4, cue: 1.4). The model for global PC1 activity had 325 observations (sessions × reach types) and the following formula: <disp-formula id="FD1"><mml:math id="M1"><mml:mrow><mml:mtext> </mml:mtext><mml:mi>P</mml:mi><mml:mi>C</mml:mi><mml:mtext>1 </mml:mtext><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>z</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi/></mml:mrow></mml:msub><mml:mo>~</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mi/><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>d</mml:mi><mml:mtext> </mml:mtext><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mtext> </mml:mtext><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>∣</mml:mo><mml:mtext> </mml:mtext><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P62">The LME model for region-specific expression of PC1 activity had 770 observations (regions × sessions × reach types) and included random intercepts for each animal and each region.
<disp-formula id="FD2"><mml:math id="M2"><mml:mrow><mml:mi>P</mml:mi><mml:mi>C</mml:mi><mml:mtext>1 </mml:mtext><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>z</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi/></mml:mrow></mml:msub><mml:mo>~</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mi/><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>d</mml:mi><mml:mtext> </mml:mtext><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mtext> </mml:mtext><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>∣</mml:mo><mml:mtext> </mml:mtext><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>∣</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P63">One session exhibited significant non-aligned fluctuations in striatal and olfactory PC activity due to low numbers of spontaneous trials and the occurrence of non-stereotypical reaching behaviors. This session was excluded from the LME model to avoid distortion by under-sampled outliers.</p></sec><sec id="S42"><title>Correlating latent dynamics with behavioral timing</title><p id="P64">To compare temporal dynamics of PC1 relative to the timing of drop retrieval, we assigned trials into quartiles based on their time delay between the cue and retrieval of the droplet (<xref ref-type="fig" rid="F4">Fig. 4b</xref>). The time of PC1 peak was detected within 2 seconds after the cue. Trials with cue-to-drop delays of more than 2 s were excluded. For visualization across sessions, the PC1 dynamic were averaged within each quartile and session (<xref ref-type="fig" rid="F4">Fig. 4e</xref>). An LME model was used to determine the statistical relationship between PC1 peak time and drop retrieval time (reward), while accounting for random intercepts of each animal and each session (observations = 5,821 cued reaches): <disp-formula id="FD3"><mml:math id="M3"><mml:mi>P</mml:mi><mml:mi>C</mml:mi><mml:mtext>1 </mml:mtext><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mtext> </mml:mtext></mml:mrow></mml:msub><mml:mo>~</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mo>-</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>d</mml:mi><mml:mtext> </mml:mtext></mml:mrow></mml:msub><mml:mo>±</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P65">For region-wise statistics, we calculated the mean peak of region-specific PC1 activity and cuereward delay for each cue-reward quartile of each session. We estimated their relationship using a LME model for each region separately while accounting for random intercepts of each session: <disp-formula id="FD4"><mml:math id="M4"><mml:mi>P</mml:mi><mml:mi>C</mml:mi><mml:mtext>1 </mml:mtext><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mtext> </mml:mtext></mml:mrow></mml:msub><mml:mo>~</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mo>-</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>d</mml:mi><mml:mtext> </mml:mtext></mml:mrow></mml:msub><mml:mo>±</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P66">To determine the influence of successive re-reaches (up to the tenth re-reach) and the availability of reward during these re-reaches, we calculated an LME model that accounted for random intercepts for each session (observations = 16,747 re-reaches): <disp-formula id="FD5"><mml:math id="M5"><mml:mi>P</mml:mi><mml:mi>C</mml:mi><mml:mtext>1 </mml:mtext><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>k</mml:mi><mml:mtext> </mml:mtext><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>z</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mtext> </mml:mtext></mml:mrow></mml:msub><mml:mo>~</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>-</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mtext> </mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>d</mml:mi><mml:mtext> </mml:mtext><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>∣</mml:mo><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula></p></sec><sec id="S43"><title>Spatial analysis</title><p id="P67">Trial-aligned latent dynamics were mapped to 3D spatial bins of 0.5 x 0.5 x 0.5 mm size based on the movement trajectory. Data was interpolated from 20 ms time bins to 5 ms time bins (0.25 steps). For detection of PC1 peak location, we focused on data during the first reach and subsequent re-reaches after a cue that were performed when the droplet was still present. We only included spatial bins that had been traversed 20 or more times during the session. To obtain a spatial heatmap for PC1 activity (<xref ref-type="fig" rid="F4">Fig. 4d</xref>), we averaged each spatial bin across trials. To detect the location of the peak, we smoothed the spatial heatmap using 2D interpolation (step size 0.25) and determined the bin with the maximum mean PC1 value. To spatially align reach trajectories across sessions and animals, we manually determined, for each session individually (<xref ref-type="fig" rid="F4">Fig. 4g</xref>), the position at the end of the first reach before the initiation of re-reaches to approximate the position of reward consumption.</p></sec></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplemental video 1</label><caption><title>Video of cued reaches and global PC1 dynamic.</title></caption><media xlink:href="EMS199918-supplement-Supplemental_video_1.mp4" mimetype="video" mime-subtype="mp4" id="d8aAcEbC" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD2"><label>Supplemental video 2</label><caption><title>Video of spontaneous reaches with reward and global PC1 dynamic.</title></caption><media xlink:href="EMS199918-supplement-Supplemental_video_2.mp4" mimetype="video" mime-subtype="mp4" id="d8aAcEcC" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD3"><label>Supplemental video 3</label><caption><title>Video of spontaneous reaches without reward and global PC1 dynamic.</title></caption><media xlink:href="EMS199918-supplement-Supplemental_video_3.mp4" mimetype="video" mime-subtype="mp4" id="d8aAcEdC" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD4"><label>Supplemental video 4</label><caption><title>Video of grooming episode and neural PC1 dynamic.</title></caption><media xlink:href="EMS199918-supplement-Supplemental_video_4.mp4" mimetype="video" mime-subtype="mp4" id="d8aAcEeC" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD5"><label>Supplementary figures 1-7</label><media xlink:href="EMS199918-supplement-Supplementary_figures_1_7.pdf" mimetype="application" mime-subtype="pdf" id="d8aAcEfB" position="anchor"/></supplementary-material></sec></body><back><ack id="S44"><title>Acknowledgements</title><p>We thank Brook Perry, Robert Toth, Ben Micklem, Melissa Serrano, Colin McNamara, Julien Carponcy, Naomi Berry, Shiva Mahdian, Zengcai V Guo, and Jessica Myatt for technical and experimental assistance.</p><sec id="S45"><title>Funding</title><p>German Research Foundation (DFG) Walter Benjamin Fellowship (451242556) and DFG Retune TRR 295 to Yangfan Peng; Medical Research Council UK (MRC) to Andrew Sharott (MC_UU_00003/6), Einstein Foundation Berlin visiting fellowship to Andrew Sharott (EVF-BUA-2022-726= ; Wellcome Trust Sir Henry Wellcome Postdoctoral Fellowship to Jeffrey Stedehouder (224129/Z/21/Z); Wellcome Trust Clinical PhD Fellowship to Rahul Shah (109030/Z/15/Z), Wellcome Trust grant to Armin Lak (213465).</p></sec></ack><sec id="S46" sec-type="data-availability"><title>Data availability</title><p id="P68">Upon publication, the data and core analysis code will be made available at <ext-link ext-link-type="uri" xlink:href="https://data.mrc.ox.ac.uk">https://data.mrc.ox.ac.uk</ext-link>.</p></sec><fn-group><fn id="FN2" fn-type="con"><p id="P69"><bold>Author contributions</bold></p><p id="P70">Conceptualization: YP, AS. Methodology: YP, CL, ST, JS, RS, AL. Formal analysis: YP, CL. Investigation: YP, ST. Funding and resources: YP, AS, CS. Data curation: YP, CL, ST, JS. Writing – original draft: YP, AS. Writing – review &amp; editing: all authors. Visualization: YP, JS. Supervision: AS, CS, AL.</p></fn><fn id="FN3" fn-type="conflict"><p id="P71"><bold>Competing interests</bold></p><p id="P72">The authors declare no competing interests.</p></fn></fn-group><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Georgopoulos</surname><given-names>A</given-names></name><name><surname>Kalaska</surname><given-names>J</given-names></name><name><surname>Caminiti</surname><given-names>R</given-names></name><name><surname>Massey</surname><given-names>J</given-names></name></person-group><article-title>On the relations between the direction of two-dimensional arm movements and cell discharge in primate motor cortex</article-title><source>J Neurosci</source><year>1982</year><volume>2</volume><fpage>1527</fpage><lpage>1537</lpage><pub-id pub-id-type="pmcid">PMC6564361</pub-id><pub-id pub-id-type="pmid">7143039</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.02-11-01527.1982</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fu</surname><given-names>QG</given-names></name><name><surname>Suarez</surname><given-names>JI</given-names></name><name><surname>Ebner</surname><given-names>TJ</given-names></name></person-group><article-title>Neuronal specification of direction and distance during reaching movements in the superior precentral premotor area and primary motor cortex of monkeys</article-title><source>J Neurophysiol</source><year>1993</year><volume>70</volume><fpage>2097</fpage><lpage>2116</lpage><pub-id pub-id-type="pmid">8294972</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwartz</surname><given-names>AB</given-names></name></person-group><article-title>Motor cortical activity during drawing movements: single-unit activity during sinusoid tracing</article-title><source>J Neurophysiol</source><year>1992</year><volume>68</volume><fpage>528</fpage><lpage>541</lpage><pub-id pub-id-type="pmid">1527573</pub-id></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steinmetz</surname><given-names>NA</given-names></name><name><surname>Zatka-Haas</surname><given-names>P</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><article-title>Distributed coding of choice, action and engagement across the mouse brain</article-title><source>Nature</source><year>2019</year><volume>576</volume><fpage>266</fpage><lpage>273</lpage><pub-id pub-id-type="pmcid">PMC6913580</pub-id><pub-id pub-id-type="pmid">31776518</pub-id><pub-id pub-id-type="doi">10.1038/s41586-019-1787-x</pub-id></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Musall</surname><given-names>S</given-names></name><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Juavinett</surname><given-names>AL</given-names></name><name><surname>Gluf</surname><given-names>S</given-names></name><name><surname>Churchland</surname><given-names>AK</given-names></name></person-group><article-title>Single-trial neural dynamics are dominated by richly varied movements</article-title><source>Nature Neuroscience</source><year>2019</year><volume>22</volume><fpage>1677</fpage><lpage>1686</lpage><pub-id pub-id-type="pmcid">PMC6768091</pub-id><pub-id pub-id-type="pmid">31551604</pub-id><pub-id pub-id-type="doi">10.1038/s41593-019-0502-4</pub-id></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>S</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>ZA</given-names></name><name><surname>Colonell</surname><given-names>J</given-names></name><name><surname>Liu</surname><given-names>LD</given-names></name><name><surname>Hou</surname><given-names>H</given-names></name><name><surname>Tien</surname><given-names>N-W</given-names></name><name><surname>Wang</surname><given-names>T</given-names></name><name><surname>Harris</surname><given-names>T</given-names></name><name><surname>Druckmann</surname><given-names>S</given-names></name><etal/></person-group><article-title>Brain-wide neural activity underlying memory-guided movement</article-title><source>Cell</source><year>2024</year><volume>187</volume><fpage>676</fpage><lpage>691</lpage><elocation-id>e16</elocation-id><pub-id pub-id-type="pmcid">PMC11492138</pub-id><pub-id pub-id-type="pmid">38306983</pub-id><pub-id pub-id-type="doi">10.1016/j.cell.2023.12.035</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lab</surname><given-names>IB</given-names></name><name><surname>Benson</surname><given-names>B</given-names></name><name><surname>Benson</surname><given-names>J</given-names></name><name><surname>Birman</surname><given-names>D</given-names></name><name><surname>Bonacchi</surname><given-names>N</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Catarino</surname><given-names>JA</given-names></name><name><surname>Chapuis</surname><given-names>GA</given-names></name><name><surname>Churchland</surname><given-names>AK</given-names></name><name><surname>Dan</surname><given-names>Y</given-names></name><etal/></person-group><article-title>A Brain-Wide Map of Neural Activity during Complex Behaviour</article-title><year>2023</year><pub-id pub-id-type="doi">10.1101/2023.07.04.547681</pub-id></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><article-title>Temporal Complexity and Heterogeneity of Single-Neuron Activity in Premotor and Motor Cortex</article-title><source>J Neurophysiol</source><year>2007</year><volume>97</volume><fpage>4235</fpage><lpage>4257</lpage><pub-id pub-id-type="pmid">17376854</pub-id></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rigotti</surname><given-names>M</given-names></name><name><surname>Barak</surname><given-names>O</given-names></name><name><surname>Warden</surname><given-names>MR</given-names></name><name><surname>Wang</surname><given-names>X-J</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name></person-group><article-title>The importance of mixed selectivity in complex cognitive tasks</article-title><source>Nature</source><year>2013</year><volume>497</volume><fpage>585</fpage><lpage>590</lpage><pub-id pub-id-type="pmcid">PMC4412347</pub-id><pub-id pub-id-type="pmid">23685452</pub-id><pub-id pub-id-type="doi">10.1038/nature12160</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shenoy</surname><given-names>KV</given-names></name><name><surname>Sahani</surname><given-names>M</given-names></name><name><surname>Churchland</surname><given-names>MM</given-names></name></person-group><article-title>Cortical Control of Arm Movements: A Dynamical Systems Perspective</article-title><source>Annu Rev Neurosci</source><year>2013</year><volume>36</volume><fpage>337</fpage><lpage>359</lpage><pub-id pub-id-type="pmid">23725001</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cunningham</surname><given-names>JP</given-names></name><name><surname>Yu</surname><given-names>BM</given-names></name></person-group><article-title>Dimensionality reduction for large-scale neural recordings</article-title><source>Nat Neurosci</source><year>2014</year><volume>17</volume><fpage>1500</fpage><lpage>1509</lpage><pub-id pub-id-type="pmcid">PMC4433019</pub-id><pub-id pub-id-type="pmid">25151264</pub-id><pub-id pub-id-type="doi">10.1038/nn.3776</pub-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vyas</surname><given-names>S</given-names></name><name><surname>Golub</surname><given-names>MD</given-names></name><name><surname>Sussillo</surname><given-names>D</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><article-title>Computation Through Neural Population Dynamics</article-title><source>Annu Rev Neurosci</source><year>2020</year><volume>43</volume><fpage>249</fpage><lpage>275</lpage><pub-id pub-id-type="pmcid">PMC7402639</pub-id><pub-id pub-id-type="pmid">32640928</pub-id><pub-id pub-id-type="doi">10.1146/annurev-neuro-092619-094115</pub-id></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mante</surname><given-names>V</given-names></name><name><surname>Sussillo</surname><given-names>D</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><article-title>Context-dependent computation by recurrent dynamics in prefrontal cortex</article-title><source>Nature</source><year>2013</year><volume>503</volume><fpage>78</fpage><lpage>84</lpage><pub-id pub-id-type="pmcid">PMC4121670</pub-id><pub-id pub-id-type="pmid">24201281</pub-id><pub-id pub-id-type="doi">10.1038/nature12742</pub-id></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DePasquale</surname><given-names>B</given-names></name><name><surname>Sussillo</surname><given-names>D</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name><name><surname>Churchland</surname><given-names>MM</given-names></name></person-group><article-title>The centrality of population-level factors to network computation is demonstrated by a versatile approach for training spiking networks</article-title><source>Neuron</source><year>2023</year><volume>111</volume><fpage>631</fpage><lpage>649</lpage><elocation-id>e10</elocation-id><pub-id pub-id-type="pmcid">PMC10118067</pub-id><pub-id pub-id-type="pmid">36630961</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2022.12.007</pub-id></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Brincat</surname><given-names>SL</given-names></name><name><surname>Roy</surname><given-names>JE</given-names></name></person-group><article-title>Cognition is an emergent property</article-title><source>Curr Opin Behav Sci</source><year>2024</year><volume>57</volume><elocation-id>101388</elocation-id><pub-id pub-id-type="doi">10.1016/j.cobeha.2024.101388</pub-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Narain</surname><given-names>D</given-names></name><name><surname>Hosseini</surname><given-names>EA</given-names></name><name><surname>Jazayeri</surname><given-names>M</given-names></name></person-group><article-title>Flexible timing by temporal scaling of cortical responses</article-title><source>Nat Neurosci</source><year>2017</year><volume>21</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="pmcid">PMC5742028</pub-id><pub-id pub-id-type="pmid">29203897</pub-id><pub-id pub-id-type="doi">10.1038/s41593-017-0028-6</pub-id></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname><given-names>M</given-names></name><name><surname>Cunningham</surname><given-names>J</given-names></name><name><surname>Kaufman</surname><given-names>M</given-names></name><name><surname>Foster</surname><given-names>J</given-names></name><name><surname>Nuyujukian</surname><given-names>P</given-names></name><name><surname>Ryu</surname><given-names>S</given-names></name><name><surname>Shenoy</surname><given-names>K</given-names></name></person-group><article-title>Neural population dynamics during reaching</article-title><source>Nature</source><year>2012</year><volume>487</volume><fpage>51</fpage><lpage>56</lpage><pub-id pub-id-type="pmcid">PMC3393826</pub-id><pub-id pub-id-type="pmid">22722855</pub-id><pub-id pub-id-type="doi">10.1038/nature11129</pub-id></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Inagaki</surname><given-names>HK</given-names></name><name><surname>Chen</surname><given-names>S</given-names></name><name><surname>Ridder</surname><given-names>MC</given-names></name><name><surname>Sah</surname><given-names>P</given-names></name><name><surname>Li</surname><given-names>N</given-names></name><name><surname>Yang</surname><given-names>Z</given-names></name><name><surname>Hasanbegovic</surname><given-names>H</given-names></name><name><surname>Gao</surname><given-names>Z</given-names></name><name><surname>Gerfen</surname><given-names>CR</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name></person-group><article-title>A midbrain-thalamus-cortex circuit reorganizes cortical dynamics to initiate movement</article-title><source>Cell</source><year>2022</year><volume>185</volume><fpage>1065</fpage><lpage>1081</lpage><elocation-id>e23</elocation-id><pub-id pub-id-type="pmcid">PMC8990337</pub-id><pub-id pub-id-type="pmid">35245431</pub-id><pub-id pub-id-type="doi">10.1016/j.cell.2022.02.006</pub-id></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>N</given-names></name><name><surname>Daie</surname><given-names>K</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name><name><surname>Druckmann</surname><given-names>S</given-names></name></person-group><article-title>Robust neuronal dynamics in premotor cortex during motor planning</article-title><source>Nature</source><year>2016</year><volume>532</volume><fpage>459</fpage><lpage>464</lpage><pub-id pub-id-type="pmcid">PMC5081260</pub-id><pub-id pub-id-type="pmid">27074502</pub-id><pub-id pub-id-type="doi">10.1038/nature17643</pub-id></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stringer</surname><given-names>C</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Steinmetz</surname><given-names>N</given-names></name><name><surname>Reddy</surname><given-names>CB</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><article-title>Spontaneous behaviors drive multidimensional, brainwide activity</article-title><source>Science</source><year>2019</year><volume>364</volume><fpage>255</fpage><pub-id pub-id-type="pmcid">PMC6525101</pub-id><pub-id pub-id-type="pmid">31000656</pub-id><pub-id pub-id-type="doi">10.1126/science.aav7893</pub-id></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Manley</surname><given-names>J</given-names></name><name><surname>Lu</surname><given-names>S</given-names></name><name><surname>Barber</surname><given-names>K</given-names></name><name><surname>Demas</surname><given-names>J</given-names></name><name><surname>Kim</surname><given-names>H</given-names></name><name><surname>Meyer</surname><given-names>D</given-names></name><name><surname>Traub</surname><given-names>FM</given-names></name><name><surname>Vaziri</surname><given-names>A</given-names></name></person-group><article-title>Simultaneous, cortex-wide dynamics of up to 1 million neurons reveal unbounded scaling of dimensionality with neuron number</article-title><source>Neuron</source><year>2024</year><pub-id pub-id-type="pmcid">PMC11098699</pub-id><pub-id pub-id-type="pmid">38452763</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2024.02.011</pub-id></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pezzulo</surname><given-names>G</given-names></name><name><surname>Cisek</surname><given-names>P</given-names></name></person-group><article-title>Navigating the Affordance Landscape: Feedback Control as a Process Model of Behavior and Cognition</article-title><source>Trends Cogn Sci</source><year>2016</year><volume>20</volume><fpage>414</fpage><lpage>424</lpage><pub-id pub-id-type="pmid">27118642</pub-id></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Desmurget</surname><given-names>M</given-names></name><name><surname>Grafton</surname><given-names>S</given-names></name></person-group><article-title>Forward modeling allows feedback control for fast reaching movements</article-title><source>Trends Cogn Sci</source><year>2000</year><volume>4</volume><fpage>423</fpage><lpage>431</lpage><pub-id pub-id-type="pmid">11058820</pub-id></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Galiñanes</surname><given-names>GL</given-names></name><name><surname>Bonardi</surname><given-names>C</given-names></name><name><surname>Huber</surname><given-names>D</given-names></name></person-group><article-title>Directional Reaching for Water as a Cortex-Dependent Behavioral Framework for Mice</article-title><source>Cell Reports</source><year>2018</year><volume>22</volume><fpage>2767</fpage><lpage>2783</lpage><pub-id pub-id-type="pmcid">PMC5863030</pub-id><pub-id pub-id-type="pmid">29514103</pub-id><pub-id pub-id-type="doi">10.1016/j.celrep.2018.02.042</pub-id></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akam</surname><given-names>T</given-names></name><name><surname>Lustig</surname><given-names>A</given-names></name><name><surname>Rowland</surname><given-names>JM</given-names></name><name><surname>Kapanaiah</surname><given-names>SK</given-names></name><name><surname>Esteve-Agraz</surname><given-names>J</given-names></name><name><surname>Panniello</surname><given-names>M</given-names></name><name><surname>Márquez</surname><given-names>C</given-names></name><name><surname>Kohl</surname><given-names>MM</given-names></name><name><surname>Kätzel</surname><given-names>D</given-names></name><name><surname>Costa</surname><given-names>RM</given-names></name><etal/></person-group><article-title>Open-source, Python-based, hardware and software for controlling behavioural neuroscience experiments</article-title><source>eLife</source><year>2022</year><volume>11</volume><elocation-id>e67846</elocation-id><pub-id pub-id-type="pmcid">PMC8769647</pub-id><pub-id pub-id-type="pmid">35043782</pub-id><pub-id pub-id-type="doi">10.7554/eLife.67846</pub-id></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathis</surname><given-names>A</given-names></name><name><surname>Mamidanna</surname><given-names>P</given-names></name><name><surname>Cury</surname><given-names>KM</given-names></name><name><surname>Abe</surname><given-names>T</given-names></name><name><surname>Murthy</surname><given-names>VN</given-names></name><name><surname>Mathis</surname><given-names>MW</given-names></name><name><surname>Bethge</surname><given-names>M</given-names></name></person-group><article-title>DeepLabCut: markerless pose estimation of user-defined body parts with deep learning</article-title><source>Nat Neurosci</source><year>2018</year><volume>21</volume><fpage>1281</fpage><lpage>1289</lpage><pub-id pub-id-type="pmid">30127430</pub-id></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jackson</surname><given-names>BE</given-names></name><name><surname>Evangelista</surname><given-names>DJ</given-names></name><name><surname>Ray</surname><given-names>DD</given-names></name><name><surname>Hedrick</surname><given-names>TL</given-names></name></person-group><article-title>3D for the people: multi-camera motion capture in the field with consumer-grade cameras and open source software</article-title><source>Biol Open</source><year>2016</year><volume>5</volume><fpage>1334</fpage><lpage>1342</lpage><pub-id pub-id-type="pmcid">PMC5051647</pub-id><pub-id pub-id-type="pmid">27444791</pub-id><pub-id pub-id-type="doi">10.1242/bio.018713</pub-id></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elsayed</surname><given-names>GF</given-names></name><name><surname>Cunningham</surname><given-names>JP</given-names></name></person-group><article-title>Structure in neural population recordings: an expected byproduct of simpler phenomena?</article-title><source>Nat Neurosci</source><year>2017</year><volume>20</volume><fpage>1310</fpage><lpage>1318</lpage><pub-id pub-id-type="pmcid">PMC5577566</pub-id><pub-id pub-id-type="pmid">28783140</pub-id><pub-id pub-id-type="doi">10.1038/nn.4617</pub-id></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallego</surname><given-names>JA</given-names></name><name><surname>Perich</surname><given-names>MG</given-names></name><name><surname>Miller</surname><given-names>LE</given-names></name><name><surname>Solla</surname><given-names>SA</given-names></name></person-group><article-title>Neural Manifolds for the Control of Movement</article-title><source>Neuron</source><year>2017</year><volume>94</volume><fpage>978</fpage><lpage>984</lpage><pub-id pub-id-type="pmcid">PMC6122849</pub-id><pub-id pub-id-type="pmid">28595054</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2017.05.025</pub-id></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stringer</surname><given-names>C</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Steinmetz</surname><given-names>N</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><article-title>High-dimensional geometry of population responses in visual cortex</article-title><source>Nature</source><year>2019</year><volume>571</volume><fpage>361</fpage><lpage>365</lpage><pub-id pub-id-type="pmcid">PMC6642054</pub-id><pub-id pub-id-type="pmid">31243367</pub-id><pub-id pub-id-type="doi">10.1038/s41586-019-1346-5</pub-id></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallego</surname><given-names>JA</given-names></name><name><surname>Perich</surname><given-names>MG</given-names></name><name><surname>Naufel</surname><given-names>SN</given-names></name><name><surname>Ethier</surname><given-names>C</given-names></name><name><surname>Solla</surname><given-names>SA</given-names></name><name><surname>Miller</surname><given-names>LE</given-names></name></person-group><article-title>Cortical population activity within a preserved neural manifold underlies multiple motor behaviors</article-title><source>Nat Commun</source><year>2018</year><volume>9</volume><elocation-id>4233</elocation-id><pub-id pub-id-type="pmcid">PMC6185944</pub-id><pub-id pub-id-type="pmid">30315158</pub-id><pub-id pub-id-type="doi">10.1038/s41467-018-06560-z</pub-id></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dorrell</surname><given-names>W</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Whittington</surname><given-names>JCR</given-names></name></person-group><article-title>Actionable Neural Representations: Grid Cells from Minimal Constraints</article-title><source>arXiv</source><year>2022</year><pub-id pub-id-type="doi">10.48550/arxiv.2209.15563</pub-id></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sauerbrei</surname><given-names>BA</given-names></name><name><surname>Guo</surname><given-names>J-Z</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name><name><surname>Mischiati</surname><given-names>M</given-names></name><name><surname>Guo</surname><given-names>W</given-names></name><name><surname>Kabra</surname><given-names>M</given-names></name><name><surname>Verma</surname><given-names>N</given-names></name><name><surname>Mensh</surname><given-names>B</given-names></name><name><surname>Branson</surname><given-names>K</given-names></name><name><surname>Hantman</surname><given-names>AW</given-names></name></person-group><article-title>Cortical pattern generation during dexterous movement is input-driven</article-title><source>Nature</source><year>2019</year><fpage>1</fpage><lpage>6</lpage><pub-id pub-id-type="pmcid">PMC6962553</pub-id><pub-id pub-id-type="pmid">31875851</pub-id><pub-id pub-id-type="doi">10.1038/s41586-019-1869-9</pub-id></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allen</surname><given-names>WE</given-names></name><name><surname>Chen</surname><given-names>MZ</given-names></name><name><surname>Pichamoorthy</surname><given-names>N</given-names></name><name><surname>Tien</surname><given-names>RH</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Luo</surname><given-names>L</given-names></name><name><surname>Deisseroth</surname><given-names>K</given-names></name></person-group><article-title>Thirst regulates motivated behavior through modulation of brainwide neural population dynamics</article-title><source>Sci New York N Y</source><year>2019</year><volume>364</volume><fpage>253</fpage><pub-id pub-id-type="pmcid">PMC6711472</pub-id><pub-id pub-id-type="pmid">30948440</pub-id><pub-id pub-id-type="doi">10.1126/science.aav3932</pub-id></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allen</surname><given-names>WE</given-names></name><name><surname>Kauvar</surname><given-names>IV</given-names></name><name><surname>Chen</surname><given-names>MZ</given-names></name><name><surname>Richman</surname><given-names>EB</given-names></name><name><surname>Yang</surname><given-names>SJ</given-names></name><name><surname>Chan</surname><given-names>K</given-names></name><name><surname>Gradinaru</surname><given-names>V</given-names></name><name><surname>Deverman</surname><given-names>BE</given-names></name><name><surname>Luo</surname><given-names>L</given-names></name><name><surname>Deisseroth</surname><given-names>K</given-names></name></person-group><article-title>Global Representations of Goal-Directed Behavior in Distinct Cell Types of Mouse Neocortex</article-title><source>Neuron</source><year>2017</year><volume>94</volume><fpage>891</fpage><lpage>907</lpage><elocation-id>e6</elocation-id><pub-id pub-id-type="pmcid">PMC5723385</pub-id><pub-id pub-id-type="pmid">28521139</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2017.04.017</pub-id></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Safaie</surname><given-names>M</given-names></name><name><surname>Chang</surname><given-names>JC</given-names></name><name><surname>Park</surname><given-names>J</given-names></name><name><surname>Miller</surname><given-names>LE</given-names></name><name><surname>Dudman</surname><given-names>JT</given-names></name><name><surname>Perich</surname><given-names>MG</given-names></name><name><surname>Gallego</surname><given-names>JA</given-names></name></person-group><article-title>Preserved neural dynamics across animals performing similar behaviour</article-title><source>Nature</source><year>2023</year><fpage>1</fpage><lpage>7</lpage><pub-id pub-id-type="pmcid">PMC10665198</pub-id><pub-id pub-id-type="pmid">37938772</pub-id><pub-id pub-id-type="doi">10.1038/s41586-023-06714-0</pub-id></element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khilkevich</surname><given-names>A</given-names></name><name><surname>Lohse</surname><given-names>M</given-names></name><name><surname>Low</surname><given-names>R</given-names></name><name><surname>Orsolic</surname><given-names>I</given-names></name><name><surname>Bozic</surname><given-names>T</given-names></name><name><surname>Windmill</surname><given-names>P</given-names></name><name><surname>Mrsic-Flogel</surname><given-names>TD</given-names></name></person-group><article-title>Brain-wide dynamics linking sensation to action during decision-making</article-title><source>Nature</source><year>2024</year><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="pmcid">PMC11499283</pub-id><pub-id pub-id-type="pmid">39261727</pub-id><pub-id pub-id-type="doi">10.1038/s41586-024-07908-w</pub-id></element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murakami</surname><given-names>M</given-names></name><name><surname>Vicente</surname><given-names>MI</given-names></name><name><surname>Costa</surname><given-names>GM</given-names></name><name><surname>Mainen</surname><given-names>ZF</given-names></name></person-group><article-title>Neural antecedents of selfinitiated actions in secondary motor cortex</article-title><source>Nat Neurosci</source><year>2014</year><volume>17</volume><fpage>1574</fpage><lpage>1582</lpage><pub-id pub-id-type="pmid">25262496</pub-id></element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cazettes</surname><given-names>F</given-names></name><name><surname>Mazzucato</surname><given-names>L</given-names></name><name><surname>Murakami</surname><given-names>M</given-names></name><name><surname>Morais</surname><given-names>JP</given-names></name><name><surname>Augusto</surname><given-names>E</given-names></name><name><surname>Renart</surname><given-names>A</given-names></name><name><surname>Mainen</surname><given-names>ZF</given-names></name></person-group><article-title>A reservoir of foraging decision variables in the mouse brain</article-title><source>Nat Neurosci</source><year>2023</year><volume>26</volume><fpage>840</fpage><lpage>849</lpage><pub-id pub-id-type="pmcid">PMC10280691</pub-id><pub-id pub-id-type="pmid">37055628</pub-id><pub-id pub-id-type="doi">10.1038/s41593-023-01305-8</pub-id></element-citation></ref><ref id="R40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kimmel</surname><given-names>DL</given-names></name><name><surname>Elsayed</surname><given-names>GF</given-names></name><name><surname>Cunningham</surname><given-names>JP</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><article-title>Value and choice as separable and stable representations in orbitofrontal cortex</article-title><source>Nat Commun</source><year>2020</year><volume>11</volume><elocation-id>3466</elocation-id><pub-id pub-id-type="pmcid">PMC7351792</pub-id><pub-id pub-id-type="pmid">32651373</pub-id><pub-id pub-id-type="doi">10.1038/s41467-020-17058-y</pub-id></element-citation></ref><ref id="R41"><label>41</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname><given-names>W</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Montague</surname><given-names>PR</given-names></name></person-group><article-title>A Neural Substrate of Prediction and Reward</article-title><source>Science</source><year>1997</year><volume>275</volume><fpage>1593</fpage><lpage>1599</lpage><pub-id pub-id-type="pmid">9054347</pub-id></element-citation></ref><ref id="R42"><label>42</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Komura</surname><given-names>Y</given-names></name><name><surname>Tamura</surname><given-names>R</given-names></name><name><surname>Uwano</surname><given-names>T</given-names></name><name><surname>Nishijo</surname><given-names>H</given-names></name><name><surname>Kaga</surname><given-names>K</given-names></name><name><surname>Ono</surname><given-names>T</given-names></name></person-group><article-title>Retrospective and prospective coding for predicted reward in the sensory thalamus</article-title><source>Nature</source><year>2001</year><volume>412</volume><fpage>546</fpage><lpage>549</lpage><pub-id pub-id-type="pmid">11484055</pub-id></element-citation></ref><ref id="R43"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shuler</surname><given-names>MG</given-names></name><name><surname>Bear</surname><given-names>MF</given-names></name></person-group><article-title>Reward Timing in the Primary Visual Cortex</article-title><source>Science</source><year>2006</year><volume>311</volume><fpage>1606</fpage><lpage>1609</lpage><pub-id pub-id-type="pmid">16543459</pub-id></element-citation></ref><ref id="R44"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Young</surname><given-names>ME</given-names></name><name><surname>Spencer-Salmon</surname><given-names>C</given-names></name><name><surname>Mosher</surname><given-names>C</given-names></name><name><surname>Tamang</surname><given-names>S</given-names></name><name><surname>Rajan</surname><given-names>K</given-names></name><name><surname>Rudebeck</surname><given-names>PH</given-names></name></person-group><article-title>Temporally specific patterns of neural activity in interconnected corticolimbic structures during reward anticipation</article-title><source>Neuron</source><year>2023</year><volume>111</volume><fpage>3668</fpage><lpage>3682</lpage><elocation-id>e5</elocation-id><pub-id pub-id-type="pmcid">PMC10840822</pub-id><pub-id pub-id-type="pmid">37586366</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2023.07.012</pub-id></element-citation></ref><ref id="R45"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kostadinov</surname><given-names>D</given-names></name><name><surname>Beau</surname><given-names>M</given-names></name><name><surname>Pozo</surname><given-names>MB</given-names></name><name><surname>Hausser</surname><given-names>M</given-names></name></person-group><article-title>Predictive and reactive reward signals conveyed by climbing fiber inputs to cerebellar Purkinje cells</article-title><source>Nat Neurosci</source><year>2019</year><volume>22</volume><fpage>950</fpage><lpage>962</lpage><pub-id pub-id-type="pmcid">PMC7612392</pub-id><pub-id pub-id-type="pmid">31036947</pub-id><pub-id pub-id-type="doi">10.1038/s41593-019-0381-8</pub-id></element-citation></ref><ref id="R46"><label>46</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levy</surname><given-names>S</given-names></name><name><surname>Lavzin</surname><given-names>M</given-names></name><name><surname>Benisty</surname><given-names>H</given-names></name><name><surname>Ghanayim</surname><given-names>A</given-names></name><name><surname>Dubin</surname><given-names>U</given-names></name><name><surname>Achvat</surname><given-names>S</given-names></name><name><surname>Brosh</surname><given-names>Z</given-names></name><name><surname>Aeed</surname><given-names>F</given-names></name><name><surname>Mensh</surname><given-names>BD</given-names></name><name><surname>Schiller</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Cell-Type-Specific Outcome Representation in the Primary Motor Cortex</article-title><source>Neuron</source><year>2020</year><volume>107</volume><fpage>954</fpage><lpage>971</lpage><elocation-id>e9</elocation-id><pub-id pub-id-type="pmid">32589878</pub-id></element-citation></ref><ref id="R47"><label>47</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsao</surname><given-names>A</given-names></name><name><surname>Yousefzadeh</surname><given-names>SA</given-names></name><name><surname>Meck</surname><given-names>WH</given-names></name><name><surname>Moser</surname><given-names>M-B</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><article-title>The neural bases for timing of durations</article-title><source>Nat Rev Neurosci</source><year>2022</year><volume>23</volume><fpage>646</fpage><lpage>665</lpage><pub-id pub-id-type="pmid">36097049</pub-id></element-citation></ref><ref id="R48"><label>48</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mello</surname><given-names>GBM</given-names></name><name><surname>Soares</surname><given-names>S</given-names></name><name><surname>Paton</surname><given-names>JJ</given-names></name></person-group><article-title>A Scalable Population Code for Time in the Striatum</article-title><source>Curr Biol</source><year>2015</year><volume>25</volume><fpage>1113</fpage><lpage>1122</lpage><pub-id pub-id-type="pmid">25913405</pub-id></element-citation></ref><ref id="R49"><label>49</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sohn</surname><given-names>H</given-names></name><name><surname>Narain</surname><given-names>D</given-names></name><name><surname>Meirhaeghe</surname><given-names>N</given-names></name><name><surname>Jazayeri</surname><given-names>M</given-names></name></person-group><article-title>Bayesian Computation through Cortical Latent Dynamics</article-title><source>Neuron</source><year>2019</year><volume>103</volume><fpage>934</fpage><lpage>947</lpage><elocation-id>e5</elocation-id><pub-id pub-id-type="pmcid">PMC6805134</pub-id><pub-id pub-id-type="pmid">31320220</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2019.06.012</pub-id></element-citation></ref><ref id="R50"><label>50</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nyberg</surname><given-names>N</given-names></name><name><surname>Duvelle</surname><given-names>É</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Spiers</surname><given-names>HJ</given-names></name></person-group><article-title>Spatial goal coding in the hippocampal formation</article-title><source>Neuron</source><year>2022</year><volume>110</volume><fpage>394</fpage><lpage>422</lpage><pub-id pub-id-type="pmid">35032426</pub-id></element-citation></ref><ref id="R51"><label>51</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sarel</surname><given-names>A</given-names></name><name><surname>Finkelstein</surname><given-names>A</given-names></name><name><surname>Las</surname><given-names>L</given-names></name><name><surname>Ulanovsky</surname><given-names>N</given-names></name></person-group><article-title>Vectorial representation of spatial goals in the hippocampus of bats</article-title><source>Science</source><year>2017</year><volume>355</volume><fpage>176</fpage><lpage>180</lpage><pub-id pub-id-type="pmid">28082589</pub-id></element-citation></ref><ref id="R52"><label>52</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boccara</surname><given-names>CN</given-names></name><name><surname>Nardin</surname><given-names>M</given-names></name><name><surname>Stella</surname><given-names>F</given-names></name><name><surname>O’Neill</surname><given-names>J</given-names></name><name><surname>Csicsvari</surname><given-names>J</given-names></name></person-group><article-title>The entorhinal cognitive map is attracted to goals</article-title><source>Science</source><year>2019</year><volume>363</volume><fpage>1443</fpage><lpage>1447</lpage><pub-id pub-id-type="pmid">30923221</pub-id></element-citation></ref><ref id="R53"><label>53</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moser</surname><given-names>EI</given-names></name><name><surname>Moser</surname><given-names>M-B</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><article-title>Spatial representation in the hippocampal formation: a history</article-title><source>Nat Neurosci</source><year>2017</year><volume>20</volume><fpage>1448</fpage><lpage>1464</lpage><pub-id pub-id-type="pmid">29073644</pub-id></element-citation></ref><ref id="R54"><label>54</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stachenfeld</surname><given-names>KL</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name></person-group><article-title>The hippocampus as a predictive map</article-title><source>Nat Neurosci</source><year>2017</year><volume>20</volume><fpage>1643</fpage><lpage>1653</lpage><pub-id pub-id-type="pmid">28967910</pub-id></element-citation></ref><ref id="R55"><label>55</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zagha</surname><given-names>E</given-names></name><name><surname>Erlich</surname><given-names>JC</given-names></name><name><surname>Lee</surname><given-names>S</given-names></name><name><surname>Lur</surname><given-names>G</given-names></name><name><surname>O’Connor</surname><given-names>DH</given-names></name><name><surname>Steinmetz</surname><given-names>NA</given-names></name><name><surname>Stringer</surname><given-names>C</given-names></name><name><surname>Yang</surname><given-names>H</given-names></name></person-group><article-title>The Importance of Accounting for Movement When Relating Neuronal Activity to Sensory and Cognitive Processes</article-title><source>J Neurosci</source><year>2022</year><volume>42</volume><fpage>1375</fpage><lpage>1382</lpage><pub-id pub-id-type="pmcid">PMC8883841</pub-id><pub-id pub-id-type="pmid">35027407</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1919-21.2021</pub-id></element-citation></ref><ref id="R56"><label>56</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>KD</given-names></name><name><surname>Thiele</surname><given-names>A</given-names></name></person-group><article-title>Cortical state and attention</article-title><source>Nat Rev Neurosci</source><year>2011</year><volume>12</volume><fpage>509</fpage><lpage>523</lpage><pub-id pub-id-type="pmcid">PMC3324821</pub-id><pub-id pub-id-type="pmid">21829219</pub-id><pub-id pub-id-type="doi">10.1038/nrn3084</pub-id></element-citation></ref><ref id="R57"><label>57</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schaffer</surname><given-names>ES</given-names></name><name><surname>Mishra</surname><given-names>N</given-names></name><name><surname>Whiteway</surname><given-names>MR</given-names></name><name><surname>Li</surname><given-names>W</given-names></name><name><surname>Vancura</surname><given-names>MB</given-names></name><name><surname>Freedman</surname><given-names>J</given-names></name><name><surname>Patel</surname><given-names>KB</given-names></name><name><surname>Voleti</surname><given-names>V</given-names></name><name><surname>Paninski</surname><given-names>L</given-names></name><name><surname>Hillman</surname><given-names>EMC</given-names></name><etal/></person-group><article-title>The spatial and temporal structure of neural activity across the fly brain</article-title><source>Nat Commun</source><year>2023</year><volume>14</volume><elocation-id>5572</elocation-id><pub-id pub-id-type="pmcid">PMC10495430</pub-id><pub-id pub-id-type="pmid">37696814</pub-id><pub-id pub-id-type="doi">10.1038/s41467-023-41261-2</pub-id></element-citation></ref><ref id="R58"><label>58</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flavell</surname><given-names>SW</given-names></name><name><surname>Gogolla</surname><given-names>N</given-names></name><name><surname>Lovett-Barron</surname><given-names>M</given-names></name><name><surname>Zelikowsky</surname><given-names>M</given-names></name></person-group><article-title>The emergence and influence of internal states</article-title><source>Neuron</source><year>2022</year><volume>110</volume><fpage>2545</fpage><lpage>2570</lpage><pub-id pub-id-type="pmcid">PMC9391310</pub-id><pub-id pub-id-type="pmid">35643077</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2022.04.030</pub-id></element-citation></ref><ref id="R59"><label>59</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>MacDowell</surname><given-names>CJ</given-names></name><name><surname>Libby</surname><given-names>A</given-names></name><name><surname>Jahn</surname><given-names>CI</given-names></name><name><surname>Tafazoli</surname><given-names>S</given-names></name><name><surname>Buschman</surname><given-names>TJ</given-names></name></person-group><article-title>Multiplexed Subspaces Route Neural Activity Across Brain-wide Networks</article-title><year>2023</year><pub-id pub-id-type="doi">10.1101/2023.02.08.527772</pub-id></element-citation></ref><ref id="R60"><label>60</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markowitz</surname><given-names>JE</given-names></name><name><surname>Gillis</surname><given-names>WF</given-names></name><name><surname>Jay</surname><given-names>M</given-names></name><name><surname>Wood</surname><given-names>J</given-names></name><name><surname>Harris</surname><given-names>RW</given-names></name><name><surname>Cieszkowski</surname><given-names>R</given-names></name><name><surname>Scott</surname><given-names>R</given-names></name><name><surname>Brann</surname><given-names>D</given-names></name><name><surname>Koveal</surname><given-names>D</given-names></name><name><surname>Kula</surname><given-names>T</given-names></name><etal/></person-group><article-title>Spontaneous behaviour is structured by reinforcement without explicit reward</article-title><source>Nature</source><year>2023</year><volume>614</volume><fpage>108</fpage><lpage>117</lpage><pub-id pub-id-type="pmcid">PMC9892006</pub-id><pub-id pub-id-type="pmid">36653449</pub-id><pub-id pub-id-type="doi">10.1038/s41586-022-05611-2</pub-id></element-citation></ref><ref id="R61"><label>61</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oryshchuk</surname><given-names>A</given-names></name><name><surname>Sourmpis</surname><given-names>C</given-names></name><name><surname>Weverbergh</surname><given-names>J</given-names></name><name><surname>Asri</surname><given-names>R</given-names></name><name><surname>Esmaeili</surname><given-names>V</given-names></name><name><surname>Modirshanechi</surname><given-names>A</given-names></name><name><surname>Gerstner</surname><given-names>W</given-names></name><name><surname>Petersen</surname><given-names>CCH</given-names></name><name><surname>Crochet</surname><given-names>S</given-names></name></person-group><article-title>Distributed and specific encoding of sensory, motor, and decision information in the mouse neocortex during goal-directed behavior</article-title><source>Cell Rep</source><year>2024</year><volume>43</volume><elocation-id>113618</elocation-id><pub-id pub-id-type="pmid">38150365</pub-id></element-citation></ref><ref id="R62"><label>62</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mayrhofer</surname><given-names>JM</given-names></name><name><surname>El-Boustani</surname><given-names>S</given-names></name><name><surname>Foustoukos</surname><given-names>G</given-names></name><name><surname>Auffret</surname><given-names>M</given-names></name><name><surname>Tamura</surname><given-names>K</given-names></name><name><surname>Petersen</surname><given-names>CCH</given-names></name></person-group><article-title>Distinct Contributions of Whisker Sensory Cortex and Tongue-Jaw Motor Cortex in a Goal-Directed Sensorimotor Transformation</article-title><source>Neuron</source><year>2019</year><volume>103</volume><fpage>1034</fpage><lpage>1043</lpage><elocation-id>e5</elocation-id><pub-id pub-id-type="pmcid">PMC6859494</pub-id><pub-id pub-id-type="pmid">31402199</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2019.07.008</pub-id></element-citation></ref><ref id="R63"><label>63</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doll</surname><given-names>BB</given-names></name><name><surname>Simon</surname><given-names>DA</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name></person-group><article-title>The ubiquity of model-based reinforcement learning</article-title><source>Curr Opin Neurobiol</source><year>2012</year><volume>22</volume><fpage>1075</fpage><lpage>1081</lpage><pub-id pub-id-type="pmcid">PMC3513648</pub-id><pub-id pub-id-type="pmid">22959354</pub-id><pub-id pub-id-type="doi">10.1016/j.conb.2012.08.003</pub-id></element-citation></ref><ref id="R64"><label>64</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><article-title>Goals and Habits in the Brain</article-title><source>Neuron</source><year>2013</year><volume>80</volume><fpage>312</fpage><lpage>325</lpage><pub-id pub-id-type="pmcid">PMC3807793</pub-id><pub-id pub-id-type="pmid">24139036</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2013.09.007</pub-id></element-citation></ref><ref id="R65"><label>65</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name><name><surname>Kiebel</surname><given-names>S</given-names></name></person-group><article-title>Predictive coding under the free-energy principle</article-title><source>Philos Trans R Soc B: Biol Sci</source><year>2009</year><volume>364</volume><fpage>1211</fpage><lpage>1221</lpage><pub-id pub-id-type="pmcid">PMC2666703</pub-id><pub-id pub-id-type="pmid">19528002</pub-id><pub-id pub-id-type="doi">10.1098/rstb.2008.0300</pub-id></element-citation></ref><ref id="R66"><label>66</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barack</surname><given-names>DL</given-names></name><name><surname>Krakauer</surname><given-names>JW</given-names></name></person-group><article-title>Two views on the cognitive brain</article-title><source>Nat Rev Neurosci</source><year>2021</year><volume>22</volume><fpage>359</fpage><lpage>371</lpage><pub-id pub-id-type="pmid">33859408</pub-id></element-citation></ref><ref id="R67"><label>67</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laboratory</surname><given-names>TIB</given-names></name><name><surname>Aguillon-Rodriguez</surname><given-names>V</given-names></name><name><surname>Angelaki</surname><given-names>D</given-names></name><name><surname>Bayer</surname><given-names>H</given-names></name><name><surname>Bonacchi</surname><given-names>N</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Cazettes</surname><given-names>F</given-names></name><name><surname>Chapuis</surname><given-names>G</given-names></name><name><surname>Churchland</surname><given-names>AK</given-names></name><name><surname>Dan</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Standardized and reproducible measurement of decision-making in mice</article-title><source>eLife</source><year>2021</year><volume>10</volume><elocation-id>e63711</elocation-id><pub-id pub-id-type="pmcid">PMC8137147</pub-id><pub-id pub-id-type="pmid">34011433</pub-id><pub-id pub-id-type="doi">10.7554/eLife.63711</pub-id></element-citation></ref><ref id="R68"><label>68</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jun</surname><given-names>JJ</given-names></name><name><surname>Steinmetz</surname><given-names>NA</given-names></name><name><surname>Siegle</surname><given-names>JH</given-names></name><name><surname>Denman</surname><given-names>DJ</given-names></name><name><surname>Bauza</surname><given-names>M</given-names></name><name><surname>Barbarits</surname><given-names>B</given-names></name><name><surname>Lee</surname><given-names>AK</given-names></name><name><surname>Anastassiou</surname><given-names>CA</given-names></name><name><surname>Andrei</surname><given-names>A</given-names></name><name><surname>Aydin</surname><given-names>Ç</given-names></name><etal/></person-group><article-title>Fully integrated silicon probes for high-density recording of neural activity</article-title><source>Nature</source><year>2017</year><volume>551</volume><fpage>232</fpage><pub-id pub-id-type="pmcid">PMC5955206</pub-id><pub-id pub-id-type="pmid">29120427</pub-id><pub-id pub-id-type="doi">10.1038/nature24636</pub-id></element-citation></ref><ref id="R69"><label>69</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shamash</surname><given-names>P</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>K</given-names></name><name><surname>Steinmetz</surname><given-names>N</given-names></name></person-group><article-title>A tool for analyzing electrode tracks from slice histology</article-title><source>bioRxiv</source><year>2018</year><elocation-id>447995</elocation-id><pub-id pub-id-type="doi">10.1101/447995</pub-id></element-citation></ref><ref id="R70"><label>70</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>LD</given-names></name><name><surname>Chen</surname><given-names>S</given-names></name><name><surname>Hou</surname><given-names>H</given-names></name><name><surname>West</surname><given-names>SJ</given-names></name><name><surname>Faulkner</surname><given-names>M</given-names></name><name><surname>Laboratory</surname><given-names>IB</given-names></name><name><surname>Economo</surname><given-names>MN</given-names></name><name><surname>Li</surname><given-names>N</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name></person-group><article-title>Accurate Localization of Linear Probe Electrode Arrays across Multiple Brains</article-title><source>eNeuro</source><year>2021</year><volume>8</volume><elocation-id>ENEURO.0241-21.2021</elocation-id><pub-id pub-id-type="pmcid">PMC8597948</pub-id><pub-id pub-id-type="pmid">34697075</pub-id><pub-id pub-id-type="doi">10.1523/ENEURO.0241-21.2021</pub-id></element-citation></ref><ref id="R71"><label>71</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Sridhar</surname><given-names>S</given-names></name><name><surname>Stringer</surname><given-names>C</given-names></name></person-group><article-title>Solving the spike sorting problem with Kilosort</article-title><source>bioRxiv</source><year>2023</year><elocation-id>2023.01.07.523036</elocation-id><pub-id pub-id-type="doi">10.1101/2023.01.07.523036</pub-id></element-citation></ref><ref id="R72"><label>72</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petersen</surname><given-names>PC</given-names></name><name><surname>Siegle</surname><given-names>JH</given-names></name><name><surname>Steinmetz</surname><given-names>NA</given-names></name><name><surname>Mahallati</surname><given-names>S</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><article-title>CellExplorer: A framework for visualizing and characterizing single neurons</article-title><source>Neuron</source><year>2021</year><volume>109</volume><fpage>3594</fpage><lpage>3608</lpage><elocation-id>e2</elocation-id><pub-id pub-id-type="pmcid">PMC8602784</pub-id><pub-id pub-id-type="pmid">34592168</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2021.09.002</pub-id></element-citation></ref><ref id="R73"><label>73</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holt</surname><given-names>GR</given-names></name><name><surname>Softky</surname><given-names>WR</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Douglas</surname><given-names>RJ</given-names></name></person-group><article-title>Comparison of discharge variability in vitro and in vivo in cat visual cortex neurons</article-title><source>J Neurophysiol</source><year>1996</year><volume>75</volume><fpage>1806</fpage><lpage>1814</lpage><pub-id pub-id-type="pmid">8734581</pub-id></element-citation></ref><ref id="R74"><label>74</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Trautmann</surname><given-names>EM</given-names></name><name><surname>Stavisky</surname><given-names>SD</given-names></name><name><surname>Lahiri</surname><given-names>S</given-names></name><name><surname>Ames</surname><given-names>KC</given-names></name><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>O’Shea</surname><given-names>DJ</given-names></name><name><surname>Vyas</surname><given-names>S</given-names></name><name><surname>Sun</surname><given-names>X</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name><etal/></person-group><article-title>Accurate Estimation of Neural Population Dynamics without Spike Sorting</article-title><source>Neuron</source><year>2019</year><volume>103</volume><fpage>292</fpage><lpage>308</lpage><elocation-id>e4</elocation-id><pub-id pub-id-type="pmcid">PMC7002296</pub-id><pub-id pub-id-type="pmid">31171448</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2019.05.003</pub-id></element-citation></ref><ref id="R75"><label>75</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>JMJF</given-names></name><name><surname>van B</surname><given-names>EH</given-names></name><name><surname>P</surname><given-names>AJ</given-names></name><name><surname>C</surname><given-names>M</given-names></name><name><surname>D</surname><given-names>K</given-names></name></person-group><article-title>Bombcell: automated curation and cell classification of spike-sorted electrophysiology data</article-title><year>2023</year><pub-id pub-id-type="doi">10.5281/zenodo.8172822</pub-id></element-citation></ref><ref id="R76"><label>76</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nath</surname><given-names>T</given-names></name><name><surname>Mathis</surname><given-names>A</given-names></name><name><surname>Chen</surname><given-names>AC</given-names></name><name><surname>Patel</surname><given-names>A</given-names></name><name><surname>Bethge</surname><given-names>M</given-names></name><name><surname>Mathis</surname><given-names>MW</given-names></name></person-group><article-title>Using DeepLabCut for 3D markerless pose estimation across species and behaviors</article-title><source>Nat Protoc</source><year>2019</year><volume>14</volume><fpage>2152</fpage><lpage>2176</lpage><pub-id pub-id-type="pmid">31227823</pub-id></element-citation></ref><ref id="R77"><label>77</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morel</surname><given-names>P</given-names></name></person-group><article-title>Gramm: grammar of graphics plotting in Matlab</article-title><source>J Open Source Softw</source><year>2018</year><volume>3</volume><fpage>568</fpage><pub-id pub-id-type="doi">10.21105/joss.00568</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>Heterogeneous modulation of neuron activity across regions during reaching.</title><p><bold>(a)</bold> Schematic of head-fixed recording setup and water reaching task. Cue and droplet are presented after 3-6 s holding period, red shaded area illustrates reaction time until reach onset (bar release) and reach duration until spout touch. Automated pose estimation of forelimb joints obtained through DeepLabCut. <bold>(b)</bold> Front and side video allowed projection of joint position into 3D space. Black trajectories represent movement of left digit II from the side view and top view during one session. White dot and line represent rest bar. Orange dot shows spout position, blue dot indicates location of reward consumption. <bold>(c)</bold> Schematic of sagittal brain atlas showing recorded region categories in colour. Abbreviation in parentheses indicate included subregions according to Allen Mouse Common Coordinate Framework. Black lines represent Neuropixels trajectories from different sessions approximating positions of active electrodes. <bold>(d)</bold> Peri-spike timing histogram (PSTH) shows trial-averaged and range-normalized firing rate of 37,567 neurons (rows) from all recording sessions, aligned to time of cue and sorted by brain regions and product of modulation index and significance level. Shaded red interval indicates 500 ms window used to compute modulation index. <bold>(e)</bold> Volcano plot shows cue modulation index (log) and significance level (-log10) for each recorded neuron, color-coded by its brain region. Grey neurons are not significant after Bonferroni correction (p &gt; 1.3 x 10<sup>-06</sup>). Circled dots indicate example neurons from each region with spike rasters shown on the right (matching colours). <bold>(f)</bold> Spike rasters show spiking activity (dots) across all cued reach trials (rows) from individual neurons, aligned to time of cue (dashed vertical line). Vertical scale bar: 100 trials, horizontal scale bar: 1 s. <bold>(g)</bold> Scatter plot shows fraction of significantly positively modulated (index &gt; 1) and negatively modulated (index &lt; 1) neurons in each region (colour). Each transparent dot indicates an individual recording session, circled dots represent mean and standard error of mean across sessions per region. Bar graph on right shows pooled number of neurons recorded in each region, subdivided into their activity change upon cue.</p></caption><graphic xlink:href="EMS199918-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Consistent reach-related latent dynamics across sessions, animals, and regions.</title><p><bold>(a)</bold> PC1 and PC2 dynamics of sessions (grey lines) and animal-wise average (black line) for different animals (rows). The rightmost column shows state-space trajectories of individual sessions (grey) and of the animal-wise average (black). The bottom row shows mean dynamics of each animal (black lines), shade represents bootstrapped 95% confidence interval (CI). <bold>(b)</bold> Box plots show correlation coefficients within (grey/black) and across dimensions (blue), stratified by comparisons within (black) or across animals (gray). <bold>(c)</bold> PSTH shows z-scored firing rate of pooled neurons (rows) from all sessions, sorted by PC1 coefficient and brain region). <bold>(d)</bold> Scatter plots of PC1 and PC2 coefficients for cortical (top), thalamic (middle), and other regions (bottom). Each transparent dot represents a neuron, colour coded by its brain region (see panel c). Vertical and horizontal curves indicate superimposed density distributions. <bold>(e)</bold> Region-specific expression of PC1 dynamic, individual lines represent different sessions, colors correspond to region annotation in panel c. Black line represents mean. Vertical line indicates time of reach onset. <bold>(f)</bold> Box plots show the correlation coefficient calculated from the PC1 coefficient of PCA, either from all neurons or from neurons in a specific brain region (x-axis and color code). Each data point represents a single recording session.</p></caption><graphic xlink:href="EMS199918-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Modulation of latent dynamic by cue, movement, and reward.</title><p><bold>(a)</bold> Side view of movement trajectories of left digit II from example session at 1:1 scale. Holding bar is located at bottom left, droplet position is at top right. Colors indicate different movement types, lightness categorizes maximum reach distance within 500 ms. <bold>(b)</bold> Top row: Movement position in anterior-posterior axis (AP distance) in different movement types (color) from a single session, aligned to time of movement onset. Light thin lines represent individual trials, dark thick lines represent means for different reach distances (lightness). Bottom row: PC1 activity is shown for individual trials (thin lines) and group means (thick lines). PC1 activity has been normalized to the peak of PC1 activity in cued long reaches (dark blue). Note the separation and differences between movement types and reach distances already on the single neuron level. <bold>(c)</bold> Same visualization as in (b) for session means. Each thin line represents the session average across all trials of a movement type. The thick lines represent the mean across all sessions. PC1 activity has been normalized to the peak amplitude of long cued reaches within each session. Data with less than five trials of a reach type in a session were excluded. <bold>(d)</bold> Dots represent mean AP position peak (within first 500 ms) and PC1 peak for each movement type and session. Thick line represents mean across sessions, shaded error represents bootstrapped 95% confidence interval. Rightmost column represents overlaid session means, showing identical reach distances across reach types, but significantly different PC1 peak amplitudes across reach types and distances. Grooming is represented as a grey line. Asterisks indicates significant contributions of reach distance, reward presence, and cue in linear mixed effect model at p &lt; 0.05).</p></caption><graphic xlink:href="EMS199918-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Dominant latent dynamic represents time-varying action-mediated goal prediction.</title><p><bold>(a)</bold> Single trial data of forepaw position (grey) and global PC1 activity (orange). Vertical lines represent times behavioral events. <bold>(b)</bold> Line plots show AP position (top row) and PC1 activity (bottom row) from example session aligned to different events (columns). Gray lines depict individual trials. The coloured thick lines correspond to the average of trials within quartile bins, that are determined by the duration between cue and reward (drop consumption). <bold>(c)</bold> Scatter plot shows cue-reward delay and cue-PC1 peak delay of single trials (dots, n = 131) for example session. Red line represents linear fit and correlation coefficient r and p-value were calculated by Pearson correlation. <bold>(d)</bold> Movement trajectories of left digit II in AP-ML horizontal plane from same session. Heatmap represents trial-averaged PC1 activity (z-scored) across 0.5 x 0.5 mm spatial bins. Red dot indicates location of maximum PC1 activity. Note the proximity to the posteromedial quadrant of circular trajectories corresponding to mouth location whereas the spout is located at the anterolateral quadrant. <bold>(e)</bold> Line plots show the mean PC1 activity across all sessions aligned to different events (columns). Different quartile bins (colors) aggregate trials based on the within-session distribution of cue-reward delay. <bold>(f)</bold> Scatter plot shows correlation between cue-reward times and cue-PC1 peak times (red fit line and coefficients were calculated using Pearson’s correlation based on all cued trials, n = 5821). Each dot represents one trial, color code represents time delay between cue and reward. Black lines represent linear fits of individual sessions. <bold>(g)</bold> Mean movement trajectories of sessions for the reach period aligned to end position (time before re-approach). Black dots represent session-wise peaks in spatially mapped PC1 activity. <bold>(h)</bold> Single session example: Top row shows movement trajectories of reaches and re-reaches. Leftmost column shows first reach of each trial; subsequent columns show re-reaches sorted by sequence within each trial. Re-reaches with reward (blue) or without reward (yellow) showed similar movement trajectories. Bottom row shows single trial PC1 activity aligned to re-reach onset, color coded by reward presence. <bold>(i)</bold> Line plots show mean AP distance peak (top) and mean PC1 peak (bottom) for each session (thin lines), across sequential re-reach indices (x-axis) and different reward conditions (colour), at least 10 re-reaches per condition and session. In panels (e, h, i), thick lines represent mean and shaded areas represent bootstrapped 95%-confidence interval.</p></caption><graphic xlink:href="EMS199918-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>Distributed goal representation with region-specific modulation and temporal hierarchy.</title><p><bold>(a)</bold> Lines show across-session means of PC1 peak amplitude for different reach types (colour) and reach distances (x-axis) in different brain regions (rows, columns). <bold>(b)</bold> Heatmap matrix represents coefficients of predictors (distance, reward, cue) that were calculated in global or region-specific LME models to fit the normalized PC1 p ea<bold>k</bold> amplitude (see <xref ref-type="sec" rid="S5">methods</xref>). Numbers represents coefficients that were statistically significant at p &lt; 0.05. <bold>(c)</bold> Top row shows mean local PC1 activity of cued reaches across sessions for different regions (columns), aligned to time of reward. Trials are aggregated based on within-session quartile of cue-reward delay (lightness). Thick lines represent across-session and within-quartile means; shaded errors represent 95% confidence interval. Bottom scatter plots show the time of local PC1 peak relative to time of reward after the cue. Each dot represents the mean of a cue-reward quartile (lightness) from each session. Fit lines and p-values are derived from an LME model with session-level random intercepts.</p></caption><graphic xlink:href="EMS199918-f005"/></fig></floats-group></article>