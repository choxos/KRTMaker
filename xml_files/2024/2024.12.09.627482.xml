<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS201969</article-id><article-id pub-id-type="doi">10.1101/2024.12.09.627482</article-id><article-id pub-id-type="archive">PPR953335</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">1</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>GEMS: A Generalizable GNN Framework For Protein-Ligand Binding Affinity Prediction Through Robust Data Filtering and Language Model Integration</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Graber</surname><given-names>David</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Stockinger</surname><given-names>Peter</given-names></name><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Meyer</surname><given-names>Fabian</given-names></name><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Mishra</surname><given-names>Siddhartha</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><contrib contrib-type="author"><name><surname>Horn</surname><given-names>Claus</given-names></name><xref ref-type="aff" rid="A4">4</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><contrib contrib-type="author"><name><surname>Buller</surname><given-names>Rebecca</given-names></name><xref ref-type="aff" rid="A2">2</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib></contrib-group><aff id="A1"><label>1</label>Seminar for Applied Mathematics, Department of Mathematics and ETH AI Center, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/05a28rw58</institution-id><institution>ETH Zurich</institution></institution-wrap>, <postal-code>8092</postal-code><city>Zurich</city>, <country country="CH">Switzerland</country></aff><aff id="A2"><label>2</label>Competence Center for Biocatalysis, Zurich University of Applied Sciences, 8820 Waedenswil, Switzerland</aff><aff id="A3"><label>3</label>Institute for Computational Life Sciences, Zurich University of Applied Sciences, 8820 Waedenswil, Switzerland</aff><aff id="A4"><label>4</label>School of Medicine, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/03v76x132</institution-id><institution>Yale University</institution></institution-wrap>, <city>New Haven, CT</city><postal-code>06510</postal-code>, <country country="US">USA</country></aff><author-notes><corresp id="CR1">
<label>*</label>corresponding authors, shared senior authorship</corresp></author-notes><pub-date pub-type="nihms-submitted"><day>18</day><month>12</month><year>2024</year></pub-date><pub-date pub-type="preprint"><day>11</day><month>12</month><year>2024</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nd/4.0/">CC BY-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">The field of computational drug design requires accurate scoring functions to predict binding affinities for protein-ligand interactions. However, train-test data leakage between the PDBbind database and the CASF benchmark datasets has significantly inflated the performance metrics of currently available deep-learning-based binding affinity prediction models, leading to overestimation of their generalization capabilities. We address this issue by proposing PDBbind CleanSplit, a training dataset curated by a novel structure-based filtering algorithm that eliminates train-test data leakage as well as redundancies within the training set. Retraining the current best-performing model on CleanSplit caused its benchmark performance to drop to uncompetitive levels, indicating that the performance of existing models is largely driven by data leakage. In contrast, our graph neural network model for efficient molecular scoring (GEMS) maintains high benchmark performance when trained on CleanSplit. Leveraging a sparse graph modeling of protein-ligand interactions and transfer learning from language models, GEMS is able to generalize to strictly independent test datasets.</p></abstract><kwd-group><kwd>Binding Affinity Prediction</kwd><kwd>Protein-Ligand Scoring</kwd><kwd>Scoring Functions</kwd><kwd>Data Leakage</kwd><kwd>Structure-Based Drug Design</kwd><kwd>Graph Neural Networks</kwd><kwd>Transfer Learning</kwd><kwd>Computational Drug Discovery</kwd><kwd>Protein Language Model</kwd><kwd>Large Language Model</kwd></kwd-group></article-meta></front><body><p id="P2">Structure-based drug design (SBDD) aims to design small-molecule drugs that bind with high affinity to specific protein targets. In recent years, computational methods and deep neural networks have begun to revolutionize the field, offering new possibilities for computational drug design. These include molecular docking algorithms that allow to fit drug candidates into the binding sites of target proteins, outputting potential binding poses [<xref ref-type="bibr" rid="R1">1</xref>, <xref ref-type="bibr" rid="R2">2</xref>]. New protein folding models like RoseTTAFold All-Atom [<xref ref-type="bibr" rid="R3">3</xref>] and AlphaFold3 [<xref ref-type="bibr" rid="R4">4</xref>] can also consider small-molecule ligands to predict potential binding conformations. Furthermore, generative artificial intelligence can design entirely novel protein-ligand interactions. For instance, RFdiffusion [<xref ref-type="bibr" rid="R5">5</xref>] can construct proteins around small-molecules starting from random clouds of amino acids while the denoising diffusion model DiffSBDD [<xref ref-type="bibr" rid="R6">6</xref>] generates novel ligands tailored to fit specific protein pockets. While these methods excel at generating diverse collections of protein-ligand interactions, these interactions are not necessarily characterized by drug-like affinity. Therefore, using these models for development of small-molecule drugs requires <italic>scoring functions</italic> that can accurately predict binding affinities for protein-ligand poses and identify high-affinity complexes. Classical scoring functions, such as force-field-based, empirical, and knowledge-based methods implemented in docking tools like AutoDock Vina [<xref ref-type="bibr" rid="R1">1</xref>] and GOLD [<xref ref-type="bibr" rid="R2">2</xref>] are computationally intensive and show limited accuracy in binding affinity prediction [<xref ref-type="bibr" rid="R7">7</xref>–<xref ref-type="bibr" rid="R10">10</xref>]. Despite notable advancements in deep-learning-based scoring functions, including the design of many 3D convolutional [<xref ref-type="bibr" rid="R11">11</xref>–<xref ref-type="bibr" rid="R17">17</xref>] and graph neural networks [<xref ref-type="bibr" rid="R18">18</xref>–<xref ref-type="bibr" rid="R22">22</xref>], accurately predicting binding affinities for protein-ligand poses remains an outstanding challenge.</p><p id="P3">In addition to the fact that many deep-learning-based scoring functions are either not publicly available or are difficult to implement, the key reason for their limited applicability currently is the observation that these scoring functions perform poorly, with considerably lower than expected accuracy on independent test data sets [<xref ref-type="bibr" rid="R23">23</xref>–<xref ref-type="bibr" rid="R26">26</xref>]. This large gap between benchmark and real-world performance has been attributed to the underlying training and evaluation procedures used for the design of these scoring functions. Typically, these models are trained on the PDBbind database [<xref ref-type="bibr" rid="R27">27</xref>], and their generalization is assessed using the Critical Assessment of Scoring Function (CASF) benchmark datasets [<xref ref-type="bibr" rid="R9">9</xref>]. However, several studies have reported a high degree of similarity between PDBbind and the CASF benchmarks. Due to this similarity, the performance on CASF overestimates the generalization capability of models trained on PDBbind [<xref ref-type="bibr" rid="R9">9</xref>, <xref ref-type="bibr" rid="R28">28</xref>, <xref ref-type="bibr" rid="R29">29</xref>]. Alarmingly, some of these models even perform comparably well on the CASF datasets after omitting all protein or ligand information from their input data. This suggests that the reported impressive performance of these models on the CASF benchmarks are not based on an understanding of protein-ligand interactions. Instead, memorization and exploitation of structural similarities between training and test complexes appear to be the main factors driving the observed benchmark performance of these models [<xref ref-type="bibr" rid="R25">25</xref>, <xref ref-type="bibr" rid="R26">26</xref>, <xref ref-type="bibr" rid="R30">30</xref>–<xref ref-type="bibr" rid="R32">32</xref>].</p><p id="P4">Our first goal in this paper is to further investigate the presence of a train-test data leakage between PDBbind and the commonly used CASF benchmarks. To this end, we propose a novel structure-based clustering algorithm to analyze and filter datasets of protein-ligand complex structures. By identifying large similarities between PBDbind and CASF datasets, our algorithm revealed a significant level of train-test data leakage. Going further, it also enabled us to devise a new split for the PBDbind dataset for providing a better setup for the training and testing of structure-based affinity prediction models. Our filtered training dataset, termed <italic>PDBbind CleanSplit</italic>, is strictly separated from the CASF benchmark datasets, turning them into true external datasets and enabling genuine evaluation of model generalizability.</p><p id="P5">To evaluate the true performance of recently published deep-learning-based scoring functions, we retrained the state-of-the-art binding affinity prediction model on the PDBbind CleanSplit dataset with removed data leakage. Although this model had previously shown excellent benchmark performance when trained on the original PDBbind dataset, its performance dropped to uncompetitive levels when trained on PDBbind CleanSplit, confirming that the prior high scores were largely driven by data leakage.</p><p id="P6">Recognizing that the generalization capability of existing deep-learning-based scoring functions might be much lower than previously thought, our main goal in this paper was to design a binding affinity prediction model with robustly validated generalization capability. To this end, we combined a novel graph neural network (GNN) architecture with transfer learning from large language models and trained this model on the filtered PDBbind CleanSplit. Despite the eliminated data leakage, our Graph Neural Network for Efficient Molecular Scoring (GEMS) achieves state-of-the-art predictions on the CASF benchmark. Since all protein-ligand complexes that remotely resembled any from the CASF test set were excluded from training, we can confidently state that the performance of GEMS is not the result of exploiting data leakage, but genuinely reflects its capability to generalize to new complexes. Moreover, our ablation studies showed that GEMS fails to produce accurate predictions when protein nodes are omitted from the graph, suggesting that its predictions are based on a genuine understanding of protein-ligand interactions.</p><p id="P7">GEMS is a promising tool with broad potential impact on the field of structure-based drug design (SBDD). Generative models like RFdiffusion and DiffSBDD can generate libraries of novel protein-ligand interactions, but their potential in drug design has been bottlenecked by the lack of accurate scoring functions to predict binding affinities for these interactions. GEMS fills this critical gap in SBDD. With its robust generalization capabilities evaluated on strictly independent datasets, it provides the scoring accuracy needed to identify interactions with therapeutic potential. To enable researchers to leverage and further develop GEMS, we have made all Python code publicly available in an easy-to-use format.</p><sec id="S1" sec-type="results"><title>Results</title><sec id="S2"><title>Dataset Filtering</title><p id="P8">To gain the ability to identify and remove structural similarities in datasets of protein-ligand complexes, we set out to design a structure-based clustering algorithm (<xref ref-type="fig" rid="F1">Fig. 1</xref>). In this algorithm, the computation of similarity between two protein-ligand complexes is based on a combined assessment of pocket similarity (TM-scores), ligand similarity (Tanimoto scores), and binding conformation similarity (pocket-aligned ligand RMSD). Combining these three metrics allows a robust and detailed comparison of protein-ligand complex structures. Importantly, in difference to traditional sequence-based analysis approaches, our multi-modal filtering can identify complexes with similar interaction patterns, even when the proteins have low sequence identity (<xref ref-type="supplementary-material" rid="SD1">Supplementary Fig. 1</xref>).</p><p id="P9">By comparing all CASF complexes to all PDBbind complexes, we identified a large number of similar complexes between PDBbind and the CASF test datasets, characterized by train-test pairs sharing not only similar ligand and protein structures but also comparable ligand positioning within the protein pocket, unsurprisingly also being accompanied by closely matched affinity labels (<xref ref-type="fig" rid="F2">Fig. 2a</xref>). Consequently, these structures provide nearly identical input data points to the model, enabling accurate prediction of test data point labels through simple memorization. According to the thresholds of our filtering algorithm, more than 700 PDBbind training complexes were detected to share such similarities with a CASF complex, involving 45% of all CASF complexes. These findings reveal a clear train-test data leakage when models are trained on PDBbind and tested on the CASF benchmark datasets, with nearly half of the CASF complexes not presenting novel challenges to these models.</p><p id="P10">Our filtering algorithm eliminated train-test data leakage by excluding all training complexes that closely resemble any CASF test complex. Additionally, it removed all training complexes with ligands similar to those in the CASF test complex (Tanimoto &gt; 0.9), ensuring that the ligands in the test datasets are never encountered during model training. This step provides an additional safeguard against ligand-based data leakage, addressing prior research that shows GNNs for binding affinity predictions often rely on ligand memorization to make affinity predictions [<xref ref-type="bibr" rid="R30">30</xref>]. Together, this filtering excluded 5% of all training complexes. The remaining train-test pairs with the highest similarity after filtering exhibited clear structural differences (<xref ref-type="fig" rid="F2">Fig. 2c</xref>), highlighting the effectiveness of our filtering algorithm in removing structurally similar data points. The resulting filtered training dataset is strictly separated from the CASF datasets, allowing models trained on it to be evaluated on the CASF benchmark, offering a genuine assessment of their generalization to unseen protein-ligand complexes.</p><p id="P11">In addition to the train-test overlap, we found significant similarity clusters within the training dataset itself. According to the thresholds of our filtering algorithm, nearly 50% of all training complexes are part of a similarity cluster. This means that random splitting inadvertently leads to inflated validation performance metrics, as some validation complexes can be predicted by matching labels with similar training complexes. Consequently, it is not surprising that models trained on a dataset with such extensive redundancies perform structure-matching, thereby settling for an easily attainable local minimum in the loss landscape. We hypothesized that this redundancy hampers model generalization, as it encourages memorization, leading to models that rely on exploiting structural similarities. Thus, we proposed that binding affinity prediction models would benefit from a more diverse dataset as a robust basis for training.</p><p id="P12">To test this hypothesis, our filtering algorithm includes a step to reduce training dataset redundancy. To find an optimal trade-off between maximizing dataset size and minimizing redundancy, we used adapted filtering thresholds to identify and eliminate the most striking similarity clusters. Using these adapted thresholds, our filtering algorithm iteratively removed complexes from the training dataset until all similarity clusters were resolved. Ultimately, this process resulted in the removal of 8.8% of all training complexes.</p><p id="P13">Given the extensive data leakage between PDBbind and the CASF benchmarks, the performance reported by many published models trained on these datasets likely overestimate their true generalization capabilities. Combining our strategies for removing train-test data leakage and minimizing training dataset redundancy, we have created a new refined split of the PDBbind dataset, which we call PDBbind CleanSplit.</p></sec><sec id="S3"><title>Search Algorithms</title><p id="P14">To illustrate the effect of train-test data leakage on model performance, we devised a simple algorithm that predicts the affinity of each CASF test complex by identifying the five most similar training complexes and averaging their affinity labels. This algorithm showed competitive CASF2016 prediction root-mean-square-error (RMSE) compared to some published deep-learning-based scoring functions (RMSE=1.526). To explore whether ligand memorization alone is sufficient for accurate CASF predictions, we modified the algorithm to search for the five training complexes with the most similar ligands. Averaging the labels of these complexes produced similarly high performance (RMSE = 1.543), confirming prior research on the importance of ligand memorization [<xref ref-type="bibr" rid="R30">30</xref>] (<xref ref-type="fig" rid="F3">Fig. 3a</xref>). When using the two search algorithms on the filtered PDBbind CleanSplit, we found that this led to a dramatic drop in their CASF prediction performance. Averaging the affinity label of the five most similar training complexes resulted in an RMSE of 1.817, which is only 0.3 pK units better than assigning the mean training label to all complexes. Using the labels of the five complexes with the most similar ligands resulted in an RMSE of 1.842 (<xref ref-type="fig" rid="F3">Fig. 3b</xref>).</p><p id="P15">Overall, the success of these two search algorithms on the unfiltered PDBbind illustrates how much training data memorization can boost CASF prediction accuracy when training on PDBbind. The low accuracy of the same algorithms on PDBbind CleanSplit, however, demonstrates that the train-test similarities have been largely removed through our filtering. For models trained on PDBbind CleanSplit, training data memorization is not sufficient for high CASF performance.</p></sec><sec id="S4"><title>Retraining Pafnucy</title><p id="P16">Building on the findings we obtained with our simple search algorithms, we set out to investigate whether the train-test data leakage within PDBbind has similarly inflated the benchmark performance of published state-of-the-art models. Toward this goal, we retrained the well-known Pafnucy binding affinity prediction model [<xref ref-type="bibr" rid="R11">11</xref>] as a test case. This model, published in 2018, was originally trained on the 2016 version of PDBbind, and its benchmark performance has been surpassed by newer models over time. We retrained Pafnucy using a 5-fold cross-validation approach on the more recent 2020 version of PDBbind according to the authors’ instructions. This increased the CASF performance of Pafnucy to an RMSE of 1.046, making it the best-performing binding affinity prediction model among all models that have, to our knowledge, been evaluated on the complete CASF2016 dataset to date (<xref ref-type="fig" rid="F3">Fig. 3a</xref>).</p><p id="P17">As a next step in our evaluation, we repeated the Pafnucy training using our PDBbind CleanSplit dataset. Strikingly, the performance of the newly trained Pafnucy model on the CASF2016 benchmark dropped to an RMSE of 1.500, supporting our hypothesis that the reported performance of many published binding affinity prediction models are boosted by data leakage and that the true generalization capabilities of many models are much lower than reported.</p></sec><sec id="S5"><title>GEMS</title><p id="P18">Aiming to create a scoring function that better generalizes to new data, we developed GEMS, a graph-based model for protein-ligand binding affinity prediction. GEMS models protein-ligand structures as interaction graphs enhanced with embeddings from language models and processes these graphs through a series of graph convolutions to predict binding affinities (<xref ref-type="fig" rid="F4">Fig. 4</xref>).</p><p id="P19">When trained on PDBbind, all tested model architectures showed benchmark performance comparable to those of the top deep-learning-based scoring functions reported to date. Training these models on PDBbind CleanSplit initially resulted in much lower benchmark performance, as would be expected when removing data leakage. However, after substantial architectural optimizations and the integration of language model embeddings to enrich the feature space of the graphs, our GEMS model achieved competitive results on the CASF2016 benchmark (<xref ref-type="fig" rid="F3">Fig. 3b,c</xref>). With a prediction RMSE of 1.305, GEMS considerably outperforms Pafnucy (RMSE=1.500) when trained on PDBbind CleanSplit, demonstrating its ability to generalize to unseen data. Moreover, GEMS even surpasses the reported performance metrics of several other deep-learning-based scoring functions that benefited from extensive train-test data leakage affecting 45% of all test data points (<xref ref-type="fig" rid="F3">Fig. 3a</xref>).</p><p id="P20">In addition to its scoring power, we also evaluated GEMS’ ranking power. The CASF2016 dataset features 57 clusters, each consisting of five identical proteins paired with diverse ligands that span a wide range of binding affinities. The ranking power of a scoring function refers to its ability to accurately rank ligands for a given target protein based on their binding affinities. When trained on PDBbind CleanSplit, GEMS outperformed Pafnucy, as underscored by the distribution of Spearman correlation coefficients across all 57 CASF2016 clusters (<xref ref-type="fig" rid="F3">Fig. 3c</xref>).</p><sec id="S6"><title>Ablation</title><p id="P21">When trained on the original PDBbind, all tested GEMS model variants achieved competitive CASF2016 performance even after removing all protein information from the input data (RMSE=1.402) (<xref ref-type="fig" rid="F5">Fig. 5a</xref>, <xref ref-type="fig" rid="F7">Extended Data Fig. 1a</xref>). According to this evaluation, these models - when trained only on ligands - make more accurate predictions than the scoring function of AutoDock Vina and even outperform several published deep-learning-based scoring functions. These results align with other studies indicating that models trained on PDBbind can achieve remarkably high performance on the CASF benchmark even when one interaction partner is deleted from the input data [<xref ref-type="bibr" rid="R25">25</xref>, <xref ref-type="bibr" rid="R26">26</xref>, <xref ref-type="bibr" rid="R31">31</xref>, <xref ref-type="bibr" rid="R32">32</xref>]. As these models received no protein information, their predictions are clearly not based on an understanding of protein-ligand interactions.</p><p id="P22">In contrast, when GEMS was trained on PDBbind CleanSplit, it produced very inaccurate benchmark predictions once protein nodes were omitted from the input data (RMSE = 1.609). This significant performance drop indicates that when data leakage and redundancies are eliminated, models must rely on a true understanding of protein-ligand interactions to make accurate predictions. The fact that GEMS achieves high performance when trained on CleanSplit suggests that it has indeed acquired this necessary understanding.</p></sec><sec id="S7"><title>Generalization to independent subset of CASF dataset</title><p id="P23">To explore whether models trained on PDBbind CleanSplit can generalize better to unseen data, we evaluated the performance of our models on a subset of the CASF2016 benchmark dataset, which is independent even before filtering the training data. According to the stringent similarity thresholds of our filtering algorithm, a fraction of the CASF2016 test dataset (155/285 complexes) is independent, with no similar complexes present in PDBbind. This independent subset thus provides a more reliable measure of generalization capability for models trained on PDBbind. While GEMS trained on PDBbind showed high overall performance on the complete CASF2016 dataset (RMSE=1.223), the performance on the independent subset is notably lower (RMSE=1.483). Notably, when tested on the same independent subset, the GEMS model trained on PDBbind CleanSplit performed better than the model trained on PDBbind (RMSE=1.425) despite the significant training dataset size reduction, suggesting that the true generalization capability of the models trained on PDBbind CleanSplit is indeed superior (<xref ref-type="fig" rid="F5">Fig. 5b</xref>, <xref ref-type="fig" rid="F7">Extended Data Fig. 1b</xref>).</p></sec><sec id="S8"><title>Influence of training redundancy</title><p id="P24">Our filtering approach for compiling PDBbind CleanSplit not only removed train-test overlap but also eliminated training dataset redundancies. This removal led to a decrease in validation performance, supporting our hypothesis that these redundancies had previously inflated validation results. While the removal of the train-test overlap led to the anticipated drop in test set performance, eliminating the redundancies from the training dataset improved performance again (<xref ref-type="fig" rid="F5">Fig. 5c</xref>, <xref ref-type="fig" rid="F7">Extended Data Fig. 1c</xref>). This positive effect suggests that extensive redundancies can be problematic in affinity prediction models, as models are prone to overfit to these clusters to minimize the training loss. Such overfitting interferes with learning the causal relationships behind molecular binding affinity and leads to models with lower generalization. In this case, distilling the training data to a smaller but more diverse collection of the most relevant complexes can be helpful for model training.</p></sec><sec id="S9"><title>Influence of language model embeddings</title><p id="P25">Models trained on PDBbind and PDBbind CleanSplit exhibit a distinct response to the incorporation of language model embeddings (<xref ref-type="fig" rid="F6">Fig. 6</xref>, <xref ref-type="fig" rid="F8">Extended Data Fig. 2</xref>). As these embeddings are rich in biological and chemical information, initializing graph features with them is expected to improve performance in the challenging task of binding affinity prediction. When training on PDBbind, the GEMS baseline model, which lacks any language model embeddings, performed best on the CASF2016 test dataset. Incorporating language model features resulted in a continuous increase in cross-validation performance, without a corresponding improvement in test set performance. Conversely, when trained on PDBbind CleanSplit, the baseline model without language model features showed relatively low cross-validation and test dataset performance. However, the introduction of such features led to simultaneous improvements in both metrics. This suggests that PDBbind CleanSplit provides a better foundation for training protein-ligand affinity prediction models, as it eliminates straightforward paths to high test performance, such as exploiting biases and data leakages. Instead, the diversity inherent in the filtered dataset and the absence of structural similarities requires models to approach the task by actually learning the factors driving high-affinity protein-ligand interactions. These models benefit from increased model complexity and enriched feature sets, such as those incorporating language model embeddings.</p></sec></sec></sec><sec id="S10" sec-type="discussion"><title>Discussion</title><p id="P26">The PDBbind dataset remains the largest resource for training protein-ligand binding affinity prediction models. However, the development of a generalisable affinity prediction model requires refining this dataset to address its significant training redundancies and data leakage into the commonly used CASF bechmark. By developing a structure-based filtering algorithm, we created PDBbind CleanSplit, a refined training dataset with minimized redundancy and strict separation from the CASF complexes. With PDBbind CleanSplit, models can no longer rely on training data memorization, as all complexes resembling any from the CASF benchmarks have been excluded from the training dataset. Additionally, the removal of redundancy ensures that models are trained on a much more diverse dataset, ultimately improving their generalization capabilities. In summary, PDBbind CleanSplit provides an improved foundation for training binding affinity prediction models, setting a new standard for robust training and reliable evaluation in this field.</p><p id="P27">The impact of using PDBbind CleanSplit for training becomes evident in the performance drop of Pafnucy, revealing that the true generalization capability of this previously top-performing model is much lower than reported. In contrast, our GEMS scoring function maintained excellent prediction accuracy when trained on PDBbind CleanSplit, achieving performance comparable to many deep-learning-based scoring functions that trained on the original PDBbind and profited from the associated data leakage. In addition, training GEMS was over 100 times faster than training Pafnucy on the same GPU, thanks to our sparse graph-based modeling of protein-ligand interactions and an efficient GNN architecture. Combined with transfer learning from large language models, GEMS obtained an understanding of protein-ligand interactions and thus can generalize to strictly external test datasets.</p><p id="P28">GEMS is a powerful scoring function designed to address a critical bottleneck in structure-based drug design (SBDD) and computational drug discovery. While recent generative models like AlphaFold3, RFdiffusion, and DiffSBDD can create libraries of novel protein-ligand interactions, their impact is constrained by the lack of tools to accurately predict binding affinities. Importantly, scoring <italic>de novo</italic> protein-ligand interactions demands models that go beyond exploiting structural similarities to existing complexes and demonstrate true generalization. GEMS fills this gap by offering robust scoring capabilities validated on strictly independent datasets, enabling identification of interactions with therapeutic potential.</p><p id="P29">We have prioritized accessibility by making our data, code, and model publicly available, including datasets of precomputed interactions graphs for fast reproduction of our results, and scripts for filtering the PDBbind database based on precomputed pairwise similarity matrices.</p><sec id="S11"><title>Related Work</title><p id="P30">Accurately predicting binding affinities for three-dimensional protein-ligand poses is crucial in structure-based drug design (SBDD). Traditionally, researchers used classical scoring functions, such as force-field-based, empirical, and knowledge-based methods, which are implemented in docking tools like AutoDock Vina and GOLD [<xref ref-type="bibr" rid="R1">1</xref>, <xref ref-type="bibr" rid="R2">2</xref>, <xref ref-type="bibr" rid="R7">7</xref>, <xref ref-type="bibr" rid="R10">10</xref>]. However, due to the linearity of the implemented scoring functions, these tools often produce low accuracy affinity predictions [<xref ref-type="bibr" rid="R8">8</xref>, <xref ref-type="bibr" rid="R9">9</xref>]. The use of deep learning has led to substantial advancements in scoring binding poses. The most effective models are 3D-convolutional neural networks (3D-CNNs) [<xref ref-type="bibr" rid="R11">11</xref>–<xref ref-type="bibr" rid="R17">17</xref>] and graph convolutional networks (GCNs) [<xref ref-type="bibr" rid="R18">18</xref>–<xref ref-type="bibr" rid="R22">22</xref>].</p><p id="P31">3D-CNNs represent protein-ligand complexes as voxel grids enhanced with chemical data of the underlying atoms. But these models can be computationally inefficient due to the lack of rotational and translational invariance, which requires training models with multiple orientations of each complex. Moreover, a significant fraction of voxels usually encode empty or non-informative regions of the protein-ligand complex [<xref ref-type="bibr" rid="R21">21</xref>, <xref ref-type="bibr" rid="R24">24</xref>, <xref ref-type="bibr" rid="R26">26</xref>, <xref ref-type="bibr" rid="R31">31</xref>].</p><p id="P32">GCNs, which model molecules as graphs with atoms as nodes and bonds as edges, offer a sparse representation that inherently supports rotational and translational invariance [<xref ref-type="bibr" rid="R21">21</xref>, <xref ref-type="bibr" rid="R26">26</xref>, <xref ref-type="bibr" rid="R37">37</xref>–<xref ref-type="bibr" rid="R40">40</xref>]. As a result, GCNs have become increasingly prevalent in recent protein-ligand binding affinity prediction models. These models are often based on molecular graphs of the ligand molecule embedded with chemical information of the surrounding protein residues [<xref ref-type="bibr" rid="R18">18</xref>, <xref ref-type="bibr" rid="R19">19</xref>, <xref ref-type="bibr" rid="R22">22</xref>]. Alternatively, some models extend molecular ligand graphs to include protein residues, with edges representing various types of interactions, such as hydrogen bonds, ionic interactions, and van der Waals forces, among others [<xref ref-type="bibr" rid="R20">20</xref>, <xref ref-type="bibr" rid="R21">21</xref>, <xref ref-type="bibr" rid="R41">41</xref>, <xref ref-type="bibr" rid="R42">42</xref>].</p></sec></sec><sec id="S12" sec-type="methods"><title>Methods</title><sec id="S13"><title>Datasets</title><p id="P33">The main data resource used in this work was the PDBbind (v.2020) database, containing 19’443 protein-ligand complexes from the Protein Data Bank (PDB) with experimentally measured binding affinities. This database is split into a general set (n=14127) and a refined set (n=5316) that has been compiled based on strict curation criteria, including crystallographic structures (excluding NMR structures) with a resolution of &lt; 2.5Å and an inhibition constant (Ki) or dissociation constant (Kd) in the range of 1pM to 10mM (pK range 2-12). To keep our training set as large as possible, we used a merged dataset containing all data from the general and the refined set as training data, excluding all complexes present in the Comparative Assessment of Scoring Functions (CASF) benchmark datasets (versions 2013 and 2016), which served as external test datasets in this work. Each complex is labelled with either an inhibition constant Ki, the dissociation constant Kd, or the half-maximal inhibitory concentration IC50. In this study, these metrics were considered interchangeable and converted to pK values with −log<sub>10</sub>(<italic>Ki/Kd/IC</italic>50) to generate the final affinity labels. During data preprocessing and graph construction, some protein-ligand complexes were excluded from the datasets based on the following criteria:</p><list list-type="bullet" id="L1"><list-item><p id="P34">Affinity label is not exact, e.g. <italic>K</italic><sub><italic>i</italic></sub> &lt; 100<italic>nm</italic> (n=383)</p></list-item><list-item><p id="P35">Error in RDKit when handling explicit hydrogens in some SDF files (n=45)</p></list-item><list-item><p id="P36">Protein contains unknown residue or heteroatom in binding pocket, such as UNK or DOD (n=14)</p></list-item><list-item><p id="P37">Error occurring during RDKit parsing due to incorrect valences in SDF files (n=5)</p></list-item><list-item><p id="P38">Protein structure is not completely resolved and atoms are missing from the binding pocket (n=2)</p></list-item><list-item><p id="P39">The ligand contains fewer than 5 heavy atoms (n=1)</p></list-item></list><p id="P40">This filtering reduced the size of the training dataset by 450 complexes to <italic>N</italic> = 18623 protein-ligand complexes. The CASF2016 (N=285) and CASF2013 (N=195) test sets were unaffected.</p></sec><sec id="S14"><title>Filtering Algorithm</title><p id="P41">To identify and remove structural similarities between the PDBbind database and the CASF benchmark datasets, our dataset filtering process relied on a combination of Tanimoto ligand similarity, TM scores, and a pocket-aligned ligand root-mean-square-deviation to compare the positioning of the ligands within the protein pockets. Tanimoto similarity is commonly used in cheminformatics to measure the similarity between small molecules. Based on comparing the chemical fingerprints, this score ranges between 0 (no similarity) and 1 (identical) and is a useful metric to identify compounds with similar structural and chemical properties. This score served as the first layer of our filtering, identifying pairs of complexes with similar ligands. The second layer of the filtering process used TM-align [<xref ref-type="bibr" rid="R33">33</xref>], a computational tool designed to compare protein structures by finding the optimal alignment of their three-dimensional shapes. It uses a scoring function based on the root-mean-square-distance of aligned residues and a length normalization factor, making it particularly effective for identifying structural similarities between proteins, regardless of sequence similarity. In our application, TM-align was valuable for identifying proteins that share similar binding pockets despite having low sequence identity. For instance, the test complex 1P1N and the training complex 3U92 share 53% sequence identity. Nevertheless, TM-align has recognized that 1P1N is well-represented within 3U92 and returns a TM score of 0.93. Alignment of the proteins then revealed that these complexes share identical binding pockets (<xref ref-type="supplementary-material" rid="SD1">Supplementary Fig. 1</xref>). The capability of our filtering process to identify complexes with similar interaction patterns in proteins that are otherwise dissimilar is a key advantage of our method over traditional sequence-based clustering approaches, which would overlook this similarity.</p><p id="P42">However, the combination of TM-score and Tanimoto similarity does not conclusively determine the similarity between two complexes. Even with a Tanimoto similarity of 1 and a TM-score of 1, two complexes might have different positioning of the ligand within the binding pocket, or the ligands might even bind at entirely different sites of the protein. Therefore, the third layer of our filtering process compares ligand positioning through a pocket alignment followed by a root-mean-square-deviation (RMSD) calculation between the ligand atoms. For this analysis, one ligand’s atom coordinates are translated and rotated using the rotation matrix and translation vector obtained from TM-align (<xref ref-type="supplementary-material" rid="SD1">Supplementary Fig. 2</xref>). This alignment positions both ligands within the coordinate system of the optimal alignment of the protein structures. RMSD between the ligand atoms is then calculated to provide a quantitative measure of the positional similarity.</p><p id="P43">Our filtering algorithm imposes stringent rules on the structural and chemical similarity within the dataset. The similarity between two complexes is quantified on the basis of four computed similarity metrics:</p><list list-type="bullet" id="L2"><list-item><p id="P44"><bold>Affinity:</bold> The absolute difference between the reported binding affinities (pK values)</p></list-item><list-item><p id="P45"><bold>Tanimoto:</bold> The Tanimoto similarity score to compare ligand structure was computed using RDKit library v.2024.03.3.</p></list-item><list-item><p id="P46"><bold>TM-score:</bold> TM-align [<xref ref-type="bibr" rid="R33">33</xref>] was used to assess protein structural similarity and to align complexes based on their protein residues. This algorithm identifies the best structural alignment between protein pairs and outputs a TM-score, which ranges from 0 to 1, where 1 indicates a perfect match (i.e., identical structures), along with the translation vector and rotation matrix necessary to achieve optimal alignment. To find if one of the proteins is well represented within the other, we considered TM-scores normalized by the lengths of both amino acid chains and used the highest result as a similarity score.</p></list-item><list-item><p id="P47"><bold>RMSD:</bold> A root-mean-square-deviation (RMSD) is computed to compare ligand positioning in the binding pocket of the proteins. For this, the protein pockets were aligned by applying the translation vector and rotation matrix that TM-align used to generate an optimal protein alignment. Then, the atom coordinates of the aligned ligands were compared by computing the root-mean-square-distance between the nearest points in the two point clouds. A lower distance value indicates a very similar positioning of the two ligands in their binding pockets, and a higher value suggests very dissimilar binding conformations (or even binding at a different location of the protein).</p></list-item></list><sec id="S15"><title>Removal of Train-Test-Overlap</title><p id="P48">To remove the overlap between the training dataset (PDBbind) and the CASF test datasets (CASF2013 and CASF2016), our filtering algorithm removed all training complexes that are similar to any test complex in terms of protein structure, ligand structure, ligand binding and affinity. This eliminates data leakage by removing shared similarities between training and test datasets, effectively bringing the CASF datasets closer to being independent test datasets. A training complex was excluded if it shared all of the following similarities with a test complex:</p><list list-type="order" id="L3"><list-item><p id="P49">The proteins have a TM-score higher than 0.8</p></list-item><list-item><p id="P50">The sum of the Tanimoto score (T) and the inverted RMSD is higher than 0.8 (<italic>T</italic> + (1 − <italic>RMSD</italic>))</p></list-item><list-item><p id="P51">The affinity labels are similar (±1 in pK units)</p></list-item></list><p id="P52">The first criterion ensures that training complexes are only excluded if they share a high structural similarity with a test complex. The second criterion balances ligand chemical similarity with binding conformation similarity. This approach means that a greater ligand positioning similarity is acceptable for two ligands with modest chemical similarity (e.g., Tanimoto coefficient, T=0.6). Conversely, for very similar ligands (T approaching 1), even larger deviations in positioning can lead to the exclusion of the complex from the dataset. The third criterion ensures that training complexes are only excluded if they share a similar affinity label with the test complex. In addition, training complexes were excluded if they had an identical ligand (Tanimoto &gt; 0.9) and a closely matching affinity label (±1) compared to a test complex. Together, this filtering excluded 874 training complexes.</p></sec><sec id="S16"><title>Removal of Training Dataset Redundancy</title><p id="P53">A second filtering layer was applied to the training dataset to eliminate excessive redundancies while preserving the largest possible dataset size and quality. Initially, pairwise similarities between all training complexes were calculated using the described similarity metrics and recorded in a pairwise similarity matrix. To identify clusters of high similarity, this matrix was transformed into an adjacency matrix by applying the following thresholds:</p><list list-type="order" id="L4"><list-item><p id="P54">The proteins have a TM-score higher than 0.8</p></list-item><list-item><p id="P55">The sum of the Taminoto score (T) and the inverted RMSD is higher than 1.3 (<italic>T</italic> + (1 − <italic>RMSD</italic>))</p></list-item><list-item><p id="P56">The affinity labels differ by less than ±0.5 in pK unit</p></list-item></list><p id="P57">The resulting adjacency matrix connects all data points that meet these criteria. The filtering algorithm then iteratively removed complexes from the training dataset until no connections remained in the adjacency matrix. During each iteration, the complex with the highest number of connections (indicating the most similarities to other complexes) was excluded. In cases where multiple complexes had the same number of connections, preference was given to removing those from the PDBbind general set rather than the refined set. If ties persisted, the complex with the lowest resolution was preferentially excluded. In total, this filtering process excluded 1707 training complexes and allowed us to confidently train models using 5-fold cross-validation with random splitting, without the risk of inflated validation performance that could arise from similarities between training and validation datasets.</p></sec></sec><sec id="S17"><title>Graph Construction</title><p id="P58">Each complex in the PDBbind database was translated into an affinity-labeled graph that models the interaction between the ligand and the protein (hereafter referred to as interaction graphs). For this, the affinity labels of all protein-ligand complexes in the database were extracted from the index files provided by the PDBbind database. The supplied inhibition constants (Ki), dissociation constant (Kd) and half-maximal inhibitory concentration (IC50) were converted to pK values with −log<sub>10</sub>(<italic>Ki/Kd/IC</italic>50) to generate the final affinity labels.</p><p id="P59">The interaction graphs were generated as follows: Protein PDB files were processed with Biopython v.1.83 to retrieve the amino acid sequences. Ligand SDF files were parsed with RDKit v.2024.03.3. From the atom coordinates of the ligand and protein, a pairwise distance matrix was generated to identify ligand atoms and protein atoms in close vicinity. An interaction distance of 5Å was considered sufficient to capture the most critical molecular interaction between ligand and protein. Consequently, if any atom of a protein residue was closer to a ligand atom than 5A, the protein residue was considered to be in interaction distance to this ligand atom. Based on this, a list of amino acids and heteroatoms in interaction distance was generated for each ligand atom.</p><p id="P60">A basic molecular graph was generated from the ligand by translating the atoms into graph nodes, and the covalent bonds into graph edges. All protein residues and heteroatoms in interaction distance were added as additional graph nodes to encode the molecular environment of the ligands. Importantly, the protein is represented at the amino acid level, which means that each amino acid is represented by a single graph node located at the position of its C<italic>α</italic> atom. To model the potential non-covalent interactions in the binding pocket, additional graph edges were introduced to connect each ligand node to the protein nodes and heteroatoms previously determined to be in interaction distance. The resulting interaction graphs consisted of an atom-level graph representation of the ligand, supplemented with an amino acid-level representation of its surrounding protein residues (<xref ref-type="supplementary-material" rid="SD1">Supplementary Fig. 3</xref>). All edges of these basic interaction graphs were undirected (applying message-passing in both directions), and self-loops were included for each node.</p><sec id="S18"><title>Featurization</title><p id="P61">The interaction graphs’ initial node and edge features consisted of one-hot-encoded chemical properties computed with the RDKit v.2024.03.3 library. The following basic chemical features were included:</p><list list-type="bullet" id="L5"><list-item><p id="P62">Nodes: Atom type (B, C, N, O, P, S, Se, metal, halogen), ring membership, hybridization, formal charge, aromaticity, atomic mass, number of bonded hydrogens, degree, chirality</p></list-item><list-item><p id="P63">Edges: Edge type (covalent, self-loop, non-covalent), length, bond type (single/double/triple/aromatic), conjugation, ring membership, stereochemistry</p></list-item></list><p id="P64">In feature vectors of edges connecting a ligand atom node with a protein residue node, the length feature was replaced with four values representing the distances between the ligand atom and the four main backbone atoms of the residue (N, C<italic>α</italic>, C and virtual C<italic>β</italic>). If any feature did not apply to a certain node (e.g. atom type for a node representing a protein residue), the feature was replaced with zero padding to maintain consistent feature dimensions across the graphs.</p><p id="P65">The features of the nodes representing protein residues were additionally supplemented with a vector containing the one-hot-encoded amino acid type and with amino acid embeddings. These embeddings were generated with ESM2 (T6 8M checkpoint downloaded from huggingface <ext-link ext-link-type="uri" xlink:href="https://huggingface.co/facebook">https://huggingface.co/facebook</ext-link> through the transfomers library v.4.33.3) [<xref ref-type="bibr" rid="R34">34</xref>] and ANKH (base model downloaded through the ankh python library v.1.10.0) [<xref ref-type="bibr" rid="R35">35</xref>]. For this, the amino acid sequence of a protein was passed through the downloaded tokenizers and model checkpoints. The resulting matrices contained embeddings for each amino acid in the protein sequences, which were then appended to the features of the corresponding graph nodes. In addition, a ligand embedding was computed for each complex using the ChemBERTa-2 language model (ChemBERTa-77M-MLM downloaded from <ext-link ext-link-type="uri" xlink:href="https://huggingface.co/DeepChem">https://huggingface.co/DeepChem</ext-link> through the transformers library v.4.33.3) [<xref ref-type="bibr" rid="R36">36</xref>]). The smiles codes of all ligands in the dataset were generated with RDKit v.2024.03.3 and passed through the downloaded model to obtain ligand embeddings. These embeddings were appended to the graph’s initial global features during model training.</p></sec></sec><sec id="S19"><title>Model Architecture</title><p id="P66">Our graph neural network models were implemented using PyTorch v.2.0.1 and Torch Geometric (pyg) v.2.5.2. The model architecture captures and integrates multi-level graph information across nodes, edges, and the entire graph. It receives batches of interaction graphs as input and alternates between updating the graph’s edge features, node features, and global features (<xref ref-type="fig" rid="F4">Fig. 4b</xref>). The architecture includes the following components:</p><list list-type="order" id="L6"><list-item><p id="P67">A NodeTransformMLP module, which applies a multi-layer perceptron (MLP) with ReLU and dropout to transform the input node features.</p></list-item><list-item><p id="P68">An EdgeModel module to update edge features. It processes the concatenated features of source nodes, destination nodes, and existing edge features through an MLP with ReLU and dropout.</p></list-item><list-item><p id="P69">A NodeModel module to update node features. It uses a graph attention network (GATv2Conv) [<xref ref-type="bibr" rid="R43">43</xref>] convolution to update node features based on their neighboring nodes and edge attributes.</p></list-item><list-item><p id="P70">A GlobalModel module concatenates the global graph features with aggregated node features and applies an MLP with dropout to create updated global graph features.</p></list-item></list><p id="P71">In a forward pass of the model, the node features are first transformed by the NodeTransformMLP module. These transformed node features, along with edge attributes and global features, are then processed through two consecutive graph layers. Each graph layer performs the following sequence of updates: the EdgeModel updates the edge features based on the connected node’s features, the NodeModel updates the node features based on the features of neighboring nodes and the connecting edges, and the GlobalModel updates the global features with pooled node features. After the first graph layer, batch normalization is applied to the node, edge, and global features. Following the second graph layer, a dropout layer is applied to the global features to prevent overfitting. Finally, the global features are passed through two fully connected layers with a ReLU activation to produce the final output.</p><p id="P72">As graph convolutional operator, GATv2Conv [<xref ref-type="bibr" rid="R43">43</xref>] from Torch Geometric was selected with concatenation of multi-head attention. To find the optimal number of message-passing steps, channels and attention heads of the individual layers, different model architectures were tested:</p><list list-type="bullet" id="L7"><list-item><p id="P73">Number of message passing steps: Search space [1,2,3] with final value 2.</p></list-item><list-item><p id="P74">Graph pooling operator: Search space [mean pooling, add pooling, max pooling] with final choice add pooling.</p></list-item><list-item><p id="P75">NodeTransformMLP output channels: Search space [256, 128, 64] with final value 64.</p></list-item><list-item><p id="P76">NodeModel output channels: Search space [256, 128, 64] with final value 64.</p></list-item><list-item><p id="P77">EdgeModel output channels: Search space [128, 64] with final value 64.</p></list-item><list-item><p id="P78">GlobalModel output channels: Search space [768, 512, 384, 256] with final value 384.</p></list-item></list></sec><sec id="S20"><title>Model Training and Selection</title><p id="P79">During the training of GEMS and Pafnucy, all model variants trained on the same dataset were subjected to the same five-fold cross-validation split to eliminate the variability introduced by differences in data partitioning. The models were trained across all five splits, and the models that achieved the lowest validation root-mean-square-error (RMSE) were saved. The training objective was to minimize the RMSE of the predicted pK values of the training complexes, using a stochastic gradient descent (SGD) optimizer. To prevent overfitting, early stopping was implemented. This technique halted the training process if there was no improvement in the validation RMSE for 100 consecutive epochs. All models were trained on one NVIDIA GeForce RTX 4090 or one NVIDIA GeForce RTX 3090 for approximately 200-1200 epochs (depending on the early stopping), taking between 10 and 60 minutes. The training hyperparameters were optimized as follows:</p><list list-type="bullet" id="L8"><list-item><p id="P80">Batch size: Search space [128,256,512,640] with final value 256.</p></list-item><list-item><p id="P81">Learning rate: Search space [0.0001, 0.001, 0.01] with final value 0.001.</p></list-item><list-item><p id="P82">Weight decay: Search space [0.0001, 0.001, 0.01] with final value 0.001.</p></list-item></list><p id="P83">From all trained models, the one with the highest and most consistent validation performance across all five folds was selected. This ensures that the model with the most robust generalization across different subsets of our training data is selected. For testing models on the CASF test datasets, the CASF complexes were passed through all five cross-validation models and the predictions from all five models were averaged to generate the final ensemble predictions.</p><p id="P84">To robustly determine the uncertainty of GEMS, we trained it using our five-fold cross-validation approach at five different random seeds. This approach ensures that the randomness in the data splitting differs with each training run, which allows us to estimate the variability in performance that arises from different data splits. By averaging the outcomes and calculating the standard deviation between these iterations, we generated error bars for our performance metrics.</p><sec id="S21"><title>Ablation</title><p id="P85">To facilitate ablation experiments, our script for constructing interaction graph datasets from protein-ligand complexes includes a parameter that allows for the optional removal of all protein information from the graphs. To test whether GEMS relies on the presence of both ligand and protein data, we generated ligand-only versions of the PDBbind, PDBbind CleanSplit, and CASF datasets by removing all protein nodes, leaving only the molecular graph of the ligand. We then trained and tested GEMS as described above using these ligand-only datasets.</p></sec><sec id="S22"><title>Pafnucy</title><p id="P86">The Pafnucy model was obtained from the authors public repository (<ext-link ext-link-type="uri" xlink:href="https://gitlab.com/cheminfIBB/pafnucy">https://gitlab.com/cheminfIBB/pafnucy</ext-link>) and trained on a NVIDIA GeForce RTX 3090 GPU using the provided scripts and instructions. Protein-ligand complexes were preprocessed and datasets prepared according to the authors’ specifications. We evaluated its performance on the training and validation sets, as well as on the CASF2016 dataset, using the predictions from the output text file generated by the training script. To compare the performance of our model with that of Pafnucy, we used the same cross-validation method and identical data split.</p></sec></sec></sec><sec id="S23" sec-type="extended-data"><title>Extended Data</title><fig id="F7" position="anchor"><label>Extended Data Figure 1</label><caption><title>Impact of Ablation and Dataset Filtering on GEMS Performance on CASF2013 (N=195):</title><p id="P87"><bold>a)</bold> Ablation study showing the impact of removing all protein information from the graphs on CASF2013 performance, comparing models trained on PDBbind (left) and PDBbind CleanSplit (right). <bold>b)</bold> Comparison of GEMS performance on cross-validation (CV), CASF2013, and the independent subset of CASF2013 (N=89), for models trained on PDBbind (left) and PDBbind CleanSplit (right). <bold>c)</bold> CASF2013 performance of GEMS with varying levels of training dataset filtering: complete dataset (PDBbind), train-test overlap removed, and both overlap and redundancy removed (PDBbind CleanSplit). Error bars represent data uncertainty, calculated as the standard deviation of the performance across five models trained with 5-fold cross-validation at different random seeds.</p></caption><graphic xlink:href="EMS201969-f007"/></fig><fig id="F8" position="anchor"><label>Extended Data Figure 2</label><caption><title>Impact of Language Model Embeddings on GEMS Performance on CASF2013(N=195):</title><p id="P88"><bold>a)</bold> Effect of incorporating language model embeddings on the CASF2013 performance of GEMS models trained on the original PDBbind dataset. <bold>b)</bold> Effect of incorporating language model embeddings on the CASF2013 performance of GEMS models trained on PDBbind CleanSplit.</p></caption><graphic xlink:href="EMS201969-f008"/></fig></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary Information</label><media xlink:href="EMS201969-supplement-Supplementary_Information.pdf" mimetype="application" mime-subtype="pdf" id="d140aAcKbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S24"><title>Acknowledgements</title><p>This study was financed by C.H.’s ZHAW DIZH Fellowship (Call 2022) and supported by NCCR Catalysis, a National Centre of Competence in Research funded by the Swiss National Science Foundation (Grant No. 180544 to R.B. und P.S). S.M.’s contribution to this work was supported in part by the DOE SEA-CROGS project (DE-SC-0023191).</p></ack><sec id="S25" sec-type="data-availability"><title>Data availability</title><p id="P89">PDBbind data are available at: <ext-link ext-link-type="uri" xlink:href="http://www.pdbbind.org.cn/">http://www.pdbbind.org.cn/</ext-link>. The data generated in this study are freely available on GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/camlab-ethz/GEMS">https://github.com/camlab-ethz/GEMS</ext-link>) including GEMS model parameters and PDBbind CleanSplit. For fast reproduction of our results, we provide PyTorch datasets of precomputed interaction graphs for the entire PDBbind database on Zenodo (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.14260171">https://doi.org/10.5281/zenodo.14260171</ext-link>). To enable quick establishment of leakage-free evaluation setups with PDBbind, we also provide pairwise similarity matrices for the entire PDBbind dataset on Zenodo.</p></sec><sec id="S26" sec-type="data-availability"><title>Code availability</title><p id="P90">The code generated in this study is freely available on GitHub. All scripts for dataset filtering, model training and inference can be accessed through <ext-link ext-link-type="uri" xlink:href="https://github.com/camlab-ethz/GEMS">https://github.com/camlab-ethz/GEMS</ext-link>. A docker container for easy reproduction and implementation is provided.</p></sec><fn-group><fn fn-type="con" id="FN1"><p id="P91"><bold>Author contributions</bold></p><p id="P92">D.G., C.H. and S.M. conceived the GEMS model architecture. D.G., P.S., F.M., C.H., S.M. and R.M.B designed the experiments. D.G. carried out the experiments and D.G., P.S., R.M.B. and S.M. analysed the data. P.S. tested the code for usability with different datasets and set up a docker container. D.G., C.H., S.M. and R.M.B. wrote the manuscript with feedback from F.M. and P.S. The project was supervised by C.H., R.M.B. and S.M.</p></fn><fn fn-type="conflict" id="FN2"><p id="P93"><bold>Competing interests</bold></p><p id="P94">All authors declare no competing interests.</p></fn></fn-group><ref-list><ref id="R1"><label>[1]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Trott</surname><given-names>O</given-names></name><name><surname>Olson</surname><given-names>AJ</given-names></name></person-group><article-title>AutoDock Vina: Improving the speed and accuracy of docking with a new scoring function, efficient optimization, and multithreading</article-title><source>Journal of Computational Chemistry</source><year>2010</year><volume>31</volume><issue>2</issue><fpage>455</fpage><lpage>461</lpage><pub-id pub-id-type="pmcid">PMC3041641</pub-id><pub-id pub-id-type="pmid">19499576</pub-id><pub-id pub-id-type="doi">10.1002/jcc.21334</pub-id></element-citation></ref><ref id="R2"><label>[2]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>G</given-names></name><etal/></person-group><article-title>Development and validation of a genetic algorithm for flexible docking</article-title><source>Journal of Molecular Biology</source><year>1997</year><volume>267</volume><issue>3</issue><fpage>727</fpage><lpage>748</lpage><pub-id pub-id-type="pmid">9126849</pub-id></element-citation></ref><ref id="R3"><label>[3]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krishna</surname><given-names>R</given-names></name><etal/></person-group><article-title>Generalized biomolecular modeling and design with RoseTTAFold All-Atom</article-title><source>Science</source><year>2024</year><volume>384</volume><issue>6693</issue><elocation-id>eadl2528</elocation-id><pub-id pub-id-type="pmid">38452047</pub-id></element-citation></ref><ref id="R4"><label>[4]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abramson</surname><given-names>J</given-names></name><etal/></person-group><article-title>Accurate structure prediction of biomolecular interactions with AlphaFold 3</article-title><source>Nature</source><year>2024</year><volume>630</volume><issue>8016</issue><fpage>493</fpage><lpage>500</lpage><pub-id pub-id-type="pmcid">PMC11168924</pub-id><pub-id pub-id-type="pmid">38718835</pub-id><pub-id pub-id-type="doi">10.1038/s41586-024-07487-w</pub-id></element-citation></ref><ref id="R5"><label>[5]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watson</surname><given-names>JL</given-names></name><etal/></person-group><article-title>De novo design of protein structure and function with RFdiffusion</article-title><source>Nature</source><year>2023</year><volume>620</volume><issue>7976</issue><fpage>1089</fpage><lpage>1100</lpage><pub-id pub-id-type="pmcid">PMC10468394</pub-id><pub-id pub-id-type="pmid">37433327</pub-id><pub-id pub-id-type="doi">10.1038/s41586-023-06415-8</pub-id></element-citation></ref><ref id="R6"><label>[6]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneuing</surname><given-names>A</given-names></name><etal/></person-group><article-title>Structure-based Drug Design with Equivariant Diffusion Models</article-title><source>arXiv</source><year>2022</year><comment>eprint: 2210.13695</comment><pub-id pub-id-type="pmcid">PMC11659159</pub-id><pub-id pub-id-type="pmid">39653846</pub-id><pub-id pub-id-type="doi">10.1038/s43588-024-00737-x</pub-id></element-citation></ref><ref id="R7"><label>[7]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kitchen</surname><given-names>DB</given-names></name><name><surname>Decornez</surname><given-names>H</given-names></name><name><surname>Furr</surname><given-names>JR</given-names></name><name><surname>Bajorath</surname><given-names>J</given-names></name></person-group><article-title>Docking and scoring in virtual screening for drug discovery: methods and applications</article-title><source>Nature Reviews Drug Discovery</source><year>2004</year><volume>3</volume><issue>11</issue><fpage>935</fpage><lpage>949</lpage><pub-id pub-id-type="pmid">15520816</pub-id></element-citation></ref><ref id="R8"><label>[8]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Assessing protein–ligand interaction scoring functions with the CASF-2013 benchmark</article-title><source>Nature Protocols</source><year>2018</year><volume>13</volume><issue>4</issue><fpage>666</fpage><lpage>680</lpage><pub-id pub-id-type="pmid">29517771</pub-id></element-citation></ref><ref id="R9"><label>[9]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Su</surname><given-names>M</given-names></name><etal/></person-group><article-title>Comparative Assessment of Scoring Functions: The CASF-2016 Update</article-title><source>Journal of Chemical Information and Modeling</source><year>2019</year><volume>59</volume><issue>2</issue><fpage>895</fpage><lpage>913</lpage><pub-id pub-id-type="pmid">30481020</pub-id></element-citation></ref><ref id="R10"><label>[10]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maia</surname><given-names>EHB</given-names></name><etal/></person-group><article-title>Structure-Based Virtual Screening: From Classical to Artificial Intelligence</article-title><source>Frontiers in Chemistry</source><year>2020</year><volume>8</volume><fpage>343</fpage><pub-id pub-id-type="pmcid">PMC7200080</pub-id><pub-id pub-id-type="pmid">32411671</pub-id><pub-id pub-id-type="doi">10.3389/fchem.2020.00343</pub-id></element-citation></ref><ref id="R11"><label>[11]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stepniewska-Dziubinska</surname><given-names>MM</given-names></name><name><surname>Zielenkiewicz</surname><given-names>P</given-names></name><name><surname>Siedlecki</surname><given-names>P</given-names></name></person-group><article-title>Development and evaluation of a deep learning model for protein–ligand binding affinity prediction</article-title><source>Bioinformatics</source><year>2018</year><volume>34</volume><issue>21</issue><fpage>3666</fpage><lpage>3674</lpage><comment>PDBbind 2016</comment><pub-id pub-id-type="pmcid">PMC6198856</pub-id><pub-id pub-id-type="pmid">29757353</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/bty374</pub-id></element-citation></ref><ref id="R12"><label>[12]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>L</given-names></name><name><surname>Fan</surname><given-names>J</given-names></name><name><surname>Mu</surname><given-names>Y</given-names></name></person-group><article-title>OnionNet: a Multiple-Layer Intermolecular-Contact-Based Convolutional Neural Network for Protein–Ligand Binding Affinity Prediction</article-title><source>ACS Omega</source><year>2019</year><volume>4</volume><issue>14</issue><fpage>15956</fpage><lpage>15965</lpage><comment>eprint: 1906.02418</comment><pub-id pub-id-type="pmcid">PMC6776976</pub-id><pub-id pub-id-type="pmid">31592466</pub-id><pub-id pub-id-type="doi">10.1021/acsomega.9b01997</pub-id></element-citation></ref><ref id="R13"><label>[13]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>S</given-names></name><etal/></person-group><article-title>SE-OnionNet: A Convolution Neural Network for Protein–Ligand Binding Affinity Prediction</article-title><source>Frontiers in Genetics</source><year>2021</year><volume>11</volume><elocation-id>607824</elocation-id><pub-id pub-id-type="pmcid">PMC7962986</pub-id><pub-id pub-id-type="pmid">33737946</pub-id><pub-id pub-id-type="doi">10.3389/fgene.2020.607824</pub-id></element-citation></ref><ref id="R14"><label>[14]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gomes</surname><given-names>J</given-names></name><name><surname>Ramsundar</surname><given-names>B</given-names></name><name><surname>Feinberg</surname><given-names>EN</given-names></name><name><surname>Pande</surname><given-names>VS</given-names></name></person-group><article-title>Atomic Convolutional Networks for Predicting Protein-Ligand Binding Affinity</article-title><source>arXiv</source><year>2017</year><comment>eprint: 1703.10603</comment><pub-id pub-id-type="doi">10.48550/arxiv.1703.10603</pub-id></element-citation></ref><ref id="R15"><label>[15]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wallach</surname><given-names>I</given-names></name><name><surname>Dzamba</surname><given-names>M</given-names></name><name><surname>Heifets</surname><given-names>A</given-names></name></person-group><article-title>AtomNet: A Deep Convolutional Neural Network for Bioactivity Prediction in Structure-based Drug Discovery</article-title><source>arXiv</source><year>2015</year><comment>eprint: 1510.02855</comment><pub-id pub-id-type="doi">10.48550/arxiv.1510.02855</pub-id></element-citation></ref><ref id="R16"><label>[16]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jimenez</surname><given-names>J</given-names></name><name><surname>Skalic</surname><given-names>M</given-names></name><name><surname>Martinez-Rosell</surname><given-names>G</given-names></name><name><surname>Fabritiis</surname><given-names>GD</given-names></name></person-group><article-title>K DEEP: Protein–Ligand Absolute Binding Affinity Prediction via 3D-Convolutional Neural Networks</article-title><source>Journal of Chemical Information and Modeling</source><year>2018</year><volume>58</volume><issue>2</issue><fpage>287</fpage><lpage>296</lpage><pub-id pub-id-type="pmid">29309725</pub-id></element-citation></ref><ref id="R17"><label>[17]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hassan-Harrirou</surname><given-names>H</given-names></name><name><surname>Zhang</surname><given-names>C</given-names></name><name><surname>Lemmin</surname><given-names>T</given-names></name></person-group><article-title>RosENet: Improving Binding Affinity Prediction by Leveraging Molecular Mechanics Energies with an Ensemble of 3D Convolutional Neural Networks</article-title><source>Journal of Chemical Information and Modeling</source><year>2020</year><volume>60</volume><issue>6</issue><fpage>2791</fpage><lpage>2802</lpage><pub-id pub-id-type="pmid">32392050</pub-id></element-citation></ref><ref id="R18"><label>[18]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karlov</surname><given-names>DS</given-names></name><name><surname>Sosnin</surname><given-names>S</given-names></name><name><surname>Fedorov</surname><given-names>MV</given-names></name><name><surname>Popov</surname><given-names>P</given-names></name></person-group><article-title>graphDelta: MPNN Scoring Function for the Affinity Prediction of Protein–Ligand Complexes</article-title><source>ACS Omega</source><year>2020</year><volume>5</volume><issue>10</issue><fpage>5150</fpage><lpage>5159</lpage><comment>PDBbind 2018</comment><pub-id pub-id-type="pmcid">PMC7081425</pub-id><pub-id pub-id-type="pmid">32201802</pub-id><pub-id pub-id-type="doi">10.1021/acsomega.9b04162</pub-id></element-citation></ref><ref id="R19"><label>[19]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moesser</surname><given-names>MA</given-names></name><etal/></person-group><article-title>Protein-Ligand Interaction Graphs: Learning from Ligand-Shaped 3D Interaction Graphs to Improve Binding Affinity Prediction</article-title><source>bioRxiv</source><year>2022</year><elocation-id>2022.03.04.483012</elocation-id><comment>PDBbind 2020</comment><pub-id pub-id-type="doi">10.1101/2022.03.04.483012</pub-id></element-citation></ref><ref id="R20"><label>[20]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>S</given-names></name><etal/></person-group><article-title>GIANT: Protein-Ligand Binding Affinity Prediction via Geometry-aware Interactive Graph Neural Network</article-title><source>IEEE Transactions on Knowledge and Data Engineering</source><year>2023</year><issue>99</issue><fpage>1</fpage><lpage>17</lpage><comment>PP PDBbind 2016 refined</comment><pub-id pub-id-type="doi">10.1109/tkde.2023.3314502</pub-id></element-citation></ref><ref id="R21"><label>[21]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>D</given-names></name><etal/></person-group><article-title>InteractionGraphNet: A Novel and Efficient Deep Graph Representation Learning Framework for Accurate Protein–Ligand Interaction Predictions</article-title><source>Journal of Medicinal Chemistry</source><year>2021</year><volume>64</volume><issue>24</issue><fpage>18209</fpage><lpage>18232</lpage><pub-id pub-id-type="pmid">34878785</pub-id></element-citation></ref><ref id="R22"><label>[22]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mqawass</surname><given-names>G</given-names></name><name><surname>Popov</surname><given-names>P</given-names></name></person-group><article-title>graphLambda: Fusion Graph Neural Networks for Binding Affinity Prediction</article-title><source>Journal of Chemical Information and Modeling</source><year>2024</year><pub-id pub-id-type="pmid">38366974</pub-id></element-citation></ref><ref id="R23"><label>[23]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahmed</surname><given-names>A</given-names></name><name><surname>Mam</surname><given-names>B</given-names></name><name><surname>Sowdhamini</surname><given-names>R</given-names></name></person-group><article-title>DEELIG: A Deep Learning Approach to Predict Protein-Ligand Binding Affinity</article-title><source>Bioinformatics and Biology Insights</source><year>2021</year><volume>15</volume><elocation-id>11779322211030364</elocation-id><comment>Self-curated dataset</comment><pub-id pub-id-type="pmcid">PMC8274096</pub-id><pub-id pub-id-type="pmid">34290496</pub-id><pub-id pub-id-type="doi">10.1177/11779322211030364</pub-id></element-citation></ref><ref id="R24"><label>[24]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>D</given-names></name><etal/></person-group><article-title>Improved Protein–Ligand Binding Affinity Prediction with Structure-Based Deep Fusion Inference</article-title><source>Journal of Chemical Information and Modeling</source><year>2021</year><volume>61</volume><issue>4</issue><fpage>1583</fpage><lpage>1592</lpage><comment>PDBbind 2016</comment><pub-id pub-id-type="pmid">33754707</pub-id></element-citation></ref><ref id="R25"><label>[25]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>J</given-names></name><name><surname>Shen</surname><given-names>C</given-names></name><name><surname>Huang</surname><given-names>N</given-names></name></person-group><article-title>Predicting or Pretending: Artificial Intelligence for Protein-Ligand Interactions Lack of Sufficiently Large and Unbiased Datasets</article-title><source>Frontiers in Pharmacology</source><year>2020</year><volume>11</volume><fpage>69</fpage><pub-id pub-id-type="pmcid">PMC7052818</pub-id><pub-id pub-id-type="pmid">32161539</pub-id><pub-id pub-id-type="doi">10.3389/fphar.2020.00069</pub-id></element-citation></ref><ref id="R26"><label>[26]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Volkov</surname><given-names>M</given-names></name><etal/></person-group><article-title>On the Frustration to Predict Binding Affinities from Protein–Ligand Structures with Deep Neural Networks</article-title><source>Journal of Medicinal Chemistry</source><year>2022</year><volume>65</volume><issue>11</issue><fpage>7946</fpage><lpage>7958</lpage><comment>PDBbind 2019</comment><pub-id pub-id-type="pmid">35608179</pub-id></element-citation></ref><ref id="R27"><label>[27]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Z</given-names></name><etal/></person-group><article-title>PDB-wide collection of binding data: current status of the PDBbind database</article-title><source>Bioinformatics</source><year>2015</year><volume>31</volume><issue>3</issue><fpage>405</fpage><lpage>412</lpage><pub-id pub-id-type="pmid">25301850</pub-id></element-citation></ref><ref id="R28"><label>[28]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kramer</surname><given-names>C</given-names></name><name><surname>Gedeck</surname><given-names>P</given-names></name></person-group><article-title>Leave-Cluster-Out Cross-Validation Is Appropriate for Scoring Functions Derived from Diverse Protein Data Sets</article-title><source>Journal of Chemical Information and Modeling</source><year>2010</year><volume>50</volume><issue>11</issue><fpage>1961</fpage><lpage>1969</lpage><pub-id pub-id-type="pmid">20936880</pub-id></element-citation></ref><ref id="R29"><label>[29]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Yang</surname><given-names>J</given-names></name></person-group><article-title>Structural and Sequence Similarity Makes a Significant Impact on Machine-Learning-Based Scoring Functions for Protein–Ligand Interactions</article-title><source>Journal of Chemical Information and Modeling</source><year>2017</year><volume>57</volume><issue>4</issue><fpage>1007</fpage><lpage>1012</lpage><pub-id pub-id-type="pmid">28358210</pub-id></element-citation></ref><ref id="R30"><label>[30]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mastropietro</surname><given-names>A</given-names></name><name><surname>Pasculli</surname><given-names>G</given-names></name><name><surname>Bajorath</surname><given-names>J</given-names></name></person-group><article-title>Learning characteristics of graph neural networks predicting protein–ligand affinities</article-title><source>Nature Machine Intelligence</source><year>2023</year><volume>5</volume><issue>12</issue><fpage>1427</fpage><lpage>1436</lpage><pub-id pub-id-type="doi">10.1038/s42256-023-00756-9</pub-id></element-citation></ref><ref id="R31"><label>[31]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harren</surname><given-names>T</given-names></name><etal/></person-group><article-title>Modern machine-learning for binding affinity estimation of protein–ligand complexes: Progress, opportunities, and challenges</article-title><source>Wiley Interdisciplinary Reviews: Computational Molecular Science</source><year>2024</year><volume>14</volume><issue>3</issue><pub-id pub-id-type="doi">10.1002/wcms.1716</pub-id></element-citation></ref><ref id="R32"><label>[32]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Dokholyan</surname><given-names>NV</given-names></name></person-group><article-title>Yuel: Improving the Generalizability of Structure-Free Compound–Protein Interaction Prediction</article-title><source>Journal of Chemical Information and Modeling</source><year>2022</year><volume>62</volume><issue>3</issue><fpage>463</fpage><lpage>471</lpage><pub-id pub-id-type="pmcid">PMC9203246</pub-id><pub-id pub-id-type="pmid">35103472</pub-id><pub-id pub-id-type="doi">10.1021/acs.jcim.1c01531</pub-id></element-citation></ref><ref id="R33"><label>[33]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Skolnick</surname><given-names>J</given-names></name></person-group><article-title>TM-align: a protein structure alignment algorithm based on the TM-score</article-title><source>Nucleic Acids Research</source><year>2005</year><volume>33</volume><issue>7</issue><fpage>2302</fpage><lpage>2309</lpage><pub-id pub-id-type="pmcid">PMC1084323</pub-id><pub-id pub-id-type="pmid">15849316</pub-id><pub-id pub-id-type="doi">10.1093/nar/gki524</pub-id></element-citation></ref><ref id="R34"><label>[34]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>Z</given-names></name><etal/></person-group><article-title>Evolutionary-scale prediction of atomic level protein structure with a language model</article-title><year>2022</year><pub-id pub-id-type="pmid">36927031</pub-id></element-citation></ref><ref id="R35"><label>[35]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elnaggar</surname><given-names>A</given-names></name><etal/></person-group><article-title>Ankh: Optimized Protein Language Model Unlocks General-Purpose Modelling</article-title><source>arXiv</source><year>2023</year><comment>eprint: 2301.06568</comment><pub-id pub-id-type="doi">10.48550/arxiv.2301.06568</pub-id></element-citation></ref><ref id="R36"><label>[36]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahmad</surname><given-names>W</given-names></name><etal/></person-group><article-title>ChemBERTa-2: Towards Chemical Foundation Models</article-title><source>arXiv</source><year>2022</year><comment>eprint: 2209.01712</comment><pub-id pub-id-type="doi">10.48550/arxiv.2209.01712</pub-id></element-citation></ref><ref id="R37"><label>[37]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duval</surname><given-names>A</given-names></name><etal/></person-group><article-title>A Hitchhiker’s Guide to Geometric GNNs for 3D Atomic Systems</article-title><source>arXiv</source><year>2023</year><comment>eprint: 2312.07511</comment><pub-id pub-id-type="doi">10.48550/arxiv.2312.07511</pub-id></element-citation></ref><ref id="R38"><label>[38]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bronstein</surname><given-names>MM</given-names></name><name><surname>Bruna</surname><given-names>J</given-names></name><name><surname>Cohen</surname><given-names>T</given-names></name><name><surname>Veličković</surname><given-names>P</given-names></name></person-group><article-title>Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges</article-title><year>2021</year></element-citation></ref><ref id="R39"><label>[39]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stokes</surname><given-names>JM</given-names></name><etal/></person-group><article-title>A Deep Learning Approach to Antibiotic Discovery</article-title><source>Cell</source><year>2020</year><volume>180</volume><issue>4</issue><fpage>688</fpage><lpage>702</lpage><elocation-id>e13</elocation-id><pub-id pub-id-type="pmcid">PMC8349178</pub-id><pub-id pub-id-type="pmid">32084340</pub-id><pub-id pub-id-type="doi">10.1016/j.cell.2020.01.021</pub-id></element-citation></ref><ref id="R40"><label>[40]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xiong</surname><given-names>J</given-names></name><etal/></person-group><article-title>Graph neural networks for automated de novo drug design</article-title><source>Drug Discovery Today</source><year>2021</year><volume>26</volume><issue>6</issue><fpage>1382</fpage><lpage>1393</lpage><pub-id pub-id-type="pmid">33609779</pub-id></element-citation></ref><ref id="R41"><label>[41]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shen</surname><given-names>H</given-names></name><etal/></person-group><article-title>A Cascade Graph Convolutional Network for Predicting Protein–Ligand Binding Affinity</article-title><source>International Journal of Molecular Sciences</source><year>2021</year><volume>22</volume><issue>8</issue><fpage>4023</fpage><comment>PDBbind 2016</comment><pub-id pub-id-type="pmcid">PMC8070477</pub-id><pub-id pub-id-type="pmid">33919681</pub-id><pub-id pub-id-type="doi">10.3390/ijms22084023</pub-id></element-citation></ref><ref id="R42"><label>[42]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Son</surname><given-names>J</given-names></name><name><surname>Kim</surname><given-names>D</given-names></name></person-group><article-title>Development of a graph convolutional neural network model for efficient prediction of protein-ligand binding affinities</article-title><source>PLoS ONE</source><year>2021</year><volume>16</volume><issue>4</issue><elocation-id>e0249404</elocation-id><comment>PDBbind 2016</comment><pub-id pub-id-type="pmcid">PMC8031450</pub-id><pub-id pub-id-type="pmid">33831016</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0249404</pub-id></element-citation></ref><ref id="R43"><label>[43]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brody</surname><given-names>S</given-names></name><name><surname>Alon</surname><given-names>U</given-names></name><name><surname>Yahav</surname><given-names>E</given-names></name></person-group><article-title>How Attentive are Graph Attention Networks?</article-title><source>arXiv</source><year>2021</year><comment>GATv2Conv eprint: 2105.14491</comment><pub-id pub-id-type="doi">10.48550/arxiv.2105.14491</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>Overview of the Similarity Computation Between Two Protein-Ligand Complexes</title><p>Our structure-based dataset filtering algorithm evaluates structural similarity using a three-step process: <bold>a)</bold> Tanimoto Similarity: The first layer of filtering assesses the chemical similarity between ligands using Tanimoto similarity scores. These scores, which range from 0 (no similarity) to 1 (identical), identify pairs of complexes with chemically similar ligands. <bold>b)</bold> TM-Align: The second layer applies TM-align [<xref ref-type="bibr" rid="R33">33</xref>], a computational tool designed to compare protein structures by finding the optimal alignment of their three-dimensional structures. The resulting TM-scores range from 0 (no similarity) to 1 (identical) and identify proteins with high structural similarity, even when sequence identity is low (e.g. when one protein is a substructure of the other). <bold>c)</bold> Pocket-aligned ligand RMSD: The final layer compares the positioning of ligands within aligned protein pockets. Ligands are transformed into the same coordinate frame using the optimal alignment from TM-align, and a root-mean-square-deviation (RMSD) calculation provides a quantitative measure of positional similarity. This three-layer approach effectively identifies complexes with similar interaction patterns, even when traditional sequence-based methods would overlook these similarities.</p></caption><graphic xlink:href="EMS201969-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Superpositions of Complexes Highlighting Train-Test Structural Similarities Before and After Filtering</title><p><bold>a)</bold> Superpositions of the most prominent train-test similarities before applying the filtering algorithm. <bold>b)</bold> Superpositions of the same test complexes as in a), now shown with the most similar training complexes found in PDB CleanSplit. <bold>c)</bold> Superpositions of the closest train-test similarities that remained post-filtering in the dataset PDB CleanSplit. Protein structures from the test and training datasets are depicted as grey and blue cartoons, respectively, with ligands shown in magenta (test) and green (train). Below each superposition, the Tanimoto score, TM-score, ligand RMSD, and affinity difference (ΔpK) is shown, which are combined into an overall similarity score <italic>S</italic> = TM-Score + Tanimoto + (1− Ligand RMSD) −ΔpK. Train-test pairs were selected from the top 10 pairs with the highest <italic>S</italic>, prioritizing good ligand visibility. In some superpositions (1O3F/1O3G, 3DD0/3DWC and 3DD0/3S73), one structure has been slightly shifted to enhance visibility of structural differences. Original PyMol sessions of all of superpositions are provided on GitHub.</p></caption><graphic xlink:href="EMS201969-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Prediction Accuracy of Pafnucy and GEMS in Dependence of Dataset Filtering</title><p><bold>a)</bold> Reported CASF2016 prediction RMSE values for all published deep-learning-based scoring functions (to our knowledge) that have evaluated their performance on the complete CASF2016 (n=285) dataset. The plot includes Pafnucy (retrained on the more recent 2020 version of PDBbind), our two search algorithms (“Search Top 5 Complexes” and “Search Top 5 Ligands”), and the scoring function of AutoDock Vina. As a baseline, the lowest bar shows the RMSE that is achieved when the average training dataset label is assigned to all CASF2016 complexes. <bold>b)</bold> Bar plot comparing the CASF2016 prediction RMSE values of a simple search algorithm (Search Top 5 Complexes), Pafnucy, and GEMS when trained on the original PDBbind dataset (left) and the filtered PDBbind CleanSplit dataset (right). <bold>c)</bold> Ranking power: The distribution of Spearman correlation coefficients for the search algorithm, Pafnucy, and GEMS across all 57 clusters of CASF2016, presented separately for training on PDBbind (left) and PDBbind CleanSplit (right). To ensure a fair comparison, Pafnucy and GEMS were trained using the same 5-fold cross-validation split (one for PDBbind and one for PDBbind CleanSplit). The reported performance values reflect the predictions of an ensemble comprising all five models from cross-validation, with error bars representing the standard deviation across CASF2016 results from the five folds.</p></caption><graphic xlink:href="EMS201969-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Graph-Based Modeling of Protein-Ligand Interactions and GEMS Model Architecture.</title><p><bold>a)</bold> Schematic overview of the graph construction process used to model protein-ligand complexes in a sparse, rotation- and translation-invariant graph representation enhanced with language model embeddings. The core of these graph representations consists of an atom-level molecular graph of the ligand molecule (magenta) combined with an amino acid-level graph of the protein pocket (green). Additional edges are introduced to connect ligand atom nodes to amino acid nodes based on spatial proximity, computed using a K-nearest neighbors algorithm. The amino-acid nodes are featurized with their type and embeddings derived from the protein language models ESM2 [<xref ref-type="bibr" rid="R34">34</xref>] and Ankh [<xref ref-type="bibr" rid="R35">35</xref>]. The ligand graph is featurized with atomic properties and a global context vector containing a ligand embedding from the language model ChemBERTa-2 [<xref ref-type="bibr" rid="R36">36</xref>]. <bold>b)</bold> GEMS model architecture for processing interaction graphs composed of node features, edge features, and global context features. After an initial node feature dimensionality reduction (Dim.Red.), node and edge features are transformed through an alternating sequence of node convolutions (GATConv) and edge convolutions (EdgeConv). The global graph features are dynamically updated throughout this process, incorporating pooled node representations after each node convolution. A final pK value prediction is made from the updated global features using a fully connected neural network.</p></caption><graphic xlink:href="EMS201969-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>Impact of Ablation and Dataset Filtering on GEMS Performance</title><p><bold>a)</bold> Ablation study showing the impact of removing all protein information from the graphs on CASF2016 (n=285) performance, comparing GEMS models trained on PDBbind (left) and PDBbind CleanSplit (right). <bold>b)</bold> Comparison of GEMS performance on cross-validation (CV), CASF2016, and the independent subset of CASF2016 (n=155) for models trained on PDBbind (left) and PDBbind CleanSplit (right). <bold>c)</bold> CASF2016 performance of GEMS with varying levels of training dataset filtering: complete dataset (PDBbind), train-test overlap removed, and both overlap and redundancy removed (PDBbind CleanSplit). Error bars represent data uncertainty, calculated as the standard deviation of the performance across five models trained with 5-fold cross-validation at different random seeds.</p></caption><graphic xlink:href="EMS201969-f005"/></fig><fig id="F6" position="float"><label>Figure 6</label><caption><title>Impact of Language Model Embeddings on GEMS Prediction Error (RMSE)</title><p><bold>a)</bold> Effect of incorporating language model embeddings on the CASF2016 (n=285) performance of GEMS models trained on the original PDBbind dataset. <bold>b)</bold> Effect of incorporating language model embeddings on the CASF2016 performance of GEMS models trained on PDBbind CleanSplit. Error bars represent data uncertainty, calculated as the standard deviation of the performance across five models trained with 5-fold cross-validation at different random seeds.</p></caption><graphic xlink:href="EMS201969-f006"/></fig></floats-group></article>