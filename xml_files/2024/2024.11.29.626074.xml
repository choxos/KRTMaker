<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS201581</article-id><article-id pub-id-type="doi">10.1101/2024.11.29.626074</article-id><article-id pub-id-type="archive">PPR947628</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">1</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Semi-automated navigation for efficient targeting of electron tomography to regions of interest in volume correlative light and electron microscopy</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Konishi</surname><given-names>Kohki</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><contrib contrib-type="author"><name><surname>Neves</surname><given-names>Guilherme</given-names></name><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Russell</surname><given-names>Matthew</given-names></name><xref ref-type="aff" rid="A4">4</xref></contrib><contrib contrib-type="author"><name><surname>Mimura</surname><given-names>Masafumi</given-names></name><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Burrone</surname><given-names>Juan</given-names></name><xref ref-type="aff" rid="A3">3</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><contrib contrib-type="author"><name><surname>Fleck</surname><given-names>Roland</given-names></name><xref ref-type="aff" rid="A4">4</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib></contrib-group><aff id="A1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/042j06y04</institution-id><institution>Nikon U.K.</institution></institution-wrap>, Branch of Nikon Europe B.V., Surrey, <country country="GB">United Kingdom</country></aff><aff id="A2"><label>2</label>Mathematical Science Research Laboratory, Nikon Corporation, Tokyo, Japan</aff><aff id="A3"><label>3</label>Centre for Developmental Neurobiology, Institute of Psychiatry, Psychology &amp; Neuroscience, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/0220mzb33</institution-id><institution>King’s College London</institution></institution-wrap>, <city>London</city>, <country country="GB">United Kingdom</country></aff><aff id="A4"><label>4</label>Centre for Ultrastructural Imaging, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/0220mzb33</institution-id><institution>King’s College London</institution></institution-wrap>, <city>London</city>, <country country="GB">United Kingdom</country></aff><author-notes><corresp id="CR1">
<label>*</label>Corresponding authors: <email>kohki.konishi@nikon.com</email>, <email>juan.burrone@kcl.ac.uk</email>, <email>roland.fleck@kcl.ac.uk</email></corresp></author-notes><pub-date pub-type="nihms-submitted"><day>01</day><month>12</month><year>2024</year></pub-date><pub-date pub-type="preprint"><day>30</day><month>11</month><year>2024</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nd/4.0/">CC BY-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Electron microscopy is essential for the quantitative study of synaptic ultrastructure. At present, the correlation of functional and structural properties of the same synapse is extremely challenging. We introduce a novel integrated workflow designed to simplify sample navigation across spatial scales, allowing the identification of individual synapses from optical microscopy mouse brain image stacks that can be targeted for analysis using electron tomography imaging. We developed a software which has a function to register multimodal images using a novel segmentation-based image registration algorithm as well as a function to visualize all the registration results. Using our newly designed software we streamline mapping of high-resolution optical imaging onto reference maps using blood vessels as endogenous fiducial marks. Further we demonstrate significant improvements on the ultramicrotomy stage of volume Correlative Light and Electron Microscopy (vCLEM) workflows, providing real time guidance to targeted trimming to match previously acquired Regions Of Interest (ROIs), and reliable estimates of cutting depth relative to ROI, based on fluorescence imaging of TEM ready ultrathin sections. Using this workflow, we successfully targeted TEM tomography to the proximal axonal region containing the Axon Initial Segment identified using fluorescent light microscopy.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">Electron microscopy (EM) has been a powerful tool for investigating the ultrastructure of cells and tissues. Volume EM (vEM), which enables three-dimensional (3D) ultrastructural analysis, has gained significant attention [<xref ref-type="bibr" rid="R1">1</xref>,<xref ref-type="bibr" rid="R2">2</xref>]. Block-face methods, such as serial block-face scanning electron microscopy (SBF-SEM; [<xref ref-type="bibr" rid="R3">3</xref>]) and focused ion beam scanning electron microscopy (FIB-SEM; [<xref ref-type="bibr" rid="R4">4</xref>]), are widely used for acquiring vEM data by sequentially imaging the surface of a sample block. SBF-SEM has yielded novel insights into development of synaptic ultrastructure [<xref ref-type="bibr" rid="R5">5</xref>,<xref ref-type="bibr" rid="R6">6</xref>]. Other volume methods include serial section electron microscopy (ssTEM), where serial sections are collected on grids and imaged using transmission electron microscopy (TEM; [<xref ref-type="bibr" rid="R7">7</xref>]). ssTEM and SBF-SEM have been extensively used in connectomics research to analyze neural circuit connectivity (e.g. [<xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R9">9</xref>]).</p><p id="P3">Volume correlative light and electron microscopy (vCLEM) enables the visualization of the ultrastructure of specific targets with known functional properties by volume imaging of fluorescently labeled cells or tissues (e.g. [<xref ref-type="bibr" rid="R10">10</xref>] reviewed by [<xref ref-type="bibr" rid="R11">11</xref>–<xref ref-type="bibr" rid="R13">13</xref>]). Recently, A workflow that performs multiplexed detergent-free immunolabeling and vCLEM on the same sample was developed by using mouse brain tissue [<xref ref-type="bibr" rid="R14">14</xref>]. However, navigation to the target of interest across different microscopy modalities and different scales remains labor-intensive.</p><p id="P4">Image registration is a crucial technique for navigation between microscopy images of the same structures across scales and imaging modalities. At each stage, alignment of an image from one modality and/or scale with another is needed so that one can be used as a reference to navigate to the same region of interest within the other. A range of registration approaches have been developed. One conventional method is for a user to manually identify landmark features that are visible in both images (eg cell nuclei). A transform of one image – rotation, translation, non-linear warping, etc. – can then be calculated so that corresponding landmark features are aligned when the image is overlaid onto the other one. This approach is enabled by tools such as Bigwarp [<xref ref-type="bibr" rid="R15">15</xref>] and ec-CLEM [<xref ref-type="bibr" rid="R16">16</xref>]. While these methods can achieve high accuracy, manual landmark selection process is labor-intensive. Consequently, automating multimodal image registration has been investigated. AutoCLEM was developed to automatically detect embedded beads and use them as landmarks for image warping [<xref ref-type="bibr" rid="R17">17</xref>]. Intensity-based image registration tools are freely provided as the Elastix toolbox [<xref ref-type="bibr" rid="R18">18</xref>,<xref ref-type="bibr" rid="R19">19</xref>] for medical image registration, implemented in a multi-modal big image data sharing and exploration viewer (MoBIE; [<xref ref-type="bibr" rid="R20">20</xref>]), and applied to align DAPI signals with segmented nuclear masks from EM images, enabling the identification of cells corresponding to gene expression [<xref ref-type="bibr" rid="R21">21</xref>]. Moreover, combination of segmentation and point cloud matching was developed to automatically establish correspondences between two images [<xref ref-type="bibr" rid="R22">22</xref>].</p><p id="P5">Recent years have seen a surge in research on efficient navigation workflows to fluorescently labeled targets for vEM. One approach involves acquiring light microscopy images of fluorescently labeled cells, followed by resin embedding and vEM imaging using the ‘approach and correlation’ method [<xref ref-type="bibr" rid="R23">23</xref>]. Another workflow embeds the sample in resin, then iteratively performs light microscopy imaging and stepwise trimming to navigate to fluorescently labeled cells for FIB-SEM imaging [<xref ref-type="bibr" rid="R24">24</xref>,<xref ref-type="bibr" rid="R25">25</xref>]. A third approach incorporates x-ray micro-CT imaging between light microscopy and vEM imaging [<xref ref-type="bibr" rid="R26">26</xref>–<xref ref-type="bibr" rid="R29">29</xref>]. Additionally, a workflow integrating a motorized ultramicrotome with x-ray micro-CT imaging has been proposed [<xref ref-type="bibr" rid="R30">30</xref>]. This approach also requires access to x-ray micro-CT.</p><p id="P6">In this paper we present a novel integrated workflow for vCLEM that uses in resin fluorescence signals to allow navigation of millimetre sized resin embedded mouse brain tissue blocks and specific targeting of sub-micrometre sized regions containing synaptic structures for TEM tomography. Our strategy starts with the creation of a reference map using fluorescence microscopy confocal stacks encompassing the entire tissue block. Regions Of Interest (ROIs) are then imaged at higher resolution and mapped onto the reference map using a newly created user-friendly software based on napari (NavROI) that simplifies registering and display of imaging datasets acquired with different imaging modalities. Previously acquired confocal images can be registered in real time with the video signal of the ultramicrotome camera to simplify the process of sample trimming in the X-Y dimension. Further, we show that the fluorescence of ultrathin (200 nm) sections can be mapped with the reference to produce reliable estimates of section Z depth. We used this approach to target TEM tomography to the proximal axonal region containing the Axon Initial Segment fluorescently labelled with a viral approach.</p></sec><sec id="S2" sec-type="results"><title>Results</title><sec id="S3"><title>Integrated workflow</title><p id="P7">We developed an integrated workflow of navigating ROIs for volume CLEM. <xref ref-type="fig" rid="F1">Figure 1(A)</xref> shows its overview. The workflow integrates imaging and computation across spatial scales, from light microscopy (LM) imaging of sub-millimeter scale to highlighting individual subcellular structure, to transmission electron microscopy (TEM) tomogram imaging of nanometer scale structures. The computation consists of two algorithms to register pairs of images in different modalities and/or scales, to facilitate navigation through them. The two algorithms are, 1) a novel segmentation-based image registration algorithm shown in <xref ref-type="fig" rid="F1">Figure 1(B)</xref>, which is described in the next section, and 2) a conventional landmark-based image registration algorithm.</p><p id="P8">The workflow starts with a resin block containing brain tissue with fluorescently tagged markers (<xref ref-type="fig" rid="F1">Figure 1(A)</xref>). We initially identified regions of interest (ROIs) within the block by microscopy of the fluorescent markers, and trimmed the sides of the block to those ROIs. To direct this trimming process we needed to be able to identify the lateral position of those regions when viewing the block surface in the ultramicrotome. We therefore registered pairs of images that could be used to navigate between the ROIs within the block and the view of the full surface of the block.</p><p id="P9">We first acquired a full-width fluorescence microscopy (FM) image stack of the resin block (Block FM, <xref ref-type="fig" rid="F1">Figure 1</xref>). The regions of interest (ROIs) were visually identified and subsequently imaged at higher resolution (ROI FM, <xref ref-type="fig" rid="F1">Figure 1</xref>). To spatially register these image datasets, we generated a three-dimensional map of the ROI locations within the entire block through segmentation-based image registration (ROI FM locations map, <xref ref-type="fig" rid="F1">Figure 1</xref>). Since FM features within the block are not visible in the ultramicrotome stereomicroscope, a DIC image of the full surface of the resin block was also acquired at this point to relate the FM ROIs to the surface view in the ultramicrotome (Surface DIC map, <xref ref-type="fig" rid="F1">Figure 1</xref>). A maximum intensity projection (MIP) of the ROI FM locations map (ROI FM locations MIP map, <xref ref-type="fig" rid="F1">Figure 1</xref>) was then generated. Landmark-based image registration was then employed to register the ROI FM locations MIP map with the Surface DIC map, essentially resulting in a projection of the lateral positions of the ROIs onto the surface view of the block (Surface DIC-ROI FM locations MIP map, <xref ref-type="fig" rid="F1">Figure 1</xref>).</p><p id="P10">The subsequent step involved guiding the lateral trimming of the block during ultramicrotomy. The ultramicrotome camera view of the block was acquired and registered with the Surface DIC-ROI FM locations MIP map through landmark-based image registration. This process enabled the overlay of the projected lateral ROI locations onto the ultramicrotome camera view. By referencing this overlay during the trimming process, we optimized mesa trimming by removing material outside the ROI FM.</p><p id="P11">We then proceeded with sectioning into the trimmed mesa to find sections at the depth of the ROI FMs. To find the sections at the correct depth, we collected sections onto cover slips and imaged using FM (Sections FM, in <xref ref-type="fig" rid="F1">Figure 1</xref>). We defined the depth of each section as the depth corresponding to the optimal segmentation-based image registration between Section FM and Block FM. By this method we could estimate the depth of each section within the Block FM, and then relate this to the ROI FM locations. Thus, the sections whose estimated cutting depth matches the depth of the ROI FMs in the ROI FM locations map could be selected for subsequent correlative TEM imaging of those ROIs.</p><p id="P12">The final step involved targeting TEM tomography to specific ROIs identified in the high resolution ROI FM image stacks. TEM images of the whole of selected sections (Section TEM map, <xref ref-type="fig" rid="F1">Figure 1</xref>) were acquired. Within these images, specific ROIs were located and targeted for higher magnification TEM imaging (ROI TEM map, <xref ref-type="fig" rid="F1">Figure 1</xref>). Segmentation-based image registration was employed to register the ROI TEM map with the ROI FM map, enabling the overlay of target positions onto the ROI TEM map. TEM tomography was then performed at the target positions. Through the same image registration method, the ROI FM was successfully registered with the TEM tomogram. If all the steps are performed without interruption, the average duration of this workflow is roughly 1 week.</p></sec><sec id="S4"><title>Segmentation-based image registration for multimodal images</title><p id="P13">We developed a segmentation-based image registration algorithm for registering pairs of multimodal images such as images acquired from different microscopy modalities and/or scales. <xref ref-type="fig" rid="F1">Figure 1(B)</xref> presents a flowchart illustrating the algorithm. One image serves as the reference image (Image A in <xref ref-type="fig" rid="F1">Figure 1B</xref>), while the other serves as the moving image (Image B in <xref ref-type="fig" rid="F1">Figure 1B</xref>). The algorithm primarily consists of two primary components: object segmentation and image registration.</p><p id="P14">For object segmentation, we employed automated or user-assisted techniques to segment objects that are frequently present in both images. Segmentation masks were subsequently converted into labels via connected component labeling. Examples of such common objects include blood vessels, cell nuclei, and neurons.</p><p id="P15">During image registration, we selected the registration that yielded the highest mutual information (MI) metric. To achieve this, we randomly generated affine transformation parameters, warped the moving image, and computed the MI values between the labels from images A and B.</p></sec><sec id="S5"><title>ROI navigation tool</title><p id="P16">To streamline the integrated workflow, we developed a ROI navigation tool, navROI, using napari that displays the spatial relationships between multiple images. The images can be multiple image stacks, multiple section images, or their mixture. The tool accepts the paths of the images and their registration parameters and displays their locations relative to the largest field-of-view image.</p></sec><sec id="S6"><title>Implementation of the integrated workflow to mouse brain tissue</title><p id="P17">We applied the integrated workflow to a resin block in which mouse brain tissue was embedded.</p><sec id="S7"><title>Mapping the ROI FM to the Block FM</title><p id="P18"><xref ref-type="fig" rid="F2">Figure 2(A)</xref> shows an example of ROI FMs of mouse brain tissue. Neurons are shown in cyan, synapses in green, blood vessels in red, and nuclei in blue. The neuron centered in the ROI FM is surrounded by distinctive blood vessels. Three points of the blood vessel structures are indicated by five arrowheads. Since the blood vessel structure is diverse, we used the blood vessel channel to map the ROI FM locations to the Block FM. The region containing the ROI FM is highlighted in the white box and its volume rendering is shown in the inset. The five green arrowheads in panel (B) are the corresponding points in panel (A).</p><p id="P19">To map the ROI FM to the Block FM, we utilized image registration and visualization techniques. Segmentation-based image registration was employed to determine the optimal registration parameters between these two image stacks. Subsequently, we utilized navROI for visualization by inputting the file paths of the ROI FM, Block FM, and the optimal registration parameters.</p><p id="P20"><xref ref-type="fig" rid="F2">Figures 2(C)</xref> and <xref ref-type="fig" rid="F2">2(D)</xref> present screenshots of the navROI interface. <xref ref-type="fig" rid="F2">Figure 2(C)</xref> displays its Z-plane view, where the ROI FM region is highlighted with a cyan-colored box, the neuron channel of the ROI FM is visualized, and the blood vessel channel of the Block FM is also visualized in red. A zoomed-in view of the white box surrounding the ROI FM is shown in the lower right corner. <xref ref-type="fig" rid="F2">Figure 2(D)</xref> illustrates the Y-plane view of the navROI, with the upper panel showing an overall view and the lower panel showing a zoomed-in view of the white box around the ROI FM.</p><p id="P21"><xref ref-type="fig" rid="F2">Figure 2(E)</xref> depicts a screenshot of a bird’s-eye view generated by navROI, enabling visualization of the mapping the ROI FM region in cyan to the Block FM region in red. This visualization is utilized for lateral trimming of blocks and section selection, as detailed below.</p></sec><sec id="S8"><title>Guiding the lateral trimming of the block during ultramicrotomy</title><p id="P22">We optimized trimming of the block mesa by overlaying ROI FM locations onto the ultramicrotome (UC) view of the block. <xref ref-type="fig" rid="F3">Figure 3(A)</xref> illustrates a schematic of the UC system, with the camera view displayed on the top screen. <xref ref-type="fig" rid="F3">Figure 3(B)</xref> presents a UC camera view of the block before trimming. Three landmarks of the block corners are marked with blue arrowheads. <xref ref-type="fig" rid="F3">Figure 3(C)</xref> shows a Surface DIC map of the block. The landmarks corresponding to those in panel (B) are indicated by blue arrowheads, while three blood vessel landmarks are marked with red arrowheads. <xref ref-type="fig" rid="F3">Figure 3(D)</xref> displays a ROI locations MIP map. The five ROI locations are highlighted as green rectangles, and the three landmarks of the blood vessel corner locations corresponding to those in panel (C) are marked with red arrowheads. Since the surface DIC map is registered with the ROI FM locations MIP map, we obtained an overlay of ROI locations on the UC camera view. <xref ref-type="fig" rid="F3">Figure 3(E)</xref> shows the overlay where the trimming region enclosing all the ROIs is highlighted in pink. We trimmed away materials outside of the pink polygonal region using this overlay as a guide. <xref ref-type="fig" rid="F3">Figure 3(F)</xref> shows an UC camera view of the trimmed block.</p></sec><sec id="S9"><title>Estimating cutting depth of sections</title><p id="P23">We estimated cutting depth of sections by reading the depth from the Block FM surface at the point of optimal image registration between Section FM and Block FM through segmentation-based image registration. <xref ref-type="fig" rid="F4">Figure 4(A)</xref> shows a local region of blood vessel channel image of Section FM, with the full section shown in the inset. We focused image registration analysis to the local region of a few hundred-micron size to mitigate non-linear distortions in the Section FM. Subsequently, we utilized navROI for the mapping process by inputting the file paths of the entire Section FM, its local region, Block FM, and the optimal registration parameters.</p><p id="P24"><xref ref-type="fig" rid="F4">Figures 4(B)</xref> and <xref ref-type="fig" rid="F4">4(C)</xref> present screenshots of the navROI interface. <xref ref-type="fig" rid="F4">Figure 4(B)</xref> displays its Z-plane view, where the Section FM and its local region are highlighted with white boxes, and the blood vessel channel of the Block FM is visualized in red. <xref ref-type="fig" rid="F4">Figure 4(C)</xref> illustrates the Y-plane view of the navROI. This view visualizes the depth of the Section FM from the surface of the Block FM.</p><p id="P25"><xref ref-type="fig" rid="F4">Figure 4(D)</xref> compares the cutting depths of the six sections relative to the block surface with the corresponding feeding values from the UC. Section FMs were used to generate first two points nearest to the block surface and Section TEM maps were used to generate the remaining points. The green region indicates the depth range estimated from registering the ROI FM in the Block FM. A diagonal line with a slope of 1 is also plotted for reference. Linear regression analysis of the plot yielded a slope of 0.85 and an intercept of 3.00 micron. The first two sections closest to the block surface are labeled i and ii in the plot.</p><p id="P26"><xref ref-type="fig" rid="F4">Figure 4(E)</xref> provides detailed process of the image registration for the Section FM labeled i and ii. The left panel displays the entire Section FM, with the local region used for registration highlighted in white rectangles. Note that the center of the Section FM contains no resin, as indicated by the dotted red circles. The middle panel shows a zoomed-in view of the local region in the left panel. This local region was utilized for image registration. The right panel presents the optimal image registration result between the Section FM and the Block FM. The section image is depicted in gray, while the corresponding region of the Block FM is shown in red.</p></sec></sec><sec id="S10"><title>Targeting TEM tomography to specific ROIs in FM images</title><p id="P27">In the previous sections, we utilized blood vessels in navigating ROIs. Here, we show navigation from the FM ROI to targeted TEM tomography of targets along an axon identified within the FM ROI using nuclei and neurons.</p><p id="P28"><xref ref-type="fig" rid="F5">Figure 5(A)</xref> presents a Section TEM map with an overlaid ROI FM. The ROI FM is marked by a cyan box. A neuron is shown in cyan, and nuclei in blue. A white box emphasizes a region containing the axon, which is encircled by three nuclei indicated by yellow arrowheads.</p><p id="P29"><xref ref-type="fig" rid="F5">Figure 5(B)</xref> presents a volume rendering of the axon segmented from the ROI FM and the ROI TEM map, shown in cyan and white, respectively. Segmentation of synapses along the axon of the neuron and a blob in the axon initial segment (AIS) from the ROI FM are shown in green. These are the TEM tomography targets and are further emphasized by white rectangles labeled i or ii. Additionally, nuclei segmentation from the ROI FM are rendered in blue with yellow arrowheads.</p><p id="P30">To reconstruct the axon from serial ROI TEM maps, these maps should be registered. We registered each ROI TEM map to the FM Block using segmentation-based image registration algorithm. <xref ref-type="fig" rid="F5">Figure 5(C)</xref> presents a volume rendering of the FM Block, highlighting neurons and nuclei in cyan and blue. The two target regions are outlined by white rectangles. <xref ref-type="fig" rid="F5">Figure 5(D)</xref> shows an example ROI TEM map, overlaying neuron and nuclei segmentations in cyan and blue. <xref ref-type="fig" rid="F5">Figure 5(E)</xref> demonstrates optimal image registration between panels (C) and (D). By examining <xref ref-type="fig" rid="F5">Figure 5(E)</xref>, we segmented the axon from the ROI TEM map. Repeating this registration process for all ROI TEM maps achieved axon segmentation and subsequent reconstruction.</p><p id="P31">To identify targets in ROI TEM maps, we performed non-linear image registration between adjacent ROI TEM maps by focusing on the local region of a few ten-micron size containing targets. This additional step was necessary because the initial linear image registration was not sufficient to trace the axon across adjacent ROI TEM maps due to residual non-linear registration errors. By employing non-linear image registration, we overlaid the fluorescent signal of targets onto the ROI TEM maps. After non-linear image registration, we proceeded to acquire TEM tomograms.</p><p id="P32">We registered the FM Block to TEM tomograms through segmentation-based image registration as illustrated in <xref ref-type="fig" rid="F5">Figure 5(F)</xref>. Zoomed-in regions of ROI FM are shown in the left panel, alongside corresponding TEM tomograms with segmentation overlays, the middle panel, and optimal image registrations, the right panel. Upper panels depict the synapses in the axon, while lower panels show the AIS blob.</p></sec></sec><sec id="S11" sec-type="discussion"><title>Discussion</title><sec id="S12"><title>Efficient navigation of ROIs using integrated vCLEM workflow</title><p id="P33">vCLEM offers unparalleled potential for exploring biological structures. Image registration techniques between light and electron microscopy images have been developed by several authors [<xref ref-type="bibr" rid="R15">15</xref>,<xref ref-type="bibr" rid="R16">16</xref>] and a central challenge in vCLEM has been the efficient navigation of ROIs across multimodal and multiscale images. Here we report an integrated vCLEM workflow with a novel image registration algorithm as well as a napari-based user-friendly visualization tool that simplifies the navigation from confocal microscopy images of the tissue block to high-resolution TEM tomography of the tissue sections. Our integrated workflow significantly improves both of robustness and efficiency of ROI navigation for vCLEM analysis.</p></sec><sec id="S13"><title>Robust, real-time ROI navigation with segmentation-based image registration</title><p id="P34">Robust and real-time image registration algorithms are crucial for ROI navigation. Conventional methods demand manual landmark correspondence between reference and moving images, a time-consuming task. To streamline this process, automated registration methods have been developed [<xref ref-type="bibr" rid="R17">17</xref>,<xref ref-type="bibr" rid="R22">22</xref>,<xref ref-type="bibr" rid="R31">31</xref>]. However, these methods often assume that both images are acquired from the same region, which may not be feasible in scenarios like serial section high-resolution TEM imaging.</p><p id="P35">Our novel image registration algorithm addresses this limitation by enabling immediate registration after acquiring a single image of a section, eliminating the need to wait for the entire series. By leveraging GPU acceleration for efficient mutual information (MI) computation, we achieve real-time performance. This allows for daytime imaging and same-night registration, providing timely feedback for informed decision-making. The next morning, users can decide whether to proceed with the planned imaging depth or adjust the number of sections to reach the desired ROI. This real-time capability enhances the robustness and efficiency of ROI selection. While we employed segmentation for image registration, generative adversarial network-based approaches [<xref ref-type="bibr" rid="R32">32</xref>] might also be applied to multi-modal image stack registration.</p><p id="P36">Multi-modal image registration algorithms have been extensively studied in medical imaging. For images where intensity values are positively correlated, such as MRI and CT images, MI has proven effective [<xref ref-type="bibr" rid="R33">33</xref>,<xref ref-type="bibr" rid="R34">34</xref>]. Segmentation-based approaches have been proposed for registering T1 and T2 MRI images [<xref ref-type="bibr" rid="R35">35</xref>]. Algorithms for image stack registration have also been actively explored [<xref ref-type="bibr" rid="R36">36</xref>].</p><p id="P37">Inspired by advancements in medical imaging, we propose a segmentation-based image registration method for vCLEM. Given the extensive research on segmenting light microscopy and TEM images [<xref ref-type="bibr" rid="R37">37</xref>], our method leverages these developments. We focused on segmenting key organelles: blood vessels, cell nuclei, and neurons. Blood vessel segmentation can be accomplished using either simple thresholding or machine learning techniques. For cell nuclei, we employed SAM, but Cellpose 2 [<xref ref-type="bibr" rid="R38">38</xref>] can be an option. Neuron segmentation can benefit from machine learning technique [<xref ref-type="bibr" rid="R39">39</xref>–<xref ref-type="bibr" rid="R41">41</xref>].</p></sec><sec id="S14"><title>Seamless navigation of multiscale vCLEM images using ROI navigation viewer</title><p id="P38">We developed a specialized viewer for intuitive navigation of image registration results. This tool empowers users to: <list list-type="order" id="L1"><list-item><p id="P39">Visualize 3D relationships: Grasp the spatial context of ROIs within the entire block after LM imaging and registration.</p></list-item><list-item><p id="P40">Optimize block trimming: Minimize block size by accurately locating ROIs on the ultramicrotome camera view, maximizing section count per grid slot.</p></list-item><list-item><p id="P41">Estimate cutting depth: Visually assess the proximity of the latest section to the ROI depth.</p></list-item><list-item><p id="P42">Trace ultrastructure: Seamlessly navigate between ROI FM and ROI TEM maps to explore intricate 3D details, such as axons.</p></list-item></list> Our method extends the capabilities of Fiji’s Correlia plugin [<xref ref-type="bibr" rid="R42">42</xref>] into the third dimension.</p></sec><sec id="S15"><title>Analysis of cutting depth estimation</title><p id="P43">We observed a strong linear correlation between the estimated depths of sections and their corresponding feeding values. This linear relationship supports the validity of using image registration to estimate cutting depth. Deviations were noted in deeper regions, potentially due to the decreased contrast in TEM images. For these regions, we utilized Section TEM maps for image registration. The reduced contrast in these deeper Section TEM maps can introduce uncertainties in segmentation and shape determination.</p><p id="P44">Depth estimation based on image registration contains inherent uncertainty, arising from both the object’s structural complexity and the imaging system’s limitations. For cylindrical objects aligned with the depth axis, especially those with minimal thickness variation, accurate depth estimation is particularly challenging. In images captured with a long depth-of-focus objective lens, objects can appear stretched in the depth dimension within the image stack. Considering these factors, we estimate the depth uncertainty to be approximately 2 micrometers.</p></sec><sec id="S16"><title>Comparison of the motorized ultramicrotome approach for targeted sectioning</title><p id="P45">The motorized ultramicrotome leverages x-ray micro-CT data to automatically section blocks to a specific target plane. This automation streamlines the ultramicrotomy process, albeit requiring access to x-ray micro-CT. In contrast, the integrated workflow eliminates this need. Cutting depths of sections were estimated using Section FMs and Section TEM maps, however, this strategy can be applied to sections without fluorescence by using completely Section TEM maps for depth estimation, making our workflow a viable option for targeted vCLEM.</p></sec></sec><sec id="S17" sec-type="materials | methods"><title>Materials and methods</title><sec id="S18"><title>Viral injections and transcardial perfusion fixation</title><p id="P46">C57BL/6J male mice were used for all experiments. At P1-P2 pups were anaesthetized with Iso-fluorane and intra-cortically injected with 1 ul of a viral solution containing (AAV-EF1A-Gephyrin.FingR-GFP-CCR5TC – Addgene#125692 and AAV-CAG-tdTomato - Addgene# 59462) into layers 2/3 using a Drummond Nanojet microinjector according to the manufacturer’s protocol.</p><p id="P47">Injected mice were perfused transcardially at P21. A lethal dose of Sodium Pentobarbitone was intraperitoneally injected into pups, prior to perfusion with saline (0.05% in dH2O) via a peristaltic pump (Miniplus 3, Gilson) and 30G x ½ inch needle. Perfusate was switched to formaldehyde (4% in 175 mM sodium phosphate buffer (high osmolarity PB). once the liver had blanched. Perfused mice were decapitated, and brains postfixed in the same solution (10–12 h). Fixed brains were sliced into 100 µm coronal sections using a vibratome (Leica VT10005), and then were stored in regular osmolarity PBS (supplemented with 0.05% NaN3).</p></sec><sec id="S19"><title>Immunolabelling</title><p id="P48">Cortical regions containing infected neurons were incubated for 2-h in a blocking buffer (10% goat serum, 5% BSA in high osmolarity PB). They were then incubated overnight with primary antibody against GFP at dilution of 1:1000 in antibody solution (5% goat serum, 1% BSA in high osmolarity PB). Following three 5 minute washes in high osmolarity PB, slices were incubated for 1 h (RT) with nanobody at a dilution of 1:500 (FluoTag-X4 anti-RFP AZDye568; Nanotag Biotechnologies) and secondary antibodies (Anti-Chicken 488, Invitrogen) at a dilution of 1:1000 in antibody solution and rinsed with PBS (4 times 10 min each). Finally, sections were incubated in 1:200 dilution of Lycopersicon Esculentum Lectin (LEL), DyLight649 (Vector Laboratories) and DAPI (1 ug/ml) in PBS for 30 mins at RT.</p></sec><sec id="S20"><title>Confocal microscopy</title><p id="P49">Resin embedded tissue blocks were imaged either a Nikon AX-R NSPARC or a SoRA confocal microscope using a custom built imaging chamber. Low magnification reference stacks were imaged using 20 X air objectives using the 405, 488 nm, 543 nm and 650 nm laser lines and collected with the appropriate emission filters. Higher resolution image stacks were obtained using a 60X oil immersion objective.</p><p id="P50">Ultrathin sections (200-300 nm) were either collected onto glass slides or collected in slot grids and placed onto 35 mm plastic petri dishes containing PBS. They were imaged using an inverted confocal Nikon AX-R NSPARC.</p></sec><sec id="S21"><title>EM sample preparation</title><p id="P51">EM sample preparation was performed by following a previous article [<xref ref-type="bibr" rid="R25">25</xref>]: Samples were frozen with polyvinylpyrrolidone as a cryoprotectant, in an EM ICE high pressure freezer (Leica). Freeze substitution and resin embedding were performed in an automated AFS2 machine (Leica), using the freeze substitution processor unit. To facilitate the infiltration of Lowicryl HM20 (Polysciences Inc), the temperature was gradually raised to −25°C while increasing the resin concentration in acetone, and the samples were UV polymerized at −25°C through to +25°C.</p></sec><sec id="S22"><title>Ultramicrotomy</title><p id="P52">Blocks were sectioned using a UC7 (Leica, Wetzlar, Germany). Section thickness was 200 nm. Feeding values was recorded for cutting each section.</p></sec><sec id="S23"><title>TEM imaging</title><sec id="S24"><title>Section TEM map</title><p id="P53">The entire section was imaged using a transmission electron microscope (TEM) JEM-1400 Flash (Jeol, Tokyo, Japan) with acceleration voltage of 80 kV, with Limitless Panorama montaging software. Typical montage size was 400 x 400 µm<sup>2</sup>. The pixel size (X/Y) was 340 nm.</p></sec><sec id="S25"><title>ROI TEM map</title><p id="P54">The region round the ROI was imaged by TEM as above, except typical size was 70 × 100 µm<sup>2</sup>. The pixel size (X/Y) was 3.4 nm.</p></sec><sec id="S26"><title>TEM tomography</title><p id="P55">The regions round the ROI were imaged using either a JEM-1400 Flash (Jeol, Tokyo, Japan) TEM with accelerating voltage of 120 kV or a JEM-F200 TEM with a DE16 camera, at 200 kV. Tilt series were acquired using SerialEM [<xref ref-type="bibr" rid="R43">43</xref>]. The typical size was 4 x 4 x 0.2 µm<sup>3</sup> volume. Voxel size was 1.8 nm or 0.94 nm, respectively. The tomograms were reconstructed using IMOD [<xref ref-type="bibr" rid="R44">44</xref>,<xref ref-type="bibr" rid="R45">45</xref>] software.</p></sec></sec><sec id="S27"><title>Image preprocessing for registration</title><p id="P56">Prior to applying for segmentation-based image registration, pixel resolutions of images were matched using Fiji. All the image processing was performed using the NVIDIA A5000 graphics processing unit.</p><p id="P57">For Section FMs, raw image stacks were MIP projected after drift in Z direction was corrected using Correct 3D Drift plugin [<xref ref-type="bibr" rid="R46">46</xref>].</p><p id="P58">For non-linear image registration between adjacent ROI TEM maps, approximately 30 corresponding points were manually identified and registered using bUnwarpJ plugin [<xref ref-type="bibr" rid="R47">47</xref>].</p></sec><sec id="S28"><title>Segmentation</title><sec id="S29"><title>Blood vessels</title><p id="P59">Image binarization was used in light microscopy images. The threshold for binarization was determined using the maximum entropy method.</p></sec><sec id="S30"><title>Cell nuclei</title><p id="P60">Cell nuclei segmentation algorithms have been actively proposed for both light and TEM images. The SAMJ plugin [<xref ref-type="bibr" rid="R48">48</xref>] in Fiji [<xref ref-type="bibr" rid="R49">49</xref>] was used. The SAM plugin [<xref ref-type="bibr" rid="R50">50</xref>] in napari [<xref ref-type="bibr" rid="R51">51</xref>] can also be used. Users identify cell nuclei while viewing light microscopy images and annotate boxes around the identified nuclei. Using the annotated boxes as a prompt, the algorithm segments the cell nuclei.</p></sec><sec id="S31"><title>Neurons</title><p id="P61">Image binarization was used for light microscopy images. The threshold for binarization was determined using the maximum entropy method. Manual segmentation was performed for TEM images.</p></sec><sec id="S32"><title>Synapses</title><p id="P62">Image binarization was used for light microscopy images. The threshold for binarization was determined using the maximum entropy method. Manual segmentation of presynaptic boutons was performed for TEM tomograms.</p></sec></sec></sec></body><back><ack id="S33"><title>Acknowledgements</title><p>We would like to thank Pedro Machado for help in development of methods for high pressure freezing and freeze substitution and very useful advice for analysis. We would also like to thank all the members of Burrone lab for useful feedback and comments on the manuscript, and Satoshi Takahashi, Kazuhiro Kido, Erika Kanematsu, Masataka Murakami, and Tetsuya Koike of Nikon Corporation for support. Finally, we would like to thank the Nikon Imaging Centre at Kings College London for help with light microscopy. This research was funded in whole, or in part, by the Wellcome Trust (Grant No. 215508/Z/19/Z to JB). This research was also supported by the European Research Council (692659), the British Heart Foundation (CH/11/3/29051 and RG/16/15/32294), the Fondation Leducq (RA15CVD04).</p></ack><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peddie</surname><given-names>JC</given-names></name><name><surname>Genoud</surname><given-names>C</given-names></name><name><surname>Anna</surname><given-names>K</given-names></name><name><surname>Meechan</surname><given-names>K</given-names></name><name><surname>Kristina</surname><given-names>MD</given-names></name><name><surname>Kedar</surname><given-names>N</given-names></name><name><surname>Pape</surname><given-names>C</given-names></name><name><surname>Robert</surname><given-names>Parton G</given-names></name><name><surname>Nicole</surname><given-names>SL</given-names></name><name><surname>Yannick</surname><given-names>S</given-names></name><name><surname>Benjamin</surname><given-names>T</given-names></name><etal/></person-group><article-title>Volume electron microscopy</article-title><source>Nat Rev</source><year>2022</year><volume>1</volume><fpage>2</fpage><lpage>51</lpage><pub-id pub-id-type="pmcid">PMC7614724</pub-id><pub-id pub-id-type="pmid">37409324</pub-id><pub-id pub-id-type="doi">10.1038/s43586-022-00131-9</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collinson</surname><given-names>LM</given-names></name><name><surname>Bosch</surname><given-names>C</given-names></name><name><surname>Bullen</surname><given-names>A</given-names></name><name><surname>Burden</surname><given-names>JJ</given-names></name><name><surname>Carzaniga</surname><given-names>R</given-names></name><name><surname>Cheng</surname><given-names>C</given-names></name><name><surname>Darrow</surname><given-names>MC</given-names></name><name><surname>Fletcher</surname><given-names>G</given-names></name><name><surname>Johnson</surname><given-names>E</given-names></name><name><surname>Narayan</surname><given-names>K</given-names></name><name><surname>Peddie</surname><given-names>CJ</given-names></name><etal/></person-group><article-title>Volume EM: a quiet revolution takes shape</article-title><source>Nat Methods</source><year>2023</year><volume>20</volume><fpage>777</fpage><lpage>782</lpage><pub-id pub-id-type="pmcid">PMC7614633</pub-id><pub-id pub-id-type="pmid">37076630</pub-id><pub-id pub-id-type="doi">10.1038/s41592-023-01861-8</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Denk</surname><given-names>W</given-names></name><name><surname>Horstmann</surname><given-names>H</given-names></name></person-group><article-title>Serial block-face scanning electron microscopy to reconstruct three-dimensional tissue nanostructure</article-title><source>PLoS Biol</source><year>2004</year><volume>2</volume><fpage>1900</fpage><lpage>1909</lpage><pub-id pub-id-type="pmcid">PMC524270</pub-id><pub-id pub-id-type="pmid">15514700</pub-id><pub-id pub-id-type="doi">10.1371/journal.pbio.0020329</pub-id></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knott</surname><given-names>G</given-names></name><name><surname>Rosset</surname><given-names>S</given-names></name><name><surname>Cantoni</surname><given-names>M</given-names></name></person-group><article-title>Focussed ion beam milling and scanning electron microscopy of brain tissue</article-title><source>J Vis Exp</source><year>2011</year><fpage>3</fpage><lpage>6</lpage><pub-id pub-id-type="pmcid">PMC3196160</pub-id><pub-id pub-id-type="pmid">21775953</pub-id><pub-id pub-id-type="doi">10.3791/2588</pub-id></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rigby</surname><given-names>M</given-names></name><name><surname>Grillo</surname><given-names>FW</given-names></name><name><surname>Compans</surname><given-names>B</given-names></name><name><surname>Neves</surname><given-names>G</given-names></name><name><surname>Gallinaro</surname><given-names>J</given-names></name><name><surname>Nashashibi</surname><given-names>S</given-names></name><name><surname>Horton</surname><given-names>S</given-names></name><name><surname>Pereira Machado</surname><given-names>PM</given-names></name><name><surname>Carbajal</surname><given-names>MA</given-names></name><name><surname>Vizcay-Barrena</surname><given-names>G</given-names></name><name><surname>Levet</surname><given-names>F</given-names></name><etal/></person-group><article-title>Multi-synaptic boutons are a feature of CA1 hippocampal connections in the stratum oriens</article-title><source>Cell Rep</source><year>2023</year><volume>42</volume><fpage>1</fpage><lpage>15</lpage><pub-id pub-id-type="pmcid">PMC10695768</pub-id><pub-id pub-id-type="pmid">37074915</pub-id><pub-id pub-id-type="doi">10.1016/j.celrep.2023.112397</pub-id></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horton</surname><given-names>S</given-names></name><name><surname>Mastrolia</surname><given-names>V</given-names></name><name><surname>Jackson</surname><given-names>RE</given-names></name><name><surname>Kemlo</surname><given-names>S</given-names></name><name><surname>Pereira Machado</surname><given-names>PM</given-names></name><name><surname>Carbajal</surname><given-names>MA</given-names></name><name><surname>Hindges</surname><given-names>R</given-names></name><name><surname>Fleck</surname><given-names>RA</given-names></name><name><surname>Aguiar</surname><given-names>P</given-names></name><name><surname>Neves</surname><given-names>G</given-names></name><name><surname>Burrone</surname><given-names>J</given-names></name></person-group><article-title>Excitatory and inhibitory synapses show a tight subcellular correlation that weakens over development</article-title><source>Cell Rep</source><year>2024</year><volume>43</volume><fpage>1</fpage><lpage>22</lpage><pub-id pub-id-type="pmid">38900634</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guerin</surname><given-names>CJ</given-names></name><name><surname>Lippens</surname><given-names>S</given-names></name></person-group><article-title>Correlative light and volume electron microscopy (vCLEM): How community participation can advance developing technologies</article-title><source>J Microsc</source><year>2021</year><volume>284</volume><fpage>97</fpage><lpage>102</lpage><pub-id pub-id-type="pmcid">PMC9291772</pub-id><pub-id pub-id-type="pmid">34476818</pub-id><pub-id pub-id-type="doi">10.1111/jmi.13056</pub-id></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hildebrand</surname><given-names>DC</given-names></name><name><surname>Cicconet</surname><given-names>M</given-names></name><name><surname>Torres</surname><given-names>RM</given-names></name><name><surname>Choi</surname><given-names>W</given-names></name><name><surname>Quan</surname><given-names>TM</given-names></name><name><surname>Moon</surname><given-names>J</given-names></name><name><surname>Wetzel</surname><given-names>AW</given-names></name><name><surname>Scott Champion</surname><given-names>A</given-names></name><name><surname>Graham</surname><given-names>BJ</given-names></name><name><surname>Randlett</surname><given-names>O</given-names></name><name><surname>Plummer</surname><given-names>GS</given-names></name><etal/></person-group><article-title>Whole-brain serial-section electron microscopy in larval zebrafish</article-title><source>Nature</source><year>2017</year><volume>545</volume><fpage>345</fpage><lpage>349</lpage><pub-id pub-id-type="pmcid">PMC5594570</pub-id><pub-id pub-id-type="pmid">28489821</pub-id><pub-id pub-id-type="doi">10.1038/nature22356</pub-id></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Svara</surname><given-names>F</given-names></name><name><surname>Förster</surname><given-names>D</given-names></name><name><surname>Kubo</surname><given-names>F</given-names></name><name><surname>Januszewski</surname><given-names>M</given-names></name><name><surname>dal Maschio</surname><given-names>M</given-names></name><name><surname>Schubert</surname><given-names>PJ</given-names></name><name><surname>Kornfeld</surname><given-names>J</given-names></name><name><surname>Wanner</surname><given-names>AA</given-names></name><name><surname>Laurell</surname><given-names>E</given-names></name><name><surname>Denk</surname><given-names>W</given-names></name><name><surname>Baier</surname><given-names>H</given-names></name></person-group><article-title>Automated synapse-level reconstruction of neural circuits in the larval zebrafish brain</article-title><source>Nat Methods</source><year>2022</year><volume>19</volume><fpage>1357</fpage><lpage>1366</lpage><pub-id pub-id-type="pmcid">PMC9636024</pub-id><pub-id pub-id-type="pmid">36280717</pub-id><pub-id pub-id-type="doi">10.1038/s41592-022-01621-0</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Russell</surname><given-names>MG</given-names></name><name><surname>Lerner</surname><given-names>TR</given-names></name><name><surname>Burden</surname><given-names>JJ</given-names></name><name><surname>Nkwe</surname><given-names>DO</given-names></name><name><surname>Pelchen-Matthews</surname><given-names>A</given-names></name><name><surname>Domart</surname><given-names>MC</given-names></name><name><surname>Durgan</surname><given-names>J</given-names></name><name><surname>Weston</surname><given-names>A</given-names></name><name><surname>Jones</surname><given-names>ML</given-names></name><name><surname>Peddie</surname><given-names>CJ</given-names></name><name><surname>Carzaniga</surname><given-names>R</given-names></name><etal/></person-group><article-title>3D correlative light and electron microscopy of cultured cells using serial blockface scanning electron microscopy</article-title><source>J Cell Sci</source><year>2017</year><volume>130</volume><fpage>278</fpage><lpage>291</lpage><pub-id pub-id-type="pmcid">PMC5394779</pub-id><pub-id pub-id-type="pmid">27445312</pub-id><pub-id pub-id-type="doi">10.1242/jcs.188433</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ohta</surname><given-names>K</given-names></name><name><surname>Hirashima</surname><given-names>S</given-names></name><name><surname>Miyazono</surname><given-names>Y</given-names></name><name><surname>Togo</surname><given-names>A</given-names></name><name><surname>Nakamura</surname><given-names>KI</given-names></name></person-group><article-title>Correlation of organelle dynamics between light microscopic live imaging and electron microscopic 3D architecture using FIB-SEM</article-title><source>Microscopy</source><year>2021</year><volume>70</volume><fpage>161</fpage><lpage>170</lpage><pub-id pub-id-type="pmcid">PMC7989057</pub-id><pub-id pub-id-type="pmid">33216938</pub-id><pub-id pub-id-type="doi">10.1093/jmicro/dfaa071</pub-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hayashi</surname><given-names>S</given-names></name><name><surname>Ohno</surname><given-names>N</given-names></name><name><surname>Knott</surname><given-names>G</given-names></name><name><surname>Molnár</surname><given-names>Z</given-names></name></person-group><article-title>Correlative light and volume electron microscopy to study brain development</article-title><source>Microscopy</source><year>2023</year><volume>72</volume><fpage>279</fpage><lpage>286</lpage><pub-id pub-id-type="pmid">36620906</pub-id></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McCafferty</surname><given-names>CL</given-names></name><name><surname>Klumpe</surname><given-names>S</given-names></name><name><surname>Amaro</surname><given-names>RE</given-names></name><name><surname>Kukulski</surname><given-names>W</given-names></name><name><surname>Collinson</surname><given-names>L</given-names></name><name><surname>Engel</surname><given-names>BD</given-names></name></person-group><article-title>Integrating cellular electron microscopy with multimodal data to explore biology across space and time</article-title><source>Cell</source><year>2024</year><volume>187</volume><fpage>563</fpage><lpage>584</lpage><pub-id pub-id-type="pmid">38306982</pub-id></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Han</surname><given-names>X</given-names></name><name><surname>Lu</surname><given-names>X</given-names></name><name><surname>Li</surname><given-names>PH</given-names></name><name><surname>Wang</surname><given-names>S</given-names></name><name><surname>Schalek</surname><given-names>R</given-names></name><name><surname>Meirovitch</surname><given-names>Y</given-names></name><name><surname>Lin</surname><given-names>Z</given-names></name><name><surname>Adhinarta</surname><given-names>J</given-names></name><name><surname>Murray</surname><given-names>KD</given-names></name><name><surname>MacNiven</surname><given-names>LM</given-names></name><name><surname>Berger</surname><given-names>DR</given-names></name><etal/></person-group><article-title>Multiplexed volumetric CLEM enabled by scFvs provides insights into the cytology of cerebellar cortex</article-title><source>Nat Commun</source><year>2024</year><volume>15</volume><fpage>1</fpage><lpage>18</lpage><pub-id pub-id-type="pmcid">PMC11300613</pub-id><pub-id pub-id-type="pmid">39103318</pub-id><pub-id pub-id-type="doi">10.1038/s41467-024-50411-z</pub-id></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="conf-proc"><person-group person-group-type="author"><name><surname>Bogovic</surname><given-names>JA</given-names></name><name><surname>Hanslovsky</surname><given-names>P</given-names></name><name><surname>Wong</surname><given-names>A</given-names></name><name><surname>Saalfeld</surname><given-names>S</given-names></name></person-group><article-title>Robust registration of calcium images by learned contrast synthesis</article-title><source>Proc - Int Symp Biomed Imaging</source><year>2016</year><month>June</month><fpage>1123</fpage><lpage>1126</lpage><comment>2016</comment></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paul-Gilloteaux</surname><given-names>P</given-names></name><name><surname>Heiligenstein</surname><given-names>X</given-names></name><name><surname>Belle</surname><given-names>M</given-names></name><name><surname>Domart</surname><given-names>MC</given-names></name><name><surname>Larijani</surname><given-names>B</given-names></name><name><surname>Collinson</surname><given-names>L</given-names></name><name><surname>Raposo</surname><given-names>G</given-names></name><name><surname>Salamero</surname><given-names>J</given-names></name></person-group><article-title>EC-CLEM: Flexible multidimensional registration software for correlative microscopies</article-title><source>Nat Methods</source><year>2017</year><volume>14</volume><fpage>102</fpage><lpage>103</lpage><pub-id pub-id-type="pmid">28139674</pub-id></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fu</surname><given-names>X</given-names></name><name><surname>Ning</surname><given-names>J</given-names></name><name><surname>Zhong</surname><given-names>Z</given-names></name><name><surname>Ambrose</surname><given-names>Z</given-names></name><name><surname>Charles Watkins</surname><given-names>S</given-names></name><name><surname>Zhang</surname><given-names>P</given-names></name></person-group><article-title>AutoCLEM: An Automated Workflow for Correlative Live-Cell Fluorescence Microscopy and Cryo-Electron Tomography</article-title><source>Sci Rep</source><year>2019</year><volume>9</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="pmcid">PMC6915765</pub-id><pub-id pub-id-type="pmid">31844138</pub-id><pub-id pub-id-type="doi">10.1038/s41598-019-55766-8</pub-id></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klein</surname><given-names>S</given-names></name><name><surname>Staring</surname><given-names>M</given-names></name><name><surname>Murphy</surname><given-names>K</given-names></name><name><surname>Viergever</surname><given-names>MA</given-names></name><name><surname>Pluim</surname><given-names>JW</given-names></name></person-group><article-title>Elastix: A toolbox for intensity-based medical image registration</article-title><source>IEEE Trans Med Imaging</source><year>2010</year><volume>29</volume><fpage>196</fpage><lpage>205</lpage><pub-id pub-id-type="pmid">19923044</pub-id></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ntatsis</surname><given-names>K</given-names></name><name><surname>Dekker</surname><given-names>N</given-names></name><name><surname>Van Der Valk</surname><given-names>V</given-names></name><name><surname>Birdsong</surname><given-names>T</given-names></name><name><surname>Zukíczukíc</surname><given-names>D</given-names></name><name><surname>Klein</surname><given-names>S</given-names></name><name><surname>Staring</surname><given-names>M</given-names></name><name><surname>Mccormick</surname><given-names>M</given-names></name></person-group><source>itk-elastix: Medical image registration in Python</source><publisher-name>Scipy</publisher-name><year>2023</year><fpage>101</fpage><lpage>105</lpage></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pape</surname><given-names>C</given-names></name><name><surname>Meechan</surname><given-names>K</given-names></name><name><surname>Moreva</surname><given-names>E</given-names></name><name><surname>Schorb</surname><given-names>M</given-names></name><name><surname>Chiaruttini</surname><given-names>N</given-names></name><name><surname>Zinchenko</surname><given-names>V</given-names></name><name><surname>Martinez Vergara</surname><given-names>H</given-names></name><name><surname>Mizzon</surname><given-names>G</given-names></name><name><surname>Moore</surname><given-names>J</given-names></name><name><surname>Arendt</surname><given-names>D</given-names></name><name><surname>Kreshuk</surname><given-names>A</given-names></name><etal/></person-group><article-title>MoBIE: a Fiji plugin for sharing and exploration of multi-modal cloud-hosted big image data</article-title><source>Nat Methods</source><year>2023</year><volume>20</volume><fpage>475</fpage><lpage>476</lpage><pub-id pub-id-type="pmid">36765247</pub-id></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vergara</surname><given-names>HM</given-names></name><name><surname>Pape</surname><given-names>C</given-names></name><name><surname>Meechan</surname><given-names>KI</given-names></name><name><surname>Zinchenko</surname><given-names>V</given-names></name><name><surname>Genoud</surname><given-names>C</given-names></name><name><surname>Wanner</surname><given-names>AA</given-names></name><name><surname>Mutemi</surname><given-names>KN</given-names></name><name><surname>Titze</surname><given-names>B</given-names></name><name><surname>Templin</surname><given-names>RM</given-names></name><name><surname>Bertucci</surname><given-names>PY</given-names></name><name><surname>Simakov</surname><given-names>O</given-names></name><etal/></person-group><article-title>Whole-body integration of gene expression and single-cell morphology</article-title><source>Cell</source><year>2021</year><volume>184</volume><fpage>4819</fpage><lpage>4837</lpage><elocation-id>e22</elocation-id><pub-id pub-id-type="pmcid">PMC8445025</pub-id><pub-id pub-id-type="pmid">34380046</pub-id><pub-id pub-id-type="doi">10.1016/j.cell.2021.07.017</pub-id></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krentzel</surname><given-names>D</given-names></name></person-group><article-title>CLEM-Reg: An automated registration algorithm for correlative light and volume electron microscopy</article-title><source>BioRxiv</source><year>2023</year><elocation-id>2023.05.11.540445</elocation-id></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karreman</surname><given-names>MA</given-names></name><name><surname>Mercier</surname><given-names>L</given-names></name><name><surname>Schieber</surname><given-names>NL</given-names></name><name><surname>Shibue</surname><given-names>T</given-names></name><name><surname>Schwab</surname><given-names>Y</given-names></name><name><surname>Goetz</surname><given-names>JG</given-names></name></person-group><article-title>Correlating intravital multi-photon microscopy to 3D electron microscopy of invading tumor cells using anatomical reference points</article-title><source>PLoS One</source><year>2014</year><volume>9</volume><fpage>1</fpage><lpage>23</lpage><pub-id pub-id-type="pmcid">PMC4257674</pub-id><pub-id pub-id-type="pmid">25479106</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0114448</pub-id></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mocaer</surname><given-names>K</given-names></name><name><surname>Mizzon</surname><given-names>G</given-names></name><name><surname>Gunkel</surname><given-names>M</given-names></name><name><surname>Halavatyi</surname><given-names>A</given-names></name><name><surname>Steyer</surname><given-names>A</given-names></name><name><surname>Oorschot</surname><given-names>V</given-names></name><name><surname>Schorb</surname><given-names>M</given-names></name><name><surname>Le Kieffre</surname><given-names>C</given-names></name><name><surname>Yee</surname><given-names>DP</given-names></name><name><surname>Chevalier</surname><given-names>F</given-names></name><name><surname>Gallet</surname><given-names>B</given-names></name><etal/></person-group><article-title>Targeted volume correlative light and electron microscopy of an environmental marine microorganism</article-title><source>J Cell Sci</source><year>2023</year><volume>136</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="pmcid">PMC10445747</pub-id><pub-id pub-id-type="pmid">37455654</pub-id><pub-id pub-id-type="doi">10.1242/jcs.261355</pub-id></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ronchi</surname><given-names>P</given-names></name><name><surname>Mizzon</surname><given-names>G</given-names></name><name><surname>Machado</surname><given-names>P</given-names></name><name><surname>Imprima</surname><given-names>ED</given-names></name><name><surname>Best</surname><given-names>BT</given-names></name><name><surname>Lucia</surname><given-names>Cassella</given-names></name><name><surname>Schnorrenberg</surname><given-names>S</given-names></name><name><surname>Montero</surname><given-names>MG</given-names></name><name><surname>Jechlinger</surname><given-names>M</given-names></name><name><surname>Ephrussi</surname><given-names>A</given-names></name><name><surname>Maria</surname><given-names>Leptin</given-names></name><etal/></person-group><article-title>High-precision targeting workflow for volume electron microscopy</article-title><source>J Cell Biol</source><year>2021</year><volume>220</volume><fpage>1</fpage><lpage>16</lpage><pub-id pub-id-type="pmcid">PMC8225610</pub-id><pub-id pub-id-type="pmid">34160561</pub-id><pub-id pub-id-type="doi">10.1083/jcb.202104069</pub-id></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karreman</surname><given-names>MA</given-names></name><name><surname>Mercier</surname><given-names>L</given-names></name><name><surname>Schieber</surname><given-names>NL</given-names></name><name><surname>Solecki</surname><given-names>G</given-names></name><name><surname>Allio</surname><given-names>G</given-names></name><name><surname>Winkler</surname><given-names>F</given-names></name><name><surname>Ruthensteiner</surname><given-names>B</given-names></name><name><surname>Goetz</surname><given-names>JG</given-names></name><name><surname>Schwab</surname><given-names>Y</given-names></name></person-group><article-title>Fast and precise targeting of single tumor cells in vivo by multimodal correlative microscopy</article-title><source>J Cell Sci</source><year>2016</year><volume>129</volume><fpage>444</fpage><lpage>456</lpage><pub-id pub-id-type="pmcid">PMC4732291</pub-id><pub-id pub-id-type="pmid">26659665</pub-id><pub-id pub-id-type="doi">10.1242/jcs.181842</pub-id></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karreman</surname><given-names>MA</given-names></name><name><surname>Bauer</surname><given-names>AT</given-names></name><name><surname>Solecki</surname><given-names>G</given-names></name><name><surname>Berghoff</surname><given-names>AS</given-names></name><name><surname>Mayer</surname><given-names>CD</given-names></name><name><surname>Frey</surname><given-names>K</given-names></name><name><surname>Hebach</surname><given-names>N</given-names></name><name><surname>Feinauer</surname><given-names>MJ</given-names></name><name><surname>Schieber</surname><given-names>NL</given-names></name><name><surname>Tehranian</surname><given-names>C</given-names></name><name><surname>Mercier</surname><given-names>L</given-names></name><etal/></person-group><article-title>Active remodeling of capillary endothelium via cancer cell-derived MMP9 promotes metastatic brain colonization</article-title><source>Cancer Res</source><year>2023</year><volume>83</volume><fpage>1299</fpage><lpage>1314</lpage><pub-id pub-id-type="pmcid">PMC7614438</pub-id><pub-id pub-id-type="pmid">36652557</pub-id><pub-id pub-id-type="doi">10.1158/0008-5472.CAN-22-3964</pub-id></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Musser</surname><given-names>JM</given-names></name><name><surname>Schippers</surname><given-names>KJ</given-names></name><name><surname>Nickel</surname><given-names>M</given-names></name><name><surname>Mizzon</surname><given-names>G</given-names></name><name><surname>Kohn</surname><given-names>AB</given-names></name><name><surname>Pape</surname><given-names>C</given-names></name><name><surname>Ronchi</surname><given-names>P</given-names></name><name><surname>Papadopoulos</surname><given-names>N</given-names></name><name><surname>Tarashansky</surname><given-names>AJ</given-names></name><name><surname>Hammel</surname><given-names>JU</given-names></name><name><surname>Wolf</surname><given-names>F</given-names></name><etal/></person-group><article-title>Profiling cellular diversity in sponges informs animal cell type and nervous system evolution</article-title><source>Science (80- )</source><year>2021</year><volume>374</volume><fpage>717</fpage><lpage>723</lpage><pub-id pub-id-type="pmcid">PMC9233960</pub-id><pub-id pub-id-type="pmid">34735222</pub-id><pub-id pub-id-type="doi">10.1126/science.abj2949</pub-id></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>CS</given-names></name><name><surname>Pang</surname><given-names>S</given-names></name><name><surname>Shtengel</surname><given-names>G</given-names></name><name><surname>Müller</surname><given-names>A</given-names></name><name><surname>Ritter</surname><given-names>AT</given-names></name><name><surname>Hoffman</surname><given-names>HK</given-names></name><name><surname>Takemura</surname><given-names>Sya</given-names></name><name><surname>Lu</surname><given-names>Z</given-names></name><name><surname>Pasolli</surname><given-names>HA</given-names></name><name><surname>Iyer</surname><given-names>N</given-names></name><name><surname>Chung</surname><given-names>J</given-names></name><etal/></person-group><article-title>An open-access volume electron microscopy atlas of whole cells and tissues</article-title><source>Nature</source><year>2021</year><volume>599</volume><fpage>147</fpage><lpage>151</lpage><pub-id pub-id-type="pmcid">PMC9004664</pub-id><pub-id pub-id-type="pmid">34616045</pub-id><pub-id pub-id-type="doi">10.1038/s41586-021-03992-4</pub-id></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meechan</surname><given-names>K</given-names></name><name><surname>Guan</surname><given-names>W</given-names></name><name><surname>Riedinger</surname><given-names>A</given-names></name><name><surname>Stankova</surname><given-names>V</given-names></name><name><surname>Yoshimura</surname><given-names>A</given-names></name><name><surname>Pipitone</surname><given-names>R</given-names></name><name><surname>Milberger</surname><given-names>A</given-names></name><name><surname>Schaar</surname><given-names>H</given-names></name><name><surname>Romero-Brey</surname><given-names>I</given-names></name><name><surname>Templin</surname><given-names>R</given-names></name><name><surname>Peddie</surname><given-names>CJ</given-names></name><etal/></person-group><article-title>Crosshair, semi-automated targeting for electron microscopy with a motorised ultramicrotome</article-title><source>Elife</source><year>2022</year><volume>11</volume><fpage>1</fpage><lpage>28</lpage><pub-id pub-id-type="pmcid">PMC9665851</pub-id><pub-id pub-id-type="pmid">36378502</pub-id><pub-id pub-id-type="doi">10.7554/eLife.80899</pub-id></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Acosta</surname><given-names>BT</given-names></name><name><surname>Heiligenstein</surname><given-names>X</given-names></name><name><surname>Malandain</surname><given-names>G</given-names></name><name><surname>Bouthemy</surname><given-names>P</given-names></name></person-group><article-title>Intensity-based matching and registration for 3D correlative microscopy with large discrepancies</article-title><source>Proc - Int Symp Biomed Imaging</source><year>2018</year><month>April</month><fpage>493</fpage><lpage>496</lpage><comment>2018</comment></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seifert</surname><given-names>R</given-names></name><name><surname>Markert</surname><given-names>SM</given-names></name><name><surname>Britz</surname><given-names>S</given-names></name><name><surname>Perschin</surname><given-names>V</given-names></name><name><surname>Erbacher</surname><given-names>C</given-names></name><name><surname>Stigloher</surname><given-names>C</given-names></name><name><surname>Kollmannsberger</surname><given-names>P</given-names></name></person-group><article-title>DeepCLEM : automated registration for correlative light and electron microscopy using deep learning [version 1; peer review : awaiting peer review]</article-title><year>2020</year><fpage>1</fpage><lpage>6</lpage><pub-id pub-id-type="pmcid">PMC10311120</pub-id><pub-id pub-id-type="pmid">37397873</pub-id><pub-id pub-id-type="doi">10.12688/f1000research.27158.3</pub-id></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maes</surname><given-names>F</given-names></name><name><surname>Collingnon</surname><given-names>A</given-names></name><name><surname>Vandermeulen</surname><given-names>D</given-names></name><name><surname>Marchal</surname><given-names>G</given-names></name><name><surname>Suetens</surname><given-names>P</given-names></name></person-group><article-title>Multimodality image registration by maximization of quantitative-qualitative measure of mutual information</article-title><source>IEEE Trans Med Imaging</source><year>1997</year><volume>16</volume><fpage>187</fpage><lpage>198</lpage><pub-id pub-id-type="pmid">9101328</pub-id></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jobson</surname><given-names>DJ</given-names></name><name><surname>Rahman</surname><given-names>ZU</given-names></name><name><surname>Woodell</surname><given-names>GA</given-names></name></person-group><article-title>A multiscale retinex for bridging the gap between color images and the human observation of scenes</article-title><source>IEEE Trans Image Process</source><year>1997</year><volume>6</volume><fpage>965</fpage><lpage>976</lpage><pub-id pub-id-type="pmid">18282987</pub-id></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aganj</surname><given-names>I</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name></person-group><article-title>Multimodal Image Registration through Simultaneous Segmentation</article-title><source>IEEE Signal Process Lett</source><year>2018</year><volume>24</volume><fpage>1661</fpage><lpage>1665</lpage><pub-id pub-id-type="pmcid">PMC5690540</pub-id><pub-id pub-id-type="pmid">29151777</pub-id><pub-id pub-id-type="doi">10.1109/LSP.2017.2754263</pub-id></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferrante</surname><given-names>E</given-names></name><name><surname>Paragios</surname><given-names>N</given-names></name></person-group><article-title>Slice-to-volume medical image registration: A survey</article-title><source>Med Image Anal</source><year>2017</year><volume>39</volume><fpage>101</fpage><lpage>123</lpage><pub-id pub-id-type="pmid">28482198</pub-id></element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Konishi</surname><given-names>K</given-names></name><name><surname>Nonaka</surname><given-names>T</given-names></name><name><surname>Takei</surname><given-names>S</given-names></name><name><surname>Ohta</surname><given-names>K</given-names></name><name><surname>Nishioka</surname><given-names>H</given-names></name><name><surname>Suga</surname><given-names>M</given-names></name></person-group><article-title>Reducing manual operation time to obtain a segmentation learning model for volume electron microscopy using stepwise deep learning with manual correction</article-title><source>Microscopy</source><year>2021</year><volume>70</volume><fpage>526</fpage><lpage>535</lpage><pub-id pub-id-type="pmid">34259875</pub-id></element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Stringer</surname><given-names>C</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><article-title>Robustness of spike deconvolution for neuronal calcium imaging</article-title><source>J Neurosci</source><year>2018</year><volume>38</volume><fpage>7976</fpage><lpage>7985</lpage><pub-id pub-id-type="pmcid">PMC6136155</pub-id><pub-id pub-id-type="pmid">30082416</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3339-17.2018</pub-id></element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cauzzo</surname><given-names>S</given-names></name><name><surname>Bruno</surname><given-names>E</given-names></name><name><surname>Boulet</surname><given-names>D</given-names></name><name><surname>Nazac</surname><given-names>P</given-names></name><name><surname>Basile</surname><given-names>M</given-names></name><name><surname>Callara</surname><given-names>AL</given-names></name><name><surname>Tozzi</surname><given-names>F</given-names></name><name><surname>Ahluwalia</surname><given-names>A</given-names></name><name><surname>Magliaro</surname><given-names>C</given-names></name><name><surname>Danglot</surname><given-names>L</given-names></name><name><surname>Vanello</surname><given-names>N</given-names></name></person-group><article-title>A modular framework for multi-scale tissue imaging and neuronal segmentation</article-title><source>Nat Commun</source><year>2024</year><volume>15</volume><fpage>1</fpage><lpage>7</lpage><pub-id pub-id-type="pmcid">PMC11111705</pub-id><pub-id pub-id-type="pmid">38778027</pub-id><pub-id pub-id-type="doi">10.1038/s41467-024-48146-y</pub-id></element-citation></ref><ref id="R40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheridan</surname><given-names>A</given-names></name><name><surname>Nguyen</surname><given-names>TM</given-names></name><name><surname>Deb</surname><given-names>D</given-names></name><name><surname>Lee</surname><given-names>WA</given-names></name><name><surname>Saalfeld</surname><given-names>S</given-names></name><name><surname>Turaga</surname><given-names>SC</given-names></name><name><surname>Manor</surname><given-names>U</given-names></name><name><surname>Funke</surname><given-names>J</given-names></name></person-group><article-title>Local shape descriptors for neuron segmentation</article-title><source>Nat Methods</source><year>2023</year><volume>20</volume><fpage>295</fpage><lpage>303</lpage><pub-id pub-id-type="pmcid">PMC9911350</pub-id><pub-id pub-id-type="pmid">36585455</pub-id><pub-id pub-id-type="doi">10.1038/s41592-022-01711-z</pub-id></element-citation></ref><ref id="R41"><label>41</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Januszewski</surname><given-names>M</given-names></name><name><surname>Kornfeld</surname><given-names>J</given-names></name><name><surname>Li</surname><given-names>PH</given-names></name><name><surname>Pope</surname><given-names>A</given-names></name><name><surname>Blakely</surname><given-names>T</given-names></name><name><surname>Lindsey</surname><given-names>L</given-names></name><name><surname>Maitin-shepard</surname><given-names>J</given-names></name><name><surname>Tyka</surname><given-names>M</given-names></name><name><surname>Denk</surname><given-names>W</given-names></name><name><surname>Jain</surname><given-names>V</given-names></name></person-group><article-title>High-precision automated reconstruction of neurons with flood-filling networks</article-title><source>Nat Methods</source><year>2018</year><volume>15</volume><fpage>605</fpage><lpage>610</lpage><pub-id pub-id-type="pmid">30013046</pub-id></element-citation></ref><ref id="R42"><label>42</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rohde</surname><given-names>F</given-names></name><name><surname>Braumann</surname><given-names>UD</given-names></name><name><surname>Schmidt</surname><given-names>M</given-names></name></person-group><article-title>Correlia: an ImageJ plug-in to co-register and visualise multimodal correlative micrographs</article-title><source>J Microsc</source><year>2020</year><volume>280</volume><fpage>3</fpage><lpage>11</lpage><pub-id pub-id-type="pmid">32492178</pub-id></element-citation></ref><ref id="R43"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mastronarde</surname><given-names>DN</given-names></name></person-group><article-title>Automated electron microscope tomography using robust prediction of specimen movements</article-title><source>J Struct Biol</source><year>2005</year><volume>152</volume><fpage>36</fpage><lpage>51</lpage><pub-id pub-id-type="pmid">16182563</pub-id></element-citation></ref><ref id="R44"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kremer</surname><given-names>JR</given-names></name><name><surname>Mastronarde</surname><given-names>DN</given-names></name><name><surname>McIntosh</surname><given-names>JR</given-names></name></person-group><article-title>Computer visualization of three-dimensional image data using IMOD</article-title><source>J Struct Biol</source><year>1996</year><volume>116</volume><fpage>71</fpage><lpage>76</lpage><pub-id pub-id-type="pmid">8742726</pub-id></element-citation></ref><ref id="R45"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mastronarde</surname><given-names>DN</given-names></name></person-group><article-title>Dual-Axis Tomography: An Approach with Alignment Methods That Preserve Resolution</article-title><year>1997</year><pub-id pub-id-type="pmid">9441937</pub-id></element-citation></ref><ref id="R46"><label>46</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parslow</surname><given-names>A</given-names></name><name><surname>Cardona</surname><given-names>A</given-names></name><name><surname>Bryson-Richardson</surname><given-names>RJ</given-names></name></person-group><article-title>Sample drift correction following 4D confocal time-lapse Imaging</article-title><source>J Vis Exp</source><year>2014</year><pub-id pub-id-type="pmcid">PMC4166950</pub-id><pub-id pub-id-type="pmid">24747942</pub-id><pub-id pub-id-type="doi">10.3791/51086</pub-id></element-citation></ref><ref id="R47"><label>47</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Preibisch</surname><given-names>S</given-names></name><name><surname>Saalfeld</surname><given-names>S</given-names></name><name><surname>Tomancak</surname><given-names>P</given-names></name></person-group><article-title>Globally optimal stitching of tiled 3D microscopic image acquisitions</article-title><source>Bioinformatics</source><year>2009</year><volume>25</volume><fpage>1463</fpage><lpage>1465</lpage><pub-id pub-id-type="pmcid">PMC2682522</pub-id><pub-id pub-id-type="pmid">19346324</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/btp184</pub-id></element-citation></ref><ref id="R48"><label>48</label><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Fuster-Barcelo</surname><given-names>C</given-names></name><name><surname>Carlos</surname><given-names>G-L-H</given-names></name><name><surname>Rueden</surname><given-names>CT</given-names></name><name><surname>Heras</surname><given-names>J</given-names></name><name><surname>Ulman</surname><given-names>V</given-names></name><name><surname>Ines</surname><given-names>A</given-names></name><name><surname>Eliceri</surname><given-names>K</given-names></name></person-group><source>SAMJ-IJ</source><year>2024</year><comment>https://Github.Com/Segment-Anything-Models-Java/SAMJ-IJ</comment><fpage>1</fpage><lpage>9</lpage></element-citation></ref><ref id="R49"><label>49</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schindelin</surname><given-names>J</given-names></name><name><surname>Arganda-Carreras</surname><given-names>I</given-names></name><name><surname>Frise</surname><given-names>E</given-names></name><name><surname>Kaynig</surname><given-names>V</given-names></name><name><surname>Longair</surname><given-names>M</given-names></name><name><surname>Pietzsch</surname><given-names>T</given-names></name><name><surname>Preibisch</surname><given-names>S</given-names></name><name><surname>Rueden</surname><given-names>C</given-names></name><name><surname>Saalfeld</surname><given-names>S</given-names></name><name><surname>Schmid</surname><given-names>B</given-names></name><name><surname>Tinevez</surname><given-names>J-Y</given-names></name><etal/></person-group><article-title>Fiji: an open-source platform for biological-image analysis</article-title><source>Nat Methods</source><year>2012</year><volume>9</volume><fpage>676</fpage><lpage>682</lpage><pub-id pub-id-type="pmcid">PMC3855844</pub-id><pub-id pub-id-type="pmid">22743772</pub-id><pub-id pub-id-type="doi">10.1038/nmeth.2019</pub-id></element-citation></ref><ref id="R50"><label>50</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Archit</surname><given-names>A</given-names></name><name><surname>Nair</surname><given-names>S</given-names></name><name><surname>Khalid</surname><given-names>N</given-names></name><name><surname>Hilt</surname><given-names>P</given-names></name><name><surname>Rajashekar</surname><given-names>V</given-names></name><name><surname>Freitag</surname><given-names>M</given-names></name><name><surname>Gupta</surname><given-names>S</given-names></name><name><surname>Dengel</surname><given-names>A</given-names></name><name><surname>Ahmed</surname><given-names>S</given-names></name><name><surname>Pape</surname><given-names>C</given-names></name></person-group><article-title>Segment Anything for Microscopy</article-title><source>BioRxiv</source><year>2023</year><elocation-id>2023.08.21.554208</elocation-id></element-citation></ref><ref id="R51"><label>51</label><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Sofroniew</surname><given-names>N</given-names></name></person-group><source>napari: a multi-dimensional image viewer for Python</source><year>2024</year><pub-id pub-id-type="doi">10.5281/ZENODO.3555620</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>Integrated workflow.</title><p>(A) Integrated workflow which integrates imaging and computation. Imaging consists of light microscopy (LM) imaging, ultramicrotomy, transmission electron microscopy (TEM). The computation consists of two image registration algorithms: segmentation-based image registration, shown in panel (B), and conventional landmark-based image registration. The workflow comprises four steps: mapping ROI (duration, 2 days), guiding ultramicrotomy (1 hour), estimating section depth (1-2 days) and targeting TEM tomography (2-3 days). If all the steps are performed without interruption, the average duration of this workflow is thus roughly 1 week. (B) Segmentation-based image registration algorithm. The algorithm consists of two primary components: segmentation and registration. The segmentation step segments common objects in the images from both modalities, either automatically or with user assistance. The registration step maximizes a metric called mutual information (MI) while warping the moving image. See the text for details.</p></caption><graphic xlink:href="EMS201581-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Mapping the ROI FM within the Block FM.</title><p>(A) ROI FM of mouse brain tissue: Neurons in cyan, synapses in green, blood vessels in red, and nuclei in blue are visualized. Three structures in the blood vessel channel are indicated by green arrowheads. (B) Block FM blood vessel channel: A volume rendering highlights the region containing the ROI FM, white box. A zoomed-in view is shown in the inset, with five structures corresponding to those in panel a marked by green arrowheads. The size of white cube is 100 microns. (C)-(E) ROI FM Location Maps: (C) navROI Z-plane view: A screenshot of the navROI tool in Z-plane view. Blood vessels from ROI FM are shown in white. (D) navROI Y-plane view: Screenshots of navROI in Y-plane view, showing both the entire view, top panel, and a zoomed-in region around the ROI FM, bottom panel. The size of the L is 20 microns. (E) Spatial relationship: A navROI screenshot illustrating the spatial relationship between two regions of the ROI FM and the Block FM.</p></caption><graphic xlink:href="EMS201581-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Using a Surface Differential Interference Contrast (DIC) map of the block to guide ultramicrotomy.</title><p>(A) A schematic of the UC and its camera view on top. (B) An UC camera view of the block. Three landmarks of the block corners are indicated by blue arrowheads. (C) A Surface DIC map of the block. The landmarks corresponding to those in panel b are indicated by blue arrowheads, and three landmarks of the blood vessels in red. (D) A ROI FM locations MIP map. Five regions of ROI FMs are shown in green. (E) A screen shot of navROI illustrating an UC camera view overlaid with five ROI FMs. The trimming region is shown in pink. The Surface DIC map and the ROI FM locations MIP map are also shown. (F) An UC camera view of the trimmed block. The trimmed region is shown in pink.</p></caption><graphic xlink:href="EMS201581-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Estimating cutting depth of sections.</title><p>(A) A local region of the blood vessel channel image of a Section FM. Its entire image is shown in the inset. (B)-(C) A Section FM is displayed relative to the Block FM using navROI: (B) A screen shot of navROI in Z plane view. (C) A screen shot of navROI in Y plane view. (D) Comparison of the feeding values from the UC and the depth estimation using image registration. The details of depth estimation for the leftmost point <italic>i</italic> and point <italic>ii</italic> to its right in the plot are shown in panel E. (E) The image registration for depth estimation. Left: An entire section image with a white rectangle. The white rectangle region is used for depth estimation. The inside the dotted red circle shows an empty resin region. Middle: The zoomed-in view of the white rectangle region. Right: The result of image registration for depth estimation. The top row: point <italic>i</italic>, the bottom row: point <italic>ii</italic>.</p></caption><graphic xlink:href="EMS201581-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>Targeting TEM tomography to synapses identified in confocal images.</title><p>(A) An overlay of a ROI FM on a Section TEM map. The region surrounded by a white rectangle contains an axon of a neuron and is magnified on the right panel. Surrounding nuclei are indicated by yellow arrowheads. (B) A volume rendering of the segmentations of the neuron from the ROI FM and the ROI TEM map, displayed in cyan and white. The two target regions for TEM tomography are shown in green and highlighted in a white rectangle. Surrounding nuclei are shown in blue. (C) A three-dimensional view of the ROI FM. (D) An example of the ROI TEM map with segmentation. (E) The overlay of the ROI FM on the ROI TEM map. (F) Image registration at the target regions. Left: The target region in the ROI FM, the cytoplasmic marker channel in cyan and synapse channel in green. The corresponding region to the Middle panel is shown in white rectangle. Middle: The TEM tomogram around the region with segmentation. Right: Their overlay. The top row: <italic>i</italic>. Synapses in the axon. Presynaptic boutons, outlined in purple, correspond to postsynaptic densities identified by fluorescent labeling. The bottom row: <italic>ii</italic>. A blob in the axon initial segment (AIS). Cisternal organelle, indicated by a purple arrowhead, is a distinctive feature expected to be found in the AIS.</p></caption><graphic xlink:href="EMS201581-f005"/></fig></floats-group></article>