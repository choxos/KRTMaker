<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS199508</article-id><article-id pub-id-type="doi">10.1101/2024.10.17.618830</article-id><article-id pub-id-type="archive">PPR926210</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">1</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Abstract choice representations during stable choice-response associations</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Quinn</surname><given-names>Katrina R.</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><contrib contrib-type="author"><name><surname>Sandhaeger</surname><given-names>Florian</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Noury</surname><given-names>Nima</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Žeželić</surname><given-names>Ema</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref><xref ref-type="aff" rid="A4">4</xref></contrib><contrib contrib-type="author"><name><surname>Siegel</surname><given-names>Markus</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref><xref ref-type="aff" rid="A5">5</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib></contrib-group><aff id="A1"><label>1</label>Department of Neural Dynamics and Magnetoencephalography, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/04zzwzx41</institution-id><institution>Hertie Institute for Clinical Brain Research</institution></institution-wrap>, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/03a1kwz48</institution-id><institution>University of Tübingen</institution></institution-wrap>, <country country="DE">Germany</country></aff><aff id="A2"><label>2</label>Centre for Integrative Neuroscience, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/03a1kwz48</institution-id><institution>University of Tübingen</institution></institution-wrap>, <country country="DE">Germany</country></aff><aff id="A3"><label>3</label>MEG Center, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/03a1kwz48</institution-id><institution>University of Tübingen</institution></institution-wrap>, <country country="DE">Germany</country></aff><aff id="A4"><label>4</label>Graduate Training Centre of Neuroscience, International Max Planck Research School, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/03a1kwz48</institution-id><institution>University of Tübingen</institution></institution-wrap>, <country country="DE">Germany</country></aff><aff id="A5"><label>5</label>German Center for Mental Health (DZPG), Tübingen, Germany</aff><author-notes><corresp id="CR1">
<label>*</label> Corresponding authors: Katrina Quinn (<email>katrina.quinn@uni-tuebingen.de</email>) and Markus Siegel (<email>markus.siegel@uni-tuebingen.de</email>)</corresp></author-notes><pub-date pub-type="nihms-submitted"><day>19</day><month>10</month><year>2024</year></pub-date><pub-date pub-type="preprint"><day>18</day><month>10</month><year>2024</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Perceptual decisions have long been framed in terms of the actions used to report a choice. Accordingly, studies of perceptual decision-making have historically relied on tasks with fixed choice-response mappings, in which choice and motor response are inextricably linked. Although several studies have since dissociated choice and response, they have typically involved dynamic switching of the choice-response mapping on a trial-by-trial basis. Thus, it remains unclear if abstract choice representations arise specifically when choice-response relationships change dynamically, or if they reflect a more general property of the decision-making process. Here, we show that in the human brain, choices are represented abstractly, even when the association between choice and motor response remains stable over time. We measured neural activity in humans using magnetoencephalography (MEG) while participants performed a motion discrimination task. Importantly, the associations between perceptual choice and motor response were balanced across experimental conditions and remained stable over many trials. We found neural information about the participants’ perceptual choice, independent of both the motor response and the visual stimulus. This abstract choice information increased during the stimulus period and peaked after the response had been made. Furthermore, choice and response information showed distinct cortical distributions, with strongest choice information in frontoparietal regions. Our results suggest that abstract choice representations are not restricted to action-independent contexts or those with dynamic choice-response associations and may therefore reflect a general role in perceptual decision-making.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">Many of our every-day decisions are tightly coupled to a particular motor action. Likewise, most of the tasks exploring the neural underpinnings of perceptual decision-making have inextricably linked choices with the motor-responses required to report them [<xref ref-type="bibr" rid="R1">1</xref>–<xref ref-type="bibr" rid="R5">5</xref>], for example in motion discrimination, a rightward eye movement or button press for a downwards motion choice. This is in keeping with one of the dominant accounts of perceptual decision-making, which suggests that choices are embodied [<xref ref-type="bibr" rid="R6">6</xref>–<xref ref-type="bibr" rid="R8">8</xref>]. This intentional framework suggests that choices emerge as plans to commit a particular action.</p><p id="P3">However, we are also able to make decisions that cannot immediately be followed by a specific action. This implies that the brain can represent choices independently of actions, which we here refer to as abstract choices. How this is achieved, and under what contexts such representations may persist, has been a matter of continued debate [<xref ref-type="bibr" rid="R2">2</xref>,<xref ref-type="bibr" rid="R3">3</xref>,<xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R8">8</xref>–<xref ref-type="bibr" rid="R10">10</xref>]. In recent years, there has been a greater focus on uncoupling choices and actions in perceptual tasks, to identify potentially independent neural representations. Indeed, these studies have found choice signals which arise before the choice-response mapping is known, therefore abstracting them from any representation of the motor-response [<xref ref-type="bibr" rid="R11">11</xref>–<xref ref-type="bibr" rid="R15">15</xref>]. More importantly, the same abstract choice signals were identified regardless of whether the choice-response mapping was known in advance or not [<xref ref-type="bibr" rid="R15">15</xref>], indicative of an abstract choice stage across different action contexts.</p><p id="P4">The extent to which abstract representations of choice occur ubiquitously across different task contexts remains unclear. One possibility is that an abstract choice stage is specifically recruited when flexible shifting between choice-action mappings is required. Previous studies separating choice and action representations have typically used either post-stimulus (action-independent) mapping [<xref ref-type="bibr" rid="R12">12</xref>–<xref ref-type="bibr" rid="R14">14</xref>,<xref ref-type="bibr" rid="R16">16</xref>,<xref ref-type="bibr" rid="R17">17</xref>] or trial-by-trial switching either between action-independent and action-linked decisions [<xref ref-type="bibr" rid="R15">15</xref>] or between different pre-stimulus choice-action mappings [<xref ref-type="bibr" rid="R18">18</xref>]. Alternatively, an abstract choice stage may play a general role in decision-making, even when little to no flexibility of choice-action associations is required.</p><p id="P5">We investigated these alternatives in the human brain by holding the choice-response mapping stable over extended periods of time. Human participants performed an up-down visual motion discrimination task while we recorded neural activity using magnetoencephalography (MEG). Importantly, using a blocked task design and specific analyses, we were able to disentangle choice and response representations. We found neural activity selective for the stimulus, motor response and choice. Crucially, choice information was independent of the choice-response mapping. This abstract choice representation ramped up during the stimulus period, consistent with evidence integration over the motion stimulus, and peaked after the response. Our results show that choices are represented abstractly, even when the association between choice and motor response remains stable over time. This suggests that abstract choice representations may play a more general role than purely action-based frameworks have previously implied.</p></sec><sec id="S2" sec-type="results"><title>Results</title><sec id="S3"><title>Task and behaviour</title><p id="P6">We recorded MEG in 16 human participants (20 prior to exclusions; see <xref ref-type="sec" rid="S9">Methods</xref>) while they performed an up-down visual motion discrimination task (<xref ref-type="fig" rid="F1">Fig 1A</xref>). On each trial, the participants viewed a stream of 24 random-dot motion pulses (83 ms per pulse). After an auditory go-cue they indicated whether they perceived more up- or downward motion with a left or right button press. The mapping between choice (up or down) and response (left or right button) was manipulated block-wise, such that all trials within a single block of 96 trials had the same choice-response mapping (e.g. left button press for upward motion, right for downward). The mapping was indicated to the participants at the beginning of each block. The mapping for each block was determined pseudo-randomly, such that mappings were balanced across stimulus conditions (see below). Most often, this meant that the choice-response mapping switched between blocks but could also remain stable over multiple blocks (<xref ref-type="fig" rid="F1">Fig 1B</xref>).</p><p id="P7">Each of the 24 motion pulses showed either upward or downward motion. The motion direction was determined randomly on a pulse-by-pulse basis, such that each individual pulse had an equal probability of being an up or downward motion pulse (<xref ref-type="fig" rid="F1">Fig 1C</xref>). The strength of motion for each pulse was determined by the motion coherence, which was held constant within a block. There were three coherence levels in total – low, medium and high. Low and medium coherence levels were determined by staircases prior to the task to achieve about 66% and 75% performance, respectively. In the high coherence condition, 100% of the dots moved in the specified direction. The order of the coherence blocks was determined pseudo-randomly, such that the coherence levels were balanced.</p><p id="P8">The coherence staircases had the desired effect that the three coherence levels were well-separated (<xref ref-type="fig" rid="F1">Fig 1D</xref>, left; mean coherence: 66%, 81%, 100% for low, medium and high coherence, respectively). Behavioral performance corresponded well with the expected performance for the respective coherence levels (<xref ref-type="fig" rid="F1">Fig 1D</xref>, right; mean correct performance: 65%, 74%, 82% for low, medium and high coherence respectively).</p></sec><sec id="S4"><title>Neural information about motion direction and motor responses</title><p id="P9">We quantified neural information about the direction of motion pulses and about motor responses for each participant using a cross-validated multivariate analysis of variance (cvMANOVA) [<xref ref-type="bibr" rid="R15">15</xref>,<xref ref-type="bibr" rid="R19">19</xref>,<xref ref-type="bibr" rid="R20">20</xref>]. We applied cvMANOVA on pre-processed MEG data across all sensors (see <xref ref-type="sec" rid="S9">Methods</xref>), resulting in a measure of neural information analogous to classifier performance. Importantly, cvMANOVA independently assesses the variability related to a specific variable of interest, while excluding confounds related to other variables.</p><p id="P10">We were able to quantify neural information about individual motion pulses, which can be observed as the shifting peaks of information across time relative to stimulus onset (<xref ref-type="fig" rid="F2">Figure 2A</xref>). When we aligned individual pulses by their onset time and averaged neural information across pulses, we found significant information for each coherence level (<xref ref-type="fig" rid="F2">Fig 2B</xref>; p = 0.03, 0.02, 0.017 for low, medium and high coherence, respectively, cluster permutation statistics). Motion information peaked about 300 ms after pulse onset and continued for several hundred milliseconds. Information about motion direction increased with increasing motion coherence, although this effect was not statistically significant (F = 1.23, p = 0.30, one-way ANOVA of average pulse information 200-400 ms post pulse onset with factor coherence). As the cvMANOVA also included the subjects’ choice and motor response as factors, neural information about motion pulses was independent of these factors.</p><p id="P11">We also found significant neural information about motor responses for each coherence level (<xref ref-type="fig" rid="F2">Fig 2C</xref>; p = 0.002, 0.003, &lt;0.001 for low, medium and high coherence, respectively; cluster permutation). Again, as the cvMANOVA also included the subjects’ choice as a factor, neural information about the response was independent of the choice. Response information started to rise in the second half of the stimulus period, consistent with early motor response preparation, and peaked after the go-cue. We did not observe any differences in the response information as a function of coherence (F = 0.01, p = 0.99, one-way ANOVA of average response information 0-1s post stimulus offset with factor coherence).</p><p id="P12">In summary, we found robust neural information about the sensory stimulus that subjects had to decide upon and about the motor response with which subjects reported their choice.</p></sec><sec id="S5"><title>Neural information about choices independent of responses</title><p id="P13">We next tested if we could find neural information for the perceptual choice independent of the motor response and stimulus. To do so, we first corrected neural activity for any influence of the stimulus, so that neural activity related to choice would not be confounded by the correlations which arise between stimulus and choice for above-chance performance. We implemented a pulse-based stimulus correction because, unlike for the response or choice variable, merely including the average stimulus motion as a factor in the cvMANOVA would not render other information independent of stimuli at the pulse level (see <xref ref-type="sec" rid="S9">Methods</xref>). Critically, the employed correction was conservative, i.e. would lead to an underestimation of choice information dependent on the behavioural performance. As performance differed between coherence levels, we restricted the subsequent analysis to the data averaged across coherence conditions. Furthermore, as the cvMANOVA also included the response as a factor, choice information was assessed independently from the motor response. In other words, we assessed abstract choice information.</p><p id="P14">We found significant neural information about the perceptual choice (<xref ref-type="fig" rid="F3">Fig 3A</xref>; p = 0.001, cluster permutation) which ramped up during the stimulus period (p = 0.015, one-tailed t-test for the stimulus presentation interval) consistent with evidence integration over the motion pulses and peaked after the go-cue. When we aligned the analysis to the response time based on the reaction time on each trial (<xref ref-type="fig" rid="F3">Fig 3B</xref>, p=.001, cluster permutation), we found that choice information largely peaked right after the response and declined thereafter.</p></sec><sec id="S6"><title>Choice and response information exhibit distinct cortical distributions</title><p id="P15">To further contrast choice and response information, we employed a searchlight analysis and quantified their cortical distribution across time, averaged across hemispheres (see <xref ref-type="sec" rid="S9">Methods</xref>). We found distinct patterns of information both across space and time (<xref ref-type="fig" rid="F4">Figure 4</xref>). For response information, we observed a central peak after the go-cue which continued well into the response period. In contrast, choice information was strongest in parietal and frontal regions during the stimulus period. This pattern continued into the response period, with additional central contributions.</p></sec><sec id="S7"><title>Choice information includes response-independent and response-linked components</title><p id="P16">Our experimental design and analysis approach ensured that the identified choice information was independent of the motor response, i.e. that the identified neural variability that was explained by choices could not be explained by motor responses. However, choice and response information may still recruit overlapping neural populations. To test this, we quantified the cross-variable information between choice and response (see <xref ref-type="sec" rid="S9">Methods</xref>). We found that the absolute choice-response cross-variable information was significantly lower than expected if they involved perfectly overlapping neural populations (<xref ref-type="fig" rid="F5">Fig 5A</xref>; paired t-test, p = 0.000027). However, absolute cross-variable information was also significantly above chance, indicating that the representations of choice and response were not completely orthogonal (<xref ref-type="fig" rid="F5">Fig 5B</xref>; one-tailed paired t-test, p = 0.00026 real vs. shuffled choice labels). This suggests that choice and response information arise from neural populations that are largely disparate but may have a small degree of overlap.</p></sec></sec><sec id="S8" sec-type="discussion"><title>Discussion</title><p id="P17">We found neural information about perceptual choices independently of motor responses in the human brain. These results are compatible with previous findings showing abstract choice representations both when the choice-motor mapping is known in advance [<xref ref-type="bibr" rid="R15">15</xref>,<xref ref-type="bibr" rid="R18">18</xref>], and also when it is not [<xref ref-type="bibr" rid="R11">11</xref>–<xref ref-type="bibr" rid="R17">17</xref>]. Importantly, we found abstract choice information in a task where the choice-response mappings remained stable over many trials. This contrasts with the previously mentioned studies where choice-motor mappings changed on a trial-by-trial basis. Thus, our results are, to the best of our knowledge, the first to show that abstract choice representations are not limited to tasks which require a quick and flexible mapping of choices onto responses and may therefore reflect a more general property of the perceptual decision-making process.</p><p id="P18">Our results complement a recent study which used similar methods to show that abstract choice information generalised between action-linked and not action-linked decisions. The present study provides two main advances. Firstly, as mentioned above Sandhaeger et al. [<xref ref-type="bibr" rid="R15">15</xref>] changed the choice-motor mapping and when it was cued on a trial-by-trial basis, whereas in our study the mapping was always known in advance and held stable across many trials. Secondly, Sandhaeger et al. used an asymmetric task design, where participants decided if coherent motion was present or not. Using a symmetric discrimination in the present task (up vs. down) ensures that the variables of interest are less likely to be affected by other extraneous variables, such as e.g. arousal. Specifically, for any extraneous variable to explain choice information, it would need to act differently between trials for the two choices, which is unlikely when the choice options are symmetric, e.g. around the axis of motion.</p><p id="P19">We found that choice information was present in a network of brain areas distinct from that for the motor response, with parietal and frontal areas showing significant choice signals. These results are broadly consistent with previous findings in non-human primates [<xref ref-type="bibr" rid="R11">11</xref>] and humans [<xref ref-type="bibr" rid="R12">12</xref>,<xref ref-type="bibr" rid="R15">15</xref>,<xref ref-type="bibr" rid="R16">16</xref>,<xref ref-type="bibr" rid="R21">21</xref>]. They also complement a recent study which localised an indirect measure of choice activity to fronto-parietal networks when motor-responses are held stable [<xref ref-type="bibr" rid="R22">22</xref>]. Previous evidence in humans has shown conflicting results on the involvement of posterior parietal cortex, with some suggesting that this area only play a role in action-linked contexts. Although our task involves action-linked decisions, our results show choice-related activity in a parietal region, independent of the motor response. One explanation suggested by Filimon et al. [<xref ref-type="bibr" rid="R16">16</xref>] could be that posterior parietal cortex is involved in representing abstract choices in a motion discrimination task, due to its strong connections with area MT, but not in other perceptual discriminations. Alternatively, posterior parietal cortex may multiplex signals associated with choice and response [<xref ref-type="bibr" rid="R23">23</xref>], in such a way that it is not always clear from human brain imaging whether these regions are involved in the task at hand. Further studies, using invasive recordings or more complex experimental designs are required to elucidate this issue.</p><p id="P20">The fact that we found abstract choice representations even when the choice-response association was stable over time suggests that these representations are more ubiquitous than previously thought. The intentional framework of decision-making has long viewed representations of choice to be synonymous with convergence upon an action-plan, framing abstract decision contexts almost as outliers [<xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R8">8</xref>]. While there has been a wave of evidence for abstract choice representations when the choice-response mapping is not known in advance of the stimulus, only recently has there been evidence to suggest that these persist even when the mapping is known in advance [<xref ref-type="bibr" rid="R15">15</xref>,<xref ref-type="bibr" rid="R18">18</xref>]. Our findings contribute to this evidence. Furthermore, our results address a criticism of abstract choice tasks, that participants may still plan response actions even when the mapping is not known in advance [<xref ref-type="bibr" rid="R24">24</xref>]. If individuals preferentially associate a specific choice with a specific motor response, this could mean that evidence for abstract choice representations is in fact still motor-linked. However, our cross-variable information analysis shows that even on an individual level, the neural populations supporting choice and motor-response are largely distinct. Together, these findings contradict a purely intentional framework, and at the very least suggests that abstract representations of choice are not limited to contexts in which an action cannot immediately be planned.</p><p id="P21">Our results lead us to several open questions. What is the precise role for abstract choice representations when an action can be planned directly? A recent study from Charlton &amp; Goris (2024) found that information about the choice emerged earlier than that about the response, suggestive of a choice stage prior to the action planning. In our study, choice and response information emerged at similar times, although the different strength of the signals complicates direct timing comparisons. In any case, even without a serial processing of choice and action plan, it could be beneficial to represent choices in an abstract reference frame. For example, when learning to navigate our natural environment, the coupling between particular choices and actions varies with changes of our viewpoint or dynamic properties of the visual scene. In this case, it could be advantageous to know the perceptual choice associated with particular visual stimuli and outcomes, in addition to the latter’s association with specific actions.</p><p id="P22">In which contexts do these abstract choice representations arise? In our study it was methodologically necessary to change the choice-response mapping several times to measure choice information independently of the visual stimulus and the motor response. While the blocked design was more stable than a trial-by-trial design, it could still be that the infrequent changes of the choice-response mapping led to choices being represented in an abstract format generalising across block types. This leaves open the possibility that in contexts where the choice and associated action are even more tightly coupled, decision-making operates in a fully intentional way, without abstract choice representations. However, given that our natural behaviour involves many instances of both abstract and action-linked perceptual decisions, it seems intuitive to implement neural processes that allow to fluidly switch between these different contexts. To this end, choices could be represented abstractly across all contexts, potentially simultaneously with action-linked choice signals, and utilised when required.</p></sec><sec id="S9" sec-type="methods"><title>Methods</title><sec id="S10" sec-type="subjects"><title>Participants</title><p id="P23">20 healthy, right-handed human participants (5 female; mean = 27 years, 4 year SD) took part in the current study and received monetary reward. All participants had normal or corrected-to-normal vision. Prior to the recording, participants provided written informed consent. The study was approved by the ethical committee of the Medical Faculty and University Hospital of the University of Tübingen and conducted in accordance with the Declaration of Helsinki.</p></sec><sec id="S11"><title>Behavioural task and stimuli</title><p id="P24">Participants performed a symmetric motion discrimination task. On each trial, they were asked to report whether a train of 24 motion pulses contained more upwards or downwards motion. Responses were made with a left- or right-hand button press. Importantly the mapping between choice and motor response varied block-wise, such that a left button press would correspond to an up or down choice depending on the block.</p><p id="P25">At the start of each trial participants were required to fixate a small white point at the centre of the screen, and continued fixating for the duration of the trial. Once they obtained fixation, 16 alternating up/down motion pulses (1/12 = 0.08333 s pulse duration) were presented (1.33 s total duration), centred around fixation. For the last 0.3333 s of this pre-stimulus pulse train, an auditory onset cue signalled the start of the stimulus pulses. Subsequently 24 stimulus pulses (1/12 = 0.08333 s pulse duration) were presented (2 s total stimulus duration), each showing more up or downward motion. After the stimulus pulses, a post-stimulus pulse train of alternating up/down pulses began. At the same time, an auditory offset cue (0.1667 s duration) signalled the end of the stimulus-train and acted as a go-cue for participants to respond. After the response, participants received auditory feedback about their performance. Following the feedback, a random even number of alternating up-down pulses (4-14 pulses) was presented before the next trial began.</p><p id="P26">Participants sat at a viewing distance of 50 cm from the screen. Fixation occurred within a window of 2 degrees (7 subjects) or 1.34 degrees (9 participants) of visual angle. The fixation dot was a white dot with a radius of 0.1 degrees. A single motion pulse consisted of a random-dot kinematogram with 700 white dots, each with a radius of 0.1 degrees. The dots were presented within a circular aperture on a black background (6.7 degrees radius), with an additional circular aperture without dots surrounding the fixation point (1.34 degrees radius). Each dot moved either upward or downward at 10 degrees per s. The proportion of dots moving upwards vs. downwards was determined by the motion coherence of which there were three levels – low, medium and high. For the high level, all dots moved in one direction. Low and medium coherence levels were determined using two 2:1 staircases (144 trials each) prior to each experiment, to achieve about 66% and 75% correct motion discrimination performance, respectively. For each coherence level, there were 10 possible ‘up’ pulses, which were flipped to produce 10 possible ‘down’ pulses. During the experiment, for each of the 24 stimulus pulses, the pulse direction and specific pulse (1 of 10) was drawn randomly with equal probability. For stimuli with the same number of ‘up’ and ‘down’ pulses (12:12), subjects received randomized feedback.</p><p id="P27">The auditory onset and offset tones had a frequency of 200 and 300 Hz, respectively. The auditory feedback consisted of two tones: one linearly increasing from 200 to 600 Hz and the other in the reverse direction. The mapping of the two tones to feedback (i.e. correct or incorrect) was varied block-wise.</p><p id="P28">Each block consisted of 96 trials. Participants typically completed 4 repetitions of each of the 3 types of coherence level blocks, totalling 12 blocks. Each repetition included one block at each coherence level. The choice-motor mapping, auditory feedback mapping and coherence level for each block were determined pseudo-randomly, and participants were informed of the choice-motor and feedback mappings at the beginning of each block.</p></sec><sec id="S12"><title>Setup and recording</title><p id="P29">Neural activity was recorded using a 275-channel whole-head MEG system (Omega 2000, CTF Systems, Port Coquitlam, Canada) at a sampling rate of 2,343.75Hz. Participants sat upright in a dark, magnetically shielded chamber. Stimuli were projected onto a screen using either an LCD projector (Sanyo PLC-XP41, Moriguchi, Japan) or a DLP LED PROPixx projector (VPixx, Saint-Bruno, Canada) at 60 Hz refresh rate. Eye movements were tracked with an eyetracking system (Eyelink 1000, SR Research) at a sampling rate of 1000 Hz.</p></sec><sec id="S13"><title>Preprocessing</title><p id="P30">MEG Data was low-pass filtered at 10 Hz (two-pass forward-reverse Butter-worth filter, order 4) and down-sampled to 20 Hz. We used robust detrending [<xref ref-type="bibr" rid="R25">25</xref>] to remove polynomial trends from the MEG data in a piece-wise fashion (600 s pieces, removal of linear trend followed by 10<sup>th</sup> order polynomial). Individual noisy channels and trials were defined as those exceeding 10 times the standard deviation of the variability across channels or trials, respectively, and excluded from the analysis. For all temporally resolved analyses, results were smoothed using a 100 ms Hanning window (full width at half maximum).</p></sec><sec id="S14"><title>Data exclusion</title><p id="P31">Trials with blinks or eye movements outside of the fixation window were aborted and thus automatically excluded from analysis. Eye movements could not be measured for three participants, but their exclusion did not significantly change the results.</p><p id="P32">For some participants we were unable to analyse all 12 blocks due to technical issues. In one case this led to the exclusion of an entire coherence condition (high/full) due to a lack of counterbalancing across choice-response mappings.</p><p id="P33">Two participants were excluded due to insufficient behavioral performance caused by a misunderstanding of the task. Two participants were excluded due to technical problems with stimulus presentation or data recording. For reaction-time aligned choice analysis (<xref ref-type="fig" rid="F3">Fig 3B</xref>), two participants were excluded due to technical issues.</p></sec><sec id="S15"><title>Source reconstruction</title><p id="P34">As MRIs for individual participants were not available, we source reconstructed the data using a standard MNI template brain. We generated a single-shell head model [<xref ref-type="bibr" rid="R26">26</xref>] and for each participant estimated three-dimensional (x, y, and z-direction) MEG source activity at 457 equally spaced locations 7 mm beneath the skull, using linear spatial filtering (beamforming) [<xref ref-type="bibr" rid="R27">27</xref>]. We retained, for each source, activity in all 3 directions. For the searchlight analysis, we used each of the 457 sources’ immediate neighbours, including all 3 dipole directions. We averaged data within 5 intervals with respect to stimulus onset (-0.85-0 s; 0-1 s; 1-2 s; 2-3 s; 3-4 s).</p></sec><sec id="S16"><title>Cross-validated MANOVA</title><p id="P35">We applied a cross-validated MANOVA (cvMANOVA) on the MEG data from single participants to estimate neural information about each of the variables of interest [<xref ref-type="bibr" rid="R19">19</xref>,<xref ref-type="bibr" rid="R28">28</xref>]. cvMANOVA constitutes an extension of the commonly used cross-validated Mahalanobis distance and allows for the simultaneous estimation of neural data variability due to several variables of interest. This estimation is performed in relation to unexplained noise variability. We therefore first estimate a baseline noise covariance matrix, using all trials from all possible unique combinations of variables or ‘conditions’. For each unique condition, beta weights are estimated and contrasted between conditions in cross-validation fold ‘training’ and ‘test’ sets separately. An estimate of true pattern distinctness is computed as the dot product of these contrasts, normalised by the noise covariance: <disp-formula id="FD1"><mml:math id="M1"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mtext>Σ</mml:mtext><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p id="P36">where X<sub>test</sub> is the design matrix indicating the unique condition of each trial in the test set, C<sub>train is</sub> the contrast vector the model is trained on, C<sub>test</sub> the test contrast vector and Σ<sup>-1</sup> the inverted noise covariance matrix. B<sub>train</sub> and B<sub>test</sub> contain the regression parameters of a multivariate general linear model: <disp-formula id="FD2"><mml:math id="M2"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.2em"/></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mspace width="0.2em"/></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p id="P37">where Y<sub>train</sub> and Y<sub>test</sub> are the training and test datasets. The inverted noise covariance matrix was estimated from the mean activity during the time period starting from -0.85 seconds pre-stimulus to 2 seconds post-stimulus: <disp-formula id="FD3"><mml:math id="M3"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>v</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>v</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>Ξ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>v</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>v</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mi>Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mi>E</mml:mi><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>Ξ</mml:mi><mml:mo>'</mml:mo><mml:mi>Ξ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p id="P38">With fE being the degrees of freedom and p the number of sources used. Ξ was regularised towards the unity matrix using a regularisation parameter of 0.05.</p><p id="P39">Given that the design matrix and contrast vector include all unique conditions i.e. all possible combinations of variable levels, cvMANOVA independently quantifies information about each variable of interest, while not being confounded by information about the other, potentially correlated variables. In other words, cvMANOVA quantifies the pattern distinctness explained by each variable after discounting the patterns explained by all other variables included in the model. Importantly, cvMANOVA effectively controls imbalances in the distribution of trials over conditions without explicit stratification and the resulting loss of data.</p><p id="P40">Prior to cvMANOVA we reduced the dimensionality of the data using PCA. We computed a de-mixing matrix on the condition means of the training data only, and subsequently applied it to the test data. We selected the first 100 components for further analysis.</p><p id="P41">For all analyses we performed two-fold cross validation and 10 repetitions of cvMANOVA with different random seeds. We averaged results across repetitions and folds.</p></sec><sec id="S17"><title>Task variables and stimulus correction</title><p id="P42">To accurately estimate neural information about variables independently of each other, we had to ensure that all combinations of the variables of interest were present, including those under experimental control (coherence, choice-response mapping) and those dependent on the participants behaviour (choice, response). In all cvMANOVAs we included choice, response and coherence as variables.</p><p id="P43">As each stimulus pulse was randomly selected from 10 possible movies for each direction, there were many unique 2 s stimuli, such that the full stimulus could not be included as a variable. Given that stimulus and choice are correlated for non-chance performance, we used a stimulus correction procedure for those analyses assessing neural choice information independent of the stimulus (<xref ref-type="fig" rid="F3">Figs 3</xref>, <xref ref-type="fig" rid="F4">4</xref> and <xref ref-type="fig" rid="F5">5</xref>). For this, we computed the average neural activity for each pulse position, motion direction and coherence, and subtracted the 24 pulse-related averages from the neural data of individual trials based on the pulses presented on these trials. We then added back the pulse-related activity averaged across motion directions, independently for pulse position and coherence. This conservative correction likely removes choice-related neural activity that is strongly correlated with the stimulus. As this results in different over-corrections depending on performance, we did not interpret differences in choice information between coherence conditions.</p><p id="P44">To estimate the neural information associated with each individual pulse, we computed cvMANOVAs with the additional variable pulse direction, for each pulse position independently.</p></sec><sec id="S18"><title>Cross-variable information</title><p id="P45">To assess whether choice and response shared a common representational space, we measured cross-variable information. We implemented this by using a training contrast C<sub>train</sub> differentiating between choice levels, and a test contrast C<sub>test</sub> differentiating between response levels, and vice versa.</p><p id="P46">Notably a possible relationship between choice and response representations could vary in directionality across participants, such as for example an arbitrary choice-response associations that is unrelated to the actual choice-response mapping (e.g. an association between the left button and upwards motion). Thus, we did not average the resulting cross-variable information metric but compared absolute cross-variable information across participants (<xref ref-type="fig" rid="F5">Fig 5</xref>).</p><p id="P47">Given that the maximal amount of shared information between two variables depends on the information available for each variable independently, it was important to take the strength of the individual representations into account. We therefore compared the measured cross-variable information to an estimate of the cross-variable information that could be expected for identical representations of variable strength [<xref ref-type="bibr" rid="R28">28</xref>] <disp-formula id="FD4"><mml:math id="M4"><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mi>h</mml:mi><mml:mi>R</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mo>|</mml:mo><mml:mi>C</mml:mi><mml:mi>h</mml:mi><mml:mi>R</mml:mi><mml:mi>s</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:msqrt><mml:mo>⋅</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>C</mml:mi><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P48">where Ch and Rs denote the pattern distinctness for choice and response, respectively, and E<sub>ChRs</sub> is the expected cross-variable information. If representations were identical, the measured cross-variable information is expected to approach E<sub>ChRs</sub>, whereas cross-variable information small than E<sub>ChRs</sub> indicates non-overlapping representations [<xref ref-type="bibr" rid="R28">28</xref>].</p></sec><sec id="S19"><title>Statistical analysis</title><p id="P49">We assessed the statistical significance of information using cluster-based permutation tests. After determining temporally contiguous clusters during which pattern distinctness was higher than 0 (one-tailed t-test over participants, p &lt; 0.05), we randomly multiplied the information time-course of each participant 1,000 times with either 1 or −1. In each random permutation, we recomputed information clusters and determined the cluster mass of the strongest cluster. Each original cluster was assigned a p-value by comparing its mass to the distribution of masses of the random permutation’s strongest clusters.</p><p id="P50">To assess the cortical distribution of neural information we performed analogous cluster permutation tests, but across space and time.</p><p id="P51">To determine whether the multivariate patterns underlying choice and response were significantly different, we used one-tailed paired t-tests. We tested whether the absolute cross-variable information was smaller than the expected cross-variable information, and whether the absolute cross-variable information was higher than would be expected by chance. For the latter we ran cvMANOVA on data with shuffled choice labels and tested the absolute cross-variable information against this value. Tests were performed on the time period with robust choice and response information across participants (1.5-3 s).</p></sec><sec id="S20"><title>Software</title><p id="P52">Experimental code was written in MATLAB (Mathworks) using custom code and Psychophysics Toolbox extensions [<xref ref-type="bibr" rid="R29">29</xref>]. All analyses were performed in MATLAB using custom code as well as the Fieldtrip toolboxes [<xref ref-type="bibr" rid="R30">30</xref>].</p></sec></sec></body><back><ack id="S21"><title>Acknowledgements</title><p>We thank Gabi Walker-Dietrich and Jürgen Dax for assistance with MEG recordings. This research was supported by the European Research Council (ERC; <ext-link ext-link-type="uri" xlink:href="https://erc.europa.eu/">https://erc.europa.eu/</ext-link>) StG 335880 and CoG 864491 (M.S) and Deutsche Forschungsgemeinschaft (DFG; German Research Foundation; <ext-link ext-link-type="uri" xlink:href="https://www.dfg.de/">https://www.dfg.de/</ext-link>) project 276693517 (SFB 1233) (M.S.). The authors acknowledge support by the state of Baden-Württemberg through bwHPC, by the German Research Foundation (DFG) through grant no INST 39/963-1 FUGG (bwForCluster NEMO), and by the Open Access Publishing Fund of the University of Tübingen. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p></ack><fn-group><fn fn-type="con" id="FN1"><p id="P53"><bold>Author Contributions</bold></p><p id="P54">Conceptualization: M.S., K.R.Q., N.N.; investigation: N.N., E.Z.; formal analysis: K.R.Q.; writing – original draft preparation: K.R.Q.; writing – review and editing: M.S., K.R.Q., F.S., N.N., E.Z.; supervision: M.S.; resources: M.S., F.S.; funding acquisition: M.S</p></fn><fn fn-type="conflict" id="FN2"><p id="P55"><bold>Competing Interests</bold></p><p id="P56">All authors declare no competing interests.</p></fn></fn-group><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Donner</surname><given-names>TH</given-names></name><name><surname>Siegel</surname><given-names>M</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name><name><surname>Engel</surname><given-names>AK</given-names></name></person-group><article-title>Buildup of Choice-Predictive Activity in Human Motor Cortex during Perceptual Decision Making</article-title><source>Current Biology</source><year>2009</year><volume>19</volume><fpage>1581</fpage><lpage>1585</lpage><pub-id pub-id-type="pmid">19747828</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><article-title>The Neural Basis of Decision Making</article-title><source>Annu Rev Neurosci</source><year>2007</year><volume>30</volume><fpage>535</fpage><lpage>574</lpage><pub-id pub-id-type="pmid">17600525</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heekeren</surname><given-names>HR</given-names></name><name><surname>Marrett</surname><given-names>S</given-names></name><name><surname>Ungerleider</surname><given-names>LG</given-names></name></person-group><article-title>The neural systems that mediate human perceptual decision making</article-title><source>Nat Rev Neurosci</source><year>2008</year><volume>9</volume><fpage>467</fpage><lpage>479</lpage><pub-id pub-id-type="pmid">18464792</pub-id></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><article-title>Neural Basis of a Perceptual Decision in the Parietal Cortex (Area LIP) of the Rhesus Monkey</article-title><source>Journal of Neurophysiology</source><year>2001</year><volume>86</volume><fpage>1916</fpage><lpage>1936</lpage><pub-id pub-id-type="pmid">11600651</pub-id></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Siegel</surname><given-names>M</given-names></name><name><surname>Buschman</surname><given-names>TJ</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name></person-group><article-title>Cortical information flow during flexible sensorimotor decisions</article-title><source>Science</source><year>2015</year><volume>348</volume><fpage>1352</fpage><lpage>1355</lpage><pub-id pub-id-type="pmcid">PMC4721574</pub-id><pub-id pub-id-type="pmid">26089513</pub-id><pub-id pub-id-type="doi">10.1126/science.aab0551</pub-id></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cisek</surname><given-names>P</given-names></name><name><surname>Kalaska</surname><given-names>JF</given-names></name></person-group><article-title>Neural Mechanisms for Interacting with a World Full of Action Choices</article-title><source>Annu Rev Neurosci</source><year>2010</year><volume>33</volume><fpage>269</fpage><lpage>298</lpage><pub-id pub-id-type="pmid">20345247</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Regan</surname><given-names>JK</given-names></name><name><surname>Noë</surname><given-names>A</given-names></name></person-group><article-title>A sensorimotor account of vision and visual consciousness</article-title><source>Behav Brain Sci</source><year>2001</year><volume>24</volume><fpage>939</fpage><lpage>973</lpage><pub-id pub-id-type="pmid">12239892</pub-id></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Kiani</surname><given-names>R</given-names></name><name><surname>Hanks</surname><given-names>TD</given-names></name><name><surname>Churchland</surname><given-names>AK</given-names></name></person-group><chapter-title>Neurobiology of Decision Making: An Intentional Framework</chapter-title><person-group person-group-type="editor"><name><surname>Engel</surname><given-names>C</given-names></name><name><surname>Singer</surname><given-names>W</given-names></name></person-group><source>Better Than Conscious?</source><publisher-name>The MIT Press</publisher-name><year>2008</year><fpage>71</fpage><lpage>102</lpage><pub-id pub-id-type="doi">10.7551/mitpress/7735.003.0007</pub-id></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cisek</surname><given-names>P</given-names></name></person-group><article-title>Making decisions through a distributed consensus</article-title><source>Current Opinion in Neurobiology</source><year>2012</year><volume>22</volume><fpage>927</fpage><lpage>936</lpage><pub-id pub-id-type="pmid">22683275</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wispinski</surname><given-names>NJ</given-names></name><name><surname>Gallivan</surname><given-names>JP</given-names></name><name><surname>Chapman</surname><given-names>CS</given-names></name></person-group><article-title>Models, movements, and minds: bridging the gap between decision making and action</article-title><source>Annals of the New York Academy of Sciences</source><year>2020</year><volume>1464</volume><fpage>30</fpage><lpage>51</lpage><pub-id pub-id-type="pmid">30312476</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bennur</surname><given-names>S</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><article-title>Distinct Representations of a Perceptual Decision and the Associated Oculomotor Plan in the Monkey Lateral Intraparietal Area</article-title><source>Journal of Neuroscience</source><year>2011</year><volume>31</volume><fpage>913</fpage><lpage>921</lpage><pub-id pub-id-type="pmcid">PMC3380543</pub-id><pub-id pub-id-type="pmid">21248116</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4417-10.2011</pub-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hebart</surname><given-names>MN</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name><name><surname>Haynes</surname><given-names>J-D</given-names></name></person-group><article-title>Human visual and parietal cortex encode visual choices independent of motor plans</article-title><source>NeuroImage</source><year>2012</year><volume>63</volume><fpage>1393</fpage><lpage>1403</lpage><pub-id pub-id-type="pmid">22922368</pub-id></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horwitz</surname><given-names>GD</given-names></name><name><surname>Batista</surname><given-names>AP</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><article-title>Representation of an Abstract Perceptual Decision in Macaque Superior Colliculus</article-title><source>Journal of Neurophysiology</source><year>2004</year><volume>91</volume><fpage>2281</fpage><lpage>2296</lpage><pub-id pub-id-type="pmid">14711971</pub-id></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quinn</surname><given-names>KR</given-names></name><name><surname>Seillier</surname><given-names>L</given-names></name><name><surname>Butts</surname><given-names>DA</given-names></name><name><surname>Nienborg</surname><given-names>H</given-names></name></person-group><article-title>Decision-related feedback in visual cortex lacks spatial selectivity</article-title><source>Nat Commun</source><year>2021</year><volume>12</volume><elocation-id>4473</elocation-id><pub-id pub-id-type="pmcid">PMC8298450</pub-id><pub-id pub-id-type="pmid">34294703</pub-id><pub-id pub-id-type="doi">10.1038/s41467-021-24629-0</pub-id></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sandhaeger</surname><given-names>F</given-names></name><name><surname>Omejc</surname><given-names>N</given-names></name><name><surname>Pape</surname><given-names>A-A</given-names></name><name><surname>Siegel</surname><given-names>M</given-names></name></person-group><article-title>Abstract perceptual choice signals during action-linked decisions in the human brain</article-title><person-group person-group-type="editor"><name><surname>Noppeney</surname><given-names>U</given-names></name></person-group><source>PLoS Biol</source><year>2023</year><volume>21</volume><elocation-id>e3002324</elocation-id><pub-id pub-id-type="pmcid">PMC10564462</pub-id><pub-id pub-id-type="pmid">37816222</pub-id><pub-id pub-id-type="doi">10.1371/journal.pbio.3002324</pub-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Filimon</surname><given-names>F</given-names></name><name><surname>Philiastides</surname><given-names>MG</given-names></name><name><surname>Nelson</surname><given-names>JD</given-names></name><name><surname>Kloosterman</surname><given-names>NA</given-names></name><name><surname>Heekeren</surname><given-names>HR</given-names></name></person-group><article-title>How Embodied Is Perceptual Decision Making? Evidence for Separate Processing of Perceptual and Motor Decisions</article-title><source>J Neurosci</source><year>2013</year><volume>33</volume><fpage>2121</fpage><lpage>2136</lpage><pub-id pub-id-type="pmcid">PMC6619122</pub-id><pub-id pub-id-type="pmid">23365248</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2334-12.2013</pub-id></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ludwig</surname><given-names>S</given-names></name><name><surname>Herding</surname><given-names>J</given-names></name><name><surname>Blankenburg</surname><given-names>F</given-names></name></person-group><article-title>Oscillatory EEG signatures of postponed somatosensory decisions</article-title><source>Human Brain Mapping</source><year>2018</year><volume>39</volume><fpage>3611</fpage><lpage>3624</lpage><pub-id pub-id-type="pmcid">PMC6866617</pub-id><pub-id pub-id-type="pmid">29717524</pub-id><pub-id pub-id-type="doi">10.1002/hbm.24198</pub-id></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Charlton</surname><given-names>JA</given-names></name><name><surname>Goris</surname><given-names>RLT</given-names></name></person-group><article-title>Abstract deliberation by visuomotor neurons in prefrontal cortex</article-title><source>Nat Neurosci</source><year>2024</year><date-in-citation>cited 30 Apr 2024</date-in-citation><pub-id pub-id-type="pmcid">PMC11156582</pub-id><pub-id pub-id-type="pmid">38684894</pub-id><pub-id pub-id-type="doi">10.1038/s41593-024-01635-1</pub-id></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allefeld</surname><given-names>C</given-names></name></person-group><article-title>Searchlight-based multi-voxel pattern analysis of fMRI by cross-validated MANOVA</article-title><year>2014</year><volume>13</volume><pub-id pub-id-type="pmid">24296330</pub-id></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Voigtlaender</surname><given-names>VA</given-names></name><name><surname>Sandhaeger</surname><given-names>F</given-names></name><name><surname>Hawellek</surname><given-names>DJ</given-names></name><name><surname>Hage</surname><given-names>SR</given-names></name><name><surname>Siegel</surname><given-names>M</given-names></name></person-group><article-title>Neural representations of the content and production of human vocalization</article-title><source>Proc Natl Acad Sci USA</source><year>2023</year><volume>120</volume><elocation-id>e2219310120</elocation-id><pub-id pub-id-type="pmcid">PMC10265962</pub-id><pub-id pub-id-type="pmid">37253014</pub-id><pub-id pub-id-type="doi">10.1073/pnas.2219310120</pub-id></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hebart</surname><given-names>MN</given-names></name><name><surname>Schriever</surname><given-names>Y</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name><name><surname>Haynes</surname><given-names>J-D</given-names></name></person-group><article-title>The Relationship between Perceptual Decision Variables and Confidence in the Human Brain</article-title><source>Cereb Cortex</source><year>2016</year><volume>26</volume><fpage>118</fpage><lpage>130</lpage><pub-id pub-id-type="pmid">25112281</pub-id></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gherman</surname><given-names>S</given-names></name><name><surname>Markowitz</surname><given-names>N</given-names></name><name><surname>Tostaeva</surname><given-names>G</given-names></name><name><surname>Espinal</surname><given-names>E</given-names></name><name><surname>Mehta</surname><given-names>AD</given-names></name><name><surname>O’Connell</surname><given-names>RG</given-names></name><etal/></person-group><article-title>Intracranial electroencephalography reveals effector-in-dependent evidence accumulation dynamics in multiple human brain regions</article-title><source>Nat Hum Behav</source><year>2024</year><volume>8</volume><fpage>758</fpage><lpage>770</lpage><pub-id pub-id-type="pmid">38366105</pub-id></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>IM</given-names></name><name><surname>Meister</surname><given-names>MLR</given-names></name><name><surname>Huk</surname><given-names>AC</given-names></name><name><surname>Pillow</surname><given-names>JW</given-names></name></person-group><article-title>Encoding and decoding in parietal cortex during sensorimotor decision-making</article-title><source>Nat Neurosci</source><year>2014</year><volume>17</volume><fpage>1395</fpage><lpage>1403</lpage><pub-id pub-id-type="pmcid">PMC4176983</pub-id><pub-id pub-id-type="pmid">25174005</pub-id><pub-id pub-id-type="doi">10.1038/nn.3800</pub-id></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Okazawa</surname><given-names>G</given-names></name><name><surname>Kiani</surname><given-names>R</given-names></name></person-group><article-title>Neural Mechanisms That Make Perceptual Decisions Flexible</article-title><source>Annu Rev Physiol</source><year>2023</year><volume>85</volume><fpage>191</fpage><lpage>215</lpage><pub-id pub-id-type="pmcid">PMC10308708</pub-id><pub-id pub-id-type="pmid">36343603</pub-id><pub-id pub-id-type="doi">10.1146/annurev-physiol-031722-024731</pub-id></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Cheveigné</surname><given-names>A</given-names></name><name><surname>Arzounian</surname><given-names>D</given-names></name></person-group><article-title>Robust detrending, rereferencing, outlier detection, and inpainting for multichannel data</article-title><source>NeuroImage</source><year>2018</year><volume>172</volume><fpage>903</fpage><lpage>912</lpage><pub-id pub-id-type="pmcid">PMC5915520</pub-id><pub-id pub-id-type="pmid">29448077</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.01.035</pub-id></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nolte</surname><given-names>G</given-names></name></person-group><article-title>The magnetic lead field theorem in the quasi-static approximation and its use for magnetoencephalography forward calculation in realistic volume conductors</article-title><source>Phys Med Biol</source><year>2003</year><volume>48</volume><fpage>3637</fpage><lpage>3652</lpage><pub-id pub-id-type="pmid">14680264</pub-id></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Veen</surname><given-names>BD</given-names></name><name><surname>Van Drongelen</surname><given-names>W</given-names></name><name><surname>Yuchtman</surname><given-names>M</given-names></name><name><surname>Suzuki</surname><given-names>A</given-names></name></person-group><article-title>Localization of brain electrical activity via linearly constrained minimum variance spatial filtering</article-title><source>IEEE Trans Biomed Eng</source><year>1997</year><volume>44</volume><fpage>867</fpage><lpage>880</lpage><pub-id pub-id-type="pmid">9282479</pub-id></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sandhaeger</surname><given-names>F</given-names></name><name><surname>Siegel</surname><given-names>M</given-names></name></person-group><article-title>Testing the generalization of neural representations</article-title><source>NeuroImage</source><year>2023</year><volume>278</volume><elocation-id>120258</elocation-id><pub-id pub-id-type="pmcid">PMC10443234</pub-id><pub-id pub-id-type="pmid">37429371</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2023.120258</pub-id></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kleiner</surname><given-names>M</given-names></name><name><surname>Brainard</surname><given-names>DH</given-names></name><name><surname>Pelli</surname><given-names>DG</given-names></name></person-group><article-title>What’s new in Psychtoolbox-3?</article-title><source>Perception</source><year>2007</year><volume>36</volume><fpage>89</fpage></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oostenveld</surname><given-names>R</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name><name><surname>Maris</surname><given-names>E</given-names></name><name><surname>Schoffelen</surname><given-names>J-M</given-names></name></person-group><article-title>FieldTrip: Open Source Software for Advanced Analysis of MEG, EEG, and Invasive Electrophysiological Data</article-title><source>Computational Intelligence and Neuroscience</source><year>2011</year><volume>2011</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="pmcid">PMC3021840</pub-id><pub-id pub-id-type="pmid">21253357</pub-id><pub-id pub-id-type="doi">10.1155/2011/156869</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>Up-Down motion discrimination task and behavioural performance.</title><p>(<bold>A</bold>) On each trial, participants (n = 16) were required to discriminate the average motion direction of 24 random-dot motion pulses. Choice was indicated with a left or right button press. The mapping of choice to response was pseudo-randomised block-wise (96 trials per block), such that in one block a left button press corresponded to an ‘up’ choice, and in another block to a ‘down’ choice. Grey arrows depict average pulse motion, shown here for visualisation purposes only. (<bold>B</bold>) Histogram of the proportion of successive blocks with stable choice-response mapping. (<bold>C</bold>) Ratio of ‘up’ to ‘down’ motion pulses as percentage of trials. Each pulse was drawn randomly with equal probability. 12:12 corresponded to an equal number of ‘up’ and ‘down’ pulses on a trial, for which participants were rewarded randomly. (<bold>D</bold>) Motion coherence and correct performance for the three coherence levels (low, medium, high). Coherence was pseudo-randomly varied across blocks. Low and medium coherence levels were adjusted for each participant to target 66% and 75% correct performance, respectively, using staircases prior to the task. High coherence was 100%. Error bars denote SEM across subjects.</p></caption><graphic xlink:href="EMS199508-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Neural information about motion direction and motor response.</title><p>(<bold>A</bold>) Neural information about the direction of each motion pulse averaged across coherence levels. P1 and P23 denote the first and second-to-last pulse respectively. Time axis spans stimulus onset to offset. (<bold>B</bold>) Neural information averaged across pulses 1-23, aligned to pulse onset, for each coherence level. (<bold>C</bold>) Neural information about the side on which the button was pressed (left vs. right) for each coherence level. Horizontal bars denote temporal clusters of significant information (p &lt; 0.05; cluster permutation). Solid lines and shaded regions indicate the mean +/- SEM of information across participants (N = 16).</p></caption><graphic xlink:href="EMS199508-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Neural information about choice.</title><p>(<bold>A</bold>) Neural information about the participants choices (up vs. down) averaged across coherence conditions and aligned to stimulus onset (n = 16). (<bold>B</bold>) Choice information aligned to the time of response (n = 14). Horizontal bars denote temporal clusters of significant information (p &lt; 0.05; cluster permutation). Solid lines and shaded regions indicate the mean +/- SEM of information across participants.</p></caption><graphic xlink:href="EMS199508-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Cortical distribution of choice and response information.</title><p>The spatiotemporal distribution of choice (upper row) and response (bottom row) information for 5 temporal intervals, with respect to stimulus onset (0 s). Only significant clusters of information are shown (p &lt; 0.05; cluster permutation).</p></caption><graphic xlink:href="EMS199508-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>Cross-variable information between choice and response</title><p>(<bold>A</bold>) Absolute cross-variable information is significantly lower than expected for identical neural patterns of choice and response information. (<bold>B</bold>) Absolute cross-variable information between choice and response was significantly higher than expected by chance for data with shuffled choice labels. Each dot represents a single participant. All analyses are for the time interval 1.5-3 s post stimulus onset.</p></caption><graphic xlink:href="EMS199508-f005"/></fig></floats-group></article>