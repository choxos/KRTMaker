<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS199398</article-id><article-id pub-id-type="doi">10.1101/2024.10.11.617777</article-id><article-id pub-id-type="archive">PPR923703</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">2</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Defacing biases visual quality assessments of structural MRI</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Provins</surname><given-names>Céline</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Savary</surname><given-names>Élodie</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Sanchez</surname><given-names>Thomas</given-names></name><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Mullier</surname><given-names>Emeline</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Barranco</surname><given-names>Jaime</given-names></name><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A4">4</xref><xref ref-type="aff" rid="A5">5</xref></contrib><contrib contrib-type="author"><name><surname>Fischi-Gómez</surname><given-names>Elda</given-names></name><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A6">6</xref></contrib><contrib contrib-type="author"><name><surname>Alemán-Gómez</surname><given-names>Yasser</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A7">7</xref></contrib><contrib contrib-type="author"><name><surname>Richiardi</surname><given-names>Jonas</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Poldrack</surname><given-names>Russell A.</given-names></name><xref ref-type="aff" rid="A8">8</xref></contrib><contrib contrib-type="author"><name><surname>Hagmann</surname><given-names>Patric</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Esteban</surname><given-names>Oscar</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib></contrib-group><aff id="A1"><label>1</label>Department of Radiology, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/05a353079</institution-id><institution>Lausanne University Hospital</institution></institution-wrap> and <institution-wrap><institution-id institution-id-type="ror">https://ror.org/019whta54</institution-id><institution>University of Lausanne</institution></institution-wrap>, <city>Lausanne</city>, <country country="CH">Switzerland</country></aff><aff id="A2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03fw2bn12</institution-id><institution>CIBM - Center for Biomedical Imaging</institution></institution-wrap>, <country country="CH">Switzerland</country></aff><aff id="A3"><label>3</label>EEG and Epilepsy Unit, University Hospital and Faculty of Medicine of Geneva, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/01swzsf04</institution-id><institution>University of Geneva</institution></institution-wrap>, <country country="CH">Switzerland</country></aff><aff id="A4"><label>4</label>School of Engineering, Institute of Systems Engineering, HES-SO Valais-Wallis, Sion, Switzerland</aff><aff id="A5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01eas9a07</institution-id><institution>The Sense Innovation and Research Center</institution></institution-wrap>, <city>Lausanne and Sion</city>, <country country="CH">Switzerland</country></aff><aff id="A6"><label>6</label>Signal Processing Laboratory (LTS5), <institution-wrap><institution-id institution-id-type="ror">https://ror.org/02s376052</institution-id><institution>École Polytechnique Fédérale de Lausanne (EPFL)</institution></institution-wrap>, <city>Lausanne</city>, <country country="CH">Switzerland</country></aff><aff id="A7"><label>7</label>Center for Psychiatric Neuroscience, Department of Psychiatry, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/05a353079</institution-id><institution>Lausanne University Hospital</institution></institution-wrap> and <institution-wrap><institution-id institution-id-type="ror">https://ror.org/019whta54</institution-id><institution>University of Lausanne</institution></institution-wrap>. <city>Prilly</city>, <country country="CH">Switzerland</country></aff><aff id="A8"><label>8</label>Department of Psychology, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/00f54p054</institution-id><institution>Stanford University</institution></institution-wrap>, <city>Stanford</city>, <state>CA</state>, <country country="US">US</country></aff><pub-date pub-type="nihms-submitted"><day>14</day><month>10</month><year>2024</year></pub-date><pub-date pub-type="preprint"><day>12</day><month>10</month><year>2024</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">A critical step before data-sharing of human neuroimaging is removing facial features to protect individuals’ privacy. However, not only does this process redact identifiable information about individuals, but it also removes non-identifiable information. This introduces undesired variability into downstream analysis and interpretation. This registered report investigated the degree to which the so-called <italic>defacing</italic> altered the quality assessment of T<sub>1</sub>-weighted images of the human brain from the openly available “IXI dataset”. The effect of defacing on manual quality assessment was investigated on a single-site subset of the dataset (N=185). By comparing two linear mixed-effects models, we determined that four trained human raters’ perception of quality was significantly influenced by defacing by modeling their ratings on the same set of images in two conditions: “nondefaced” (i.e., preserving facial features) and “defaced”. In addition, we investigated these biases on automated quality assessments by applying repeated-measures, multivariate ANOVA (rm-MANOVA) on the image quality metrics extracted with <italic>MRIQC</italic> on the full IXI dataset (N=581; three acquisition sites).</p><p id="P2">This study found that defacing altered the quality assessments by humans and showed that <italic>MRIQC</italic>’s quality metrics were mostly insensitive to defacing.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P3">The removal of facial features—or <italic>defacing</italic>—is necessary before sharing anatomical images of the brain to protect participants’ privacy [<xref ref-type="bibr" rid="R1">1</xref>] in compliance with some local privacy protection regulations, such as the General Data Privacy Regulation (GDPR) in Europe [<xref ref-type="bibr" rid="R2">2</xref>] or the Health Insurance Portability and Accountability Act (HIPAA) in the US [<xref ref-type="bibr" rid="R3">3</xref>]. Defacing is typically implemented by zeroing, shuffling, or filtering the content of image voxels located in an area around the participant’s face and, often, the ears (see <xref ref-type="fig" rid="F1">Fig. 1</xref>). Defacing is a destructive step with the potential to alter the results of downstream processing. De Sitter et al. [<xref ref-type="bibr" rid="R4">4</xref>] investigated the undesired effects of defacing on automated workflows in neurodegeneration studies. Failure rates—i.e., the percentage of inputs for which workflows did not finish successfully—were substantially larger on defaced inputs (19%) compared to their nondefaced counterparts (2%). They also reported systematic differences between the same processing with and without defacing in several outcomes of interest, such as gray- and white-matter volume and cortical thickness. Schwarz et al. [<xref ref-type="bibr" rid="R1">1</xref>] showed how these failures propagate and accumulate downstream, leading to substantial changes in the study outcomes. In a similar approach to our design, Bhalerao et al. [<xref ref-type="bibr" rid="R5">5</xref>] explored the impact of different defacing tools on a subset of image quality metrics (IQMs) automatically generated with <italic>MRIQC</italic> [<xref ref-type="bibr" rid="R6">6</xref>]. They found that all defacing tools impacted a subset of IQMs, and they estimated corresponding effect sizes on a sample limited to 30 subjects with a univariate modeling approach. Moreover, they identified further effects on the downstream segmentation of images. To the best of our knowledge, no study has investigated the impact of defacing on the manual assessment of MRI data quality.</p><p id="P4">Understanding how defacing alters the initial quality checkpoint of the research workflow [<xref ref-type="bibr" rid="R7">7</xref>] is necessary because there is compelling evidence that data showing specific artifacts or insufficient overall quality introduce bias into the results of analyses, raising questions about their validity [<xref ref-type="bibr" rid="R8">8</xref>–<xref ref-type="bibr" rid="R10">10</xref>]. For example, Alexander-Bloch et al. [<xref ref-type="bibr" rid="R10">10</xref>] showed that in-scanner motion can lead to systematic and region-specific biases in anatomical estimation of features of interest, such as cortical thickness.</p><p id="P5">Therefore, it is critical to reliably identify substandard MRI data and exclude them early from the research workflow (quality control, QC). Our previous efforts to automate QC by learning <italic>MRIQC</italic>’s IQMs [<xref ref-type="bibr" rid="R6">6</xref>, <xref ref-type="bibr" rid="R11">11</xref>] demonstrated that site-effects imposed the largest limitation on the performance. The reportedly modest reliability of automated QC alternatives currently available explains that QA/QC continues to require the screening of imaging data on a one-by-one basis. Because visual inspection is time-consuming and prone to large intra- and inter-rater variabilities, implementing assisting tools and protocols to screen large datasets efficiently is an active line of work (e.g., <italic>MRIQC</italic> [<xref ref-type="bibr" rid="R6">6</xref>], <italic>MindControl</italic> [<xref ref-type="bibr" rid="R12">12</xref>], and <italic>Swipes4science</italic> [<xref ref-type="bibr" rid="R13">13</xref>]). Large consortia have also made substantial investments in this critical task and have generated valuable contributions to quality assurance (QA) protocols and corresponding QC criteria, e.g., the Human Connectome Project [<xref ref-type="bibr" rid="R14">14</xref>] or the INDI initiative (QAP [<xref ref-type="bibr" rid="R15">15</xref>]). One related but conceptually innovative approach was proposed by the UK Biobank [<xref ref-type="bibr" rid="R16">16</xref>], where sufficient quality was operationalized as the success of downstream processing. Given the massive size of the UK Biobank, Alfaro-Almagro et al. [<xref ref-type="bibr" rid="R16">16</xref>] flagged the images that did not successfully undergo pre-processing for exclusion. Although image exclusions were related most often to qualitative issues on images (e.g., artifacts), some images were discarded without straightforward mapping to quality issues. Moreover, because manual QC is onerous, many teams have attempted automation, either by defining <italic>no-reference</italic> (that is, <italic>no ground truth is available</italic>) IQMs that can be used to learn a machine predictor [<xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R15">15</xref>,<xref ref-type="bibr" rid="R17">17</xref>] or by training deep models directly on 3D images [<xref ref-type="bibr" rid="R18">18</xref>]. However, the problem remains extremely challenging when predicting the quality of images acquired at new MRI devices yet unseen by the model [<xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R11">11</xref>].</p><p id="P6">In a recent exploration [<xref ref-type="bibr" rid="R19">19</xref>], we found preliminary evidence that defacing alters both the manual and automatic assessments of T<sub>1</sub>-weighted (T1w) MRI on a small sample (N=10 subjects), implemented with <italic>MRIQC</italic>. The present registered report built on our exploratory analysis and confirmed that four trained human raters made systematically varying QC decisions when rating the same images depending on whether they have been defaced. Regarding automated QC, this paper showed that differences in IQMs extracted with <italic>MRIQC</italic> before and after defacing were not meaningful.</p></sec><sec id="S2" sec-type="methods"><title>Methods</title><p id="P7">The lettered footnotes in this section indicate deviations from the Stage 1 protocol and are reported in the “Protocol Deviations” subsection.</p><sec id="S3"><title>Hypotheses</title><p id="P8">This pre-registered report was set out to confirm whether defacing alters the manual and automatic QC of T1w images of the healthy human brain—implemented with <italic>MRIQC</italic>. This overarching question was tested in two specific hypotheses:</p><list list-type="order" id="L1"><list-item><p id="P9">Defacing influences trained experts’ perception of quality, leading to significant differences in quality ratings between the defaced and the nondefaced images. Specifically, we expected raters to assign higher ratings—on average—in the defaced condition than in the corresponding nondefaced condition (see <xref ref-type="fig" rid="F1">Fig. 1</xref>).</p></list-item><list-item><p id="P10">Defacing influences automatic QA/QC with <italic>MRIQC</italic>, introducing significant and systematic biases in vectors of IQMs extracted from defaced and nondefaced images. As evidenced by our preliminary data [<xref ref-type="bibr" rid="R19">19</xref>], these biases may showcase one direction for some IQMs and the opposite or no effects on others. Therefore, a directionality of effects could not be hypothesized.</p></list-item></list></sec><sec id="S4"><title>Data</title><p id="P11">This analysis was based on the publicly available IXI dataset [<xref ref-type="bibr" rid="R20">20</xref>], which contains 581<sup>a</sup> nondefaced T1w images acquired at three different sites in London (UK). One site was the Hammersmith Hospital (HH in the following), which used one 3 Tesla (3T) scanner. The two other sites (Guy’s Hospital and Institute of Psychiatry, Psychology &amp; Neuroscience; GH and IoPPN, respectively) featured 1.5T devices. The scanner parameters available for each site are listed in <xref ref-type="supplementary-material" rid="SD1">Table S1</xref>. None of the authors had screened or queried the dataset before pre-registration to anticipate quality-related patterns or summary statistics. Moreover, except for author OE, authors neither accessed nor performed any processing on the data before pre-registration. To investigate Hypothesis 1, the initial inclusion criterion was “all subjects with a T1w scan acquired at the 3T site (HH)”, yielding a total of 185 subjects <sup>b</sup>. In testing Hypothesis 2, we included all participants in the IXI dataset with a T1w scan (581 <sup>a</sup> subjects) <sup>b</sup>. Images were excluded from the evaluation of hypotheses 1 and 2 in the case of complete failure of image reconstruction <sup>b</sup>. The local ethics committee has approved the processing of nondefaced images. This study does not attempt to re-identify the participants nor facilitate in any way such efforts <sup>c</sup>.</p><sec id="S5"><title>Data processing</title><p id="P12">First, a defaced version of each scan (N=581) was generated with <italic>PyDeface</italic> [<xref ref-type="bibr" rid="R21">21</xref>]. We chose <italic>PyDeface</italic> because it currently presents the highest success rate at removing facial features while not removing brain voxels [<xref ref-type="bibr" rid="R22">22</xref>]. Furthermore, Bhalerao et al. [<xref ref-type="bibr" rid="R5">5</xref>] showed that <italic>PyDeface</italic> resulted in the smallest effect size on a subset of <italic>MRIQC</italic>’s IQMs. Fatal failure of <italic>PyDeface</italic> was the only exclusion criterion. Because all images were successfully processed, no images were dropped from the analysis for this reason. To avoid exclusion bias that could artificially inflate the effect size, images showcasing low-quality defacing, such as those partially retaining facial features—e.g., the eyes,—were included in the analysis <sup>d</sup>. These cases were expected to be more similar between defaced and nondefaced conditions, potentially attenuating differences in human ratings and IQMs. The raters then assessed the quality of the same images in two conditions (nondefaced and defaced) following the Manual assessment protocol described below. Raters did not have access to the mapping between defaced and nondefaced counterparts. We obfuscated participant identifiers and shuffled their ordering before presentation. The latest version in the 23.1 series of <italic>MRIQC</italic> (version 23.1.0) was then executed on all the T1w images available (that is, nondefaced and defaced). Then, the IQMs generated by <italic>MRIQC</italic>, corresponding to every image in the two nondefaced/defaced conditions, were collated and converted into a tabular format. Two subjects from the GH site (1.5T) were excluded because <italic>MRIQC</italic> failed to run on both the nondefaced and defaced images, reducing the dataset size to test Hypothesis 2 to 579 subjects. Hypothesis 1 (HH site) was not affected by this exclusion <sup>e</sup>.</p></sec><sec id="S6"><title>Manual assessment protocol</title><p id="P13">We performed manual quality assessment only on the images from the site with a 3T device (HH; N=185). This choice eliminated the field strength and other variability sources emerging from the specific scanning site as potential random effects. Moreover, images acquired with the 3T scanner were expected to showcase a signal-to-noise ratio (SNR) approximately twice as high as the SNR of images acquired with 1.5T scanners. Thus, the images acquired with the 3T scanner likely yielded, on average, better quality assessments by human raters independently of the defacing condition. Four human raters (authors TS, EM, JB, and EFG <sup>f</sup>) assessed the quality of the subsample in each of the two conditions (that is, defaced and nondefaced). The quality assessment was carried out by individually screening one <italic>MRIQC</italic>-generated visual report per subject and condition. These reports are openly shared (see Data and code availability statement). Raters were recruited by inviting researchers who expressed their interest in QA/QC within the Department of Radiology of the Lausanne University Hospital (Lausanne, Switzerland) via e-mail. We did not impose restrictions on the raters’ experience beyond familiarity with T1w images of the human brain. To ensure the consistency of their training, raters read our published QC protocol [<xref ref-type="bibr" rid="R23">23</xref>] and participated in a 3h <sup>g</sup> training session. Following our guidelines [<xref ref-type="bibr" rid="R23">23</xref>], raters were instructed that it was critical to scrutinize the background visualization carefully because most of the artifacts are more noticeable in the absence of signal of interest.</p><p id="P14">Several examples supported this remark during the training sessions (see <xref ref-type="fig" rid="F1">Fig. 1</xref>, <xref ref-type="supplementary-material" rid="SD1">Supplementary Fig. S21</xref>, and the training materials). At the end <sup>g</sup> of this session, raters self-assessed their experience as either beginner, intermediate, or advanced. <sup>h</sup> One rater identified themself as an advanced rater, the three others as intermediate. The training session included an introduction to <italic>MRIQC</italic>’s visual reports, its “rating widget” (<xref ref-type="supplementary-material" rid="SD1">Fig. S1</xref>), and the data collection tools and settings. We also presented the list of quality criteria to consider, and for each criterion, we illustrated an exclusion example.</p><p id="P15">These examples were extracted from diverse, publicly available datasets [<xref ref-type="bibr" rid="R24">24</xref>–<xref ref-type="bibr" rid="R27">27</xref>] and in-house datasets. Lastly, in the same session, the raters were asked to assess 20 images independently, and we compared and discussed the ratings together to ensure that the quality criteria were interpreted consistently. None of the training and calibration examples were extracted from the IXI dataset. The materials corresponding to the training session, as well as the self-assessments of experience, are openly shared for future exploration (see Data and code availability statement). To assess the intra-rater effects on QC, 40 subjects selected randomly were presented a second time in both conditions to all raters without their knowledge. This summed up to 450 images per rater (225 images per condition). We chose to repeat 40 subjects because it represented a good trade-off between having enough statistical power and the risk of having raters who would not complete their assignment. The random number generator to choose the 40 repeated subjects and the blinding of participant identifiers were initialized with the timestamp of the registered report submission toward Stage 1. It was converted to an integer with the format YYMMDD + SSmmHH (Y: year, two last digits; M: month, D: day; S: seconds; m: minutes; H: hour). This seed was then preserved, clearly reported, and set for all the analyses. After screening each visual report, the raters assigned each image a quality grade with the rating widget presented in <xref ref-type="supplementary-material" rid="SD1">Fig. S1</xref> <sup>h</sup>. A quality score was assigned using a slider that permits the selection of numbers in a continuous scale from 1.0 to 4.0 (interval step of 0.05 and the value of 1.0 corresponding to the lowest quality). As presented in <xref ref-type="supplementary-material" rid="SD1">Fig. S1</xref> <sup>h</sup>, the slider was presented with four categorical ranges for reference. The starting position of the slider was set in the middle. The raters were instructed to assess each subject according to our QC protocol [<xref ref-type="bibr" rid="R23">23</xref>], and they did not have access to the IQMs. All raters viewed the visual reports on a single LED panel of 43” screen diagonal, 3840×2160 resolution, a typical static contrast of 5,000:1, and the same ambient lighting. <italic>MRIQC</italic> reports feature a stopwatch that recorded the exact time each assessment took. The time for each assessment was measured and is available for future exploration. The removal of the IQMs from the visual reports, the assignment of images in the two conditions to raters, the shuffling of ordering of presentation, the actual presentation, and the tracking of raters’ progress was managed with <italic>Q’kay</italic> [<xref ref-type="bibr" rid="R28">28</xref>], a Web Service we developed for this study. <sup>b</sup> Images assigned the lowest grade (one in our 1-4 interval scale) in both conditions by all raters would be excluded from all analyses. No images met this criterion.</p></sec></sec><sec id="S7"><title>Experiments</title><sec id="S8"><title>Determining that defacing biases the human raters’ assessments of quality</title><p id="P16">We tested the influence of the defacing condition and the rater (within-subject factor variables) on the ratings (dependent variable) by comparing linear mixed-effects (LME) model fits by means of a likelihood-ratio test. The LME modeling was a contingency alternative in case data violated some of the normality and sphericity assumptions of repeated-measures ANOVA (rm-ANOVA). As opposed to multiple <italic>t</italic>-tests, rm-ANOVA and LMEs enabled disentangling the inter-rater variability from intra-rater variability due to defacing and quantifying the latter. Because we do not necessarily expect the ratings distribution of each rater to have the same mean, rm-ANOVA and LMEs accounted for the baseline difference in ratings by adding the rater as a random effect in the model. We removed the 40 repeated images from the dataset because neither rm-ANOVA nor LMEs allow non-uniquely identified rows <sup>i</sup>. We first verified that the sphericity and normality assumptions of rm-ANOVA were unmet. Normality was verified with the Shapiro-Wilk normality test [<xref ref-type="bibr" rid="R29">29</xref>], employing the <italic>shapiro.test</italic> function of the <italic>ggpubr R</italic> package [<xref ref-type="bibr" rid="R30">30</xref>]. Sphericity was assessed with Mauchly’s test for sphericity [<xref ref-type="bibr" rid="R31">31</xref>] within the <italic>rstatix</italic> [<xref ref-type="bibr" rid="R32">32</xref>] <italic>R</italic> package. rm-ANOVA was implemented with the <italic>anova_test</italic> function (<italic>rstatix</italic>; <italic>p</italic>&lt;.02). <sup>i</sup> A preliminary sensitivity analysis (<xref ref-type="table" rid="T1">Table 1</xref>) executed with <italic>G*Power</italic> [<xref ref-type="bibr" rid="R33">33</xref>] had determined that our experimental design with rm-ANOVA could identify effects of size f=0.218 / <inline-formula><mml:math id="M1"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.045</mml:mn></mml:mrow></mml:math></inline-formula> (<xref ref-type="table" rid="T1">Table 1</xref>) with a power of 90% (see Equation S1 to convert effect size of type f to type <inline-formula><mml:math id="M2"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>).</p><p id="P17">For context, we found an effect size of f=0.31 (see Equations S2 and S3) in our pilot study.</p><p id="P18">Comparisons between both effect sizes need to be performed cautiously as the design of the rating collection has been modified between the pilot study and this report. In the contingency that at least one of the assumptions of rm-ANOVA was violated, we planned to compare two LMEs instead, one “alternative” model with defacing as a fixed effect and one “baseline” without defacing as a factor. In both models, the intercept was allowed to vary between raters (i.e., subject and rater were random effects) <sup>j</sup>. The models were implemented in R with the <italic>lmer</italic> function of the <italic>lme4</italic> package [<xref ref-type="bibr" rid="R34">34</xref>]. As part of regression diagnostics (e.g., non-Gaussian or heteroscedastic residuals indicate non-optimal model fit), we examined the shape of regression residuals, which are reported in the Supplementary Materials for completeness. To test the effect of defacing, we performed a likelihood-ratio test comparing baseline and alternative LMEs. The likelihood-ratio test was implemented with the <italic>anova</italic> function of the <italic>R</italic> package <italic>stats</italic> [<xref ref-type="bibr" rid="R35">35</xref>] <sup>k</sup>. We set the significance threshold for the likelihood ratio at <italic>p</italic>=0.02. In addition, to estimate the size of the effect, we computed the noncentrality parameter λ associated with the likelihood ratio test, which is a proxy for its power [<xref ref-type="bibr" rid="R36">36</xref>]. This post-hoc power analysis was then compared to the minimum power achievable from a pre-registered sensitivity analysis, which indicated that λ ≥13.017 would allow the detection of differences between models at 90% power (see <xref ref-type="table" rid="T1">Table 1</xref>) <sup>l</sup>. Lastly, the variance related to the intra-rater effect was estimated using the rm-ANOVA or, in the contingency case, by computing the variance of the regression coefficients linked to the random effect.</p></sec><sec id="S9"><title>Confirming that—on average—ratings are higher on defaced images</title><p id="P19">We used Bland-Altman (BA) plots [<xref ref-type="bibr" rid="R37">37</xref>] to visualize the bias and the agreement of manual quality ratings between the nondefaced and the defaced conditions. Five BA plots were generated (<xref ref-type="fig" rid="F2">Fig. 2</xref>), one for each individual rater and one pooling the ratings from all raters together. We used the individual-rater BA plots to investigate whether the bias varied with respect to the quality grade attributed and how the bias changes depending on the rater. <sup>m</sup>The bias 𝔼[Δ<sub>ndef−def</sub>] is defined [<xref ref-type="bibr" rid="R37">37</xref>] as the mean of rating differences <inline-formula><mml:math id="M3"><mml:mrow><mml:msub><mml:mtext>Δ</mml:mtext><mml:mrow><mml:mtext>ndef</mml:mtext><mml:mo>−</mml:mo><mml:mtext>def</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mtext>ndef</mml:mtext></mml:mrow><mml:mi>s</mml:mi></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mtext>def</mml:mtext></mml:mrow><mml:mi>S</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>,where <inline-formula><mml:math id="M4"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mtext>condition</mml:mtext><mml:mspace width="0.2em"/></mml:mrow><mml:mi>S</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> are the ratings corresponding to the nondefaced (ndef) and defaced (def) conditions of a single subject’s image <italic>s</italic>. Therefore, to investigate our hypothesis that humans’ <italic>ratings are higher on defaced images</italic>, we confirmed that 𝔼[Δ<sub>ndef−def</sub>] &lt; 0 for all raters, aggregated and individually (<xref ref-type="fig" rid="F2">Fig. 2</xref>). Bland &amp; Altman [<xref ref-type="bibr" rid="R37">37</xref>] recommend assessing the agreement between measurements by calculating the 95% limits of agreement (LoA), defined as <italic>the range in which 95% of the differences</italic> Δ<sub>ndef−def</sub> <italic>are expected to fall</italic>. In practice, <italic>two measurement approaches cannot be used interchangeably if their LoA are too broad</italic>. Following [<xref ref-type="bibr" rid="R37">37</xref>], LoA are calculated as follows: <disp-formula id="FD1"><mml:math id="M5"><mml:mrow><mml:mtext>LoA</mml:mtext><mml:mspace width="0.2em"/><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mtext>Δ</mml:mtext><mml:mrow><mml:mtext>ndef</mml:mtext><mml:mo>−</mml:mo><mml:mtext>def</mml:mtext><mml:mspace width="0.2em"/></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mi>σ</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mtext>Δ</mml:mtext><mml:mrow><mml:mtext>ndef</mml:mtext><mml:mo>−</mml:mo><mml:mtext>def</mml:mtext><mml:mspace width="0.2em"/></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mi>σ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula> where <italic>σ</italic> is the sample standard deviation, and <italic>z</italic><sub><italic>α/2</italic></sub> is the critical value-with <italic>z</italic><sub><italic>α/2</italic></sub>=1.96 for the 95% coverage range of the differences, and <italic>z</italic><sub><italic>α/2</italic>,</sub>=2.0 recommended as a close approximation [<xref ref-type="bibr" rid="R37">37</xref>]. To demonstrate that nonzero biases were not obtained by chance, we tested whether the bias was significantly negative by checking if Δ<sub>ndef−def</sub>=0 was contained within the 95% confidence interval (CI) for the bias [<xref ref-type="bibr" rid="R37">37</xref>]. We calculated the 95% CI for the bias under the assumption of normality and reasonably large sample sizes following Bland &amp; Altman’s indications [<xref ref-type="bibr" rid="R37">37</xref>], with: <disp-formula id="FD2"><mml:math id="M6"><mml:mrow><mml:mtext>CI</mml:mtext><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mtext>Δ</mml:mtext><mml:mrow><mml:mtext>ndef</mml:mtext><mml:mo>−</mml:mo><mml:mtext>def</mml:mtext><mml:mspace width="0.2em"/></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mn>1.96</mml:mn><mml:mo>⋅</mml:mo><mml:mfrac><mml:mi>σ</mml:mi><mml:mrow><mml:msqrt><mml:mi>n</mml:mi></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mtext>Δ</mml:mtext><mml:mrow><mml:mtext>ndef</mml:mtext><mml:mo>−</mml:mo><mml:mtext>def</mml:mtext><mml:mspace width="0.2em"/></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>1.96</mml:mn><mml:mo>⋅</mml:mo><mml:mfrac><mml:mi>σ</mml:mi><mml:mrow><mml:msqrt><mml:mi>n</mml:mi></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula> where <italic>n</italic> is the sample size. To protect from violations of the normality assumption, we also computed them via bootstrapping [<xref ref-type="bibr" rid="R38">38</xref>]. We reported both estimates and tested for the significance with the more conservative option. Additional considerations on the interpretation of BA plots, the 95% LoA, and the 95% CI of the mean bias are provided in the Supplementary Materials, subsection S6.2.</p></sec><sec id="S10"><title>Determining that defacing introduces biases in <italic>MRIQC</italic>-generated IQMs</title><p id="P20">Defacing impact on automatic QC was evaluated based on 58 <sup>n</sup> out of 62 IQMs calculated by <italic>MRIQC</italic>. For the complete list of IQMs produced by <italic>MRIQC</italic> and their definitions, refer to <xref ref-type="table" rid="T2">Table 2</xref> in [<xref ref-type="bibr" rid="R6">6</xref>]. A two-way repeated-measures, multivariate ANOVA (rm-MANOVA) was used to test whether defacing significantly influenced the IQMs. This test was implemented with the <italic>multRM</italic> function of the <italic>MANOVA.RM</italic> package [<xref ref-type="bibr" rid="R39">39</xref>] in R. Because many IQMs were heavily correlated (see <xref ref-type="supplementary-material" rid="SD1">Fig. S14</xref>), their dimensionality was reduced with principal components analysis (PCA) before applying rm-MANOVA. To ensure the defacing effects were not mitigated, PCA was applied only on the IQMs extracted from the nondefaced data, and the resulting transformation was applied to IQMs to the entire dataset. PCA was implemented with the <italic>prcomp</italic> function of R’s <italic>stats</italic> package, with the option <italic>scale=TRUE</italic>, meaning that the variables were standardized to have unit variance before the decomposition. The number of principal components was determined by the Kaiser criterion, which keeps components with an eigenvalue above 1.0. The rm-MANOVA was constructed with the projected IQMs as the continuous dependent variables and two categorical independent variables, one corresponding to the (nondefaced or defaced) condition of the image and the other corresponding to the scanning site. Adding the scanning site as an independent variable allowed us to control for site-effects [<xref ref-type="bibr" rid="R11">11</xref>,<xref ref-type="bibr" rid="R40">40</xref>]. We applied a significance level of <italic>p</italic>&lt;0.02 for the rm-MANOVA and considered the <italic>p</italic>-values extracted under the Wald-type statistics section. A preliminary sensitivity analysis determined that our experimental design can identify, with a 90% power, effects of f = 0.16 / <inline-formula><mml:math id="M7"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.025</mml:mn></mml:mrow></mml:math></inline-formula> (i.e., a medium effect) or greater with <italic>G*Power</italic> (see <xref ref-type="table" rid="T2">Table 2</xref>). For context, the effect size associated with the MANOVA on the IQMs of our pilot study was f=0.16 (see Equations S4 and S5 for its computation). However, comparisons between both effect sizes need to be exercised with caution as the statistical designs are different. In our pilot study, we used a standard MANOVA on only five IQMs that showed the strongest bias on the BA plots. In contrast, in this pre-registration, we planned to use a repeated-measures MANOVA with all IQMs projected onto the PCA basis. In addition, the effect size reported in [<xref ref-type="bibr" rid="R5">5</xref>] for the <italic>PyDeface</italic>’s influence on IQMs ranged from f=0.045 to f=1.79, with a mean effect size across IQMs of f=0.61 (see Equation S3 for the conversion of Cohen’s d to Cohen’s f). To visualize the defacing bias on the automatic quality ratings, we also generated a BA plot (as described above) for each IQM and each principal component. All BA plots are reported in Figs. S15 through S18 in the Supplementary Materials.</p></sec></sec><sec id="S11"><title>Protocol Deviations</title><p id="P21"><sup>a</sup> <bold>Erroneous dataset size reported within the pre-registered plan</bold>. The IXI dataset contains 581 images, but we erroneously stated that it had 580 T1w images in the pre-registration. This error only affected this experiment because the reported number of participants in the HH subsample for Hypothesis 1 (N=185) was correctly reported.</p><p id="P22"><sup>b</sup> <bold>Improved clarity in the description of inclusion and exclusion criteria from the IXI dataset.</bold> Our approved Stage 1 registration left much room for precision on the inclusion and exclusion criteria. The final text clearly delineates these criteria, separated by the two hypotheses. It also resolves the problem that while we originally had proposed three hypotheses, the finally accepted Stage 1 had been reduced to the two we introduce here. Unfortunately, some text referred to hypothesis 3, which had been dismissed after peer review. This deviation also changes the location of some exclusion criteria, for example, those regarding later steps of the processing stream that are now placed at the corresponding point of the methodological description (e.g., excluding images due to insufficient quality of defacing). While the exclusion/inclusion criterion did not change, we now indicate the criterion later in the protocol.</p><p id="P23"><sup>c</sup> <bold>Moved ethical statement and GDPR enforcement to more appropriate locations</bold>. The ethical statement has been moved up to the initial paragraph of the “Data” section. The GDPR enforcement statement is now with the “Data and software availability statement”.</p><p id="P24"><sup>d</sup> <bold>Improved precision of the QC checkpoint after <italic>PyDeface</italic></bold>. Our approved Stage 1 should have been more specific regarding what “ineffective” defacing means. Fortunately, this exclusion criteria did not apply, and no images were excluded for this reason.</p><p id="P25"><sup>e</sup> <bold>Statement of exclusions due to <italic>MRIQC</italic> failures</bold>. The approved Stage 1 plan did not explicitly anticipate the potential failure of <italic>MRIQC</italic> when processing images. We report that <italic>MRIQC</italic> unsuccessfully processed two subjects.</p><p id="P26"><sup>f</sup> Expert raters were incorporated as authors after data collection.</p><p id="P27"><sup>g</sup> The training session lasted 3 hours instead of 4 hours. Raters self-assessed their experience at the end of the session rather than at the beginning.</p><p id="P28"><sup>h</sup> The training session has been comprehensively reported, and the protocol updated correspondingly. <xref ref-type="fig" rid="F2">Figure 2</xref> in the pre-registered plan has been moved to the supplementary materials and is now <xref ref-type="supplementary-material" rid="SD1">Fig. S1</xref>.</p><p id="P29"><sup>i</sup> <bold>Images rated twice for the intra-rater reliability assessment could not be fed into the planned analyses</bold>. We had not tested at pre-registration time that neither the <italic>rstatix</italic>’s implementation of rm-ANOVA nor the LMEs’ implementation in <italic>lme4</italic> could deal with non-uniquely identified rows. As such, in the case of the images repeated twice, we excluded the ratings corresponding to the second image presentation for all raters in both conditions. We updated the preliminary sensitivity analysis for the rm-ANOVA modeling according to the reduced sample, changing the smallest detectable effect size at 90% power from f=0.14 to f=0.218. We have also transformed the reporting of the sensitivity analysis from the screen capture of <italic>G*Power</italic> in the former <xref ref-type="fig" rid="F3">Figure 3</xref> into the new <xref ref-type="table" rid="T1">Table 1</xref>. This change had no notable consequences as we finally carried out modeling with the LMEs alternative.</p><p id="P30"><sup>j</sup> <bold>Subject as a random effect in the LMEs</bold>. Our pre-registered plan failed to identify the subject as a random effect in the LMEs, which is critical for the model to capture that the subject is a repeated measure.</p><p id="P31"><sup>k</sup> <bold>Added a reference</bold>. We added the citation to the R software package [<xref ref-type="bibr" rid="R35">35</xref>] that was missing in the pre-registration.</p><p id="P32"><sup>l</sup> <bold>Post-hoc power analysis</bold>. Our pre-registered plan stated that “We will deem the effect irrelevant if the latter parameter is smaller than 13”, which we later understood is a misinterpretation of the utility of post-hoc power analyses and discussed in the results.</p><p id="P33"><sup>m</sup> <bold>Corrected interpretation of BA plots</bold>. Our pre-registered plan employed 95% LoA of the difference and 95% CI of the bias as interchangeable terms, which is incorrect. Our Stage 2 report was updated to employ unambiguous nomenclature for the bias 𝔼[Δ<sub>ndef−def</sub>], included the definition of LoA and CI as proposed initially by Bland &amp; Altman [<xref ref-type="bibr" rid="R37">37</xref>, <xref ref-type="bibr" rid="R38">38</xref>], and provided further details regarding the interpretation of LoA and the significance of the biases.</p><p id="P34"><sup>n</sup>Two IQMs, Mortamet [<xref ref-type="bibr" rid="R17">17</xref>] “quality index 1” and the “5th percentile of the background intensity”, were excluded because they were zero for all images. Two additional IQMs, the median and the median absolute deviation of the background intensity, were excluded as they were constantly zero except for two images. The distributions of all IQMs are plotted in the <xref ref-type="supplementary-material" rid="SD1">supplementary Fig. S12</xref>, with the plots corresponding to the four excluded IQMs highlighted in red.</p></sec><sec id="S12"><title>Methodological precisions at Stage 2 and exploratory analyses</title><sec id="S13"><title>An alternative to the standard BA plot is presented (Hypothesis 1)</title><p id="P35">The BA plot is designed for test-retest reliability assessment, in which neither of the two measurements being presented can be assumed to be more accurate. However, in our design, ratings on the nondefaced condition can be assumed to be the reference value from which then test deviation in the defaced condition.</p><p id="P36">Therefore, we modified the BA so that the x-axis represents nondefaced ratings (in contrast to the average between defaced and nondefaced of the “standard” plot). This modification of the BA plot displays the directionality of biases introduced by defacing more clearly. A side-by-side comparison between the standard BA plots and our “optimized” BA plot is shown in <xref ref-type="supplementary-material" rid="SD1">Fig. S2</xref>.</p></sec><sec id="S14"><title>Visually assessing homogeneity of distributions across raters (Hypothesis 1)</title><p id="P37">We visually explored the sample before carrying out the rm-ANOVA and LME tests. We evaluated the agreement across raters by generating “test-retest violin plots”, where the left part of the violin shows the distribution of ratings in the nondefaced condition, and the right side shows the distribution of ratings in the defaced condition (<xref ref-type="fig" rid="F3">Fig. 3</xref>).</p></sec><sec id="S15"><title>Clarifications regarding the control for multiple comparisons (Hypothesis 1)</title><p id="P38">In addition to the pre-registered test, we repeated the rm-ANOVA and LMEs analyses with two subsamples. We additionally ran both models (likelihood ratio test and rm-ANOVA), including only images that were rated “poor” or “exclude” (that is, ratings below 2.45) for two reasons. First, our BA plots showed that nondefaced images that were highly rated would not increase their rating after defacing.</p><p id="P39">Second, we considered that QC is more concerned with sensitivity (i.e., minimizing false negatives or, in other words, reliably detecting cases where the ratings on the defaced condition are substantially more optimistic about quality). In the second subsample, we considered only Raters 1, 2, and 3 because of the stark difference in Rater 4’s distributions displayed by the test-retest violin plots (<xref ref-type="fig" rid="F3">Fig. 3</xref>). With these additional four tests, and considering the two tests originally planned, we corrected the <italic>p</italic>-values for six tests controlling for false discovery rate (FDR [<xref ref-type="bibr" rid="R41">41</xref>]).</p></sec><sec id="S16"><title>Post-hoc sensitivity analysis implementation</title><p id="P40">Our pre-registered plan committed to estimating the effect size of the likelihood-ratio test without methodological details. The likelihood ratio test compares the ratio of likelihoods to a χ<sup>2</sup>-distribution with the degrees of freedom (df) equal to the difference in parameter counts between the nested alternative and baseline models [<xref ref-type="bibr" rid="R42">42</xref>,<xref ref-type="bibr" rid="R43">43</xref>]. As such, a proxy for power is given by the noncentrality parameter λ. For each LME, we obtained an unbiased estimate of the noncentrality parameter [<xref ref-type="bibr" rid="R42">42</xref>] using Equation S1 with df = 1.</p></sec><sec id="S17"><title>Accounting for site differences in the IQMs analysis (Hypothesis 2)</title><p id="P41">In addition to the pre-registered analysis plan, the IQMs’ standardization and PCA fitting were explored site-wise instead of considering the three sites together. We made that decision after observing that the pre-registered rm-MANOVA did not show significant IQM differences between sites (see <xref ref-type="table" rid="T4">Table 4</xref>) despite some site differences being visible in <xref ref-type="supplementary-material" rid="SD1">Fig. S13</xref>. Therefore, we computed the mean and standard deviation of the IQMs extracted from the nondefaced images of one site and standardized both the IQMs computed from nondefaced and defaced images from the same site by subtracting that mean and dividing by that standard deviation. Correspondingly, the following three PCA models were fit on the nondefaced sample separately by site. First, considering only IQMs computed from nondefaced images, we inspected how many components are needed in each site according to the Kaiser criterion. We chose the maximum number of components for all PCAs independently of the site.</p><p id="P42">Selecting a common number of components across sites was necessary as the rm-MANOVA requires a single number of dependent variables. We then re-ran the PCA separately per site with the chosen number of components considering IQMs from both conditions. The subsequent steps of the analysis remained unchanged from the pre-registered plan.</p></sec></sec></sec><sec id="S18" sec-type="results"><title>Results</title><sec id="S19"><title>We confirmed defacing biased quality assessments by human raters</title><p id="P43">A likelihood ratio test demonstrated that including defacing as a fixed effect (the alternative model) explained significantly more variance than the baseline model (see <xref ref-type="table" rid="T3">Table 3</xref>; <italic>p</italic><sub>FDR</sub> = 0.0183). This result supports that defacing significantly influenced the quality assessments issued by human raters on the same images. <xref ref-type="supplementary-material" rid="SD1">Fig. S10</xref> (Supplementary Materials) shows the distribution of residuals for each fitted LME model, as well as the Q-Q plot [<xref ref-type="bibr" rid="R44">44</xref>] for the residuals and the subject and the rater as random effects. The residuals for both the baseline and alternative models were approximately normally distributed (see <xref ref-type="supplementary-material" rid="SD1">Fig. S10</xref>), with heavier left tails. The residuals distribution plot also suggested signs of heteroscedasticity in the lower ratings, although most points were still evenly distributed around zero. <xref ref-type="supplementary-material" rid="SD1">Table S8</xref> reports the variance of the random effects coefficients and residuals.</p><p id="P44">We carried out the LME model comparison because the majority of the rating subgroups defined by the interaction between the defacing condition and rater identifier were non-normally distributed according to the Shapiro-Wilk normality test [<xref ref-type="bibr" rid="R29">29</xref>] (see <xref ref-type="supplementary-material" rid="SD1">Table S3</xref>; <xref ref-type="supplementary-material" rid="SD1">Fig. S9</xref>). Nonetheless, we also carried out the planned rm-ANOVA for completeness as an exploratory analysis, and the results of the rm-ANOVA are presented in the Supplementary Materials (<xref ref-type="supplementary-material" rid="SD1">Table S4</xref>). Even though non-normality undermines the sensitivity of rm-ANOVA, these tests also showed statistically significant biases between the defaced and nondefaced rating conditions.</p><p id="P45">Following our pre-registered plan, we also conducted a post-hoc power analysis of the alternative vs. baseline LMEs comparison to estimate an effect size. We estimated the noncentrality parameter corresponding to our maximum likelihood ratio test λ = 5.28 (see <xref ref-type="supplementary-material" rid="SD1">Table S9</xref>). Therefore, λ &lt; 13.017 indicates that the effect size was smaller than the minimum our previous sensitivity analysis found detectable at 90% power (<xref ref-type="table" rid="T1">Table 1</xref>). Our pre-registered plan explicitly stated, “We will deem the effect irrelevant if the latter parameter [noncentrality parameter of the χ<sup>2</sup>-distribution] is smaller than 13, corresponding to the minimum power achievable from the sensitivity analysis.” However, in preparing this final report, we understood these post-hoc power analyses give no basis for “deeming an effect irrelevant” (see deviation <sup>l</sup>), as effect size estimates can be extremely biased [<xref ref-type="bibr" rid="R45">45</xref>]. We report this post-hoc power analysis following the pre-registration but remark that it should be interpreted with the utmost caution.</p></sec><sec id="S20"><title>Biases were larger in images rated as having lower quality in the nondefaced condition</title><p id="P46">Our variation of the BA plot (<xref ref-type="fig" rid="F2">Fig. 2</xref>) and our test-retest violin plots contrasting defaced and nondefaced ratings (<xref ref-type="fig" rid="F3">Fig. 3</xref>) revealed that nondefaced images rated the lowest showed larger quality gaps with respect to their defaced counterpart than highly-rated nondefaced images. Low ratings presented an evolution line with a higher slope, sometimes jumping one unit (that is, a category change in the appreciation of quality, for example, from “poor” to “acceptable”), while the difference amongst the highest ratings remained within 0.5 units. Our exploratory models considering only low ratings further supported this interpretation by showing a higher effect size linked to defacing than that of the pre-registered model counterparts with all ratings (<xref ref-type="supplementary-material" rid="SD1">Table S4</xref>). Although all raters displayed individual LoA larger than one unit, indicating that defacing introduced large variability, these plots also reflected that raters were not equally affected by defacing. Our most experienced rater (Rater 1) presented the highest bias 𝔼[Δ<sub>ndef−def</sub>] = -0.12 (<xref ref-type="supplementary-material" rid="SD1">Table S2</xref>), while a more junior rater (Rater 4) barely modified their quality assessment (𝔼[Δ<sub>ndef−def</sub>]= -0.02). The differences between nondefaced and defaced ratings by Rater 4 could only be small because most of their ratings were remarkably high as compared to the other raters (see <xref ref-type="fig" rid="F3">Fig. 3</xref>). Our subsample rm-ANOVA and LMEs tests without Rater 4 supported that Raters 1, 2, and 3 showed better agreement, as shown by the larger rater effect size compared to our pre-registered model counterparts with all ratings (<xref ref-type="supplementary-material" rid="SD1">Table S4</xref>). 𝔼[Δ<sub>ndef−def</sub>] was consistently negative across all raters, implying that defaced images were, on average, scored with a higher rating. This bias was significant for Raters 1 and 3, and all raters aggregated, as shown in <xref ref-type="fig" rid="F2">Fig. 2</xref> and comprehensively reported in <xref ref-type="supplementary-material" rid="SD1">Table S2</xref>.</p></sec><sec id="S21"><title><italic>MRIQC</italic>-generated IQMs were mostly insensitive to defacing</title><p id="P47">Our pre-registered rm-MANOVA test (<xref ref-type="table" rid="T4">Table 4</xref>) did not reveal differences in the IQMs distribution before and after defacing (F(1, 184) = 0.003, <italic>p</italic>=0.96, <inline-formula><mml:math id="M8"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>3.5</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>) nor between sites (F(2, 184) = 0.376, <italic>p</italic>=0.828, <inline-formula><mml:math id="M9"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>7.9</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>). As explained in the section “Methodological precisions at Stage 2 and exploratory analyses”, observing no site-effects pushed us to refine our PCA approach. Following the Kaiser criterion, we kept ten components for each site (eigenvalues presented in <xref ref-type="supplementary-material" rid="SD1">Table S10</xref>). We also verified on a scree plot (see <xref ref-type="supplementary-material" rid="SD1">Fig. S19</xref>) that the components from the 11<sup>th</sup> did not explain a substantial part of the variance, confirming the choice of 10 components. The rm-MANOVA with refined PCA revealed a significant influence of defacing on the IQMs, although the effect size was very small (F(5,14)= 8.269, <italic>p</italic>&lt; 0.001, <inline-formula><mml:math id="M10"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.0047</mml:mn></mml:mrow></mml:math></inline-formula>, f=0.069; see Equation S1). In contrast, Bhalerao et al. [<xref ref-type="bibr" rid="R5">5</xref>] found bigger effect sizes for the impact of <italic>PyDeface</italic> on <italic>MRIQC</italic>-generated IQMs, with f ranging from 0.045 to 1.79 and a mean E[f] <bold><italic>=</italic></bold> 0.61. These post-hoc power analyses must be interpreted cautiously for the reasons stated above regarding our corresponding analyses within the LME comparison. In a post-hoc exploration using BA plots (<xref ref-type="supplementary-material" rid="SD1">Fig. S15</xref>), we found that nearly all IQMs showcased very narrow 95% LoA and minimal biases—yet non-zero—compared to their variation ranges. The narrow LoA indicate that the variance introduced by defacing into the IQMs is relatively small. Biases were deemed significant in most of the IQMs, which immediately follows the relatively large sample size. Only the entropy-focus criterion (“efc”) emerged as an exception, showcasing a substantial bias and a broad 95% LoA, which, in addition, did not contain zero. As opposed to all other IQMs, the bias corresponding to the “efc” was also clearly noticeable in violin plots (<xref ref-type="supplementary-material" rid="SD1">Fig. S13</xref>).</p></sec></sec><sec id="S22" sec-type="discussion"><title>Discussion</title><p id="P48">Typical neuroimaging workflows involve many image-processing steps, contributing to analytical variability that cascades throughout the pipeline. Even initial processing steps considered relatively innocuous, such as reorienting the volume to align the anterior-posterior commissure line with the axial plane, may conceal relevant design decisions and inadvertently introduce variability. Because defacing has been shown to influence downstream processing [<xref ref-type="bibr" rid="R1">1</xref>, <xref ref-type="bibr" rid="R4">4</xref>–<xref ref-type="bibr" rid="R5">5</xref>], this registered report investigated the alterations introduced by this step in the manual and automatic QC of whole-brain T1w images. The automatic rating used image quality metrics (IQMs)—extracted with <italic>MRIQC</italic>—as a proxy. Our analysis for manual (human) ratings showed that a linear mixed-effects (LME) model with defacing as a fixed effect explained significantly more variability than a baseline model without defacing. However, the biases we estimated were relatively small: the largest bias 𝔼[Δ<sub>ndef−def</sub>] = - 0.12 (<xref ref-type="supplementary-material" rid="SD1">Table S2</xref>) was displayed by the most experienced rater (Rater 1). This indicates that human raters are sensitive to defacing, possibly more for more experienced raters. The first implication of this result is that QA/QC protocols establishing a visual checkpoint on the unprocessed data [<xref ref-type="bibr" rid="R23">23</xref>]—e.g., with <italic>MRIQC</italic>’s visual reports—should generate visualization and other QA/QC materials before defacing anatomical images. Defacing is generally required for compliance with applicable privacy protection regulations if data are to be processed on systems with low-security clearances or if data will be made accessible to third parties or publicly. Regardless of the motivation to deface anatomical images, our results support the recommendation of providing QA/QC materials extracted from the original (nondefaced) images alongside the defaced dataset, as long as the participant’s identity cannot be reconstructed from those additional resources. This will enable data re-users to perform QA/QC in settings more consistent with those of the original authors, minimizing the risk of artifacts going unnoticed and biasing analyses.</p><p id="P49">Visual examination of the manual ratings through optimized Bland-Altman (BA) plots displayed a phenomenon we should have anticipated before pre-registration, which we acknowledge as a limitation of the present work. In agreement with our hypothesis, nondefaced images rated with the lower quality (“exclude” through “poor” and “low-acceptable” regime, from 1 to 2.45 on our rating scale) received substantially better ratings after defacing (see <xref ref-type="fig" rid="F2">Fig. 2</xref>). However, when nondefaced images were assigned high ratings (i.e., “excellent”), it was very unlikely that the defaced image received a more optimistic rating because of the scale constraint. We failed to identify this trivial limitation, and therefore, future investigations should employ datasets with balanced representations of poor-quality and excluded images. This bias is present in all datasets (as QA/QC attempts to minimize data exclusion on the grounds of insufficient quality), and it is more acute in public datasets (because data that met exclusion QC criteria are generally not shared openly as they were not considered for the analysis). For this reason, we argue that improving the automated QC of T1w images will require that all available data be shared, including samples discarded because they met the study’s exclusion criteria. Doing so will enable the development of more sensitive and specific QC tools that are robust to site effects. Sharing all data is also essential because an image deemed unsuitable for one study might be valuable for another, as exclusion criteria vary based on the specific project’s needs. Factors like the type of analysis or the region of interest in addressing the research question influence these QA/QC protocols [<xref ref-type="bibr" rid="R23">23</xref>].</p><p id="P50">While we designed the experiment with four raters, and despite the (pre-registered) efforts to calibrate the raters with a training session, one of the distributions of raters’ assessments diverged from the other three raters in location and spread. Their ratings concentrated within the “acceptable-to-excellent” range. We explored all models after discarding this rater, and alongside visualization through BA plots and “test-retest violin plots”, we found more reliable results (and larger effect sizes) excluding this rater. The distinctive distribution of ratings may indicate a failure in the design of the training session, leading to the rater’s application of starkly different assessment criteria. Our pre-registration failed to set corresponding QC criteria to assess the raters’ performance and anticipate countermeasures. Therefore, it is critical to QA/QC protocols to assess raters’ calibration before assessment and then schedule checkpoints over time to take corrective measures and identify rater disagreement early. We share all the materials in this report to allow researchers to build upon these training and calibration resources. Nonetheless, it cannot be ruled out that other circumstances determined the differences in rating distribution, such as attrition drifts (Rater 4 evaluated most of the 450 images in a single session; <xref ref-type="supplementary-material" rid="SD1">Fig. S5</xref>), differences in line-of-sight angle, or individual behavioral variables (e.g., sleep deprivation).</p><p id="P51">We carried out several exploratory analyses in addition to the pre-registered confirmatory tests (reported as Supplementary Materials). For instance, we estimated, using the intra-class correlation coefficient, that our four raters presented an inter-rater reliability of 0.542 (95% CI = [0.497, 0.587]), corresponding to a moderate agreement (see subsection S4.2). With a subsample of 40 subjects randomly selected, we ran an exploratory analysis investigating the test-retest reliability of the raters in both nondefaced and defaced conditions. This analysis revealed good intra-rater agreements (<xref ref-type="supplementary-material" rid="SD1">Table S2</xref>), with varying and slight differences across raters regarding whether they became more or less critical of perceived quality over time (<xref ref-type="supplementary-material" rid="SD1">Fig. S5 and S6</xref>). Beyond identifying one rater’s assessments sticking out compared to the others, our study was not designed to investigate how raters may be differently influenced by defacing (for example, in function of their experience), which remains a future line of research.</p><p id="P52">Finally, we also found that <italic>MRIQC</italic>’s IQMs are mostly insensitive to defacing. We tested the influence of defacing on the IQMs using rm-MANOVA after dimensionality reduction via PCA. Defacing bias became significant only when we meticulously controlled for site effects by applying standardization and PCA per site, and even then, it was associated with a minimal effect size <inline-formula><mml:math id="M11"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.0047</mml:mn></mml:mrow></mml:math></inline-formula>. In a post-hoc exploration using BA plots, only the “efc” metric showed a meaningful difference between conditions out of the total 58 IQMs investigated. Although most IQMs had significant biases (<xref ref-type="supplementary-material" rid="SD1">Fig. S15</xref>) due to the large sample size, these biases were minimal, and their LoA were narrow in comparison to their corresponding variation ranges. Conversely, “efc” was the only metric displaying a broad LoA compared to its typical range (<xref ref-type="supplementary-material" rid="SD1">Fig. S15</xref>). In addition, except for “efc”, no other IQM’s LoA excluded the zero-difference line, indicating that very rarely, differences in “efc” will be small between conditions. This result seems a consequence of <italic>MRIQC</italic>’s definition of most metrics, such as contrast-to-noise ratio (“cnr”) or signal-to-noise ratio in the gray matter (“snr_gm”), which are extracted from areas within the brain and, therefore, unaffected by defacing. The “efc” metric is an exception among IQMs, including background in their definition. For example, the “snrd_*” family of metrics is akin to their “snr_*” counterparts with the difference that the signal variability is estimated in the background [<xref ref-type="bibr" rid="R48">48</xref>]. While “efc” employs all the background surrounding the head and neck, “snrd_*” metrics discard background information outside of a “hat” mask that excludes the background below the nasio-occipital plane. Hence, they are also insensitive to the area altered by defacing. Our results contrast with [<xref ref-type="bibr" rid="R5">5</xref>], which stated that <italic>MRIQC</italic>-generated IQMs are significantly influenced by defacing. One explanation for the disagreement is that they evaluated different defacing methods, and <italic>PyDeface</italic>—our choice—yielded the smallest influence on the IQMs.</p><p id="P53">Secondly, they performed univariate tests on only ten IQMs, including “efc” and foreground-background energy ratio (“fber”), which were the IQMs varying the most with defacing when visually assessed (<xref ref-type="supplementary-material" rid="SD1">Fig. S13</xref>). These reasons explain why they found significant differences with a smaller sample size. Based on our findings, we recommend that <italic>MRIQC</italic> (and any QA/QC tool for unprocessed T1w images) include metrics sensitive to artifacts in areas typically removed or altered by defacing. Prior work by Pizarro et al. [<xref ref-type="bibr" rid="R49">49</xref>] on anatomical MRI and our later work on functional MRI [<xref ref-type="bibr" rid="R50">50</xref>] justified how information “outside” the brain region is relevant to assess the quality of imaging “within” the region of interest. These metrics—e.g., those proposed in [<xref ref-type="bibr" rid="R49">49</xref>] and derivations thereof—should be clearly annotated and excluded from analyses involving defaced images where they are not applicable. Even though <italic>MRIQC</italic>’s IQMs seemed insensitive to defacing, we also carried out a reliability analysis of the IQMs to determine whether defacing altered the repeatability of IQM calculation (Supplementary Materials, subsection S6.4), concluding that defacing did not have an appreciable impact on IQMs reliability.</p><p id="P54">This registered report lays the groundwork for a better understanding of human expert behavior in assessing anatomical T1w MRI of the human brain. It provides a tooling framework to establish a rigorous QA/QC checkpoint on the unprocessed data. Finally, this report provides the basis for standardized QA/QC protocols that are consistent across institutions, experts, and over time.</p></sec><sec id="S23" sec-type="conclusions"><title>Conclusion</title><p id="P55">The initial processing steps in the computational pipeline may have relevant downstream effects. Our report showed that defacing influences human quality assessments of T1w images, with lower-quality nondefaced images likely rated higher after defacing. Inadequate manual QC decisions deriving from the visualization of defaced images could undermine the soundness of results.</p><p id="P56"><italic>MRIQC</italic>’s automatically extracted IQMs, on the other hand, remained largely unaffected, as the tool does not consider areas typically altered by defacing when computing the IQMs.</p></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary Materials</label><media xlink:href="EMS199398-supplement-Supplementary_Materials.pdf" mimetype="application" mime-subtype="pdf" id="d11aAcFbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S25"><title>Acknowledgments</title><p>This work has been supported by the Swiss National Science Foundation —SNSF—(#185872, OE), the NIMH (RF1MH121867; OE, RP), and the Chan-Zuckerberg Initiative (EOSS5-266; OE). PH and YAG receive support from SNSF (#185897, PH), EFG receives support from SNSF (#10000706, EFG).</p></ack><sec id="S24" sec-type="data-availability"><title>Data and code availability statement</title><p id="P57">All the new materials relating to this work were shared under suitable open licenses (Apache 2.0 for code and CC-BY for data, unless otherwise specified) before the Stage 2 report submission. The IXI dataset is available at <ext-link ext-link-type="uri" xlink:href="https://brain-development.org/ixi-dataset/">https://brain-development.org/ixi-dataset/</ext-link> under the Creative Commons CC BY-SA 3.0 license. All the code related to this study and tabular data collected (manual ratings and the related covariates, as well as the IQMs extracted from defaced and nondefaced) are openly shared under the Apache 2.0 license at <ext-link ext-link-type="uri" xlink:href="https://github.com/TheAxonLab/defacing-and-qc-analysis">https://github.com/TheAxonLab/defacing-and-qc-analysis</ext-link>. The Web Service we implemented to collect the manual ratings in this study is available under the Apache 2.0 license at <ext-link ext-link-type="uri" xlink:href="https://github.com/nipreps/qkay">https://github.com/nipreps/qkay</ext-link>. The presentation used in the training session can be accessed at <ext-link ext-link-type="uri" xlink:href="https://osf.io/d57mb/">https://osf.io/d57mb/</ext-link>, and the training reports are openly shared at <ext-link ext-link-type="uri" xlink:href="https://github.com/TheAxonLab/defacing-and-qc-trainingsession">https://github.com/TheAxonLab/defacing-and-qc-trainingsession</ext-link>. The MRIQC reports generated from the IXI dataset and used by the human raters in their assessment are accessible via <ext-link ext-link-type="uri" xlink:href="https://github.com/TheAxonLab/defacing-and-qc-ixi-reports">https://github.com/TheAxonLab/defacing-and-qc-ixi-reports</ext-link> under the terms of the CC-BY-SA-4.0 license, as they are derived from the original IXI dataset.</p><p id="P58">Should any of the participants’ data be recalled from the original IXI dataset, e.g., after a UK GDPR request, we will accordingly recall the corresponding data derived from the participant’s T1w image.</p></sec><fn-group><fn fn-type="con" id="FN1"><p id="P59"><bold>Author contributions</bold></p><p id="P60">Conceptualization, funding acquisition, project administration, and supervision: OE. Data curation, visualization, and writing: CP and OE. Data collection: CP, TS, EM, JB, EFG, and OE. Methodology: CP, OE, ES, YA, RP, and JR. Formal Analysis: CP and OE. Software: ES, CP, and OE. Investigation: CP, ES, TS, JB, EM, EGF, and OE. Resources: PH, RP, and OE. All authors reviewed and edited the manuscript. All authors contributed to the article and approved the submitted version.</p></fn><fn id="FN2"><p id="P61"><bold>Financial Disclosure Statement</bold></p><p id="P62">The funders had no role in study design, data collection and analysis, the decision to publish, or the preparation of the manuscript.</p></fn></fn-group><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwarz</surname><given-names>CG</given-names></name><name><surname>Kremers</surname><given-names>WK</given-names></name><name><surname>Wiste</surname><given-names>HJ</given-names></name><name><surname>Gunter</surname><given-names>JL</given-names></name><name><surname>Vemuri</surname><given-names>P</given-names></name><name><surname>Spychalla</surname><given-names>AJ</given-names></name><etal/></person-group><article-title>Changing the face of neuroimaging research: Comparing a new MRI de-facing technique with popular alternatives</article-title><source>NeuroImage</source><year>2021</year><month>May</month><day>1</day><volume>231</volume><elocation-id>117845</elocation-id><pub-id pub-id-type="pmcid">PMC8154695</pub-id><pub-id pub-id-type="pmid">33582276</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2021.117845</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="regulation"><collab>European Parliament and of the Council</collab><source>GDPR (General Data Protection Regulation) - Regulation (EU) 2016/679 of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC</source><year>2016</year><month>Apr</month><day>27</day><comment>[Internet]. 2016/679 Available from: <ext-link ext-link-type="uri" xlink:href="https://eur-lex.europa.eu/eli/reg/2016/679/oj">https://eur-lex.europa.eu/eli/reg/2016/679/oj</ext-link></comment></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="regulation"><collab>US Health and Human Services Department</collab><source>HIPAA Privacy, Security, Enforcement, and Breach Notification Rules Under the Health Information Technology for Economic and Clinical Health Act. 45 CFR §164.514 45 CFR §164514</source><year>1996</year><month>Aug</month><day>21</day></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Sitter</surname><given-names>A</given-names></name><name><surname>Visser</surname><given-names>M</given-names></name><name><surname>Brouwer</surname><given-names>I</given-names></name><name><surname>Cover</surname><given-names>KS</given-names></name><name><surname>van Schijndel</surname><given-names>RA</given-names></name><name><surname>Eijgelaar</surname><given-names>RS</given-names></name><etal/></person-group><article-title>Facing privacy in neuroimaging: removing facial features degrades performance of image analysis methods</article-title><source>Eur Radiol</source><year>2020</year><month>Feb</month><day>1</day><volume>30</volume><issue>2</issue><fpage>1062</fpage><lpage>74</lpage><pub-id pub-id-type="pmcid">PMC6957560</pub-id><pub-id pub-id-type="pmid">31691120</pub-id><pub-id pub-id-type="doi">10.1007/s00330-019-06459-3</pub-id></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bhalerao</surname><given-names>GV</given-names></name><name><surname>Parekh</surname><given-names>P</given-names></name><name><surname>Saini</surname><given-names>J</given-names></name><name><surname>Venkatasubramanian</surname><given-names>G</given-names></name><name><surname>John</surname><given-names>JP</given-names></name><name><surname>Viswanath</surname><given-names>B</given-names></name><etal/></person-group><article-title>Systematic evaluation of the impact of defacing on quality and volumetric assessments on T1-weighted MR-images</article-title><source>J Neuroradiol</source><year>2022</year><month>May</month><day>1</day><volume>49</volume><issue>3</issue><fpage>250</fpage><lpage>7</lpage><pub-id pub-id-type="pmid">33727023</pub-id></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Esteban</surname><given-names>O</given-names></name><name><surname>Birman</surname><given-names>D</given-names></name><name><surname>Schaer</surname><given-names>M</given-names></name><name><surname>Koyejo</surname><given-names>OO</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name><name><surname>Gorgolewski</surname><given-names>KJ</given-names></name></person-group><article-title>MRIQC: Advancing the automatic prediction of image quality in MRI from unseen sites</article-title><source>PLOS ONE</source><year>2017</year><volume>12</volume><issue>9</issue><elocation-id>e0184661</elocation-id><pub-id pub-id-type="pmcid">PMC5612458</pub-id><pub-id pub-id-type="pmid">28945803</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0184661</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Esteban</surname><given-names>O</given-names></name><name><surname>Ciric</surname><given-names>R</given-names></name><name><surname>Finc</surname><given-names>K</given-names></name><name><surname>Blair</surname><given-names>R</given-names></name><name><surname>Markiewicz</surname><given-names>CJ</given-names></name><name><surname>Moodie</surname><given-names>CA</given-names></name><etal/></person-group><article-title>Analysis of task-based functional MRI data preprocessed with fMRIPrep</article-title><source>Nat Protoc</source><year>2020</year><volume>15</volume><fpage>2186</fpage><lpage>202</lpage><pub-id pub-id-type="pmcid">PMC7404612</pub-id><pub-id pub-id-type="pmid">32514178</pub-id><pub-id pub-id-type="doi">10.1038/s41596-020-0327-3</pub-id></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Power</surname><given-names>JD</given-names></name><name><surname>Barnes</surname><given-names>KA</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Schlaggar</surname><given-names>BL</given-names></name><name><surname>Petersen</surname><given-names>SE</given-names></name></person-group><article-title>Spurious but systematic correlations in functional connectivity MRI networks arise from subject motion</article-title><source>NeuroImage</source><year>2012</year><month>Feb</month><day>1</day><volume>59</volume><issue>3</issue><fpage>2142</fpage><lpage>54</lpage><pub-id pub-id-type="pmcid">PMC3254728</pub-id><pub-id pub-id-type="pmid">22019881</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.10.018</pub-id></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zalesky</surname><given-names>A</given-names></name><name><surname>Fornito</surname><given-names>A</given-names></name><name><surname>Cocchi</surname><given-names>L</given-names></name><name><surname>Gollo</surname><given-names>LL</given-names></name><name><surname>van den Heuvel</surname><given-names>MP</given-names></name><name><surname>Breakspear</surname><given-names>M</given-names></name></person-group><article-title>Connectome sensitivity or specificity: which is more important?</article-title><source>NeuroImage</source><year>2016</year><month>Nov</month><day>15</day><volume>142</volume><fpage>407</fpage><lpage>20</lpage><pub-id pub-id-type="pmid">27364472</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alexander-Bloch</surname><given-names>A</given-names></name><name><surname>Clasen</surname><given-names>L</given-names></name><name><surname>Stockman</surname><given-names>M</given-names></name><name><surname>Ronan</surname><given-names>L</given-names></name><name><surname>Lalonde</surname><given-names>F</given-names></name><name><surname>Giedd</surname><given-names>J</given-names></name><etal/></person-group><article-title>Subtle in-scanner motion biases automated measurement of brain anatomy from in vivo MRI</article-title><source>Hum Brain Mapp</source><year>2016</year><month>Jul</month><day>1</day><volume>37</volume><issue>7</issue><fpage>2385</fpage><lpage>97</lpage><pub-id pub-id-type="pmcid">PMC5110234</pub-id><pub-id pub-id-type="pmid">27004471</pub-id><pub-id pub-id-type="doi">10.1002/hbm.23180</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Esteban</surname><given-names>O</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name><name><surname>Gorgolewski</surname><given-names>KJ</given-names></name></person-group><source>Improving Out-of-Sample Prediction of Quality of MRIQC</source><series>Lecture Notes in Computer Science</series><conf-name>Intravascular Imaging and Computer Assisted Stenting and Large-Scale Annotation of Biomedical Data and Expert Label Synthesis LABELS 2018, CVII 2018, STENT 2018</conf-name><conf-sponsor>Springer</conf-sponsor><conf-loc>Granada, Spain</conf-loc><year>2018</year><volume>11043</volume><fpage>190</fpage><lpage>9</lpage><comment>[Internet]</comment><pub-id pub-id-type="doi">10.1007/978-3-030-01364-6_21</pub-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keshavan</surname><given-names>A</given-names></name><name><surname>Datta</surname><given-names>E</given-names></name><name><surname>McDonough</surname><given-names>M</given-names></name><name><surname>Madan</surname><given-names>CR</given-names></name><name><surname>Jordan</surname><given-names>K</given-names></name><name><surname>Henry</surname><given-names>RG</given-names></name></person-group><article-title>Mindcontrol: A web application for brain segmentation quality control</article-title><source>NeuroImage</source><year>2018</year><month>Apr</month><day>15</day><volume>170</volume><fpage>365</fpage><lpage>72</lpage><pub-id pub-id-type="pmid">28365419</pub-id></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keshavan</surname><given-names>A</given-names></name><name><surname>Yeatman</surname><given-names>JD</given-names></name><name><surname>Rokem</surname><given-names>A</given-names></name></person-group><article-title>Combining Citizen Science and Deep Learning to Amplify Expertise in Neuroimaging</article-title><source>Front Neuroinformatics</source><year>2019</year><volume>13</volume><date-in-citation>cited 2023 Mar 16</date-in-citation><comment>[Internet]</comment><pub-id pub-id-type="pmcid">PMC6517786</pub-id><pub-id pub-id-type="pmid">31139070</pub-id><pub-id pub-id-type="doi">10.3389/fninf.2019.00029</pub-id></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marcus</surname><given-names>DS</given-names></name><name><surname>Harms</surname><given-names>MP</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Wilson</surname><given-names>JA</given-names></name><name><surname>Glasser</surname><given-names>MF</given-names></name><etal/></person-group><article-title>Human Connectome Project informatics: Quality control, database services, and data visualization</article-title><source>NeuroImage</source><year>2013</year><month>Oct</month><day>15</day><volume>80</volume><fpage>202</fpage><lpage>19</lpage><pub-id pub-id-type="pmcid">PMC3845379</pub-id><pub-id pub-id-type="pmid">23707591</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.05.077</pub-id></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Shehzad</surname><given-names>Z</given-names></name><name><surname>Giavasis</surname><given-names>S</given-names></name><name><surname>Li</surname><given-names>Q</given-names></name><name><surname>Benhajali</surname><given-names>Y</given-names></name><name><surname>Yan</surname><given-names>C</given-names></name><name><surname>Yang</surname><given-names>Z</given-names></name><etal/></person-group><chapter-title>The Preprocessed Connectomes Project Quality Assessment Protocol - a resource for measuring the quality of MRI data</chapter-title><source>INCF Neuroinformatics</source><publisher-name>Front Neurosci</publisher-name><publisher-loc>Cairns, Australia</publisher-loc><year>2015</year><date-in-citation>cited 2017 Feb 27</date-in-citation><comment>[Internet]</comment><pub-id pub-id-type="doi">10.3389/conf.fnins.2015.91.00047/event_abstract</pub-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alfaro-Almagro</surname><given-names>F</given-names></name><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Bangerter</surname><given-names>NK</given-names></name><name><surname>Andersson</surname><given-names>JLR</given-names></name><name><surname>Griffanti</surname><given-names>L</given-names></name><name><surname>Douaud</surname><given-names>G</given-names></name><etal/></person-group><article-title>Image processing and Quality Control for the first 10,000 brain imaging datasets from UK Biobank</article-title><source>NeuroImage</source><year>2017</year><month>Oct</month><day>24</day><pub-id pub-id-type="pmcid">PMC5770339</pub-id><pub-id pub-id-type="pmid">29079522</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.10.034</pub-id></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mortamet</surname><given-names>B</given-names></name><name><surname>Bernstein</surname><given-names>MA</given-names></name><name><surname>Jack</surname><given-names>CR</given-names></name><name><surname>Gunter</surname><given-names>JL</given-names></name><name><surname>Ward</surname><given-names>C</given-names></name><name><surname>Britson</surname><given-names>PJ</given-names></name><etal/></person-group><article-title>Automatic quality assessment in structural brain magnetic resonance imaging</article-title><source>Magn Reson Med</source><year>2009</year><month>Aug</month><day>1</day><volume>62</volume><issue>2</issue><fpage>365</fpage><lpage>72</lpage><pub-id pub-id-type="pmcid">PMC2780021</pub-id><pub-id pub-id-type="pmid">19526493</pub-id><pub-id pub-id-type="doi">10.1002/mrm.21992</pub-id></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garcia</surname><given-names>M</given-names></name><name><surname>Dosenbach</surname><given-names>N</given-names></name><name><surname>Kelly</surname><given-names>C</given-names></name></person-group><article-title>BrainQCNet: a Deep Learning attention-based model for the automated detection of artifacts in brain structural MRI scans</article-title><source>Imaging Neurosci</source><year>2024</year><month>Sep</month><day>11</day><date-in-citation>cited 2024 Sep 19</date-in-citation><comment>[Internet]</comment><pub-id pub-id-type="doi">10.1162/imag_a_00300</pub-id></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Provins</surname><given-names>C</given-names></name><name><surname>Alemán-Gómez</surname><given-names>Y</given-names></name><name><surname>Cleusix</surname><given-names>M</given-names></name><name><surname>Jenni</surname><given-names>R</given-names></name><name><surname>Richiardi</surname><given-names>J</given-names></name><name><surname>Hagmann</surname><given-names>P</given-names></name><etal/></person-group><source>Defacing biases manual and automated quality assessments of structural MRI with MRIQC</source><conf-name>28th Annual Meeting of the Organization for Human Brain Mapping</conf-name><conf-sponsor>OSF Preprints</conf-sponsor><conf-loc>Glasgow, Scotland</conf-loc><year>2022</year><elocation-id>WTh566</elocation-id><date-in-citation>cited 2022 Jan 30</date-in-citation><comment>[Internet] Available from: <ext-link ext-link-type="uri" xlink:href="https://osf.io/8mcyz/">https://osf.io/8mcyz/</ext-link></comment></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Hill</surname><given-names>D</given-names></name><name><surname>Williams</surname><given-names>S</given-names></name><name><surname>Hawkes</surname><given-names>D</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name></person-group><source>IXI dataset - Information eXtraction from Images project (EPSRC GR/S21533/02)</source><year>2006</year><date-in-citation>cited 2013 May 7</date-in-citation><comment>[Internet] Available from: <ext-link ext-link-type="uri" xlink:href="http://www.brain-development.org/">http://www.brain-development.org/</ext-link></comment></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gulban</surname><given-names>OF</given-names></name><name><surname>Nielson</surname><given-names>DM</given-names></name><name><surname>Lee</surname><given-names>J</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name><name><surname>Gorgolewski</surname><given-names>C</given-names></name><name><surname>Sochat</surname><given-names>VV</given-names></name><etal/></person-group><source>Open Source Software: PyDeface</source><publisher-name>Zenodo</publisher-name><year>2022</year><date-in-citation>cited 2024 Oct 29</date-in-citation><comment>[Internet] Available from: <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/records/6856482">https://zenodo.org/records/6856482</ext-link></comment></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Theyers</surname><given-names>AE</given-names></name><name><surname>Zamyadi</surname><given-names>M</given-names></name><name><surname>O’Reilly</surname><given-names>M</given-names></name><name><surname>Bartha</surname><given-names>R</given-names></name><name><surname>Symons</surname><given-names>S</given-names></name><name><surname>MacQueen</surname><given-names>GM</given-names></name><etal/></person-group><article-title>Multisite Comparison of MRI Defacing Software Across Multiple Cohorts</article-title><source>Front Psychiatry</source><year>2021</year><month>Feb</month><day>24</day><volume>12</volume><date-in-citation>cited 2024 Oct 29</date-in-citation><comment>[Internet]</comment><pub-id pub-id-type="pmcid">PMC7943842</pub-id><pub-id pub-id-type="pmid">33716819</pub-id><pub-id pub-id-type="doi">10.3389/fpsyt.2021.617997</pub-id></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Provins</surname><given-names>C</given-names></name><name><surname>MacNicol</surname><given-names>EE</given-names></name><name><surname>Seeley</surname><given-names>SH</given-names></name><name><surname>Hagmann</surname><given-names>P</given-names></name><name><surname>Esteban</surname><given-names>O</given-names></name></person-group><article-title>Quality Control in functional MRI studies with MRIQC and fMRIPrep</article-title><source>Front Neuroimaging</source><year>2023</year><volume>1</volume><elocation-id>1073734</elocation-id><pub-id pub-id-type="pmcid">PMC10406249</pub-id><pub-id pub-id-type="pmid">37555175</pub-id><pub-id pub-id-type="doi">10.3389/fnimg.2022.1073734</pub-id></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nárai</surname><given-names>Á</given-names></name><name><surname>Hermann</surname><given-names>P</given-names></name><name><surname>Auer</surname><given-names>T</given-names></name><name><surname>Kemenczky</surname><given-names>P</given-names></name><name><surname>Szalma</surname><given-names>J</given-names></name><name><surname>Homolya</surname><given-names>I</given-names></name><etal/></person-group><article-title>Movement-related artefacts (MR-ART) dataset of matched motion-corrupted and clean structural MRI brain scans</article-title><source>Sci Data</source><year>2022</year><month>Oct</month><day>17</day><volume>9</volume><issue>1</issue><fpage>630</fpage><pub-id pub-id-type="pmcid">PMC9576686</pub-id><pub-id pub-id-type="pmid">36253426</pub-id><pub-id pub-id-type="doi">10.1038/s41597-022-01694-8</pub-id></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taylor</surname><given-names>PA</given-names></name><name><surname>Glen</surname><given-names>DR</given-names></name><name><surname>Reynolds</surname><given-names>RC</given-names></name><name><surname>Basavaraj</surname><given-names>A</given-names></name><name><surname>Moraczewski</surname><given-names>D</given-names></name><name><surname>Etzel</surname><given-names>JA</given-names></name></person-group><article-title>Editorial: Demonstrating quality control (QC) procedures in fMRI</article-title><source>Front Neurosci</source><year>2023</year><volume>17</volume><date-in-citation>cited 2023 Sep 8</date-in-citation><comment>[Internet]</comment><pub-id pub-id-type="pmcid">PMC10264898</pub-id><pub-id pub-id-type="pmid">37325035</pub-id><pub-id pub-id-type="doi">10.3389/fnins.2023.1205928</pub-id></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Di Martino</surname><given-names>A</given-names></name><name><surname>Yan</surname><given-names>CG</given-names></name><name><surname>Li</surname><given-names>Q</given-names></name><name><surname>Denio</surname><given-names>E</given-names></name><name><surname>Castellanos</surname><given-names>FX</given-names></name><name><surname>Alaerts</surname><given-names>K</given-names></name><etal/></person-group><article-title>The autism brain imaging data exchange: towards a large-scale evaluation of the intrinsic brain architecture in autism</article-title><source>Mol Psychiatry</source><year>2014</year><month>Jun</month><volume>19</volume><issue>6</issue><fpage>659</fpage><lpage>67</lpage><pub-id pub-id-type="pmcid">PMC4162310</pub-id><pub-id pub-id-type="pmid">23774715</pub-id><pub-id pub-id-type="doi">10.1038/mp.2013.78</pub-id></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gorgolewski</surname><given-names>KJ</given-names></name><name><surname>Durnez</surname><given-names>J</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name></person-group><article-title>Preprocessed Consortium for Neuropsychiatric Phenomics dataset</article-title><source>F1000Research</source><year>2017</year><month>Sep</month><day>22</day><volume>6</volume><elocation-id>1262</elocation-id><pub-id pub-id-type="pmcid">PMC5664981</pub-id><pub-id pub-id-type="pmid">29152222</pub-id><pub-id pub-id-type="doi">10.12688/f1000research.11964.2</pub-id></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Savary</surname><given-names>E</given-names></name><name><surname>Provins</surname><given-names>C</given-names></name><name><surname>Sanchez</surname><given-names>T</given-names></name><name><surname>Esteban</surname><given-names>O</given-names></name></person-group><source>Q’kay: a manager for the quality assessment of large neuroimaging studies</source><conf-name>Annual Meeting of the Organization for Human Brain Mapping (OHBM)</conf-name><conf-loc>Montréal, QC, Canada</conf-loc><year>2023</year><elocation-id>2467</elocation-id><date-in-citation>cited 2023 Jan 23</date-in-citation><comment>[Internet] Available from: <ext-link ext-link-type="uri" xlink:href="https://osf.io/edx6t/">https://osf.io/edx6t/</ext-link></comment></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shapiro</surname><given-names>SS</given-names></name><name><surname>Wilk</surname><given-names>MB</given-names></name></person-group><article-title>An analysis of variance test for normality (complete samples)</article-title><source>Biometrika</source><year>1965</year><month>Dec</month><day>1</day><volume>52</volume><issue>3–4</issue><fpage>591</fpage><lpage>611</lpage></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Kassambara</surname><given-names>A</given-names></name></person-group><source>ggpubr: “ggplot2” Based Publication Ready Plots</source><year>2023</year><date-in-citation>cited 2024 Oct 29</date-in-citation><comment>[Internet] Available from: <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/web/packages/ggpubr/index.html">https://cran.r-project.org/web/packages/ggpubr/index.html</ext-link></comment></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mauchly</surname><given-names>JW</given-names></name></person-group><article-title>Significance Test for Sphericity of a Normal n-Variate Distribution</article-title><source>Ann Math Stat</source><year>1940</year><volume>11</volume><issue>2</issue><fpage>204</fpage><lpage>9</lpage></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Kassambara</surname><given-names>A</given-names></name></person-group><source>rstatix: Pipe-Friendly Framework for Basic Statistical Tests</source><year>2023</year><date-in-citation>cited 2024 Oct 29</date-in-citation><comment>[Internet] Available from: <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/web/packages/rstatix/index.html">https://cran.r-project.org/web/packages/rstatix/index.html</ext-link></comment></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faul</surname><given-names>F</given-names></name><name><surname>Erdfelder</surname><given-names>E</given-names></name><name><surname>Buchner</surname><given-names>A</given-names></name><name><surname>Lang</surname><given-names>AG</given-names></name></person-group><article-title>Statistical power analyses using G*Power 3.1: Tests for correlation and regression analyses</article-title><source>Behav Res Methods</source><year>2009</year><month>Nov</month><day>1</day><volume>41</volume><issue>4</issue><fpage>1149</fpage><lpage>60</lpage><pub-id pub-id-type="pmid">19897823</pub-id></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Bates</surname><given-names>D</given-names></name><name><surname>Maechler</surname><given-names>M</given-names></name><name><surname>Bolker</surname><given-names>B</given-names></name><name><surname>Walker</surname><given-names>S</given-names></name><name><surname>Christensen</surname><given-names>RHB</given-names></name><etal/></person-group><source>lme4: Linear Mixed-Effects Models using “Eigen” and S4</source><year>2024</year><date-in-citation>cited 2024 Oct 29</date-in-citation><comment>[Internet] Available from: <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/web/packages/lme4/index.html">https://cran.r-project.org/web/packages/lme4/index.html</ext-link></comment></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="web"><collab>R Core Team</collab><source>R: The R Project for Statistical Computing</source><date-in-citation>cited 2024 Oct 29</date-in-citation><comment>[Internet] Available from: <ext-link ext-link-type="uri" xlink:href="https://www.r-project.org/">https://www.r-project.org/</ext-link></comment></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kirk</surname><given-names>RE</given-names></name></person-group><source>Experimental Design: Procedures for the Behavioral Sciences</source><publisher-name>SAGE Publications</publisher-name><year>2012</year><date-in-citation>cited 2024 Oct 28</date-in-citation><comment>[Internet] Available from: <ext-link ext-link-type="uri" xlink:href="https://methods.sagepub.com/book/experimental-design">https://methods.sagepub.com/book/experimental-design</ext-link></comment></element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Altman</surname><given-names>DG</given-names></name><name><surname>Bland</surname><given-names>JM</given-names></name></person-group><article-title>Measurement in Medicine: The Analysis of Method Comparison Studies</article-title><source>J R Stat Soc Ser Stat</source><year>1983</year><volume>32</volume><issue>3</issue><fpage>307</fpage><lpage>17</lpage></element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bland</surname><given-names>JM</given-names></name><name><surname>Altman</surname><given-names>DG</given-names></name></person-group><article-title>Measuring agreement in method comparison studies</article-title><source>Statistical Methods in Medical Research</source><year>1999</year><volume>8</volume><issue>2</issue><fpage>135</fpage><lpage>160</lpage><pub-id pub-id-type="pmid">10501650</pub-id></element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedrich</surname><given-names>S</given-names></name><name><surname>Konietschke</surname><given-names>F</given-names></name><name><surname>Pauly</surname><given-names>M</given-names></name></person-group><article-title>Resampling-Based Analysis of Multivariate Data and Repeated Measures Designs with the R Package MANOVA.RM</article-title><source>R J</source><year>2019</year><volume>11</volume><issue>2</issue><fpage>380</fpage><lpage>400</lpage></element-citation></ref><ref id="R40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morgan</surname><given-names>CA</given-names></name><name><surname>Roberts</surname><given-names>RP</given-names></name><name><surname>Chaffey</surname><given-names>T</given-names></name><name><surname>Tahara-Eckl</surname><given-names>L</given-names></name><name><surname>van der Meer</surname><given-names>M</given-names></name><name><surname>Günther</surname><given-names>M</given-names></name><etal/></person-group><article-title>Reproducibility and repeatability of magnetic resonance imaging in dementia</article-title><source>Phys Med</source><year>2022</year><month>Sep</month><day>1</day><volume>101</volume><fpage>8</fpage><lpage>17</lpage><pub-id pub-id-type="pmid">35849909</pub-id></element-citation></ref><ref id="R41"><label>41</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benjamini</surname><given-names>Y</given-names></name><name><surname>Hochberg</surname><given-names>Y</given-names></name></person-group><article-title>Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing</article-title><source>J R Stat Soc Ser B Methodol</source><year>1995</year><volume>57</volume><issue>1</issue><fpage>289</fpage><lpage>300</lpage></element-citation></ref><ref id="R42"><label>42</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Q</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Dai</surname><given-names>S</given-names></name></person-group><article-title>On estimating the non-centrality parameter of a chi-squared distribution</article-title><source>Stat Probab Lett</source><year>2009</year><month>Jan</month><day>1</day><volume>79</volume><issue>1</issue><fpage>98</fpage><lpage>104</lpage></element-citation></ref><ref id="R43"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gudicha</surname><given-names>DW</given-names></name><name><surname>Schmittmann</surname><given-names>VD</given-names></name><name><surname>Vermunt</surname><given-names>JK</given-names></name></person-group><article-title>Power computation for likelihood ratio tests for the transition parameters in latent Markov models</article-title><source>Struct Equ Model</source><year>2016</year><volume>23</volume><issue>2</issue><fpage>234</fpage><lpage>45</lpage></element-citation></ref><ref id="R44"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilk</surname><given-names>MB</given-names></name><name><surname>Gnanadesikan</surname><given-names>R</given-names></name></person-group><article-title>Probability plotting methods for the analysis for the analysis of data</article-title><source>Biometrika</source><year>1968</year><month>Mar</month><day>1</day><volume>55</volume><issue>1</issue><fpage>1</fpage><lpage>17</lpage><pub-id pub-id-type="pmid">5661047</pub-id></element-citation></ref><ref id="R45"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoenig</surname><given-names>JM</given-names></name><name><surname>Heisey</surname><given-names>DM</given-names></name></person-group><article-title>The Abuse of Power: The Pervasive Fallacy of Power Calculations for Data Analysis</article-title><source>Am Stat</source><year>2001</year><month>Feb</month><day>1</day><volume>55</volume><issue>1</issue><fpage>19</fpage><lpage>24</lpage></element-citation></ref><ref id="R46"><label>46</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ben-Shachar</surname><given-names>MS</given-names></name><name><surname>Lüdecke</surname><given-names>D</given-names></name><name><surname>Makowski</surname><given-names>D</given-names></name></person-group><article-title>effectsize: Estimation of Effect Size Indices and Standardized Parameters</article-title><source>J Open Source Softw</source><year>2020</year><month>Dec</month><day>23</day><volume>5</volume><issue>56</issue><elocation-id>2815</elocation-id></element-citation></ref><ref id="R47"><label>47</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoenig</surname><given-names>JM</given-names></name><name><surname>Heisey</surname><given-names>DM</given-names></name></person-group><article-title>The Abuse of Power: The Pervasive Fallacy of Power Calculations for Data Analysis</article-title><source>Am Stat</source><year>2001</year><month>Feb</month><day>1</day><volume>55</volume><issue>1</issue><fpage>19</fpage><lpage>24</lpage></element-citation></ref><ref id="R48"><label>48</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dietrich</surname><given-names>O</given-names></name><name><surname>Raya</surname><given-names>JG</given-names></name><name><surname>Reeder</surname><given-names>SB</given-names></name><name><surname>Reiser</surname><given-names>MF</given-names></name><name><surname>Schoenberg</surname><given-names>SO</given-names></name></person-group><article-title>Measurement of SNRs in MR images: influence of multichannel coils, parallel imaging and reconstruction filters</article-title><source>JMRI</source><year>2007</year><volume>26</volume><issue>2</issue><fpage>375</fpage><lpage>385</lpage><pub-id pub-id-type="pmid">17622966</pub-id></element-citation></ref><ref id="R49"><label>49</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pizarro</surname><given-names>RA</given-names></name><name><surname>Cheng</surname><given-names>X</given-names></name><name><surname>Barnett</surname><given-names>A</given-names></name><name><surname>Lemaitre</surname><given-names>H</given-names></name><name><surname>Verchinski</surname><given-names>BA</given-names></name><name><surname>Goldman</surname><given-names>AL</given-names></name><etal/></person-group><article-title>Automated Quality Assessment of Structural Magnetic Resonance Brain Images Based on a Supervised Machine Learning Algorithm</article-title><source>Front Neuroinf</source><year>2016</year><volume>10</volume><pub-id pub-id-type="pmcid">PMC5165041</pub-id><pub-id pub-id-type="pmid">28066227</pub-id><pub-id pub-id-type="doi">10.3389/fninf.2016.00052</pub-id></element-citation></ref><ref id="R50"><label>50</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Provins</surname><given-names>C</given-names></name><name><surname>Markiewicz</surname><given-names>CJ</given-names></name><name><surname>Ciric</surname><given-names>R</given-names></name><name><surname>Goncalves</surname><given-names>M</given-names></name><name><surname>Caballero-Gaudes</surname><given-names>C</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name><name><surname>Hagmann</surname><given-names>P</given-names></name><name><surname>Esteban</surname><given-names>O</given-names></name></person-group><source>Quality control and nuisance regression of fMRI, looking out where signal should not be found</source><conf-name>Proc Intl Soc Mag Reson Med</conf-name><conf-sponsor>ISMRM</conf-sponsor><conf-loc>London, England, UK</conf-loc><year>2022</year><volume>31</volume><elocation-id>2683</elocation-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>An example of T1w image before and after defacing.</title><p>Defacing is typically implemented by zeroing the voxels around the face (left-hand side, panel “T1-weighted”). The “Background noise” panel shows two visualizations extracted from the <italic>MRIQC</italic> visual report, in which a window is applied to select the lowest intensities and then they are inverted to enhance patterns in the brackground. The red arrows indicate aliases along the anterior-posterior axis—which had the lowest bandwidth in the example—produced by eye motion. These aliases are straightforward to notice in front of the ocular globes in the “Background noise” panel of the “nondefaced” image because of the absence of signal sources. This aliasing also spreads in the opposite direction, overlapping brain tissue. However, this overlap is often very hard to notice against the signal of interest within the brain. The corresponding “defaced” version of the “Background noise” panel shows how defacing eliminates valuable information for quality assessment.</p></caption><graphic xlink:href="EMS199398-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Defacing biases human assessment of image quality, particularly when image quality is low.</title><p>We examined biases with an “optimized” version of the BA plot, in which the <italic>x</italic>-axis represents the rating assigned to the nondefaced version of an image. Corresponding “standard” BA plots—in which the <italic>x</italic>-axis shows the average of the two ratings [<xref ref-type="bibr" rid="R37">37</xref>]—are reported in <xref ref-type="supplementary-material" rid="SD1">Fig. S2</xref>. Rating pairs where the defaced image’s quality was underestimated with respect to the nondefaced (Δ<sub>ndef−def</sub>&gt; 0) are represented in yellow. Conversely, pairs where the defaced image’s quality was overestimated (Δ<sub>ndef−def</sub>&lt; 0) are in purple. Pairs within the 95% LoA are represented with dim colors, and the LoA boundaries are indicated with dashed colored lines annotated with their value. For example, the LoA for all raters pooled together was [-0.91, 0.81] (left panel). Finally, the bias 𝔼[Δ<sub>ndef−def</sub>] is represented by a gray or black dashed line with a label reporting value and their corresponding 95% CI interval (parametric estimation). All raters displayed 95% LoA exceeding one unit, indicating that defacing introduces large variability in human assessments. All raters had negative—albeit small—biases, indicating that they systematically rated defaced images higher. However, these biases were statistically significant only for Raters 1 and 2, as well as the four raters aggregated together—indicated by the bias label and line colored in black. Relevant statistics (bias, LoA, 95% CI) are reported in <xref ref-type="supplementary-material" rid="SD1">Table S2</xref>, and the full report of statistics, including 95% CI intervals calculated both by parametric and non-parametric means are distributed as tab-separated-values files on the corresponding GitHub repository.</p></caption><graphic xlink:href="EMS199398-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Rater 4 issued visibly different ratings, generally more optimistic, than the other raters in both (defaced and nondefaced) conditions.</title><p>The gray lines highlight the evolution of the rating between the nondefaced image and its defaced counterpart. The full white line in the violin plot represents the median of the distribution, while the dashed white lines represent the 25% and 75% quantiles. Comparing the median of the rating distribution from the nondefaced versus defaced images, it is visible that different raters presented different bias magnitudes. Our most experienced rater (Rater 1) showed the largest bias. Rater 4’s rating distribution diverged from that of the other raters, being more optimistic overall about the quality of the images. Rater 4 also displayed a lower spread in quality assessments, which translated into the narrowest 95% LoA (<xref ref-type="fig" rid="F2">Fig. 2</xref>). Lastly, low ratings tended to be more biased by defacing as they showed a steeper evolution line, sometimes jumping one unit or more (equivalent to switching categories in the appreciation of quality, e.g., going from “poor” to “acceptable”). Higher ratings displayed gaps within 0.5 units. The same observation is visible on the BA plots (<xref ref-type="fig" rid="F2">Figs. 2</xref> and <xref ref-type="supplementary-material" rid="SD1">S2</xref>).</p></caption><graphic xlink:href="EMS199398-f003"/></fig><table-wrap id="T1" orientation="portrait" position="float"><label>Table 1</label><caption><title>Sensitivity analyses for rm-ANOVA and LME comparisons.</title><p>We determined that our rm-ANOVA modeling would confirm differences in manual ratings of f=0.218 or larger with <italic>G*Power</italic> [<xref ref-type="bibr" rid="R33">33</xref>]. This sensitivity corresponds to <inline-formula><mml:math id="M12"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.045</mml:mn></mml:mrow></mml:math></inline-formula> (i.e., a medium effect size) following Equation S1. In the rm-ANOVA sensitivity analysis, we set two groups (defaced/nondefaced) and four measurements (4 raters) with a total sample size of 185 subjects from the HH site, 90% power, α = 0.02, a nonsphericity correction of 0.34, and a correlation among repeated measures of 0.1. Note that this sensitivity analysis is conservative as we expected a much higher correlation among repeated measures, which would reduce the detectable effect size. Remaining conservative, we iteratively tried different non-sphericity correction values and kept the lowest one possible to maximize the detectable effect size. With <italic>G*Power</italic> (<xref ref-type="supplementary-material" rid="SD1">Fig. S11</xref>), we also estimated the noncentrality parameter λ associated with the likelihood ratio test, which is a proxy for the effect size, yielding λ = 13.017. The degrees of freedom of the likelihood ratio test correspond to the difference in parameter count between the two nested LMEs compared (see <xref ref-type="supplementary-material" rid="SD1">Table S6</xref>).</p></caption><table frame="void" rules="groups"><thead><tr><th valign="top" align="left" style="background: #cccccc">Test</th><th valign="top" align="left" colspan="2" style="border-left: 1px solid #000000;background: #cccccc">Input parameters</th><th valign="top" align="left" colspan="2" style="border-left: 1px solid #000000;background: #cccccc">Output parameters</th></tr></thead><tbody><tr><td valign="middle" align="left" rowspan="7" style="border-top: 1px solid">rm-ANOVA</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">α err prob</td><td valign="top" align="left" style="border-top: 1px solid">0.02</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">Noncentrality parameter λ</td><td valign="top" align="left" style="border-top: 1px solid">13.273</td></tr><tr><td valign="top" align="left" style="border-left: 1px solid #000000;background: #f2f2f2">Power (1 -β err prob)</td><td valign="top" align="left" style="background: #f2f2f2">0.9</td><td valign="top" align="left" style="border-left: 1px solid #000000;background: #f2f2f2">Critical F</td><td valign="top" align="left" style="background: #f2f2f2">5.454</td></tr><tr><td valign="top" align="left" style="border-left: 1px solid">Total sample size</td><td valign="top" align="left">185</td><td valign="top" align="left" style="border-left: 1px solid">Df (Numerator)</td><td valign="top" align="left">1.02</td></tr><tr><td valign="top" align="left" style="border-left: 1px solid #000000;background: #f2f2f2">Number of groups</td><td valign="top" align="left" style="background: #f2f2f2">2</td><td valign="top" align="left" style="border-left: 1px solid #000000;background: #f2f2f2">Df (Denominator)</td><td valign="top" align="left" style="background: #f2f2f2">186.66</td></tr><tr><td valign="top" align="left" style="border-left: 1px solid">Number of measurements</td><td valign="top" align="left">4</td><td valign="top" align="left" style="border-left: 1px solid">Effect size f</td><td valign="top" align="left">0.218</td></tr><tr><td valign="top" align="left" style="border-left: 1px solid #000000;background: #f2f2f2">Corr among rep measures</td><td valign="top" align="left" style="background: #f2f2f2">0.1</td><td valign="top" align="left" colspan="2" style="border-left: 1px solid #000000;background: #f2f2f2"/></tr><tr><td valign="top" align="left" style="border-left: 1px solid">Non-sphericity correction ε</td><td valign="top" align="left">0.34</td><td valign="top" align="left" colspan="2" style="border-left: 1px solid"/></tr><tr><td valign="middle" align="left" rowspan="3" style="border-top: 1px solid #000000">Likelihood<break/>ratio test</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000;background: #f2f2f2">α err prob</td><td valign="top" align="left" style="border-top: 1px solid #000000;background: #f2f2f2">0.02</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000;background: #f2f2f2">Critical χ<sup>2</sup></td><td valign="top" align="left" style="border-top: 1px solid #000000;background: #f2f2f2">5.412</td></tr><tr><td valign="top" align="left" style="border-left: 1px solid">Power (1 -β err prob)</td><td valign="top" align="left">0.9</td><td valign="top" align="left" style="border-left: 1px solid">Noncentrality parameter λ</td><td valign="top" align="left">13.017</td></tr><tr><td valign="top" align="left" style="border-left: 1px solid #000000;background: #f2f2f2">Degrees of freedom</td><td valign="top" align="left" style="background: #f2f2f2">1</td><td valign="top" align="left" colspan="2" style="border-left: 1px solid #000000;background: #f2f2f2"/></tr></tbody></table></table-wrap><table-wrap id="T2" orientation="portrait" position="float"><label>Table 2</label><caption><title>The sensitivity analysis indicated that the rm-MANOVA was able to confirm differences in IQM of f=0.16 corresponding to η<sup>2</sup> = 0. 025 (i.e., a medium effect) or greater.</title><p>We ran the sensitivity analysis with <italic>G*Power</italic>, setting three groups (3 sites) and two measurements (defaced/nondefaced) with N = 580 (number of T1w per subject) per condition, with 90% power, and α = 0.02.</p></caption><table frame="void" rules="groups"><thead><tr><th valign="top" align="left" style="background: #cccccc">Input parameters</th><th valign="top" align="left" style="background: #cccccc"/><th valign="top" align="left" style="border-left: 1px solid #000000;background: #cccccc">Output parameters</th><th valign="top" align="left" style="background: #cccccc"/></tr></thead><tbody><tr><td valign="top" align="left" style="border-top: 1px solid">α err prob</td><td valign="top" align="left" style="border-top: 1px solid">0.02</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">Noncentrality parameter λ</td><td valign="top" align="left" style="border-top: 1px solid">15.5188571</td></tr><tr><td valign="top" align="left" style="background: #f2f2f2">Power (1 -β err prob)</td><td valign="top" align="left" style="background: #f2f2f2">0.9</td><td valign="top" align="left" style="border-left: 1px solid #000000;background: #f2f2f2">Critical F</td><td valign="top" align="left" style="background: #f2f2f2">3.9386666</td></tr><tr><td valign="top" align="left">Total sample size</td><td valign="top" align="left">580</td><td valign="top" align="left" style="border-left: 1px solid">Numerator degree of freedom</td><td valign="top" align="left">2</td></tr><tr><td valign="top" align="left" style="background: #f2f2f2">Number of groups</td><td valign="top" align="left" style="background: #f2f2f2">3</td><td valign="top" align="left" style="border-left: 1px solid #000000;background: #f2f2f2">Denominator degree of freedom</td><td valign="top" align="left" style="background: #f2f2f2">577</td></tr><tr><td valign="top" align="left">Number of measurements</td><td valign="top" align="left">2</td><td valign="top" align="left" style="border-left: 1px solid">Effect size f</td><td valign="top" align="left">0.1635746</td></tr><tr><td valign="top" align="left" style="background: #f2f2f2"/><td valign="top" align="left" style="background: #f2f2f2"/><td valign="top" align="left" style="border-left: 1px solid #000000;background: #f2f2f2">Pillai V</td><td valign="top" align="left" style="background: #f2f2f2">0.0260594</td></tr></tbody></table></table-wrap><table-wrap id="T3" orientation="portrait" position="float"><label>Table 3</label><caption><title>The linear mixed-effect models (LME) with defacing as a fixed effect explained significantly more variance than a “baseline” counterpart without defacing.</title><p>Model comparison with a likelihood ratio test yielded a <italic>p</italic><sub>FDR</sub> = 0.0183 after false discovery rate (FDR) correction. Complete reporting of the pre-registered comparison and the additional exploratory analyses are provided in <xref ref-type="supplementary-material" rid="SD1">Tables S6 and S7</xref> (Supplementary Materials).</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top" align="right" style="border-top: solid 1px #ffffff;border-bottom:solid 1px #000000;background:#CCCCCC">Sample size</th><th valign="top" align="right" style="border-top: solid 1px #ffffff;border-bottom:solid 1px #000000;background:#CCCCCC">χ<sup>2</sup></th><th valign="top" align="right" style="border-top: solid 1px #ffffff;border-bottom:solid 1px #000000;background:#CCCCCC">df</th><th valign="top" align="right" style="border-top: solid 1px #ffffff;border-bottom:solid 1px #000000;background:#CCCCCC">P(&gt;χ<sup>2</sup>)</th><th valign="top" align="right" style="border-top: solid 1px #ffffff;border-bottom:solid 1px #000000;background:#CCCCCC"><italic>p</italic><sub>FDR</sub></th><th valign="top" align="right" style="border-top: solid 1px #ffffff;border-bottom:solid 1px #000000;background:#CCCCCC"><italic>p</italic><sub>FDR</sub> &lt;.02</th></tr></thead><tbody><tr><td valign="top" align="right" style="border-bottom: 1px solid">1480</td><td valign="top" align="right" style="border-bottom: 1px solid">6.283</td><td valign="top" align="right" style="border-bottom: 1px solid">1</td><td valign="top" align="right" style="border-bottom: 1px solid">0.0122</td><td valign="top" align="right" style="border-bottom: 1px solid">0.0183</td><td valign="top" align="right" style="border-bottom: 1px solid">*</td></tr></tbody></table></table-wrap><table-wrap id="T4" orientation="portrait" position="float"><label>Table 4</label><caption><title>Results of repeated-measures MANOVA on the projected IQMs.</title><p>We did not find an effect of the site nor an effect of defacing on the principal components extracted from the IQMs. However, applying the IQMs standardization and PCA separately per site mitigated the site effects, revealing a defacing bias. Despite being significant, the defacing bias is associated with a negligible effect size. Effect size is reported as partial eta-squared <inline-formula><mml:math id="M13"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and was computed with the function <italic>F_to_eta2</italic> from the <italic>R</italic> package <italic>effectsize</italic> [<xref ref-type="bibr" rid="R46">46</xref>], which implements the formula given in Equation S4 with df = numDF and df_error = denDF. <italic>p</italic><sub>FDR</sub> corresponds to <italic>p</italic>-values controlled for false discovery rate (FDR).</p></caption><table frame="box" rules="groups"><thead><tr><th valign="top" align="left" colspan="2" rowspan="2" style="border-top: 1px solid #000000;border-left: 1px solid #000000;background: #cccccc"/><th valign="top" align="center" colspan="4" style="border-top: 1px solid #000000;border-left: 1px solid #000000;background: #cccccc">Wald-type Statistic (WTS)</th><th valign="top" align="center" colspan="2" style="border-top:solid 1px #000000;border-left:solid 1px #000000;background:#CCCCCC">Modified ANOVA- type Statistic (MATS)</th><th valign="top" align="center" colspan="2" style="border:solid 1px #000000;background: #CCCCCC">Resampling version of the tests</th></tr><tr><th valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000;background:#CCCCCC">Test Statistic</th><th valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000;background:#CCCCCC">df</th><th valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000;background:#CCCCCC"><italic>p</italic></th><th valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000;background:#CCCCCC"><italic>p</italic><sub>FDR</sub></th><th valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000;background:#CCCCCC">Test Statistic</th><th valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000;background:#CCCCCC"><inline-formula><mml:math id="M14"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula></th><th valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000;background:#CCCCCC"><italic>p</italic><sub>WTS</sub></th><th valign="top" align="left" style="border:solid 1px #000000;background:#CCCCCC"><italic>p</italic><sub>MATS</sub></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="2" style="border-top: 1px solid #000000;border-left: 1px solid">Single<break/>PCA (pre- registered)</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">site</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.376</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">2</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.828</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.994</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.457</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">7.9 · 10-<sup>4</sup></td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.829</td><td valign="top" align="left" style="border:solid 1px #000000">0.827</td></tr><tr><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">defaced</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.003</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">1</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.96</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.96</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.002</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">3.5 · 10-<sup>6</sup></td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.961</td><td valign="top" align="left" style="border:solid 1px #000000">0.961</td></tr><tr><td valign="top" align="left" rowspan="2" style="border:solid 1px #000000;background: #CCCCCC">Site-wise<break/>PCA<break/>(exploratory)</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000;background:#CCCCCC">site</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000;background:#CCCCCC">0.358</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000;background:#CCCCCC">2</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000;background:#CCCCCC">0.836</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000;background:#CCCCCC">0.994</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000;background:#CCCCCC">0.710</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000;background:#CCCCCC">0.0012</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000;background:#CCCCCC">0.833</td><td valign="top" align="left" style="border:solid 1px #000000;background:#CCCCCC">0.833</td></tr><tr><td valign="top" align="left" style="border:solid 1px #000000;background:#CCCCCC">defaced</td><td valign="top" align="left" style="border:solid 1px #000000;background:#CCCCCC">181.182</td><td valign="top" align="left" style="border:solid 1px #000000;background:#CCCCCC">1</td><td valign="top" align="left" style="border:solid 1px #000000;background:#CCCCCC">&lt;.001</td><td valign="top" align="left" style="border:solid 1px #000000;background:#CCCCCC">&lt;.003<break/>**</td><td valign="top" align="left" style="border:solid 1px #000000;background:#CCCCCC">2.726</td><td valign="top" align="left" style="border:solid 1px #000000;background:#CCCCCC">0.0047</td><td valign="top" align="left" style="border:solid 1px #000000;background:#CCCCCC">&lt;.001<break/>***</td><td valign="top" align="left" style="border:solid 1px #000000;background:#CCCCCC">&lt;.001<break/>***</td></tr></tbody></table></table-wrap><table-wrap id="T5" orientation="portrait" position="float"><label>Table 5</label><caption><title>Study design template.</title><p>This table summarizes the link between the hypotheses, research questions, analysis plans, sensitivity analysis, and prospective interpretation given different outcomes.</p></caption><table frame="box" rules="groups"><thead><tr><th valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000;background: #d9d9d9">Hypothesis</th><th valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000;background: #d9d9d9">Question</th><th valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000;background: #d9d9d9">Sampling plan</th><th valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000;background: #d9d9d9">Analysis Plan</th><th valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000;background:#d9d9d9">Rationale for deciding the<break/>sensitivity of the test for<break/>confirming or disconfirming<break/>the hypothesis</th><th valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000;background: #d9d9d9">Interpretation given different outcomes</th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="2" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid">Defacing influences trained raters’ perception of quality</td><td valign="top" align="left" rowspan="2" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid">Do the quality ratings from human raters significantly vary between the defaced and the nondefaced conditions?</td><td valign="top" align="left" rowspan="2" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid">There is no previous analysis that can inform us on the effect size. For the rationale on how we chose the sample size, refer to the sensitivity analysis in the fifth column.</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">We will first verify whether the sphericity and normality assumptions of repeated- measures ANOVA (rm- ANOVA) are met. If they are, a rm-ANOVA will then be implemented in R.</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">The sensitivity analysis, reported in Table 1, indicates that at worst we will be able to confirm differences in manual ratings of f=0.14 corresponding to η<sup>2</sup> = 0.019 (i.e a medium effect) or greater.</td><td valign="top" align="left" style="border:solid 1px #000000">p&lt;.02 will indicate significance of the rm- ANOVA, thus confirming that manual quality ratings significantly vary between the defaced and nondefaced conditions. Conversely, we will interpret p≥.02 as a failure to confirm our hypothesis. In any case, the post hoc power achieved and the Cohen’s f effect size will be reported. The effect will be deemed irrelevant if the power achieved is lower than 90% or if the Cohen’s f effect size is smaller than the minimum detectable effect size we obtained from the sensitivity analysis.</td></tr><tr><td valign="top" align="left" style="border:solid 1px #000000">In the contingency that at least one of the rm- ANOVA assumptions is violated, we will use linear mixed-effects models instead. To test the effect of defacing, we will perform a likelihood- ratio test comparing the models with and without adding the defaced factor as a fixed effect.</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid">The sensitivity analysis for the likelihood ratio test is reported in Table 1.</td><td valign="top" align="left" style="border: 1px solid">The bias of defacing on the manual ratings will be deemed significant if the likelihood-ratio test returns p&lt;.02. Conversely, we will interpret p≥.02 as a failure to confirm our hypothesis. Furthermore, the effect will be deemed irrelevant if the non-centrality parameter associated with the likelihood ratio test is smaller than 13, corresponding to the minimum power achievable from the sensitivity analysis.</td></tr><tr><td valign="top" align="left" style="border-left: 1px solid"/><td valign="top" align="left" style="border-left: 1px solid">Are ratings in the defaced condition higher than the correspondi ng ratings on the nondefaced condition ?</td><td valign="top" align="left" style="border-left: 1px solid"/><td valign="top" align="left" style="border-left: 1px solid">We will use Bland-Altman plots (Altman and Bland 1983) to visualize the bias and the limits of agreement of manual quality ratings between the nondefaced and the defaced condition.</td><td valign="top" align="left" style="border-left: 1px solid"/><td valign="top" align="left" style="border-left:solid 1px #000000;border-right:solid 1px #000000">To demonstrate that the ratings of the defaced condition are higher than the corresponding ratings on the nondefaced condition, the bias should be shown to be significantly negative. A bias in the BA plot will be deemed significant if the 95% limits of agreement do not contain the zero difference. In case the 95% limits of agreement do not contain the zero difference, but the bias is positive, we will alternatively conclude that human raters perceive nondefaced images as having better quality overall. Lastly, in case the 95% limits of agreement contains the zero difference, we will conclude that we failed to verify the consistency of defacing bias on manual ratings.</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid">Defacing biases automatic<break/>QA/QC of structural MRI with<break/><italic>MRIQC</italic></td><td valign="top" align="left" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid">Do the<break/>IQMs computed by <italic>MRIQC</italic> significantly vary between the defaced and the nondefaced condition ?</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid">As a reference to the sensitivity analysis in the fifth column, the effect size associated with PyDeface influence on IQMs in (Bhalerao et al. 2022) ranged from f=0.045 to f=1.79 with a mean effect size across IQMs of f=0.61.</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid">A two-way repeated- measures MANOVA (rm- MANOVA) will be used to test whether defacing significantly influences the IQMs. However, because many IQMs are heavily correlated (see Figure S14), we will apply principal components analysis (PCA) on the IQMs before running rm- MANOVA.</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid">The sensitivity analysis, reported in Table 2, indicates that we will be able to confirm differences in IQM of f=0.16 corresponding to η<sup>2</sup> = 0.025 (i.e a medium effect) or greater.</td><td valign="top" align="left" style="border:solid 1px #000000">p&lt;.02 will indicate significance of the rm- MANOVA, thus confirming that the IQMs generated by <italic>MRIQC</italic> significantly vary between the defaced and nondefaced conditions. We will consider the p-values extracted under the section wald-type statistics. Conversely, we will interpret p≥.02 as a failure to confirm our hypothesis. In any case, the post hoc power achieved and the Cohen’s f effect size will be reported. The effect will be deemed irrelevant if the power achieved is lower than 90% or if the Cohen’s f effect size is smaller than the minimum detectable effect size we obtained from the sensitivity analysis.</td></tr></tbody></table></table-wrap></floats-group></article>