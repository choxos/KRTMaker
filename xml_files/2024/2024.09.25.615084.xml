<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS199031</article-id><article-id pub-id-type="doi">10.1101/2024.09.25.615084</article-id><article-id pub-id-type="archive">PPR915794</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">2</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Retinotopic coding organizes the interaction between internally and externally oriented brain networks</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Steel</surname><given-names>Adam</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref><xref ref-type="fn" rid="FN2">6</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><contrib contrib-type="author"><name><surname>Angeli</surname><given-names>Peter A.</given-names></name><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Silson</surname><given-names>Edward H.</given-names></name><xref ref-type="aff" rid="A4">4</xref></contrib><contrib contrib-type="author"><name><surname>Robertson</surname><given-names>Caroline E.</given-names></name><xref ref-type="aff" rid="A3">3</xref><xref ref-type="fn" rid="FN1">5</xref><xref ref-type="corresp" rid="CR2">**</xref></contrib></contrib-group><aff id="A1"><label>1</label>Beckman Institute, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/047426m28</institution-id><institution>University of Illinois Urbana-Champaign</institution></institution-wrap>, <city>Urbana</city>, <state>Illinois</state>, <country country="US">USA</country></aff><aff id="A2"><label>2</label>Department of Psychology, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/047426m28</institution-id><institution>University of Illinois Urbana-Champaign</institution></institution-wrap>, <city>Urbana</city>, <state>Illinois</state>, <country country="US">USA</country></aff><aff id="A3"><label>3</label>Department of Psychology, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/049s0rh22</institution-id><institution>Dartmouth College</institution></institution-wrap>, <city>Hanover</city>, <state>NH</state>, <country country="US">USA</country></aff><aff id="A4"><label>4</label>Department of Psychology, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/01nrxwf90</institution-id><institution>University of Edinburgh</institution></institution-wrap>, <city>Edinburgh</city>, <country country="GB">United Kingdom</country></aff><author-notes><corresp id="CR1"><label>*</label>Correspondence: <email>adamdanielsteel@gmail.com</email>, <email>adamdanielsteel@neuro_steel</email></corresp><corresp id="CR2"><label>**</label>Correspondence: <email>caroline.e.robertson@dartmouth.edu</email></corresp><fn id="FN1"><label>5</label><p id="P1">Senior author</p></fn><fn id="FN2"><label>6</label><p id="P2">Lead contact</p></fn></author-notes><pub-date pub-type="nihms-submitted"><day>28</day><month>09</month><year>2024</year></pub-date><pub-date pub-type="preprint"><day>27</day><month>09</month><year>2024</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P3">The human brain seamlessly integrates internally generated thoughts with incoming sensory information, yet the networks supporting internal (default network, DN) and external (dorsal attention network, dATN) processing are traditionally viewed as antagonistic. This raises a crucial question: how does the brain integrate information between these seemingly opposed systems? Here, using precision neuroimaging methods, we show that these internal/external networks are not as dissociated as traditionally thought. Using densely-sampled 7T fMRI data, we defined individualized whole-brain networks from participants at rest and calculated the retinotopic preferences of individual voxels within these networks during an visual mapping task. We show that while the overall network activity between the DN and dATN is independent at rest, considering a latent retinotopic code reveals a complex, voxel-scale interaction stratified by visual responsiveness. Specifically, the interaction between the DN and dATN at rest is structured at the voxel-level by each voxel’s retinotopic preferences, such that the spontaneous activity of voxels preferring similar visual field locations is more anti-correlated than that of voxels preferring different visual field locations. Further, this retinotopic scaffold integrates with the domain-specific preferences of subregions within these networks, enabling efficient, parallel processing of retinotopic and domain-specific information. Thus, DN and dATN are not independent at rest: voxel-scale interaction between these networks preserves and encodes information in both positive and negative BOLD responses, even in the absence of visual input or task demands. These findings suggest that retinotopic coding may serve as a fundamental organizing principle for brain-wide communication, providing a new framework for understanding how the brain balances and integrates internal cognition with external perception.</p></abstract></article-meta></front><body><p id="P4">A fundamental goal of neuroscience is to understand how activity distributed across the brain’s functional networks gives rise to cognition <sup><xref ref-type="bibr" rid="R1">1</xref>–<xref ref-type="bibr" rid="R9">9</xref></sup>. Central to this aim is understanding principles that govern interactions between different brain networks, particularly those involved in externally-oriented attention (e.g., processing sensory input) and internally-oriented attention (e.g., introspection and memory) <sup><xref ref-type="bibr" rid="R10">10</xref>–<xref ref-type="bibr" rid="R14">14</xref></sup>. This knowledge gap confounds our understanding of human cognition: the interaction between internally- and externally-oriented neural systems is foundational to how we perceive, remember, and navigate our world, yet the ‘common language’ facilitating their communication remains controversial.</p><p id="P5">One reason this knowledge gap exists is that the neural systems that subserve internally- and externally-oriented attention, such as the Default Network (DN) and dorsal attention network (dATN) respectively, are typically considered competitive<sup><xref ref-type="bibr" rid="R10">10</xref>–<xref ref-type="bibr" rid="R12">12</xref>,<xref ref-type="bibr" rid="R14">14</xref>,<xref ref-type="bibr" rid="R15">15</xref></sup>. Seminal neuroimaging studies investigating externally-oriented attention (visual processing, working memory, etc.) showed that visual tasks reliably <italic>activate</italic> brain areas in lateral occipital temporal cortex, dorsal parietal cortex, and prefrontal cortex, now collectively referred to as the dATN<sup><xref ref-type="bibr" rid="R10">10</xref>,<xref ref-type="bibr" rid="R14">14</xref>,<xref ref-type="bibr" rid="R16">16</xref>,<xref ref-type="bibr" rid="R17">17</xref></sup>. In contrast, visual tasks reliably <italic>deactivate</italic> regions in the internally-oriented DN, including lateral and medial parietal cortex, anterior temporal lobe, and medial prefrontal cortex<sup><xref ref-type="bibr" rid="R13">13</xref>,<xref ref-type="bibr" rid="R18">18</xref></sup>. This pattern reverses during introspective tasks, e.g., scene construction or theory of mind tasks: the DN systematically activates and the dATN deactivates<sup><xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R19">19</xref>–<xref ref-type="bibr" rid="R23">23</xref></sup>. The network-level independence between the dATN and DN has also been observed in spontaneous activity at rest. Prior work has found these network’s resting-state activity is independent (i.e., not correlated) or anti-correlated<sup><xref ref-type="bibr" rid="R11">11</xref>,<xref ref-type="bibr" rid="R12">12</xref>,<xref ref-type="bibr" rid="R24">24</xref>,<xref ref-type="bibr" rid="R25">25</xref></sup> (depending on the application of global signal regression<sup><xref ref-type="bibr" rid="R11">11</xref>,<xref ref-type="bibr" rid="R26">26</xref></sup>). Together, DN/dATN independence is thought to facilitate our ability to attend to external stimuli without competition from internal mnemonic representations, and vice versa <sup><xref ref-type="bibr" rid="R10">10</xref>,<xref ref-type="bibr" rid="R12">12</xref>,<xref ref-type="bibr" rid="R27">27</xref>,<xref ref-type="bibr" rid="R28">28</xref></sup>. However, if internally- and externally-oriented networks are functionally dissociated, it is not clear how the brain accomplishes tasks that require integrating perceptual and mnemonic information (e.g., anticipatory saccades, memory-based attention tasks, and mental imagery).</p><p id="P6">Two recent findings have shed light on this question. First, while the internally-oriented DN traditionally is thought to use an abstract or semantic neural code <sup><xref ref-type="bibr" rid="R2">2</xref>,<xref ref-type="bibr" rid="R28">28</xref>–<xref ref-type="bibr" rid="R30">30</xref></sup>, recent work suggests that a neural code that is typically associated with externally-oriented visual information processing -- retinotopy -- also manifests in the DN <sup><xref ref-type="bibr" rid="R31">31</xref>–<xref ref-type="bibr" rid="R34">34</xref></sup>. The retinotopic code in the DN is unlike classically visually-responsive areas, including the portions of the dATN. In the DN, retinotopic coding manifests as an “inverted retinotopic code”: while stimulation of the retina causes canonical visual areas to increase neural activity in a position-dependent manner, the DN exhibits position-specific <italic>decreases</italic> in activity <sup><xref ref-type="bibr" rid="R31">31</xref>,<xref ref-type="bibr" rid="R33">33</xref>,<xref ref-type="bibr" rid="R34">34</xref></sup>. Thus, the DN’s deactivation reflects specific properties of the attended external stimulus and is informative during visual attention tasks.</p><p id="P7">Second, recently the inverted retinotopic code has been proposed to play a functional role in structuring mnemonic-perceptual interactions, specifically across scene-selective visual and memory areas near the DN<sup><xref ref-type="bibr" rid="R34">34</xref></sup>. During familiar scene processing, activity in brain areas specialized for scene perception and memory differentially increases during perception and recall tasks, respectively<sup><xref ref-type="bibr" rid="R35">35</xref>,<xref ref-type="bibr" rid="R36">36</xref></sup>. However, at the voxel level, the visual and memory responsive areas exhibit an interlocked, retinotopically specific opponent dynamic <sup><xref ref-type="bibr" rid="R34">34</xref></sup>. In other words, stimuli in specific visual field locations activate perception voxels and suppress memory area voxels monitoring that location. This pattern reverses during memory tasks. This challenges the traditional view of internally- and externally-oriented brain networks as functionally-opposed via global opponent dynamics, suggesting instead that they are part of a common information processing stream. It also emphasizes the importance of voxel-wise activity patterns in uncovering neural codes that underpin global brain dynamics.</p><p id="P8">Based on these findings, we reasoned that retinotopic coding could be a widespread mechanism that scaffolds global interactions across large-scale internally- and externally-oriented brain networks<sup><xref ref-type="bibr" rid="R37">37</xref></sup>. We leveraged a high-resolution 7T fMRI dataset<sup><xref ref-type="bibr" rid="R38">38</xref></sup> and voxel-wise modeling to test whether retinotopic coding structures global interactions between the DN and dATN. We tested three hypotheses. First, the voxel-wise retinotopic push-pull dynamic observed in the highly-specialized subareas of the DN/dATN during visual tasks<sup><xref ref-type="bibr" rid="R34">34</xref></sup> will generalize to the overall networks’ spontaneous neural activity, even in the absence of experimenter-imposed task demands. Second, among subareas of the DN/dATN, retinotopic coding will be integrated (multiplexed) with an areas’ functional domain to allow fine-grained control of information exchange across cortex. Finally, retinotopic coding should be intrinsic throughout the brain, even in areas of the brain associated with internal attention. So, the retinotopic code will be evident in both top-down and bottom-up interactions between perceptual and mnemonic areas. Together, these results would suggest retinotopy is a unifying framework organizing brain-wide information processing and internal versus external attention dynamics.</p><sec id="S1"><title>Retinotopic coding in internally and externally oriented networks</title><p id="P9">To investigate the role of retinotopic coding in structuring activity between internally- and externally-oriented brain networks, we used voxel-wise visual population receptive field (pRF) modeling and resting-state fMRI data from the Natural Scenes Dataset<sup><xref ref-type="bibr" rid="R38">38</xref></sup> (<xref ref-type="fig" rid="F1">Fig. 1A</xref>). We assessed the retinotopic responsiveness of all voxels in the brain by modeling BOLD activity in response to a sweeping bar stimulus <sup><xref ref-type="bibr" rid="R39">39</xref></sup>. We considered any voxel with &gt;8% variance explained by our pRF model to be exhibiting a retinotopic code, and hereafter we refer to these voxels as “pRFs”. PRF amplitude maps for all participants are shown in <xref ref-type="supplementary-material" rid="SD1">Fig. S1</xref>. Because we did not observe any hemispheric differences in pRF size, contra-laterality, distribution of pRF amplitude, or effects in subsequent analyses (ps &gt; 0.55), data are presented collapsed across hemispheres.</p><p id="P10">Then, we used resting-state fMRI data to identify each participant’s idiosyncratic cortical networks <sup><xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R40">40</xref></sup> and assessed their visual responsiveness. Resting-state data were preprocessed using ICA with manual noise component selection<sup><xref ref-type="bibr" rid="R41">41</xref>,<xref ref-type="bibr" rid="R42">42</xref></sup> and no global signal regression was performed<sup><xref ref-type="bibr" rid="R26">26</xref></sup>. We established 15 cortical networks using multi-session hierarchical Bayesian modeling<sup><xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R40">40</xref></sup> and combined the Default Networks A-B and the Dorsal Attention Networks A-B to constitute our internal and externally oriented networks, respectively (hereafter, DN and dATN) (<xref ref-type="fig" rid="F1">Fig. 1B</xref>; <xref ref-type="supplementary-material" rid="SD1">Fig. S2</xref>).</p><p id="P11">Consistent with the opponent interaction between the DN and dATN during visual tasks<sup><xref ref-type="bibr" rid="R11">11</xref>,<xref ref-type="bibr" rid="R12">12</xref>,<xref ref-type="bibr" rid="R18">18</xref></sup>, we saw a strong distinction in the visual response of these internally- and externally-oriented brain networks previously observed by others <sup><xref ref-type="bibr" rid="R31">31</xref></sup> (<xref ref-type="fig" rid="F1">Fig. 1C</xref>; <xref ref-type="supplementary-material" rid="SD1">Fig. S3</xref>). Across participants, a larger proportion of dATN voxels exceeded our retinotopic variance explained threshold compared to the DN (55.3% of dATN voxels, 26.95% of DN voxels) consistent with their role as externally- and internally-oriented networks, respectively. However, the nature of retinotopy in these two networks differed significantly on their response amplitude (i.e. whether a stimulus in their preferred visual field location evoked a positive or a negative BOLD response) (<xref ref-type="fig" rid="F1">Fig 1C</xref>). On average more than half of all suprathreshold pRFs in the DNs were inverted (i.e., had a negative BOLD response to visual stimulation in their population receptive field, -pRFs). In contrast, less than 20% of the suprathreshold voxels in the dATN were -pRFs (i.e., the majority of the voxels had positive BOLD responses to visual stimulation in their receptive field, +pRFs). This distinction is particularly remarkable given the proximity of the dATN and DN clusters in posterior cerebral cortex (<xref ref-type="fig" rid="F1">Fig. 1B</xref>). The response amplitude of these pRF populations was reliable (<xref ref-type="supplementary-material" rid="SD1">Fig. S4</xref>). Together, these results establish the necessary foundation to assess whether the voxel-wise retinotopic code structures global interactions between the internally- and externally-oriented networks.</p><p id="P12">Do interactions between the DN and dATN depend on visual responsiveness of individual voxels? Across resting-state runs, we saw that the average activity of the DN and dATN was modestly positively correlated after accounting for variance across all cortical networks using partial correlation<sup><xref ref-type="bibr" rid="R43">43</xref></sup> (mean correlation = 0.117±0.12 s.d., t(6) = 2.60, p=0.041). Crucially, however, we found a strong dissociation in the nature of the interaction between the DN and dATN when we split the DN voxels by their visual responsiveness (<xref ref-type="fig" rid="F1">Fig 1D</xref>). DN voxels that responded positively to visual stimulation (+DN pRFs) had a positive correlation with the dATN (mean correlation = 0.22±0.144, t(6) = 3.99, p = 0.0072), and the activity of DN voxels that did not systematically respond to visual stimulation (i.e., pRF model R2&lt;0.08) was not significantly correlated with the dATN (mean correlation = 0.02±0.115, t(6) = 0.37, p = 0.72). On the other hand, the activity of DN voxels with systematic negative responses to visual stimulation (-DN pRFs) was anti-correlated with the dATN (mean correlation = -0.20±0.12, t(6) = 4.22, p = 0.0055). Thus, the relationship between the DN and dATN is stratified by the visual responsiveness of the voxels within the DN, and opponency at rest between the DN and dATN can be attributed to voxels with negative responses to visual stimulation in the DN.</p></sec><sec id="S2"><title>Retinotopic coding scaffolds DN and dATN interactions</title><p id="P13">To test whether the retinotopic code structured the interaction between the internally- and externally-oriented brain networks at a voxel level, we examined whether the visual field preferences of individual voxels within these networks predicted their correlation at rest. Specifically, because of the hypothesized competition of the DN and dATN, we asked whether the opponent dynamic between -pRFs in the DN and +pRFs in the dATN is stronger for voxels with similar visual field preferences?</p><p id="P14">For each pRF in the DN and dATN, we calculated the pairwise distance between the RF center position (x, y parameter estimates) of -pRFs in the DN and +pRFs in dATN (<xref ref-type="fig" rid="F2">Fig.2A</xref>). For each DN -pRF, we found the 10 closest (Matched) and furthest (Antimatched) dATN +pRF centers. Interestingly, matched pRFs were distributed across the dATN, spanning posterior areas in retinotopic cortex through prefrontal cortical regions not typically associated with visual analysis (<xref ref-type="supplementary-material" rid="SD1">Fig. S5</xref>). We then averaged these matched and antimatched pRF’s resting-state time series together, and we compared the correlation of these matched/antimatched timeseries with the time series from the DN -pRFs (see <xref ref-type="sec" rid="S7">methods</xref>). This resulted in two correlation values per resting-state run, which represented the correlation of the average matched and antimatched pRF’s time series between these areas. Importantly, the primary statistics relevant to the conclusions in the manuscript replicated when considering randomly sampled pRF pairs, and therefore our conclusions do not depend on how pRFs are selected to be compared to the best matched pRFs (See Supplemental methods and results)</p><p id="P15">If the -DN and +dATN opponent interaction is scaffolded by a retinotopic code, the correlation between spatially matched pRFs should be significantly more negative than the antimatched pRFs. For this analysis we partialled out variance associated with +DN pRFs to isolate the specific relationship between -DN and +dATN pRFs (and vice versa) <sup><xref ref-type="bibr" rid="R34">34</xref>,<xref ref-type="bibr" rid="R43">43</xref></sup>. Our results were consistent with this hypothesis. We observed a negative correlation between both matched and antimatched -DN and +dATN pRFs in the overwhelming majority of resting state runs (<xref ref-type="fig" rid="F2">Fig. 2B</xref>, left) <sup><xref ref-type="bibr" rid="R29">29</xref>,<xref ref-type="bibr" rid="R37">37</xref></sup> (see <xref ref-type="sec" rid="S7">methods</xref>). Critically, the distribution of matched +dATN and -DN pRFs was significantly shifted compared to antimatched pRFs (D(392)=0.22, p&lt;0.001), confirming an overall stronger negative correlation, and thus a stronger opponent interaction between matched compared to antimatched pRFs. The stronger opponent interaction for matched versus antimatched pRFs was clear when resting-state runs were averaged within each participant (7/7 participants; t(6)=3.63, p=0.010, <xref ref-type="fig" rid="F2">Fig.2B</xref>, right). Interestingly, retinotopy played a similarly strong role in structuring the opponent dynamic between the dATN and both subnetworks of the DN (DN-A: t(6)=3.02, p=0.023, DN-B: t(6)=2.72, p=0.034; DN-A vs. DN-B: t(6)=1.511, p&lt;0.182), although the opponency was stronger overall in DN-A compared to DN-B (t(6)=5.532, p=0.002). Importantly, tSNR of the matched and antimatched pRF’s resting-state time series did not differ (t(6)=1.007, p=0.353), suggesting that differences in signal quality did not underlie the difference in correlation.</p><p id="P16">Retinotopic coding scaffolded the interaction between +DN and +dATN pRFs, as well. Consistent with their overall positive interaction, both matched and antimatched +DN pRFs had a positive correlation with dATN pRFs after accounting for variance associated with -DN pRFs, and retinotopic coding enhanced this positive correlation, as matched pRFs had a significantly greater positive correlation than antimatched pRFs (D(392) = 0.245, p&lt;0.001; t(6)=-3.99, p=0.007; <xref ref-type="supplementary-material" rid="SD1">Fig. S6</xref>). Thus, retinotopic coding also structures interactions between positively responsive voxels in the DN and dATN.</p><p id="P17">Together, these results suggest that the retinotopic code plays a role in structuring the overall interaction between the brain’s internally- and externally-oriented cortical networks, and the nature of the DN/dATN interaction depends on the visual response of DN pRFs. DN pRFs with positive responses to visual stimulation exhibit a retinotopically-specific positive correlation to dATN pRFs, while DN pRFs with negative responses to visual stimulation exhibit a retinotopically-specific opponent interaction with dATN pRFs.</p></sec><sec id="S3"><title>Retinotopic coding organizes activity within functional domains</title><p id="P18">Our results so far clearly establish that retinotopic coding structures spontaneous interactions between internally- and externally-oriented neural systems in the absence of task demands. However, high-level cortical areas generally associate into networks based on their functional domain. For example, within the visual system, brain areas with differing retinotopic preferences (e.g., the scene-selective areas on the lateral and ventral surfaces of the brain) <sup><xref ref-type="bibr" rid="R45">45</xref>,<xref ref-type="bibr" rid="R46">46</xref></sup> nevertheless form functional networks based on their apparent preference for specific visual categories (e.g., faces, objects, or scenes)<sup><xref ref-type="bibr" rid="R47">47</xref>,<xref ref-type="bibr" rid="R48">48</xref></sup>. This raises a question: do retinotopic and domain-specific organizational principles interact to facilitate or constrain information flow across internally- and externally-oriented networks? Addressing this question would shed light on mechanisms that enable the brain to integrate information while maintaining functional specialization.</p><p id="P19">To address this question, we focused on the functional interplay between a set of areas in posterior cerebral cortex that are established models for mnemonic and visual processing in the domains of scene and face perception. Specifically, we considered the mnemonic lateral place memory area (LPMA<sup><xref ref-type="bibr" rid="R35">35</xref>,<xref ref-type="bibr" rid="R36">36</xref></sup>), an area on the brain’s lateral surface that is implicated in processing mnemonic information relevant to visual scenes at the border between DN-A and the dATNs (<xref ref-type="fig" rid="F2">Fig 2A</xref>). We examined how LPMA activation co-fluctuates with the adjacent, scene-perception area “occipital place area” on the brain’s lateral surface (OPA<sup><xref ref-type="bibr" rid="R49">49</xref>,<xref ref-type="bibr" rid="R50">50</xref></sup>) compared to two face-perception regions on the lateral and ventral surfaces, the occipital and fusiform face areas (OFA and FFA <sup><xref ref-type="bibr" rid="R51">51</xref>,<xref ref-type="bibr" rid="R52">52</xref></sup>). At a group level, these perceptual regions are situated within the dATNs and are at the same level of the visual hierarchy (<xref ref-type="fig" rid="F3">Fig. 3A</xref>), but they are differentially associated with the domains of scene (OPA) and face (OFA, FFA) processing, making them ideal model systems to examine the impact of domain-specificity and retinotopic coding in organizing neural activity.</p><p id="P20">We first defined the mnemonic area LPMA in the NSD participants. To do this, we contrasted functional connectivity between the anterior and posterior halves of the parahippocampal place area using each participant’s resting state data<sup><xref ref-type="bibr" rid="R53">53</xref>,<xref ref-type="bibr" rid="R54">54</xref></sup> (<xref ref-type="fig" rid="F3">Fig. 3B</xref>; See <xref ref-type="sec" rid="S7">Methods</xref>), which revealed a cluster in lateral parietal cortex with a similar topographic profile as LPMA based on a group analysis from our prior work <sup><xref ref-type="bibr" rid="R35">35</xref></sup> (<xref ref-type="fig" rid="F3">Fig.3C</xref>). Replicating our previous findings<sup><xref ref-type="bibr" rid="R34">34</xref></sup>, this connectivity-defined LPMA had a higher concentration of robust -pRFs compared to OPA (t(7)=5.26, p=0.002) (<xref ref-type="fig" rid="F3">Fig.3D</xref>, <xref ref-type="supplementary-material" rid="SD1">Supplemental Fig. S4, S7</xref>) and exhibited a similar lower visual field bias as OPA (OPA: 8/8 t(7)=3.13, p=0.016; LPMA: 7/8 participants, t(7)=2.11, p=0.07; OPA v LPMA: t(7)=0.441, p=0.67) (<xref ref-type="fig" rid="F3">Fig. 3E</xref>).</p><p id="P21">We first considered whether the retinotopic opponent dynamic we have previously shown in the domain of scenes (i.e., between -LPMA and +OPA pRFs) during perceptual and mnemonic tasks<sup><xref ref-type="bibr" rid="R34">34</xref></sup> was also present at rest (<xref ref-type="fig" rid="F3">Fig. 3F</xref>). As we observed for the overall -DN and +dATN pRFs, we found that -LPMA and +OPA pRFs are interlocked in a retinotopically-grounded opponent interaction. Resting-state activity of -LPMA and +OPA pRFs was reliably negatively correlated after accounting for variance associated with +DN pRFs, and, critically, this negative correlation was stronger for matched compared with antimatched pRFs (K-S test: D(392)=0.22, p&lt;0.001; t(6)=4.45, p=0.004) (<xref ref-type="fig" rid="F3">Fig.3-I</xref>; <xref ref-type="supplementary-material" rid="SD1">Fig. S8</xref>). This pattern was consistent when matched/antimatched pRFs were equated for eccentricity and size (matched vs. antimatched: D(392)=0.148, p=0.028; t(6)=2.03,p=0.087; 5/7 participants) (<xref ref-type="supplementary-material" rid="SD1">Fig. S9</xref>). Matched and antimatched +OPA pRFs resting-state tSNR (t(6)=1.922, p=0.103) and variance explained by the pRF model (t(6)=0.47, p=0.65) did not differ, suggesting that idiosyncratic voxels did not drive these results. Additionally, the opponent interaction was specific to -pRFs in LPMA: the activity of the best matched +pRFs in LPMA and OPA was positively correlated, and significantly more so than antimatched +pRFs in LPMA and OPA (t(6)=3.22, p=0.018; <xref ref-type="supplementary-material" rid="SD1">Supplementary Fig. S10</xref>). Taken together, these results show that the retinotopic code scaffolds the spontaneous interaction between perceptual and mnemonic brain areas within a functional domain, conceptually replicating our previous findings from task-fMRI <sup><xref ref-type="bibr" rid="R34">34</xref></sup>.</p><p id="P22">Having established that the retinotopic opponent dynamic between -/+pRFs is present among functionally-paired brain areas within the domain of scenes, we next tested whether this opponent dynamic was modified by functional domain (i.e., the scene memory area LPMA paired with the face perception areas FFA and OFA). Remarkably, when matching across functional domains we observed no significant difference between the distribution of correlation values for matched and antimatched pRFs (Matched versus antimatched pRFs – -LPMA x +OFA: D(392)=0.09,p=0.44, t(6)=1.04, p=0.34; FFA: D(392)=0.11,p=0.15, t(6)=1.48, p=0.18; <xref ref-type="fig" rid="F2">Fig. 2G</xref>-I). Retinotopic-opponency was greater within- compared to across-domain matching (scene-memory x scene-perception versus average scene-memory x face-perception: t(6)=2.46, p=0.049). Importantly, matched pRFs within domain had a significantly stronger opponent interaction than across domains (within vs across domains – -LPMAx+OPA v -LPMAx+FFA: t(6)=5.94, p=0.001; - LPMAx+OPA v -LPMAx+OFA: t(6)=7.03, p&lt;0.0005). These results indicate that retinotopic coding does not structure the interaction between pairs of regions associated with distinct functional domains. Instead, retinotopic scaffolding appears to be selective, operating only within a given functional domain. This coding scheme could allow for efficient, parallel processing of domain-specific information (e.g., faces, scenes) that can be flexibly adapted depending on task demands.</p></sec><sec id="S4"><title>Retinotopic coding is inherent to internally-oriented areas</title><p id="P23">Our findings support the crucial role of retinotopic coding in scaffolding spontaneous interactions between functionally-coupled mnemonic and perceptual brain areas. However, a fundamental question remains: is retinotopy intrinsic to internally-oriented cortical areas’ top-down influence over externally-oriented areas, or is the internally-oriented areas’ retinotopic code merely adopted in response to bottom-up perceptual input? Resolving this distinction is critical to understanding if the retinotopic scaffold is a general-purpose mechanism for cross-network interaction that transcends specific task demands and cognitive domains (i.e., memory vs. perception).</p><p id="P24">To address this question, we developed an analytical approach to disambiguate bottom-up perceptual signals from top-down mnemonic signals. This allowed us to determine whether the influence of top-down or bottom-up was more influential on the overall opponent relationship. We only considered the interaction between -LPMA and +OPA pRFs because we were specifically interested in whether the opponent dynamic would be present during periods of top-down drive. We identified periods where spontaneous activity of individual -LPMA or +OPA pRFs was unusually high (z-scored BOLD signal of a given voxel exceeded the 99th percentile of activity in a resting-state run). We considered these time points neural “events.” Events detected in -LPMA pRFs were considered top-down, and events in +OPA pRFs were considered bottom-up, and we analyzed the peri-event activation in the target area’s matched and antimatched pRFs (<xref ref-type="fig" rid="F3">Fig. 3A</xref>). Because participants do not have any experimentally imposed task demands during resting-state fMRI, any structured interaction between areas will reflect these regions’ spontaneous dynamics.</p><p id="P25">Our analysis detected 20,958 top-down events and 7,193 bottom-up events. Top-down and bottom-up events occurred at the same rate per pRF (t(6)=0.71, p=0.50). Individual participants averaged 116±70.4 top-down and 32±11.76 bottom up (mean±sd) events per run. All pRFs had between 0 and 4 events per run (<xref ref-type="supplementary-material" rid="SD1">Fig. S11A-C</xref>). The wide distribution of events in time suggested that individual pRF-level correlation could be isolated from global fluctuations in regional activity (<xref ref-type="supplementary-material" rid="SD1">Fig. S11A</xref>), making this approach suitable for evaluating distinct interactions at the individual voxel level.</p><p id="P26">Intriguingly, although both top-down and bottom-up events tended to reduce target area activity via a retinotopic code, only top-down events resulted in suppression of the target pRFs (relative to the pre-event baseline). During top-down events, compared to pre-event baseline +OPA pRFs showed significant deactivation that was more pronounced in matched compared to antimatched pRFs (<xref ref-type="fig" rid="F3">Fig. 3B</xref>). On the other hand, relative to their pre-event baseline -LPMA pRFs had elevated activity during bottom-up events. However, despite the lack of opponency, the activation of matched pRFs was significantly reduced compared to antimatched pRFs suggesting an inhibitory influence of bottom-up activity of +OPA on -LPMA pRFs. The influence of retinotopic coding was similar for both bottom-up and top-down events, indicating a symmetric inhibitory interaction: target area activity was significantly lower for matched compared to antimatched pRFs in both directions (top-down: t(6)=4.13, p=0.006; bottom-up: t(6)=3.17, p=0.02), with no difference between event types (t(6)=0.86, p=0.42). The balanced dynamic between -LPMA and +OPA pRFs mirrors other nervous system interactions <sup><xref ref-type="bibr" rid="R56">56</xref>–<xref ref-type="bibr" rid="R59">59</xref></sup>, extending this well-established framework in these sensory/motor domains to higher-order cognitive functions.</p><p id="P27">We further tested whether top-down events detected across all DN -pRFs would show this opponent dynamic. Indeed, we observed a clear, retinotopic opponency during top-down events in -DN pRFs, relative to the activity of the dATN (Matched vs antimatched: t(6)=10.43, p&lt;0.001, <xref ref-type="supplementary-material" rid="SD1">Fig. S12</xref>). This is clear evidence that both top-down and bottom-up events evoke retinotopically-specific inhibitory responses in the target region, supporting the hypothesis that retinotopic coding is intrinsic to mnemonic cortical areas, even in the absence of task demands or overt visual input.</p></sec><sec id="S5" sec-type="discussion"><title>Discussion</title><p id="P28">In summary, it is well-established that internally- and externally-oriented brain networks, including DNs and dATNs, support higher cognition in humans <sup><xref ref-type="bibr" rid="R1">1</xref>–<xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R11">11</xref>–<xref ref-type="bibr" rid="R13">13</xref></sup>. Yet we lack an understanding of what coding principles, if any, underpin interactions across these distributed brain networks <sup><xref ref-type="bibr" rid="R30">30</xref>,<xref ref-type="bibr" rid="R60">60</xref>–<xref ref-type="bibr" rid="R64">64</xref></sup>. Here, we show that a retinotopic code scaffolds the voxel-scale interaction between internally- and externally-oriented brain networks, even in the absence of overt visual demands. Moreover, by examining functionally-linked perceptual and mnemonic areas straddling the boundary between the DNs and dATNs, we found that this retinotopic information is multiplexed with domain-specific information, which may enable effective parallel processing of representations depending on retinotopic location, attentional-state, and task-demands. Finally, analysis of neural events in these functionally-linked regions showed that retinotopic opponency is present in top-down as well as bottom-up events, suggesting that the retinotopic code is intrinsic to both perceptual and mnemonic cortical areas. Collectively, our results provide a unified framework for understanding the flow of neural activity between brain areas, whereby macro-scale neural dynamics are organized at the meso-scale by functional domain and at the voxel-scale by a low-level retinotopic code. This multi-scale view of information processing has broad implications for understanding how the brain’s distributed networks give rise to attention, perception, and memory.</p><p id="P29">Because of the DN’s importance in many cognitive processes, including spatial and episodic memory, social processing, and executive functioning <sup><xref ref-type="bibr" rid="R13">13</xref>,<xref ref-type="bibr" rid="R65">65</xref>–<xref ref-type="bibr" rid="R70">70</xref></sup>, resolving the coding principles inherent to the DN is central to understanding human cognition<sup><xref ref-type="bibr" rid="R12">12</xref>,<xref ref-type="bibr" rid="R61">61</xref>–<xref ref-type="bibr" rid="R66">66</xref></sup>. The traditional view of neural coding posits that sensory codes like retinotopy are shed in favor of abstract, amodal codes moving up the cortical hierarchy towards the DN <sup><xref ref-type="bibr" rid="R2">2</xref>,<xref ref-type="bibr" rid="R29">29</xref>,<xref ref-type="bibr" rid="R30">30</xref></sup>. Our data contrast strikingly with this view. Instead of shedding the retinotopic code at the cortical apex, our prior work has shown that the low-level retinotopic code structures interactions between functionally paired perceptual and mnemonic areas in posterior cerebral cortex involved in visual scene analysis during visual and memory tasks<sup><xref ref-type="bibr" rid="R34">34</xref></sup>. Here we significantly extend that earlier finding by showing that the retinotopic code organizes spontaneous interactions between the brain’s primary internally- and externally-oriented large-scale networks, DN and dATN, even in the absence of task demands.</p><p id="P30">Our findings of retinotopic, voxel-scale opponency between DN and dATN pRFs is at odds with theories that posit that these networks’ activity is independent<sup><xref ref-type="bibr" rid="R11">11</xref>,<xref ref-type="bibr" rid="R23">23</xref>,<xref ref-type="bibr" rid="R27">27</xref>,<xref ref-type="bibr" rid="R28">28</xref></sup> or even competitive<sup><xref ref-type="bibr" rid="R10">10</xref>,<xref ref-type="bibr" rid="R12">12</xref>,<xref ref-type="bibr" rid="R71">71</xref></sup>. Moreover, the traditional conception of the DN suggests that it does not participate in sensory processing<sup><xref ref-type="bibr" rid="R10">10</xref>–<xref ref-type="bibr" rid="R13">13</xref></sup>. Instead of independence between these networks, our results suggest that the activation of the visually-responsive voxels in the DN and dATN is complementary, with the precise relationship stratified by individual voxel’s positive or negative responsiveness to visual stimuli. Without considering voxel-wise information, these voxel-level distinctions appear to “average out” into a global independence or opponency <sup><xref ref-type="bibr" rid="R11">11</xref>,<xref ref-type="bibr" rid="R12">12</xref></sup>, which has led to the conclusion that these networks are engaged in fundamentally different cognitive processes. In contrast, our results emphasize that the DN and dATNs jointly process common, retinotopic information. Their mutual retinotopic code enables these networks to encode retinotopic information at a voxel level in both positive and negative BOLD responses.</p><p id="P31">What purpose might this retinotopically-specific opponent dynamic coding serve in the context of overall brain function? We propose two complementary functions. One possibility is that oppositional coding of -DN pRFs, in particular, may serve as a neural mechanism for maintaining separate channels for perceptual and mnemonic information <sup><xref ref-type="bibr" rid="R61">61</xref></sup>. Representing mnemonic signals in topographically distinct regions may prevent this internally-generated information from being interpreted as external. Similarly, by encoding remembered information in an inverted retinotopic format, the brain could process memory and perception simultaneously while preventing cross-talk—much like how opposing radio frequencies can carry different signals without interference. A second possibility is that oppositional coding could be a mechanism for signaling mnemonic predictions via top-down inhibitory processes<sup><xref ref-type="bibr" rid="R72">72</xref></sup>. Specifically, when the DN generates predictions about incoming sensory information, the inverted retinotopic code could act as a suppressive signal that sharpens tuning in perceptual areas<sup><xref ref-type="bibr" rid="R73">73</xref>,<xref ref-type="bibr" rid="R74">74</xref></sup>. This suppression would effectively enhance the neural representation of predicted stimuli by reducing background noise. These mechanisms likely work in concert: the inverted code simultaneously maintains separate channels for memory/perception while enabling precise top-down predictive signaling. Future work combining cellular recording techniques with behavior will be crucial for testing these proposed mechanisms and understanding how they contribute to cognitive function.</p><p id="P32">Retinotopic coding between the DN and dATN was clear in both subnetworks of the DN, DN-A and DN-B<sup><xref ref-type="bibr" rid="R3">3</xref>,<xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R20">20</xref></sup>. This is surprising given that these subnetworks are thought to subserve very different cognitive functions. Between these subnetworks, the role of DN-A is more easily tied to visual processing. DN-A is thought to be involved in memory tasks with a visual component, like episodic projection and scene construction <sup><xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R20">20</xref></sup>, and at the group-level DN-A overlaps with areas of the brain that we have previously shown implement a retinotopic code and respond to visual tasks<sup><xref ref-type="bibr" rid="R34">34</xref>–<xref ref-type="bibr" rid="R36">36</xref></sup>. On the other hand, DN-B is thought to be involved with theory of mind tasks that do not obviously rely on visual information, like interpretation of false belief and emotional/physical pain <sup><xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R20">20</xref></sup>. In this case, retinotopic coding might still be a useful format for transforming these abstract signals into sensory-grounded representations that can inform behavioral decisions (e.g., eye movements) and sensory predictions (e.g., anticipating facial expressions or body postures). Despite these differences, both DN subnetworks implemented a retinotopic code with respect to their interaction with the dATN, which further supports retinotopic coding as a core principle underpinning the brain’s functional organization.</p><p id="P33">The importance of retinotopic coding is further underscored when assessing “top-down” events (i.e. events that originate in the DN) detected at rest, which had a retinotopically-specific suppressive influence on pRFs in their downstream target area. This result joins mounting evidence demonstrating retinotopic coding in the DN <sup><xref ref-type="bibr" rid="R31">31</xref>–<xref ref-type="bibr" rid="R34">34</xref></sup>, as well as new evidence supporting the importance of visual coding in the DN during visual tasks <sup><xref ref-type="bibr" rid="R34">34</xref>,<xref ref-type="bibr" rid="R75">75</xref></sup>. Our findings align with other recent studies suggesting an important role of the DN in shaping visual responses. For example, others have shown that ongoing prestimulus DN activity influences the sensitivity of near-threshold visual object recognition <sup><xref ref-type="bibr" rid="R75">75</xref></sup>. Other work has shown that subareas of the DN represent the visuospatial context that is associated in memory with a perceived scene <sup><xref ref-type="bibr" rid="R34">34</xref>–<xref ref-type="bibr" rid="R36">36</xref>,<xref ref-type="bibr" rid="R76">76</xref></sup>. Relatedly, DN activity reflects semantic-level attentional priorities during visual search <sup><xref ref-type="bibr" rid="R77">77</xref></sup>. Taken together, these findings show that, rather than being disengaged during visual tasks, the DN actively shapes responses in perceptually-oriented cortex, and that retinotopic coding is part of the DN’s “native language”. Taken together with prior results<sup><xref ref-type="bibr" rid="R31">31</xref>–<xref ref-type="bibr" rid="R34">34</xref></sup>, our findings prompt a reevaluation of the role of the DN in perceptual processing, and the extent to which roles in “internally- and externally-oriented attention” adequately captures the DN and dATN’s role in cognition.</p><p id="P34">These findings and others<sup><xref ref-type="bibr" rid="R31">31</xref>–<xref ref-type="bibr" rid="R34">34</xref></sup> raise a fundamental question: is the DN a “visual” network? One possible interpretation of retinotopic coding in the DN is that the DN directly and obligatorily represents retinal position, like low-level visual areas, and that the DN is engaged in processing visual features in addition to more abstract features<sup><xref ref-type="bibr" rid="R39">39</xref>,<xref ref-type="bibr" rid="R78">78</xref></sup>. Under this hypothesis, the retinotopic code indicates that the information represented in the DN is, in part, sensory. Alternatively, the apparent visual coding may simply represent an underlying connectivity structure<sup><xref ref-type="bibr" rid="R79">79</xref></sup>, which enables associative <sup><xref ref-type="bibr" rid="R80">80</xref></sup> and semantic <sup><xref ref-type="bibr" rid="R30">30</xref>,<xref ref-type="bibr" rid="R81">81</xref></sup> information that the DN directly represents to be effectively transferred to sensory areas of the brain. Under this alternative hypothesis, the information represented in the DN is not itself sensory in nature; the retinotopic code in the DN simply serves as a “highway” between the abstract representations in the DN and sensory representations in the dATN. Notably, in either case the retinotopic scaffolding represents a latent structure linking high-level and low-level areas through consistent, spatially-organized interactions<sup><xref ref-type="bibr" rid="R79">79</xref></sup>. This provides more evidence that low-level sensory codes are distributed across the brain, joining recent work showing latent somatotopic codes in regions of the brain that are not typically associated with somatosensation, including visual cortex <sup><xref ref-type="bibr" rid="R82">82</xref></sup>. The wide and overlapping distribution of sensory codes across the brain may allow multiplexing of complex information to structure cross-network interactions<sup><xref ref-type="bibr" rid="R37">37</xref>,<xref ref-type="bibr" rid="R82">82</xref></sup>. Further studies investigating this framework with diverse tasks and stimuli could reshape our understanding of how the brain processes and integrates information across different levels of cognitive complexity.</p><p id="P35">Finally, our findings paint a clear picture of cortical dynamics spanning levels of analysis, from macro-scale brain networks, to meso-scale domain-specific subareas, to small-scale voxel-level interactions. Prior work has emphasized the importance of each of these organizational scales independently<sup><xref ref-type="bibr" rid="R1">1</xref>,<xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R16">16</xref>,<xref ref-type="bibr" rid="R31">31</xref>,<xref ref-type="bibr" rid="R32">32</xref>,<xref ref-type="bibr" rid="R34">34</xref>,<xref ref-type="bibr" rid="R39">39</xref>,<xref ref-type="bibr" rid="R44">44</xref>,<xref ref-type="bibr" rid="R48">48</xref>,<xref ref-type="bibr" rid="R51">51</xref>,<xref ref-type="bibr" rid="R83">83</xref>,<xref ref-type="bibr" rid="R84">84</xref></sup>. Here, our results suggest a comprehensive framework for understanding the brain’s functional organization that spans these levels of description. At the smallest scale, we demonstrate that retinotopic coding underpins voxel-scale interactions that are observable across the brain. At the meso-scale, these retinotopic interactions are constrained by specific brain areas’ functional domains (e.g., processing visual scenes). At a macro-scale, interplay among these domain-specific regions underpins the organization of large-scale brain networks, whose interactions give rise to specific complex behavior, like memory recall or visual attention. This nested hierarchy of neural interactions may account for the efficiency of parallel information processing in the brain and our ability to flexibly to adapt to ongoing task demands.</p><p id="P36">In summary, our results show that a retinotopic code organizes the spontaneous interactions of large-scale internally- and externally-oriented networks in the human brain. These findings challenge our classic understanding of internally-oriented networks like the DN, showing that the independence of the DN and dATN does not reflect disengagement from visual processing. Rather, their dynamic is structured by a voxel-wise retinotopic code that scaffolds interactions across these large-scale internally- and externally-oriented networks. Taken together, these results indicate that retinotopic coding, the human brain’s foundational visuo-spatial reference frame<sup><xref ref-type="bibr" rid="R37">37</xref>,<xref ref-type="bibr" rid="R79">79</xref></sup>, structures large-scale neural dynamics and may be a “common currency” or subspace for information exchange across the brain’s functional networks.</p></sec><sec id="S6" sec-type="methods"><title>Methods</title><p id="P37">The data analyzed here are part of the Natural Scenes Dataset (NSD), a large 7T dataset of precision MRI data from 8 participants, including retinotopic mapping, anatomical segmentations, functional localizers for visual areas, and task and resting-state fMRI. A full description of the dataset can be found in the original manuscript <sup><xref ref-type="bibr" rid="R38">38</xref></sup>. Here we detail the data processing and analysis steps relevant to the present work.</p><sec id="S7" sec-type="subjects"><title>Subjects</title><p id="P38">The NSD comprises data from 8 participants collected at the University of Minnesota (two male, six female, ages 19-32). One subject (subj03) was excluded from resting-state analyses for having insufficient resting-state runs that passed our quality metrics. All participants had normal or correct to normal vision and no known neurological impairments. Informed consent was collected from all participants, and the study was approved by the University of Minnesota institutional review board.</p></sec><sec id="S8"><title>MRI acquisition and processing</title><p id="P39">For this study we made use of the following data from the NSD: anatomical (T1 and FreeSurfer segmentation/reconstruction<sup><xref ref-type="bibr" rid="R85">85</xref>,<xref ref-type="bibr" rid="R86">86</xref></sup>), functional regions of interest ROIs, and minimally preprocessed retinotopy and resting-state time series. All analyses were conducted in original subject volume space, and data were projected on the surface for visualization purposes only.</p><sec id="S9"><title>Anatomical data</title><p id="P40">Anatomical data was collected using a 3T Siemens Prisma scanner and a 32-channel head coil. We used the anatomical data provided at 0.8mm resolution as well as the registered output from FreeSurfer recon-all, aligned to the 1.8mm functional data. For visualization purposes, we projected statistical and retinotopy data to the cortical surface using SUMA <sup><xref ref-type="bibr" rid="R87">87</xref></sup> from the afni software package<sup><xref ref-type="bibr" rid="R88">88</xref></sup>.</p></sec><sec id="S10"><title>Defining functional regions of interest (PPA, OPA, OFA, FFA)</title><p id="P41">We used the volumetric functional regions of interest provided with the NSD at 1.8mm resolution. Specifically, we used the parahippocampal place area (PPA), occipital place area (OPA), iog-faces (referred to here as occipital face area (OFA)), and pfus-faces (fusiform face area, FFA1) regions of interest. In brief, these regions were defined in the NSD using within-subject data collected from 6 runs of a multi-category visual localizer paradigm <sup><xref ref-type="bibr" rid="R38">38</xref></sup>.</p></sec><sec id="S11"><title>Defining functional region LPMA</title><p id="P42">Because the NSD did not include mnemonic localizers <sup><xref ref-type="bibr" rid="R35">35</xref></sup>, we used the resting-state data to define the lateral place memory area (LPMA). Briefly, the LPMA is a region anterior to OPA and near caudal inferior parietal lobule<sup><xref ref-type="bibr" rid="R53">53</xref>,<xref ref-type="bibr" rid="R54">54</xref></sup> that selectively responds during recall of personally familiar places compared to other stimulus types. We have previous shown that OPA and LPMA are functionally-linked and work jointly to process knowledge of visuospatial context out of view during scene perception.</p><p id="P43">Prior work has suggested that a mnemonic area linked to scenes on the lateral surface can be localized by comparing resting-state co-fluctuations of anterior versus posterior PPA (aPPA and pPPA, respectively)<sup><xref ref-type="bibr" rid="R19">19</xref>,<xref ref-type="bibr" rid="R53">53</xref>,<xref ref-type="bibr" rid="R54">54</xref></sup>, and we adopted that approach here. We preprocessed the resting-state fixation fMRI data, runs 1 and 14 from NSD sessions 22 and 23, in all participants (prior to data exclusion) and extracted the average time series of aPPA, pPPA, aFFA, and pFFA. We used these time series as regressors in a general linear model, and we compared the beta-values from the aPPA and pPPA. We considered any voxels with a t-statistic &gt; 5 within posterior parietal-occipital cortex on the lateral surface as an LPMA ROI (Individual ROIs can be found in <xref ref-type="supplementary-material" rid="SD1">Supplemental Fig.4</xref>). Across subjects, there was considerable overlap between this connectivity-defined area and a group-level LPMA defined based on our prior work (<xref ref-type="fig" rid="F2">Fig. 2</xref>).</p></sec></sec><sec id="S12"><title>Functional MRI data acquisition and processing</title><p id="P44">All analyses were conducted on 1.8mm isotropic resolution minimally processed runs of a sweeping-bar retinotopy task and resting-state fixation provided in the NSD.</p><sec id="S13"><title>Quality assessment</title><p id="P45">To ensure only high-quality resting-state data were included, we trimmed the first 25 TRs (40s) from each run <sup><xref ref-type="bibr" rid="R76">76</xref></sup>, which left 4.25 min of resting-state data per run. We then used afni’s quality control assessment tool (APQC<sup><xref ref-type="bibr" rid="R89">89</xref></sup>) on the raw trimmed resting-state time series to assess degree of motion in the resting-state scans. We excluded runs with greater than 1.8mm maximum displacement per run or 0.12mm framewise displacement from analysis and assessed runs with greater than 1mm displacement or 0.10mm framewise displacement on a case-by-case basis<sup><xref ref-type="bibr" rid="R8">8</xref></sup>. After exclusions, one participant (subj03) had only a single run that survived our criteria (4.25 minutes of data)), so we excluded them from resting-state analyses. The remaining 7 participants had at least 8 resting-state runs (&gt; 34 minutes of data; mean number of runs: 14±6.13 (sd), range: 8-24 runs).</p></sec><sec id="S14"><title>ICA denoising</title><p id="P46">To further denoise the retinotopy and remaining resting-state data, we used manual ICA classification of signal and noise on the minimally-preprocessed time series<sup><xref ref-type="bibr" rid="R35">35</xref>,<xref ref-type="bibr" rid="R41">41</xref>,<xref ref-type="bibr" rid="R42">42</xref></sup>. We used manual classification because automated tools perform poorly on the high spatial and temporal resolution data of the NSD<sup><xref ref-type="bibr" rid="R90">90</xref></sup>. For each retinotopy and resting state run, we decomposed the data into independent spatial components and their associated temporal signals using ICA (FSL’s melodic<sup><xref ref-type="bibr" rid="R91">91</xref>,<xref ref-type="bibr" rid="R92">92</xref></sup>). We then manually classified each component as signal or noise using the criteria established in<sup><xref ref-type="bibr" rid="R42">42</xref></sup>. Noise signals were projected out of the data using fsl_regfilt<sup><xref ref-type="bibr" rid="R41">41</xref></sup>.</p><p id="P47">We did not perform global signal regression<sup><xref ref-type="bibr" rid="R26">26</xref></sup>. Data were normalized to percent signal change. A 2.5mm FWHM smooth was applied to resting-state fixation data used in functional connectivity network identification. The analysis of voxel-scale interactions performed on unsmoothed data.</p></sec></sec><sec id="S15"><title>Data analysis - retinotopy</title><sec id="S16"><title>pRF Modelling</title><p id="P48">The NSD retinotopy stimuli features a mosaic of faces, houses, and objects superimposed on pink noise that are revealed through a continuously drifting aperture. For our analysis, we considered only the bar stimulus time series, which is consistent with other studies investigating -pRFs in high-level cortical areas <sup><xref ref-type="bibr" rid="R31">31</xref>,<xref ref-type="bibr" rid="R33">33</xref>,<xref ref-type="bibr" rid="R34">34</xref></sup>. We did not consider the wedge/ring stimulus for any analyses.</p><p id="P49">After denoising the retinotopy data, we averaged the three retinotopy runs with the bar aperture together to form the final retinotopy time series. We performed population receptive field modeling using afni following the procedure described in <sup><xref ref-type="bibr" rid="R45">45</xref></sup>. First, because the pRF stimulus in the NSD is continuous, we resampled the stimulus time series to the fMRI temporal resolution (TR = 1.333s). Next, we implemented afni’s pRF mapping procedure (3dNLfim). Given the position of the stimulus in the visual field at every time point, the model estimates the pRF parameters that yield the best fit to the data: pRF amplitude (positive, negative), pRF center location (x, y) and size (diameter of the pRF). Both Simplex and Powell optimization algorithms are used simultaneously to find the best time series/parameter sets (amplitude, x, y, size) by minimizing the least-squares error of the predicted time series with the acquired time series for each voxel. Relevant to the present work, the amplitude measure refers to the signed (positive or negative) degree of linear scaling applied to the pRF model, which reflects the sign of the neural response to visual stimulation of its receptive field.</p></sec></sec><sec id="S17"><title>Visual field coverage</title><p id="P50">Visual-field coverage (VFC) plots represent the sensitivity of an ROI across the visual field. We followed the procedure in Steel et al., 2024 to compute these<sup><xref ref-type="bibr" rid="R34">34</xref></sup>, which we have reproduced here. Individual participant VFC plots were first derived. These plots combine the best Gaussian receptive field model for each suprathreshold voxel within each ROI. Here, a max operator is used, which stores, at each point in the visual field, the maximum value from all pRFs within the ROI. The resulting coverage plot thus represents the maximum envelope of sensitivity across the visual field. Individual participant VFC plots were averaged across participants to create group-level coverage plots.</p><p id="P51">To compute the elevation biases, we calculated the mean pRF value (defined as the mean value in a specific portion of the visual-field coverage plot) in the contralateral upper visual field (UVF) and contralateral lower visual field (LVF) and computed the difference (UVF–LVF) for each participant, ROI and amplitude (+/−) separately. A positive value thus represents an upper visual-field bias, whereas a negative value represents a lower visual-field bias. Analysis of the visual-field biases considers pRF center, as well as pRF size and R<sup><xref ref-type="bibr" rid="R2">2</xref></sup>.</p></sec><sec id="S18"><title>Reliability of pRF amplitude estimate</title><p id="P52">To assess the reliability of pRF amplitude (i.e., positive versus negative), we iteratively compared the amplitude of significant pRFs from individual runs of pRF data. Specifically, for each single run of pRF data, we fit our pRF model. We then binarized vertices according to significance and amplitude – voxels that surpassed our significance threshold (R2 &gt; 0.08) in the full model were assigned a value of 0 or 1. When investigating +pRF reliability in OPA, significant vertices with a positive amplitude were assigned to 1, all other vertices 0. For -pRF reliability in LPMA, the opposite was done: significant negative amplitude vertices were assigned a value of 1, and all other vertices set to 0.</p><p id="P53">For each participant, after binarization, we calculated a dice-like coefficient within each ROI which considered all three retinotopy runs <inline-formula><mml:math id="M1"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>3</mml:mn><mml:mo>|</mml:mo><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mn>1</mml:mn><mml:mstyle displaystyle="true"><mml:mo>∩</mml:mo></mml:mstyle><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mn>2</mml:mn><mml:mstyle displaystyle="true"><mml:mo>∩</mml:mo></mml:mstyle><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mn>3</mml:mn><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mo>∣</mml:mo><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:mo>+</mml:mo><mml:mo>|</mml:mo><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mn>2</mml:mn><mml:mo>|</mml:mo><mml:mo>+</mml:mo><mml:mo>|</mml:mo><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mn>3</mml:mn><mml:mo>∣</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. We compared this value versus 5000 iterations of the same number of voxels randomly sampled from all voxels, both significant and non-significant, in the ROI. For each participant, this resulted in 1 “observed” dice coefficients, along with 5000 bootstrapped values representing the distribution of dice coefficients expected by chance which we used to evaluate the significance of each pRF amplitude’s run-to-run consistency.</p><sec id="S19"><title>Voxel-wise pRF matching</title><p id="P54">We matched -pRFs in source (i.e., the DN) with target (i.e., +pRFs in the dATN) using the following procedure. Within each participant, we computed the pairwise Euclidean distance between the center (x,y) of each source pRF with each target pRF. For each source pRF, we considered the top 10 closest target pRFs the “matched pRFs” and the 10 furthest target pRFs the “antimatched pRFs.” So, each pRF within a memory area yielded 10 matched and 10 antimatched pRFs.</p><p id="P55">To investigate the opponent interaction between areas for top-down interactions (below), we conducted this procedure using -LPMA pRFs as the source and +OPA pRFs as targets. To investigate bottom-up interactions, we considered +OPA pRFs as the source and -LPMA pRFs as targets. To investigate the importance of functional domain in retinotopic interactions, we considered -LPMA pRFs as the source and 1) +OFA and 2) +FFA pRFs as targets.</p></sec></sec><sec id="S20"><title>Resting-state analyses</title><sec id="S21"><title>Individual-specific cerebral network estimation</title><p id="P56">In each participant, we identified a set of 15 distributed networks on the cerebral cortical surface using a multi-session hierarchical Bayesian model (MS-HBM) functional connectivity approach <sup><xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R40">40</xref></sup>. Briefly, the MS-HBM approach calculates a connectivity profile for every vertex on the cortical surface derived from that vertex’s correlation to all other vertices during each run of resting-state fixation. The MS-HBM then uses the resulting run- and participant-level profiles, along with a 15 network group-level prior created from a portion of the HCP S900 data<sup><xref ref-type="bibr" rid="R44">44</xref></sup>, to create a unique 15-network parcellation for each individual.</p><p id="P57">The MS-HBM has two primary advantages compared to other approaches used to parcellate functional connectivity data, such as k-mean clustering. First, it accounts for differences in connectivity both within an individual (likely the result of confounding variables such as scanner variability, time of day, etc.), and between participants (reflecting potentially meaningful individual differences), allowing for more reliable estimates. Second, by incorporating a group prior which includes all the networks of interest, we ensure that all networks will be identified in all participants, while allowing for idiosyncratic topographic differences.</p></sec><sec id="S22"><title>Correlation among cortical networks</title><p id="P58">We calculated the unique correlation between the combined DNs and dATNs using partial correlation to account for variation associated with other cortical networks <sup><xref ref-type="bibr" rid="R43">43</xref></sup>. We averaged the time series from separate subnetworks of the DN and dATN prior to calculating the partial correlation. Then, to determine whether activity the different populations of visually responsive voxels (-pRFs, +pRFs, sub threshold (i.e., non-retinotopic) within the DNs was differentially correlated with the dATNs, we re-calculated the partial correlation between the average time series of these populations of DN voxels with the dATNs while accounting for the activity of all other cortical networks.</p></sec><sec id="S23"><title>Opponent interaction at rest</title><p id="P59">To assess the influence of retinotopy on the correlation of areas at rest, we used the following procedure. First, we established matched source (i.e., -DN or -LPMA) and target (i.e., +dATN or +OPA) pRF pairs using the procedure described above. For this analysis, our primary focus was on the -pRFs in the DN or LPMA and their relationship with perceptual areas (dATN, OPA, OFA, FFA). Among these highly connected areas, large-scale fluctuations due to attention and motion will cause these voxels to be highly correlated. To control for this, consistent with prior work, we extracted the average time series of all +pRFs in the DN or LPMA and partialed out the variance associated with these pRFs from the -pRFs in the DN or LPMA and +pRFs in the perceptual areas of interest from each resting-state run <sup><xref ref-type="bibr" rid="R34">34</xref>,<xref ref-type="bibr" rid="R43">43</xref></sup>. This provided an ROI-level analog to the whole-brain partial correlation described above (Section: Correlation among cortical networks), allowing us to isolate the unique contribution of the pRFs of interest from overall activity in the region as well as to control for global fluctuations that cause widespread positive correlations like motion and attentional state<sup><xref ref-type="bibr" rid="R34">34</xref>,<xref ref-type="bibr" rid="R43">43</xref></sup>.</p><p id="P60">To examine the opponent interaction for matched pRFs, we considered each resting state run separately. In each resting state run, we first calculated the average time series of all -pRFs in LPMA. We then calculated the average time series for the top 10 best matched +pRFs in OPA of all voxels. For example, if a participant had 211 -pRFs in LPMA, these voxels were averaged together to get a single -LPMA pRF time series, and the top 10 matched +pRFs in OPA (i.e., 2110 time series) would be averaged together to constitute the +OPA time series. Note that the matched +OPA pRFs were not unique for each voxel. We then correlated these time series (-LPMA and +OPA pRFs). A negative correlation was considered an opponent interaction.</p><p id="P61">To compare the importance of retinotopy in structuring the interaction between LPMA and OPA, we performed the same averaging and correlation procedure described above with the 10 worst matched pRFs (antimatched). For each participant, all Fisher-transformed correlation values (z) for matched versus antimatched pRFs were averaged together and we compared these matched and antimatched correlation values using a paired t-test. To examine the specificity within each functional network, we repeated this procedure for -LPMA matched/antimatched with OFA and FFA-1.</p><p id="P62">To confirm that retinotopic coding structured the opponent interaction, we repeated this anaylsis with two key differences: 1), to ensure that the choosing the bottom 10 voxels did not drive our results, we randomly sampled 10 pRFs from the furthest 33% of pRFs from each participant, and 2) to ensure that ROI-level effect was present at the individual pRF level, we performed the analysis without averaging the pRF’s resting-state time series within each ROI. For each resting state run, we extracted each -pRF time series and correlated this time series with the time series from the average of its top 10 best matched +pRF in OPA. We performed this matching and random sampling procedure 1000 times for each pRF in the source area. For example, if a participant had 211 -pRFs in LPMA, we would correlated each of these pRFs with the average time series from the their top 10 best matched +pRFs in OPA, resulting in 211 individual r-values for each resting-state run, and compared each of these 211 values with the correlation of 1000 randomly paired pRFs for that source pRF. We then Fisher-transformed these matched and randomly sampled values and averaged them to constitute a single value for each run. We repeated this procedure for all runs in all participants. The mean Fisher-transformed values were compared using a paired t-test. These results are described in the supplemental methods and results.</p></sec></sec><sec id="S24"><title>Resting-state event detection</title><p id="P63">We reasoned that the influence of top-down versus bottom-up drive on the spontaneous interaction between regions could be isolated by examining periods of unusually high activity in voxels in these respective areas (“events”)<sup><xref ref-type="bibr" rid="R93">93</xref>,<xref ref-type="bibr" rid="R94">94</xref></sup>. Specifically, we tested the hypothesis that top-down events in -LPMA pRFs would co-occur with periods of lower activity in +OPA pRFs, and that the suppressive influence of top-down events would be stronger compared with bottom-up events. To test these hypotheses, we isolated neural events in each source region’s (-LPMA (top-down) and +OPA (bottom-up)) pRF time series and examined the activity in the corresponding target region at these event times.</p><p id="P64">Event detection was performed for each +/- pRF independently. To detect events, we z-scored all pRF’s resting-state time series and identified TRs with unusually high activity in source region pRFs. Specifically, we considered each time point with a z-value greater than 2.4 (i.e., 99.18 percentile) as a neural event. Results were comparable with varying thresholds between 2.1 &lt; z &lt; 2.9. At each event, we extracted the 6 TRs before and after the event time (i.e., 13 TRs) surrounding the average time from that pRF’s top-10 matched pRFs in the target region. To make time series comparable across events, we normalized the event time series to the mean of the first 4 TRs. We repeated this procedure for all -LPMA/+OPA pRFs for top-down and bottom-up events.</p><p id="P65">For top-down and bottom-up events, we compared the activity of the target region (top-down: +OPA pRFs; bottom up: -LPMA pRFs) at event time using paired t-tests. We only considered matched pRFs for this analysis.</p></sec><sec id="S25"><title>Statistical tests</title><p id="P66">Statistical analyses were implemented in Matlab (Mathworks, Inc). Given the small number of subjects in this dataset, we used two statistical analysis methods to ensure robustness of any detected effects. First, borrowing analytical methods from neuroscientific studies using animal models, we leveraged the large within participant data by pooling observations (e.g., resting-state runs or pRFs) from each participant. We then tested for differences in distributions using two-sample Kolmogorov-Smirnov goodness-of-fit hypothesis tests. Second, we adopted more classic statistical methods to test for effects within participants. We used paired-sample t-tests and corrected for multiple comparisons where appropriate.</p></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary Materials</label><media xlink:href="EMS199031-supplement-Supplementary_Materials.pdf" mimetype="application" mime-subtype="pdf" id="d23aAcLbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S26"><title>Acknowledgements</title><p>The authors would like to thank the authors of the Natural Scenes Dataset for making these data publicly available. This work was supported by an award from the National Institutes of Mental Health (R01MH130529) to CER. AS was supported by the Neukom Institute for Computational Sciences. EHS was supported by the Biotechnology and Biological Sciences Research Council (BB/V003917/1).</p></ack><sec id="S27" sec-type="data-availability"><title>Data availability</title><p id="P67">All data is made publicly available via the Natural Scenes Dataset (<ext-link ext-link-type="uri" xlink:href="https://naturalscenesdataset.org/">https://naturalscenesdataset.org/</ext-link>)</p></sec><sec id="S28" sec-type="data-availability"><title>Code availability</title><p id="P68">This data does not use any original code. Any additional information required to reanalyze the data reported in this paper is available from the lead contact upon request.</p></sec><fn-group><fn fn-type="conflict" id="FN3"><p id="P69">Competing interests: The authors declare no competing interests.</p></fn></fn-group><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thomas Yeo</surname><given-names>BT</given-names></name><name><surname>Krienen</surname><given-names>FM</given-names></name><name><surname>Sepulcre</surname><given-names>J</given-names></name><name><surname>Sabuncu</surname><given-names>MR</given-names></name><name><surname>Lashkari</surname><given-names>D</given-names></name><name><surname>Hollinshead</surname><given-names>M</given-names></name><name><surname>Roffman</surname><given-names>JL</given-names></name><name><surname>Smoller</surname><given-names>JW</given-names></name><name><surname>Zöllei</surname><given-names>L</given-names></name><name><surname>Polimeni</surname><given-names>JR</given-names></name><etal/></person-group><article-title>The organization of the human cerebral cortex estimated by intrinsic functional connectivity</article-title><source>J Neurophysiol</source><year>2011</year><volume>106</volume><fpage>1125</fpage><lpage>1165</lpage><pub-id pub-id-type="pmcid">PMC3174820</pub-id><pub-id pub-id-type="pmid">21653723</pub-id><pub-id pub-id-type="doi">10.1152/jn.00338.2011</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Ghosh</surname><given-names>SS</given-names></name><name><surname>Goulas</surname><given-names>A</given-names></name><name><surname>Falkiewicz</surname><given-names>M</given-names></name><name><surname>Huntenburg</surname><given-names>JM</given-names></name><name><surname>Langs</surname><given-names>G</given-names></name><name><surname>Bezgin</surname><given-names>G</given-names></name><name><surname>Eickhoff</surname><given-names>SB</given-names></name><name><surname>Castellanos</surname><given-names>FX</given-names></name><name><surname>Petrides</surname><given-names>M</given-names></name><etal/></person-group><article-title>Situating the default-mode network along a principal gradient of macroscale cortical organization</article-title><source>Proc Natl Acad Sci U S A</source><year>2016</year><volume>113</volume><fpage>12574</fpage><lpage>12579</lpage><pub-id pub-id-type="pmcid">PMC5098630</pub-id><pub-id pub-id-type="pmid">27791099</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1608282113</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Braga</surname><given-names>RM</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name></person-group><article-title>Parallel Interdigitated Distributed Networks within the Individual Estimated by Intrinsic Functional Connectivity</article-title><source>Neuron</source><year>2017</year><volume>95</volume><fpage>457</fpage><lpage>471</lpage><elocation-id>e5</elocation-id><pub-id pub-id-type="pmcid">PMC5519493</pub-id><pub-id pub-id-type="pmid">28728026</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.038</pub-id></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gordon</surname><given-names>EM</given-names></name><name><surname>Laumann</surname><given-names>TO</given-names></name><name><surname>Gilmore</surname><given-names>AW</given-names></name><name><surname>Newbold</surname><given-names>DJ</given-names></name><name><surname>Greene</surname><given-names>DJ</given-names></name><name><surname>Berg</surname><given-names>JJ</given-names></name><name><surname>Ortega</surname><given-names>M</given-names></name><name><surname>Hoyt-Drazen</surname><given-names>C</given-names></name><name><surname>Gratton</surname><given-names>C</given-names></name><name><surname>Sun</surname><given-names>H</given-names></name><etal/></person-group><article-title>Precision Functional Mapping of Individual Human Brains</article-title><source>Neuron</source><year>2017</year><volume>95</volume><fpage>791</fpage><lpage>807</lpage><elocation-id>e7</elocation-id><pub-id pub-id-type="pmcid">PMC5576360</pub-id><pub-id pub-id-type="pmid">28757305</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2017.07.011</pub-id></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ranganath</surname><given-names>C</given-names></name><name><surname>Ritchey</surname><given-names>M</given-names></name></person-group><article-title>Two cortical systems for memory-guided behaviour</article-title><publisher-name>Nature Publishing Group</publisher-name><year>2012</year><comment>Preprint at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nrn3338">https://doi.org/10.1038/nrn3338</ext-link></comment><pub-id pub-id-type="pmid">22992647</pub-id></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andrews-Hanna</surname><given-names>JR</given-names></name><name><surname>Reidler</surname><given-names>JS</given-names></name><name><surname>Sepulcre</surname><given-names>J</given-names></name><name><surname>Poulin</surname><given-names>R</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name></person-group><article-title>Functional-Anatomic Fractionation of the Brain’s Default Network</article-title><source>Neuron</source><year>2010</year><volume>65</volume><fpage>550</fpage><lpage>562</lpage><pub-id pub-id-type="pmcid">PMC2848443</pub-id><pub-id pub-id-type="pmid">20188659</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2010.02.005</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barnett</surname><given-names>AJ</given-names></name><name><surname>Reilly</surname><given-names>W</given-names></name><name><surname>Dimsdale-Zucker</surname><given-names>HR</given-names></name><name><surname>Mizrak</surname><given-names>E</given-names></name><name><surname>Reagh</surname><given-names>Z</given-names></name><name><surname>Ranganath</surname><given-names>C</given-names></name></person-group><article-title>Intrinsic connectivity reveals functionally distinct cortico-hippocampal networks in the human brain</article-title><source>PLoS Biol</source><year>2021</year><volume>19</volume><elocation-id>e3001275</elocation-id><pub-id pub-id-type="pmcid">PMC8202937</pub-id><pub-id pub-id-type="pmid">34077415</pub-id><pub-id pub-id-type="doi">10.1371/journal.pbio.3001275</pub-id></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Du</surname><given-names>J</given-names></name><name><surname>DiNicola</surname><given-names>LM</given-names></name><name><surname>Angeli</surname><given-names>PA</given-names></name><name><surname>Saadon-Grosman</surname><given-names>N</given-names></name><name><surname>Sun</surname><given-names>W</given-names></name><name><surname>Kaiser</surname><given-names>S</given-names></name><name><surname>Ladopoulou</surname><given-names>J</given-names></name><name><surname>Xue</surname><given-names>A</given-names></name><name><surname>Yeo</surname><given-names>BTT</given-names></name><name><surname>Eldaief</surname><given-names>MC</given-names></name><etal/></person-group><article-title>Organization of the human cerebral cortex estimated within individuals: networks, global topography, and function</article-title><source>J Neurophysiol</source><year>2024</year><volume>131</volume><fpage>1014</fpage><lpage>1082</lpage><pub-id pub-id-type="pmcid">PMC11383390</pub-id><pub-id pub-id-type="pmid">38489238</pub-id><pub-id pub-id-type="doi">10.1152/jn.00308.2023</pub-id></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laumann</surname><given-names>TO</given-names></name><name><surname>Gordon</surname><given-names>EM</given-names></name><name><surname>Adeyemo</surname><given-names>B</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Joo</surname><given-names>SJ</given-names></name><name><surname>Chen</surname><given-names>MY</given-names></name><name><surname>Gilmore</surname><given-names>AW</given-names></name><name><surname>McDermott</surname><given-names>KB</given-names></name><name><surname>Nelson</surname><given-names>SM</given-names></name><name><surname>Dosenbach</surname><given-names>NUF</given-names></name><etal/></person-group><article-title>Functional System and Areal Organization of a Highly Sampled Individual Human Brain</article-title><source>Neuron</source><year>2015</year><volume>87</volume><fpage>657</fpage><lpage>670</lpage><pub-id pub-id-type="pmcid">PMC4642864</pub-id><pub-id pub-id-type="pmid">26212711</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2015.06.037</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chun</surname><given-names>MM</given-names></name><name><surname>Golomb</surname><given-names>JD</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name></person-group><article-title>A Taxonomy of External and Internal Attention</article-title><source>Annu Rev Psychol</source><year>2011</year><volume>62</volume><fpage>73</fpage><lpage>101</lpage><pub-id pub-id-type="pmid">19575619</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dixon</surname><given-names>ML</given-names></name><name><surname>Andrews-Hanna</surname><given-names>JR</given-names></name><name><surname>Spreng</surname><given-names>RN</given-names></name><name><surname>Irving</surname><given-names>ZC</given-names></name><name><surname>Mills</surname><given-names>C</given-names></name><name><surname>Girn</surname><given-names>M</given-names></name><name><surname>Christoff</surname><given-names>K</given-names></name></person-group><article-title>Interactions between the default network and dorsal attention network vary across default subsystems, time, and cognitive states</article-title><source>Neuroimage</source><year>2017</year><volume>147</volume><fpage>632</fpage><lpage>649</lpage><pub-id pub-id-type="pmid">28040543</pub-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fox</surname><given-names>MD</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Vincent</surname><given-names>JL</given-names></name><name><surname>Corbetta</surname><given-names>M</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Raichle</surname><given-names>ME</given-names></name></person-group><article-title>The human brain is intrinsically organized into dynamic, anticorrelated functional networks</article-title><source>Proc Natl Acad Sci U S A</source><year>2005</year><volume>102</volume><fpage>9673</fpage><lpage>9678</lpage><pub-id pub-id-type="pmcid">PMC1157105</pub-id><pub-id pub-id-type="pmid">15976020</pub-id><pub-id pub-id-type="doi">10.1073/pnas.0504136102</pub-id></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raichle</surname><given-names>ME</given-names></name></person-group><article-title>The Brain’s Default Mode Network</article-title><source>Annu Rev Neurosci</source><year>2015</year><volume>38</volume><fpage>433</fpage><lpage>447</lpage><pub-id pub-id-type="pmid">25938726</pub-id></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fox</surname><given-names>MD</given-names></name><name><surname>Corbetta</surname><given-names>M</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Vincent</surname><given-names>JL</given-names></name><name><surname>Raichle</surname><given-names>ME</given-names></name></person-group><article-title>Spontaneous neuronal activity distinguishes human dorsal and ventral attention systems</article-title><source>Proceedings of the National Academy of Sciences</source><year>2006</year><volume>103</volume><fpage>10046</fpage><lpage>10051</lpage><pub-id pub-id-type="pmcid">PMC1480402</pub-id><pub-id pub-id-type="pmid">16788060</pub-id><pub-id pub-id-type="doi">10.1073/pnas.0604187103</pub-id></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raichle</surname><given-names>ME</given-names></name><name><surname>MacLeod</surname><given-names>AM</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Powers</surname><given-names>WJ</given-names></name><name><surname>Gusnard</surname><given-names>DA</given-names></name><name><surname>Shulman</surname><given-names>GL</given-names></name></person-group><article-title>A default mode of brain function</article-title><source>Proceedings of the National Academy of Sciences</source><year>2001</year><volume>98</volume><fpage>676</fpage><lpage>682</lpage><pub-id pub-id-type="pmcid">PMC14647</pub-id><pub-id pub-id-type="pmid">11209064</pub-id><pub-id pub-id-type="doi">10.1073/pnas.98.2.676</pub-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fedorenko</surname><given-names>E</given-names></name><name><surname>Duncan</surname><given-names>J</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name></person-group><article-title>Broad domain generality in focal regions of frontal and parietal cortex</article-title><source>Proceedings of the National Academy of Sciences</source><year>2013</year><volume>110</volume><fpage>16616</fpage><lpage>16621</lpage><pub-id pub-id-type="pmcid">PMC3799302</pub-id><pub-id pub-id-type="pmid">24062451</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1315235110</pub-id></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vossel</surname><given-names>S</given-names></name><name><surname>Geng</surname><given-names>JJ</given-names></name><name><surname>Fink</surname><given-names>GR</given-names></name></person-group><article-title>Dorsal and Ventral Attention Systems: Distinct Neural Circuits but Collaborative Roles</article-title><source>The Neuroscientist</source><year>2013</year><volume>20</volume><fpage>150</fpage><lpage>159</lpage><pub-id pub-id-type="pmcid">PMC4107817</pub-id><pub-id pub-id-type="pmid">23835449</pub-id><pub-id pub-id-type="doi">10.1177/1073858413494269</pub-id></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shulman</surname><given-names>GL</given-names></name><name><surname>Fiez</surname><given-names>JA</given-names></name><name><surname>Corbetta</surname><given-names>M</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name><name><surname>Miezin</surname><given-names>FM</given-names></name><name><surname>Raichle</surname><given-names>ME</given-names></name><name><surname>Petersen</surname><given-names>SE</given-names></name></person-group><article-title>Common Blood Flow Changes across Visual Tasks: II. Decreases in Cerebral Cortex</article-title><source>J Cogn Neurosci</source><year>1997</year><volume>9</volume><fpage>648</fpage><lpage>663</lpage><pub-id pub-id-type="pmid">23965122</pub-id></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silson</surname><given-names>EH</given-names></name><name><surname>Steel</surname><given-names>A</given-names></name><name><surname>Kidder</surname><given-names>A</given-names></name><name><surname>Gilmore</surname><given-names>AW</given-names></name><name><surname>Baker</surname><given-names>CI</given-names></name></person-group><article-title>Distinct subdivisions of human medial parietal cortex support recollection of people and places</article-title><source>Elife</source><year>2019</year><volume>8</volume><pub-id pub-id-type="pmcid">PMC6667275</pub-id><pub-id pub-id-type="pmid">31305238</pub-id><pub-id pub-id-type="doi">10.7554/eLife.47391</pub-id></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DiNicola</surname><given-names>LM</given-names></name><name><surname>Braga</surname><given-names>RM</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name></person-group><article-title>Parallel distributed networks dissociate episodic and social functions within the individual</article-title><source>J Neurophysiol</source><year>2020</year><volume>123</volume><fpage>1144</fpage><lpage>1179</lpage><pub-id pub-id-type="pmcid">PMC7099479</pub-id><pub-id pub-id-type="pmid">32049593</pub-id><pub-id pub-id-type="doi">10.1152/jn.00529.2019</pub-id></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thakral</surname><given-names>PP</given-names></name><name><surname>Madore</surname><given-names>KP</given-names></name><name><surname>Schacter</surname><given-names>DL</given-names></name></person-group><article-title>A Role for the Left Angular Gyrus in Episodic Simulation and Memory</article-title><source>J Neurosci</source><year>2017</year><volume>37</volume><fpage>8142</fpage><lpage>8149</lpage><pub-id pub-id-type="pmcid">PMC5566865</pub-id><pub-id pub-id-type="pmid">28733357</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1319-17.2017</pub-id></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilmore</surname><given-names>AW</given-names></name><name><surname>Quach</surname><given-names>A</given-names></name><name><surname>Kalinowski</surname><given-names>SE</given-names></name><name><surname>Gotts</surname><given-names>SJ</given-names></name><name><surname>Schacter</surname><given-names>DL</given-names></name><name><surname>Martin</surname><given-names>A</given-names></name></person-group><article-title>Dynamic Content Reactivation Supports Naturalistic Autobiographical Recall in Humans</article-title><source>Journal of Neuroscience</source><year>2021</year><volume>41</volume><fpage>153</fpage><lpage>166</lpage><pub-id pub-id-type="pmcid">PMC7786205</pub-id><pub-id pub-id-type="pmid">33203742</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1490-20.2020</pub-id></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christoff</surname><given-names>K</given-names></name><name><surname>Gordon</surname><given-names>AM</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Smith</surname><given-names>R</given-names></name><name><surname>Schooler</surname><given-names>JW</given-names></name></person-group><article-title>Experience sampling during fMRI reveals default network and executive system contributions to mind wandering</article-title><source>Proc Natl Acad Sci U S A</source><year>2009</year><volume>106</volume><fpage>8719</fpage><lpage>8724</lpage><pub-id pub-id-type="pmcid">PMC2689035</pub-id><pub-id pub-id-type="pmid">19433790</pub-id><pub-id pub-id-type="doi">10.1073/pnas.0900234106</pub-id></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greicius</surname><given-names>MD</given-names></name><name><surname>Krasnow</surname><given-names>B</given-names></name><name><surname>Reiss</surname><given-names>AL</given-names></name><name><surname>Menon</surname><given-names>V</given-names></name></person-group><article-title>Functional connectivity in the resting brain: A network analysis of the default mode hypothesis</article-title><source>Proceedings of the National Academy of Sciences</source><year>2003</year><volume>100</volume><fpage>253</fpage><lpage>258</lpage><pub-id pub-id-type="pmcid">PMC140943</pub-id><pub-id pub-id-type="pmid">12506194</pub-id><pub-id pub-id-type="doi">10.1073/pnas.0135058100</pub-id></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Menon</surname><given-names>V</given-names></name></person-group><article-title>20 years of the default mode network: A review and synthesis</article-title><source>Neuron</source><year>2023</year><volume>111</volume><fpage>2469</fpage><lpage>2487</lpage><pub-id pub-id-type="pmcid">PMC10524518</pub-id><pub-id pub-id-type="pmid">37167968</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2023.04.023</pub-id></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saad</surname><given-names>ZS</given-names></name><name><surname>Gotts</surname><given-names>SJ</given-names></name><name><surname>Murphy</surname><given-names>K</given-names></name><name><surname>Chen</surname><given-names>G</given-names></name><name><surname>Jo</surname><given-names>HJ</given-names></name><name><surname>Martin</surname><given-names>A</given-names></name><name><surname>Cox</surname><given-names>RW</given-names></name></person-group><article-title>Trouble at Rest: How Correlation Patterns and Group Differences Become Distorted After Global Signal Regression</article-title><source>Brain Connect</source><year>2012</year><volume>2</volume><fpage>25</fpage><lpage>32</lpage><pub-id pub-id-type="pmcid">PMC3484684</pub-id><pub-id pub-id-type="pmid">22432927</pub-id><pub-id pub-id-type="doi">10.1089/brain.2012.0080</pub-id></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>C</given-names></name><name><surname>Wang</surname><given-names>H-T</given-names></name><name><surname>Konu</surname><given-names>D</given-names></name><name><surname>Lowndes</surname><given-names>R</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><article-title>Modes of operation: A topographic neural gradient supporting stimulus dependent and independent cognition</article-title><source>Neuroimage</source><year>2019</year><volume>186</volume><fpage>487</fpage><lpage>496</lpage><pub-id pub-id-type="pmid">30447291</pub-id></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>C</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Rueschemeyer</surname><given-names>SA</given-names></name><name><surname>Sormaz</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>H ting</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><article-title>Distant from input: Evidence of regions within the default mode network supporting perceptually-decoupled and conceptually-guided cognition</article-title><source>Neuroimage</source><year>2018</year><volume>171</volume><fpage>393</fpage><lpage>401</lpage><pub-id pub-id-type="pmcid">PMC5883322</pub-id><pub-id pub-id-type="pmid">29339310</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.01.017</pub-id></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bellmund</surname><given-names>JLS</given-names></name><name><surname>Gärdenfors</surname><given-names>P</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name></person-group><article-title>Navigating cognition: Spatial codes for human thinking</article-title><source>Science (1979)</source><year>2018</year><volume>362</volume><elocation-id>eaat6766</elocation-id><pub-id pub-id-type="pmid">30409861</pub-id></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Popham</surname><given-names>SF</given-names></name><name><surname>Huth</surname><given-names>AG</given-names></name><name><surname>Bilenko</surname><given-names>NY</given-names></name><name><surname>Deniz</surname><given-names>F</given-names></name><name><surname>Gao</surname><given-names>JS</given-names></name><name><surname>Nunez-Elizalde</surname><given-names>AO</given-names></name><name><surname>Gallant</surname><given-names>JL</given-names></name></person-group><article-title>Visual and linguistic semantic representations are aligned at the border of human visual cortex</article-title><source>Nature Neuroscience</source><year>2021</year><volume>24</volume><fpage>1628</fpage><lpage>1636</lpage><comment>2021 24:11</comment><pub-id pub-id-type="pmid">34711960</pub-id></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Szinte</surname><given-names>M</given-names></name><name><surname>Knapen</surname><given-names>T</given-names></name></person-group><article-title>Visual Organization of the Default Network</article-title><source>Cerebral Cortex</source><year>2020</year><volume>30</volume><fpage>3518</fpage><lpage>3527</lpage><pub-id pub-id-type="pmcid">PMC7232993</pub-id><pub-id pub-id-type="pmid">32031204</pub-id><pub-id pub-id-type="doi">10.1093/cercor/bhz323</pub-id></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knapen</surname><given-names>T</given-names></name></person-group><article-title>Topographic connectivity reveals task-dependent retinotopic processing throughout the human brain</article-title><source>Proc Natl Acad Sci U S A</source><year>2021</year><volume>118</volume><pub-id pub-id-type="pmcid">PMC7812773</pub-id><pub-id pub-id-type="pmid">33372144</pub-id><pub-id pub-id-type="doi">10.1073/pnas.2017032118</pub-id></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christiaan Klink</surname><given-names>P</given-names></name><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Vanduffel</surname><given-names>W</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name></person-group><article-title>Population receptive fields in non-human primates from whole-brain fmri and large-scale neurophysiology in visual cortex</article-title><source>Elife</source><year>2021</year><volume>10</volume><pub-id pub-id-type="pmcid">PMC8641953</pub-id><pub-id pub-id-type="pmid">34730515</pub-id><pub-id pub-id-type="doi">10.7554/eLife.67304</pub-id></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steel</surname><given-names>A</given-names></name><name><surname>Silson</surname><given-names>EH</given-names></name><name><surname>Garcia</surname><given-names>BD</given-names></name><name><surname>Robertson</surname><given-names>CE</given-names></name></person-group><article-title>A retinotopic code structures the interaction between perception and memory systems</article-title><source>Nat Neurosci</source><year>2024</year><volume>27</volume><fpage>339</fpage><lpage>347</lpage><pub-id pub-id-type="pmcid">PMC10923171</pub-id><pub-id pub-id-type="pmid">38168931</pub-id><pub-id pub-id-type="doi">10.1038/s41593-023-01512-3</pub-id></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steel</surname><given-names>A</given-names></name><name><surname>Billings</surname><given-names>MM</given-names></name><name><surname>Silson</surname><given-names>EH</given-names></name><name><surname>Robertson</surname><given-names>CE</given-names></name></person-group><article-title>A network linking scene perception and spatial memory systems in posterior cerebral cortex</article-title><source>Nature Communications</source><year>2021</year><volume>12</volume><fpage>1</fpage><lpage>13</lpage><comment>2021 12:1</comment><pub-id pub-id-type="pmcid">PMC8113503</pub-id><pub-id pub-id-type="pmid">33976141</pub-id><pub-id pub-id-type="doi">10.1038/s41467-021-22848-z</pub-id></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steel</surname><given-names>A</given-names></name><name><surname>Garcia</surname><given-names>BD</given-names></name><name><surname>Goyal</surname><given-names>K</given-names></name><name><surname>Mynick</surname><given-names>A</given-names></name><name><surname>Robertson</surname><given-names>CE</given-names></name></person-group><article-title>Scene Perception and Visuospatial Memory Converge at the Anterior Edge of Visually Responsive Cortex</article-title><source>The Journal of Neuroscience</source><year>2023</year><volume>43</volume><elocation-id>5723</elocation-id><pub-id pub-id-type="pmcid">PMC10401646</pub-id><pub-id pub-id-type="pmid">37474310</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2043-22.2023</pub-id></element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Groen</surname><given-names>IIA</given-names></name><name><surname>Dekker</surname><given-names>TM</given-names></name><name><surname>Knapen</surname><given-names>T</given-names></name><name><surname>Silson</surname><given-names>EH</given-names></name></person-group><article-title>Visuospatial coding as ubiquitous scaffolding for human cognition</article-title><source>Trends Cogn Sci</source><year>2022</year><volume>26</volume><fpage>81</fpage><lpage>96</lpage><pub-id pub-id-type="pmid">34799253</pub-id></element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allen</surname><given-names>EJ</given-names></name><name><surname>St-Yves</surname><given-names>G</given-names></name><name><surname>Wu</surname><given-names>Y</given-names></name><name><surname>Breedlove</surname><given-names>JL</given-names></name><name><surname>Prince</surname><given-names>JS</given-names></name><name><surname>Dowdle</surname><given-names>LT</given-names></name><name><surname>Nau</surname><given-names>M</given-names></name><name><surname>Caron</surname><given-names>B</given-names></name><name><surname>Pestilli</surname><given-names>F</given-names></name><name><surname>Charest</surname><given-names>I</given-names></name><etal/></person-group><article-title>A massive 7T fMRI dataset to bridge cognitive neuroscience and artificial intelligence</article-title><source>Nature Neuroscience</source><year>2021</year><volume>25</volume><fpage>116</fpage><lpage>126</lpage><comment>2021 25:1</comment><pub-id pub-id-type="pmid">34916659</pub-id></element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dumoulin</surname><given-names>SO</given-names></name><name><surname>Wandell</surname><given-names>BA</given-names></name></person-group><article-title>Population receptive field estimates in human visual cortex</article-title><source>Neuroimage</source><year>2008</year><volume>39</volume><fpage>647</fpage><pub-id pub-id-type="pmcid">PMC3073038</pub-id><pub-id pub-id-type="pmid">17977024</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.09.034</pub-id></element-citation></ref><ref id="R40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kong</surname><given-names>R</given-names></name><name><surname>Yang</surname><given-names>Q</given-names></name><name><surname>Gordon</surname><given-names>E</given-names></name><name><surname>Xue</surname><given-names>A</given-names></name><name><surname>Yan</surname><given-names>X</given-names></name><name><surname>Orban</surname><given-names>C</given-names></name><name><surname>Zuo</surname><given-names>X-N</given-names></name><name><surname>Spreng</surname><given-names>N</given-names></name><name><surname>Ge</surname><given-names>T</given-names></name><name><surname>Holmes</surname><given-names>A</given-names></name><etal/></person-group><article-title>Individual-Specific Areal-Level Parcellations Improve Functional Connectivity Prediction of Behavior</article-title><source>Cerebral Cortex</source><year>2021</year><volume>31</volume><fpage>4477</fpage><lpage>4500</lpage><pub-id pub-id-type="pmcid">PMC8757323</pub-id><pub-id pub-id-type="pmid">33942058</pub-id><pub-id pub-id-type="doi">10.1093/cercor/bhab101</pub-id></element-citation></ref><ref id="R41"><label>41</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Griffanti</surname><given-names>L</given-names></name><name><surname>Salimi-Khorshidi</surname><given-names>G</given-names></name><name><surname>Beckmann</surname><given-names>CF</given-names></name><name><surname>Auerbach</surname><given-names>EJ</given-names></name><name><surname>Douaud</surname><given-names>G</given-names></name><name><surname>Sexton</surname><given-names>CE</given-names></name><name><surname>Zsoldos</surname><given-names>E</given-names></name><name><surname>Ebmeier</surname><given-names>KP</given-names></name><name><surname>Filippini</surname><given-names>N</given-names></name><name><surname>Mackay</surname><given-names>CE</given-names></name><etal/></person-group><article-title>ICA-based artefact removal and accelerated fMRI acquisition for improved resting state network imaging</article-title><source>Neuroimage</source><year>2014</year><volume>95</volume><fpage>232</fpage><lpage>247</lpage><pub-id pub-id-type="pmcid">PMC4154346</pub-id><pub-id pub-id-type="pmid">24657355</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.03.034</pub-id></element-citation></ref><ref id="R42"><label>42</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Griffanti</surname><given-names>L</given-names></name><name><surname>Douaud</surname><given-names>G</given-names></name><name><surname>Bijsterbosch</surname><given-names>J</given-names></name><name><surname>Evangelisti</surname><given-names>S</given-names></name><name><surname>Alfaro-Almagro</surname><given-names>F</given-names></name><name><surname>Glasser</surname><given-names>MF</given-names></name><name><surname>Duff</surname><given-names>EP</given-names></name><name><surname>Fitzgibbon</surname><given-names>S</given-names></name><name><surname>Westphal</surname><given-names>R</given-names></name><name><surname>Carone</surname><given-names>D</given-names></name><etal/></person-group><article-title>Hand classification of fMRI ICA noise components</article-title><source>Neuroimage</source><year>2017</year><volume>154</volume><fpage>188</fpage><lpage>205</lpage><pub-id pub-id-type="pmcid">PMC5489418</pub-id><pub-id pub-id-type="pmid">27989777</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.12.036</pub-id></element-citation></ref><ref id="R43"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>SM</given-names></name><name><surname>Vidaurre</surname><given-names>D</given-names></name><name><surname>Beckmann</surname><given-names>CF</given-names></name><name><surname>Glasser</surname><given-names>MF</given-names></name><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Miller</surname><given-names>KL</given-names></name><name><surname>Nichols</surname><given-names>TE</given-names></name><name><surname>Robinson</surname><given-names>EC</given-names></name><name><surname>Salimi-Khorshidi</surname><given-names>G</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><etal/></person-group><article-title>Functional connectomics from resting-state fMRI</article-title><source>Trends Cogn Sci</source><year>2013</year><volume>17</volume><fpage>666</fpage><lpage>682</lpage><pub-id pub-id-type="pmcid">PMC4004765</pub-id><pub-id pub-id-type="pmid">24238796</pub-id><pub-id pub-id-type="doi">10.1016/j.tics.2013.09.016</pub-id></element-citation></ref><ref id="R44"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yeo</surname><given-names>BTT</given-names></name><name><surname>Krienen</surname><given-names>FM</given-names></name><name><surname>Eickhoff</surname><given-names>SB</given-names></name><name><surname>Yaakub</surname><given-names>SN</given-names></name><name><surname>Fox</surname><given-names>PT</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name><name><surname>Asplund</surname><given-names>CL</given-names></name><name><surname>Chee</surname><given-names>MWL</given-names></name></person-group><article-title>Functional Specialization and Flexibility in Human Association Cortex</article-title><source>Cerebral Cortex</source><year>2015</year><volume>25</volume><fpage>3654</fpage><lpage>3672</lpage><pub-id pub-id-type="pmcid">PMC4598819</pub-id><pub-id pub-id-type="pmid">25249407</pub-id><pub-id pub-id-type="doi">10.1093/cercor/bhu217</pub-id></element-citation></ref><ref id="R45"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silson</surname><given-names>EH</given-names></name><name><surname>Chan</surname><given-names>AWY</given-names></name><name><surname>Reynolds</surname><given-names>RC</given-names></name><name><surname>Kravitz</surname><given-names>DJ</given-names></name><name><surname>Baker</surname><given-names>CI</given-names></name></person-group><article-title>A retinotopic basis for the division of high-level scene processing between lateral and ventral human occipitotemporal cortex</article-title><source>Journal of Neuroscience</source><year>2015</year><volume>35</volume><fpage>11921</fpage><lpage>11935</lpage><pub-id pub-id-type="pmcid">PMC4549403</pub-id><pub-id pub-id-type="pmid">26311774</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0137-15.2015</pub-id></element-citation></ref><ref id="R46"><label>46</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silson</surname><given-names>EH</given-names></name><name><surname>Groen</surname><given-names>IIA</given-names></name><name><surname>Kravitz</surname><given-names>DJ</given-names></name><name><surname>Baker</surname><given-names>CI</given-names></name></person-group><article-title>Evaluating the correspondence between face–, scene–, and object-selectivity and retinotopic organization within lateral occipitotemporal cortex</article-title><source>J Vis</source><year>2016</year><volume>16</volume><fpage>14</fpage><pub-id pub-id-type="pmcid">PMC4898275</pub-id><pub-id pub-id-type="pmid">27105060</pub-id><pub-id pub-id-type="doi">10.1167/16.6.14</pub-id></element-citation></ref><ref id="R47"><label>47</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hutchison</surname><given-names>RM</given-names></name><name><surname>Culham</surname><given-names>JC</given-names></name><name><surname>Everling</surname><given-names>S</given-names></name><name><surname>Flanagan</surname><given-names>JR</given-names></name><name><surname>Gallivan</surname><given-names>JP</given-names></name></person-group><article-title>Distinct and distributed functional connectivity patterns across cortex reflect the domain-specific constraints of object, face, scene, body, and tool category-selective modules in the ventral visual pathway</article-title><source>Neuroimage</source><year>2014</year><volume>96</volume><fpage>216</fpage><lpage>236</lpage><pub-id pub-id-type="pmid">24699018</pub-id></element-citation></ref><ref id="R48"><label>48</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stevens</surname><given-names>WD</given-names></name><name><surname>Tessler</surname><given-names>MH</given-names></name><name><surname>Peng</surname><given-names>CS</given-names></name><name><surname>Martin</surname><given-names>A</given-names></name></person-group><article-title>Functional connectivity constrains the category-related organization of human ventral occipitotemporal cortex</article-title><source>Hum Brain Mapp</source><year>2015</year><volume>36</volume><fpage>2187</fpage><lpage>2206</lpage><pub-id pub-id-type="pmcid">PMC4414790</pub-id><pub-id pub-id-type="pmid">25704493</pub-id><pub-id pub-id-type="doi">10.1002/hbm.22764</pub-id></element-citation></ref><ref id="R49"><label>49</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dilks</surname><given-names>DD</given-names></name><name><surname>Julian</surname><given-names>JB</given-names></name><name><surname>Paunov</surname><given-names>AM</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name></person-group><article-title>The occipital place area is causally and selectively involved in scene perception</article-title><source>Journal of Neuroscience</source><year>2013</year><volume>33</volume><fpage>1331</fpage><lpage>1336</lpage><pub-id pub-id-type="pmcid">PMC3711611</pub-id><pub-id pub-id-type="pmid">23345209</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4081-12.2013</pub-id></element-citation></ref><ref id="R50"><label>50</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Harel</surname><given-names>M</given-names></name><name><surname>Levy</surname><given-names>I</given-names></name><name><surname>Malach</surname><given-names>R</given-names></name></person-group><article-title>Large-scale mirror-symmetry organization of human occipito-temporal object areas</article-title><source>Neuron</source><year>2003</year><volume>37</volume><fpage>1027</fpage><lpage>1041</lpage><pub-id pub-id-type="pmid">12670430</pub-id></element-citation></ref><ref id="R51"><label>51</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kanwisher</surname><given-names>N</given-names></name><name><surname>McDermott</surname><given-names>J</given-names></name><name><surname>Chun</surname><given-names>MM</given-names></name></person-group><article-title>The fusiform face area: A module in human extrastriate cortex specialized for face perception</article-title><source>Journal of Neuroscience</source><year>1997</year><volume>17</volume><fpage>4302</fpage><lpage>4311</lpage><pub-id pub-id-type="pmcid">PMC6573547</pub-id><pub-id pub-id-type="pmid">9151747</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.17-11-04302.1997</pub-id></element-citation></ref><ref id="R52"><label>52</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Halgren</surname><given-names>E</given-names></name><name><surname>Dale</surname><given-names>AM</given-names></name><name><surname>Sereno</surname><given-names>MI</given-names></name><name><surname>Tootell</surname><given-names>RBH</given-names></name><name><surname>Marinkovic</surname><given-names>K</given-names></name><name><surname>Rosen</surname><given-names>BR</given-names></name></person-group><article-title>Location of human face-selective cortex with respect to retinotopic areas</article-title><source>Hum Brain Mapp</source><year>1999</year><volume>7</volume><fpage>29</fpage><pub-id pub-id-type="pmcid">PMC6873292</pub-id><pub-id pub-id-type="pmid">9882088</pub-id><pub-id pub-id-type="doi">10.1002/(SICI)1097-0193(1999)7:1&amp;#x0003c;29::AID-HBM3&amp;#x0003e;3.0.CO;2-R</pub-id></element-citation></ref><ref id="R53"><label>53</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silson</surname><given-names>EH</given-names></name><name><surname>Steel</surname><given-names>AD</given-names></name><name><surname>Baker</surname><given-names>CI</given-names></name></person-group><article-title>Scene-Selectivity and Retinotopy in Medial Parietal Cortex</article-title><source>Front Hum Neurosci</source><year>2016</year><volume>10</volume><fpage>412</fpage><pub-id pub-id-type="pmcid">PMC4988988</pub-id><pub-id pub-id-type="pmid">27588001</pub-id><pub-id pub-id-type="doi">10.3389/fnhum.2016.00412</pub-id></element-citation></ref><ref id="R54"><label>54</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baldassano</surname><given-names>C</given-names></name><name><surname>Esteva</surname><given-names>A</given-names></name><name><surname>Fei-Fei</surname><given-names>L</given-names></name><name><surname>Beck</surname><given-names>DM</given-names></name></person-group><article-title>Two Distinct Scene-Processing Networks Connecting Vision and Memory</article-title><source>eNeuro</source><year>2016</year><volume>3</volume><pub-id pub-id-type="pmcid">PMC5075944</pub-id><pub-id pub-id-type="pmid">27822493</pub-id><pub-id pub-id-type="doi">10.1523/ENEURO.0178-16.2016</pub-id></element-citation></ref><ref id="R55"><label>55</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosenke</surname><given-names>M</given-names></name><name><surname>van Hoof</surname><given-names>R</given-names></name><name><surname>van den Hurk</surname><given-names>J</given-names></name><name><surname>Grill-Spector</surname><given-names>K</given-names></name><name><surname>Goebel</surname><given-names>R</given-names></name></person-group><article-title>A Probabilistic Functional Atlas of Human Occipito-Temporal Visual Cortex</article-title><source>Cerebral Cortex</source><year>2021</year><volume>31</volume><fpage>603</fpage><lpage>619</lpage><pub-id pub-id-type="pmcid">PMC7727347</pub-id><pub-id pub-id-type="pmid">32968767</pub-id><pub-id pub-id-type="doi">10.1093/cercor/bhaa246</pub-id></element-citation></ref><ref id="R56"><label>56</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heeger</surname><given-names>DJ</given-names></name><name><surname>Boynton</surname><given-names>GM</given-names></name><name><surname>Demb</surname><given-names>JB</given-names></name><name><surname>Seidemann</surname><given-names>E</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><article-title>Motion Opponency in Visual Cortex</article-title><source>The Journal of Neuroscience</source><year>1999</year><volume>19</volume><fpage>7162</fpage><pub-id pub-id-type="pmcid">PMC6782843</pub-id><pub-id pub-id-type="pmid">10436069</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.19-16-07162.1999</pub-id></element-citation></ref><ref id="R57"><label>57</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reid</surname><given-names>RC</given-names></name><name><surname>Shapley</surname><given-names>RM</given-names></name></person-group><article-title>Spatial structure of cone inputs to receptive fields in primate lateral geniculate nucleus</article-title><source>Nature</source><year>1992</year><volume>356</volume><fpage>716</fpage><lpage>718</lpage><pub-id pub-id-type="pmid">1570016</pub-id></element-citation></ref><ref id="R58"><label>58</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berardelli</surname><given-names>A</given-names></name><name><surname>Day</surname><given-names>BL</given-names></name><name><surname>Marsden</surname><given-names>CD</given-names></name><name><surname>Rothwell</surname><given-names>JC</given-names></name></person-group><article-title>Evidence favouring presynaptic inhibition between antagonist muscle afferents in the human forearm</article-title><source>J Physiol</source><year>1987</year><volume>391</volume><fpage>71</fpage><lpage>83</lpage><pub-id pub-id-type="pmcid">PMC1192202</pub-id><pub-id pub-id-type="pmid">3443961</pub-id><pub-id pub-id-type="doi">10.1113/jphysiol.1987.sp016726</pub-id></element-citation></ref><ref id="R59"><label>59</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname><given-names>DH</given-names></name><name><surname>Wiesel</surname><given-names>TN</given-names></name></person-group><article-title>Receptive fields, binocular interaction and functional architecture in the cat’s visual cortex</article-title><source>J Physiol</source><year>1962</year><volume>160</volume><fpage>106</fpage><lpage>154</lpage><pub-id pub-id-type="pmcid">PMC1359523</pub-id><pub-id pub-id-type="pmid">14449617</pub-id><pub-id pub-id-type="doi">10.1113/jphysiol.1962.sp006837</pub-id></element-citation></ref><ref id="R60"><label>60</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buschman</surname><given-names>TJ</given-names></name><name><surname>Siegel</surname><given-names>M</given-names></name><name><surname>Roy</surname><given-names>JE</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name></person-group><article-title>Neural substrates of cognitive capacity limitations</article-title><source>Proc Natl Acad Sci U S A</source><year>2011</year><volume>108</volume><fpage>11252</fpage><lpage>11255</lpage><pub-id pub-id-type="pmcid">PMC3131328</pub-id><pub-id pub-id-type="pmid">21690375</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1104666108</pub-id></element-citation></ref><ref id="R61"><label>61</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Libby</surname><given-names>A</given-names></name><name><surname>Buschman</surname><given-names>TJ</given-names></name></person-group><article-title>Rotational dynamics reduce interference between sensory and memory representations</article-title><source>Nature Neuroscience</source><year>2021</year><volume>24</volume><fpage>715</fpage><lpage>726</lpage><comment>2021 24:5</comment><pub-id pub-id-type="pmcid">PMC8102338</pub-id><pub-id pub-id-type="pmid">33821001</pub-id><pub-id pub-id-type="doi">10.1038/s41593-021-00821-9</pub-id></element-citation></ref><ref id="R62"><label>62</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Semedo</surname><given-names>JD</given-names></name><name><surname>Zandvakili</surname><given-names>A</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name><name><surname>Yu</surname><given-names>BM</given-names></name><name><surname>Kohn</surname><given-names>A</given-names></name></person-group><article-title>Cortical areas interact through a communication subspace</article-title><source>Neuron</source><year>2019</year><volume>102</volume><fpage>249</fpage><pub-id pub-id-type="pmcid">PMC6449210</pub-id><pub-id pub-id-type="pmid">30770252</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2019.01.026</pub-id></element-citation></ref><ref id="R63"><label>63</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gregoriou</surname><given-names>GG</given-names></name><name><surname>Gotts</surname><given-names>SJ</given-names></name><name><surname>Zhou</surname><given-names>H</given-names></name><name><surname>Desimone</surname><given-names>R</given-names></name></person-group><article-title>High-frequency, long-range coupling between prefrontal and visual cortex during attention</article-title><source>Science</source><year>2009</year><volume>324</volume><fpage>1207</fpage><lpage>1210</lpage><pub-id pub-id-type="pmcid">PMC2849291</pub-id><pub-id pub-id-type="pmid">19478185</pub-id><pub-id pub-id-type="doi">10.1126/science.1171402</pub-id></element-citation></ref><ref id="R64"><label>64</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bosman</surname><given-names>CA</given-names></name><name><surname>Schoffelen</surname><given-names>JM</given-names></name><name><surname>Brunet</surname><given-names>N</given-names></name><name><surname>Oostenveld</surname><given-names>R</given-names></name><name><surname>Bastos</surname><given-names>AM</given-names></name><name><surname>Womelsdorf</surname><given-names>T</given-names></name><name><surname>Rubehn</surname><given-names>B</given-names></name><name><surname>Stieglitz</surname><given-names>T</given-names></name><name><surname>De Weerd</surname><given-names>P</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name></person-group><article-title>Attentional stimulus selection through selective synchronization between monkey visual areas</article-title><source>Neuron</source><year>2012</year><volume>75</volume><fpage>875</fpage><lpage>888</lpage><pub-id pub-id-type="pmcid">PMC3457649</pub-id><pub-id pub-id-type="pmid">22958827</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2012.06.037</pub-id></element-citation></ref><ref id="R65"><label>65</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Ghosh</surname><given-names>SS</given-names></name><name><surname>Goulas</surname><given-names>A</given-names></name><name><surname>Falkiewicz</surname><given-names>M</given-names></name><name><surname>Huntenburg</surname><given-names>JM</given-names></name><name><surname>Langs</surname><given-names>G</given-names></name><name><surname>Bezgin</surname><given-names>G</given-names></name><name><surname>Eickhoff</surname><given-names>SB</given-names></name><name><surname>Castellanos</surname><given-names>FX</given-names></name><name><surname>Petrides</surname><given-names>M</given-names></name><etal/></person-group><article-title>Situating the default-mode network along a principal gradient of macroscale cortical organization</article-title><source>Proc Natl Acad Sci U S A</source><year>2016</year><volume>113</volume><fpage>12574</fpage><lpage>12579</lpage><pub-id pub-id-type="doi">10.1073/pnas.1608282113</pub-id></element-citation></ref><ref id="R66"><label>66</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buckner</surname><given-names>RL</given-names></name><name><surname>DiNicola</surname><given-names>LM</given-names></name></person-group><article-title>The brain’s default network: updated anatomy, physiology and evolving insights</article-title><source>Nat Rev Neurosci</source><year>2019</year><pub-id pub-id-type="pmid">31492945</pub-id></element-citation></ref><ref id="R67"><label>67</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yeshurun</surname><given-names>Y</given-names></name><name><surname>Nguyen</surname><given-names>M</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><article-title>The default mode network: where the idiosyncratic self meets the shared social world</article-title><source>Nature Reviews Neuroscience</source><year>2021</year><volume>22</volume><fpage>181</fpage><lpage>192</lpage><comment>2021 22:3</comment><pub-id pub-id-type="pmcid">PMC7959111</pub-id><pub-id pub-id-type="pmid">33483717</pub-id><pub-id pub-id-type="doi">10.1038/s41583-020-00420-w</pub-id></element-citation></ref><ref id="R68"><label>68</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spreng</surname><given-names>RN</given-names></name><name><surname>Stevens</surname><given-names>WD</given-names></name><name><surname>Chamberlain</surname><given-names>JP</given-names></name><name><surname>Gilmore</surname><given-names>AW</given-names></name><name><surname>Schacter</surname><given-names>DL</given-names></name></person-group><article-title>Default network activity, coupled with the frontoparietal control network, supports goal-directed cognition</article-title><source>Neuroimage</source><year>2010</year><volume>53</volume><fpage>303</fpage><lpage>317</lpage><pub-id pub-id-type="pmcid">PMC2914129</pub-id><pub-id pub-id-type="pmid">20600998</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.06.016</pub-id></element-citation></ref><ref id="R69"><label>69</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spreng</surname><given-names>RN</given-names></name><name><surname>Mar</surname><given-names>RA</given-names></name><name><surname>Kim</surname><given-names>ASN</given-names></name></person-group><article-title>The common neural basis of autobiographical memory, prospection, navigation, theory of mind, and the default mode: A quantitative meta-analysis</article-title><source>J Cogn Neurosci</source><year>2009</year><volume>21</volume><fpage>489</fpage><lpage>510</lpage><pub-id pub-id-type="pmid">18510452</pub-id></element-citation></ref><ref id="R70"><label>70</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foster</surname><given-names>BL</given-names></name><name><surname>Koslov</surname><given-names>SR</given-names></name><name><surname>Aponik-Gremillion</surname><given-names>L</given-names></name><name><surname>Monko</surname><given-names>ME</given-names></name><name><surname>Hayden</surname><given-names>BY</given-names></name><name><surname>Heilbronner</surname><given-names>SR</given-names></name></person-group><article-title>A tripartite view of the posterior cingulate cortex</article-title><source>Nat Rev Neurosci</source><year>2023</year><volume>24</volume><fpage>173</fpage><lpage>189</lpage><pub-id pub-id-type="pmcid">PMC10041987</pub-id><pub-id pub-id-type="pmid">36456807</pub-id><pub-id pub-id-type="doi">10.1038/s41583-022-00661-x</pub-id></element-citation></ref><ref id="R71"><label>71</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fox</surname><given-names>KCR</given-names></name><name><surname>Spreng</surname><given-names>RN</given-names></name><name><surname>Ellamil</surname><given-names>M</given-names></name><name><surname>Andrews-Hanna</surname><given-names>JR</given-names></name><name><surname>Christoff</surname><given-names>K</given-names></name></person-group><article-title>The wandering brain: Meta-analysis of functional neuroimaging studies of mind-wandering and related spontaneous thought processes</article-title><year>2015</year><comment>Preprint <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2015.02.039">https://doi.org/10.1016/j.neuroimage.2015.02.039</ext-link></comment><pub-id pub-id-type="pmid">25725466</pub-id></element-citation></ref><ref id="R72"><label>72</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bastos</surname><given-names>AM</given-names></name><name><surname>Usrey</surname><given-names>WM</given-names></name><name><surname>Adams</surname><given-names>RA</given-names></name><name><surname>Mangun</surname><given-names>GR</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><article-title>Canonical Microcircuits for Predictive Coding</article-title><source>Neuron</source><year>2012</year><volume>76</volume><fpage>695</fpage><lpage>711</lpage><pub-id pub-id-type="pmcid">PMC3777738</pub-id><pub-id pub-id-type="pmid">23177956</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2012.10.038</pub-id></element-citation></ref><ref id="R73"><label>73</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Albright</surname><given-names>TD</given-names></name></person-group><article-title>On the perception of probable things: neural substrates of associative memory, imagery, and perception</article-title><source>Neuron</source><year>2012</year><volume>74</volume><fpage>227</fpage><lpage>245</lpage><pub-id pub-id-type="pmcid">PMC3361508</pub-id><pub-id pub-id-type="pmid">22542178</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2012.04.001</pub-id></element-citation></ref><ref id="R74"><label>74</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barron</surname><given-names>HC</given-names></name><name><surname>Vogels</surname><given-names>TP</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name><name><surname>Ramaswami</surname><given-names>M</given-names></name><name><surname>Thomas Albright</surname><given-names>ED</given-names></name></person-group><article-title>Inhibitory engrams in perception and memory</article-title><year>2017</year><volume>114</volume><fpage>6666</fpage><lpage>6674</lpage><pub-id pub-id-type="pmcid">PMC5495250</pub-id><pub-id pub-id-type="pmid">28611219</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1701812114</pub-id></element-citation></ref><ref id="R75"><label>75</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>Y</given-names></name><name><surname>Podvalny</surname><given-names>E</given-names></name><name><surname>Levinson</surname><given-names>M</given-names></name><name><surname>He</surname><given-names>BJ</given-names></name></person-group><article-title>Network mechanisms of ongoing brain activity’s influence on conscious visual perception</article-title><source>Nat Commun</source><year>2024</year><volume>15</volume><elocation-id>5720</elocation-id><pub-id pub-id-type="pmcid">PMC11231278</pub-id><pub-id pub-id-type="pmid">38977709</pub-id><pub-id pub-id-type="doi">10.1038/s41467-024-50102-9</pub-id></element-citation></ref><ref id="R76"><label>76</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steel</surname><given-names>A</given-names></name><name><surname>Thomas</surname><given-names>C</given-names></name><name><surname>Trefler</surname><given-names>A</given-names></name><name><surname>Chen</surname><given-names>G</given-names></name><name><surname>Baker</surname><given-names>CI</given-names></name></person-group><article-title>Finding the baby in the bath water – evidence for task-specific changes in resting state functional connectivity evoked by training</article-title><source>Neuroimage</source><year>2019</year><volume>188</volume><fpage>524</fpage><lpage>538</lpage><pub-id pub-id-type="pmid">30578926</pub-id></element-citation></ref><ref id="R77"><label>77</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Çukur</surname><given-names>T</given-names></name><name><surname>Nishimoto</surname><given-names>S</given-names></name><name><surname>Huth</surname><given-names>AG</given-names></name><name><surname>Gallant</surname><given-names>JL</given-names></name></person-group><article-title>Attention during natural vision warps semantic representation across the human brain</article-title><source>Nat Neurosci</source><year>2013</year><volume>16</volume><fpage>763</fpage><lpage>770</lpage><pub-id pub-id-type="pmcid">PMC3929490</pub-id><pub-id pub-id-type="pmid">23603707</pub-id><pub-id pub-id-type="doi">10.1038/nn.3381</pub-id></element-citation></ref><ref id="R78"><label>78</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wandell</surname><given-names>BA</given-names></name><name><surname>Dumoulin</surname><given-names>SO</given-names></name><name><surname>Brewer</surname><given-names>AA</given-names></name></person-group><article-title>Visual field maps in human cortex</article-title><source>Neuron</source><year>2007</year><volume>56</volume><fpage>366</fpage><lpage>383</lpage><pub-id pub-id-type="pmid">17964252</pub-id></element-citation></ref><ref id="R79"><label>79</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arcaro</surname><given-names>M</given-names></name><name><surname>Livingstone</surname><given-names>M</given-names></name></person-group><article-title>A Whole-Brain Topographic Ontology</article-title><source>Annu Rev Neurosci</source><year>2024</year><volume>47</volume><fpage>21</fpage><lpage>40</lpage><pub-id pub-id-type="pmid">38360565</pub-id></element-citation></ref><ref id="R80"><label>80</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peer</surname><given-names>M</given-names></name><name><surname>Brunec</surname><given-names>IK</given-names></name><name><surname>Newcombe</surname><given-names>NS</given-names></name><name><surname>Epstein</surname><given-names>RA</given-names></name></person-group><article-title>Structuring Knowledge with Cognitive Maps and Cognitive Graphs</article-title><source>Trends Cogn Sci</source><year>2020</year><pub-id pub-id-type="pmcid">PMC7746605</pub-id><pub-id pub-id-type="pmid">33248898</pub-id><pub-id pub-id-type="doi">10.1016/j.tics.2020.10.004</pub-id></element-citation></ref><ref id="R81"><label>81</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huth</surname><given-names>AG</given-names></name><name><surname>De Heer</surname><given-names>WA</given-names></name><name><surname>Griffiths</surname><given-names>TL</given-names></name><name><surname>Theunissen</surname><given-names>FE</given-names></name><name><surname>Gallant</surname><given-names>JL</given-names></name></person-group><article-title>Natural speech reveals the semantic maps that tile human cerebral cortex</article-title><source>Nature</source><year>2016</year><volume>532</volume><fpage>453</fpage><lpage>458</lpage><pub-id pub-id-type="pmcid">PMC4852309</pub-id><pub-id pub-id-type="pmid">27121839</pub-id><pub-id pub-id-type="doi">10.1038/nature17637</pub-id></element-citation></ref><ref id="R82"><label>82</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hedger</surname><given-names>N</given-names></name><name><surname>Naselaris</surname><given-names>T</given-names></name><name><surname>Kay</surname><given-names>K</given-names></name><name><surname>Knapen</surname><given-names>T</given-names></name></person-group><article-title>Vicarious Somatotopic Maps Tile Visual Cortex</article-title><source>bioRxiv</source><year>2024</year><elocation-id>2024.10.21.619382</elocation-id><pub-id pub-id-type="doi">10.1101/2024.10.21.619382</pub-id></element-citation></ref><ref id="R83"><label>83</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Epstein</surname><given-names>R</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name></person-group><article-title>A cortical representation the local visual environment</article-title><source>Nature</source><year>1998</year><volume>392</volume><fpage>598</fpage><lpage>601</lpage><pub-id pub-id-type="pmid">9560155</pub-id></element-citation></ref><ref id="R84"><label>84</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Grill-Spector</surname><given-names>K</given-names></name><name><surname>Weiner</surname><given-names>KS</given-names></name></person-group><article-title>The functional architecture of the ventral temporal cortex and its role in categorization</article-title><publisher-name>Nature Publishing Group</publisher-name><year>2014</year><comment>Preprint at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nrn3747">https://doi.org/10.1038/nrn3747</ext-link></comment><pub-id pub-id-type="pmcid">PMC4143420</pub-id><pub-id pub-id-type="pmid">24962370</pub-id><pub-id pub-id-type="doi">10.1038/nrn3747</pub-id></element-citation></ref><ref id="R85"><label>85</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dale</surname><given-names>AM</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Sereno</surname><given-names>MI</given-names></name></person-group><article-title>Cortical surface-based analysis: I. Segmentation and surface reconstruction</article-title><source>Neuroimage</source><year>1999</year><volume>9</volume><fpage>179</fpage><lpage>194</lpage><pub-id pub-id-type="pmid">9931268</pub-id></element-citation></ref><ref id="R86"><label>86</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Salat</surname><given-names>DH</given-names></name><name><surname>Busa</surname><given-names>E</given-names></name><name><surname>Albert</surname><given-names>M</given-names></name><name><surname>Dieterich</surname><given-names>M</given-names></name><name><surname>Haselgrove</surname><given-names>C</given-names></name><name><surname>Van Der Kouwe</surname><given-names>A</given-names></name><name><surname>Killiany</surname><given-names>R</given-names></name><name><surname>Kennedy</surname><given-names>D</given-names></name><name><surname>Klaveness</surname><given-names>S</given-names></name><etal/></person-group><article-title>Whole brain segmentation: Automated labeling of neuroanatomical structures in the human brain</article-title><source>Neuron</source><year>2002</year><volume>33</volume><fpage>341</fpage><lpage>355</lpage><pub-id pub-id-type="pmid">11832223</pub-id></element-citation></ref><ref id="R87"><label>87</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saad</surname><given-names>ZS</given-names></name><name><surname>Reynolds</surname><given-names>RC</given-names></name></person-group><article-title>SUMA</article-title><source>Neuroimage</source><year>2012</year><volume>62</volume><fpage>768</fpage><lpage>773</lpage><pub-id pub-id-type="pmcid">PMC3260385</pub-id><pub-id pub-id-type="pmid">21945692</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.09.016</pub-id></element-citation></ref><ref id="R88"><label>88</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cox</surname><given-names>RW</given-names></name></person-group><article-title>AFNI: Software for analysis and visualization of functional magnetic resonance neuroimages</article-title><source>Computers and Biomedical Research</source><year>1996</year><volume>29</volume><fpage>162</fpage><lpage>173</lpage><pub-id pub-id-type="pmid">8812068</pub-id></element-citation></ref><ref id="R89"><label>89</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taylor</surname><given-names>PA</given-names></name><name><surname>Glen</surname><given-names>DR</given-names></name><name><surname>Chen</surname><given-names>G</given-names></name><name><surname>Cox</surname><given-names>RW</given-names></name><name><surname>Hanayik</surname><given-names>T</given-names></name><name><surname>Rorden</surname><given-names>C</given-names></name><name><surname>Nielson</surname><given-names>DM</given-names></name><name><surname>Rajendra</surname><given-names>JK</given-names></name><name><surname>Reynolds</surname><given-names>RC</given-names></name></person-group><article-title>A Set of FMRI Quality Control Tools in AFNI: Systematic, in-depth and interactive QC with afni_proc py and more</article-title><source>bioRxiv</source><year>2024</year><elocation-id>2024.03.27.586976</elocation-id><pub-id pub-id-type="pmcid">PMC11382598</pub-id><pub-id pub-id-type="pmid">39257641</pub-id><pub-id pub-id-type="doi">10.1162/imag_a_00246</pub-id></element-citation></ref><ref id="R90"><label>90</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beckers</surname><given-names>AB</given-names></name><name><surname>Drenthen</surname><given-names>GS</given-names></name><name><surname>Jansen</surname><given-names>JFA</given-names></name><name><surname>Backes</surname><given-names>WH</given-names></name><name><surname>Poser</surname><given-names>BA</given-names></name><name><surname>Keszthelyi</surname><given-names>D</given-names></name></person-group><article-title>Comparing the efficacy of data-driven denoising methods for a multi-echo fMRI acquisition at 7T</article-title><source>Neuroimage</source><year>2023</year><volume>280</volume><elocation-id>120361</elocation-id><pub-id pub-id-type="pmid">37669723</pub-id></element-citation></ref><ref id="R91"><label>91</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Beckmann</surname><given-names>CF</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name></person-group><article-title>FSL</article-title><source>Neuroimage</source><year>2012</year><volume>62</volume><fpage>782</fpage><lpage>790</lpage><pub-id pub-id-type="pmid">21979382</pub-id></element-citation></ref><ref id="R92"><label>92</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>SM</given-names></name><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Beckmann</surname><given-names>CF</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Johansen-Berg</surname><given-names>H</given-names></name><name><surname>Bannister</surname><given-names>PR</given-names></name><name><surname>De Luca</surname><given-names>M</given-names></name><name><surname>Drobnjak</surname><given-names>I</given-names></name><name><surname>Flitney</surname><given-names>DE</given-names></name><etal/></person-group><article-title>Advances in functional and structural MR image analysis and implementation as FSL</article-title><source>NeuroImage</source><publisher-name>Academic Press</publisher-name><year>2004</year><fpage>S208</fpage><lpage>S219</lpage><pub-id pub-id-type="pmid">15501092</pub-id></element-citation></ref><ref id="R93"><label>93</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gordon</surname><given-names>EM</given-names></name><name><surname>Chauvin</surname><given-names>RJ</given-names></name><name><surname>Van</surname><given-names>AN</given-names></name><name><surname>Rajesh</surname><given-names>A</given-names></name><name><surname>Nielsen</surname><given-names>A</given-names></name><name><surname>Newbold</surname><given-names>DJ</given-names></name><name><surname>Lynch</surname><given-names>CJ</given-names></name><name><surname>Seider</surname><given-names>NA</given-names></name><name><surname>Krimmel</surname><given-names>SR</given-names></name><name><surname>Scheidter</surname><given-names>KM</given-names></name><etal/></person-group><article-title>A somato-cognitive action network alternates with effector regions in motor cortex</article-title><source>Nature</source><year>2023</year><volume>617</volume><fpage>351</fpage><lpage>359</lpage><pub-id pub-id-type="pmcid">PMC10172144</pub-id><pub-id pub-id-type="pmid">37076628</pub-id><pub-id pub-id-type="doi">10.1038/s41586-023-05964-2</pub-id></element-citation></ref><ref id="R94"><label>94</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mitra</surname><given-names>A</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Blazey</surname><given-names>T</given-names></name><name><surname>Raichle</surname><given-names>ME</given-names></name></person-group><article-title>Lag threads organize the brain’s intrinsic activity</article-title><source>Proceedings of the National Academy of Sciences</source><year>2015</year><volume>112</volume><fpage>E2235</fpage><lpage>E2244</lpage><pub-id pub-id-type="pmcid">PMC4418865</pub-id><pub-id pub-id-type="pmid">25825720</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1503960112</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Fig. 1</label><caption><title>Inversion of retinotopic coding between externally- and internally-oriented networks in the human brain.</title><p>A. Population receptive field (pRF) modeling with fMRI. A visual pRF model was fit for all participants to determine visual field preferences for each voxel. Voxels with positive BOLD responses to the visual stimulus are referred to as positive pRFs (+pRFs), and those with negative BOLD responses are referred to as negative pRFs (-pRFs). B. Individualized resting-state network parcellation. Resting-state fMRI was collected in all participants (N=7; 34-102 minutes per participant) and used to derive individualized cortical network parcellations. Parcellations were generated using the multi-session hierarchical Bayesian modelling approach<sup><xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R40">40</xref></sup> with the Yeo 15 HCP atlas<sup><xref ref-type="bibr" rid="R44">44</xref></sup> as a prior. C. Differential concentrations of +/-pRFs in task-negative and task-positive (internally/externally oriented) brain networks. Bars show the proportion of -pRFs (of total suprathreshold voxels) within each individual’s cortical networks. The dATN (combined dATN-A/B) had the lowest proportion of -pRFs, while the DN (combined DN-A/B) had the highest. All networks’ concentration of -pRFs are shown in <xref ref-type="supplementary-material" rid="SD1">Fig., S3</xref>. D. Interaction between the DN and dATN differs by visual field preference of DN voxels. DN voxels with +pRFs had a positive correlation with the dATN (mean correlation = 0.22±0.144, t(6) = 3.99, p = 0.0072), while non-retinotopic DN\ voxels (i.e., pRF model R2 &lt; 0.08) were not significantly correlated with the dATN (mean correlation = 0.02±0.115, t(6) = 0.37, p = 0.72). On the other hand, DN voxels with -pRFs were anti-correlated with the dATN (mean correlation = -0.20±0.12, t(6) = 4.22, p = 0.0055). To conduct these analyses, we accounted for variance associated with other cortical networks using partial correlation<sup><xref ref-type="bibr" rid="R43">43</xref></sup>.</p></caption><graphic xlink:href="EMS199031-f001"/></fig><fig id="F2" position="float"><label>Fig. 2</label><caption><title>Retinotopic coding organizes spontaneous interaction between internally and externally oriented brain networks.</title><p>A. Determining spatially-matched pRFs in dATNs and DNs. We assessed the influence of retinotopic coding on the interaction between internally- and externally-oriented brain areas’ spontaneous activity during resting-state fMRI, by comparing the correlation in activation between pRFs in these networks that represent similar (vs. different) regions of visual space. For each -DN pRF, we established the top 10 closest +dATN pRF voxels’ centers (“matched”) and the 10 furthest pRF centers (“antimatched”). For each resting-state fMRI scan, we extracted the average time series from -DN pRFs and correlated that time series with the average time series from the +dATN matched and antimatched pRFs. We repeated this procedure for all resting-state runs in all participants. Plot shows one example resting-state time series from a participant’s -DN, +dATN matched and +dATN antimatched pRFs and their associated correlation values. B. Spatially matched -DN/+dATN pRFs have a greater opponent interaction than antimatched pRFs, showing that opponent dynamics depend on retinotopic preferences. Histogram shows the distribution in correlation values between matched (dark green) and antimatched (light green) pRF pairs for each resting-state run in all participants, which were significantly different (matched versus antimatched: D(392)=0.245, p&lt;0.001). Bar plot shows the average correlation for each participant (matched versus antimatched: t(6)=3.49, p=0.011). C. DN subnetworks A and B both evidenced a retinotopic opponent interaction (DN-A: t(6)=3.02, p=0.023, DN-B: t(6)=2.72, p=0.034; DN-A vs. DN-B: t(6)=1.64, p&lt;0.15), although the opponency was stronger overall in DN-A compared to DN-B (difference in average correlation between - DN/+dATN pRFs: t(6)=5.41, p=0.002).</p></caption><graphic xlink:href="EMS199031-f002"/></fig><fig id="F3" position="float"><label>Fig. 3</label><caption><title>Retinotopic coding structures the spontaneous interaction between functionally-coupled mnemonic and perceptual areas during resting-state fMRI.</title><p>A. Isolating functionally coupled internally- and externally-oriented brain areas within the DNs and dATNs. We identified brain areas that were specialized in two domains: scenes and faces processing. Specifically, we focused on the lateral place memory area (LPMA; from <sup><xref ref-type="bibr" rid="R35">35</xref></sup>), white), a memory area in the domain of scene perception at the posterior edge of the DN-A (purple; from <sup><xref ref-type="bibr" rid="R44">44</xref></sup>). We examined LPMA’s relationship to three different of category-selective visual areas in the dATN (green; from <sup><xref ref-type="bibr" rid="R44">44</xref></sup>), 1) the occipital place area (OPA; from <sup><xref ref-type="bibr" rid="R35">35</xref></sup>), an area within the domain of scene perception, along with 2) the occipital face area (OFA) and 3) the fusiform face area (FFA), two areas involved in the domain of face perception (white; from <sup><xref ref-type="bibr" rid="R55">55</xref></sup>). B-C. We localized LPMA in all participants by contrasting the correlation in resting-state activity between anterior and posterior parahippocampal place area (PPA) (B). This yielded a region in lateral occipital-parietal cortex that overlapped with the LPMA defined in an independent group of participants (C). D-E. Consistent with prior work, the connectivity-defined LPMA had greater concentration of -pRFs compared to OPA (D), and exhibited a lower visual field bias to OPA (E), consistent with an opponent interaction between these areas during perception. F. We assessed the influence of retinotopic coding on the interaction between -pRFs in mnemonic and +pRFs in perceptual areas using the same pRF matching and correlation procedure described above. We compared pRFs within functional domain (scene memory x perception – LPMA to OPA) as well as across domains (scene memory x face perception – LPMA to the occipital face area (OFA) and fusiform face area (FFA)). G. Within functional domain opponent interaction reflects voxel-wise retinotopic coding. We observed a stronger negative correlation between matched compared to antimatched - LPMA/+OPA pRFs (-LPMA x +OPA matched versus antimatched pRFs: D(392)=0.22, p&lt;0.001). H. Retinotopic coding did not impact the interaction between areas across functional domains. We found no significant difference between matched and antimatched pRFs between the scene memory area LPMA and the face perception areas FFA and OFA (-LPMA x +OFA: D(392)=0.09, p=0.44; -LPMA x +FFA: D(392)=0.11, p=0.15). Histograms depict the distribution of correlation values between matched (dark) and antimatched (light) pRFs for all runs in all participants. I. Retinotopic coding organizes interactions within a domain, but not across domains. When the correlation values were averaged within each participant, we observed a significant difference between matched versus antimatched pRFs within functional domain (-LPMA x +OPA: t(6)=4.45, p=0.004) but not across domains (-LPMA x +OFA: t(6)=1.04, p=0.34; -LPMA x +FFA: t(6)=1.48, p=0.188).</p></caption><graphic xlink:href="EMS199031-f003"/></fig><fig id="F4" position="float"><label>Fig. 4</label><caption><title>Top-down vs. bottom-up neural events detected in spontaneous resting-state dynamics show evidence for retinotopically-specific suppression.</title><p>A. Event detection and analysis procedure and example events from a single resting-state run. To detect events, we extracted the time series from each pRF in the source regions (top-down: -LPMA; bottom-up: +OPA) and isolated time points where the z-scored time series exceeded 2.4 s.d. (99th percentile). We then examined the activity of matched and antimatched pRFs from the target region in this peri-event time frame (6 TRs (8 s) before and after the event). Overall, this event detection procedure yielded 20958 top-down and 7985 bottom-up events that were well distributed in time (<xref ref-type="supplementary-material" rid="SD1">Fig. S11</xref>). B. -LPMA pRF events co-occur with suppression of retinotopically-matched +OPA pRFs. Peri-event time series depicts the grand average activity of matched (dark) and antimatched +OPA pRFs. Time series are baselined to the mean of the first three TRs (TRs -6 to -4 relative to event onset, dotted line). Red significance line shows time points with a significant difference between matched and antimatched activation, corrected for multiple comparisons (alpha-level: p&lt;0.05/13 = 0.0038). C. Suppression of ongoing activity in retinotopically matched -LPMA pRFs during +OPA events. Peri-event time series depicts the grand average activity of matched (dark) and antimatched +OPA pRFs. As predicted, -LPMA activity is elevated during resting-state. This elevated ongoing activity is suppressed during events in retinotopically matched +OPA pRFs. Time series are baselined to the mean of the first three TRs (TRs -6 to -4 relative to event onset, dotted line). Blue significance line shows time points with a significant difference between matched and antimatched activation, corrected for multiple comparisons. D. Target area shows retinotopically-specific suppression of activity for both top-down and bottom-up events. Bars show the average activation at event time of the target areas’ matched and antimatched pRFs for each participant. Activity in matched pRFs was significantly lower than antimatched pRFs for both top-down (t(6)=4.13, p=0.006) and bottom-up (t(6)=3.17, p=0.02), and there was no difference in the influence of retinotopic coding between these event types (t(6)=0.86, p=0.42).</p></caption><graphic xlink:href="EMS199031-f004"/></fig></floats-group></article>