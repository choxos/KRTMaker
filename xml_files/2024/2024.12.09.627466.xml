<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS202013</article-id><article-id pub-id-type="doi">10.1101/2024.12.09.627466</article-id><article-id pub-id-type="archive">PPR954163</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">1</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Motor imagery and execution activate similar finger representations that are spatially consistent over time</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Odermatt</surname><given-names>Ingrid Angela</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><contrib contrib-type="author"><name><surname>Schönberg</surname><given-names>Laura</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Heimhofer</surname><given-names>Caroline</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Freund</surname><given-names>Patrick</given-names></name><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref><xref ref-type="aff" rid="A4">4</xref><xref ref-type="aff" rid="A5">5</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Wenderoth</surname><given-names>Nicole</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A6">6</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Kikkert</surname><given-names>Sanne</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref></contrib></contrib-group><aff id="A1"><label>1</label>Neural Control of Movement Laboratory, Department of Health Sciences and Technology, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/05a28rw58</institution-id><institution>ETH Zurich</institution></institution-wrap>, <city>Zurich</city>, <country country="CH">Switzerland</country></aff><aff id="A2"><label>2</label>Neuroscience Center Zurich (ZNZ), <institution-wrap><institution-id institution-id-type="ror">https://ror.org/02crff812</institution-id><institution>University of Zurich</institution></institution-wrap> and <institution-wrap><institution-id institution-id-type="ror">https://ror.org/05a28rw58</institution-id><institution>ETH Zurich</institution></institution-wrap>, <city>Zurich</city>, <country country="CH">Switzerland</country></aff><aff id="A3"><label>3</label>Spinal Cord Injury Centre, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/02yzaka98</institution-id><institution>Balgrist University Hospital</institution></institution-wrap>, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/02crff812</institution-id><institution>University of Zurich</institution></institution-wrap>, <city>Zurich</city>, <country country="CH">Switzerland</country></aff><aff id="A4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02704qw51</institution-id><institution>Wellcome Trust Centre for Neuroimaging</institution></institution-wrap>, Queen Square Institute of Neurology, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>University College London</institution></institution-wrap>, <city>London</city>, <country country="GB">UK</country></aff><aff id="A5"><label>5</label>Department of Neurophysics, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/0387jng26</institution-id><institution>Max Planck Institute for Human Cognitive and Brain Sciences</institution></institution-wrap>, <city>Leipzig</city>, <country country="DE">Germany</country></aff><aff id="A6"><label>6</label>Future Health Technologies, Singapore-ETH Centre, Campus for Research Excellence and Technological Enterprise (CREATE), Singapore, Singapore</aff><author-notes><corresp id="CR1"><label>*</label>Corresponding author: <email>ingrid.odermatt@hest.ethz.ch</email></corresp></author-notes><pub-date pub-type="nihms-submitted"><day>18</day><month>12</month><year>2024</year></pub-date><pub-date pub-type="preprint"><day>13</day><month>12</month><year>2024</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Finger representations in the sensorimotor cortex can be activated even in the absence of somatosensory input or motor output through mere top-down processes, such as motor imagery. While executed finger movements activate finger representations in the primary sensorimotor cortex that are spatially consistent over time within participants, the stability of top-down activated finger representations remains largely unexplored. Given the increasing use of top-down activated sensorimotor representations to both plan implantation of and control brain-computer interfaces, it is crucial to understand the stability of these representations. Here, we investigated the spatial consistency, and thereby reliability, of finger representations activated through motor imagery in the primary somatosensory and primary motor cortex over time. To assess this, participants performed imagined and executed individual finger movements in two 3T fMRI sessions that were ~2 weeks apart. We observed highly consistent univariate finger-selective activity clusters and multivariate vertex-wise activity patterns within participants over time in both the motor imagery and motor execution task. Using a multivariate across-task decoding approach, we further found that motor execution and motor imagery activate similar finger representations in both the primary somatosensory and primary motor cortex. This demonstrates that motor imagery can be used to identify finger representations related to movement execution. Our findings not only validate the use of top-down processes for brain-computer interface planning and control, but also open up new opportunities for the development of sensorimotor training interventions that do not rely on overt movements.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">The somatotopic organisation in the primary somatosensory cortex (S1) and primary motor cortex (M1) describes the correspondence between an area of the body and the specific area of the cortex representing that body part (<xref ref-type="bibr" rid="R56">Penfield &amp; Boldrey, 1937</xref>). Neural finger representations have been of particular interest in this context given their fine-grained somatotopy (<xref ref-type="bibr" rid="R9">Besle et al., 2013</xref>; <xref ref-type="bibr" rid="R18">Ejaz et al., 2015</xref>; <xref ref-type="bibr" rid="R43">Kolasinski et al., 2016</xref>; <xref ref-type="bibr" rid="R60">Sanchez-Panchuelo et al., 2010</xref>; <xref ref-type="bibr" rid="R61">Sanders et al., 2023</xref>; <xref ref-type="bibr" rid="R62">Schellekens et al., 2018</xref>) and importance for fine motor skills (<xref ref-type="bibr" rid="R75">Xu et al., 2024</xref>). Their detailed somatotopic organisation has been extensively studied using functional magnetic resonance imaging (fMRI) (<xref ref-type="bibr" rid="R36">Janko et al., 2022</xref>). Traditionally, S1 and M1 finger representations are investigated using tactile stimulation or motor execution paradigms (<xref ref-type="bibr" rid="R8">Berlot et al., 2019</xref>; <xref ref-type="bibr" rid="R61">Sanders et al., 2023</xref>). Over the past years, evidence has accumulated demonstrating that neural representations of individual fingers in S1 and M1 can also be activated through top-down processes, i.e., without any overt motor output or somatosensory input. Specifically, finger representations have been detected in S1 by directing attention to individual fingers (<xref ref-type="bibr" rid="R58">Puckett et al., 2017</xref>), by anticipated tactile stimulation (<xref ref-type="bibr" rid="R40">Kassraian et al., 2023</xref>), by merely holding tactile information in working memory (<xref ref-type="bibr" rid="R59">Rabe et al., 2023</xref>), or by observed touch (<xref ref-type="bibr" rid="R44">Kuehn et al., 2018</xref>). Furthermore, finger representations are activated in both M1 and S1 during movement preparation (<xref ref-type="bibr" rid="R5">Ariani et al., 2022</xref>) or motor imagery (<xref ref-type="bibr" rid="R52">Odermatt et al., 2024</xref>). While it has been shown that finger representations activated through executed movements are spatially highly stable over time for up to six months (<xref ref-type="bibr" rid="R18">Ejaz et al., 2015</xref>; <xref ref-type="bibr" rid="R43">Kolasinski et al., 2016</xref>), the spatial consistency, and thus reliability, of top-down activated finger representations has not yet been explored.</p><p id="P3">The lack of a clear understanding regarding the reliability of top-down activated sensorimotor representations is surprising, given their growing neuroscientific and clinical importance. Indeed, the fact that top-down processes can activate representations of individual fingers has enabled researchers to study finger representations in populations in the absence of sensorimotor functions. Specifically, S1 and M1 finger representations have been detected through attempted finger movements of a missing hand after arm amputation or paralysed hand after cervical spinal cord injury (<xref ref-type="bibr" rid="R41">Kikkert et al., 2016</xref>, <xref ref-type="bibr" rid="R42">2021</xref>; <xref ref-type="bibr" rid="R73">Wesselink et al., 2019</xref>). These preserved representations (<xref ref-type="bibr" rid="R64">Shah et al., 2023</xref>; <xref ref-type="bibr" rid="R69">van den Boom et al., 2021</xref>) are increasingly used to control brain-computer interfaces (BCIs) (<xref ref-type="bibr" rid="R65">Shah et al., 2024</xref>; <xref ref-type="bibr" rid="R74">Willsey et al., 2024</xref>). Using intracortical recordings in the sensorimotor cortex of cervical spinal cord injury patients with completely paralysed fingers, it has been demonstrated that it is possible to decode individual attempted and imagined finger movements even though actual motor output is completely lacking (<xref ref-type="bibr" rid="R2">Andersen &amp; Aflalo, 2022</xref>; <xref ref-type="bibr" rid="R29">Guan et al., 2022</xref>, <xref ref-type="bibr" rid="R28">2023</xref>; <xref ref-type="bibr" rid="R38">Jorge et al., 2020</xref>). Additionally, we have shown that it is possible to strengthen these top-down activated finger representations through motor imagery training in the absence of overt movements (<xref ref-type="bibr" rid="R52">Odermatt et al., 2024</xref>). Such top-down sensorimotor training interventions may allow to induce adaptive sensorimotor neuroplasticity in patients who are not (yet) able to perform overt movements (<xref ref-type="bibr" rid="R49">McFarland et al., 2020</xref>; <xref ref-type="bibr" rid="R51">Norman et al., 2018</xref>), for instance following a stroke or incomplete spinal cord injury.</p><p id="P4">To validate the use of and optimally leverage top-down activated sensorimotor representations for BCI control and training interventions, we investigated the reproducibility of fine-grained finger representations activated through motor imagery of three different fingers (thumb, index finger, and little finger) over time. To do so, we assessed finger representations in a motor imagery and a motor execution task in 16 healthy participants across two 3T fMRI sessions that were approximately two weeks apart. We investigated spatial consistency in S1 and M1 using two distinct approaches. First, we applied univariate analysis methods to quantify the spatial correspondence of finger-selective (or winner-take-all) maps. Second, we used multivariate analysis to examine the reproducibility of the full intricate activity patterns associated with individual (imagined) finger movements through a decoding approach. If finger representations activated through motor imagery (and motor execution) are spatially consistent over time, then the univariate analysis should reveal more spatial overlap of finger-selective activity across sessions for ‘same’ compared to ‘neighbouring’ or ‘non-neighbouring’ fingers. Furthermore, if motor imagery (and motor execution) elicit consistent activity patterns over time, the multivariate decoding approach should achieve high classification accuracy across sessions. In both the uni- and multivariate analysis, we expected higher consistency within participants than across participants. Given the intertwined nature of S1 and M1, we expected to obtain similar results in these areas. Additionally, due to the implicated role of the supplementary motor area (SMA) and the ventral (PMv) and dorsal premotor cortex (PMd) in top-down motor-related processes (<xref ref-type="bibr" rid="R13">Bruurmijn et al., 2017</xref>; <xref ref-type="bibr" rid="R55">Park et al., 2015</xref>; <xref ref-type="bibr" rid="R57">Pilgramm et al., 2016</xref>; <xref ref-type="bibr" rid="R76">Zabicki et al., 2017</xref>), we exploratively conducted uni- and multivariate analyses to characterise motor imagery finger representations in these secondary motor areas. Finally, we compared motor imagery finger representations to the representations activated through motor execution to test their neural similarity in M1 and S1.</p></sec><sec id="S2" sec-type="results"><title>Results</title><sec id="S3"><title>Univariate finger-selective maps activated through motor imagery are spatially consistent over time</title><p id="P5">Motor imagery of individual fingers revealed top-down activated finger-selective activity clusters in the primary sensorimotor cortex at the individual participant level based on winner-take-all finger maps that were minimally thresholded (Z &gt; 2) (<xref ref-type="fig" rid="F1">Fig. 1</xref>). These finger-selective activity clusters progressed from the thumb (laterally) to the little finger (medially), corresponding to the gradient of finger preference in characteristic hand maps (<xref ref-type="bibr" rid="R9">Besle et al., 2013</xref>; <xref ref-type="bibr" rid="R43">Kolasinski et al., 2016</xref>; <xref ref-type="bibr" rid="R60">Sanchez-Panchuelo et al., 2010</xref>; <xref ref-type="bibr" rid="R61">Sanders et al., 2023</xref>). Qualitative assessment of these motor imagery finger maps suggests some extent of reproducibility across sessions for most participants, but high variability across participants.</p><p id="P6">To understand the stability, or spatial correspondence, of motor imagery finger maps, we then quantified the spatial overlap of the finger-selective (or winner-take-all) maps across sessions. Specifically, we calculated the Dice Overlap Coefficient (DOC) between every possible finger pair across both sessions within S1 and M1. In the main text, we focus on the results in S1 (<xref ref-type="fig" rid="F2">Fig. 2</xref>), as we obtained similar results in M1 (<xref ref-type="supplementary-material" rid="SD1">Supplementary Fig. 1</xref>). The explorative analysis for secondary motor areas is reported in <xref ref-type="supplementary-material" rid="SD1">Supplementary Fig. 2</xref>.</p><p id="P7">A DOC of 1 reflects a perfect overlap of two representations, while 0 indicates no overlap at all. In S1, our analysis revealed relatively high spatial consistency (DOC) for the ‘same’ motor imagery finger representations over time and low DOC for ‘neighbouring’ and ‘non-neighbouring’ finger representations (<xref ref-type="fig" rid="F2">Fig. 2a</xref>), consistent with previously reported somatotopic finger maps (<xref ref-type="bibr" rid="R41">Kikkert et al., 2016</xref>, <xref ref-type="bibr" rid="R42">2021</xref>; <xref ref-type="bibr" rid="R43">Kolasinski et al., 2016</xref>; <xref ref-type="bibr" rid="R61">Sanders et al., 2023</xref>). This was indicated in a significant <italic>Task</italic> by <italic>Finger pair</italic> interaction (<italic>χ</italic><sup>2</sup><sub>(2)</sub> = 15.38, <italic>p</italic> &lt; .001; main effect <italic>Task:</italic> <italic>χ</italic><sup>2</sup><sub>(1)</sub> = 87.25, <italic>p</italic> &lt; .0001; main effect <italic>Finger pair:</italic> <italic>χ</italic><sup>2</sup><sub>(2)</sub> = 203.82, <italic>p</italic> &lt; .0001). For the motor imagery task, the DOC for the same finger representations was higher compared to neighbouring (<italic>t</italic><sub>(85)</sub> = 7.09, <italic>p</italic> &lt; .0001) and non-neighbouring finger representations (<italic>t</italic><sub>(85)</sub> = 9.12, <italic>p</italic> &lt; .0001), and higher for neighbouring compared to non-neighbouring finger representations (<italic>t</italic><sub>(85)</sub> = 3.42, <italic>p</italic> = .003). This demonstrates a somatotopic gradient in the spatial correspondence across sessions and indicates that the finger maps activated through motor imagery were stable over time. Similarly, in the motor execution task, the DOC was higher for same compared to neighbouring (<italic>t</italic><sub>(85)</sub> = 10.73, <italic>p</italic> &lt; .0001) and non-neighbouring finger representations (<italic>t</italic><sub>(85)</sub> = 11.20, <italic>p</italic> &lt; .0001). However, there was no difference in the DOC for neighbouring and non-neighbouring finger representations (<italic>t</italic><sub>(85)</sub> = -0.72 <italic>p</italic> = .95), possibly due to the inclusion of only three fingers (i.e., thumb, index finger, little finger) in the analysis (see <xref ref-type="supplementary-material" rid="SD1">Supplementary Fig. 3b</xref> for DOC including all five fingers). When comparing the spatial consistency across the two tasks, we found lower DOC during motor imagery compared to motor execution for the same (<italic>t</italic><sub>(85)</sub> = -4.07, <italic>p</italic> = .003) and non-neighbouring (<italic>t</italic><sub>(85)</sub> = -9.27, <italic>p</italic> &lt; .0001) finger representations, and no significant difference for neighbouring finger representations (<italic>t</italic><sub>(85)</sub> = -0.37, <italic>p</italic> = .95; for simplicity of visualisation not depicted in <xref ref-type="fig" rid="F2">Fig. 2a</xref>).</p><p id="P8">Next, we compared the within-participant to across-participants consistency. To do so, we calculated the DOC across sessions for all possible finger and participant pairings. The across-participants DOC matrix (<xref ref-type="fig" rid="F2">Fig. 2b</xref>) consists of submatrices representing each finger pair. If the spatial overlap of finger-selective activity clusters is higher within than across participants, then the values on the diagonal of the ‘same’ finger pair submatrices (i.e., D1-D1, D2-D2, D5-D5) should be higher than the values on the off-diagonal of these ‘same’ finger pair submatrices. As expected, within-participant DOC was higher than across-participants DOC for same fingers, as indicated by all matrix dominance ratios (Mdr) &gt; 1 (Mdr D1 = 3.03, Mdr D2 = 3.42, Mdr D5 = 5.22; see diagonal of matrix on the right in <xref ref-type="fig" rid="F2">Fig. 2b</xref>). By contrast, for both neighbouring and non-neighbouring finger pairs, all Mdrs were &lt; 1 (see off-diagonal of matrix on the right in <xref ref-type="fig" rid="F2">Fig. 2b</xref>). This indicates that for neighbouring and non-neighbouring finger-pairs, the spatial correspondence across sessions within a participant was not higher than the spatial correspondence across participants. Finally, the overall Mdr was calculated based on the Mdr scores of the submatrices in <xref ref-type="fig" rid="F2">Fig. 2b</xref>. The resulting overall Mdr of 10.68 implies that spatial correspondence of the ‘same’ finger representations across sessions drives within-participant consistency. To investigate the likelihood of obtaining a Mdr score higher or equal to the obtained Mdr score merely by chance, we applied bootstrapping and found that the overall Mdr was significanty different from chance level (<italic>p</italic> &lt; .0001), demonstrating higher within-participant than across-participants consistency of motor imagery finger representations.</p><p id="P9">Together, the DOC analyses suggest that, at the group level, the finger-selective activity clusters elicited through motor imagery can be studied using fMRI and follow a somatotopic organisation, similarly as finger maps activated through finger movement or tactile finger stimulation. Importantly, these somatotopic motor imagery finger maps are spatially consistent over weeks. However, at the individual participant level, the minimally thresholded finger maps did not reveal finger-selective activity clusters for each participant, session, and finger. If overall activity levels are (expected to be) low and the conditions are thought to be represented in distributed activity patterns, as suggested for individual (imagined) finger movements, then univariate analysis is suboptimal. Thus, we next used multivariate analysis to overcome these limitations.</p></sec><sec id="S4"><title>Imagined finger movements can be decoded with higher accuracy across sessions than across participants</title><p id="P10">Multivariate pattern analysis (MVPA) takes into account the full pattern of activity elicited by (imagined) finger movements. Here, we used a multivariate decoding approach to investigate whether imagined finger movements can be reliably predicted from the activity pattern in the S1 or M1 hand area across sessions, giving insight into the consistency of these activity patterns over time. To do so, we trained a linear support vector machine on the data of one session and tested it on the data of the other session. In the S1 hand area, we found that within-participant classifiers generalised well across sessions. Specifically, accuracy of this across-sessions decoding was significantly above the empirical chance level <italic>p</italic> &lt; .0001, <xref ref-type="fig" rid="F3">Fig. 3a</xref>), and did not differ from within-session accuracy (<italic>t</italic><sub>(15)</sub> = 1.30, <italic>p</italic> = .21, BF<sub>10</sub> = 0.52 indicating anecdotal evidence for the null hypothesis). This suggests that activity patterns associated with individual imagined finger movements are highly reproducible over fMRI sessions, demonstrating high within-participant consistency.</p><p id="P11">To investigate across-participants consistency in finger representations, we next tested the generalisability of a classifier to other participants and found that such an across-participants classifier was able to successfully decode individual fingers of participants whose data were unseen in the training (average accuracy in leave-one-participant-out cross-validation: 0.40, <italic>p</italic> &lt; .001, empirical chance level: 0.33). However, classification accuracy was significantly lower compared to within-participant classification (within session vs. across participants <italic>t</italic><sub>(15)</sub> = 6.38, <italic>p</italic> &lt; .0001; across sessions vs. across participants <italic>t</italic><sub>(15)</sub> = 6.37, <italic>p</italic> &lt; .0001; <xref ref-type="fig" rid="F3">Fig. 3a</xref>). These results demonstrate that within-participant consistency in activity patterns associated with individual finger motor imagery is significantly higher than across-participants consistency.</p><p id="P12">When comparing the true vs. the predicted labels in the decoding analyses (<xref ref-type="fig" rid="F3">Fig. 3b</xref>), we found more misclassified trials for neighbouring fingers (i.e., thumb misclassified as index finger or vice versa), than for non-neighbouring fingers (i.e., thumb or index finger misclassified as little finger or vice versa; <xref ref-type="fig" rid="F3">Fig. 3c</xref>; significant main effect <italic>Prediction</italic>: <italic>F</italic><sub>(290)</sub> = 187.22, <italic>p</italic> &lt; .0001; non-significant main effect <italic>Comparison</italic>: <italic>F</italic><sub>(1,190)</sub> = 0.00, <italic>p</italic> = .99; non-significant interaction effect: <italic>F</italic><sub>(2,90)</sub> = 0.17, <italic>p</italic> = .85). Significantly more trials were correctly classified compared to misclassified as neighbouring (<italic>t</italic><sub>(75)</sub> = 14.68, <italic>p</italic> &lt; .0001) or as non-neighbouring fingers (<italic>t</italic><sub>(75)</sub> = 18.26, <italic>p</italic> &lt; .0001). From the wrongly classified trials, significantly more trials were misclassified as a neighbouring finger compared to another finger (<italic>t</italic><sub>(75)</sub> = 3.58, <italic>p</italic> = .0006), indicating higher similarity of vertex-wise activity patterns of neighbouring fingers compared to non-neighbouring fingers. Note that the values obtained from the across-participants classification are plotted for visualisation purposes only in <xref ref-type="fig" rid="F3">Fig. 3c</xref> but were not considered in the statistical analysis as only a single value per <italic>Prediction</italic> level was available.</p><p id="P13">We then compared the classification accuracy scores obtained from decoding of fingers in the motor imagery vs. the motor execution task (<xref ref-type="fig" rid="F3">Fig. 3d</xref>), and found, as expected, lower scores for imagined than executed finger movements (significant main effect <italic>Task</italic>: <italic>F</italic><sub>(1,45)</sub> = 364.59, <italic>p</italic> &lt; .0001; non-significant main effect <italic>Comparison</italic>: <italic>F</italic><sub>(1,45)</sub> = 0.30, <italic>p</italic> = .59; non-significant interaction effect: <italic>F</italic><sub>(1,45)</sub> = 0.16, <italic>p</italic> = .69). While decoding of three fingers in the motor execution task lead to very high classification accuracies (mean within session: 0.92; mean across sessions: 0.91; empirical chance level: 0.33), including all five fingers lead to lower absolute values (mean within session: 0.63; mean across sessions: 0.58; empirical chance level: 0.20; <xref ref-type="supplementary-material" rid="SD1">Supplementary Fig. 4</xref>). These findings reveal that although motor imagery elicits less distinguishable activity patterns for individual fingers compared to motor execution, the reproducibility of these patterns across sessions does not differ significantly between the two tasks.</p><p id="P14">Similar results were obtained for the M1 hand area, as depicted in <xref ref-type="supplementary-material" rid="SD1">Supplementary Fig. 5</xref>. In secondary motor areas including SMA, PMd, and PMv we found that imagined and executed finger movements could be decoded significantly above chance, with most correctly classified trials for the thumb (<xref ref-type="supplementary-material" rid="SD1">Supplementary Fig. 6</xref>).</p></sec><sec id="S5"><title>Within-participant variability in vividness, motivation, and perceived effort do not predict across-sessions generalisability of a classifier that decodes imagined finger movements</title><p id="P15">In comparison to overt finger movements or tactile stimulation, motor imagery has a higher cognitive component that may increase variability in task performance both within and across participants. We thus investigated whether session-to-session variations in attentional and cognitive processes could explain the scores obtained from generalising a classifier across sessions. We calculated the absolute difference score from session 1 to session 2 for the subjective measures of vividness during motor imagery, perceived motivation, and effort. We then used these difference scores as fixed effects in a multiple linear regression to predict the average across-sessions motor imagery classification accuracy in the S1 hand area. This model did not reach significance (<italic>F</italic><sub>(3,12)</sub> = 1.87, <italic>p</italic> = .19, multiple <italic>r</italic><sup>2</sup> = .32; vividness: <italic>t</italic> = 0.46, <italic>p</italic> = .65; motivation: <italic>t</italic> = -1.21, <italic>p</italic> = .25, effort: <italic>t</italic> = -1.77, <italic>p</italic> = .10).</p><p id="P16">We then investigated whether the subjective measures would predict the within-session classification accuracy score, using the average of the subjective measures of both sessions as predictors, and found that motivation significantly predicted the average within-session classification accuracy (<italic>t</italic> = 2.44, <italic>p</italic> = .03). Vividness (<italic>t</italic> = -0.90, <italic>p</italic> = .39) and effort (<italic>t</italic> = .68, <italic>p</italic> = .51) did not reach significance (model: <italic>F</italic><sub>(3,12)</sub> = 5.05, <italic>p</italic> = .02, multiple <italic>r</italic><sup>2</sup> = .56).</p></sec><sec id="S6"><title>Neural similarity of finger representations activated through motor imagery vs. motor execution</title><p id="P17">Finally, we investigated the neural similarity between activity patterns elicited by individual imagined and executed finger movements. We used an across-task decoding analysis and trained a classifier on all data of one task in one session and tested it then on all data of the other task in either the same (within session) or other session (across sessions). This analysis revealed that we could successfully decode individual fingers across tasks, as indicated by classification accuracies significantly above the empirical chance level (all p &lt; .0001; <xref ref-type="fig" rid="F4">Fig. 4</xref>). We found that a classifier trained on motor imagery generalises better to motor execution, than vice versa (significant main effect of <italic>Task</italic>: <italic>F</italic><sub>(1,45)</sub> = 225.53, <italic>p</italic> &lt; .0001). Within- and across-sessions classification accuracy did not differ (non-significant main effect <italic>Comparison</italic>: <italic>F</italic><sub>(1,45)</sub> = 0.09, <italic>p</italic> = .77; non-significant interaction effect: <italic>F</italic><sub>(1,45)</sub> = 0.07, <italic>p</italic> = .79). Similar results were obtained for the M1 hand area (<xref ref-type="supplementary-material" rid="SD1">Supplementary Fig. 7</xref>). These findings show that motor imagery and motor execution activate finger representations containing mutual information in their finger-specific vertex-wise activity patterns.</p></sec></sec><sec id="S7" sec-type="discussion"><title>Discussion</title><p id="P18">In this study, we investigated the spatial consistency of finger representations activated through motor imagery over time. Our results show that both finger-selective activity clusters and the full intricate activity patterns associated with individual imagined finger movements were highly consistent across two fMRI sessions. The finding that motor imagery reliably activated finger representations is particularly striking given the highly unsupervised nature of the task. Notably, the level of consistency of finger representations activated through motor imagery was comparable to motor execution. Furthermore, an across-task decoding analysis revealed that motor imagery and motor execution activated finger representations that contained shared information in their underlying activity patterns, indicating neural similarity between these representations.</p><p id="P19">Using univariate and multivariate analyses, we found high within-participant consistency in finger representations activated through motor imagery in both S1 and M1. These findings align with the results of previous (<xref ref-type="bibr" rid="R18">Ejaz et al., 2015</xref>; <xref ref-type="bibr" rid="R43">Kolasinski et al., 2016</xref>) and the current study showing highly reproducible finger representations activated through motor execution, which we used as a benchmark for comparing our motor imagery findings. In line with the results from univariate analysis of motor execution finger representations reported in <xref ref-type="bibr" rid="R43">Kolasinski et al. (2016)</xref>, we found that the spatial correspondence of finger-selective activity clusters in S1 for the same motor imagery finger representations across sessions was higher compared to different finger pairs, representing a hallmark of somatotopic organisation (<xref ref-type="bibr" rid="R41">Kikkert et al., 2016</xref>; <xref ref-type="bibr" rid="R43">Kolasinski et al., 2016</xref>; <xref ref-type="bibr" rid="R61">Sanders et al., 2023</xref>). While <xref ref-type="bibr" rid="R43">Kolasinski et al. (2016</xref>) employed a travelling-wave paradigm, we created finger maps based on a blocked paradigm. Travelling-wave paradigms are powerful in detecting finger maps based on gradients from the thumb to the little finger. In contrast, blocked paradigms allow to investigate more detailed somatotopic information that account better for the spatial overlap of finger representations (<xref ref-type="bibr" rid="R9">Besle et al., 2013</xref>; <xref ref-type="bibr" rid="R42">Kikkert et al., 2021</xref>). Nevertheless, even based on blocked paradigms, winner-take-all approaches have limitations as they strongly depend on the (arbitrarily) chosen threshold and the specific conditions (in our case, fingers) that were tested (<xref ref-type="bibr" rid="R50">Muret et al., 2022</xref>; <xref ref-type="bibr" rid="R73">Wesselink et al., 2019</xref>). Indeed, despite minimal thresholding, motor imagery finger maps did not show finger-selective activity clusters for all tested fingers in every participant. To circumvent arbitrarily thresholding of winner-take-all approaches, and to account for low activity levels during motor imagery and largely overlapping finger representations, we used a multivariate decoding approach and examined whether the finger with which motor imagery (or motor execution) was performed could be predicted from the full activity patterns of single trials. Our results confirm high reproducibility of these activity patterns associated with individual fingers across sessions for both motor imagery and motor execution.</p><p id="P20">For finger representations activated through motor imagery, we found lower absolute values in spatial consistency compared to motor execution. This was evident in lower spatial correspondence of the same finger representations across sessions in the univariate analysis and in lower classification accuracy when decoding fingers within- and across-session. Multiple factors may have contributed to this effect. First, it is likely that the activity levels evoked by motor execution were higher, resulting in a better signal-to-noise-ratio and thus more clearly distinguishable activity patterns associated with individual fingers. Second, the motor execution task was more standardised compared to the motor imagery task. For motor execution, participants performed paced button presses. If participants started a trial with a delay, we corrected the trial onsets and if they accidentally moved with the wrong finger, we assigned the trial to that finger. In contrast, the motor imagery task was unsupervised, self-paced, and without clear instruction towards the specific motor imagery strategies. Suggested strategies included pressing a button, playing the piano, typing on keyboard, moving the finger up and down or left and right, or imagine pulses in the finger muscle. We did not restrict participants to use only one motor imagery strategy and left it open to change strategies from trial to trial or session to session (see <xref ref-type="supplementary-material" rid="SD1">Supplementary Table 1</xref> for instructions and self-reported strategies). These task differences may have resulted in higher variability in the motor imagery performance and thus resulting activity patterns. Third, top-down processes may be more affected by task compliance and attentional and cognitive processes compared to motor execution tasks, additionally contributing to more variability in motor imagery finger representations. Indeed, attention can greatly modulate finger representations measured with fMRI (<xref ref-type="bibr" rid="R58">Puckett et al., 2017</xref>) and vividness of imagined action has been shown to be reflected in more distinguishable top-down activated representations of hand actions (<xref ref-type="bibr" rid="R77">Zabicki et al., 2019</xref>). We found that session-to-session variability of perceived vividness of motor imagery, motivation and how exhausting the motor imagery task was perceived, did not predict the generalisability of a classifier across sessions, suggesting that top-down activated finger representations may be robust against small session-to-session fluctuations in attentional and cognitive processes. However, higher self-reported motivation scores were associated with higher decoding performance within session, indicating that motivation (and thus, task compliance) may indeed play a role. In summary, it is likely that an interplay of all processes contributed to lower classification accuracy and lower spatial overlap of finger-selective activity for motor imagery compared to motor execution. Nevertheless, higher classification accuracies may be achievable through training, as we have demonstrated that neurofeedback training for mental finger individuation results in more distinguishable activity patterns of individual imagined finger movements (<xref ref-type="bibr" rid="R52">Odermatt et al., 2024</xref>).</p><p id="P21">In the across-task decoding analysis, we found neural similarity between activity patterns elicited by imagined and executed finger movements. We have previously reported that motor imagery activates similar finger representations as motor execution in the primary sensorimotor cortex (<xref ref-type="bibr" rid="R52">Odermatt et al., 2024</xref>). Here, we extend this finding by showing high spatial consistency over time across tasks. Notably, the across-task decoding analysis performed better when trained on motor imagery and tested on motor execution, than vice versa. We speculate that the lower signal-to-noise-ratio and higher within-session variability in activity patterns elicited by motor imagery compared to motor execution (as described in the previous paragraph), may have contributed to this finding. If motor execution of individual fingers elicits highly consistent activity patterns across trials, a decoder trained on this data may exhibit decreased performance when tested on the more variable activity patterns of motor imagery (<xref ref-type="bibr" rid="R31">Hebart &amp; Baker, 2018</xref>). Sensorimotor representations activated through motor imagery are thought to be more sparse and widespread than motor execution patterns (<xref ref-type="bibr" rid="R76">Zabicki et al., 2017</xref>). While motor execution patterns may be encompassed within the broader motor imagery patterns, and thus be successfully predicted by a decoder trained on motor imagery patterns, the reverse case may be more challenging. These findings of our across-task decoding analysis add to the knowledge on neural equivalence of imagined and executed movements, which is relevant for the development of motor imagery training interventions aiming to improve sensorimotor functions.</p><p id="P22">In both motor imagery and execution, we found similar patterns of spatial consistency in S1 and M1, reaffirming their tight inter-connections and co-involvement not only in executed (<xref ref-type="bibr" rid="R53">Ogawa et al., 2019</xref>; <xref ref-type="bibr" rid="R61">Sanders et al., 2023</xref>; <xref ref-type="bibr" rid="R68">Umeda et al., 2019</xref>; <xref ref-type="bibr" rid="R73">Wesselink et al., 2019</xref>) but also imagined finger movements. While S1 activity during motor execution is modulated by the sensory feedback from finger movements, it has been shown that top-down processes elicit activity in the form of predicted sensory consequences prior to (and in the complete absence of) sensory input (<xref ref-type="bibr" rid="R5">Ariani et al., 2022</xref>; <xref ref-type="bibr" rid="R6">Bashford et al., 2021</xref>; <xref ref-type="bibr" rid="R21">Gale et al., 2021</xref>; <xref ref-type="bibr" rid="R34">Jafari et al., 2020</xref>; <xref ref-type="bibr" rid="R47">London &amp; Miller, 2013</xref>; <xref ref-type="bibr" rid="R68">Umeda et al., 2019</xref>). This top-down induced activity, or corollary discharge, in S1 is highly somatotopic with a topographic arrangement of individual fingers, while neuronal populations in M1 may be less selective towards individual fingers (<xref ref-type="bibr" rid="R3">Arbuckle et al., 2022</xref>; <xref ref-type="bibr" rid="R18">Ejaz et al., 2015</xref>; <xref ref-type="bibr" rid="R25">Graziano et al., 2002</xref>; <xref ref-type="bibr" rid="R32">Hluštík et al., 2001</xref>; <xref ref-type="bibr" rid="R39">Kakei et al., 1999</xref>; <xref ref-type="bibr" rid="R62">Schellekens et al., 2018</xref>; <xref ref-type="bibr" rid="R63">Schieber, 2001</xref>). Studying M1 and S1 separately is interesting due to their differences in somatotopic organisation. However, the exact delineation of M1 and S1 is challenging with 3T fMRI given the spatial resolution. Most previous studies investigated uni- and multivariate characteristics of finger representations using 7T fMRI (<xref ref-type="bibr" rid="R9">Besle et al., 2013</xref>, <xref ref-type="bibr" rid="R10">2014</xref>; <xref ref-type="bibr" rid="R23">Gooijers et al., 2022</xref>; <xref ref-type="bibr" rid="R43">Kolasinski et al., 2016</xref>; <xref ref-type="bibr" rid="R60">Sanchez-Panchuelo et al., 2010</xref>; <xref ref-type="bibr" rid="R61">Sanders et al., 2023</xref>; <xref ref-type="bibr" rid="R72">Wesselink et al., 2022</xref>) achieving a spatial resolution of ~ 1mm<sup>3</sup> (as opposed to 2.2 mm<sup>3</sup> in the present study). However, our results relating to the motor execution task are in line with studies using ultra-high field fMRI (<xref ref-type="bibr" rid="R18">Ejaz et al., 2015</xref>; <xref ref-type="bibr" rid="R43">Kolasinski et al., 2016</xref>), indicating that the similar findings obtained in S1 and M1 are not merely effects of the lower spatial resolution in our study, but likely attributable to the co-involvement of S1 and M1 during (imagined) finger movements.</p><p id="P23">Our results have implications for technologies relying on top-down processes to activate sensorimotor representations such as the control of BCIs, including neuroprosthetic devices. While top-down processes during fMRI assessments have been used for presurgical planning to optimally locate BCI target regions (<xref ref-type="bibr" rid="R17">Downey et al., 2024</xref>; <xref ref-type="bibr" rid="R45">Leinders et al., 2023</xref>), the reliability of these approaches to activate finger representations has not yet been explicitly studied. For BCI localisation, attempted movements are typically employed, as they were shown to result in higher blood oxygen level dependent (BOLD) activity compared to motor imagery (<xref ref-type="bibr" rid="R33">Hotz-Boendermaker et al., 2008</xref>) and better discrimination of specific representations using intracortical recordings (<xref ref-type="bibr" rid="R71">Vargas-Irwin et al., 2018</xref>).</p><p id="P24">However, it is likely that some patients are unable to perform attempted movements. Our findings suggest that in these cases motor imagery can be used instead to reliably reveal finger maps. Additionally, our results validate the use of 3T fMRI to study and visualise top-down finger representations, which makes is more accessible in research and clinical settings than its 7T equivalent. The stability of top-down sensorimotor representations across sessions is promising for the use of decoding approaches that are intended for longer-term use. Finally, despite rather high variability across participants, similar as for finger representations activated through motor execution, we observed that motor imagery finger representations share some information across participants. This was evidenced in a decoding approach that successfully generalised across participants and implies that technologies focusing on decoding individual fingers, such as BCIs for fine-motor control, may benefit from pre-training with large datasets of multiple participants to improve performance.</p><p id="P25">Together, our results highlight the use of fMRI and multivariate analysis that takes into account the full activity pattern as a reliable method to study (top-down activated) finger representations in sensorimotor areas, also if a clearly ordered somatotopic organisation is lacking and activity levels are relatively low. We show that motor imagery, a mere top-down process, activates consistent finger representations over time. Additionally, we demonstrate that finger representations activated through motor imagery and motor execution contain mutual information. These findings not only validate the use of top-down processes for brain-computer interface control, but also have implications for the development of top-down training interventions targeting sensorimotor functions without relying on overt movements.</p></sec><sec id="S8" sec-type="methods"><title>Methods</title><p id="P26">The data used in this manuscript was published previously in <xref ref-type="bibr" rid="R52">Odermatt et al. (2024)</xref>. The focus of this already published manuscript lay on changes in finger representations of a neurofeedback intervention group compared to a control group that merely served to control for test-retest effects. In the current manuscript we explore the data of the control group in greater detail. The motor imagery and execution tasks, as well as fMRI acquisition and preprocessing in the current manuscript are therefore identical to <xref ref-type="bibr" rid="R52">Odermatt et al. (2024)</xref>. The relevant sections are reiterated below for the reader’s convenience.</p><sec id="S9" sec-type="subjects"><title>Participants</title><p id="P27">16 volunteers (age (mean ± SD): 26.4 ± 2.7 years; 8 females) participated in the current study. Inclusion criteria were: No use of medication acting on the central nervous system, no neurological and psychiatric disorders, right-handed according to the Edinburgh Handedness Inventory (<xref ref-type="bibr" rid="R54">Oldfield, 1971</xref>), normal or corrected-to-normal vision, and no MRI contraindications. All research procedures were approved by the Cantonal Ethics Committee Zurich (BASEC Nr. 2018-01078) and were conducted in accordance with the declaration of Helsinki. Written informed consent was provided by all participants prior to study onset.</p></sec><sec id="S10"><title>Experimental sessions</title><p id="P28">In this study, we report data collected in two identical fMRI sessions that took place on the same time of the day and at an interval of approximately two weeks (mean ± SD: 13.8 ± 6.2 days; range: 7 – 32 days). Prior to the first fMRI session, participants were screened for their ability to perform kinaesthetic motor imagery using the kinaesthetic subscale of the Movement Imagery Questionnaire – Revised second version (MIQ-RS) (<xref ref-type="bibr" rid="R26">Gregg et al., 2010</xref>; <xref ref-type="bibr" rid="R67">Thomschewski et al., 2017</xref>). None of the recruited participants exhibited a score below the defined cut-off that was set to 1 SD below the mean reported in <xref ref-type="bibr" rid="R26">Gregg et al. (2010)</xref>. In an experimental session prior to the first fMRI session, participants already performed kinaesthetic motor imagery of individual fingers (right thumb, index, or little finger) while we measured surface electromyography (EMG) in the left and right thumb, index, and little finger and applied transcranial magnetic stimulation (TMS) single- and paired-pulse testing protocols. In this pre-fMRI session, participants trained to imagine movements without making any actual movements or muscle contractions by receiving online visual feedback indicating if the EMG activity in any of the finger muscles exceeded 10 μV (<xref ref-type="bibr" rid="R52">Odermatt et al. 2024</xref>). Importantly, there was no experimental session between the two fMRI sessions.</p></sec><sec id="S11"><title>fMRI tasks</title><p id="P29">In the two fMRI sessions, we assessed brain activity during imagined and executed right hand finger movements. Participants viewed a fixation cross centred on a screen through a mirror mounted to the head coil. To restrict head motion, we used padded cushions. We first assessed four motor imagery runs using a blocked design with the conditions ‘Thumb’, ‘Index’, ‘Little’ and ‘Rest’ (block length = 7.5 s; each condition presented 12 x per run in counterbalanced order; 9 min 8s per run; <xref ref-type="fig" rid="F5">Fig. 5</xref>). The verbal task instructions replaced the fixation cross for the duration of the trial. After each trial, the fixation cross reappeared for a jittered period of 3-4 s during which participants were instructed to rest, i.e., as during the rest trials. This additional rest period was included to facilitate switching between different fingers during the motor imagery task. We instructed participants to imagine, as vividly as possible, how it would feel to move the cued finger (see <xref ref-type="supplementary-material" rid="SD1">Supplementary Table 1a</xref> for verbatim instructions). Additionally, we reminded them to not contract any finger muscles, as trained in the pre-fMRI session with EMG activity control. An experimenter visually controlled for finger movements inside the scanner room. If any movements were detected, we stopped the run, instructed the participant to refrain from executing finger movements, and repeated the run. At the end of each motor imagery run, participants used a button box to move a cursor on a visual analogue scale (ranging 0-100) to rate, per finger, how vividly they felt they imagined the movements (verbal anchors: <italic>not vivid at all; felt as vivid as during real movements</italic>). At the end of the last motor imagery run, participants additionally rated their motivation (<italic>not motivated at all; perfectly motivated)</italic>, focus on motor imagery (<italic>not focused at all; perfectly focused)</italic>, and effort (<italic>not exhausting at all; extremely exhausting)</italic> during the session.</p><p id="P30">Following the motor imagery runs, we assessed six motor execution runs that consisted of a paced button press task and included the conditions ‘Thumb’, ‘Index’, ‘Middle’, ‘Ring’, ‘Little’, and ‘Rest’. We used a similar blocked paradigm as for motor imagery but did not provide any additional jittered rest periods between the movement trials (block length = 7.5 s; each condition presented 5 x per run in counterbalanced order; 4 min 5 s per run; <xref ref-type="fig" rid="F5">Fig. 5</xref>). The verbal task instructions cueing the condition appeared above the fixation cross. Participants placed their right index, ring, middle and little fingers on the buttons of a four-button response box, with the thumb placed on the side of the box. We instructed participants to press the button with the cued finger (or tap on the side of the button response box with the thumb) every time the fixation cross blinked (1.4 Hz).</p></sec><sec id="S12"><title>fMRI data acquisition</title><p id="P31">We used a 3T Siemens Magnetom Prisma scanner with a 64-channel head-neck coil (Siemens Healthcare, Erlangen, Germany) to acquire fMRI data. For the anatomical T1-weighted images, we used a Magnetization Prepared Rapid Gradient Echo (MPRAGE) protocol with the following acquisition parameters: 160 sagittal slices, resolution = 1.1 x 1.1 x 1 mm<sup>3</sup>, field of view (FOV) = 240 x 240 x 160 mm<sup>3</sup>, repetition time (TR) = 2300 ms, echo time (TE) = 2.25 ms, flip angle = 8°. For the task-fMRI data acquisition we used a multiband echo-planar-imaging (EPI) sequence covering the whole brain and the cerebellum with the following acquisition parameters: 66 transversal slices, resolution = 2.2 mm<sup>3</sup> isotropic, FOV = 210 x 210 x 145 mm<sup>3</sup>, TR = 846 ms, TE = 30 ms, flip angle = 56°, acceleration factor = 6, and echo spacing = 0.6 ms. We acquired 636 and 278 volumes for each of the motor imagery and motor execution runs, respectively. To measure B0 deviations we used a fieldmap with the same resolution and slice angle as the EPI sequence and the following acquisition parameters: TR = 649 ms, TE1 = 4.92 ms, TE2 = 7.38 ms.</p></sec><sec id="S13"><title>Data preprocessing and co-registration</title><p id="P32">For preprocessing and co-registration of fMRI data we used tools from FSL v5.0.7 (<ext-link ext-link-type="uri" xlink:href="http://fsl.fmrib.ox.ac.uk/fsl">http://fsl.fmrib.ox.ac.uk/fsl</ext-link>) and applied the following preprocessing steps to the fMRI data using FSL’s Expert Analysis Tool (FEAT): motion correction using MCFLIRT (<xref ref-type="bibr" rid="R37">Jenkinson et al., 2002</xref>), brain extraction using the automated brain extraction tool (BET) (<xref ref-type="bibr" rid="R66">Smith, 2002</xref>), spatial smoothing using a 3 mm full-width at half-maximum (FWHM) Gaussian kernel, and high-pass temporal filtering with a 100 s cut-off. Using BET and/or Advanced Normalization Tools (ANTs) v2.3.5 (<ext-link ext-link-type="uri" xlink:href="http://stnava.github.io/ANTs">http://stnava.github.io/ANTs</ext-link>) we removed non-brain tissue from the T1-weighted images of two fMRI sessions and created binarized masks of the extracted brains. We then performed image co-registration in separate, visually inspected steps. For each participant, we created a mid-space, i.e., an average space, between the T1-weighted images of both sessions and its binarized brain masks. We then used the mid-space brain mask to brain extract the mid-space T1-weighted image. By using this T1-weighted mid-space for co-registration we ensured that the extent of reorientation required in the registration from functional to structural data was equal in both fMRI sessions. We then aligned functional data to the brain-extracted T1-weighted mid-space, initially using six degrees of freedom and the mutual information cost function, and then optimised using boundary-based registration (BBR) (<xref ref-type="bibr" rid="R27">Greve &amp; Fischl, 2009</xref>). To correct for B0 distortions, we constructed a fieldmap for B0 unwarping and added it to the registration. For one participant that we took out of the scanner for a brief break during the first fMRI session, we applied the fieldmap only to the functional runs that were acquired with the same head position as the fieldmap.</p></sec><sec id="S14"><title>General Linear Models</title><sec id="S15"><title>Univariate analysis</title><p id="P33">To assess univariate task-related activity of motor imagery and execution, we carried out time-series statistical analysis per run using FMRIB’s Improved Linear Model (FILM) with local autocorrelation, as implemented in FSL’s FEAT. We defined one regressor of interest for each individual finger (i.e., for motor imagery: thumb, index, and little finger; for motor execution: thumb, index, middle, ring, and little finger) and obtained parameter estimates using a GLM based on the gamma hemodynamic response function (HRF) and its temporal derivatives. For motor execution, we examined the recorded button presses of each trial to control whether participants used the instructed finger to tap the button and adjusted the finger movement regressors if necessary: If the switch to the next cued finger in a new trial was delayed, then we adjusted the corresponding block lengths and the onset of the next trial. If the button of a non-instructed finger was pressed during a trial, then we adjusted the regressors such that the trial was assigned to this non-instructed, moving, finger. To reduce noise, we added nuisance regressors for the six motion parameters (rotation and translation along the x, y, and z-axis), and white matter and cerebrospinal fluid time series to the GLM. We further assessed the data for excessive head motion and scrubbed volumes with an estimated absolute displacement greater than 1.1 mm (i.e., half of the functional voxel size; maximum percentage of volumes scrubbed in a run = 2.16 %).</p><p id="P34">We defined contrasts for each finger &gt; other fingers and averaged across runs at the individual participant level using fixed-effect analysis to obtain the winner-take-all z-statistic maps, i.e. finger-selective activity clusters, for each finger in native space. For motor execution, we created contrasts for all five fingers vs. the other fingers, and additionally, to compare the univariate analysis with motor imagery, for thumb &gt; index and little finger, index &gt; thumb and little finger, and little finger &gt; thumb and index finger.</p></sec><sec id="S16"><title>&gt;Multivariate analysis</title><p id="P35">For multivariate pattern analysis (MVPA), we computed single-trial parameter estimates using an HRF-based first-level GLM in SPM12 (<ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm/">http://www.fil.ion.ucl.ac.uk/spm/</ext-link>) using SPM’s default parameters, and disabled implicit masking based on the global mean intensity. The design matrix consisted of individual regressors for each motor imagery and motor execution trial based on the run-wise regressors described in the previous paragraph. This resulted in 48 parameter estimates per finger, session, and participant for motor imagery, and 30 for motor execution (unless the motor execution trials were adjusted as described in the previous paragraph). Additionally, we included the temporal derivatives and the same nuisance regressors as in the GLM for univariate analysis.</p><p id="P36">To directly compare the MVPA results in motor imagery with motor execution, we computed a second GLM for the motor execution runs with individual regressors for all thumb, index, and little finger trials, and regressors of no interest that included all middle and ring finger trials.</p></sec></sec><sec id="S17"><title>Surface projections</title><p id="P37">For optimal co-registration and functional signal alignment across participants, we projected all contrast and parameter estimate maps to the cortical surface, using FreeSurfer v6.0 (<xref ref-type="bibr" rid="R14">Dale et al., 1999</xref>; <xref ref-type="bibr" rid="R19">Fischl, 2012</xref>) and Connectome Workbench v1.3.2 (<xref ref-type="bibr" rid="R48">Marcus et al., 2011</xref>). First, we reconstructed the cortical surface of each individual participant’s T1-weighted mid-space image. Following visual inspection of the pial and white matter reconstruction, we corrected any pial surface errors by manually adjusting the individual participant’s brain mask image. Then, we projected the winner-take-all z-statistic maps obtained from each individual participant’s fixed-effect analysis and the single-trial parameter estimate maps to the individual surface using cortical-ribbon mapping. Finally, we resampled the maps to the HCP fsLR-32k surface template brain (<xref ref-type="bibr" rid="R70">Van Essen et al., 2012</xref>).</p></sec><sec id="S18"><title>Regions of interest</title><p id="P38">Regions of interest (ROIs) were anatomically defined on the fsLR-32k surface template brain. For the univariate analysis (spatial overlap analysis), we defined contralateral M1 as Brodmann area (BA) 4, and S1 as BA 1, 2, 3a and 3b from the parcellation of <xref ref-type="bibr" rid="R22">Glasser et al. (2016</xref>). For MVPA, we used the contralateral M1 and S1 hand area masks covering 2 cm above and below the anatomical hand knob area (as made available by the Diedrichsen Lab on <ext-link ext-link-type="uri" xlink:href="https://github.com/DiedrichsenLab/fs_LR_32">https://github.com/DiedrichsenLab/fs_LR_32</ext-link>). Our exploratory analyses included secondary motor areas, namely supplementary motor area (SMA), ventral premotor cortex (PMv), and dorsal premotor cortex (PMd). As these secondary brain regions were slightly overlapping with the M1 mask obtained from the Glasser atlas, we removed any overlapping voxels from all ROIs to avoid a voxel being assigned to multiple ROIs.</p></sec><sec id="S19"><title>Spatial overlap analysis</title><p id="P39">The Dice Overlap Coefficient (DOC) (<xref ref-type="bibr" rid="R15">Dice, 1945</xref>) was used to quantify the spatial consistency of univariate finger-selective (or winner-take-all) motor imagery and motor execution maps across sessions and participants. The DOC calculates the spatial overlap between two representations relative to the total area of these representations and varies from 0 (no spatial correspondence between finger representations) to 1 (perfect spatial correspondence between finger representations). Where A and B are the areas of two finger representations, the DOC is expressed as:
<disp-formula id="FD1"><mml:math id="M1"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>x</mml:mi><mml:mo>|</mml:mo><mml:mi>A</mml:mi><mml:mstyle displaystyle="true"><mml:mo>∩</mml:mo></mml:mstyle><mml:mtext>​</mml:mtext><mml:mi>B</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>A</mml:mi><mml:mo>|</mml:mo><mml:mo>+</mml:mo><mml:mo>|</mml:mo><mml:mi>B</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p id="P40">We closely followed previously described procedures (<xref ref-type="bibr" rid="R24">Gozzi et al., 2024</xref>; <xref ref-type="bibr" rid="R41">Kikkert et al., 2016</xref>; <xref ref-type="bibr" rid="R43">Kolasinski et al., 2016</xref>; <xref ref-type="bibr" rid="R61">Sanders et al., 2023</xref>). We minimally thresholded (Z &gt; 2) the winner-take-all maps to obtain finger-selective activity clusters and masked these clusters using the ROIs (S1, M1, SMA, PMd, or PMv). We then used the in-vertex volume between the white matter and pial surfaces to calculate the volume covered by the thresholded representations and the resulting DOCs.</p><sec id="S20"><title>Within participant</title><p id="P41">To assess within-participant consistency of univariate finger maps, we calculated the DOC for all possible finger pairings across the two fMRI sessions per participant. We then categorised the finger pairs in ‘same’, ‘neighbouring’ and ‘non-neighbouring’. A benchmark for finger-selectivity identified in univariate finger maps is greater DOC for the same finger representations than for neighbouring finger pairs, followed by non-neighbouring finger pairs (<xref ref-type="bibr" rid="R41">Kikkert et al., 2016</xref>; <xref ref-type="bibr" rid="R61">Sanders et al., 2023</xref>). Here, we investigated whether there is such spatial correspondence in the finger-selectivity across two fMRI sessions for motor imagery finger representations and whether it differed from motor execution. If spatial correspondence is high across two sessions, the DOC is higher for the same finger representations across sessions compared to neighbouring and non-neighbouring representations. To investigate how the choice of threshold influences the spatial overlap results, the DOC was further calculated as a function of Z-thresholds ranging from 1.4 to 3.2 (see <xref ref-type="supplementary-material" rid="SD1">Supplementary Fig. 2 and Supplementary Fig. 3</xref>).</p></sec><sec id="S21"><title>Within vs. across participants</title><p id="P42">To investigate the spatial correspondence of finger maps across participants, we calculated the DOC for all possible finger pairs and participants across sessions and constructed an across-participants DOC comparison matrix (48 x 48 for motor imagery and motor execution with three fingers; 80 x 80 for motor execution with five fingers), similar to <xref ref-type="bibr" rid="R43">Kolasinski et al., (2016</xref>). The across-participants matrix consisted of submatrices (16 x 16) containing the DOC for the 16 participants for each possible finger pair. We then calculated the matrix dominance ratio (Mdr) for each submatrix (i.e., each finger pair) by dividing the average of the diagonal (i.e., DOCs of the same participant) to the average of the off-diagonal (i.e., DOCs across different participant pairs). Values &gt; 1 indicate higher overlap of finger representations within the same participants than across participants. We then computed the overall Mdr by calculating a higher-order Mdr of the Mdr scores in the submatrices. Here, a value &gt; 1 indicates a matrix dominance for spatial correspondence of ‘same’ finger representations compared to ‘different’ (i.e., neighbouring and non-neighbouring) finger pairs. To obtain a p-value indicating significance of the overall Mdr value, we applied bootstrap resampling (n = 10’000) to the across-participants DOC comparison matrix.</p></sec></sec><sec id="S22"><title>Multivariate pattern analysis</title><p id="P43">While the (univariate) spatial overlap analysis gives insight into the consistency of winner-take-all finger-specific activity clusters across sessions and participants, it does not account for the full activity pattern associated with individual (imagined) finger movements. In contrast, MVPA allows to examine the spatial consistency of the full intricate activity patterns associated with individual (imagined) finger movements. Here, we used multivariate classification analysis to decode the instructed finger during motor imagery (or motor execution) from the single-trial parameter estimates in a specific ROI (S1 hand area, M1 hand area, SMA, PMd, or PMv), using the scikit-learn python library (<xref ref-type="bibr" rid="R1">Abraham et al., 2014</xref>). To prepare the data set, we extracted the single-trial parameter estimates corresponding to the vertices in a ROI using nibabel (<xref ref-type="bibr" rid="R11">Brett et al., 2024</xref>). We then scaled the data across all motor imagery (or motor execution) runs for each session and participant separately with the StandardScaler from scikit-learn to remove the mean and scale to unit variance within each vertex. Next, we performed the classification analysis using a Support Vector Machine (SVM) with a linear kernel and default parameters of C = 1 and l2 regularisation.</p><sec id="S23"><title>Within session</title><p id="P44">Within each session, and separately for each participant, we conducted a leave-one-run-out cross-validation. We evaluated the classifier performance based on the classification accuracy averaged across cross-validation folds and labels. To compare the actual and predicted labels, we averaged the confusion matrices obtained from each cross-validation fold. To define chance level, we generated a null distribution based on 1000 random permutations of the trial labels. We then computed an empirical p-value by dividing the number of permutation-based classification accuracies that were greater than or equal to the true score +1, by the number of permutations + 1 as implemented in scikit-learn. Finally, we averaged the classification accuracies, confusion matrices and empirical p-values across the two sessions for each participant.</p></sec><sec id="S24"><title>Across sessions</title><p id="P45">To investigate whether a classifier trained on one session within a participant generalised to data acquired in another session, we performed an across-sessions decoding analysis. For that, we fitted a linear SVM on all data of the first session and tested it on all trials of the second session, and vice versa. To determine the empirical chance level and p-values, we shuffled the labels of the test set using 1000 permutations. We then averaged the two classification accuracies, confusion matrices and p-values for each participant.</p></sec><sec id="S25"><title>Across participants</title><p id="P46">To test whether a classifier may generalise across participants, we conducted a leave-one-participant-out cross-validation pooling the data of both sessions together. This analysis resulted in only one value indicating classification accuracy on ‘group level’.</p></sec><sec id="S26"><title>Across tasks</title><p id="P47">Finally, to examine the neural similarity of activity patterns associated with individual fingers elicited by the motor imagery vs. the motor execution task, we trained a classifier on data of one task and tested it on data of the other task. We performed this across-tasks decoding analysis within-and across-sessions.</p></sec></sec><sec id="S27"><title>Data analysis</title><p id="P48">For statistical analyses we used R v.4.3.1 (R Core Team, Vienna, Austria) and JASP v. 0.18.3 (JASP Team 2024, Netherlands). To determine statistical significance of classification accuracy at group level, i.e., whether classification accuracy is significantly above the empirical chance level, we combined the empirical p-values across participants using Fisher’s method (<xref ref-type="bibr" rid="R20">Fisher, 1992</xref>). To compare within-session to across-session accuracy, we used paired t-tests (or non-parametric Wilcoxon signed-rank tests if normality was violated according to the Shapiro-Wilk test). To compare within-session or across-session accuracy to across-participants accuracy (that consisted of only one value per ROI), we used one-sample t-tests.</p><p id="P49">To examine the effects and interaction of tasks and conditions on DOC and classification accuracy, we used lme4 (<xref ref-type="bibr" rid="R7">Bates et al., 2015</xref>) for linear mixed-effects models. We defined all factors <italic>(Task</italic> (motor imagery, motor execution); <italic>Finger-pair</italic> (same, neighbour, non-neighbour); <italic>Comparison</italic> (within-session, across-sessions); <italic>Prediction</italic> (correctly classified, misclassified as neighbouring finger, misclassified as non-neighbouring finger) as fixed effects and participant as random effect. For each model, we evaluated the expected against observed residuals for uniform distribution using the R package DHARMA (<xref ref-type="bibr" rid="R30">Hartig, 2022</xref>). If violations were detected (which was the case for the models on DOC in both S1 and M1), we used glmmTMB (<xref ref-type="bibr" rid="R12">Brooks et al., 2017</xref>) instead, which allows the dispersion parameter of the linear mixed-effects model to vary with the different levels of the factors. If the linear mixed-effects models revealed significant main effects or interaction, we computed post-hoc contrasts using emmeans (<xref ref-type="bibr" rid="R46">Lenth, 2024</xref>).</p><p id="P50">To examine whether subjective measures of attentional and cognitive states (i.e., vividness of motor imagery averaged across the three fingers and the four runs, motivation, focus and effort; see <xref ref-type="supplementary-material" rid="SD1">Supplementary Table 2</xref> for differences in the subjective measures across the two sessions) were associated with within-session classification accuracy, we performed linear regressions on the average within-session classification accuracy using the average of the subjective measures reported in both sessions. To assess potential multicollinearity of fixed effects, we examined the VIF (Variance Inflation Factor). Due to high multicollinearity, we excluded the predictor with the highest VIF (focus: VIF = 9.76), and rerun the model, resulting in low (i.e., &lt; 5; <xref ref-type="bibr" rid="R35">James et al., 2021</xref>) multicollinearity of predictors (vividness = 2.87, effort = 2.87, motivation = 2.59). To evaluate whether changes in the subjective measures predict the generalisibility of a classifier across sessions we calculated session 2 minus session 1 difference scores per subjective measure and included these as fixed effects in the model. The average score of the across-sessions classification accuracy was the dependent variable. Multicollinearity was again high (focus: VIF = 25.96). After excluding focus, VIFs were &lt; 5 for the remaining predictors (vividness = 1.87, effort = 1.11, motivation = 1.76).</p><p id="P51">The significance level alpha was set to 0.05 for all inferential tests. We corrected the p-values for multiple comparisons using the Bonferroni Holmes method within each ROI. For non-significant results, we further used Bayesian tests with default settings in JASP to provide evidence for or against the null hypothesis and reported the Bayes factor BF<sub>10</sub> following conventional cut-offs (<xref ref-type="bibr" rid="R16">Dienes, 2014</xref>): BF<sub>10</sub> &lt; 0.1: strong evidence for the null hypothesis; BF<sub>10</sub> &lt; .33: moderate evidence for the null hypothesis, BF<sub>10</sub> &lt; 1: anecdotal evidence for the null hypothesis, BF<sub>10</sub> = 1: no evidence.</p></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary Materials</label><media xlink:href="EMS202013-supplement-supplementary_Materials.pdf" mimetype="application" mime-subtype="pdf" id="d17aAcEbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S28"><title>Acknowledgements</title><p>We thank all participants of the study, the Swiss Center for Musculoskeletal Imaging (SCMI) at Balgrist Campus for support with fMRI data acquisition, and Lukas Graz for his advice on statistical analysis. This project is supported by the Swiss National Science Foundation Grant 32003B_207719, and the National Research Foundation, Prime Minister’s Office, Singapore under its Campus for Research Excellence and Technological Enterprise (CREATE) program (FHT), S.K. is supported by the Swiss National Science Foundation Ambizione Grant (PZ00P3_208996).</p></ack><ref-list><ref id="R1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abraham</surname><given-names>A</given-names></name><name><surname>Pedregosa</surname><given-names>F</given-names></name><name><surname>Eickenberg</surname><given-names>M</given-names></name><name><surname>Gervais</surname><given-names>P</given-names></name><name><surname>Mueller</surname><given-names>A</given-names></name><name><surname>Kossaifi</surname><given-names>J</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Thirion</surname><given-names>B</given-names></name><name><surname>Varoquaux</surname><given-names>G</given-names></name></person-group><article-title>Machine learning for neuroimaging with scikit-learn</article-title><source>Frontiers in Neuroinformatics</source><year>2014</year><volume>8</volume><pub-id pub-id-type="pmcid">PMC3930868</pub-id><pub-id pub-id-type="pmid">24600388</pub-id><pub-id pub-id-type="doi">10.3389/fninf.2014.00014</pub-id></element-citation></ref><ref id="R2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andersen</surname><given-names>RA</given-names></name><name><surname>Aflalo</surname><given-names>T</given-names></name></person-group><article-title>Preserved cortical somatotopic and motor representations in tetraplegic humans</article-title><source>Current Opinion in Neurobiology</source><year>2022</year><volume>74</volume><elocation-id>102547</elocation-id><pub-id pub-id-type="pmcid">PMC9167753</pub-id><pub-id pub-id-type="pmid">35533644</pub-id><pub-id pub-id-type="doi">10.1016/j.conb.2022.102547</pub-id></element-citation></ref><ref id="R3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arbuckle</surname><given-names>SA</given-names></name><name><surname>Pruszynski</surname><given-names>JA</given-names></name><name><surname>Diedrichsen</surname><given-names>J</given-names></name></person-group><article-title>Mapping the Integration of Sensory Information across Fingers in Human Sensorimotor Cortex</article-title><source>Journal of Neuroscience</source><year>2022</year><volume>42</volume><issue>26</issue><fpage>5173</fpage><lpage>5185</lpage><pub-id pub-id-type="pmcid">PMC9236287</pub-id><pub-id pub-id-type="pmid">35606141</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2152-21.2022</pub-id></element-citation></ref><ref id="R4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arbuckle</surname><given-names>SA</given-names></name><name><surname>Weiler</surname><given-names>J</given-names></name><name><surname>Kirk</surname><given-names>EA</given-names></name><name><surname>Rice</surname><given-names>CL</given-names></name><name><surname>Schieber</surname><given-names>M</given-names></name><name><surname>Pruszynski</surname><given-names>JA</given-names></name><name><surname>Ejaz</surname><given-names>N</given-names></name><name><surname>Diedrichsen</surname><given-names>J</given-names></name></person-group><article-title>Structure of Population Activity in Primary Motor Cortex for Single Finger Flexion and Extension</article-title><source>Journal of Neuroscience</source><year>2020</year><volume>40</volume><issue>48</issue><fpage>9210</fpage><lpage>9223</lpage><pub-id pub-id-type="pmcid">PMC7687056</pub-id><pub-id pub-id-type="pmid">33087474</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0999-20.2020</pub-id></element-citation></ref><ref id="R5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ariani</surname><given-names>G</given-names></name><name><surname>Pruszynski</surname><given-names>JA</given-names></name><name><surname>Diedrichsen</surname><given-names>J</given-names></name></person-group><article-title>Motor planning brings human primary somatosensory cortex into action-specific preparatory states</article-title><source>eLife</source><year>2022</year><volume>11</volume><elocation-id>e69517</elocation-id><pub-id pub-id-type="pmcid">PMC8786310</pub-id><pub-id pub-id-type="pmid">35018886</pub-id><pub-id pub-id-type="doi">10.7554/eLife.69517</pub-id></element-citation></ref><ref id="R6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bashford</surname><given-names>L</given-names></name><name><surname>Rosenthal</surname><given-names>I</given-names></name><name><surname>Kellis</surname><given-names>S</given-names></name><name><surname>Pejsa</surname><given-names>K</given-names></name><name><surname>Kramer</surname><given-names>D</given-names></name><name><surname>Lee</surname><given-names>B</given-names></name><name><surname>Liu</surname><given-names>C</given-names></name><name><surname>Andersen</surname><given-names>RA</given-names></name></person-group><article-title>The Neurophysiological Representation of Imagined Somatosensory Percepts in Human Cortex</article-title><source>Journal of Neuroscience</source><year>2021</year><volume>41</volume><issue>10</issue><fpage>2177</fpage><lpage>2185</lpage><pub-id pub-id-type="pmcid">PMC8018772</pub-id><pub-id pub-id-type="pmid">33483431</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2460-20.2021</pub-id></element-citation></ref><ref id="R7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bates</surname><given-names>D</given-names></name><name><surname>Mächler</surname><given-names>M</given-names></name><name><surname>Bolker</surname><given-names>B</given-names></name><name><surname>Walker</surname><given-names>S</given-names></name></person-group><article-title>Fitting Linear Mixed-Effects Models Using lme4</article-title><source>Journal of Statistical Software</source><year>2015</year><volume>67</volume><fpage>1</fpage><lpage>48</lpage><pub-id pub-id-type="doi">10.18637/jss.v067.i01</pub-id></element-citation></ref><ref id="R8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berlot</surname><given-names>E</given-names></name><name><surname>Prichard</surname><given-names>G</given-names></name><name><surname>O’Reilly</surname><given-names>J</given-names></name><name><surname>Ejaz</surname><given-names>N</given-names></name><name><surname>Diedrichsen</surname><given-names>J</given-names></name></person-group><article-title>Ipsilateral finger representations in the sensorimotor cortex are driven by active movement processes, not passive sensory input</article-title><source>Journal of Neurophysiology</source><year>2019</year><volume>121</volume><issue>2</issue><fpage>418</fpage><lpage>426</lpage><pub-id pub-id-type="pmcid">PMC6397402</pub-id><pub-id pub-id-type="pmid">30517048</pub-id><pub-id pub-id-type="doi">10.1152/jn.00439.2018</pub-id></element-citation></ref><ref id="R9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Besle</surname><given-names>J</given-names></name><name><surname>Sánchez-Panchuelo</surname><given-names>R-M</given-names></name><name><surname>Bowtell</surname><given-names>R</given-names></name><name><surname>Francis</surname><given-names>S</given-names></name><name><surname>Schluppeck</surname><given-names>D</given-names></name></person-group><article-title>Single-subject fMRI mapping at 7 T of the representation of fingertips in S1: A comparison of event-related and phase-encoding designs</article-title><source>Journal of Neurophysiology</source><year>2013</year><volume>109</volume><issue>9</issue><fpage>2293</fpage><lpage>2305</lpage><pub-id pub-id-type="pmcid">PMC3652218</pub-id><pub-id pub-id-type="pmid">23427300</pub-id><pub-id pub-id-type="doi">10.1152/jn.00499.2012</pub-id></element-citation></ref><ref id="R10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Besle</surname><given-names>J</given-names></name><name><surname>Sánchez-Panchuelo</surname><given-names>R-M</given-names></name><name><surname>Bowtell</surname><given-names>R</given-names></name><name><surname>Francis</surname><given-names>S</given-names></name><name><surname>Schluppeck</surname><given-names>D</given-names></name></person-group><article-title>Event-related fMRI at 7T reveals overlapping cortical representations for adjacent fingertips in S1 of individual subjects</article-title><source>Human Brain Mapping</source><year>2014</year><volume>35</volume><issue>5</issue><fpage>2027</fpage><lpage>2043</lpage><pub-id pub-id-type="pmcid">PMC4216413</pub-id><pub-id pub-id-type="pmid">24014446</pub-id><pub-id pub-id-type="doi">10.1002/hbm.22310</pub-id></element-citation></ref><ref id="R11"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Brett</surname><given-names>M</given-names></name><name><surname>Markiewicz</surname><given-names>CJ</given-names></name><name><surname>Hanke</surname><given-names>M</given-names></name><name><surname>Côté</surname><given-names>M-A</given-names></name><name><surname>Cipollini</surname><given-names>B</given-names></name><name><surname>McCarthy</surname><given-names>P</given-names></name><name><surname>Jarecka</surname><given-names>D</given-names></name><name><surname>Cheng</surname><given-names>CP</given-names></name><name><surname>Larson</surname><given-names>E</given-names></name><name><surname>Halchenko</surname><given-names>YO</given-names></name><name><surname>Cottaar</surname><given-names>M</given-names></name><etal/></person-group><source>nipy/nibabel: 521</source><publisher-name>Zenodo</publisher-name><year>2024</year><comment>(Version 5.2.1) [Computer software]</comment><pub-id pub-id-type="doi">10.5281/zenodo.10714563</pub-id></element-citation></ref><ref id="R12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brooks</surname><given-names>ME</given-names></name><name><surname>Kristensen</surname><given-names>K</given-names></name><name><surname>van Benthem</surname><given-names>KJ</given-names></name><name><surname>Magnusson</surname><given-names>A</given-names></name><name><surname>Berg</surname><given-names>CW</given-names></name><name><surname>Nielsen</surname><given-names>A</given-names></name><name><surname>Skaug</surname><given-names>HJ</given-names></name><name><surname>Machler</surname><given-names>M</given-names></name><name><surname>Bolker</surname><given-names>BM</given-names></name></person-group><article-title>glmmTMB balances speed and flexibility among packages for zero-inflated generalized linear mixed modeling</article-title><source>The R Journal</source><year>2017</year><volume>9</volume><issue>2</issue><fpage>378</fpage><lpage>400</lpage><pub-id pub-id-type="doi">10.3929/ethz-b-000240890</pub-id></element-citation></ref><ref id="R13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bruurmijn</surname><given-names>MLCM</given-names></name><name><surname>Pereboom</surname><given-names>IPL</given-names></name><name><surname>Vansteensel</surname><given-names>MJ</given-names></name><name><surname>Raemaekers</surname><given-names>MAH</given-names></name><name><surname>Ramsey</surname><given-names>NF</given-names></name></person-group><article-title>Preservation of hand movement representation in the sensorimotor areas of amputees</article-title><source>Brain</source><year>2017</year><volume>140</volume><issue>12</issue><fpage>3166</fpage><lpage>3178</lpage><pub-id pub-id-type="pmcid">PMC6411136</pub-id><pub-id pub-id-type="pmid">29088322</pub-id><pub-id pub-id-type="doi">10.1093/brain/awx274</pub-id></element-citation></ref><ref id="R14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dale</surname><given-names>AM</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Sereno</surname><given-names>MI</given-names></name></person-group><article-title>Cortical Surface-Based Analysis: I. Segmentation and Surface Reconstruction</article-title><source>NeuroImage</source><year>1999</year><volume>9</volume><issue>2</issue><fpage>179</fpage><lpage>194</lpage><pub-id pub-id-type="pmid">9931268</pub-id></element-citation></ref><ref id="R15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dice</surname><given-names>LR</given-names></name></person-group><article-title>Measures of the Amount of Ecologic Association Between Species</article-title><source>Ecology</source><year>1945</year><volume>26</volume><issue>3</issue><fpage>297</fpage><lpage>302</lpage><pub-id pub-id-type="doi">10.2307/1932409</pub-id></element-citation></ref><ref id="R16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dienes</surname><given-names>Z</given-names></name></person-group><article-title>Using Bayes to get the most out of non-significant results</article-title><source>Frontiers in Psychology</source><year>2014</year><volume>5</volume><pub-id pub-id-type="pmcid">PMC4114196</pub-id><pub-id pub-id-type="pmid">25120503</pub-id><pub-id pub-id-type="doi">10.3389/fpsyg.2014.00781</pub-id></element-citation></ref><ref id="R17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Downey</surname><given-names>JE</given-names></name><name><surname>Schone</surname><given-names>HR</given-names></name><name><surname>Foldes</surname><given-names>ST</given-names></name><name><surname>Greenspon</surname><given-names>C</given-names></name><name><surname>Liu</surname><given-names>F</given-names></name><name><surname>Verbaarschot</surname><given-names>C</given-names></name><name><surname>Biro</surname><given-names>D</given-names></name><name><surname>Satzer</surname><given-names>D</given-names></name><name><surname>Moon</surname><given-names>CH</given-names></name><name><surname>Coffman</surname><given-names>BA</given-names></name><name><surname>Youssofzadeh</surname><given-names>V</given-names></name><etal/></person-group><article-title>A roadmap for implanting microelectrode arrays to evoke tactile sensations through intracortical microstimulation</article-title><source>medRxiv</source><year>2024</year><elocation-id>2024.04.26.24306239</elocation-id><pub-id pub-id-type="pmcid">PMC11669040</pub-id><pub-id pub-id-type="pmid">39720868</pub-id><pub-id pub-id-type="doi">10.1002/hbm.70118</pub-id></element-citation></ref><ref id="R18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ejaz</surname><given-names>N</given-names></name><name><surname>Hamada</surname><given-names>M</given-names></name><name><surname>Diedrichsen</surname><given-names>J</given-names></name></person-group><article-title>Hand use predicts the structure of representations in sensorimotor cortex</article-title><source>Nature Neuroscience</source><year>2015</year><volume>18</volume><issue>7</issue><elocation-id>7</elocation-id><pub-id pub-id-type="pmid">26030847</pub-id></element-citation></ref><ref id="R19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischl</surname><given-names>B</given-names></name></person-group><article-title>FreeSurfer</article-title><source>Neuroimage</source><year>2012</year><volume>62</volume><issue>2</issue><fpage>774</fpage><lpage>781</lpage><pub-id pub-id-type="pmcid">PMC3685476</pub-id><pub-id pub-id-type="pmid">22248573</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.01.021</pub-id></element-citation></ref><ref id="R20"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fisher</surname><given-names>RA</given-names></name></person-group><chapter-title>Statistical Methods for Research Workers</chapter-title><person-group person-group-type="editor"><name><surname>Kotz</surname><given-names>S</given-names></name><name><surname>Johnson</surname><given-names>NL</given-names></name></person-group><source>Breakthroughs in Statistics: Methodology and Distribution</source><publisher-name>Springer</publisher-name><year>1992</year><fpage>66</fpage><lpage>70</lpage><pub-id pub-id-type="doi">10.1007/978-1-4612-4380-9_6</pub-id></element-citation></ref><ref id="R21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gale</surname><given-names>DJ</given-names></name><name><surname>Flanagan</surname><given-names>JR</given-names></name><name><surname>Gallivan</surname><given-names>JP</given-names></name></person-group><article-title>Human Somatosensory Cortex Is Modulated during Motor Planning</article-title><source>Journal of Neuroscience</source><year>2021</year><volume>41</volume><issue>27</issue><fpage>5909</fpage><lpage>5922</lpage><pub-id pub-id-type="pmcid">PMC8265805</pub-id><pub-id pub-id-type="pmid">34035139</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0342-21.2021</pub-id></element-citation></ref><ref id="R22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glasser</surname><given-names>MF</given-names></name><name><surname>Coalson</surname><given-names>TS</given-names></name><name><surname>Robinson</surname><given-names>EC</given-names></name><name><surname>Hacker</surname><given-names>CD</given-names></name><name><surname>Harwell</surname><given-names>J</given-names></name><name><surname>Yacoub</surname><given-names>E</given-names></name><name><surname>Ugurbil</surname><given-names>K</given-names></name><name><surname>Andersson</surname><given-names>J</given-names></name><name><surname>Beckmann</surname><given-names>CF</given-names></name><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name><etal/></person-group><article-title>A multi-modal parcellation of human cerebral cortex</article-title><source>Nature</source><year>2016</year><volume>536</volume><issue>7615</issue><fpage>171</fpage><lpage>178</lpage><pub-id pub-id-type="pmcid">PMC4990127</pub-id><pub-id pub-id-type="pmid">27437579</pub-id><pub-id pub-id-type="doi">10.1038/nature18933</pub-id></element-citation></ref><ref id="R23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gooijers</surname><given-names>J</given-names></name><name><surname>Chalavi</surname><given-names>S</given-names></name><name><surname>Koster</surname><given-names>LK</given-names></name><name><surname>Roebroeck</surname><given-names>A</given-names></name><name><surname>Kaas</surname><given-names>A</given-names></name><name><surname>Swinnen</surname><given-names>SP</given-names></name></person-group><article-title>Representational similarity scores of digits in the sensorimotor cortex are associated with behavioral performance</article-title><source>Cerebral Cortex</source><year>2022</year><volume>32</volume><issue>17</issue><fpage>3848</fpage><lpage>3863</lpage><pub-id pub-id-type="pmid">35029640</pub-id></element-citation></ref><ref id="R24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gozzi</surname><given-names>N</given-names></name><name><surname>Chee</surname><given-names>L</given-names></name><name><surname>Odermatt</surname><given-names>I</given-names></name><name><surname>Kikkert</surname><given-names>S</given-names></name><name><surname>Preatoni</surname><given-names>G</given-names></name><name><surname>Valle</surname><given-names>G</given-names></name><name><surname>Pfender</surname><given-names>N</given-names></name><name><surname>Beuschlein</surname><given-names>F</given-names></name><name><surname>Wenderoth</surname><given-names>N</given-names></name><name><surname>Zipser</surname><given-names>C</given-names></name><name><surname>Raspopovic</surname><given-names>S</given-names></name></person-group><article-title>Wearable neuroprosthesis improves mobility and reduces pain in neuropathic participants</article-title><source>medRxiv</source><year>2024</year><elocation-id>2024.05.08.24306164</elocation-id><pub-id pub-id-type="doi">10.1101/2024.05.08.24306164</pub-id></element-citation></ref><ref id="R25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Graziano</surname><given-names>MSA</given-names></name><name><surname>Taylor</surname><given-names>CSR</given-names></name><name><surname>Moore</surname><given-names>T</given-names></name></person-group><article-title>Complex Movements Evoked by Microstimulation of Precentral Cortex</article-title><source>Neuron</source><year>2002</year><volume>34</volume><issue>5</issue><fpage>841</fpage><lpage>851</lpage><pub-id pub-id-type="pmid">12062029</pub-id></element-citation></ref><ref id="R26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gregg</surname><given-names>M</given-names></name><name><surname>Hall</surname><given-names>C</given-names></name><name><surname>Butler</surname><given-names>A</given-names></name></person-group><article-title>The MIQ-RS: A Suitable Option for Examining Movement Imagery Ability</article-title><source>Evidence-Based Complementary and Alternative Medicine</source><year>2010</year><volume>7</volume><issue>2</issue><fpage>249</fpage><lpage>257</lpage><pub-id pub-id-type="pmcid">PMC2862926</pub-id><pub-id pub-id-type="pmid">18955294</pub-id><pub-id pub-id-type="doi">10.1093/ecam/nem170</pub-id></element-citation></ref><ref id="R27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greve</surname><given-names>DN</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name></person-group><article-title>Accurate and robust brain image alignment using boundary-based registration</article-title><source>NeuroImage</source><year>2009</year><volume>48</volume><issue>1</issue><fpage>63</fpage><lpage>72</lpage><pub-id pub-id-type="pmcid">PMC2733527</pub-id><pub-id pub-id-type="pmid">19573611</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.06.060</pub-id></element-citation></ref><ref id="R28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guan</surname><given-names>C</given-names></name><name><surname>Aflalo</surname><given-names>T</given-names></name><name><surname>Kadlec</surname><given-names>K</given-names></name><name><surname>de Leon</surname><given-names>JG</given-names></name><name><surname>Rosario</surname><given-names>ER</given-names></name><name><surname>Bari</surname><given-names>A</given-names></name><name><surname>Pouratian</surname><given-names>N</given-names></name><name><surname>Andersen</surname><given-names>RA</given-names></name></person-group><article-title>Decoding and geometry of ten finger movements in human posterior parietal cortex and motor cortex</article-title><source>Journal of Neural Engineering</source><year>2023</year><volume>20</volume><issue>3</issue><elocation-id>036020</elocation-id><pub-id pub-id-type="pmcid">PMC10209510</pub-id><pub-id pub-id-type="pmid">37160127</pub-id><pub-id pub-id-type="doi">10.1088/1741-2552/acd3b1</pub-id></element-citation></ref><ref id="R29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guan</surname><given-names>C</given-names></name><name><surname>Aflalo</surname><given-names>T</given-names></name><name><surname>Zhang</surname><given-names>CY</given-names></name><name><surname>Amoruso</surname><given-names>E</given-names></name><name><surname>Rosario</surname><given-names>ER</given-names></name><name><surname>Pouratian</surname><given-names>N</given-names></name><name><surname>Andersen</surname><given-names>RA</given-names></name></person-group><article-title>Stability of motor representations after paralysis</article-title><source>eLife</source><year>2022</year><volume>11</volume><elocation-id>e74478</elocation-id><pub-id pub-id-type="pmcid">PMC9555862</pub-id><pub-id pub-id-type="pmid">36125116</pub-id><pub-id pub-id-type="doi">10.7554/eLife.74478</pub-id></element-citation></ref><ref id="R30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hartig</surname><given-names>F</given-names></name></person-group><article-title>DHARMa: Residual Diagnostics for Hierarchical (Multi-Level /Mixed) Regression Models</article-title><source>Rpackage version 046</source><year>2022</year><comment><ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=DHARMa">https://CRAN.R-project.org/package=DHARMa</ext-link></comment></element-citation></ref><ref id="R31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hebart</surname><given-names>MN</given-names></name><name><surname>Baker</surname><given-names>CI</given-names></name></person-group><article-title>Deconstructing multivariate decoding for the study of brain function</article-title><source>NeuroImage</source><year>2018</year><volume>180</volume><fpage>4</fpage><lpage>18</lpage><pub-id pub-id-type="pmcid">PMC5797513</pub-id><pub-id pub-id-type="pmid">28782682</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.08.005</pub-id></element-citation></ref><ref id="R32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hluštík</surname><given-names>P</given-names></name><name><surname>Solodkin</surname><given-names>A</given-names></name><name><surname>Gullapalli</surname><given-names>RP</given-names></name><name><surname>Noll</surname><given-names>DC</given-names></name><name><surname>Small</surname><given-names>SL</given-names></name></person-group><article-title>Somatotopy in Human Primary Motor and Somatosensory Hand Representations Revisited</article-title><source>Cerebral Cortex</source><year>2001</year><volume>11</volume><issue>4</issue><fpage>312</fpage><lpage>321</lpage><pub-id pub-id-type="pmid">11278194</pub-id></element-citation></ref><ref id="R33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hotz-Boendermaker</surname><given-names>S</given-names></name><name><surname>Funk</surname><given-names>M</given-names></name><name><surname>Summers</surname><given-names>P</given-names></name><name><surname>Brugger</surname><given-names>P</given-names></name><name><surname>Hepp-Reymond</surname><given-names>M-C</given-names></name><name><surname>Curt</surname><given-names>A</given-names></name><name><surname>Kollias</surname><given-names>SS</given-names></name></person-group><article-title>Preservation of motor programs in paraplegics as demonstrated by attempted and imagined foot movements</article-title><source>NeuroImage</source><year>2008</year><volume>39</volume><issue>1</issue><fpage>383</fpage><lpage>394</lpage><pub-id pub-id-type="pmid">17919932</pub-id></element-citation></ref><ref id="R34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jafari</surname><given-names>M</given-names></name><name><surname>Aflalo</surname><given-names>T</given-names></name><name><surname>Chivukula</surname><given-names>S</given-names></name><name><surname>Kellis</surname><given-names>SS</given-names></name><name><surname>Salas</surname><given-names>MA</given-names></name><name><surname>Norman</surname><given-names>SL</given-names></name><name><surname>Pejsa</surname><given-names>K</given-names></name><name><surname>Liu</surname><given-names>CY</given-names></name><name><surname>Andersen</surname><given-names>RA</given-names></name></person-group><article-title>The human primary somatosensory cortex encodes imagined movement in the absence of sensory information</article-title><source>Communications Biology</source><year>2020</year><volume>3</volume><fpage>757</fpage><pub-id pub-id-type="pmcid">PMC7732821</pub-id><pub-id pub-id-type="pmid">33311578</pub-id><pub-id pub-id-type="doi">10.1038/s42003-020-01484-1</pub-id></element-citation></ref><ref id="R35"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>James</surname><given-names>G</given-names></name><name><surname>Witten</surname><given-names>D</given-names></name><name><surname>Hastie</surname><given-names>T</given-names></name><name><surname>Tibshirani</surname><given-names>R</given-names></name></person-group><source>An Introduction to Statistical Learning: With Applications in R</source><publisher-name>Springer Nature</publisher-name><year>2021</year></element-citation></ref><ref id="R36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Janko</surname><given-names>D</given-names></name><name><surname>Thoenes</surname><given-names>K</given-names></name><name><surname>Park</surname><given-names>D</given-names></name><name><surname>Willoughby</surname><given-names>WR</given-names></name><name><surname>Horton</surname><given-names>M</given-names></name><name><surname>Bolding</surname><given-names>M</given-names></name></person-group><article-title>Somatotopic Mapping of the Fingers in the Somatosensory Cortex Using Functional Magnetic Resonance Imaging: A Review of Literature</article-title><source>Frontiers in Neuroanatomy</source><year>2022</year><volume>16</volume><pub-id pub-id-type="pmcid">PMC9277538</pub-id><pub-id pub-id-type="pmid">35847829</pub-id><pub-id pub-id-type="doi">10.3389/fnana.2022.866848</pub-id></element-citation></ref><ref id="R37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Bannister</surname><given-names>P</given-names></name><name><surname>Brady</surname><given-names>M</given-names></name><name><surname>Smith</surname><given-names>S</given-names></name></person-group><article-title>Improved Optimization for the Robust and Accurate Linear Registration and Motion Correction of Brain Images</article-title><source>NeuroImage</source><year>2002</year><volume>17</volume><issue>2</issue><fpage>825</fpage><lpage>841</lpage><pub-id pub-id-type="pmid">12377157</pub-id></element-citation></ref><ref id="R38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jorge</surname><given-names>A</given-names></name><name><surname>Royston</surname><given-names>DA</given-names></name><name><surname>Tyler-Kabara</surname><given-names>EC</given-names></name><name><surname>Boninger</surname><given-names>ML</given-names></name><name><surname>Collinger</surname><given-names>JL</given-names></name></person-group><article-title>Classification of Individual Finger Movements Using Intracortical Recordings in Human Motor Cortex</article-title><source>Neurosurgery</source><year>2020</year><volume>87</volume><issue>4</issue><fpage>630</fpage><pub-id pub-id-type="pmid">32140722</pub-id></element-citation></ref><ref id="R39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kakei</surname><given-names>S</given-names></name><name><surname>Hoffman</surname><given-names>DS</given-names></name><name><surname>Strick</surname><given-names>PL</given-names></name></person-group><article-title>Muscle and Movement Representations in the Primary Motor Cortex</article-title><source>Science</source><year>1999</year><volume>285</volume><issue>5436</issue><fpage>2136</fpage><lpage>2139</lpage><pub-id pub-id-type="pmid">10497133</pub-id></element-citation></ref><ref id="R40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kassraian</surname><given-names>P</given-names></name><name><surname>Rabe</surname><given-names>F</given-names></name><name><surname>Enz</surname><given-names>N</given-names></name><name><surname>Maathuis</surname><given-names>M</given-names></name><name><surname>Wenderoth</surname><given-names>N</given-names></name></person-group><article-title>Prior information enhances tactile representation in primary somatosensory cortex</article-title><source>bioRxiv</source><year>2023</year><elocation-id>2022.10.10.511201</elocation-id><pub-id pub-id-type="doi">10.1101/2022.10.10.511201</pub-id></element-citation></ref><ref id="R41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kikkert</surname><given-names>S</given-names></name><name><surname>Kolasinski</surname><given-names>J</given-names></name><name><surname>Jbabdi</surname><given-names>S</given-names></name><name><surname>Tracey</surname><given-names>I</given-names></name><name><surname>Beckmann</surname><given-names>CF</given-names></name><name><surname>Johansen-Berg</surname><given-names>H</given-names></name><name><surname>Makin</surname><given-names>TR</given-names></name></person-group><article-title>Revealing the neural fingerprints of a missing hand</article-title><source>eLife</source><year>2016</year><volume>5</volume><elocation-id>e15292</elocation-id><pub-id pub-id-type="pmcid">PMC5040556</pub-id><pub-id pub-id-type="pmid">27552053</pub-id><pub-id pub-id-type="doi">10.7554/eLife.15292</pub-id></element-citation></ref><ref id="R42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kikkert</surname><given-names>S</given-names></name><name><surname>Pfyffer</surname><given-names>D</given-names></name><name><surname>Verling</surname><given-names>M</given-names></name><name><surname>Freund</surname><given-names>P</given-names></name><name><surname>Wenderoth</surname><given-names>N</given-names></name></person-group><article-title>Finger somatotopy is preserved after tetraplegia but deteriorates over time</article-title><source>eLife</source><year>2021</year><volume>10</volume><elocation-id>e67713</elocation-id><pub-id pub-id-type="pmcid">PMC8575460</pub-id><pub-id pub-id-type="pmid">34665133</pub-id><pub-id pub-id-type="doi">10.7554/eLife.67713</pub-id></element-citation></ref><ref id="R43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kolasinski</surname><given-names>J</given-names></name><name><surname>Makin</surname><given-names>TR</given-names></name><name><surname>Jbabdi</surname><given-names>S</given-names></name><name><surname>Clare</surname><given-names>S</given-names></name><name><surname>Stagg</surname><given-names>CJ</given-names></name><name><surname>Johansen-Berg</surname><given-names>H</given-names></name></person-group><article-title>Investigating the Stability of Fine-Grain Digit Somatotopy in Individual Human Participants</article-title><source>Journal of Neuroscience</source><year>2016</year><volume>36</volume><issue>4</issue><fpage>1113</fpage><lpage>1127</lpage><pub-id pub-id-type="pmcid">PMC4728720</pub-id><pub-id pub-id-type="pmid">26818501</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1742-15.2016</pub-id></element-citation></ref><ref id="R44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuehn</surname><given-names>E</given-names></name><name><surname>Haggard</surname><given-names>P</given-names></name><name><surname>Villringer</surname><given-names>A</given-names></name><name><surname>Pleger</surname><given-names>B</given-names></name><name><surname>Sereno</surname><given-names>MI</given-names></name></person-group><article-title>Visually-Driven Maps in Area 3b</article-title><source>Journal of Neuroscience</source><year>2018</year><volume>38</volume><issue>5</issue><fpage>1295</fpage><lpage>1310</lpage><pub-id pub-id-type="pmcid">PMC6596270</pub-id><pub-id pub-id-type="pmid">29301873</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0491-17.2017</pub-id></element-citation></ref><ref id="R45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leinders</surname><given-names>S</given-names></name><name><surname>Vansteensel</surname><given-names>MJ</given-names></name><name><surname>Piantoni</surname><given-names>G</given-names></name><name><surname>Branco</surname><given-names>MP</given-names></name><name><surname>Freudenburg</surname><given-names>ZV</given-names></name><name><surname>Gebbink</surname><given-names>TA</given-names></name><name><surname>Pels</surname><given-names>EGM</given-names></name><name><surname>Raemaekers</surname><given-names>MAH</given-names></name><name><surname>Schippers</surname><given-names>A</given-names></name><name><surname>Aarnoutse</surname><given-names>EJ</given-names></name><name><surname>Ramsey</surname><given-names>NF</given-names></name></person-group><article-title>Using fMRI to localize target regions for implanted brain-computer interfaces in locked-in syndrome</article-title><source>Clinical Neurophysiology</source><year>2023</year><volume>155</volume><fpage>1</fpage><lpage>15</lpage><pub-id pub-id-type="pmid">37657190</pub-id></element-citation></ref><ref id="R46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lenth</surname><given-names>RV</given-names></name></person-group><article-title>Emmeans: Estimated Marginal Means, aka Least-Squares Means</article-title><source>R package version 1100</source><year>2024</year><comment><ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=emmeans">https://CRAN.R-project.org/package=emmeans</ext-link></comment></element-citation></ref><ref id="R47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>London</surname><given-names>BM</given-names></name><name><surname>Miller</surname><given-names>LE</given-names></name></person-group><article-title>Responses of somatosensory area 2 neurons to actively and passively generated limb movements</article-title><source>Journal of Neurophysiology</source><year>2013</year><volume>109</volume><issue>6</issue><fpage>1505</fpage><lpage>1513</lpage><pub-id pub-id-type="pmcid">PMC3774588</pub-id><pub-id pub-id-type="pmid">23274308</pub-id><pub-id pub-id-type="doi">10.1152/jn.00372.2012</pub-id></element-citation></ref><ref id="R48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marcus</surname><given-names>DS</given-names></name><name><surname>Harwell</surname><given-names>J</given-names></name><name><surname>Olsen</surname><given-names>T</given-names></name><name><surname>Hodge</surname><given-names>M</given-names></name><name><surname>Glasser</surname><given-names>MF</given-names></name><name><surname>Prior</surname><given-names>F</given-names></name><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Laumann</surname><given-names>T</given-names></name><name><surname>Curtiss</surname><given-names>SW</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name></person-group><article-title>Informatics and Data Mining Tools and Strategies for the Human Connectome Project</article-title><source>Frontiers in Neuroinformatics</source><year>2011</year><volume>5</volume><issue>4</issue><pub-id pub-id-type="pmcid">PMC3127103</pub-id><pub-id pub-id-type="pmid">21743807</pub-id><pub-id pub-id-type="doi">10.3389/fninf.2011.00004</pub-id></element-citation></ref><ref id="R49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McFarland</surname><given-names>DJ</given-names></name><name><surname>Norman</surname><given-names>SL</given-names></name><name><surname>Sarnacki</surname><given-names>WA</given-names></name><name><surname>Wolbrecht</surname><given-names>ET</given-names></name><name><surname>Reinkensmeyer</surname><given-names>DJ</given-names></name><name><surname>Wolpaw</surname><given-names>JR</given-names></name></person-group><article-title>BCI-based sensorimotor rhythm training can affect individuated finger movements</article-title><source>Brain-Computer Interfaces</source><year>2020</year><volume>7</volume><issue>1-2</issue><fpage>38</fpage><lpage>46</lpage><pub-id pub-id-type="doi">10.1080/2326263X.2020.1763060</pub-id></element-citation></ref><ref id="R50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muret</surname><given-names>D</given-names></name><name><surname>Root</surname><given-names>V</given-names></name><name><surname>Kieliba</surname><given-names>P</given-names></name><name><surname>Clode</surname><given-names>D</given-names></name><name><surname>Makin</surname><given-names>TR</given-names></name></person-group><article-title>Beyond body maps: Information content of specific body parts is distributed across the somatosensory homunculus</article-title><source>Cell Reports</source><year>2022</year><volume>38</volume><issue>11</issue><elocation-id>110523</elocation-id><pub-id pub-id-type="pmcid">PMC8938902</pub-id><pub-id pub-id-type="pmid">35294887</pub-id><pub-id pub-id-type="doi">10.1016/j.celrep.2022.110523</pub-id></element-citation></ref><ref id="R51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norman</surname><given-names>SL</given-names></name><name><surname>McFarland</surname><given-names>DJ</given-names></name><name><surname>Miner</surname><given-names>A</given-names></name><name><surname>Cramer</surname><given-names>SC</given-names></name><name><surname>Wolbrecht</surname><given-names>ET</given-names></name><name><surname>Wolpaw</surname><given-names>JR</given-names></name><name><surname>Reinkensmeyer</surname><given-names>DJ</given-names></name></person-group><article-title>Controlling pre-movement sensorimotor rhythm can improve finger extension after stroke</article-title><source>Journal of Neural Engineering</source><year>2018</year><volume>15</volume><issue>5</issue><elocation-id>056026</elocation-id><pub-id pub-id-type="pmcid">PMC6158016</pub-id><pub-id pub-id-type="pmid">30063219</pub-id><pub-id pub-id-type="doi">10.1088/1741-2552/aad724</pub-id></element-citation></ref><ref id="R52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Odermatt</surname><given-names>IA</given-names></name><name><surname>Schulthess-Lutz</surname><given-names>M</given-names></name><name><surname>Mihelj</surname><given-names>E</given-names></name><name><surname>Howell</surname><given-names>P</given-names></name><name><surname>Heimhofer</surname><given-names>C</given-names></name><name><surname>McMackin</surname><given-names>R</given-names></name><name><surname>Ruddy</surname><given-names>K</given-names></name><name><surname>Freund</surname><given-names>P</given-names></name><name><surname>Kikkert</surname><given-names>S</given-names></name><name><surname>Wenderoth</surname><given-names>N</given-names></name></person-group><article-title>TMS-based neurofeedback training of mental finger individuation induces neuroplastic changes in the sensorimotor cortex</article-title><source>bioRxiv</source><year>2024</year><elocation-id>2024.05.16.594100</elocation-id><pub-id pub-id-type="doi">10.1101/2024.05.16.594100</pub-id></element-citation></ref><ref id="R53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ogawa</surname><given-names>K</given-names></name><name><surname>Mitsui</surname><given-names>K</given-names></name><name><surname>Imai</surname><given-names>F</given-names></name><name><surname>Nishida</surname><given-names>S</given-names></name></person-group><article-title>Long-term training-dependent representation of individual finger movements in the primary motor cortex</article-title><source>NeuroImage</source><year>2019</year><volume>202</volume><elocation-id>116051</elocation-id><pub-id pub-id-type="pmid">31351164</pub-id></element-citation></ref><ref id="R54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oldfield</surname><given-names>RC</given-names></name></person-group><article-title>The assessment and analysis of handedness: The Edinburgh inventory</article-title><source>Neuropsychologia</source><year>1971</year><volume>9</volume><issue>1</issue><fpage>97</fpage><lpage>113</lpage><pub-id pub-id-type="pmid">5146491</pub-id></element-citation></ref><ref id="R55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>C</given-names></name><name><surname>Chang</surname><given-names>WH</given-names></name><name><surname>Lee</surname><given-names>M</given-names></name><name><surname>Kwon</surname><given-names>GH</given-names></name><name><surname>Kim</surname><given-names>L</given-names></name><name><surname>Kim</surname><given-names>ST</given-names></name><name><surname>Kim</surname><given-names>Y-H</given-names></name></person-group><article-title>Which motor cortical region best predicts imagined movement?</article-title><source>NeuroImage</source><year>2015</year><volume>113</volume><fpage>101</fpage><lpage>110</lpage><pub-id pub-id-type="pmid">25800212</pub-id></element-citation></ref><ref id="R56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Penfield</surname><given-names>W</given-names></name><name><surname>Boldrey</surname><given-names>E</given-names></name></person-group><article-title>Somatic motor and sensory representation in the cerebral cortex of man as studied by electrical stimulation</article-title><source>Brain</source><year>1937</year><volume>60</volume><issue>4</issue><fpage>389</fpage><lpage>443</lpage><pub-id pub-id-type="doi">10.1093/brain/60.4.389</pub-id></element-citation></ref><ref id="R57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pilgramm</surname><given-names>S</given-names></name><name><surname>de Haas</surname><given-names>B</given-names></name><name><surname>Helm</surname><given-names>F</given-names></name><name><surname>Zentgraf</surname><given-names>K</given-names></name><name><surname>Stark</surname><given-names>R</given-names></name><name><surname>Munzert</surname><given-names>J</given-names></name><name><surname>Krüger</surname><given-names>B</given-names></name></person-group><article-title>Motor imagery of hand actions: Decoding the content of motor imagery from brain activity in frontal and parietal motor areas</article-title><source>Human Brain Mapping</source><year>2016</year><volume>37</volume><issue>1</issue><fpage>81</fpage><lpage>93</lpage><pub-id pub-id-type="pmcid">PMC4737127</pub-id><pub-id pub-id-type="pmid">26452176</pub-id><pub-id pub-id-type="doi">10.1002/hbm.23015</pub-id></element-citation></ref><ref id="R58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Puckett</surname><given-names>AM</given-names></name><name><surname>Bollmann</surname><given-names>S</given-names></name><name><surname>Barth</surname><given-names>M</given-names></name><name><surname>Cunnington</surname><given-names>R</given-names></name></person-group><article-title>Measuring the effects of attention to individual fingertips in somatosensory cortex using ultra-high field (7T) fMRI</article-title><source>NeuroImage</source><year>2017</year><volume>161</volume><fpage>179</fpage><lpage>187</lpage><pub-id pub-id-type="pmid">28801252</pub-id></element-citation></ref><ref id="R59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rabe</surname><given-names>F</given-names></name><name><surname>Kikkert</surname><given-names>S</given-names></name><name><surname>Wenderoth</surname><given-names>N</given-names></name></person-group><article-title>Performing a vibrotactile discrimination task modulates finger representations in primary somatosensory cortex</article-title><source>Journal of Neurophysiology</source><year>2023</year><volume>130</volume><issue>4</issue><fpage>1015</fpage><lpage>1027</lpage><pub-id pub-id-type="pmcid">PMC10649835</pub-id><pub-id pub-id-type="pmid">37671429</pub-id><pub-id pub-id-type="doi">10.1152/jn.00428.2022</pub-id></element-citation></ref><ref id="R60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanchez-Panchuelo</surname><given-names>RM</given-names></name><name><surname>Francis</surname><given-names>S</given-names></name><name><surname>Bowtell</surname><given-names>R</given-names></name><name><surname>Schluppeck</surname><given-names>D</given-names></name></person-group><article-title>Mapping Human Somatosensory Cortex in Individual Subjects With 7T Functional MRI</article-title><source>Journal of Neurophysiology</source><year>2010</year><volume>103</volume><issue>5</issue><fpage>2544</fpage><lpage>2556</lpage><pub-id pub-id-type="pmcid">PMC2867563</pub-id><pub-id pub-id-type="pmid">20164393</pub-id><pub-id pub-id-type="doi">10.1152/jn.01017.2009</pub-id></element-citation></ref><ref id="R61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanders</surname><given-names>Z-B</given-names></name><name><surname>Dempsey-Jones</surname><given-names>H</given-names></name><name><surname>Wesselink</surname><given-names>DB</given-names></name><name><surname>Edmondson</surname><given-names>LR</given-names></name><name><surname>Puckett</surname><given-names>AM</given-names></name><name><surname>Saal</surname><given-names>HP</given-names></name><name><surname>Makin</surname><given-names>TR</given-names></name></person-group><article-title>Similar somatotopy for active and passive digit representation in primary somatosensory cortex</article-title><source>Human Brain Mapping</source><year>2023</year><volume>44</volume><issue>9</issue><fpage>3568</fpage><lpage>3585</lpage><pub-id pub-id-type="pmcid">PMC10203813</pub-id><pub-id pub-id-type="pmid">37145934</pub-id><pub-id pub-id-type="doi">10.1002/hbm.26298</pub-id></element-citation></ref><ref id="R62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schellekens</surname><given-names>W</given-names></name><name><surname>Petridou</surname><given-names>N</given-names></name><name><surname>Ramsey</surname><given-names>NF</given-names></name></person-group><article-title>Detailed somatotopy in primary motor and somatosensory cortex revealed by Gaussian population receptive fields</article-title><source>NeuroImage</source><year>2018</year><volume>179</volume><fpage>337</fpage><lpage>347</lpage><pub-id pub-id-type="pmcid">PMC6413921</pub-id><pub-id pub-id-type="pmid">29940282</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.06.062</pub-id></element-citation></ref><ref id="R63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schieber</surname><given-names>MH</given-names></name></person-group><article-title>Constraints on Somatotopic Organization in the Primary Motor Cortex</article-title><source>Journal of Neurophysiology</source><year>2001</year><volume>86</volume><issue>5</issue><fpage>2125</fpage><lpage>2143</lpage><pub-id pub-id-type="pmid">11698506</pub-id></element-citation></ref><ref id="R64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shah</surname><given-names>NP</given-names></name><name><surname>Avansino</surname><given-names>D</given-names></name><name><surname>Kamdar</surname><given-names>F</given-names></name><name><surname>Nicolas</surname><given-names>C</given-names></name><name><surname>Kapitonava</surname><given-names>A</given-names></name><name><surname>Vargas-Irwin</surname><given-names>C</given-names></name><name><surname>Hochberg</surname><given-names>L</given-names></name><name><surname>Pandarinath</surname><given-names>C</given-names></name><name><surname>Shenoy</surname><given-names>K</given-names></name><name><surname>Willett</surname><given-names>FR</given-names></name><name><surname>Henderson</surname><given-names>J</given-names></name></person-group><article-title>Pseudo-linear Summation explains Neural Geometry of Multi-finger Movements in Human Premotor Cortex</article-title><source>bioRxiv</source><year>2023</year><elocation-id>2023.10.11.561982</elocation-id><pub-id pub-id-type="doi">10.1101/2023.10.11.561982</pub-id></element-citation></ref><ref id="R65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shah</surname><given-names>NP</given-names></name><name><surname>Willsey</surname><given-names>MS</given-names></name><name><surname>Hahn</surname><given-names>N</given-names></name><name><surname>Kamdar</surname><given-names>F</given-names></name><name><surname>Avansino</surname><given-names>DT</given-names></name><name><surname>Fan</surname><given-names>C</given-names></name><name><surname>Hochberg</surname><given-names>LR</given-names></name><name><surname>Willett</surname><given-names>FR</given-names></name><name><surname>Henderson</surname><given-names>JM</given-names></name></person-group><article-title>A flexible intracortical brain-computer interface for typing using finger movements</article-title><source>bioRxiv</source><year>2024</year><elocation-id>2024.04.22.590630</elocation-id><pub-id pub-id-type="doi">10.1101/2024.04.22.590630</pub-id></element-citation></ref><ref id="R66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>SM</given-names></name></person-group><article-title>Fast robust automated brain extraction</article-title><source>Human Brain Mapping</source><year>2002</year><volume>17</volume><issue>3</issue><fpage>143</fpage><lpage>155</lpage><pub-id pub-id-type="pmcid">PMC6871816</pub-id><pub-id pub-id-type="pmid">12391568</pub-id><pub-id pub-id-type="doi">10.1002/hbm.10062</pub-id></element-citation></ref><ref id="R67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thomschewski</surname><given-names>A</given-names></name><name><surname>Ströhlein</surname><given-names>A</given-names></name><name><surname>Langthaler</surname><given-names>PB</given-names></name><name><surname>Schmid</surname><given-names>E</given-names></name><name><surname>Potthoff</surname><given-names>J</given-names></name><name><surname>Höller</surname><given-names>P</given-names></name><name><surname>Leis</surname><given-names>S</given-names></name><name><surname>Trinka</surname><given-names>E</given-names></name><name><surname>Höller</surname><given-names>Y</given-names></name></person-group><article-title>Imagine There Is No Plegia. Mental Motor Imagery Difficulties in Patients with Traumatic Spinal Cord Injury</article-title><source>Frontiers in Neuroscience</source><year>2017</year><volume>11</volume><pub-id pub-id-type="pmcid">PMC5732245</pub-id><pub-id pub-id-type="pmid">29311771</pub-id><pub-id pub-id-type="doi">10.3389/fnins.2017.00689</pub-id></element-citation></ref><ref id="R68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Umeda</surname><given-names>T</given-names></name><name><surname>Isa</surname><given-names>T</given-names></name><name><surname>Nishimura</surname><given-names>Y</given-names></name></person-group><article-title>The somatosensory cortex receives information about motor output</article-title><source>Science Advances</source><year>2019</year><volume>5</volume><issue>7</issue><elocation-id>eaaw5388</elocation-id><pub-id pub-id-type="pmcid">PMC6620090</pub-id><pub-id pub-id-type="pmid">31309153</pub-id><pub-id pub-id-type="doi">10.1126/sciadv.aaw5388</pub-id></element-citation></ref><ref id="R69"><element-citation publication-type="journal"><person-group person-group-type="author">van<name><surname>den Boom</surname><given-names>M</given-names></name><name><surname>Miller</surname><given-names>KJ</given-names></name><name><surname>Gregg</surname><given-names>NM</given-names></name><name><surname>Ojeda Valencia</surname><given-names>G</given-names></name><name><surname>Lee</surname><given-names>KH</given-names></name><name><surname>Richner</surname><given-names>TJ</given-names></name><name><surname>Ramsey</surname><given-names>NF</given-names></name><name><surname>Worrell</surname><given-names>GA</given-names></name><name><surname>Hermes</surname><given-names>D</given-names></name></person-group><article-title>Typical somatomotor physiology of the hand is preserved in a patient with an amputated arm: An ECoG case study</article-title><source>NeuroImage: Clinical</source><year>2021</year><volume>31</volume><elocation-id>102728</elocation-id><pub-id pub-id-type="pmcid">PMC8253998</pub-id><pub-id pub-id-type="pmid">34182408</pub-id><pub-id pub-id-type="doi">10.1016/j.nicl.2021.102728</pub-id></element-citation></ref><ref id="R70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Glasser</surname><given-names>MF</given-names></name><name><surname>Dierker</surname><given-names>DL</given-names></name><name><surname>Harwell</surname><given-names>J</given-names></name><name><surname>Coalson</surname><given-names>T</given-names></name></person-group><article-title>Parcellations and Hemispheric Asymmetries of Human Cerebral Cortex Analyzed on Surface-Based Atlases</article-title><source>Cerebral Cortex</source><year>2012</year><volume>22</volume><issue>10</issue><fpage>2241</fpage><lpage>2262</lpage><pub-id pub-id-type="pmcid">PMC3432236</pub-id><pub-id pub-id-type="pmid">22047963</pub-id><pub-id pub-id-type="doi">10.1093/cercor/bhr291</pub-id></element-citation></ref><ref id="R71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vargas-Irwin</surname><given-names>CE</given-names></name><name><surname>Feldman</surname><given-names>JM</given-names></name><name><surname>King</surname><given-names>B</given-names></name><name><surname>Simeral</surname><given-names>JD</given-names></name><name><surname>Sorice</surname><given-names>BL</given-names></name><name><surname>Oakley</surname><given-names>EM</given-names></name><name><surname>Cash</surname><given-names>SS</given-names></name><name><surname>Eskandar</surname><given-names>EN</given-names></name><name><surname>Friehs</surname><given-names>GM</given-names></name><name><surname>Hochberg</surname><given-names>LR</given-names></name><name><surname>Donoghue</surname><given-names>JP</given-names></name></person-group><article-title>Watch, Imagine, Attempt: Motor Cortex Single-Unit Activity Reveals Context-Dependent Movement Encoding in Humans With Tetraplegia</article-title><source>Frontiers in Human Neuroscience</source><year>2018</year><volume>12</volume><pub-id pub-id-type="pmcid">PMC6262367</pub-id><pub-id pub-id-type="pmid">30524258</pub-id><pub-id pub-id-type="doi">10.3389/fnhum.2018.00450</pub-id></element-citation></ref><ref id="R72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wesselink</surname><given-names>DB</given-names></name><name><surname>Sanders</surname><given-names>Z-B</given-names></name><name><surname>Edmondson</surname><given-names>LR</given-names></name><name><surname>Dempsey-Jones</surname><given-names>H</given-names></name><name><surname>Kieliba</surname><given-names>P</given-names></name><name><surname>Kikkert</surname><given-names>S</given-names></name><name><surname>Themistocleous</surname><given-names>AC</given-names></name><name><surname>Emir</surname><given-names>U</given-names></name><name><surname>Diedrichsen</surname><given-names>J</given-names></name><name><surname>Saal</surname><given-names>HP</given-names></name><name><surname>Makin</surname><given-names>TR</given-names></name></person-group><article-title>Malleability of the cortical hand map following a finger nerve block</article-title><source>Science Advances</source><year>2022</year><volume>8</volume><issue>16</issue><elocation-id>eabk2393</elocation-id><pub-id pub-id-type="pmcid">PMC9032959</pub-id><pub-id pub-id-type="pmid">35452294</pub-id><pub-id pub-id-type="doi">10.1126/sciadv.abk2393</pub-id></element-citation></ref><ref id="R73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wesselink</surname><given-names>DB</given-names></name><name><surname>van den Heiligenberg</surname><given-names>FM</given-names></name><name><surname>Ejaz</surname><given-names>N</given-names></name><name><surname>Dempsey-Jones</surname><given-names>H</given-names></name><name><surname>Cardinali</surname><given-names>L</given-names></name><name><surname>Tarall-Jozwiak</surname><given-names>A</given-names></name><name><surname>Diedrichsen</surname><given-names>J</given-names></name><name><surname>Makin</surname><given-names>TR</given-names></name></person-group><article-title>Obtaining and maintaining cortical hand representation as evidenced from acquired and congenital handlessness</article-title><source>eLife</source><year>2019</year><volume>8</volume><elocation-id>e37227</elocation-id><pub-id pub-id-type="pmcid">PMC6363469</pub-id><pub-id pub-id-type="pmid">30717824</pub-id><pub-id pub-id-type="doi">10.7554/eLife.37227</pub-id></element-citation></ref><ref id="R74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Willsey</surname><given-names>MS</given-names></name><name><surname>Shah</surname><given-names>NP</given-names></name><name><surname>Avansino</surname><given-names>DT</given-names></name><name><surname>Hahn</surname><given-names>NV</given-names></name><name><surname>Jamiolkowski</surname><given-names>RM</given-names></name><name><surname>Kamdar</surname><given-names>FB</given-names></name><name><surname>Hochberg</surname><given-names>LR</given-names></name><name><surname>Willett</surname><given-names>FR</given-names></name><name><surname>Henderson</surname><given-names>JM</given-names></name></person-group><article-title>A real-time, high-performance brain-computer interface for finger decoding and quadcopter control</article-title><source>bioRxiv</source><year>2024</year><elocation-id>2024.02.06.578107</elocation-id><pub-id pub-id-type="doi">10.1101/2024.02.06.578107</pub-id></element-citation></ref><ref id="R75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>J</given-names></name><name><surname>Mawase</surname><given-names>F</given-names></name><name><surname>Schieber</surname><given-names>MH</given-names></name></person-group><article-title>Evolution, biomechanics, and neurobiology converge to explain selective finger motor control</article-title><source>Physiological Reviews</source><year>2024</year><volume>104</volume><issue>3</issue><fpage>983</fpage><lpage>1020</lpage><pub-id pub-id-type="pmcid">PMC11380997</pub-id><pub-id pub-id-type="pmid">38385888</pub-id><pub-id pub-id-type="doi">10.1152/physrev.00030.2023</pub-id></element-citation></ref><ref id="R76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zabicki</surname><given-names>A</given-names></name><name><surname>de Haas</surname><given-names>B</given-names></name><name><surname>Zentgraf</surname><given-names>K</given-names></name><name><surname>Stark</surname><given-names>R</given-names></name><name><surname>Munzert</surname><given-names>J</given-names></name><name><surname>Krüger</surname><given-names>B</given-names></name></person-group><article-title>Imagined and Executed Actions in the Human Motor System: Testing Neural Similarity Between Execution and Imagery of Actions with a Multivariate Approach</article-title><source>Cerebral Cortex</source><year>2017</year><volume>27</volume><issue>9</issue><fpage>4523</fpage><lpage>4536</lpage><pub-id pub-id-type="pmid">27600847</pub-id></element-citation></ref><ref id="R77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zabicki</surname><given-names>A</given-names></name><name><surname>de Haas</surname><given-names>B</given-names></name><name><surname>Zentgraf</surname><given-names>K</given-names></name><name><surname>Stark</surname><given-names>R</given-names></name><name><surname>Munzert</surname><given-names>J</given-names></name><name><surname>Krüger</surname><given-names>B</given-names></name></person-group><article-title>Subjective vividness of motor imagery has a neural signature in human premotor and parietal cortex</article-title><source>NeuroImage</source><year>2019</year><volume>197</volume><fpage>273</fpage><lpage>283</lpage><pub-id pub-id-type="pmid">31051294</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>Minimally thresholded finger-selective motor imagery maps per participant across two fMRI sessions ~2 weeks apart.</title><p>Finger-selective motor imagery maps per participant (N = 16) visualised on a surface template brain with the sulcal pattern in dark grey. The top left shows the magnified area (black square), encompassing the hand area of the primary somatosensory (S1; green) and primary motor cortex (M1; purple). The colours of activity clusters refer to the winner-take-all finger contrasts thresholded at Z &gt; 2 (red = thumb; blue = index finger; yellow = little finger). Typical finger-selectivity maps can be observed with a gradient of finger preference, progressing from the thumb (laterally) to the little finger (medially). While these characteristic aspects of finger maps are displayed for most participants, some finger representations are not visible in the minimally thresholded maps. A = anterior, P = posterior, CS = central sulcus.</p></caption><graphic xlink:href="EMS202013-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Finger-selective motor imagery maps in S1 are stable across sessions.</title><p><bold>a)</bold> Left: Spatial consistency, quantified using the Dice Overlap Coefficient (DOC), for all possible finger pairs across the two fMRI sessions. Results are averaged across all participants in the motor imagery and motor execution task based on the minimally thresholded (Z &gt; 2) winner-take-all finger maps. Middle: The DOC were assigned to ‘same’ (diagonal of matrix: D1-D1, D2-D2, D5-D5), ‘neighbouring’ (D1-D2, D2-D1), or ‘non-neighbouring’ finger representations (D1-D5, D5-D1, D2-D5, D5-D2) for the statistical analysis depicted on the right. Dots depict data of individual participants. **** <italic>p</italic> &lt; .0001; ** <italic>p</italic> &lt; .01; ns = non-significant. b) Left: DOC comparing all combinations of individual finger representations across participants and sessions. The diagonal of the matrix represents the overlap of the same finger representations and participants across the two sessions. The 16 x 16 submatrices depicted by the white lines show the overlap for a specific finger pair for all participants. Right: Matrix dominance ratio (Mdr) for all submatrices based on the matrix on the left. The values &gt; 1 on the diagonal reflect that the spatial overlap of the same finger representations was higher within-participant than across-participants. For neighbouring and non-neighbouring fingers there was no such higher spatial overlap within compared to across participants. From the Mdr matrix, an overall Mdr was calculated. A value &gt; 1 indicates higher within-participant consistency than across-participants consistency. Bootstrapping revealed that the overall Mdr is significantly different from chance. D1 (digit 1) = thumb; D2 = index finger; D5 = little finger.</p></caption><graphic xlink:href="EMS202013-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Decoding analysis of individual imagined finger movements reveals that finger-specific activity patterns are spatially consistent across sessions in the S1 hand area.</title><p><bold>a</bold>) Classification accuracy of individual fingers during motor imagery in the S1 hand area. Within-session classification accuracy depicts the average accuracy of a leave-one-run-out cross-validation performed separately for each participant and session. Across-sessions is based on the average accuracy score of a within-participant classifier trained on all trials of one session and tested on all trials of the other session. Across-participants classification accuracy shows the average accuracy of a leave-one-participant-out cross-validation using the data of all participants. Paired classical and Bayesian t-tests suggest that within-session and across-sessions accuracy do not differ significantly (BF<sub>10</sub> = 0.52). One-sample t-tests demonstrate significantly higher classification accuracy for classifiers trained and tested within-participants compared to across-participants, indicating higher within-participant consistency of motor imagery finger represenations over time than across-participants. Asterisks on top of bars refer to the statistical difference of classification accuracy from the empirical chance level. <bold>b</bold>) Confusion matrices depicting the correctly classified trials (diagonal) and the misclassified trials (off-diagonal) in the S1 hand area. Each row refers to all trials of a finger, and the cells in a row show the % of predicted trials for each label. <bold>c</bold>) We assigned the scores of the confusion matrices in b) to ‘correctly classified’ (diagonal; true label – predicted label: D1-D1, D2-D2, D5-D5), misclassified as ‘neighbouring’ finger (D1-D2, D2-D1), and as ‘non-neighbouring’ (D1-D5, D5-D1, D2-D5, D5-D2) and found that significantly more trials were correctly classified than misclassified. From the misclassified trials, significantly more trials were wrongly predicted as a neighbouring than non-neighbouring finger. The across-participants classification scores are displayed merely for visualisation and were not included in the statistical analysis. The significance bars refer to post-hoc contrasts based on the main effect of <italic>Prediction</italic> (correctly classified, misclassified as neighbouring, misclassified as non-neighbouring finger), averaged over both levels of <italic>Comparison</italic> (within-session, across-sessions). <bold>d</bold>) Finger representations activated through motor imagery were less clearly distinguishable in the S1 hand area than when they were activated through motor execution. However, the generalisability of a classifier trained on trials of one session and tested on trials of the other session was comparable for motor imagery and motor execution. The significance bars refer to the main effect <italic>Task</italic> (motor imagery, motor execution). The across-participants scores are merely displayed for visualisation and were not included in the statistical analysis. The dotted lines represent the empirical chance level (i.e., 0.33) based on permutation testing. Dots depict data of individual participants. **** <italic>p</italic> &lt; .0001; *** <italic>p</italic> &lt; .001; ns = non-significant. D1 (digit 1) = thumb; D2 = index; D5 = little.</p></caption><graphic xlink:href="EMS202013-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Across-task decoding analysis reveals neural similarity of finger representations activated through motor imagery and motor execution in the S1 hand area.</title><p>Within-session classification accuracy depicts the average accuracy of a classifier trained on all data of one task (i.e., either motor imagery or motor execution) in one session and tested on all data of the other task in the same session, performed separately for each participant. Across-sessions shows the average accuracy of a classifier trained on all data of one task in one session and tested on all data of the other task in the other session. Asterisks on top of bars refer to the statistical difference of classification accuracy from the empirical chance level. The dotted lines represent the empirical chance level (i.e., 0.33) based on permutation testing. Dots depict data of individual participants. **** p &lt; .0001; ns = non-significant.</p></caption><graphic xlink:href="EMS202013-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>Experimental setup of one fMRI session.</title><p>In each fMRI session, four motor imagery runs (purple) were acquired using a blocked paradigm. In each block, participants were visually cued to imagine individual finger movements by the words ‘Thumb’, ‘Index’, ‘Little’, or ‘Rest’, presented in a counterbalanced order. After each trial, an additional rest period (3-4s) to facilitate switching between different fingers was indicated by a fixation cross. After acquiring a T1 and B0 sequence, six motor execution runs were assessed, using an identical blocked paradigm as for motor imagery but without additional rest periods between the movement trials. The participants’ right index, ring, middle and little fingers were placed on the buttons of a four-button response box, with the thumb placed on the side of the box. Participants were visually cued by the words ‘Thumb’, ‘Index’, ‘Middle’, ‘Ring’, ‘Little’, or ‘Rest’ displayed above the fixation cross to perform paced button presses with the corresponding finger (or to tap the side of the button box with the thumb) or to rest. The pace was instructed by the fixation cross blinking at 1.4 Hz. In the rest trials, no fixation cross was displayed.</p></caption><graphic xlink:href="EMS202013-f005"/></fig></floats-group></article>