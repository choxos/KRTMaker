<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS200697</article-id><article-id pub-id-type="doi">10.1101/2024.11.20.624484</article-id><article-id pub-id-type="archive">PPR943953</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">1</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Similarity corpus on microbial transcriptional regulation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Oscar</surname><given-names>Lithgow-Serrano</given-names></name><xref ref-type="corresp" rid="CR1">*</xref><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Socorro</surname><given-names>Gama-Castro</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Cecilia</surname><given-names>Ishida-Gutiérrez</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Citlali</surname><given-names>Mejía-Almonte</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Víctor</surname><given-names>Tierrafría</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Sara</surname><given-names>Martínez-Luna</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Alberto</surname><given-names>Santos-Zavaleta</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>David</surname><given-names>Velázquez-Ramírez</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Julio</surname><given-names>Collado-Vides</given-names></name><xref ref-type="corresp" rid="CR2">†</xref><xref ref-type="aff" rid="A1">1</xref></contrib></contrib-group><aff id="A1"><label>1</label>Computational Genomics, Centro de Ciencias Genómicas, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/01tmp8f25</institution-id><institution>Universidad Nacional Autónoma de México</institution></institution-wrap>. <addr-line>A.P. 565-A Cuernavaca, Morelos</addr-line><postal-code>62100</postal-code>, <country country="MX">México</country></aff><aff id="A2"><label>2</label>Instituto de Investigaciones en Matemáticas Aplicadas y en Sistemas (IIMAS), <institution-wrap><institution-id institution-id-type="ror">https://ror.org/01tmp8f25</institution-id><institution>Universidad Nacional Autónoma de México (UNAM)</institution></institution-wrap>, <city>Mexico City</city>, <country country="MX">México</country></aff><author-notes><corresp id="CR1"><label>*</label>Corresponding author, <email>olithgow@ccg.unam.mx</email></corresp><corresp id="CR2"><label>†</label>Corresponding author, <email>collado@ccg.unam.mx</email></corresp></author-notes><pub-date pub-type="nihms-submitted"><day>23</day><month>11</month><year>2024</year></pub-date><pub-date pub-type="preprint"><day>21</day><month>11</month><year>2024</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">The ability to express the same meaning in different ways is a well known property of natural language. This amazing property is the source of major difficulties in natural language processing. Given the constant increase in published literature, its curation and information extraction would strongly benefit by efficient automatic processes, for which, corpora of sentences evaluated by experts is a valuable resource. Given our interest in applying such approaches to the benefit of curation of the biomedical literature, specifically about gene regulation in microbial organisms, we decided to build a corpus with graded textual similarity evaluated by curators, and designed specifically oriented to our purposes. Based on the predefined statistical power of future analyses, we defined features of the design including sampling, selection criteria, balance, and size among others. A non-fully crossed-design was performed for each pair of sentences by 3 evaluators from 7 different groups, adapting the SEMEVAL scale to our goals in four successive iterative sessions with a clear improvement in the consensuated guidelines and inter-rater-reliability results. Alternatives for the corpus evaluation are widely discussed. To the best of our knowledge this is the first similarity corpus in this domain of knowledge. We have initiated its incorporation in our research towards high throughput curation strategies based in natural language processing.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><label>1</label><title>Introduction</title><p id="P2">Expressing the same approximate meaning with different wordings is a phenomenon widely present in the every day use of natural language. It shows the richness and polymorphic power of natural language, but it also exhibits the complexity implied in understanding the conveyed meaning. Due to these characteristics, paraphrase identification is necessary in many Natural Language Processing (NLP) tasks, such as information retrieval, machine translation, plagiarism detection, among others. Although strictly a “paraphrasis” refers to a rewording stating the same meaning, a binary decision, frequently, a graded paraphrasing is needed. This graded paraphrasing is often called Semantic Textual Similarity (STS).</p><p id="P3">Textual similarity depends on particular text features, domain relations and on the applied perspective, therefore it has to be “defined” according to the context. This context specification presuppose the delineation of the <italic>kind of textual similarity</italic> desired, e.g., assigning grades of importance to the syntactic parallelism, to the ontological closeness, to the statistical representations likeness, etc.</p><p id="P4">It is not a simple endeavor to explicitly state these grades of importance. Its difficulty relies on the fact that it is very complicated to envisage all possible language’s feature variations to express the same idea, and so to have a broad perspective and identify which feature or relations are important. It is here that a paraphrase corpus is a very useful instrument because it implicitly enclose those nuances.</p><p id="P5">There are several paraphrase corpora available, both in general and specific domains. However, as stated before these corpora are very sensitive to the aimed task and to the targeted domain. Hence, when a task or domain are very specific and the available corpora do not fit. an ad-hoc corpus has to be built. This is the case for the biomedical curation of the literature about the regulation of transcription initiation in bacteria, a very specific domain.</p><p id="P6">RegulonDB <sup><xref ref-type="fn" rid="FN1">1</xref></sup> (<xref ref-type="bibr" rid="R11">[GCSSZ<sup>+</sup>16]</xref>) is a manually curated standard resource, an organized and computable database, about the regulation of gene expression in E. coli K-12. It aims at integrating in a single repository all the scattered information about genetic regulation in this microorganism including elements about transcriptional regulation, such as: promoters, transcription units (TUs), transcription factors (TFs), effectors that affect TFs, active and inactive conformations of TFs, TFs binding sites (TFBSs), regulatory interactions (RIs) of TFs with their target genes/TUs, terminators, riboswitches, small RNAs and their target genes. RegulonDB plays an important role in scientific research with citations in more than 800 scientific publications within the gene regulation field.</p><p id="P7">As an ongoing effort to enrich the already curated information and to improve the curation process, we are developing Natural Language Processing (NLP) tools some of which relay on STS. Due to the very specific nature of our domain we built an ad-hoc graded paraphrase corpus to be used as training and evaluation source of truth for our NLP tools.</p><p id="P8">Within the next sections we first describe the methodology followed to build our corpus, then we analyze it quantitatively and finally we briefly mention the immediate foreseen uses.</p></sec><sec id="S2"><label>2</label><title>Related work and Motivation</title><p id="P9">Semantic Textual Similarity (STS) aims at measuring the degree of semantic equivalence between two fragments of texts. As so, it tries to unveil the meaning conveyed by a textual expression and compare it with the meaning conveyed by another one. The comparison’s result is a graded similarity score that ranges from an exact semantic match to a completely independent meaning, passing through a continuous scale of graded semantic parallelism. This scale intuitively captures the notion that a pair of texts can share different aspects of meaning at different levels (<xref ref-type="bibr" rid="R1">[ACD<sup>+</sup>13]</xref>), i.e. it could differ in just some minor details, could share a common topic and important details, or just share the domain and context, etc. Another characteristic of STS is that it treats similarity between two texts as bijective putting it apart from textual entailment where the relation is directed and can not be assumed in the other way around.</p><p id="P10">Many NLP tasks, such as machine translation, question answering, summarization, and information extraction, are beneficed from this quantifiable graded bidirectional notion of textual similarity. Building this kind of corpus is difficult and expensive that is why there are not as many corpora of this kind as expected given their utility.</p><p id="P11">In recent years the most notorious effort on the STS task and their correspondent corpus construction has been tackled by the <italic>Semantic Evaluation workshop</italic> (SEMEVAL) (<xref ref-type="bibr" rid="R1">[ACD<sup>+</sup>13]</xref>). The <italic>SEMEVAL corpus</italic> consists of 15,000 sentence pairs coming from different sources. <italic>Microsoft Research Paraphrase</italic> (MSRP) and PASCAL VOC (<xref ref-type="bibr" rid="R9">[EVW<sup>+</sup>10]</xref>) corpora among them. It was annotated through crowd sourcing on a scale from 5 (identical) to 0 (completely unrelated).</p><p id="P12">Another corpus that is useful for STS is the <italic>User Language Paraphrase Corpus</italic> (ULPC) (<xref ref-type="bibr" rid="R22">[MM11]</xref>). It was built by asking students to rephrase target sentences. As a result 1998 sentence pairs were annotated with ratings ranging from 1 to 6 for 10 paraphrasing dimensions; entailment and lexical, syntactic and semantic similarity are among those dimensions.</p><p id="P13">The SIMILAR corpus (<xref ref-type="bibr" rid="R25">[RLMB12]</xref>) is a qualitative assessment of 700 pairs of sentences from the MSRP corpus, and besides providing word-to-word semantic similarity annotations, it also supplies a qualitative similarity relationship identical, related, context, close, world-knowledge, and none — between each pair of sentences.</p><p id="P14">Not in the scope of graded similarity but instead in the binary paraphrase one, there are important corpora such as the <italic>Microsoft Research Paraphrase</italic> (MSRP) (<xref ref-type="bibr" rid="R7">[DB05]</xref>). It is one of the first major public paraphrase corpora comprising 5801 news sentence pairs of which 67% were judged “semantically equivalent” by two human judges. In the Q&amp;A field. <italic>The Question Paraphrase Corpus</italic> (<xref ref-type="bibr" rid="R3">[BG08]</xref>) was built by collecting, from <italic>WikiAnswers,</italic> 7434 sentences formed by 1000 different questions and their paraphrases.</p><p id="P15">All these corpora target general domains and were sourced mainly from news making very difficult to fit them into a such an specific topic like ours, the <italic>bacterial transcriptional regulation.</italic> Closer to our domain is the BIOSSES corpus (<xref ref-type="bibr" rid="R27">[SÖÖ17]</xref>). It is formed by 100 pairs of sentences from the biomedical domain which were rated following the guidelines of the STS SEMEVAL’s task. The candidate sentences were collected by taking those that cited the same reference article from a set of 20 reference articles each of which had another 12-20 citing articles. Articles were taken from the <italic>Biomedical Summarization Track Training Dataset</italic> from the <italic>Text Analysis Conference.</italic></p><p id="P16">Due to the extension of the biomedical domain and the small size of this corpus, the nuances of our subject of study are not captured by it. For this reason we decided to build our own corpus of naturally-occurring non-handcrafted sentence pairs within the subject of <italic>regulation of gene expression in E. coli K-12</italic> literature. The semantic similarity grade of each pair was evaluated by human experts in the bacterial gene regulation domain.</p></sec><sec id="S3" sec-type="materials | methods"><label>3</label><title>Materials and Methods</title><sec id="S4"><label>3.1</label><title>Corpus design</title><p id="P17">“A corpus is a collection of pieces of language text in electronic form, selected according to external criteria to represent, as far as possible, a language or language variety as a source of data for linguistic research”. (<xref ref-type="bibr" rid="R26">[Sin04]</xref>)</p><p id="P18">Before building a corpus the source textual set, the evaluation rules, the corpus size and other characteristics must be defined. This design should be, as possible, informed and principled so the resulting corpus fulfill the desired goals. The decisions taken within the axes of consideration (<xref ref-type="bibr" rid="R26">[Sin04]</xref>) for the corpus construction are the following.</p><p id="P19">The <italic>sampling</italic> policy defines where and how the candidate texts are going to be selected following 3 main criteria: the <italic>orientation,</italic> in this case a contrastive corpus that aimed to show the language varieties that express the same meaning (semantic similarity); the <italic>selection criteria</italic> that circumscribed candidates to written sentences (origin and granularity) in English (language) taken from scientific articles (type) on the topic of genetic regulation (domain) where the sentence attitude<sup><xref ref-type="fn" rid="FN2">2</xref></sup> was irrelevant and a specific content was not required; finally, the <italic>sampling</italic> criteria consisted in a sentence pairs pre-selection through a very basic STS component and a posterior filtering process to keep the same number of exemplars for each similarity grade, i.e., a balanced candidate set.</p><p id="P20">The corpus <italic>representativeness</italic> and <italic>balance</italic> refers to the kind of features and the exemplars distribution of each of those features, hence, these characteristics determine the corpus’ usage possibilities. In this sense, sentences containing any biological element or knowledge were preferred but not limited to. It was more important that all similarity grades were represented within the corpus and preferably in equally proportions. Our main analysis axis was at the semantic similarity between a pair of sentences and not the topic represented by each sentence, neither the sentences specialization or technical level, nor the ontological specificity.</p><p id="P21">The corpus <italic>topic</italic> orientation impact directly in the resulting vocabulary variety and size. Whereas embracing more topics can broad the corpus possibilities of use, it can also have negative consequences in the semantic similarity measures due to the increased chances of the same term having different meanings for different topics (ambiguity). Consequently, a limited set of topics is preferred. Our intention was that the corpus be representative of the genetic regulation literature. It is worth noting that it was not limited to those sentences specifically about genetic regulation but all kind of sentences present in the correspondent literature. The corpus <italic>homogeneity</italic> was tackled by stripping out those sentences considered too short (less than 10 words) (<xref ref-type="bibr" rid="R18">[KKM]</xref>) and those sentences that were not part of the main body of the article<xref ref-type="fn" rid="FN3"><sup>3</sup></xref></p><p id="P22">Finally, the corpus’ <italic>size</italic> should be dependent on the questions that it is aimed to answer and the type of tasks where it would be applied (<xref ref-type="bibr" rid="R23">[PCH07]</xref>, <xref ref-type="bibr" rid="R16">[Juc12]</xref>). However, in practice it is largely restrained according to available resources (time, money and people). Our main goals are, to train our STS system and to measure its performance. Because our STS system is based on the combination of several similarity methods, and more to come, it is difficult to estimate the required number of cases that would fulfill significant training source for the reason that it depends of each type of metric. For example, one of the most demanding methods on training data are neural networks, whose complexity can be expressed based on the number of parameters (<italic>P</italic>) and it is common practice to have at least <italic>P</italic><sup>2</sup> training cases. This would results in thousands of training cases, which is out of our reach. Thus we focused in the second goal, to measure the STS system performance. We plan to measure the Pearson’s correlation between the computed system similarity and that generated by human-experts (corpus). Accordingly to <xref ref-type="bibr" rid="R6">[Coh92]</xref>, considering a medium size effect (r=0.30), a significance level of 0.05 and a power of 80%, 85 samples would be enough. However, <xref ref-type="bibr" rid="R21">[MG14]</xref> and <xref ref-type="bibr" rid="R24">[Pen]</xref> suggested a minimum sample size of 120 cases in order to cover not only the Pearson’s correlation but a regression analysis as well. With this in mind, we decided to generate a corpus of 170 sentence pairs, just above those thresholds.</p><p id="P23">Lastly, as a validity exercise, we compared our design decisions versus those taken in other corpora, for example, the Microsoft Paraphrase Corpus. Within the construction of the MSRP corpus (<xref ref-type="bibr" rid="R7">[DB05]</xref>), several constraints were applied to narrow the space of possible paraphrases. However, in our opinion and for our specific purpose, these guidelines limit the aspects of semantic similarity that the corpus could capture. For example: only those pairs of sentences with at least 3 words in common and within a range of Levenshtein edit distance were considered, but these are constraining similarity, at least at some degree, to a textual one; it was required that for a pair to be candidate, the length in words of the shorter sentence had to be more than 66% of the length of the longer sentence thus limiting the possibility for the corpus to represent the cross-level semantic similarity (<xref ref-type="bibr" rid="R15">[JPN16]</xref>), a phenomenon of sentences with different length. It also worth to note that the MSPRP has an agreed consensus that 67% of the proposed sentence pairs are paraphrases, meaning that the majority of sentences are semantically equivalent and, therefore, other grades of similarity and even non-similarity are under-represented.</p><sec id="S5"><label>3.1.1</label><title>Compiling the corpus</title><p id="P24">As stated in the sampling criteria of the corpus design, the selection of candidate pairs was performed using a basic STS process that automatically assigned similarity scores consisting in continuous numbers between 0 and 1 inclusive, where 1 represented exactly semantic equivalence<xref ref-type="fn" rid="FN4"><sup>4</sup></xref> and 0 totally unrelated meaning. Next, the final candidate sentences were selected by a balanced stratified random sampling from those pre-rated sentence pairs.</p><p id="P25">This process was applied to two different sets: the <italic>anaerobiosis FNR</italic> subset formed by articles about the anaerobiosis from which 40% of the sentences were taken; and the <italic>general</italic> set, consisting of sentences taken by randomly sampling all RegulonDB’s articles from which the remaining 60% was selected. The former subset was built manually by an expert-curator who selected sentences considered relevant within the subject. The later subset was generated by randomly choosing two sentences from each of the 5963 processed articles. In order to focus on sentences belonging to the article’s main body, only sentences within the 30% to 70% of the article’s length were selected<xref ref-type="fn" rid="FN5"><sup>5</sup></xref>.</p></sec></sec><sec id="S6"><label>3.2</label><title>Annotation design</title><p id="P26">Besides the corpus design, it was necessary to delineate the semantic similarity rating process. We followed a similar rating scale to the one used in SEMEVAL. An ordinal scale ranging from 0 to 4, where 0 represents a totally disconnected semantic relation between the two sentences, and 4 conveys an exact semantic match, having in the middle 3 other similarity shades, as shown in <xref ref-type="table" rid="T1">table 1</xref>.</p><p id="P27"><italic>Each sentence pair would be rated by 3 evaluators</italic> selected by chance from 7<xref ref-type="fn" rid="FN6"><sup>6</sup></xref> different groups, which in turn were formed by the combination of 3 from 7 different human-experts. This resulted in a <italic>non-fully crossed design,</italic> i.e., different items (subjects) were annotated by different raters. Even when it is possible that only 2 annotators rated each item (<xref ref-type="bibr" rid="R8">[DLL<sup>+</sup>12]</xref>), we considered that 3 annotators bring the best balance and flexibility; on the one hand it allows to evaluate a larger number of exemplars and, on the other. 3 is the smallest number to use the median when there is no consensus and a discrete final score is desired.</p><p id="P28">Due to the fact that “what is considered semantically equivalent” is prone to be biased by personal subjective considerations, it was necessary to homogenize the annotation process among raters. To achieve this, a training period (annotation guideline refinement period) of 4 iterated sessions was scheduled, so annotators could get familiarized with the annotation guidelines and the corpora to be rated. During this training, each session consisted in evaluating a small subset of sentence pairs and at the end of each session, disagreements would be discussed and resolved, and annotation guidelines more precisely defined. This training period was considered concluded when a minimum annotator inter-agreement was achieved or the annotators qualitatively considered that they have fully understood the annotation guidelines.</p><sec id="S7"><label>3.2.1</label><title>General guidelines</title><p id="P29">In order to make the annotation process less subjective some general guidelines were given to raters. These were collected from other corpus building experiments (<xref ref-type="bibr" rid="R28">[TMSP17]</xref>) and from our own observations, including:</p><list list-type="bullet" id="L1"><list-item><p id="P30"><italic>Order,</italic> clauses in compound sentences can be arranged in a different order without this implying a change in its meaning.</p></list-item><list-item><p id="P31"><italic>Missing clauses</italic>, in complex or compound sentences, if a clause is present in one and missing in the other, it do not automatically results in a zero similarity. It depends on grade of importance of the shared information.</p></list-item><list-item><p id="P32"><italic>Adjectives,</italic> missing adjectives in principle do not affect similarity</p></list-item><list-item><p id="P33"><italic>Enumerations</italic>, missing elements can be considered as a minor decrease in the similarity score unless enumeration convey the main sentence meaning. Reordering is considered as equivalent.</p></list-item><list-item><p id="P34"><italic>Abbreviations</italic>, are considered equivalent, e.g. “vs” and “versus”</p></list-item><list-item><p id="P35"><italic>Hyperonyms and hyponyms</italic>, share a grade of similarity “sugar substance” vs “honey” vs “bee honey”</p></list-item><list-item><p id="P36">Compound words, some terms are semantically equivalent to multi-term expressions, e.g.,</p></list-item><list-item><p id="P37"><italic>Generalization or abstractions</italic>, consider that two textual expressions share some grade of semantic similarity if one is a generalization or abstraction of the other, e.g. 8 vs “one digit number”</p></list-item></list></sec><sec id="S8"><label>3.2.2</label><title>Consensuated refinement</title><p id="P38">General guidelines were subsequently refined and enriched during the consensus sessions.</p><p id="P39">As a first approximation to clarify the rating scale in our context, it was decided to use the class of the Regulon’s objects as topic markers within the sentences. RegulonDB contains objects of the following classes: Gene, Features, Promoter, Transcription Unit (TU), Regulatory Interaction (RI), Reaction, Transcription Factors(TF), Growth Conditions (GC). Examples clarifying the scale similarity are the following:</p><list list-type="bullet" id="L2"><list-item><p id="P40"><bold>[4]</bold> Both sentences have in common the same objects and express the same meaning, i.e. they are paraphrase of each other. Example cases: <list list-type="simple" id="L3"><list-item><label>–</label><p id="P41">Both sentences express the same meaning. <list list-type="simple" id="L4"><list-item><label>*</label><p id="P42">This would mean that the IS5 element is able to provide FNR regulatory sites if inserted at appropriate positions.</p></list-item><list-item><label>*</label><p id="P43">In any case, insertion of an IS5 element is able to increase FNR-dependent expression or to place genes under FNR control.</p></list-item></list></p></list-item></list></p></list-item><list-item><p id="P44"><bold>[3]</bold> Both sentences share the same objects and other elements of its meaning. However one of the sentences lack relevant elements or refers to the same objects, arrive to different conclusions. Example cases: <list list-type="simple" id="L5"><list-item><label>–</label><p id="P45">Both sentences refers to the same Gene and share all other information, except that in one it is an activated and in the other is repressed.</p></list-item><list-item><label>–</label><p id="P46">Sentences referencing to same RI but just differ in the RI’s conditions.</p></list-item><list-item><label>–</label><p id="P47">Both sentences are almost paraphrase but one have more details. <list list-type="simple" id="L6"><list-item><label>*</label><p id="P48">These results confirm that the N-terminal domain of NikR is responsible for DNA recognition.</p></list-item><list-item><label>*</label><p id="P49">In preliminary experiments, we have also found that a subset of mutations within the DNA region protected by the N-terminal domain reduce the affinity of NikR for the operator data not shown!.</p></list-item></list></p></list-item></list></p></list-item><list-item><p id="P50"><bold>[2]</bold> Both sentences share at least one specific object and some other similarities. In this sense, contrasting conditions are considered as equivalent conditions, this is, they are taken as the same object. Example cases: <list list-type="simple" id="L7"><list-item><label>–</label><p id="P51">Both sentences refer to the same TF <list list-type="simple" id="L8"><list-item><label>*</label><p id="P52">The fnr mutant was thus deficient in the anaerobic induction of fumarate reductase expression.</p></list-item><list-item><label>*</label><p id="P53">Aerobic regulation of the sucABCD genes of Escherichia coli, which encode K-ketoglutarate dehydrogenase and succinyl coenzyme A synthetase: roles of Arc A, Fnr, and the upstream sdhCDAB promoter.</p></list-item></list></p></list-item><list-item><label>–</label><p id="P54">Contrasting conditions taken as equivalent conditions. <list list-type="simple" id="L9"><list-item><label>*</label><p id="P55">Aerobic regulation of the sucABCD genes of Escherichia coli, which encode K-ketoglutarate dehydrogenase and succinyl coenzyme A synthetase: roles of Arc A, Fnr, and the upstream sdhCDAB promoter.</p></list-item><list-item><label>*</label><p id="P56">Transcription of the fdnGHI and narGHJI operons is induced during anaerobic-growth in the presence of nitrate.</p></list-item></list></p></list-item></list></p></list-item><list-item><p id="P57"><bold>[1]</bold> Both sentences have the same object’s class in common but the specific object is different. Due to Gene and GC objects are highly common in RegulonDB’s literature, it was decided that sharing just these classes is not a sufficient condition for sentences to be rated as <bold>[1]</bold>. When comparing sentence that refers to a TF with other that refers to any other object (or GC) that refers to the same process in which the TF is involved, the sentence pair has to be considered as <bold>[1]</bold>. Example cases: <list list-type="simple" id="L10"><list-item><label>–</label><p id="P58">Both sentences refer to sequences and genes, even when neither the sequences nor the genes refered are the same. <list list-type="simple" id="L11"><list-item><label>*</label><p id="P59">The low level of 3-galactosidase expression seen in dinF1::Mu d (Ap lac) derivatives containing the lexA7J:TnS mutation but not the lex AS J (Def) mutation might then be due to a polar effect of the Tn5 insertion in the lexA gene on transcription at the dinF locus.</p></list-item><list-item><label>*</label><p id="P60">Sequence comparisons (18) suggest that E. coli and S. typhimurium have the same gene order in the metA-metH region, in agreement with P22 mapping studies.</p></list-item></list></p></list-item><list-item><label>–</label><p id="P61">Other example <list list-type="simple" id="L12"><list-item><label>*</label><p id="P62">To construct lADHop656 (operon fusion) and lADHpr656 (protein fusion), a 1.1-kb DNA fragment was excised from pADH8 by Bglll and BstYI.</p></list-item><list-item><p id="P63">*<italic>The product was ligated into the BamHI site of the plasmid pRS415 (for an operon fusion) and pRS414 (for a protein fusion).</italic></p></list-item></list></p></list-item></list></p></list-item><list-item><p id="P64"><bold>[0]</bold> Sentences do not even share object’s class. Example cases: <list list-type="simple" id="L13"><list-item><label>–</label><p id="P65">Sentences share to Gene and GC class (exception of <bold>[1]</bold> rate) but not the same specific objects. <list list-type="simple" id="L14"><list-item><label>*</label><p id="P66">Aerobic regulation of the sucABCD genes of Escherichia coli, which encode K-ketoglutarate dehydrogenase and succinyl coenzyme A synthetase: roles of Arc A, Fnr, and the upstream sdhCDAB promoter.</p></list-item><list-item><label>*</label><p id="P67">Carbon metabolism regulates expression of the pfl (pyruvate formatelyase) gene in Escheiichia coli.</p></list-item></list></p></list-item></list></p></list-item></list><p id="P68">It was clarified that sentences do not necessarily have to contain biological content or refer to RegulonDB’s objects to be annotated and have rates above <italic>0.</italic> The annotation is assessing the similarity in meaning irrespective of the topic.</p></sec><sec id="S9"><label>3.2.3</label><title>Annotation process</title><p id="P69">To facilitate the annotation process, we decided to provide annotators with a spread sheet template (see <xref ref-type="fig" rid="F1">figure 1</xref>). The template was designed so that all needed information would be in it and the rater did not had to switch to other files. It consist of a list of all sentence pairs that the annotator has to rate, for each pair the sentences’ ID and text are displayed. This area where the user writes the scores is organized by columns where each column represents an annotation session with date and time at the top cells. A small rating scale table is also included as reference.</p><p id="P70">The process consisted in: provide each annotator with a file, based on the annotation template, containing exclusively the sentence pairs that have to be evaluated by him/her; annotators had a fixed period of time of one week to rate all pairs; during that period each annotator could divide the rating task in as many sessions as desired adding date and time of each; it was indicated that sessions should be exclusive and continuous, i.e., task should not be interrupted by more than 5 minutes and annotators should not be performing other tasks in parallel.</p></sec></sec></sec><sec id="S10"><label>4</label><title>Corpus evaluation</title><p id="P71">The recommended way to evaluate the quality of the resulting corpus is through the Inter-Rater Agreement also known as Inter-Rater Reliability (IRR) ([<xref ref-type="bibr" rid="R14">Hal12</xref>, <xref ref-type="bibr" rid="R12">Gwe02a</xref>, <xref ref-type="bibr" rid="R29">VBMR14</xref>, <xref ref-type="bibr" rid="R8">DLL<sup>+</sup>12</xref>, <xref ref-type="bibr" rid="R4">BMB08</xref>, <xref ref-type="bibr" rid="R20">Mch17</xref>]). IRR is a mean to measure the agreement between two or more annotators who rated an item in a nominal, ordinal, interval or ratio scale. It is based on the idea that <italic>observed scores</italic> (<italic>O</italic>) are the result of the scores that would be obtained if there were no measurement error –<italic>true scores</italic> (<italic>T</italic>)– plus the <italic>measurement error</italic> (<italic>E</italic>), i.e. <italic>O</italic> = <italic>T</italic> + <italic>E</italic> (<xref ref-type="bibr" rid="R14">[Hal12]</xref>). One possible source of the measurement errors is the measure instrument’s instability when multiple annotators are involved. IRR focuses in analyzing how much of the observed scores’ variance corresponds to variance in the true scores by removing the measurement error between annotators. Thus, the reliability coefficient represents how close are the given scores (by multiple annotators) to what would be expected if all annotators would have used the same instrument; the highest the coefficient, the better the scores reliability.</p><p id="P72">There are multiple IRR statistics and which should be used depends on the study design. Factors such as: the type of the measured variable (nominal, ordinal, etc.); if it is a fully-crossed design or not; and if what it is desired is to measure the annotator or the ratings reliability have to be considered to select the IRR statistic and/or its variant.</p><p id="P73">Our design (see <xref ref-type="sec" rid="S6">section 3.2</xref>) corresponds to non fully-crossed design where an ordinal variable is measured and we are interested in measuring the ratings reliability. Having that in mind, the statistics that better accommodate are <italic>Fleiss’ Kappa</italic> (Fleiss) (<xref ref-type="bibr" rid="R10">[Fle71]</xref>). <italic>Krippendorff’s alpha</italic> (Kripp), <italic>Intra Class Correlation</italic> (ICC) (<xref ref-type="bibr" rid="R2">[Bar66]</xref>), <italic>Kendall</italic> (Kendall) (<xref ref-type="bibr" rid="R17">[Ken48]</xref>) and <italic>Gwet’s AC1</italic> (Gwet) (<xref ref-type="bibr" rid="R12">[Gwe02a]</xref>).</p><p id="P74">One of the most used IRR statistic is the Cohen’s Kappa analysis (k) (<xref ref-type="disp-formula" rid="FD6">eq 6</xref>) (<xref ref-type="bibr" rid="R5">[Coh60]</xref>). It is a relation between <italic>the proportion of units in which the annotators agreed,</italic> <inline-formula><mml:math id="M1"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="fraktur">p</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <italic>the proportion of units for which agreement is expected by chance</italic> <inline-formula><mml:math id="M2"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="fraktur">p</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, thus <inline-formula><mml:math id="M3"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="fraktur">p</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="fraktur">p</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="fraktur">p</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Originally this measure was intended for just two annotators who rate all items, so variants were developed in order to fit non fully-crossed study designs with more than two raters per item. The <italic>Fleiss’ Kappa</italic> (<xref ref-type="disp-formula" rid="FD1">eq 1</xref>). is a no weighting measure that considers unordered categories and it was designed for cases when <italic>m</italic> evaluators are randomly sampled from a larger population of evaluators, and each item is rated by a different sample of <italic>m</italic> evaluators. In equation <italic>p</italic><sub><italic>a</italic></sub> represents the averaged extent to which raters agree for the items rate, and <italic>p</italic><sub><italic>ϵ</italic></sub> the proportion of assignments to the categories. <disp-formula id="FD1"><label>(eq 1)</label><mml:math id="M4"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>ϵ</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>ϵ</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p id="P75"><italic>Krippendorff’s Alpha</italic> (<xref ref-type="disp-formula" rid="FD2">eq 2</xref>) is a inter-rater reliability measure that is based on computing the disagreement. It provides advantages like being able to handle missing data, handling various sample sizes, and supports categorical, ordinal, interval or ratio measured variable metric. In <xref ref-type="disp-formula" rid="FD2">eq 2</xref>, <italic>D</italic><sub><italic>o</italic></sub> is the observed disagreement and <italic>D</italic><sub><italic>ϵ</italic></sub> the disagreement one would get if rates were by chance, thus it is the ration between the observed disagreement and the expected disagreement. <disp-formula id="FD2"><label>(eq 2)</label><mml:math id="M5"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>ϵ</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p id="P76"><italic>Intra-class correlation</italic> (<xref ref-type="disp-formula" rid="FD3">eq 3</xref>) is a consistency measure that can be used to evaluate the ratings’ reliability by comparing the item’s ratings variability to the variability of all items and all ratings. It is appropriate for fully-crossed as well for non-fully crossed designs and when there are two or more evaluators. Another feature is that the disagreement’s magnitude is considered in the computation, such as in a weighted Kappa. In eq 3 <italic>var</italic>(<italic>β</italic>) accounts for variability due to differences in the items, <italic>var</italic>(<italic>α</italic>) from variability due to differences in the item’s revaluations, and <italic>var</italic>(<italic>ϵ</italic>) for the variability due to differences in the rating scale used by annotators. Consistent with our study design, we selected the ICC variant as: A “one way” model, to avoid from accounting for systematic deviations among evaluators because annotators for each item are selected at random; and used the average as the unit of analysis, because all items were rated by an equal number of annotators (i.e. 3). <disp-formula id="FD3"><label>(eq 3)</label><mml:math id="M6"><mml:mrow><mml:mi>I</mml:mi><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>v</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>β</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>v</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>β</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>v</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p id="P77"><italic>Kendall’s coefficient</italic> is an association measure based on the ranked items that quantifies the degree of agreement among annotators. As a special case of the correlation coefficient, this coefficient will be high when items’ order (ranked by the given rate) would be similar across annotators. It is based on the computation of the symmetric distances between the ranks, and then normalize it. Because it relies in the distances instead of the absolute values, it better handles consistent rater biases, i.e. the bias effect. In eq 4 <italic>n</italic><sub><italic>c</italic></sub> refers to the number of concordant and <italic>n</italic><sub><italic>d</italic></sub> to the number of discordant with in a sample of <italic>n</italic> number of items. <disp-formula id="FD4"><label>(eq 4)</label><mml:math id="M7"><mml:mrow><mml:mi>W</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>n</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p id="P78"><xref ref-type="bibr" rid="R13">[Gwe02b]</xref> demonstrated that Kappa coefficient is influenced by trait prevalence (distribution) and base-rates, thus limiting the comparison across studies. For that reason <xref ref-type="bibr" rid="R12">[Gwe02a]</xref> proposed a IRR coefficient (<xref ref-type="disp-formula" rid="FD6">eq 6</xref>) that, as Cohen’s Kappa statistic, adjusts the chance agreement – raters agree based on a random rating– to avoid inflating the agreement probability with not true intentional rater’s agreement. However, <italic>Gwet’s coefficient</italic> has the property of not relying on independence between observations, weights are based on weighted dissimilarities. This coefficient presents several advantages: it is less sensitive to marginal homogeneity and positively biases for trait prevalence (more stable); it can be extended to multiple raters; As Krippendorff’s coefficient it can deal with categorical, ordinal, interval or ratio measures and it can handle missing data; contrary to weighted Kappa, it is not necessary to provide arbitrary weights when applied to ordinal data. <disp-formula id="FD5"><label>(eq 5)</label><mml:math id="M8"><mml:mrow><mml:mi>K</mml:mi><mml:mi>a</mml:mi><mml:mi>p</mml:mi><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mo>−</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula> <disp-formula id="FD6"><label>(eq 6)</label><mml:math id="M9"><mml:mrow><mml:mi>A</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mo>−</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>γ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>γ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p id="P79">The difference between Gwet and Kappa is in the way that probability of chance agreement are estimated. In Kappa, <italic>e</italic>(<italic>κ</italic>) is based in combining the estimates of the chance that both raters independently classify a subject into category 1 and estimates the probability of independent classification of a subject into category 2 (<xref ref-type="disp-formula" rid="FD7">eq 7</xref>). Whereas in Gwet, it is based in the chance that any rater (A or B) classifies an item into a category (<xref ref-type="disp-formula" rid="FD8">eq 8</xref>). <disp-formula id="FD7"><label>(eq 7)</label><mml:math id="M10"><mml:mrow><mml:mi>e</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mi>A</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:mfrac><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mi>B</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:mfrac><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mi>A</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:mfrac><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mi>B</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula> <disp-formula id="FD8"><label>(eq 8)</label><mml:math id="M11"><mml:mrow><mml:mi>e</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>γ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>P</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:mfrac><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:mfrac><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P80">It is important to note that Gwet proposed 2 variants of its statistic, AC1 and AC2. AC2 is a weighted version —some disagreements between raters are considered more serious than others— of AC1 thus a better alternative for ordinal data. AC2 is intended to be used with any number of raters and an ordered categorical rating system to rate objects, as it is our case. In AC2 both chance-agreement as well as misclassification errors are adjusted, thus it is defined as “bias-adjusted conditional probability that two randomly chosen raters agree given that there is no agreement by chance” (<xref ref-type="bibr" rid="R12">[Gwe02a]</xref>).</p></sec><sec id="S11" sec-type="results"><label>5</label><title>Results</title><sec id="S12"><label>5.1</label><title>Training period</title><p id="P81">The training period consisted in 4 iterations in each of which a set of sentence pairs was rated by all annotators and afterwards, we had a consensus session where conflicts were resolved and questions about the guidelines were answered, resulting in guidelines updating.</p><p id="P82">We performed the IRR analysis of each iteration in order to review the effect of consensus sessions in homogenizing the annotation process. As can be seen in <xref ref-type="fig" rid="F3">figure 3</xref> and table 5.1, the grade of inter-agreement increased in each iteration irrespectively of the statistic. In the 4th session we reached a Fleiss’ Kappa of 0f 0.546 as the lowest metric, considered as a <italic>moderate</italic> strength of agreement (<xref ref-type="bibr" rid="R19">[LK77]</xref>). However, we have to remember that this metric is a non-weighting coefficient, i.e., it considers as bad that an item is rated 0 and 4 by two different annotators, as if they are rated 2 and 3. That is why we reached an <italic>almost perfect</italic> IRR in statistics that better deals with ordinal scales: ICC (0.964) and Gwet’s AC2 (0.910). It is worth to note that Gwet’s coefficients are much more recommended methods to compute IRR than those of the Kappa coefficients family.</p><p id="P83">We also compared the IRR between all combinations of annotators’s pairs as a way to detect consistent bias of one annotator versus the others, see <xref ref-type="fig" rid="F3">figure 3</xref>. We detected that more guidelines’ clarifications were needed with annotator 4 who consistently had lower IRR with the other raters.</p></sec><sec id="S13"><label>5.2</label><title>Corpus</title><p id="P84">After the training period we built the corpus based on the proposed designed (3.2). It resulted in 171 pairs of sentences each rated by 3 annotators taken by chance from a group of 7<xref ref-type="fn" rid="FN7"><sup>7</sup></xref>.</p><p id="P85">Several IRR analysis were performed to assess the degree that annotators consistently assigned similarity ratings to sentence pairs (see <xref ref-type="table" rid="T2">table 2</xref>). The marginal distributions of similarity ratings did not indicate a considerable bias among annotators (<xref ref-type="fig" rid="F5">figure 5</xref>) but it shows a prevalence effect towards lower similarity rates (<xref ref-type="fig" rid="F4">figure 4</xref>). A statistic less sensitive to this effect is Gwet’s AC which makes an appropriate index of IRR. in particular the AC2 variant due to the ordinal nature of our data. The resulting coefficient indicated <italic>very good agreement</italic> (<xref ref-type="bibr" rid="R30">[WWWG13]</xref>) of <italic>AC</italic>2 = 0.8696 with a 95% confidence interval (0.8399 - 0.8993).</p><p id="P86">For the sake of clarity, we investigated if the non fully-crossed design caused too inflated coefficients. To do this we first grouped the sentence pairs by the annotators who rate them; next, we computed the IRR for each group —it is worth to note that each of these groups is now fully-crossed—; and finally, we computed the arithmetic mean of all groups. The resulting averages (table 5.2) were quite similar to coefficients computed for the whole corpus, re-confirming the corpus reliability.</p><p id="P87">From the individual ratings distribution (<xref ref-type="fig" rid="F4">fig 4</xref>) we can see that although the distribution is biased towards no similarity, we got a good amount (&gt; 50%) of sentence pairs rated within 1-3 score.</p></sec></sec><sec id="S14" sec-type="conclusions"><label>6</label><title>Conclusion</title><p id="P88">We did not got a corpus with as balanced ratings as desired, however, we have a good representation of 4 of the 5 rates and a corpus with very good inter-rater reliability. Therefore, it is going to serve well our purposes and we think it can be a quite valuable starting point, with respect to data and processes to continue building a standard similarity corpus in the transcriptional regulation’s literature field. To the best of our understanding, this is the first similarity corpus in the topic and thus, it represents a step stone towards the evaluation and training of NLP-based high-throughput curation’s systems.</p></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Movie 1</label><media xlink:href="EMS200697-supplement-Movie_1.mp4" mimetype="video" mime-subtype="mp4" id="d305aAcGbB" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD2"><label>Movie 2</label><media xlink:href="EMS200697-supplement-Movie_2.mp4" mimetype="video" mime-subtype="mp4" id="d305aAcGcB" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD3"><label>Supplementary Table 1</label><media xlink:href="EMS200697-supplement-Supplementary_Table_1.xlsx" mimetype="application" mime-subtype="vnd.openxmlformats-officedocument.spreadsheetml.sheet" id="d305aAcGdB" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD4"><label>Supplementary Table 2</label><media xlink:href="EMS200697-supplement-Supplementary_Table_2.xlsx" mimetype="application" mime-subtype="vnd.openxmlformats-officedocument.spreadsheetml.sheet" id="d305aAcGeB" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD5"><label>Supplementary Table 3</label><media xlink:href="EMS200697-supplement-Supplementary_Table_3.xlsx" mimetype="application" mime-subtype="vnd.openxmlformats-officedocument.spreadsheetml.sheet" id="d305aAcGfB" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD6"><label>Appendix</label><media xlink:href="EMS200697-supplement-Appendix.pdf" mimetype="application" mime-subtype="pdf" id="d305aAcGgB" position="anchor"/></supplementary-material></sec></body><back><ack id="S15"><title>Acknowledgments</title><p>We acknowledge funding from UNAM, from FOINS CONACyT Fronteras de la Ciencia [project 15], and from the National Institutes of Health (grant number 5R01GM110597-03). CMA is a doctoral student from Programa de Doctorado en Ciencias Biomédicas, Universidad Nacional Autónoma de México (UNAM) and received fellowship 576333 from CONACYT.</p></ack><fn-group><fn id="FN1"><label>1</label><p id="P89"><ext-link ext-link-type="uri" xlink:href="http://regulondb.ccg.unam.mx/">http://regulondb.ccg.unam.mx/</ext-link></p></fn><fn id="FN2"><label>2</label><p id="P90">declarative, interrogative, exclamatory, etc.</p></fn><fn id="FN3"><label>3</label><p id="P91">Based on the stylographic tag assigned by our home-made PDF processing tool.</p></fn><fn id="FN4"><label>4</label><p id="P92">Applying a baseline metric</p></fn><fn id="FN5"><label>5</label><p id="P93">This is, we discarded as selection candidates the first 30% and the last 30% of the article’s sentences</p></fn><fn id="FN6"><label>6</label><p id="P94">The 7 groups were taken by chance from all group combinations.</p></fn><fn id="FN7"><label>7</label><p id="P95">Corpus is also available at <ext-link ext-link-type="uri" xlink:href="https://github.com/JCollado-NLP/Corpus-Transcriptional-Regulation">https://github.com/JCollado-NLP/Corpus-Transcriptional-Regulation</ext-link></p></fn></fn-group><ref-list><ref id="R1"><label>[ACD<sup>+</sup>13]</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Agirre</surname><given-names>Eneko</given-names></name><name><surname>Cer</surname><given-names>Daniel</given-names></name><name><surname>Diab</surname><given-names>Mona</given-names></name><name><surname>Gonzalez-Agirre</surname><given-names>Aitor</given-names></name><name><surname>Guo</surname><given-names>Weiwei</given-names></name></person-group><source>*SEM 2013 shared task : Semantic Textual Similarity</source><conf-name>The Second Joint Conference on Lexical and Computational Semantics (*SEM 2013)</conf-name><year>2013</year><volume>1</volume><fpage>32</fpage><lpage>43</lpage></element-citation></ref><ref id="R2"><label>[Bar66]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bartko</surname><given-names>John J</given-names></name></person-group><article-title>The Intraclass Correlation Coefficient as a Measure of Reliability</article-title><source>Psychological Reports</source><year>1966</year><volume>19</volume><issue>1</issue><fpage>3</fpage><lpage>11</lpage><pub-id pub-id-type="pmid">5942109</pub-id></element-citation></ref><ref id="R3"><label>[BG08]</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bernhard</surname><given-names>Delphine</given-names></name><name><surname>Gurevych</surname><given-names>Iryna</given-names></name></person-group><source>Answering learners’ questions by retrieving question paraphrases from social Q&amp;A sites</source><conf-name>Proceedings of the Third Workshop on Innovative Use of NLP for Building Educational Applications - EANL ’08</conf-name><year>2008</year><month>June</month><fpage>44</fpage><lpage>52</lpage></element-citation></ref><ref id="R4"><label>[BMB08]</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bhowmick</surname><given-names>Plaban Kr</given-names></name><name><surname>Mitra</surname><given-names>Pabitra</given-names></name><name><surname>Basu</surname><given-names>Anupam</given-names></name></person-group><source>An agreement measure for determining inter-annotator reliability of human judgements on affective text</source><conf-name>Proceedings of the Workshop on Human Judgements in Computational Linguistics - HumanJudge ’08</conf-name><year>2008</year><month>August</month><fpage>58</fpage><lpage>65</lpage></element-citation></ref><ref id="R5"><label>[Coh60]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>Jacob</given-names></name></person-group><article-title>A Coefficient of Agreement for Nominal Scales</article-title><source>Educational and Psychological Measurement</source><year>1960</year><volume>20</volume><issue>1</issue><fpage>37</fpage><lpage>46</lpage></element-citation></ref><ref id="R6"><label>[Coh92]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>Jacob</given-names></name></person-group><article-title>A Power Primer</article-title><year>1992</year><month>July</month><pub-id pub-id-type="pmid">19565683</pub-id></element-citation></ref><ref id="R7"><label>[DB05]</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Dolan</surname><given-names>William B</given-names></name><name><surname>Brockett</surname><given-names>Chris</given-names></name></person-group><source>Automatically Constructing a Corpus of Sentential Paraphrases</source><conf-name>Proceedings of the Third International Workshop on Paraphrasing (IWP2005)</conf-name><year>2005</year><fpage>9</fpage><lpage>16</lpage></element-citation></ref><ref id="R8"><label>[DLL<sup>+</sup>12]</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Deleger</surname><given-names>Louise</given-names></name><name><surname>Li</surname><given-names>Qi</given-names></name><name><surname>Lingren</surname><given-names>Todd</given-names></name><name><surname>Kaiser</surname><given-names>Megan</given-names></name><name><surname>Molnar</surname><given-names>Katalin</given-names></name><name><surname>Stouten-borough</surname><given-names>Laura</given-names></name><name><surname>Kouril</surname><given-names>Michal</given-names></name><name><surname>Marsolo</surname><given-names>Keith</given-names></name><name><surname>Solti</surname><given-names>Imre</given-names></name></person-group><source>Building gold standard corpora for medical natural language processing tasks</source><conf-name>AMI A … Annual Symposium proceedings / AMIA Symposium. AMIA Symposium</conf-name><year>2012</year><volume>2012</volume><fpage>144</fpage><lpage>53</lpage></element-citation></ref><ref id="R9"><label>[EVW<sup>+</sup>10]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Everingham</surname><given-names>Mark</given-names></name><name><surname>Van Gool</surname><given-names>Luc</given-names></name><name><surname>Williams</surname><given-names>Christopher KI</given-names></name><name><surname>Winn</surname><given-names>John</given-names></name><name><surname>Zisserman</surname><given-names>Andrew</given-names></name></person-group><article-title>The Pascal Visual Object Classes (VOC) Challenge</article-title><source>International Journal of Computer Vision</source><year>2010</year><month>jun</month><volume>88</volume><issue>2</issue><fpage>303</fpage><lpage>338</lpage></element-citation></ref><ref id="R10"><label>[Fle71]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fleiss</surname><given-names>Joseph L</given-names></name></person-group><article-title>Measuring nominal scale agreement among many raters</article-title><source>Psychological Bulletin</source><year>1971</year><volume>76</volume><issue>5</issue><fpage>378</fpage><lpage>382</lpage></element-citation></ref><ref id="R11"><label>[GCSSZ<sup>+</sup>16]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gama-Castro</surname><given-names>Socorro</given-names></name><name><surname>Salgado</surname><given-names>Heladia</given-names></name><name><surname>Santos-Zavaleta</surname><given-names>Alberto</given-names></name><name><surname>Ledezma-Tejeida</surname><given-names>Daniela</given-names></name><name><surname>Muñiz-Rascado</surname><given-names>Luis</given-names></name><name><surname>García-Sotelo</surname><given-names>Jair Santiago</given-names></name><name><surname>Alquicira-Hernández</surname><given-names>Kevin</given-names></name><name><surname>Martínez-Flores</surname><given-names>Irma</given-names></name><name><surname>Pannier</surname><given-names>Lucia</given-names></name><name><surname>Castro-Mondragón</surname><given-names>Jaime Abraham</given-names></name><name><surname>Medina-Rivera</surname><given-names>Alejandra</given-names></name><etal/></person-group><article-title>RegulonDB version 9.0: High-level integration of gene regulation, coexpression, motif clustering and beyond</article-title><source>Nucleic Acids Research</source><year>2016</year><volume>44</volume><issue>D1</issue><fpage>D133</fpage><lpage>D143</lpage><pub-id pub-id-type="pmcid">PMC4702833</pub-id><pub-id pub-id-type="pmid">26527724</pub-id><pub-id pub-id-type="doi">10.1093/nar/gkv1156</pub-id></element-citation></ref><ref id="R12"><label>[Gwe02a]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gwet</surname><given-names>Kilem</given-names></name></person-group><article-title>Inter-Rater Reliability : Dependency on Trait Prevalence and Marginal Homogeneity</article-title><source>Statistical Methods for Inter-Reliability Assessment</source><year>2002</year><issue>2</issue><fpage>1</fpage><lpage>9</lpage></element-citation></ref><ref id="R13"><label>[Gwe02b]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gwet</surname><given-names>Kilem</given-names></name></person-group><article-title>Kappa Statistic is not satisfactory for assessing the extent of agreement between raters</article-title><source>Statistical Methods For Inter-Rater Reliability Assessmen</source><year>2002</year><issue>1</issue><fpage>1</fpage><lpage>5</lpage></element-citation></ref><ref id="R14"><label>[Hal12]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hallgren</surname><given-names>Kevin A</given-names></name></person-group><article-title>Computing Inter-Rater Reliability for Observational Data: An Overview and Tutorial</article-title><source>Tutorials in Quantitative Methods for Psychology</source><year>2012</year><volume>8</volume><issue>1</issue><fpage>23</fpage><lpage>34</lpage><pub-id pub-id-type="pmcid">PMC3402032</pub-id><pub-id pub-id-type="pmid">22833776</pub-id><pub-id pub-id-type="doi">10.20982/tqmp.08.1.p023</pub-id></element-citation></ref><ref id="R15"><label>[JPN16]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jurgens</surname><given-names>David</given-names></name><name><surname>Pilehvar</surname><given-names>Mohammad Taher</given-names></name><name><surname>Navigli</surname><given-names>Roberto</given-names></name></person-group><article-title>Cross level semantic similarity: an evaluation framework for universal measures of similarity</article-title><source>Language Resources and Evaluation</source><year>2016</year><volume>50</volume><issue>1</issue><fpage>5</fpage><lpage>33</lpage></element-citation></ref><ref id="R16"><label>[Juc12]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Juckett</surname><given-names>David</given-names></name></person-group><article-title>A method for determining the number of documents needed for a gold standard corpus</article-title><source>Journal of Biomedical Informatics</source><year>2012</year><volume>45</volume><issue>3</issue><fpage>460</fpage><lpage>470</lpage><pub-id pub-id-type="pmid">22245601</pub-id></element-citation></ref><ref id="R17"><label>[Ken48]</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kendall</surname><given-names>MG</given-names></name></person-group><source>Rank correlation methods</source><publisher-loc>Griffin, Oxford, England</publisher-loc><year>1948</year></element-citation></ref><ref id="R18"><label>[KKM]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karaoğlan</surname><given-names>Bahar</given-names></name><name><surname>Kişla</surname><given-names>Tarik</given-names></name><name><surname>Metin</surname><given-names>Senem Kumova</given-names></name></person-group><article-title>Using Multiple Metrics in Automatically Building Turkish Paraphrase Corpus</article-title><year>2016</year><volume>117</volume><fpage>75</fpage><lpage>83</lpage></element-citation></ref><ref id="R19"><label>[LK77]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Landis</surname><given-names>J Richard</given-names></name><name><surname>Koch</surname><given-names>Gary G</given-names></name></person-group><article-title>The Measurement of Observer Agreement for Categorical Data</article-title><source>Biometrics</source><year>1977</year><volume>33</volume><issue>1</issue><fpage>159</fpage><pub-id pub-id-type="pmid">843571</pub-id></element-citation></ref><ref id="R20"><label>[Mch17]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mchugh</surname><given-names>Mary L</given-names></name></person-group><article-title>Interrater reliability : the kappa statistic Importance of measuring interrater reliability Measurement of interrater reliability</article-title><year>2017</year><volume>22</volume><issue>3</issue><fpage>276</fpage><lpage>282</lpage></element-citation></ref><ref id="R21"><label>[MG14]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moinester</surname><given-names>Murray</given-names></name><name><surname>Gottfried</surname><given-names>Ruth</given-names></name></person-group><article-title>Sample size estimation for correlations with pre-specified confidence interval</article-title><year>2014</year><fpage>124</fpage><lpage>130</lpage></element-citation></ref><ref id="R22"><label>[MM11]</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>McCarthy</surname><given-names>Philip M</given-names></name><name><surname>McNamara</surname><given-names>Danielle S</given-names></name></person-group><chapter-title>The User-Language Paraphrase Corpus</chapter-title><source>Cross-Disciplinary Advances in Applied Natural Language Processing</source><publisher-name>IGI Global</publisher-name><year>2011</year><fpage>73</fpage><lpage>89</lpage></element-citation></ref><ref id="R23"><label>[PCH07]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paroubek</surname><given-names>Patrick</given-names></name><name><surname>Chaudiron</surname><given-names>Stéphane</given-names></name><name><surname>Hirschman</surname><given-names>Lynette</given-names></name></person-group><article-title>Principles of Evaluation in Natural Language Processing</article-title><source>Traitement Automatique des Langues</source><year>2007</year><volume>48</volume><issue>1</issue><fpage>7</fpage><lpage>31</lpage></element-citation></ref><ref id="R24"><label>[Pen]</label><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Penyelidikan</surname><given-names>Jabatan</given-names></name></person-group><source>SAMPLE SIZE ESTIMATION USING KREJCIE AND MORGAN AND COHEN STATISTICAL POWER ANALYSIS: A COMPARISON Chua Lee Chuan Jabatan Penyelidikan</source></element-citation></ref><ref id="R25"><label>[RLMB12]</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Rus</surname><given-names>V</given-names></name><name><surname>Lintean</surname><given-names>M</given-names></name><name><surname>Moldovan</surname><given-names>C</given-names></name><name><surname>Baggett</surname><given-names>W</given-names></name></person-group><source>The SIMILAR Corpus: A Resource to Foster the Qualitative Understanding of Semantic Similarity of Texts</source><conf-name>Proceedings of Semantic Relations-II. Enhancing Resources and Applications. The 8th Language Resources and Evaluation Conference (LREC 2012)</conf-name><year>2012</year></element-citation></ref><ref id="R26"><label>[Sin04]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sinclair</surname><given-names>John</given-names></name></person-group><article-title>Developing Linguistic Corpora: a Guide to Good Practice</article-title><year>2004</year></element-citation></ref><ref id="R27"><label>[SÖÖ17]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soğancloğlu</surname><given-names>Gizem</given-names></name><name><surname>Öztürk</surname><given-names>Hakime</given-names></name><name><surname>Özgür</surname><given-names>Arzucan</given-names></name></person-group><article-title>BIOSSES: A semantic sentence similarity estimation system for the biomedical domain</article-title><source>Bioinformatics</source><year>2017</year><volume>33</volume><fpage>i49</fpage><lpage>i58</lpage><pub-id pub-id-type="pmcid">PMC5870675</pub-id><pub-id pub-id-type="pmid">28881973</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/btx238</pub-id></element-citation></ref><ref id="R28"><label>[TMSP17]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Torres-Moreno</surname><given-names>Juan-Manuel</given-names></name><name><surname>Sierra</surname><given-names>Gerardo</given-names></name><name><surname>Peinl</surname><given-names>Peter</given-names></name></person-group><article-title>A German Corpus for Text Similarity Detection Tasks</article-title><year>2017</year><volume>5</volume><issue>2</issue></element-citation></ref><ref id="R29"><label>[VBMR14]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vila</surname><given-names>Marta</given-names></name><name><surname>Bertran</surname><given-names>Manuel</given-names></name><name><surname>Marti</surname><given-names>M Antònia</given-names></name><name><surname>Rodríguez</surname><given-names>Horacio</given-names></name></person-group><article-title>Corpus annotation with paraphrase types: new annotation scheme and inter-annotator agreement measures</article-title><source>Language Resources and Evaluation</source><year>2014</year><volume>49</volume><issue>1</issue><fpage>77</fpage><lpage>105</lpage></element-citation></ref><ref id="R30"><label>[WWWG13]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wongpakaran</surname><given-names>Nahathai</given-names></name><name><surname>Wongpakaran</surname><given-names>Tinakon</given-names></name><name><surname>Wedding</surname><given-names>Danny</given-names></name><name><surname>Gwet</surname><given-names>Kilem L</given-names></name></person-group><article-title>A comparison of Cohen’s Kappa and Gwet’s AC1 when calculating inter-rater reliability coefficients : a study conducted with personality disorder samples</article-title><year>2013</year><fpage>1</fpage><lpage>7</lpage><pub-id pub-id-type="pmcid">PMC3643869</pub-id><pub-id pub-id-type="pmid">23627889</pub-id><pub-id pub-id-type="doi">10.1186/1471-2288-13-61</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>Annotation tompiate</title></caption><graphic xlink:href="EMS200697-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>IRR through agreement sessions</title></caption><graphic xlink:href="EMS200697-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>IRR between annotators</title></caption><graphic xlink:href="EMS200697-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Ratings distribution</title></caption><graphic xlink:href="EMS200697-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>Ratings distribution por annotator</title></caption><graphic xlink:href="EMS200697-f005"/></fig><table-wrap id="T1" position="float" orientation="portrait"><label>Table 1</label><caption><title>Rating scale</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle">Similarity tag</th><th align="left" valign="middle">Description</th></tr></thead><tbody><tr><td align="left" valign="middle">0</td><td align="left" valign="middle">The two sentences are on different topics.</td></tr><tr><td align="left" valign="middle">1</td><td align="left" valign="middle">The two sentences are not equivalent, but are on the same topic.</td></tr><tr><td align="left" valign="middle">2</td><td align="left" valign="middle">The two sentences are not equivalent, but share some details.</td></tr><tr><td align="left" valign="middle">3</td><td align="left" valign="middle">The two sentences are roughly equivalent, but some important information differs/ missing.</td></tr><tr><td align="left" valign="middle">4</td><td align="left" valign="middle">The two sentences are completely or mostly equivalent, as they mean the same thing.</td></tr></tbody></table></table-wrap><table-wrap id="T2" position="float" orientation="portrait"><label>Table 2</label><caption><title>Corpus’ inter-rate agreement for various statistics</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle">Statistic</th><th align="center" valign="middle">Variable</th><th align="center" valign="middle">Value</th><th align="center" valign="middle">p-value</th></tr></thead><tbody><tr><td align="left" valign="middle">Fleiss’ Kappa</td><td align="right" valign="middle">Kappa</td><td align="right" valign="middle">0.443</td><td align="right" valign="middle">0</td></tr><tr><td align="left" valign="middle">Krippendorff’s alpha</td><td align="right" valign="middle">alpha</td><td align="right" valign="middle">0.745</td><td align="right" valign="middle"/></tr><tr><td align="left" valign="middle">Kendall’s coefficient</td><td align="right" valign="middle">W</td><td align="right" valign="middle">0.741</td><td align="right" valign="middle">7.86e-18</td></tr><tr><td align="left" valign="middle">Intraclass Correlation</td><td align="right" valign="middle">ICC</td><td align="right" valign="middle">0.919</td><td align="right" valign="middle">6.7e-83</td></tr><tr><td align="left" valign="middle">Gwct’s coefficient</td><td align="right" valign="middle">AC2</td><td align="right" valign="middle">0.870</td><td align="right" valign="middle">0</td></tr></tbody></table></table-wrap><table-wrap id="T3" position="float" orientation="portrait"><label>Table 3</label><caption><title>IRR by annotators group</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle">Annotators</th><th align="left" valign="middle">Kendall</th><th align="left" valign="middle">Fleiss</th><th align="left" valign="middle">ICC</th><th align="left" valign="middle">Kripp</th><th align="left" valign="middle">Gwet</th></tr></thead><tbody><tr><td align="left" valign="middle">1,2,3</td><td align="left" valign="middle">0.782</td><td align="left" valign="middle">0.597</td><td align="left" valign="middle">0.941</td><td align="left" valign="middle">0.814</td><td align="left" valign="middle">0.864</td></tr><tr><td align="left" valign="middle">1,2,7</td><td align="left" valign="middle">0.641</td><td align="left" valign="middle">0.512</td><td align="left" valign="middle">0.926</td><td align="left" valign="middle">0.705</td><td align="left" valign="middle">0.894</td></tr><tr><td align="left" valign="middle">1,6,7</td><td align="left" valign="middle">0.788</td><td align="left" valign="middle">0.358</td><td align="left" valign="middle">0.912</td><td align="left" valign="middle">0.756</td><td align="left" valign="middle">0.686</td></tr><tr><td align="left" valign="middle">2,3,4</td><td align="left" valign="middle">0.669</td><td align="left" valign="middle">0.442</td><td align="left" valign="middle">0.916</td><td align="left" valign="middle">0.691</td><td align="left" valign="middle">0.907</td></tr><tr><td align="left" valign="middle">3,4,5</td><td align="left" valign="middle">0.712</td><td align="left" valign="middle">0.310</td><td align="left" valign="middle">0.894</td><td align="left" valign="middle">0.708</td><td align="left" valign="middle">0.802</td></tr><tr><td align="left" valign="middle">4,5,6</td><td align="left" valign="middle">0.593</td><td align="left" valign="middle">0.268</td><td align="left" valign="middle">0.753</td><td align="left" valign="middle">0.602</td><td align="left" valign="middle">0.818</td></tr><tr><td align="left" valign="middle">5,6,7</td><td align="left" valign="middle">0.833</td><td align="left" valign="middle">0.409</td><td align="left" valign="middle">0.913</td><td align="left" valign="middle">0.772</td><td align="left" valign="middle">0.784</td></tr><tr><td align="left" valign="middle">Mean</td><td align="left" valign="middle">0.717</td><td align="left" valign="middle">0.414</td><td align="left" valign="middle">0.894</td><td align="left" valign="middle">0.721</td><td align="left" valign="middle">0.822</td></tr></tbody></table></table-wrap></floats-group></article>