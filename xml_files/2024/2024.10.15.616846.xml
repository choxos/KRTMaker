<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS199513</article-id><article-id pub-id-type="doi">10.1101/2024.10.15.616846</article-id><article-id pub-id-type="archive">PPR926320</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">1</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>A bounded accumulation model of temporal generalization outperforms existing models and captures modality differences and learning effects</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Ofir</surname><given-names>Nir</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Landau</surname><given-names>Ayelet N.</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="fn" rid="FN1">4</xref></contrib><aff id="A1"><label>1</label>Department of Psychology, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/03qxff017</institution-id><institution>Hebrew University of Jerusalem</institution></institution-wrap>, Mt. Scopus, <city>Jerusalem</city><postal-code>9190501</postal-code>, <country country="IL">Israel</country></aff><aff id="A2"><label>2</label>Department of Cognitive and Brain Sciences, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/03qxff017</institution-id><institution>Hebrew University of Jerusalem</institution></institution-wrap>, Mt. Scopus, <city>Jerusalem</city><postal-code>9190501</postal-code>, <country country="IL">Israel</country></aff><aff id="A3"><label>3</label>Edmond and Lily Safra Center for Brain Sciences, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/03qxff017</institution-id><institution>Hebrew University of Jerusalem</institution></institution-wrap>, Edmond J. Safra Campus, <city>Jerusalem</city><postal-code>9190401</postal-code>, <country country="IL">Israel</country></aff></contrib-group><author-notes><corresp id="CR1">Correspondence: <email>nir.ofir@mail.huji.ac.il</email> (N.O.), <email>ayelet.landau@mail.huji.ac.il</email> (A.N.L.)</corresp><fn id="FN1"><label>4</label><p id="P1">Lead contact</p></fn></author-notes><pub-date pub-type="nihms-submitted"><day>19</day><month>10</month><year>2024</year></pub-date><pub-date pub-type="preprint"><day>17</day><month>10</month><year>2024</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P2">Multiple systems in the brain track the passage of time and can adapt their activity to temporal requirements (<xref ref-type="bibr" rid="R25">Paton &amp; Buonomano, 2018</xref>). While the neural implementation of timing varies widely between neural substrates and behavioral tasks, at the algorithmic level many of these behaviors can be described as bounded accumulation (<xref ref-type="bibr" rid="R3">Balcı &amp; Simen, 2024</xref>). So far, from the range of temporal psychophysical tasks, the bounded accumulation model has only been applied to temporal bisection, in which participants are requested to categorize an interval as “long” or “short” (<xref ref-type="bibr" rid="R2">Balcı &amp; Simen, 2014</xref>; <xref ref-type="bibr" rid="R23">Ofir &amp; Landau, 2022</xref>). In this work, we extend the model to fit performance in the temporal generalization task, in which participants are required to categorize an interval as being the same or different compared to a standard, or reference, duration (<xref ref-type="bibr" rid="R31">Wearden, 1992</xref>). Previous models of performance in this task focused on either the group level or performance of highly trained animals (<xref ref-type="bibr" rid="R6">Birngruber et al., 2014</xref>; <xref ref-type="bibr" rid="R7">Church &amp; Gibbon, 1982</xref>; <xref ref-type="bibr" rid="R31">Wearden, 1992</xref>). Whether the same models can fit performance from a few hundreds of trials of single participants, necessary for comparing performance across experimental manipulations, has not been tested. A drift-diffusion model with two decision boundaries fits the data of single participants better than the previous models. We ran two experiments, one comparing performance between vision and audition and another examining the effect of learning. We found that decision boundaries can be modified independently: While the upper boundary was higher in vision compared to audition, the lower boundary decreased with learning in the task.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P3">Accurately tracking the passage of time is crucial for all behavior. When we play a ball game, timing is critical from multiple perspectives. From a sensory perspective, we need to constantly track the ball and players and predict their next move. From a motor perspective, we need to time our hands and feet to meet the ball at the right moment. Neurobiological and theoretical studies suggest the implementation of tracking time takes many different forms, depending on the specific neural network and behavioral goal (<xref ref-type="bibr" rid="R25">Paton &amp; Buonomano, 2018</xref>). Despite this variability in implementation, at the algorithmic level timing behaviors can often be described as a bounded accumulation process (<xref ref-type="bibr" rid="R1">Balci &amp; Simen, 2016</xref>). The bounded accumulation model was first proposed for animal timing tasks, such as the peak interval procedure (<xref ref-type="bibr" rid="R30">Simen et al., 2011</xref>). In those tasks, an animal subject is given reward for the first response made after a certain interval has elapsed since a cue. In this case the model is most intuitive, as behavior can be explained by an accumulator and a decision boundary. The accumulator starts with cue presentation, and once it reaches the decision boundary, a response is made. The bounded accumulation model was later expanded to fit data from the temporal bisection task, a prototypical psychophysical timing task (<xref ref-type="bibr" rid="R2">Balcı &amp; Simen, 2014</xref>). In this task, participants categorize intervals as being “short” or “long” based on two reference intervals they are familiarized with at the start of the experiment. With a minimal change, the bounded accumulation model can also fit data from this experiment: Instead of triggering a response, crossing the decision boundary signifies that an interval is long enough to be considered “long”. This model can explain both binary “short”/”long” responses as well as the EEG activity evoked by the offset of the interval (<xref ref-type="bibr" rid="R23">Ofir &amp; Landau, 2022</xref>). Given the success of the bounded accumulation model in explaining behavior and EEG in temporal bisection, we wondered if it could accommodate other temporal tasks too. Specifically, can bounded accumulation explain behavior when more than one boundary is required? An example of such a task is the temporal generalization task, introduced to human research by John <xref ref-type="bibr" rid="R31">Wearden (1992)</xref>. We first survey existing models, then describe an extension of the bounded accumulation model to this task. We next compare all models, showing the bounded accumulation model generally fits single participants’ data better than other models and has better parameter recovery. Finally, we demonstrate the use of the proposed model by investigating two scenarios. First, we use it to explain differences in temporal generalization between modalities. Second, we use it to account for changes in performance over learning.</p></sec><sec id="S2" sec-type="methods"><title>Method</title><sec id="S3" sec-type="subjects"><title>Participants</title><p id="P4">A total of 85 individuals participated in two experiments. Forty participated in experiment 1 (32 female participants, average age 23.9, SD 3) and 45 in experiment 2 (32 female participants, average age = 23.6, SD 2.6). Participants were recruited from the university community and were compensated for their time with either money (10 euro per hour) or class credit. All procedures were approved by the institutional review board of ethical conduct. Six participants from each experiment were excluded from the analysis (15% and 13.3%, respectively), as they produced flat psychometric curves, meaning they were not responding to the presented intervals (<xref ref-type="supplementary-material" rid="SD1">Figure S1 &amp; S2</xref>).</p></sec><sec id="S4" sec-type="methods"><title>Experimental procedure</title><p id="P5">A typical temporal generalization experiment consists of several blocks of trials with an identical structure (<xref ref-type="fig" rid="F1">Figure 1</xref>). Each block starts with several repetitions of the standard duration, which participants are not requested to respond to (Familiarization phase). Next, the test phase starts. In each trial of this phase, the participant is presented with a single interval and is asked to report whether the interval had the same duration as the standard or not. The presented duration varies from trial to trial, and usually covers a range spread evenly around the standard (<xref ref-type="fig" rid="F1">Figure 1B</xref>).</p><p id="P6">We report the results of two behavioral experiments, both run using OpenSesame (<xref ref-type="bibr" rid="R22">Mathôt et al., 2012</xref>). The first compared temporal generalization with visual vs. auditory stimuli, and the second examined the effect of learning in the task. Both experiments used 400 msec as the standard duration, and seven levels of stimulus duration as comparison stimuli (100, 200, 300, 400, 500, 700 and 800 msec).</p><p id="P7">In the first experiment, participants completed two parts, one containing visual stimuli and one containing auditory stimuli. The order of the parts was counterbalanced across participants. Each part included 3 blocks of 75 trials each, separated by breaks. The standard duration was presented 5 times at the start of each block. At the end of a block, the percent of accurate responses was presented on the screen. In total, all durations except the standard were presented 30 times and the standard 45 times in each modality. A white fixation dot appeared at the center of the screen whenever no stimuli were presented on the screen.</p><p id="P8">In the second experiment we used visual stimuli in two levels of contrast (50% or 100%). The experiment contained 6 blocks of 80 trials each, separated by breaks. The standard duration was presented 6 times at the start of each block (3 in each contrast). At the end of a block, the percent of accurate responses was presented on the screen. All durations except the standard were presented 60 times (30 in each contrast) and the standard 120 times (60 in each contrast). Each block contained the same number of trials in each duration, displayed in a different order, to facilitate studying learning effects. A white fixation dot appeared at the center of the screen whenever no stimuli were presented on the screen.</p><p id="P9">In both experiments, participants could only respond once the stimulus was over.</p></sec><sec id="S5"><title>Experiment 1 stimuli</title><p id="P10">Visual stimuli consisted of a square-wave grating presented in a circular window on a BenQ XL2420Z monitor running on 144 Hz, which was positioned 50 cm away from the participants. The grating had a spatial frequency of 1 cycle per centimeter, a diameter of 7 centimeters (corresponding to 8° visual angle) and was positioned at the center of the screen. Gratings were presented with a random orientation of 45° or 135°. Auditory stimuli were 500 Hz tones presented at a comfortable hearing level via Sennheiser HD 280 pro headphones.</p></sec><sec id="S6"><title>Experiment 2 stimuli</title><p id="P11">Experiment 2 focused on the visual modality. The stimuli were the same square-wave gratings as presented in the visual part of experiment 1.</p></sec><sec id="S7"><title>Modelling temporal generalization performance</title><p id="P12">Developing mathematical models of behavior can serve several distinct goals (<xref ref-type="bibr" rid="R36">Wilson &amp; Collins, 2019</xref>). One goal, which has guided early efforts to model temporal generalization, is to hypothesize and test the main sources of variability in performance (<xref ref-type="bibr" rid="R7">Church &amp; Gibbon, 1982</xref>; <xref ref-type="bibr" rid="R14">Gibbon et al., 1984</xref>). This type of work sometimes places an emphasis on “well behaved” data, such as data pooled across participants, or the very large number of trials that come from experiments on animals. Another goal of computational modelling is to provide tools to summarize the data of single participants, which facilitates comparing behavior across conditions or individuals in cognitively meaningful terms (<xref ref-type="bibr" rid="R29">Schurr et al., 2024</xref>; <xref ref-type="bibr" rid="R36">Wilson &amp; Collins, 2019</xref>). The second goal typically weighs more heavily the ability of the model to fit the “noisier” data of single participants.</p><p id="P13">All models considered here rely on a common approach in models of perception: a decision variable (DV) sample is drawn on each trial, and this sample is compared against two decision boundaries, to produce a binary decision: “Same” if the DV is within the boundaries, “different” otherwise. The models differ along several dimensions: Whether decision boundaries are constrained to be symmetric around the true standard duration, whether there’s trial-to-trial variability in the boundaries, and how noise in the internal representation of the current interval depends on the interval duration. In this work we focus on cognitive models for temporal generalization. Analysis approaches that assume a specific cognitive model were reviewed recently elsewhere (<xref ref-type="bibr" rid="R5">Bausenhart et al., 2018</xref>; See also <xref ref-type="bibr" rid="R26">Piras &amp; Coull, 2011</xref>).</p></sec><sec id="S8"><title><xref ref-type="bibr" rid="R7">Church &amp; Gibbon 1982</xref> (CG model)</title><p id="P14">Russel Church and John Gibbon originally developed a model to describe the performance of rats in a temporal generalization task (<xref ref-type="bibr" rid="R7">Church &amp; Gibbon, 1982</xref>; Henceforth CG, following (<xref ref-type="bibr" rid="R31">Wearden, 1992</xref>)). The model assumes that on each trial a random sample of the standard duration is retrieved from memory as well as a random sample of the decision boundary. Then, the absolute value of the normalized difference of the current duration, which is assumed to be accurately perceived, and the sample of the standard is computed. This normalized difference is compared against the decision boundary. If the absolute normalized difference is smaller than the boundary, the interval is categorized as “same”, and if it is larger than the boundary, the interval is categorized as “different”. The decision rule can be formalized as follows: <disp-formula id="FD1"><mml:math id="M1"><mml:mrow><mml:mo>−</mml:mo><mml:mi>b</mml:mi><mml:mo>&lt;</mml:mo><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:mfrac><mml:mo>&lt;</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:math></disp-formula>
</p><p id="P15">Where <italic>s</italic> (the standard memory) and <italic>b</italic> (the decision boundary) are both normally distributed random variables, and <italic>t</italic> is equal to the duration presented on the current trial. The psychophysical function – the probability to label an interval <italic>t</italic> as “same” – was derived by Church and Gibbon to be: <disp-formula id="FD2"><mml:math id="M2"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mspace width="0.2em"/><mml:mtext>same</mml:mtext><mml:mspace width="0.2em"/><mml:mo>∣</mml:mo><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mi>B</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mi>t</mml:mi><mml:mi>S</mml:mi></mml:mfrac></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:msup><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>B</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mi>B</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>B</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p id="P16"><italic>Ф</italic> is the standard normal cumulative density function and <italic>S</italic> is the true standard duration. The model has three free parameters: <italic>B</italic> (mean boundary value, relative to the standard), <italic>σ<sub>B</sub></italic> (boundary standard deviation) and <italic>k</italic> (Weber fraction, which specifies the variability of standard memory samples).</p></sec><sec id="S9"><title><xref ref-type="bibr" rid="R31">Wearden 1992</xref> (MCG: Modified Church &amp; Gibbon model)</title><p id="P17">Later work that developed an analogue of the experimental design for humans found that humans displayed greater asymmetries in their psychophysical curves compared to rats (<xref ref-type="bibr" rid="R31">Wearden, 1992</xref>); Henceforth MCG “modified Church &amp; Gibbon”). Wearden suggested to modify the DV, replacing the standard memory sample in the denominator with the objective duration of the current interval (the variables are the same as in the original model by Church &amp; Gibbon): <disp-formula id="FD3"><mml:math id="M3"><mml:mrow><mml:mo>−</mml:mo><mml:mi>b</mml:mi><mml:mo>&lt;</mml:mo><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:mfrac><mml:mo>&lt;</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:math></disp-formula></p><p id="P18">The psychophysical function can be found by algebraic operations (<xref ref-type="supplementary-material" rid="SD1">appendix 1</xref>) to be: <disp-formula id="FD4"><mml:math id="M4"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mspace width="0.2em"/><mml:mtext>same</mml:mtext><mml:mspace width="0.2em"/><mml:mo>∣</mml:mo><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mi>B</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>B</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p id="P19">The free parameters are the same as for the CG model. Normalizing the DV by the interval duration instead of the standard means that the variability of the DV decreases for longer durations. This property is unusual for timing models, which typically assume that the uncertainty of estimated duration increases for longer intervals (<xref ref-type="bibr" rid="R16">Hass &amp; Durstewitz, 2016</xref>). Over the years, many different variants of this model were developed to fit different scenarios, such as changes in performance over development (<xref ref-type="bibr" rid="R10">Droit-Volet et al., 2001</xref>; <xref ref-type="bibr" rid="R32">Wearden, 2004</xref>). We focus on the simplest one, as it provides the clearest comparison to the other models.</p></sec><sec id="S10"><title><xref ref-type="bibr" rid="R6">Birngruber, Schröter &amp; Ulrich 2014</xref> (BSU model)</title><p id="P20">Both CG and MCG models assume that participants place their decision boundaries around the true standard duration. This assumption seems too strict for two reasons: First, individual participants often display idiosyncratic biases, in timing and other forms of perception, that result in shifted psychometric curves (<xref ref-type="bibr" rid="R14">Gibbon et al., 1984</xref>; <xref ref-type="bibr" rid="R21">Lebovich et al., 2019</xref>). Second, some experimental manipulations can create systematic shifts in the psychometric curves across participants. The third model we review was developed for data representing such a scenario. Birngruber and colleagues found that when the comparison interval is an oddball in a sequence of stimuli, it is perceived as longer than its objective duration (<xref ref-type="bibr" rid="R6">Birngruber et al., 2014</xref>; Henceforth BSU). Specifically, the peak of the psychometric function, which is the interval that is most often reported to be equal to the standard, is shorter than the standard. To allow the model to capture such biases, the authors suggested the following psychophysical function: <disp-formula id="FD5"><mml:math id="M5"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mspace width="0.2em"/><mml:mtext>same</mml:mtext><mml:mspace width="0.2em"/><mml:mo>∣</mml:mo><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>ε</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>ε</mml:mi><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>ε</mml:mi><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p id="P21">Where <italic>s</italic> and <italic>t</italic> are the objective standard and comparison intervals, respectively, <italic>k</italic> is the Weber fraction, which describes how quickly noise grows with the comparison interval, <italic>b</italic><sub>1</sub> and <italic>b</italic><sub>2</sub> are the lower and upper boundaries, respectively, and <italic>ε</italic> represents a bias term. We make two technical notes. First, as <italic>s</italic> is the objective standard duration, its only effect is that the boundaries are expressed as relative to the standard rather than in absolute terms. That can be done independently of the fitting procedure if desired. Second, <italic>ε</italic> trades-off perfectly with the boundaries. For any choice of <italic>ε</italic>, we can define new boundaries <inline-formula><mml:math id="M6"><mml:mrow><mml:msubsup><mml:mi>b</mml:mi><mml:mn>1</mml:mn><mml:mo>′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mi>ε</mml:mi><mml:mo>,</mml:mo><mml:msubsup><mml:mi>b</mml:mi><mml:mn>2</mml:mn><mml:mo>′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mi>ε</mml:mi></mml:mrow></mml:math></inline-formula> which would undo the effect of <italic>ε</italic>. In the original work, the value of the bias was constrained by additional data from a separate temporal bisection task. However, when only data from a temporal generalization task is available, this function is over-parameterized, and not all parameters can be estimated (see also <xref ref-type="supplementary-material" rid="SD1">appendix 2</xref> in <xref ref-type="bibr" rid="R6">Birngruber et al., 2014</xref>). Hence, we remove <italic>ε</italic> and <italic>s</italic> from the function, yielding the simplified form: <disp-formula id="FD6"><mml:math id="M7"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mspace width="0.2em"/><mml:mtext>same</mml:mtext><mml:mspace width="0.2em"/><mml:mo>∣</mml:mo><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>u</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>u</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p id="P22">This model essentially states that a noisy estimate of the comparison interval is compared to 2 boundaries. If it is within those boundaries, it is reported as “same”, and as “different” otherwise. The model has three free parameters: The upper (<italic>b</italic><sub><italic>u</italic></sub>) and lower (<italic>b</italic><sub><italic>l</italic></sub>) boundaries and the Weber fraction <italic>k</italic>.</p></sec><sec id="S11"><title>Proposed drift-diffusion model (DDM)</title><p id="P23">Previous research showed that the bounded accumulation framework captures behavioral as wells as different aspects of neural activity in the temporal bisection task (<xref ref-type="bibr" rid="R2">Balcı &amp; Simen, 2014</xref>; <xref ref-type="bibr" rid="R23">Ofir &amp; Landau, 2022</xref>). We propose a modified drift-diffusion model (henceforth DDM), derived from this framework, for the temporal generalization task. The proposed model includes a single drift-diffusion process with two boundaries. Different from the typical implementation of the DDM in two-choice scenarios (<xref ref-type="bibr" rid="R27">Ratcliff et al., 2016</xref>), here both boundaries are placed above the starting point of the drift diffusion process. At interval onset, the drift-diffusion process starts, and the accumulated value is compared to the boundaries at interval offset. If the accumulated value at the offset hasn’t reached the lower boundary or has surpassed the upper boundary the interval is categorized as “different”. Otherwise, if the accumulated value at the offset is between the two boundaries, the interval is categorized as “same”. The psychophysical function is (see <xref ref-type="supplementary-material" rid="SD1">appendix 2</xref> for the mathematical derivation): <disp-formula id="FD7"><mml:math id="M8"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mspace width="0.2em"/><mml:mo>"</mml:mo><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mo>"</mml:mo><mml:mspace width="0.2em"/><mml:mo>∣</mml:mo><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>u</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>u</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:msqrt><mml:mi>t</mml:mi></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:msqrt><mml:mi>t</mml:mi></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p id="P24">The model has three free parameters: the diffusion-to-drift ratio <italic>c</italic>, controlling how rapidly noise grows with time, the ratio of the lower boundary to drift (<italic>b</italic><sub><italic>l</italic></sub>) and the ratio of the upper boundary to drift (<italic>b</italic><sub><italic>u</italic></sub>). For brevity, the parameters will be denoted as diffusion coefficient, lower and upper boundary. We note that the DDM and BSU are very similar. They differ only in how rapidly timing noise grows with interval duration. The faster growth in variability assumed by BSU translates into curves that are generally more asymmetric than the ones produced by the DDM.</p></sec><sec id="S12"><title>Models summary</title><p id="P25">To summarize, all models assume a decision variable which is compared against decision boundaries. The DDM is the only model that explicitly describes the dynamics of the decision variable over time, so it is the simplest to plot as an example (<xref ref-type="fig" rid="F2">Figure 2A</xref>). We can also think about the models through the psychometric curves they produce (<xref ref-type="fig" rid="F2">Figure 2B</xref>). All four models have parameters that control the slopes (rising and falling) and asymmetry of the curve, which reflect the internal noise in the perceptual decision process. While the DDM and BSU models restrict noise to originate only from the timing process, CG and MCG assume that both timing (through the memory of the standard) and decision variability affect the slopes. In addition, DDM and BSU can produce curves that are not centered on the true standard, while CG and MCG cannot.</p></sec><sec id="S13"><title>Fitting the model to behavior</title><p id="P26">The three free parameters of each model were estimated by a maximum likelihood procedure, using the fminsearch function of Matlab (MathWorks, MA). We used heuristics to make sure the fitting procedure started at parameter values that produce finite likelihoods (<xref ref-type="bibr" rid="R36">Wilson &amp; Collins, 2019</xref>).</p><p id="P27">When working on the fits of the CG and MCG models, we noticed that fminsearch would sometime try combinations of the two slope parameters that lead to imaginary numbers in the denominator of the psychometric function, which cause Matlab errors. Therefore, for MCG and CG specifically, we constrained all parameters to be positive using fmincon.</p></sec><sec id="S14"><title>Parameter recovery</title><p id="P28">An important step in testing a model is examining its ability to fit data it simulated. This is called parameter recovery, and it measures the fitting capability of the model under an ideal situation (<xref ref-type="bibr" rid="R36">Wilson &amp; Collins, 2019</xref>). In a parameter recovery analysis, a dataset is simulated by a model with given parameters, and then the model is fitted to the simulated data to estimate the model’s parameters. If the model parameters are well defined, and the data collection is well suited, we expect that the estimated parameter values will be close to the values used to simulate the data. We created parameter-generating distributions for the simulations by fitting a probability distribution to the fitted values of each parameter separately (twelve independent distributions in total, three for each of the four models). Fits of the MCG and CG models had four outlier datasets each, that were removed prior to the parameter recovery analysis. We chose the distributions manually to reasonably fit the parameter values. For each model, 5000 simulations were generated from the parameter distributions using the same trial numbers as in the actual experiment. The simulated parameters were independent, except for the upper and lower boundaries in the DDM and BSU. Simulations in which the upper boundary was less than 0.1 larger than the lower boundary were redrawn. Finally, the results of each simulation were fitted by the model that created it, and the estimated and simulated parameters were compared (<xref ref-type="fig" rid="F6">Figure 6</xref>). As a general measure for fitting accuracy, we calculated the Pearson correlation coefficient between simulated and estimated parameter values. Parameter trade-off was assessed using the correlation between all pairs of estimated parameter values.</p></sec></sec><sec id="S15" sec-type="results"><title>Results</title><sec id="S16"><title>The double-boundary DDM fits single participants’ data better than the other models</title><p id="P29">We analyzed the data of 34 participants who completed two versions of temporal generalization, one block using auditory pure tones and one using visual gratings. Overall, participants were better with auditory stimuli (<xref ref-type="fig" rid="F3">Figure 3</xref>). Participants performed significantly more accurately in the auditory modality (M = 71.01%, SD = 9.52%) than in the visual modality (M = 58.77%, SD = 8.88%). All participants but one had higher accuracy in the auditory modality (paired t-test, t<sub>33</sub> = 11.18, p &lt; 0.001, d = 1.92). We performed a repeated-measures analysis of variance (ANOVA) on the probability of “same” responses with interval duration (7 levels, 0.1-0.7 s), modality (2 levels, audition or vision) and their interaction as within-participant factors. We found an expected significant main effect of interval duration <inline-formula><mml:math id="M9"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mtext>F</mml:mtext><mml:mrow><mml:mn>6</mml:mn><mml:mo>,</mml:mo><mml:mn>33</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>92.23</mml:mn><mml:mo>,</mml:mo><mml:mtext>p</mml:mtext><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.74</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, signifying that participants were attending to the task. In addition, we found a significant main effect of modality <inline-formula><mml:math id="M10"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mtext>F</mml:mtext><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>33</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>77.32</mml:mn><mml:mo>,</mml:mo><mml:mtext>p</mml:mtext><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.7</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> as well as a significant duration by modality interaction <inline-formula><mml:math id="M11"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mtext>F</mml:mtext><mml:mrow><mml:mn>6</mml:mn><mml:mo>,</mml:mo><mml:mn>33</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>17.23</mml:mn><mml:mo>,</mml:mo><mml:mtext>p</mml:mtext><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.34</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Visually inspecting participants’ performance shows that the psychometric curves for auditory and visual stimuli differ greatly in their shapes. These differences between are most pronounced for longer intervals. Considering Weber’s law, this would intuitively correspond to a larger coefficient of variation in vision compared to audition: Timing noise for static gratings grows at a faster rate compared to pure tones. To test that intuition formally and statistically, we can use cognitive models, as explored below.</p><p id="P30">Comparing behavior under different conditions is often done by first summarizing behavior within conditions into model parameters, and then comparing the parameter values between conditions. To do so, we need to establish the models are suitable, both in how well they can fit the data and in how well-defined the models’ parameters are. First, we compared the ability of the four different models to fit data at a single participant level. For each participant, we fit each model to the data of each condition separately. Since all models have three free parameters, they can be directly compared in terms of their maximum likelihood. For both modalities, the DDM considerably outperformed all other models (<xref ref-type="fig" rid="F4">Figure 4</xref>), with 47.1% and 73.5% of participants in the auditory and visual modalities respectively, compared with a chance level of 25% (<xref ref-type="table" rid="T1">Table 1</xref>). There was no obvious systematic difference between the other three models. Models BSU and CG were somewhat better on auditory than visual data. MCG performed the same in both modalities. Following previous research, we also fitted the models to the pooled data across participants. In the auditory modality, the original CG model performed best, while in the visual modality it was the MCG model. In both modalities, the DDM came in second. Visually inspecting the group results reveals the CG model tracks the auditory data closely, while the MCG model tracks the visual data closely (<xref ref-type="fig" rid="F5">Figure 5</xref>). Both models failed quite clearly in fitting the other modality (i.e. CG in the visual modality, and MCG in the auditory modality). The DDM was more balanced in fitting the group data, achieving good yet not optimal fits in both modalities. Importantly, the fits at the group level should be taken with a grain of salt. Accepting the group results at face value assumes that the pooled data is a cleaner version of the prototypical pattern of performance, or in other words, that participants behave similarly. However, participants in psychophysical tasks often display significant variability (<xref ref-type="supplementary-material" rid="SD1">Figure S1</xref>; See also <xref ref-type="bibr" rid="R21">Lebovich et al., 2019</xref>). In more mathematical terms, given the variability of single participants, there is no guaranty that the same psychometric function applies at both single participant and group levels. As reported above, at the single participant level, the DDM considerably outperforms the other models.</p><p id="P31">As noted, both CG and MCG models have two parameters that control the slopes and asymmetry of the curves: Boundary variability and memory variability, controlled by the Weber fraction. Having more than one parameter affecting the psychometric curve similarly could lead to identifiability problems, where changes to one parameter can be undone by changes to another parameter (<xref ref-type="bibr" rid="R13">Gershman, 2016</xref>). This means both parameters cannot be reliably estimated from typical empirical data at once. Identifiability is especially important if the parameters are used for inference, such as comparing between experimental conditions. To test parameter identifiability, we explored the estimated parameter values of all models (<xref ref-type="fig" rid="F4">Figure 4</xref>). Fits of both CG and MCG models show a tendency to shrink one of the two parameters towards zero, more often boundary variability, leaving the other parameter to absorb all explained variability (<xref ref-type="table" rid="T2">Table 2</xref>). This suggests the slopes parameters are unidentifiable. We note this was already reported briefly by <xref ref-type="bibr" rid="R31">Wearden (1992)</xref>. The CG model was only used to fit pooled data of several animals, each completing many hundreds of trials. These large amounts of data, atypical in human psychophysics, possibly allowed the fitting procedure to distinguish both sources of variability (<xref ref-type="bibr" rid="R14">Gibbon et al., 1984</xref>). However, for the type of data discussed here, these models are suboptimal.</p></sec><sec id="S17"><title>Parameters of the DDM are more successfully recovered than the other models</title><p id="P32">Finally, we tested the validity of the fitted parameter values as estimates of the values which hypothetically produced the data by parameter recovery (<xref ref-type="bibr" rid="R36">Wilson &amp; Collins, 2019</xref>). The DDM model displayed the overall highest recovery accuracy for all three parameters. Upper boundaries were generally estimated well, up to upper boundaries of about 0.8 s. Above this point, the fitting procedure tended to inflate the estimated upper boundaries. This means upper boundaries estimates larger than 0.8 should be treated somewhat cautiously. In our data, estimated upper boundaries above 0.8 s occurred only once in the auditory condition, but 17 times (50% of participants) in the visual condition. This reveals a limitation in the experimental design. It is possible that the range of intervals used in the experiment was too difficult for many of our participants in the visual modality. Cross-parameter correlations were low overall, indicating good parameter identifiability, except for the correlation between lower and upper boundaries. As the simulated boundaries were constrained to have a separation of at least 100 ms, there was a correlation of 0.15 in the simulated values, close to the 0.13 correlation in the estimated values. The BSU model displayed somewhat worse parameter recovery, which is most apparent in the estimation of upper boundaries in that model. The variability of estimated upper boundaries increased quite rapidly with increasing simulated upper boundaries. This translates into lower recoverability, as measured by the correlation between simulated and estimated upper boundaries. For both MCG and CG models, mean boundary was recovered well. However, both slope parameters showed low recovery accuracy across the entire range of values tested. The trade-off between slope parameters, which was very strong when fitting empirical data, was less severe in the recovery analysis. This is evident in the wide spread of estimated slope values. This suggests that the trade-off found in fitting single participants data stems from the models being generally less suitable for such data. In summary, the DDM showed satisfactory parameter recovery, better than the other models explored, as well as minimal trade-off between parameters, making it a good candidate to test the effect of experimental manipulations.</p></sec><sec id="S18"><title>Participants have less internal noise and use stricter decision boundaries when timing auditory vs. visual stimuli</title><p id="P33">Having established the DDM as a suitable model to analyze single-participant data, we next use it to capture differences between conditions. We fit the DDM to the data of each participant within each condition separately (<xref ref-type="fig" rid="F5">Figure 5</xref>) and compared the estimated parameters between the conditions using paired t-tests. Lower boundaries weren’t significantly different between modalities (M<sub>aud</sub> = 0.27, SD<sub>aud</sub> = 0.06, M<sub>vis</sub> = 0.29, SD<sub>vis</sub> = 0.09; t<sub>33</sub> = 0.99, p = 0.329, d = 0.17). In contrast, both the diffusion and upper boundaries were strongly affected by the modality. Diffusion coefficients were significantly larger in the visual condition (M<sub>aud</sub> = 0.17, SD<sub>aud</sub> = 0.06, M<sub>vis</sub> = 0.28, SD<sub>vis</sub> = 0.11; t<sub>33</sub> = 7.50, p &lt; 0.001, d = 0.77), and participants placed their upper boundaries at longer intervals in the visual condition (M<sub>aud</sub> = 0.54, SD<sub>aud</sub> = 0.09, M<sub>vis</sub> = 0.83, SD<sub>vis</sub> = 0.38; t<sub>33</sub> = -4.51, p &lt; 0.001).</p><p id="P34">As both internal noise and upper boundary were significantly different between modalities, we next explored whether both parameters might be inherently related. If this were the case, both parameters should be correlated across participants. To make sure our statistical analysis isn’t overly affected by outlier values, we checked for upper boundaries or diffusion coefficients that were 3.5 standard deviations or more away from the respective means. We excluded 1 participant with an upper boundary of 2.6, which is 6.27 standard deviations above the mean upper boundary. We ran a linear mixed effects model predicting the upper boundary using modality (binary predictor with effects coding: -1 for audition and 1 for vision) and diffusion (continuous predictor) as fixed effects. The intercept and slope against diffusion were set as random effects. We found that participants with larger diffusion tended to place their upper boundary at longer intervals (β = 0.91, p &lt; 0.001; <xref ref-type="fig" rid="F7">Figure 7A</xref>). Modality still predicted significant variability in upper boundaries, even after taking diffusion into account (β = -0.07, p &lt; 0.001). Additionally, the relation between diffusion and upper boundary was stronger in the visual modality, as indicated by a significant interaction of modality and diffusion (β = -0.38, p = 0.011). Importantly, the correlations seen in the empirical data are larger than those seen in the parameter recovery analysis, meaning this correlation reveals a true link between the two measures, rather than an artifact of the fitting procedure or model specification. If diffusion and upper boundaries are related, another prediction is that participants who displayed a larger effect of modality on their diffusion coefficient, should also display a larger effect of modality on upper boundaries. Hence, we computed the difference of diffusion coefficient between modalities (vision minus audition, so we generally expect positive differences) as well as the difference of upper boundaries and correlated the two. The two differences were significantly correlated (Pearson ρ = 0.56, p &lt; 0.001; <xref ref-type="fig" rid="F7">Figure 7B</xref>) in line with the prediction. In summary, upper boundaries and diffusion are related, yet the effect of modality on upper boundaries is not completely explained by its effect on internal noise.</p></sec><sec id="S19"><title>Psychophysical functions become narrower with increased experience in the task</title><p id="P35">We analyzed the data of 39 participants in the second experiment, exploring the effect of learning in the task. We performed a repeated-measures ANOVA on the probability of “same” responses with interval duration (7 levels, 0.1-0.7 s), block (3 levels, blocks 1-2, 3-4 and 5-6) and their interaction as within-participant factors. As expected, there was a significant main effect of interval duration <inline-formula><mml:math id="M12"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mtext>F</mml:mtext><mml:mrow><mml:mn>6</mml:mn><mml:mo>,</mml:mo><mml:mn>228</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>133.81</mml:mn><mml:mo>,</mml:mo><mml:mtext>p</mml:mtext><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.78</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. More importantly, we found a significant main effect of block number <inline-formula><mml:math id="M13"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mtext>F</mml:mtext><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>76</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>18.58</mml:mn><mml:mo>,</mml:mo><mml:mtext>p</mml:mtext><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.33</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, as well as a significant duration by block interaction <inline-formula><mml:math id="M14"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mtext>F</mml:mtext><mml:mrow><mml:mn>12</mml:mn><mml:mo>,</mml:mo><mml:mn>456</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>5.84</mml:mn><mml:mo>,</mml:mo><mml:mtext>p</mml:mtext><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.13</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. This means participants systematically modified their behavior over the course of the experiment. Visually inspecting participants’ performance shows that the generalization gradients became narrower with longer experience with the task and increasing exposure to the standard durations (<xref ref-type="fig" rid="F8">Figure 8</xref>). We next examined whether participants adapted their decision strategy and whether their internal timing noise changed as a function of learning, by fitting the DDM to the data of each participant and block independently (meaning 39 X 3 models were fitted in total). We then performed a repeated-measures ANOVA on the estimated parameters with block (3 levels, blocks 1-2, 3-4 and 5-6) as a within-participant factor. We found that the lower boundary differed significantly between blocks <inline-formula><mml:math id="M15"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mtext>F</mml:mtext><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>76</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>14.82</mml:mn><mml:mo>,</mml:mo><mml:mtext>p</mml:mtext><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.28</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, shifting to shorter durations with learning (Tukey-Kramer post-hoc tests, 1<sup>st</sup> vs. 2<sup>nd</sup> tertile: p = 0.010, 1<sup>st</sup> vs. 3<sup>rd</sup>: p &lt; 0.001, 2<sup>nd</sup> vs. 3<sup>rd</sup>: p = 0.021). Diffusion coefficients also changed significantly between blocks <inline-formula><mml:math id="M16"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mtext>F</mml:mtext><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>76</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>4.70</mml:mn><mml:mo>,</mml:mo><mml:mtext>p</mml:mtext><mml:mo>=</mml:mo><mml:mn>0.012</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.11</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, becoming somewhat smaller over the course of the experiment. A post-hoc test found a significant difference between the 1<sup>st</sup> and 3<sup>rd</sup> tertiles (1<sup>st</sup> vs. 2<sup>nd</sup> tertile: p = 0.275, 1<sup>st</sup> vs. 3<sup>rd</sup>: p = 0.017, 2<sup>nd</sup> vs. 3<sup>rd</sup>: p = 0.237). Upper boundaries did not significantly differ between blocks <inline-formula><mml:math id="M17"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mtext>F</mml:mtext><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>76</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2.33</mml:mn><mml:mo>,</mml:mo><mml:mtext>p</mml:mtext><mml:mo>=</mml:mo><mml:mn>0.105</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.06</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p id="P36">Here, as in the comparison between modalities, we found two parameters of the model - diffusion coefficient and lower boundary - that changed significantly between blocks. As before, we first tested for outlier values in lower boundaries and diffusion coefficients, with 3.5 standard deviations away from the mean as the rejection criterion. We removed one participant which had a diffusion coefficient in the first block 4.8 standard deviations above the mean. We next used a linear mixed effects model to predict the lower boundary using block (categorical predictor with the first block as the reference level), diffusion coefficient (continuous predictor) and the diffusion coefficient by block interaction as fixed effects and a random intercept per participant. As expected, lower boundaries were gradually shifted to shorter intervals over blocks (2<sup>nd</sup> vs. 1<sup>st</sup> tertile, β = -0.04, p = 0.003; 3<sup>rd</sup> vs. 1<sup>st</sup> tertile, β = -0.06, p &lt; 0.001). The diffusion coefficient wasn’t significantly correlated with lower boundaries in the first tertile (β = 0.12, p = 0.165). The interaction terms were not significant either, suggesting similar relations of diffusion to lower boundaries over learning (2<sup>nd</sup> vs. 1<sup>st</sup> tertile, β = -0.02, p = 0.864; 3<sup>rd</sup> vs. 1<sup>st</sup> tertile, β = 0.16, p = 0.283; <xref ref-type="fig" rid="F9">Figure 9</xref>). The mixed model results suggest that learning affects the lower boundary and diffusion coefficient independently.</p></sec></sec><sec id="S20" sec-type="discussion"><title>Discussion</title><p id="P37">A diverse set of neural mechanisms is thought to underly our capability to track the passage of time (<xref ref-type="bibr" rid="R25">Paton &amp; Buonomano, 2018</xref>). Yet, at the algorithmic level many timing behaviors can be described as bounded accumulation processes (<xref ref-type="bibr" rid="R3">Balcı &amp; Simen, 2024</xref>). The bounded accumulation framework has been successfully applied to behavioral performance in temporal reproduction tasks (<xref ref-type="bibr" rid="R30">Simen et al., 2011</xref>). An extension of the framework to more complex temporal decisions, such as temporal bisection, explains results at the level of behavior (<xref ref-type="bibr" rid="R2">Balcı &amp; Simen, 2014</xref>) and EEG (<xref ref-type="bibr" rid="R23">Ofir &amp; Landau, 2022</xref>). In temporal bisection, binary responses (“long” or “short”) and EEG patterns could be captured with a single decision boundary (<xref ref-type="bibr" rid="R23">Ofir &amp; Landau, 2022</xref>). In this work, we extend the framework further to temporal generalization.</p><p id="P38">The previous models, as well as the proposed DDM, all share the basic design of psychophysical models, that is comparing a decision variable against decision boundaries, but vary considerably in their assumptions regarding the boundaries and the sources of variability. The original models, CG and MCG (<xref ref-type="bibr" rid="R7">Church &amp; Gibbon, 1982</xref>; <xref ref-type="bibr" rid="R31">Wearden, 1992</xref>), constrained decision boundaries to be fixed around the true standard duration and assumed that performance variability in the task (i.e. the slopes of psychophysical functions) is driven by noise in the memory of the standard and the decision boundaries. A more recent model, BSU (<xref ref-type="bibr" rid="R6">Birngruber et al., 2014</xref>), relaxed the constraint on the decision boundaries, and removed their trial-to-trial variability. Here, we apply the drift-diffusion approach to temporal generalization. We defined two decision boundaries, free to take any values, as well as a diffusion coefficient controlling the level of internal noise.</p><p id="P39">The DDM outperforms all other models in fitting single participants’ data. This is found both for timing using auditory stimuli and using visual stimuli. Furthermore, an analysis of parameter recovery revealed that the DDM parameters were best recovered. The two slope parameters of the CG and MCG models were recovered especially inaccurately, meaning the values estimated from empirical data are less reliable for these two models.</p><p id="P40">Having a model which can be robustly fitted to single participants’ data enables statistically testing how experimental manipulations affect the cognitive processes underlying behavior. Using the proposed DDM, we found that timing visual stimuli differed in two ways when compared to timing auditory stimuli. First, participants had a noisier representation of time in the visual modality, reflected by higher diffusion coefficients. Second, they also adopted higher upper boundaries in the visual modality, meaning that they were more likely to categorize longer intervals as identical to the standard. Numerous previous studies found timing of auditory stimuli to be better than timing of visual stimuli, leading to the hypothesis that audition is more temporally accurate (<xref ref-type="bibr" rid="R9">Di Luca &amp; Rhodes, 2016</xref>; <xref ref-type="bibr" rid="R11">Espinoza-Monroy &amp; De Lafuente, 2021</xref>; <xref ref-type="bibr" rid="R33">Wearden et al., 1998</xref>). A post-hoc analysis revealed that participants with more internal noise placed their upper boundaries at longer intervals. This result is reminiscent of previous findings, which indicate that participants adapt their behavior according to their level of internal noise (<xref ref-type="bibr" rid="R12">Freestone &amp; Church, 2016</xref>; <xref ref-type="bibr" rid="R20">Kononowicz et al., 2022</xref>). However, even when this correlation is considered, modality has an additional independent effect on upper boundaries, with upper boundaries placed at longer intervals for visual stimuli. These results suggest that modality affects timing at the perceptual level, with visual stimuli less precisely timed, as well as at the decision-making level, with less strict boundary placement for visual stimuli.</p><p id="P41">We additionally used the DDM to uncover the cognitive processes affected by learning in the task, using data from a second temporal generalization experiment. At the raw behavioral level, we found that psychophysical curves became narrower with increased experience with the task. This sharpening was captured in the DDM as a lowering of the lower decision boundaries, accompanied by a decrease in the diffusion coefficient. We found that participants initially placed the lower boundary almost at the true standard duration. As they gained practice with the task, participants gradually shifted their lower boundaries to shorter durations, which might reflect a more accurate representation of the standard. Our findings contrast with a previous study which suggested that upper boundaries were lowered with learning (<xref ref-type="bibr" rid="R34">Wearden &amp; Towse, 1994</xref>). However, that study, which relied on the MCG model and a variant of it, did not statistically compare parameter estimates between blocks of trials. Additionally, their pooled behavioral results (<xref ref-type="bibr" rid="R34">Wearden &amp; Towse, 1994</xref>; <xref ref-type="fig" rid="F2">Figure 2</xref>) are much sharper than the ones we found, making direct comparisons difficult.</p><p id="P42">The results of the modality and learning experiments combined show that the lower and upper boundaries can be modified independently of each other. This contrasts with the symmetric boundaries assumed by the CG and MCG models, which implies both should change in concert. Whether the boundaries are symmetric or not, all four models assume they are stable across trials, or vary randomly from trial to trial. Past studies, about time perception as well as many other forms of perception, suggest decision boundaries and internal references change systematically across trials (<xref ref-type="bibr" rid="R15">Hachen et al., 2021</xref>; <xref ref-type="bibr" rid="R28">Raviv et al., 2012</xref>; <xref ref-type="bibr" rid="R35">Wiener &amp; Thompson, 2015</xref>). Future work could leverage serial dependence to explore how the recent history of presented intervals and responses affects temporal generalization performance.</p><p id="P43">Finally, in the proposed model we assumed that the decision variable is compared against the boundaries only at interval offset, regardless of whether it crossed the boundaries during the interval. In the context of drift-diffusion models, such boundaries are termed “unabsorbing”. However, it is reasonable to hypothesize that the upper boundary is absorbing. In other words, relatively long intervals could be categorized as “different” before their offset, as soon as the decision variable reaches the upper boundary. An analogous process is thought to occur in temporal bisection, where “long” decisions are often made before interval offset (<xref ref-type="bibr" rid="R23">Ofir &amp; Landau, 2022</xref>). Two predictions can be made based on this hypothesis, at the behavioral and physiological level. First, the fact that for longer intervals “different” decisions can be made before interval offsets predicts faster responses in those cases, as motor preparation can start in advance. There is some evidence that this is the case (<xref ref-type="bibr" rid="R17">Klapproth, 2018</xref>; <xref ref-type="bibr" rid="R18">Klapproth &amp; Müller, 2008</xref>; <xref ref-type="bibr" rid="R19">Klapproth &amp; Wearden, 2011</xref>). Second, breaking the decision process into two stages, until interval offset and after it, suggests that we can expect to see a similar pattern of neural signatures in temporal generalization and bisection. Specifically, it is expected that the offset-evoked potential in temporal generalization will be larger for shorter intervals, as it is in bisection (<xref ref-type="bibr" rid="R23">Ofir &amp; Landau, 2022</xref>). To our knowledge, only two studies examined the offset-evoked potential in temporal generalization (<xref ref-type="bibr" rid="R4">Bannier et al., 2019</xref>; <xref ref-type="bibr" rid="R24">Özoğlu &amp; Thomaschke, 2023</xref>). Both studies found the same pattern of non-linear decreasing EEG potential as a function of interval duration in temporal generalization and bisection. A DDM with absorbing upper boundaries would be a beneficial tool for future studies recording response times alongside non-invasive physiology to study the temporal dynamics of the decisions in the temporal generalization task.</p><p id="P44">In summary, we provide a model for temporal generalization, which can robustly fit single participants data, enabling us to directly test the effect of stimulus modality and learning on the cognitive processes that are involved in temporal generalization. We hope this advance in the behavioral analysis of temporal generalization will facilitate future exploration of this task, both at the behavioral level and as a basis for relating neural activity to the underlying cognitive processes, similarly to what we have shown in temporal bisection (<xref ref-type="bibr" rid="R23">Ofir &amp; Landau, 2022</xref>).</p></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplemental Data</label><media xlink:href="EMS199513-supplement-Supplemental_Data.pdf" mimetype="application" mime-subtype="pdf" id="d53aAcEbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S21"><title>Acknowledgements</title><p>The authors would like to thank Michal Shoham and Shir Nehamkin for assistance in the design of the experiments. We thank Michal Shoham, Shir Nehamkin and Vanessa Kibel for assistance in data acquisition. We thank the members of the Brain Attention and Time Lab for their input on the work. The Brain Attention and Time Lab (PI: A.N.L.) is supported by the James McDonnell Scholar Award in Understanding Human Cognition, ISF grant 958/16. This project has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme (grant agreement no. 852387).</p></ack><fn-group><fn fn-type="con" id="FN2"><p id="P45">Author contributions: N.O. and A.N.L designed research, N.O. performed research, N.O. analyzed data, N.O. and A.N.L. wrote the paper.</p></fn><fn id="FN3"><p id="P46"><bold>Open Practice Statement</bold></p><p id="P47">The data and code for all experiments and analyses are available at <ext-link ext-link-type="uri" xlink:href="https://osf.io/87zbp/">https://osf.io/87zbp/</ext-link>. Neither of the experiments were preregistered.</p></fn></fn-group><ref-list><ref id="R1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Balci</surname><given-names>F</given-names></name><name><surname>Simen</surname><given-names>P</given-names></name></person-group><article-title>A decision model of timing</article-title><source>Current Opinion in Behavioral Sciences</source><year>2016</year><volume>8</volume><fpage>94</fpage><lpage>101</lpage><pub-id pub-id-type="doi">10.1016/J.COBEHA.2016.02.002</pub-id></element-citation></ref><ref id="R2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Balcı</surname><given-names>F</given-names></name><name><surname>Simen</surname><given-names>P</given-names></name></person-group><article-title>Decision processes in temporal discrimination</article-title><source>Acta Psychologica</source><year>2014</year><volume>149</volume><fpage>157</fpage><lpage>168</lpage><pub-id pub-id-type="pmid">24726447</pub-id></element-citation></ref><ref id="R3"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Balcı</surname><given-names>F</given-names></name><name><surname>Simen</surname><given-names>P</given-names></name></person-group><chapter-title>Neurocomputational Models of Interval Timing: Seeing the Forest for the Trees</chapter-title><person-group person-group-type="editor"><name><surname>Merchant</surname><given-names>H</given-names></name><name><surname>De Lafuente</surname><given-names>V</given-names></name></person-group><source>Neurobiology of Interval Timing</source><publisher-name>Springer International Publishing</publisher-name><year>2024</year><volume>1455</volume><fpage>51</fpage><lpage>78</lpage><pub-id pub-id-type="pmid">38918346</pub-id></element-citation></ref><ref id="R4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bannier</surname><given-names>D</given-names></name><name><surname>Wearden</surname><given-names>J</given-names></name><name><surname>Le Dantec</surname><given-names>CC</given-names></name><name><surname>Rebaï</surname><given-names>M</given-names></name></person-group><article-title>Differences in the temporal processing between identification and categorization of durations: A behavioral and ERP study</article-title><source>Behavioural Brain Research</source><year>2019</year><volume>356</volume><fpage>197</fpage><lpage>203</lpage><pub-id pub-id-type="pmid">30189287</pub-id></element-citation></ref><ref id="R5"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bausenhart</surname><given-names>KM</given-names></name><name><surname>Di Luca</surname><given-names>M</given-names></name><name><surname>Ulrich</surname><given-names>R</given-names></name></person-group><chapter-title>Assessing Duration Discrimination: Psychophysical Methods and Psychometric Function Analysis</chapter-title><person-group person-group-type="editor"><name><surname>Vatakis</surname><given-names>A</given-names></name><name><surname>Di Luca</surname><given-names>M</given-names></name><name><surname>Correa</surname><given-names>Á</given-names></name></person-group><source>Timing and Time Perception: Procedures, Measures, &amp; Applications</source><publisher-name>BRILL</publisher-name><year>2018</year><pub-id pub-id-type="doi">10.1163/9789004280205</pub-id></element-citation></ref><ref id="R6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Birngruber</surname><given-names>T</given-names></name><name><surname>Schröter</surname><given-names>H</given-names></name><name><surname>Ulrich</surname><given-names>R</given-names></name></person-group><article-title>Duration perception of visual and auditory oddball stimuli: Does judgment task modulate the temporal oddball effect?</article-title><source>Attention, Perception, &amp; Psychophysics</source><year>2014</year><volume>76</volume><issue>3</issue><fpage>814</fpage><lpage>828</lpage><pub-id pub-id-type="pmid">24435899</pub-id></element-citation></ref><ref id="R7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Church</surname><given-names>R</given-names></name><name><surname>Gibbon</surname><given-names>J</given-names></name></person-group><article-title>Temporal generalization</article-title><source>Journal of Experimental Psychology: Animal Behavior Processes</source><year>1982</year><volume>8</volume><issue>2</issue><fpage>165</fpage><lpage>186</lpage><pub-id pub-id-type="pmid">7069377</pub-id></element-citation></ref><ref id="R8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cousineau</surname><given-names>D</given-names></name><name><surname>Goulet</surname><given-names>M-A</given-names></name><name><surname>Harding</surname><given-names>B</given-names></name></person-group><article-title>Summary Plots With Adjusted Error Bars: The superb Framework With an Implementation in R</article-title><source>Advances in Methods and Practices in Psychological Science</source><year>2021</year><volume>4</volume><issue>3</issue><elocation-id>251524592110351</elocation-id><pub-id pub-id-type="doi">10.1177/25152459211035109</pub-id></element-citation></ref><ref id="R9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Di Luca</surname><given-names>M</given-names></name><name><surname>Rhodes</surname><given-names>D</given-names></name></person-group><article-title>Optimal Perceived Timing: Integrating Sensory Information with Dynamically Updated Expectations</article-title><source>Scientific Reports</source><year>2016</year><volume>6</volume><issue>1</issue><elocation-id>28563</elocation-id><pub-id pub-id-type="pmcid">PMC4935895</pub-id><pub-id pub-id-type="pmid">27385184</pub-id><pub-id pub-id-type="doi">10.1038/srep28563</pub-id></element-citation></ref><ref id="R10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Droit-Volet</surname><given-names>S</given-names></name><name><surname>Clément</surname><given-names>A</given-names></name><name><surname>Wearden</surname><given-names>J</given-names></name></person-group><article-title>Temporal Generalization in 3- to 8-Year-Old Children</article-title><source>Journal of Experimental Child Psychology</source><year>2001</year><volume>80</volume><issue>3</issue><fpage>271</fpage><lpage>288</lpage><pub-id pub-id-type="pmid">11583526</pub-id></element-citation></ref><ref id="R11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Espinoza-Monroy</surname><given-names>M</given-names></name><name><surname>De Lafuente</surname><given-names>V</given-names></name></person-group><article-title>Discrimination of Regular and Irregular Rhythms Explained by a Time Difference Accumulation Model</article-title><source>Neuroscience</source><year>2021</year><volume>459</volume><fpage>16</fpage><lpage>26</lpage><pub-id pub-id-type="pmid">33549694</pub-id></element-citation></ref><ref id="R12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freestone</surname><given-names>DM</given-names></name><name><surname>Church</surname><given-names>RM</given-names></name></person-group><article-title>Optimal timing</article-title><source>Current Opinion in Behavioral Sciences</source><year>2016</year><volume>8</volume><fpage>276</fpage><lpage>281</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2016.02.031</pub-id></element-citation></ref><ref id="R13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname><given-names>SJ</given-names></name></person-group><article-title>Empirical priors for reinforcement learning models</article-title><source>Journal of Mathematical Psychology</source><year>2016</year><volume>71</volume><fpage>1</fpage><lpage>6</lpage><pub-id pub-id-type="doi">10.1016/j.jmp.2016.01.006</pub-id></element-citation></ref><ref id="R14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gibbon</surname><given-names>J</given-names></name><name><surname>Church</surname><given-names>RM</given-names></name><name><surname>Meck</surname><given-names>WH</given-names></name></person-group><article-title>Scalar Timing in Memory</article-title><source>Annals of the New York Academy of Sciences</source><year>1984</year><volume>423</volume><issue>1</issue><fpage>52</fpage><lpage>77</lpage><pub-id pub-id-type="pmid">6588812</pub-id></element-citation></ref><ref id="R15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hachen</surname><given-names>I</given-names></name><name><surname>Reinartz</surname><given-names>S</given-names></name><name><surname>Brasselet</surname><given-names>R</given-names></name><name><surname>Stroligo</surname><given-names>A</given-names></name><name><surname>Diamond</surname><given-names>ME</given-names></name></person-group><article-title>Dynamics of history-dependent perceptual judgment</article-title><source>Nature Communications</source><year>2021</year><volume>12</volume><issue>1</issue><elocation-id>6036</elocation-id><pub-id pub-id-type="pmcid">PMC8521591</pub-id><pub-id pub-id-type="pmid">34654804</pub-id><pub-id pub-id-type="doi">10.1038/s41467-021-26104-2</pub-id></element-citation></ref><ref id="R16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hass</surname><given-names>J</given-names></name><name><surname>Durstewitz</surname><given-names>D</given-names></name></person-group><article-title>Time at the center, or time at the side? Assessing current models of time perception</article-title><source>Current Opinion in Behavioral Sciences</source><year>2016</year><volume>8</volume><fpage>238</fpage><lpage>244</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2016.02.030</pub-id></element-citation></ref><ref id="R17"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Klapproth</surname><given-names>F</given-names></name></person-group><chapter-title>Towards a Process Model of Temporal Generalization</chapter-title><person-group person-group-type="editor"><name><surname>Vatakis</surname><given-names>A</given-names></name><name><surname>Balcı</surname><given-names>M</given-names></name><name><surname>Di Luca</surname><given-names>M</given-names></name><name><surname>Correa</surname><given-names>Á</given-names></name></person-group><source>Timing and Time Perception: Procedures, Measures, &amp; Applications</source><publisher-name>BRILL</publisher-name><year>2018</year><pub-id pub-id-type="doi">10.1163/9789004280205</pub-id></element-citation></ref><ref id="R18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klapproth</surname><given-names>F</given-names></name><name><surname>Müller</surname><given-names>M</given-names></name></person-group><article-title>Temporal Generalization under Time Pressure in Humans</article-title><source>Quarterly Journal of Experimental Psychology</source><year>2008</year><volume>61</volume><issue>4</issue><fpage>588</fpage><lpage>600</lpage><pub-id pub-id-type="pmid">18938277</pub-id></element-citation></ref><ref id="R19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klapproth</surname><given-names>F</given-names></name><name><surname>Wearden</surname><given-names>J</given-names></name></person-group><article-title>Why Do Temporal Generalization Gradients Change When People Make Decisions as Quickly as Possible?</article-title><source>Quarterly Journal of Experimental Psychology</source><year>2011</year><volume>64</volume><issue>8</issue><fpage>1646</fpage><lpage>1664</lpage><pub-id pub-id-type="pmid">21563017</pub-id></element-citation></ref><ref id="R20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kononowicz</surname><given-names>TW</given-names></name><name><surname>Van Wassenhove</surname><given-names>V</given-names></name><name><surname>Doyère</surname><given-names>V</given-names></name></person-group><article-title>Rodents monitor their error in self-generated duration on a single trial basis</article-title><source>Proceedings of the National Academy of Sciences</source><year>2022</year><volume>119</volume><issue>9</issue><elocation-id>e2108850119</elocation-id><pub-id pub-id-type="pmcid">PMC8892352</pub-id><pub-id pub-id-type="pmid">35193973</pub-id><pub-id pub-id-type="doi">10.1073/pnas.2108850119</pub-id></element-citation></ref><ref id="R21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lebovich</surname><given-names>L</given-names></name><name><surname>Darshan</surname><given-names>R</given-names></name><name><surname>Lavi</surname><given-names>Y</given-names></name><name><surname>Hansel</surname><given-names>D</given-names></name><name><surname>Loewenstein</surname><given-names>Y</given-names></name></person-group><article-title>Idiosyncratic choice bias naturally emerges from intrinsic stochasticity in neuronal dynamics</article-title><source>Nature Human Behaviour</source><year>2019</year><volume>3</volume><issue>11</issue><fpage>1190</fpage><lpage>1202</lpage><pub-id pub-id-type="pmid">31477911</pub-id></element-citation></ref><ref id="R22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathôt</surname><given-names>S</given-names></name><name><surname>Schreij</surname><given-names>D</given-names></name><name><surname>Theeuwes</surname><given-names>J</given-names></name></person-group><article-title>OpenSesame: An open-source, graphical experiment builder for the social sciences</article-title><source>Behavior Research Methods</source><year>2012</year><volume>44</volume><issue>2</issue><fpage>314</fpage><lpage>324</lpage><pub-id pub-id-type="pmcid">PMC3356517</pub-id><pub-id pub-id-type="pmid">22083660</pub-id><pub-id pub-id-type="doi">10.3758/s13428-011-0168-7</pub-id></element-citation></ref><ref id="R23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ofir</surname><given-names>N</given-names></name><name><surname>Landau</surname><given-names>AN</given-names></name></person-group><article-title>Neural signatures of evidence accumulation in temporal decisions</article-title><source>Current Biology</source><year>2022</year><volume>32</volume><issue>18</issue><fpage>4093</fpage><lpage>4100</lpage><elocation-id>e6</elocation-id><pub-id pub-id-type="pmid">36007527</pub-id></element-citation></ref><ref id="R24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Özoğlu</surname><given-names>E</given-names></name><name><surname>Thomaschke</surname><given-names>R</given-names></name></person-group><article-title>Post-interval potentials in temporal judgements</article-title><source>Experimental Brain Research</source><year>2023</year><volume>241</volume><issue>3</issue><fpage>917</fpage><lpage>926</lpage><pub-id pub-id-type="pmcid">PMC9985573</pub-id><pub-id pub-id-type="pmid">36806967</pub-id><pub-id pub-id-type="doi">10.1007/s00221-023-06568-y</pub-id></element-citation></ref><ref id="R25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paton</surname><given-names>JJ</given-names></name><name><surname>Buonomano</surname><given-names>DV</given-names></name></person-group><article-title>The Neural Basis of Timing: Distributed Mechanisms for Diverse Functions</article-title><source>Neuron</source><year>2018</year><volume>98</volume><issue>4</issue><fpage>687</fpage><lpage>705</lpage><pub-id pub-id-type="pmcid">PMC5962026</pub-id><pub-id pub-id-type="pmid">29772201</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2018.03.045</pub-id></element-citation></ref><ref id="R26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piras</surname><given-names>F</given-names></name><name><surname>Coull</surname><given-names>JT</given-names></name></person-group><article-title>Implicit, Predictive Timing Draws upon the Same Scalar Representation of Time as Explicit Timing</article-title><source>PLoS ONE</source><year>2011</year><volume>6</volume><issue>3</issue><elocation-id>e18203</elocation-id><pub-id pub-id-type="pmcid">PMC3064672</pub-id><pub-id pub-id-type="pmid">21464972</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0018203</pub-id></element-citation></ref><ref id="R27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratcliff</surname><given-names>R</given-names></name><name><surname>Smith</surname><given-names>PL</given-names></name><name><surname>Brown</surname><given-names>SD</given-names></name><name><surname>McKoon</surname><given-names>G</given-names></name></person-group><article-title>Diffusion Decision Model: Current Issues and History</article-title><source>Trends in Cognitive Sciences</source><year>2016</year><volume>20</volume><issue>4</issue><fpage>260</fpage><lpage>281</lpage><pub-id pub-id-type="pmcid">PMC4928591</pub-id><pub-id pub-id-type="pmid">26952739</pub-id><pub-id pub-id-type="doi">10.1016/j.tics.2016.01.007</pub-id></element-citation></ref><ref id="R28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raviv</surname><given-names>O</given-names></name><name><surname>Ahissar</surname><given-names>M</given-names></name><name><surname>Loewenstein</surname><given-names>Y</given-names></name></person-group><article-title>How Recent History Affects Perception: The Normative Approach and Its Heuristic Approximation</article-title><source>PLoS Computational Biology</source><year>2012</year><volume>8</volume><issue>10</issue><elocation-id>e1002731</elocation-id><pub-id pub-id-type="pmcid">PMC3486920</pub-id><pub-id pub-id-type="pmid">23133343</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1002731</pub-id></element-citation></ref><ref id="R29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schurr</surname><given-names>R</given-names></name><name><surname>Reznik</surname><given-names>D</given-names></name><name><surname>Hillman</surname><given-names>H</given-names></name><name><surname>Bhui</surname><given-names>R</given-names></name><name><surname>Gershamn</surname><given-names>SJ</given-names></name></person-group><article-title>Dynamic computational phenotyping of human cognition</article-title><source>Nature Human Behaviour</source><year>2024</year><pub-id pub-id-type="pmcid">PMC11132988</pub-id><pub-id pub-id-type="pmid">38332340</pub-id><pub-id pub-id-type="doi">10.1038/s41562-024-01814-x</pub-id></element-citation></ref><ref id="R30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simen</surname><given-names>P</given-names></name><name><surname>Balci</surname><given-names>F</given-names></name><name><surname>DeSouza</surname><given-names>L</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name><name><surname>Holmes</surname><given-names>P</given-names></name></person-group><article-title>A Model of Interval Timing by Neural Integration</article-title><source>Journal of Neuroscience</source><year>2011</year><volume>31</volume><issue>25</issue><fpage>9238</fpage><lpage>9253</lpage><pub-id pub-id-type="pmcid">PMC3142662</pub-id><pub-id pub-id-type="pmid">21697374</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3121-10.2011</pub-id></element-citation></ref><ref id="R31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wearden</surname><given-names>J</given-names></name></person-group><article-title>Temporal Generalization in Humans</article-title><source>Journal of Experimental Psychology: Animal Behavior Processes</source><year>1992</year><volume>18</volume><issue>2</issue><fpage>134</fpage><lpage>144</lpage><pub-id pub-id-type="pmid">9335137</pub-id></element-citation></ref><ref id="R32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wearden</surname><given-names>J</given-names></name></person-group><article-title>Decision processes in models of timing</article-title><source>Acta Neurobiologiae Experimentalis</source><year>2004</year><volume>64</volume><issue>3</issue><fpage>303</fpage><lpage>317</lpage><pub-id pub-id-type="pmid">15283474</pub-id></element-citation></ref><ref id="R33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wearden</surname><given-names>J</given-names></name><name><surname>Edwards</surname><given-names>H</given-names></name><name><surname>Fakhri</surname><given-names>M</given-names></name><name><surname>Percival</surname><given-names>A</given-names></name></person-group><article-title>Why “Sounds Are Judged Longer Than Lights”: Application of a Model of the Internal Clock in Humans</article-title><source>Quarterly Journal of Experimental Psychology</source><year>1998</year><volume>51B</volume><issue>2</issue><fpage>97</fpage><lpage>120</lpage><pub-id pub-id-type="pmid">9621837</pub-id></element-citation></ref><ref id="R34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wearden</surname><given-names>J</given-names></name><name><surname>Towse</surname><given-names>JN</given-names></name></person-group><article-title>Temporal generalization in humans: Three further studies</article-title><source>Behavioural Processes</source><year>1994</year><volume>32</volume><issue>3</issue><fpage>247</fpage><lpage>264</lpage></element-citation></ref><ref id="R35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiener</surname><given-names>M</given-names></name><name><surname>Thompson</surname><given-names>JC</given-names></name></person-group><article-title>Repetition enhancement and memory effects for duration</article-title><source>NeuroImage</source><year>2015</year><volume>113</volume><fpage>268</fpage><lpage>278</lpage><pub-id pub-id-type="pmid">25818689</pub-id></element-citation></ref><ref id="R36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Collins</surname><given-names>AG</given-names></name></person-group><article-title>Ten simple rules for the computational modeling of behavioral data</article-title><source>eLife</source><year>2019</year><volume>8</volume><elocation-id>e49547</elocation-id><pub-id pub-id-type="pmcid">PMC6879303</pub-id><pub-id pub-id-type="pmid">31769410</pub-id><pub-id pub-id-type="doi">10.7554/eLife.49547</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>Schematic representation of a temporal generalization task.</title><p><bold>A</bold> Progression of the familiarization and test phases. While the familiarization phase is passive, after each interval in the test phase, the participant must respond before the experiment continues. <bold>B</bold> Intervals used in this work. In the first experiment, participants performed the same task twice, once with auditory stimuli and once with visual stimuli, in separate blocks. 0.4 s, in light color, is the standard.</p></caption><graphic xlink:href="EMS199513-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Schematic representation of the drift-diffusion temporal generalization model.</title><p><bold>A</bold> The basic components of the model – decision boundaries and decision variable – and examples of the evolution of the decision variable over time. Darker hues correspond to traces simulated with larger diffusion coefficients. Note the traces become more jagged as the diffusion coefficient increases. <bold>B</bold> Psychometric curves for the three levels of diffusion coefficient plotted in <bold>A</bold>. As internal noise grows, the curves become wider with shallower slopes, and the asymmetry increases.</p></caption><graphic xlink:href="EMS199513-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Participants perform better on auditory intervals.</title><p>Circles show the average probability to label an interval as “same” across participants, and error bars depict the within-participant SEM using the Morey-Cousineau method (<xref ref-type="bibr" rid="R8">Cousineau et al., 2021</xref>). In blue is data from the auditory modality and in red data from the visual modality.</p></caption><graphic xlink:href="EMS199513-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>The DDM outperforms the other models at the single participant level in both modalities.</title><p>The height of each bar signifies the number of participants (out of a total of 34) for which each model, at the x-axis, achieved the largest likelihood. Left shows results from the auditory block and right shows data from the visual block.</p></caption><graphic xlink:href="EMS199513-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>Behavioral performance and model fits for Experiment 1.</title><p>Each row shows results of one model. <bold>A</bold> DDM. Leftmost is the performance and model fits at the group level. Circles show the average probability to label an interval as “same” across participants, and error bars depict the within-participant SEM. Scatter plots show the estimated values of each of the free parameters (Left to right: lower boundary, upper boundary and diffusion). X and Y axes correspond to the auditory and visual modalities, respectively. To facilitate visualization, parameters far from the group are truncated and depicted with empty circles. <bold>B</bold> Same as <bold>A</bold>, for the BSU model. Parameter scatter plots show, left to right: lower boundary, upper boundary and Weber fraction. <bold>C</bold> Same as <bold>A</bold>, for the MCG model. Parameter scatter plots show, left to right: Mean boundary, boundary standard deviation and Weber fraction. <bold>D</bold> Same as <bold>A</bold>, for the CG model. Parameter scatter plots show, left to right: Mean boundary, boundary standard deviation and Weber fraction.</p></caption><graphic xlink:href="EMS199513-f005"/></fig><fig id="F6" position="float"><label>Figure 6</label><caption><title>DDM Parameters are more accurately recovered than the other models.</title><p>Each row shows the result of one model. <bold>A</bold> Parameter recovery for the DDM. Scatter plots show the estimated parameter (y-axis) against the simulated parameter (x-axis), for each of the free parameters (left to right: lower boundary, upper boundary and diffusion). Each point represents a single simulation. To facilitate visualization, values that were estimated as larger than the largest simulated parameter are truncated and replaced with empty circles. The heatmap at the right show the parameter correlations. Diagonal cells depict the correlation coefficient between simulated and estimated parameters, and off-diagonal cells depict the correlation between the estimated values of two different parameters. <bold>B</bold> Same as <bold>A</bold>, for the BSU model. Scatter plots depict, left to right: lower boundary, upper boundary and Weber fraction. <bold>C</bold> Same as <bold>A</bold>, for the MCG model. Parameter scatter plots show, left to right: Mean boundary, boundary standard deviation and Weber fraction. <bold>D</bold> Same as <bold>A</bold>, for the CG model. Parameter scatter plots show, left to right: Mean boundary, boundary standard deviation and Weber fraction.</p></caption><graphic xlink:href="EMS199513-f006"/></fig><fig id="F7" position="float"><label>Figure 7</label><caption><title>Diffusion coefficient and upper boundary are correlated.</title><p><bold>A</bold> Correlation of diffusion coefficient and upper boundary in both modalities. Circles represent the data of a single participant in a single modality (blue for auditory and red for visual). The 95% confidence interval of the regression lines are marked using shaded ribbons. <bold>B</bold> correlation across participants between upper boundary difference (vision – audition) and diffusion coefficient difference.</p></caption><graphic xlink:href="EMS199513-f007"/></fig><fig id="F8" position="float"><label>Figure 8</label><caption><title>Psychophysical performance improves with learning.</title><p>Group fits and individual parameter estimates for each block using the DDM. Left, performance and model fits at the group level. Circles show the average probability to label an interval as “same” across participants, and error bars depict the within-participant SEM. Scatter plots show the estimated values of each of the free parameters for data of each block. Circles and connecting lines mark the parameter values across blocks for a single participant, with box plots overlaid. Horizontal lines within the boxes represent the group median, the box extends from the 25th percentile to the 75th percentile, and the whiskers extend 1.5 IQRs from the median.</p></caption><graphic xlink:href="EMS199513-f008"/></fig><fig id="F9" position="float"><label>Figure 9</label><caption><title>Diffusion coefficients and lower boundaries aren’t correlated.</title><p>Correlation of diffusion coefficient and lower boundary in the three tertiles. Each circle represents the data of a single participant in a single tertile (Darker colors for later tertiles). The 95% confidence interval of the regression lines are marked using shaded ribbons.</p></caption><graphic xlink:href="EMS199513-f009"/></fig><table-wrap id="T1" orientation="portrait" position="float"><label>Table 1</label><caption><title>Number of participants and group log-likelihood for each model in each modality.</title><p>Bold numbers mark the model that performed best in each modality at the single participant or group level.</p></caption><table frame="box" rules="groups"><thead><tr><th valign="top" align="left" rowspan="2" style="border-left: 1px solid #000000;border-top: 1px solid #000000;border-right: 1px solid #000000;border-bottom: 1px solid #000000"/><th valign="top" align="center" colspan="3" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-bottom: 1px solid #000000">Audition</th><th valign="top" align="center" colspan="3" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-bottom: 1px solid #000000">Vision</th></tr><tr><th valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">Nr.<break/>participants</th><th valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">% of<break/>participants</th><th valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">Group LL</th><th valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">Nr.<break/>participants</th><th valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">% of<break/>participants</th><th valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">Group LL</th></tr></thead><tbody><tr><td valign="top" align="left" style="border-right: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid #000000">DDM</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000"><bold>16</bold></td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000"><bold>47.1</bold></td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">-4045.9</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000"><bold>24</bold></td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000"><bold>70.6</bold></td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">-4530.7</td></tr><tr><td valign="top" align="left" style="border-right: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid #000000">BSU</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">7</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">20.6</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">-4221.5</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">4</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">11.8</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">-4607.9</td></tr><tr><td valign="top" align="left" style="border-right: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid #000000">MCG</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">4</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">11.8</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">-4183.2</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">4</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">11.8</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000"><bold>-4513.8</bold></td></tr><tr><td valign="top" align="left" style="border-right: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid #000000">CG</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">7</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">20.6</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000"><bold>-4008.9</bold></td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">2</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">5.9</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">-4618.5</td></tr></tbody></table></table-wrap><table-wrap id="T2" orientation="portrait" position="float"><label>Table 2</label><caption><title>Parameter unidentifiability in the MCG and CG models.</title><p>Each cell includes the number of participants (out of 34) for which the specific parameter ( σ<sub><italic>B</italic></sub>, <italic>k</italic> or both) was estimated to be smaller than 0.001.</p></caption><table frame="box" rules="groups"><thead><tr><th valign="top" align="left" rowspan="2" style="border-left: 1px solid #000000;border-top: 1px solid #000000;border-right: 1px solid #000000;border-bottom: 1px solid #000000"/><th valign="top" align="left" colspan="3" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-bottom: 1px solid #000000">MCG</th><th valign="top" align="left" colspan="3" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-bottom: 1px solid #000000">CG</th></tr><tr><th valign="top" align="center" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">σ<sub><italic>B</italic></sub></th><th valign="top" align="center" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000"><italic>k</italic></th><th valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">Both</th><th valign="top" align="center" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">σ<sub><italic>B</italic></sub></th><th valign="top" align="center" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000"><italic>k</italic></th><th valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">Both</th></tr></thead><tbody><tr><td valign="top" align="left" style="border-right: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid #000000">Audition</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">21</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">6</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">0</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">15</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">12</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">0</td></tr><tr><td valign="top" align="left" style="border-right: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid #000000">Vision</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">19</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">3</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">0</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">26</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">4</td><td valign="top" align="left" style="border-bottom: 1px solid #000000;border-right: 1px solid #000000">0</td></tr></tbody></table></table-wrap></floats-group></article>