<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS152748</article-id><article-id pub-id-type="doi">10.1101/2020.10.02.323832</article-id><article-id pub-id-type="archive">PPR221424</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Abstract neural choice signals during action-linked decisions</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Sandhaeger</surname><given-names>Florian</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref><xref ref-type="aff" rid="A4">4</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><contrib contrib-type="author"><name><surname>Omejc</surname><given-names>Nina</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref><xref ref-type="aff" rid="A4">4</xref></contrib><contrib contrib-type="author"><name><surname>Pape</surname><given-names>Anna-Antonia</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref><xref ref-type="aff" rid="A4">4</xref></contrib><contrib contrib-type="author"><name><surname>Siegel</surname><given-names>Markus</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib></contrib-group><aff id="A1"><label>1</label>Department of Neural Dynamics and Magnetoencephalography, Hertie Institute for Clinical Brain Research, University of Tübingen, Germany</aff><aff id="A2"><label>2</label>Centre for Integrative Neuroscience, University of Tübingen, Germany</aff><aff id="A3"><label>3</label>MEG Center, University of Tübingen, Germany</aff><aff id="A4"><label>4</label>Graduate Training Centre of Neuroscience, International Max Planck Research School, University of Tübingen, Germany</aff><author-notes><corresp id="CR1">
<label>*</label>Correspondence to: <email>florian.sandhaeger@uni-tuebingen.de</email>, <email>markus.siegel@uni-tuebingen.de</email>
</corresp></author-notes><pub-date pub-type="nihms-submitted"><day>14</day><month>08</month><year>2022</year></pub-date><pub-date pub-type="preprint"><day>12</day><month>08</month><year>2022</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Humans can make abstract choices independent of motor actions. However, in laboratory tasks, choices are typically reported with an associated action. Consequentially, knowledge about the neural representation of abstract choices is sparse, and choices are often thought to evolve as motor intentions. Here, we show that in the human brain, perceptual choices are represented in an abstract, motor-independent manner, even when they are directly linked to an action. We measured MEG signals while participants made choices with known or unknown motor response mapping. Using multivariate decoding, we quantified stimulus, perceptual choice and motor response information with distinct cortical distributions. Choice representations were invariant to whether the response mapping was known during stimulus presentation, and they occupied distinct representational spaces from both stimulus and motor signals. Furthermore, their strength predicted decision confidence and accuracy, as expected from an internal decision variable. Our results uncover abstract neural choice signals that generalize to action-linked decisions, suggesting a general role of an abstract choice stage in human decision-making.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">Sensory decisions are often linked to an appropriate motor action. This has led to a framework of choices emerging as action intentions (<xref ref-type="bibr" rid="R9">Cisek and Kalaska, 2010</xref>), supported by numerous studies showing action-specific choice signals in motor- and premotor areas of the brain (<xref ref-type="bibr" rid="R15">Gold and Shadlen, 2000</xref>, <xref ref-type="bibr" rid="R16">2007</xref>; <xref ref-type="bibr" rid="R53">Shadlen and Newsome, 2001</xref>; <xref ref-type="bibr" rid="R61">Wang et al., 2019</xref>). Compelling evidence favors such an intentional framework over the historic idea of decision-making as a sequential process involving several, successive modules. However, a key component of intelligent behavior is the ability to also make abstract choices when a suitable action is not known in advance (<xref ref-type="bibr" rid="R10">Coallier and Kalaska, 2014</xref>; <xref ref-type="bibr" rid="R16">Gold and Shadlen, 2003</xref>; <xref ref-type="bibr" rid="R39">Nieder et al., 2020</xref>). Any comprehensive account of human decision-making thus has to account for the possibility of abstract choices.</p><p id="P3">Since most studies use a fixed mapping of perceptual choices (in the following referred to as “choices”) to motor responses, the role of abstraction in sensorimotor decision-making remains elusive. A few notable exceptions, using behavioral tasks with a variable mapping of choices to motor responses, have identified neural representations of abstract choices (<xref ref-type="bibr" rid="R2">Bennur and Gold, 2011</xref>; <xref ref-type="bibr" rid="R21">Hebart et al., 2012</xref>; <xref ref-type="bibr" rid="R24">Horwitz et al., 2004</xref>; <xref ref-type="bibr" rid="R31">Ludwig et al., 2018</xref>; <xref ref-type="bibr" rid="R36">Merten and Nieder, 2012</xref>, <xref ref-type="bibr" rid="R37">2013</xref>; <xref ref-type="bibr" rid="R38">Minxha et al., 2020</xref>; <xref ref-type="bibr" rid="R39">Nieder et al., 2020</xref>; <xref ref-type="bibr" rid="R66">Zhou and Freedman, 2019</xref>). However, empirical results comparing choice signals in action-linked and action-independent situations are sparse. While some recent work found perceptual choice representations to depend on the ability to plan motor actions (<xref ref-type="bibr" rid="R31">Ludwig et al., 2018</xref>; <xref ref-type="bibr" rid="R61">Wang et al., 2019</xref>) or response modality (<xref ref-type="bibr" rid="R23">Herding et al., 2017</xref>; <xref ref-type="bibr" rid="R63">Wu et al., 2019</xref>), other previous evidence suggests at least partially overlapping representations of perceptual choices with specified or unspecified motor actions (<xref ref-type="bibr" rid="R2">Bennur and Gold, 2011</xref>).</p><p id="P4">It is therefore unclear whether, and under which conditions, the same neural representations underlying abstract choice in an action-independent context are also present during choices that are linked to actions. Furthermore, the spatio-temporal dynamics of abstract choice signals are unknown, and it remains unclear whether abstract choice signals constitute an internal decision variable that tracks accumulated evidence. Consequentially, the demonstration of a context-independent, abstract decision variable would be important to confirm predictions of abstraction as an essential stage in perceptual decision-making.</p><p id="P5">To address this, we investigated human brain activity underlying flexible sensorimotor choices using magnetoencephalography (MEG). The task design and a multivariate analysis framework allowed us to pinpoint abstract neural choice signals in an action-linked as well as in an action-independent context. MEG activity was predictive of participants’ perceptual choices independently of both sensory input and motor behavior. Crucially, a novel metric for the assessment of cross-decoding results enabled us to conclude that abstract choice representations were not only present in both contexts, but indistinguishable between them. Furthermore, choice signals dynamically evolved along the sensorimotor hierarchy and predicted both decision confidence and accuracy, thus exhibiting a hallmark property of an internal decision variable. Our results cast doubt on a purely action-based framework, and suggest a general role for abstraction in sensorimotor decision-making.</p></sec><sec id="S2" sec-type="results"><title>Results</title><sec id="S3"><title>Behavior in a flexible sensorimotor decision-making task</title><p id="P6">We recorded MEG in 33 human participants, while they performed variants of a sensorimotor decision-making task (<xref ref-type="fig" rid="F1">Fig. 1A</xref>, see <xref ref-type="sec" rid="S12">Methods</xref> for subsets of participants used for some analyses). In each trial, we presented one of two dynamic random dot stimuli which either contained coherent downwards motion or not (referred to as “signal” and “noise” trials, respectively), and participants judged the presence of coherent motion. To separate stimulus-related neural signals from choice-related signals, we adapted the coherence level in the signal stimulus for each participant such that they performed near threshold. The presence of both correct and error trials then allowed us to identify neural signals associated with the perceptual choice, independent of the physical stimulus, i.e. neural signals that separated correct signal and incorrect noise trials from incorrect signal and correct noise trials. To disentangle choice-and motor response-related signals, we introduced a flexible mapping between perceptual choices and left- or righthand button presses that was cued on a trial-by-trial basis. For half of the trials, the choice-response mapping was revealed before stimulus onset (‘pre-condition’), such that emerging choices could immediately be linked to the appropriate motor response. For the other half (‘post-condition’), we revealed the mapping after stimulus offset, such that participants had to make abstract choices initially, before later selecting their motor response. Participants reported their choices with one of two buttons per choice (inner and outer buttons), thereby additionally indicating their confidence. Participants performed equally well on “pre” and “post” trials (74 % and 73 % correct), neither their sensitivity (d’ = 1.35 and 1.28; <italic>t<sub>25</sub></italic> = 1.27, <italic>P =</italic> 0.21, two-tailed t-test) nor criterion (C’ = -0.01 and 0.05; <italic>t<sub>25</sub></italic> = -1.49, <italic>P</italic> = 0.15) were different between tasks, and neither choice was preferentially associated with a particular motor response (50 % “right” responses for both “yes” and “no” choices, <italic>t<sub>25</sub></italic> = 0.58, <italic>P</italic> = 0.57 and <italic>t<sub>25</sub></italic> = -0.09, <italic>P</italic> = 0.93, two-tailed t-test). In both task conditions, responses had to be withheld until the fixation point disappeared, and while reaction times (0.74+/-0.23 s, mean +/-standard deviation over participants) were higher in the post- than the pre-condition (<xref ref-type="fig" rid="F1">Fig, 1B</xref>, 0.75 s vs 0.72 s, <italic>F</italic>(1,415) = 7.77, <italic>P</italic> = 0.0056), in noise than in signal trials (<italic>F</italic> = 9.7, <italic>P</italic> = 0.002), and in incorrect than in correct trials (<italic>F</italic> = 34.41, <italic>P</italic> &lt; 10<sup>-8</sup>), they were not significantly different between choices (<italic>F</italic> = 0.81, <italic>P</italic> = 0.37) or responses (<italic>F</italic> = 0.17, <italic>P</italic> = 0.68) (six-way ANOVA including the factors of participant, task condition, stimulus, choice, response and accuracy).</p></sec><sec id="S4"><title>Decoding neural representations of stimulus, response and choice-response mapping</title><p id="P7">For each task condition separately, we quantified neural information about the stimulus, response, choice-response mapping and choice using a multivariate analysis approach (cross-validated MANOVA (<xref ref-type="bibr" rid="R1">Allefeld and Haynes, 2014</xref>; <xref ref-type="bibr" rid="R5">Christophel et al., 2018</xref>), <xref ref-type="supplementary-material" rid="SD1">Fig. S1</xref>). This method is a generalization of the commonly used cross-validated Mahalanobis distance. cvMANOVA builds on a multivariate general linear model to assess the cross-validated variability contained in the data that is related to a specific variable of interest. While conceptually similar to decoding algorithms, cvMANOVA offers a number of advantages. Firstly, it allows for the simultaneous extraction of information about multiple variables without repeatedly training decoders on each variable separately. Secondly, this enables the quantification of information related to one variable, while excluding confounds related to any other variable. Thirdly, the resulting measure of the separability of the multivariate activity patterns associated with the variables of interest is continuous, offering a better interpretability and higher sensitivity compared to classifier accuracy. In addition, cross-validation ensures the unbiased estimation of information by using non-overlapping test- and training data sets. Thus, importantly, this analysis isolated neural information about each individual variable, independently of the others. Choice information, for example, was the information contained in the neural data about a participant’s perceptual choice independent of all other variables.</p><p id="P8">We found significant neural information about all task variables in both conditions (P &lt; 0.01, cluster-permutation statistics, <xref ref-type="fig" rid="F2">Fig. 2</xref>). Stimulus information (i.e. the neural pattern distinctness between “signal” and “noise” trials) rose after stimulus onset and remained partially present after stimulus offset. Response information (i.e. right vs. left-hand button presses) built up after stimulus offset; it did so earlier in the pre-condition where the choice-response mapping was already known during stimulus presentation. Motor responses could be predicted more easily, and earlier in the trial, from motor-cortical beta lateralization (<xref ref-type="supplementary-material" rid="SD1">Fig. S2</xref>, (<xref ref-type="bibr" rid="R47">Pape and Siegel, 2016</xref>). Choice-response mapping information (i.e., yes/left and no/right vs. yes/right and no/left trials) peaked upon presentation of the relevant cue; after the pre-cue in the pre-condition and after the post-cue in the post-condition. Notably, in the pre-condition, mapping information was still present late in the trial, several seconds after presentation of the visual cue, indicating that mapping information was likely not purely sensory driven by the visual features of the cues.</p></sec><sec id="S5"><title>Abstract choice representations generalize between task contexts</title><p id="P9">Crucially, we also found information about the perceptual choice (i.e. yes vs. no choices, <xref ref-type="fig" rid="F2">Fig. 2</xref>, bottom, <italic>P</italic> &lt; 0.0001 in both ‘pre’ and ‘post’ conditions, cluster permutation). Even though participants’ choices were related to the presented stimuli and behavioral responses, our analysis framework ensured that choice information could not be explained by neural variability due to either stimuli or responses. Thus, choice information was stimulus- and response-independent. In both conditions, choices could be predicted before stimulus onset (pre: <italic>P</italic> = 0.003, post: <italic>P</italic> = 0.045; one-tailed t-tests on time-averaged choice information up to 1.25s), indicating that they were partly based on purely internal priors.</p><p id="P10">While, in the ‘post’-condition, the required motor action was not specified until after the stimulus, choices could be immediately mapped to the appropriate response in the ‘pre’-condition. Nevertheless, choice information was present in both conditions with a similar magnitude and time course (<italic>P</italic> &gt; 0.05 for all time points before the end of the stimulus, two-tailed t-test), rising during stimulus presentation and remaining present until the end of the trial. Choice information could not be explained by eye movements (<xref ref-type="supplementary-material" rid="SD1">Fig. S3</xref>). Thus, choices were represented abstractly in the human brain, regardless of whether they could be directly linked to an action or not.</p><p id="P11">We employed a cross-decoding approach to assess the extent to which these choice representations were similar between both task conditions. We trained a decoding model on one task condition and tested it on the other. As the information estimated using cvMANOVA is symmetric with respect to the test- and training data used, we averaged results from both directions for all cross-decoding analyses. If the multivariate neural patterns distinguishing choices were identical in the ‘pre’- and ‘post’-conditions, we would expect the magnitude of the resulting cross-information to be comparable to the information found within the individual conditions. If, on the other hand, choices were represented in orthogonal neural subspaces in both conditions, cross-information should be much lower or negligible.</p><p id="P12">Cross-decoding of choices was positive throughout the trial (<italic>P</italic> &lt; 0.0001, cluster permutation). Furthermore, the magnitude of cross-information was similar to the magnitude of choice information in the ‘pre’- and ‘post’-conditions. To quantify this, we derived an estimate of the expected cross-information under the assumption of identical representations in both conditions, i.e. representations relying on the same multivariate pattern and differing only in signal to noise ratio between conditions (see <xref ref-type="sec" rid="S12">Materials and Methods</xref>). We found that cross-decoded choice information was never significantly lower than expected if representations were identical (<italic>P</italic> &gt; 0.05 for all time points). Thus, abstract choice representations were not only present but were also shared between an action-linked and an action-independent choice context.</p></sec><sec id="S6"><title>Choice representations dynamically shift from sensory to motor areas</title><p id="P13">We further investigated the properties of neural stimulus, choice and response representations by pooling data from both task conditions. This choice was justified by our finding of shared choice representations and maximized the signal to noise ratio for the following analyses. We repeated the decoding analysis in a searchlight fashion across cortex to extract the spatiotemporal evolution of neural information about each variable (<xref ref-type="fig" rid="F3">Fig. 3</xref>). During stimulus presentation, stimulus information was strongest in occipital visual cortex, in line with early visual representations of the sensory input. After stimulus offset, information remained at a lower level, uniformly across the brain (<xref ref-type="fig" rid="F3">Fig. 3A</xref>, top). Response information increased earliest and most strongly in motor areas (<xref ref-type="fig" rid="F3">Fig. 3A</xref>, middle), consistent with preparatory activity related to the upcoming motor response.</p><p id="P14">The expected cortical distribution and temporal evolution of choice information is less clear. Choices may be represented in visual areas, consistent with findings of choice probabilities in sensory neurons reflecting either the effect of sensory noise on decision formation or high-level feedback onto sensory populations (<xref ref-type="bibr" rid="R3">Britten et al., 1996</xref>; <xref ref-type="bibr" rid="R40">Nienborg and Cumming, 2009</xref>; <xref ref-type="bibr" rid="R54">Siegel et al., 2015</xref>). Choice-specific signals may also be present in motor- and premotor areas, supporting the planning of potential motor responses (<xref ref-type="bibr" rid="R2">Bennur and Gold, 2011</xref>; <xref ref-type="bibr" rid="R8">Cisek and Kalaska, 2005</xref>; <xref ref-type="bibr" rid="R23">Herding et al., 2017</xref>; <xref ref-type="bibr" rid="R54">Siegel et al., 2015</xref>) or in associative areas specialized for decision formation.</p><p id="P15">We found that the distribution of choice information changed dynamically over the course of the trial, rising first in occipital areas, before spreading throughout the brain. After the go cue, choice information remained strongest in parietal cortex and central motor areas (<xref ref-type="fig" rid="F3">Fig. 3A</xref>, bottom). Given the apparent shift of choice information from occipital areas during stimulus presentation to central areas during the response phase, we quantified the similarity the cortical distribution of choice information exhibited with those of stimulus and response information. We found a significant correlation between the cortical distributions of choice and stimulus information during stimulus presentation, and between choice and response information during the response phase (<xref ref-type="fig" rid="F3">Fig. 3B</xref>, stimulus: <italic>P</italic> = 0.0064, response: <italic>P</italic> = 0.0227, cluster permutation). We found similar results when repeating the searchlight analysis independently for pre- and post-condition trials and extracting correlation values for the early stimulus-related and the later response-related cluster. Despite the reduced number of trials, two out of four correlation values were significant, and all four had the same directionality as in the pooled data (stimulus vs. choice in pre: <italic>t<sub>25</sub></italic> = 4.24, <italic>P</italic> = 0.0001, response vs. choice in post: <italic>t<sub>25</sub></italic> = 2.81, <italic>P</italic> = 0.0047, stimulus vs. choice in post: <italic>t<sub>25</sub></italic> = 0.98, <italic>P</italic> = 0.1683, response vs. choice in pre: <italic>t<sub>25</sub></italic> = 1.64, <italic>P</italic> = 0.0569, all one-tailed t-tests).</p></sec><sec id="S7"><title>Temporal stability of neural representations</title><p id="P16">The spatial overlap between choice, stimulus and response information raised the question whether there were shared representations between stimulus and choice during evidence accumulation and between choice and response during motor execution, respectively. We used cross-temporal and cross-variable decoding to test this and evaluated both the temporal dynamics of representations and the relationships between stimulus, choice and response representations (<xref ref-type="fig" rid="F4">Fig. 4A</xref>).</p><p id="P17">First, we focused on the temporal dynamics of representations. By using data from one timepoint for training, and from another timepoint for testing, cross-temporal decoding can reveal time periods of relative stability (<xref ref-type="bibr" rid="R27">King and Dehaene, 2014</xref>). Furthermore, it is possible to compute the expected cross-temporal decoding under the assumption that the underlying representation remains perfectly stable over time. Comparing the empirical cross-temporal decoding to this expectation can reveal periods of relative dynamics (<xref ref-type="bibr" rid="R55">Spaak et al., 2017</xref>). Stimulus information was initially highly dynamic, as indicated by high cross-decoding values being concentrated along the diagonal, but stable after stimulus offset, as indicated by significant cross-decoding far from the diagonal (<xref ref-type="fig" rid="F4">Fig. 4A</xref>, top left). Given our use of fixed random dot patterns, this was consistent with stimulus information being driven by two components: During stimulus presentation, information was likely dominated by moment-to-moment differences in retinal input. After stimulus offset, the global motion content may have contributed more strongly. Choice information was temporally more stable; still, early and late choice representations were distinct (<xref ref-type="fig" rid="F4">Fig. 4A</xref>, center), in line with the observed spatial shift from sensory to motor areas.</p></sec><sec id="S8"><title>Choice representations are distinct from sensory and motor representations</title><p id="P18">How did the neural representations of different variables relate to each other? The multivariate patterns that encode any two variables are either orthogonal, indicating non-overlapping underlying population subspaces, collinear, indicating indistinguishable circuits underlying both representations, or somewhere in between (<xref ref-type="fig" rid="F4">Fig. 4B</xref>; see also <xref ref-type="supplementary-material" rid="SD1">Fig. S1</xref> for further details). Furthermore, the representation of one variable may differ depending on the value of the other, i.e. the two variables may interact. In the present data, stimulus- and choice representations may depend on identical underlying circuits. For example, sensory neurons may show the same responses for visually presented as for imagined motion (<xref ref-type="bibr" rid="R65">Zhao et al., 2020</xref>; <xref ref-type="bibr" rid="R66">Zhou and Freedman, 2019</xref>). If such neurons constituted stimulus- and choice representations, we would expect strong positive cross-information between stimulus and choice. In contrast, if choice and stimulus information were largely driven by distinct populations, this may result in no cross-information; Our results were compatible with the latter scenario. There was no significant cross-decoding between stimulus and choice (<xref ref-type="fig" rid="F4">Fig. 4A</xref>, top center, biggest cluster: <italic>P</italic> = 0.11; <xref ref-type="fig" rid="F4">Fig. 4C</xref>, biggest cluster: <italic>P</italic> = 0.22), and cross-decoding was significantly lower than expected for identical representations (<xref ref-type="fig" rid="F4">Fig. 4A</xref>, top center; <xref ref-type="fig" rid="F4">Fig. 4C</xref>, <italic>P</italic> &lt; 0.0001).</p><p id="P19">Next, we investigated the relationship between choice- and response representations. Again, we found only weak cross-information between the two variables, indicating that neural choice and response representations did not overlap (<xref ref-type="fig" rid="F4">Fig. 4A</xref>, middle right, biggest cluster: <italic>P</italic> = 0.15; <xref ref-type="fig" rid="F4">Fig. 4D</xref>, biggest cluster: from 0.8 to 2.55 s, <italic>P</italic> = 0.038, uncorrected). After selection of a motor response, choices may still have been represented as a modulation of the motor signal, e.g. leading to a relative strengthening of the activity pattern associated with the upcoming motor response for “yes”-choices compared to “no”-choices. We thus assessed the magnitude of response information, separately for each choice. However, we found no difference between both conditions (<italic>P</italic> &gt; 0.05 for all time points), indicating that even during response execution, choices were not represented as a modulation of neural motor activity. (<xref ref-type="fig" rid="F4">Fig. 4E</xref>). We further visualized these results geometrically, which well illustrated the near-orthogonality of choice-and stimulus-, or choice- and response signals, respectively (<xref ref-type="fig" rid="F4">Fig. 4F-G</xref>). In sum, the neural circuit patterns underlying choice information in our MEG data were not significantly shared with those underlying stimulus and response information, even when they were strongest in similar areas.</p><p id="P20">Abstract choice signals may also be related to, and caused by, sequential choice biases, i.e. preceding choices (<xref ref-type="bibr" rid="R32">Lueckmann et al., 2018</xref>; <xref ref-type="bibr" rid="R54">Siegel et al., 2015</xref>; <xref ref-type="bibr" rid="R59">Urai et al., 2019</xref>). Furthermore, when pooling over the pre- and post- conditions, the higher signal-to-noise ratio revealed robust pre-stimulus choice information (<xref ref-type="fig" rid="F4">Fig. 4A, C, D</xref>), indicating the formation of choices even before stimulus presentation, which may well be related to sequential choice biases. We therefore repeated the analysis including the previous choice as an additional variable, and found that choice information after stimulus onset could not be explained by the previous choice (<xref ref-type="supplementary-material" rid="SD1">Fig. S4A</xref>). Including the previous motor response instead of previous choice showed a sustained representation of past motor actions (<xref ref-type="bibr" rid="R47">Pape and Siegel, 2016</xref>). However, this had an even weaker effect on choice information. Thus, neuronal choice signals did not merely reflect the previous choice or motor response.</p><p id="P21">While our analysis already excluded the possibility that choice information was driven by overall differences between stimuli, it could theoretically still be explained by a difference between correct and error trials for one of the two stimulus classes. To eliminate this possibility, we trained the choice decoding model on all trials and evaluated it separately on correct and incorrect trials. As choice information was present in both cases, and had the same sign, it could not be explained by choice accuracy (<xref ref-type="fig" rid="F5">Fig. 5</xref>). In sum, abstract choice information did not result from the representation of either previous choices or accuracy as potentially confounding variables.</p></sec><sec id="S9"><title>Choice signals predict stimuli</title><p id="P22">The above results suggested that choice signals reflected an abstract decision stage which was neither directly related to early sensory nor to motor representations. Nonetheless, behavioral choices were based on the presented stimuli, and therefore strongly correlated with them. We thus asked whether this relationship was reflected in the neural choice signals, or whether they were stimulus-independent and therefore purely internally driven. To do so, we computed single-trial estimates of the choice signal by projecting each trial’s data onto the choice axis defined by our multivariate analysis. We then assessed whether the sign of the single-trial choice signals predicted the stimulus. Indeed, after stimulus onset, the predictability of the stimulus increased until it reached a stable level for the remainder of the trial (<xref ref-type="fig" rid="F5">Fig. 5A</xref>, P &lt; 0.0001, cluster-permutation). As expected, there was no significant stimulus-predictability before stimulus onset, even though there was a small amount of choice information (<xref ref-type="fig" rid="F4">Fig. 4C</xref>).</p></sec><sec id="S10"><title>The strength of choice signals predicts decision confidence and accuracy</title><p id="P23">Our participants also reported their confidence in each trial’s perceptual choice, providing us with further leverage to unravel the nature of the choice signals we found. Specifically, this allowed us to test whether the choice-predictive signal merely correlated with choices, or whether its relation to accuracy and confidence exhibited additional key properties expected of a decision variable integrating evidence towards a choice.</p><p id="P24">First, we behaviorally assessed the relationship between participants’ choices and confidence ratings. Participants were more confident in yes- than in no-choices (average proportion of high confidence reports: 0.54 vs. 0.47, <italic>P</italic> = 0.034, two-tailed t-test) and in trials with signal-than in those with noise stimuli (0.55 vs. 0.46, <italic>P</italic> = 1.4×10<sup>-4</sup>). In addition, and critically, they reported high confidence more often in correct trials than in incorrect trials (average proportion of high confidence reports: 0.56 vs. 0.35, <italic>P</italic> = 3 ×10<sup>-7</sup>, two-tailed t-test). We quantified this relationship using the meta-d’ measure of metacognitive sensitivity (<xref ref-type="bibr" rid="R34">Maniscalco and Lau, 2012</xref>) (<xref ref-type="fig" rid="F5">Fig. 5A</xref>). As expected, meta-d’ was positive (<italic>t<sub>18</sub></italic> = 7.4, <italic>P</italic> = 7.5×10<sup>-7</sup>, two-tailed t-test), correlated with d’ (r<sub><italic>17</italic></sub> = 0.82, <italic>P</italic> = 1.5×10<sup>-5</sup>, Pearson correlation), but tended to be smaller than d’ (<italic>t<sub>18</sub></italic> = -4.1, <italic>P</italic> = 7×10<sup>-4</sup>, two-tailed t-test). This showed that participants veridically reported their confidence and suggested that their confidence judgements were largely, but not perfectly based on the same sensory evidence as their choices (<xref ref-type="bibr" rid="R18">Grimaldi et al., 2015</xref>; <xref ref-type="bibr" rid="R26">Kiani et al., 2014</xref>; <xref ref-type="bibr" rid="R35">Maniscalco et al., 2021</xref>; <xref ref-type="bibr" rid="R43">Odegaard et al., 2018</xref>). These results also held when we separately assessed them in the pre- and post-conditions, and neither d’ (<italic>t<sub>18</sub></italic> = 1.2, <italic>P</italic> = 0.24) nor meta-d’ (<italic>t<sub>18</sub></italic> = 0.2, <italic>P</italic> = 0.83) were significantly different between conditions.</p><p id="P25">Next, we directly investigated the relation of neural choice signals to decision confidence and accuracy. In signal detection theory and in related accumulator models of decision making an internal decision variable tracks the integrated evidence for a given choice. Importantly, such a decision variable enables the computation of choice-confidence, as the absolute distance to the decision boundary (<xref ref-type="bibr" rid="R22">Hebart et al., 2016</xref>; <xref ref-type="bibr" rid="R25">Kiani and Shadlen, 2009</xref>; <xref ref-type="bibr" rid="R33">Macmillan and Creelman, 2004</xref>; <xref ref-type="bibr" rid="R52">Shadlen and Kiani, 2013</xref>). Consequentially, the absolute value of the decision variable should be larger during high-confidence trials than during low-confidence trials (<xref ref-type="fig" rid="F5">Fig. 5B</xref>, blue vs. green), and, importantly independent of confidence, higher during correct than during error trials (<xref ref-type="fig" rid="F5">Fig. 5B</xref>, bright vs. dark colors).</p><p id="P26">To establish whether the choice signals found here could reflect an internal decision variable, we thus repeated our decoding analysis, now adding decision confidence as an additional variable. We trained the decoding model separately on confident and unconfident trials, and tested it separately on confident correct, unconfident correct, confident error and unconfident error trials. We hypothesized that, if choice information constituted an internal decision variable reflecting the same subjective evidence used to inform confidence judgements, it would be strongest in correct trials when confidence was high, and progressively weaker in confident error trials, unconfident correct trials and unconfident error trials.</p><p id="P27">Indeed, we found that the strength of choice representations descriptively followed this pattern predicted by signal detection theory (<xref ref-type="fig" rid="F5">Fig. 5C</xref>: correct/high confidence larger than incorrect/high confidence, correct/low confidence and incorrect/low confidence; <italic>P</italic> = 0.013, <italic>P</italic> = 0.002, <italic>P</italic> = 0.001; high confidence larger than low confidence and correct larger than incorrect; P = 0.027, P = 0.025). Importantly, participants’ accuracy and confidence were assessed as separate factors. Thus, the relationship between choice and confidence could not simply be explained by accuracy or vice versa. We additionally performed this analysis separately for the pre-cue and post-cue task conditions, after excluding the factor of response from our model in order to retain a sufficient number of trials per condition. There was a similar pattern in both tasks (Post: correct/high confidence larger than incorrect/high confidence, correct/low confidence and incorrect/low confidence; <italic>P</italic> = 0.035, <italic>P</italic> = 0.008, <italic>P</italic> = 0.005. Pre: correct/high confidence larger than incorrect/high confidence, correct/low confidence and incorrect/low confidence; <italic>P</italic> = 0.007, <italic>P</italic> = 0.002, <italic>P</italic> = 0.023). In contrast, there was no clear relationship between choice confidence or accuracy and the strength of stimulus- or motor representations (<xref ref-type="supplementary-material" rid="SD1">Fig. S5</xref>).</p><p id="P28">Finally, we investigated the relative placement of correct and incorrect trials of both choices on the neural choice axis. As the stimulus design used was inherently asymmetric (signal vs. noise stimuli), a similar asymmetry may be expected for the neural representations of yes- and no-choices, opening the door for potential, choice-unrelated confounds. For example, the timing of choice commitment may be different for yes- and no-choices, differentially affecting the neural signal. While our fixed-time design did not provide access to commitment times, responses in similar forced-response detection tasks have been found to be slower for no-than for yes-choices, and highly similar between correct and incorrect no-choices (<xref ref-type="bibr" rid="R14">de Gee et al., 2014</xref>). This is consistent with no-choices occurring when the internal decision variable does not hit a bound until the end of the trial. This leads to a critical prediction for the present data. If neural choice signals reflected the time of choice commitment rather than the decision variable itself, they should exhibit a similar pattern with a difference between yes- and no-choices but similar signals for correct and incorrect no-choices. To test this, we trained a decoding model on all choices and tested it separately on, first, correct yes vs. correct no-choices, secondly, incorrect yes vs. incorrect no-choices, and third, correct yes vs, incorrect no-choices. The resulting distances allowed us to estimate the relative placement of correct and incorrect, yes and no choices on the choice axis. As expected from a neural decision variable, these trial types were well-ordered, with correct no-choices being followed by incorrect no-, incorrect yes-, and correct yes-choices (<xref ref-type="fig" rid="F5">Fig. 5E-F</xref>, P&lt;0.05 for all pairwise comparisons apart from correct yes vs. correct no with P = 0.12, one-tailed t-tests). In contrast, this ordering is incompatible with a timing confound arising from a potential asymmetry between yes- and no-choices.</p><p id="P29">In sum, our behavioral results pointed to the existence of an internal decision variable, which informed both choices and confidence ratings. Furthermore, the strength of the choice-predictive neural signal varied with confidence and accuracy, precisely following a pattern predicted from signal detection theory. Thus, neural choice information measured in MEG did not only predict abstract perceptual choices but appeared to reflect the underlying internal decision variable.</p></sec></sec><sec id="S11" sec-type="discussion"><title>Discussion</title><p id="P30">Studies of the neural basis of sensorimotor decision-making have often neglected abstract, motor-independent choices (<xref ref-type="bibr" rid="R11">Donner et al., 2009</xref>). This is rooted in the fact that many real-world choices appear to be choices between motor actions (<xref ref-type="bibr" rid="R9">Cisek and Kalaska, 2010</xref>) and in the difficulty of accessing signals representing purely abstract choices. On the one hand, in animal studies, which provide the majority of evidence in support of neural circuits selective for specific choice options, behavioral tasks that disentangle choices from motor responses are very challenging. Non-invasive human studies, on the other hand, struggle to read out choice contents, and thus mostly provide indirect evidence for choice-related neural activity. Consequently, studies comparing the representation of choices in abstract and action-linked contexts are rare. A small number of notable exceptions have provided intriguing results (<xref ref-type="bibr" rid="R2">Bennur and Gold, 2011</xref>; <xref ref-type="bibr" rid="R31">Ludwig et al., 2018</xref>; <xref ref-type="bibr" rid="R61">Wang et al., 2019</xref>), but not established a unified account of the role and extent of abstract choice signals.</p><p id="P31">By combining non-invasive MEG in humans with an advanced multivariate analysis framework, we robustly read out abstract choice contents from whole-brain neural activity. In accordance with current theories (<xref ref-type="bibr" rid="R25">Kiani and Shadlen, 2009</xref>; <xref ref-type="bibr" rid="R52">Shadlen and Kiani, 2013</xref>), abstract choice representations predicted decision confidence and accuracy. This indicates that this neural signal did not merely correlate with choice but reflected the underlying decision variable. In sum, our findings point to an important role of abstraction in decision-making, even in a simple task involving a known sensorimotor mapping.</p><p id="P32">Abstract choices were not only represented in brain activity when decisions had to be made abstractly, but also when the sensorimotor mapping was known in advance. Importantly, our cross-decoding analysis showed that choice representations in both task contexts were indistinguishable from one another. While the fundamental limits of MEG spatial resolution and sensitivity prevent the conclusion that the underlying circuit representations are identical, this striking similarity requires any potentially remaining differences between conditions to be small and of a type that MEG is blind to.</p><p id="P33">Our finding of abstract choice representations generalizing between contexts in which actions can be planned and those in which they cannot is in line with behavioral evidence suggesting analogous mechanisms underlying decision-making in action-linked and -independent contexts (<xref ref-type="bibr" rid="R57">Tsetsos et al., 2015</xref>). Moreover, recordings in macaque area LIP have found the choice selectivity of neurons to be similar, regardless of whether a motor action was specified (<xref ref-type="bibr" rid="R2">Bennur and Gold, 2011</xref>). Our results extend this finding to the whole-brain level, indicating that the dominant sources of choice-selective signals generalize between contexts. Intriguingly, a recent study found representations of the decision variable in area LIP that were not tightly linked to the population’s oculomotor selectivity, but varied in a task-dependent manner (<xref ref-type="bibr" rid="R44">Okazawa et al., 2021</xref>). These task-dependent representations are compatible with abstract, motor-independent choice representations as reported here. Furthermore, our findings accord well with research implicating a centro-parietal positivity (CPP) as an electrophysiological marker of evidence accumulation (<xref ref-type="bibr" rid="R42">O’Connell et al., 2012</xref>; <xref ref-type="bibr" rid="R58">Twomey et al., 2016</xref>). The CPP exhibits several properties of a domain-general, abstract neural decision variable; however, while it gradually builds up with the absolute amount of evidence, it has not been shown to carry information about the choice itself. Thus, the CPP, as an unsigned marker of integration, and the specific choice signals found in the present study may reflect different aspects of the same underlying process.</p><p id="P34">This - as well as any other - decision making study lives off the fact that sometimes participants make different choices for identical stimuli. How does this variability arise? In principle two broad, and not mutually exclusive, classes of explanations exist. First, it could be bottom-up driven, with sensory noise having a causal effect on choices. This sensory noise could be internal, arising from the inherent variability in neural responses for identical stimuli, or due to uncontrolled external variability, such as small differences in the stimulus itself. Secondly, it could be top-down driven, with internal factors such as expectations, biases or beliefs or simply non-sensory noise pushing choices one or the other way. Several of our results consistently suggest that the demonstrated choice signals are positioned at an intermediate stage between these extremes. First, if the choice signals directly reflected sensory noise, we would expect this noise to inhabit the same neural subspace as the stimulus signals themselves - in other words, there should be strong cross-information between stimulus and choice. In contrast to this, our results are better compatible with choice signals reflecting integrated sensory noise represented distinctly. For example, one may expect to find instantaneous sensory noise represented in area MT, but integrated sensory information, and therefore integrated noise as well, represented in area LIP. Notably, such an integration stage would still be expected to be modulated by the stimulus, and thus to lead to stimulus-choice cross-information, but only subtly so. In our data this effect was too weak to result in significant cross-information, but is nonetheless apparent in the hypothesis-driven finding of stronger choice signals in correct than in error trials. Second, we found that signed choice information predicted the stimulus - despite near-orthogonality of the representations of both variables. This suggests that choice information was indeed reflective of a stage separate from, but influenced by the early sensory representation. This prediction increased during stimulus presentation and then remained stable, similar to the choice information time course itself, and consistent with the time course expected from temporal integration. In contrast, choice signals at an instantaneous, early sensory non-integration stage would also predict the stimulus, but predictions should be at the same level throughout the stimulus presentation interval, and subsequently taper off. Third, we found small amounts of choice information before stimulus presentation. As these could not have arisen due to the stimulus, they must reflect intraneous factors. In conclusion, the most parsimonious explanation for our data is an intermediate choice stage which reflects both accumulated sensory evidence and top-down contributions, akin to an internal decision variable.</p><p id="P35">The stimuli used in the present study, and therefore the corresponding choices, were inherently asymmetric. Thus, one may plausibly assume that this asymmetry underlies the decodablity of choices: an unobserved, confounding variable correlated with choice may result in the seeming readout of choices. However, our finding of a significant difference of the choice signal between correct and incorrect no-choices does not accord with a timing-related confound due to this asymmetry (<xref ref-type="bibr" rid="R14">de Gee et al., 2014</xref>). More generally, any confounding variable would have to exhibit the properties of the choice signal demonstrated here: small, but existing pre-stimulus differences between choices, a modulation by confidence and accuracy even within no-trials, and a trial-by-trial predictability of the stimulus. We therefore consider it unlikely that our results can be accounted for by the asymmetric task-design. Nonetheless, future research should explicitly test whether the current findings generalize to symmetric choices.</p><p id="P36">The cortical distribution of abstract choice signals may be modulated by response modality. Recent work using fMRI suggested that, for vibrotactile comparisons, abstract choice representations are present in non-overlapping, modality-specific cortical areas (<xref ref-type="bibr" rid="R63">Wu et al., 2019</xref>, <xref ref-type="bibr" rid="R64">2021</xref>). On the other hand, direct neuronal recordings have shown the representation of recognition and categorization choices in medial frontal cortex to generalize between manual and saccadic responses (<xref ref-type="bibr" rid="R38">Minxha et al., 2020</xref>). The accessibility of such modality-independent representations of choice likely depends on the specific behavioral task and type of neural measurement. Research combining multiple measurement scales (<xref ref-type="bibr" rid="R6">Cichy et al., 2014</xref>; <xref ref-type="bibr" rid="R29">Kriegeskorte et al., 2008</xref>; <xref ref-type="bibr" rid="R51">Sandhaeger et al., 2019</xref>) should help resolving this. Our results only have indirect implications for the modality-dependence of choice signals because participants eventually always reported their choice using a button press. Nonetheless, the broad availability of choice representations across the brain, in conjunction with the shift of the information peak from visual sensory to motor areas is consistent with the co-existence of modality-independent and modality-specific components.</p><p id="P37">Perceptual decisions involve a complex interaction of feedforward and feedback processes throughout the brain (<xref ref-type="bibr" rid="R50">Quinn et al., 2021</xref>; <xref ref-type="bibr" rid="R54">Siegel et al., 2015</xref>; <xref ref-type="bibr" rid="R62">Wilming et al., 2020</xref>). Here, we found that the spatial peak of abstract choice information shifted throughout the trial, reflecting the currently relevant stage (<xref ref-type="bibr" rid="R30">Li Hegner et al., 2017</xref>; <xref ref-type="bibr" rid="R54">Siegel et al., 2015</xref>). This does not necessitate that choices originate in sensory cortex and are later relayed to motor cortex; in fact, choices may be computed elsewhere, but be preferentially accessible in currently engaged areas. The global availability of choice information is in line with either a distributed computation that involves recurrent interactions, or a global broadcast of choice signals (<xref ref-type="bibr" rid="R40">Nienborg and Cumming, 2009</xref>; <xref ref-type="bibr" rid="R54">Siegel et al., 2015</xref>), for example through feature-attentional mechanisms (<xref ref-type="bibr" rid="R50">Quinn et al., 2021</xref>). Further studies including invasive and manipulative approaches are required to pinpoint where and by which mechanisms abstract choices are computed.</p><p id="P38">A growing body of evidence has related the formation of action-linked sensorimotor decisions to activity in motor- and premotor areas (<xref ref-type="bibr" rid="R8">Cisek and Kalaska, 2005</xref>; <xref ref-type="bibr" rid="R11">Donner et al., 2009</xref>; <xref ref-type="bibr" rid="R15">Gold and Shadlen, 2000</xref>; <xref ref-type="bibr" rid="R53">Shadlen and Newsome, 2001</xref>; <xref ref-type="bibr" rid="R61">Wang et al., 2019</xref>; <xref ref-type="bibr" rid="R62">Wilming et al., 2020</xref>). Our findings are well compatible with these results: the presence of an abstract choice stage does not preclude the simultaneous planning and competition of multiple response options or a general unspecific response preparation (<xref ref-type="bibr" rid="R8">Cisek and Kalaska, 2005</xref>; <xref ref-type="bibr" rid="R28">Klaes et al., 2011</xref>). Indeed, we found fluctuations in motor cortical beta band activity to predict upcoming motor responses, independently of the perceptual choice (<xref ref-type="bibr" rid="R47">Pape and Siegel, 2016</xref>; <xref ref-type="bibr" rid="R48">Pape et al., 2017</xref>). These response-predictive beta band signals ramped up upon stimulus presentation in the “pre”-condition, as expected due to the earlier availability of the choice-response mapping. Notably, this ramp-up happened earlier than the appearance of response information in the broadband electrophysiological signals, underpinning the well-known role of beta band activity as a specific marker of motor preparation (<xref ref-type="bibr" rid="R58">Twomey et al., 2016</xref>). Taken together, these findings support a multi-level model of decision-making involving simultaneous evaluation of abstract choices as well as motor actions (<xref ref-type="bibr" rid="R7">Cisek, 2012</xref>). The relevance of an abstract choice level may be understood in light of phenomena like perceptual priors (<xref ref-type="bibr" rid="R19">Haefner et al., 2016</xref>; <xref ref-type="bibr" rid="R56">Summerfield and de Lange, 2014</xref>), sequential choice biases (<xref ref-type="bibr" rid="R47">Pape and Siegel, 2016</xref>; <xref ref-type="bibr" rid="R59">Urai et al., 2019</xref>), or value computations associated with the choices themselves (<xref ref-type="bibr" rid="R46">Padoa-Schioppa, 2011</xref>), which all require and act on abstract choice representations. The primate brain, which is able to assess abstract options and treat decision-making problems as arbitrary categorization (<xref ref-type="bibr" rid="R13">Freedman and Assad, 2011</xref>; <xref ref-type="bibr" rid="R36">Merten and Nieder, 2012</xref>), may do so even when not strictly necessary. Importantly, this can still be reconciled with an intentional framework of decision-making, if intentions are not only about actions, but also rules, or activations of neural circuits in general (<xref ref-type="bibr" rid="R7">Cisek, 2012</xref>; <xref ref-type="bibr" rid="R52">Shadlen and Kiani, 2013</xref>).</p><p id="P39">We conclude that an abstract choice stage may be universally present in human perceptual decision-making, enabling the evaluation of motor-independent choice options even during action-linked decisions.</p></sec><sec id="S12" sec-type="methods"><title>Methods</title><sec id="S13"><title>Experimental Design</title><sec id="S14" sec-type="subjects"><title>Participants</title><p id="P40">33 healthy, right-handed human volunteers (18 female; mean age: 28 years; 3 years SD) participated in this study and received monetary reward. All participants had normal or corrected-to-normal vision and gave written informed consent before participating. The study was conducted in accordance with the Declaration of Helsinki and approved by the ethics committee of the University of Tübingen.</p></sec><sec id="S15"><title>Behavioural task &amp; stimuli</title><p id="P41">Participants performed a flexible sensorimotor decision-making task. In each trial, they had to decide whether a random dot kinematogram contained coherent downwards motion or not and reported their choice with a left- or righthand button press. Crucially, the mapping between response hand and choice varied on a trial by trial basis. Moreover, the mapping was either revealed before (pre-condition) or after (post-condition) the stimulus. Additionally, an irrelevant cue was presented after (pre-condition) or before (post-condition) the stimulus.</p><p id="P42">Participants started a trial by acquiring fixation on a fixation spot. After a fixation period, the first cue appeared for 250 ms, followed by a delay of 1000 ms, the presentation of the random dot stimulus for 2000 ms, another 1000 ms delay and the second cue for 250 ms. A third 1000 ms delay was followed by a 33 ms dimming of the fixation spot, which served as the go-cue for the participant’s response. The response consisted in a button press using the left or right index finger, according to the choice and the choice-response mapping. Participants chose one of two buttons on either side to indicate whether they were confident in their choice or not. 250 ms after their response, participants received a 100 ms visual feedback (centrally presented circle, 2.1 degree diameter, red for incorrect or green for correct).</p><p id="P43">The random dot stimuli consisted of 1500 white dots with a diameter of 0.12 degrees, presented in an 8.5 degree diameter circular aperture on a black background. Dots moved at a speed of 10 degrees per second. For each participant, we used only two stimuli, each presented in half of the trials: First, a target stimulus, in which, on each frame, a fraction of dots moved coherently downwards, whereas the rest moved in random directions. Secondly, a noise stimulus, in which all dots moved in random directions. In a separate session before the MEG recordings, the motion coherence of target stimuli was titrated to each participant’s individual perceptual threshold using a staircase procedure with 280 trials. Motion coherence was adaptively lowered by one level after each correct choice and increased by two levels after each incorrect choice. To determine the coherence threshold, a Weibull function was fit to the resulting data, excluding the first 50 trials. Choice-response cues and irrelevant cues all had the same luminance and size (0.85 degree diameter).</p><p id="P44">Each participant took part in two recording runs of one of two task versions which differed in the details of the choice-response cue as well as the confidence report. Participants 1-20 performed version A: here, the choice-response cue consisted of a centrally presented red or green square (yes=right hand: green; yes=left hand: red), whereas the irrelevant cue was a blue square. The outer button always indicated a confident, the inner one an unconfident choice. In this version, the fixation baseline at the beginning of each trial lasted 1500 ms. Each recording run consisted of 400 randomly ordered trials, of which 120 were pre-cue trials, 120 post-cue trials, and 160 belonged to one of two control conditions not reported here. Participants 21-33 performed version B: here, the choice-response cue consisted of two vertical rectangles (yes=right hand: left rectangle mint, right rectangle pink; yes=left hand: left rectangle pink, right rectangle mint) forming a square, whereas the irrelevant cue consisted of two horizontal rectangles (upper: pink, lower: mint). The confidence mapping (inner or outer button for confident / unconfident responses) was changed in each recording run. Here, the fixation baseline was 1000 ms. Each run consisted of 400 randomly ordered trials, 200 of which were pre-cue and 200 post-cue trials. The changes in version B were designed to minimize sensory- and motor confounds in a separate analysis of task- and confidence-related effects (not reported here). The data from version A was previously used in another publication (<xref ref-type="bibr" rid="R47">Pape and Siegel, 2016</xref>).</p><p id="P45">To ensure that participants were performing both task conditions well, we computed overall accuracy as the percentage of correct trials. We used a two-tailed paired t-test to test whether accuracy was different between task conditions. To make sure participants did not systematically associate one of the motor responses with one of the choices, we computed the percentage of “right” button presses for “yes”- and “no” choices separately and compared both against 50% using two-tailed t-tests.</p></sec><sec id="S16"><title>Setup &amp; recording</title><p id="P46">We recorded MEG (Omega 2000, CTF Systems, Inc., Port Coquitlam, Canada) with 275 channels at a sampling rate of 2,343.75 Hz in a magnetically shielded chamber. Participants sat upright in a dark room, while stimuli were projected onto a screen at a viewing distance of 55 cm using an LCD projector (Sanyo PLC-XP41, Moriguchi, Japan) at 60 Hz refresh rate. Stimuli were constructed offline and presented using the Presentation software (NeuroBehavioral Systems, Albany, CA, USA). To ensure continuous fixation, we recorded eye movements using an Eyelink 1000 system (SR Research, Ottawa, Ontario, Canada).</p></sec></sec><sec id="S17"><title>MEG preprocessing and source analysis</title><sec id="S18"><title>Preprocessing</title><p id="P47">We low-pass-filtered MEG and eye-tracking data at 10 Hz (two-pass forward-reverse Butterworth filter, order 4) and down-sampled to 20Hz. Trials containing eye-blinks were rejected. We chose not to apply a high-pass filter in order to avoid filter artefacts (<xref ref-type="bibr" rid="R12">van Driel et al., 2021</xref>). At the same time, we could not use a baseline correction as choice effects could plausibly be driven by previous trials. We thus used robust detrending (<xref ref-type="bibr" rid="R4">de Cheveigné and Arzounian, 2018</xref>) to remove polynomial trends from the MEG data, but not the eye tracking data, in a piecewise fashion (600 s pieces, removal of linear trend followed by 10th order polynomial). Data of three participants was rejected due to metal artifacts.</p></sec><sec id="S19"><title>Source reconstruction</title><p id="P48">For source reconstruction based on each participant’s individual anatomy, we recorded structural T1-weighted MRIs (echo time (TE) = 2.18ms, repetition time (TR) = 2.3 ms, longitudinal relaxation time (T1) = 1.1 ms, flip angle = 9°, 192 slices, voxel size 1×1×1 mm3) with a Siemens 3T Tim Trio scanner and a 32 channel Head Coil. We generated single-shell head models (<xref ref-type="bibr" rid="R41">Nolte, 2003</xref>) and estimated three-dimensional (x, y and z-direction) MEG source activity at 457 equally spaced locations 7 mm beneath the skull, using linear spatial filtering (<xref ref-type="bibr" rid="R60">Van Veen et al., 1997</xref>). We retained, for each source, activity in all three directions and concatenated the data of the two separate recording runs per participant. For all subsequent analyses, we reduced the dimensionality of this 1371-dimensional source space: for all whole-head decoding analyses we performed principal component analysis, retaining the 75 components with the largest variance across all combinations of task variables. For searchlight analyses, we used each of the 457 sources’ immediate neighbors, including all 3 dipole directions.</p></sec></sec><sec id="S20"><title>Multivariate decoding analyses</title><sec id="S21"><title>Task variables and cross-validation scheme</title><p id="P49">The experimental design resulted in a number of variables of which each trial instantiated a combination. For each trial, we defined the task (pre- or post-cue), stimulus (target or noise), response (left or right hand button-press), mapping (target = left or target = right), choice (yes/target or no/noise), accuracy (correct or incorrect) and confidence (high or low). Not all of these variables were independent of each other: for a given stimulus and choice, accuracy is fixed; and for a given choice and mapping, response is fixed. Thus, 5 independent variables giving rise to 32 conditions remained (<xref ref-type="supplementary-material" rid="SD1">Fig. S1A</xref>). While those variables under experimental control (task, stimulus, mapping) were fully balanced, those dependent on the participants’ behavior (choice, response, confidence, accuracy) were not, leading to a non-uniform sampling of conditions (<xref ref-type="supplementary-material" rid="SD1">Fig. S1A</xref>). To ensure an accurate estimation of neural information about each variable, independent of the others, we implemented an n-fold cross-validation scheme, where n was the lowest trial count per condition. Thus, for each cross-validation fold, both training and test data contained trials of all conditions. In order to decrease the dependence of our results on a particular random partition into folds, we repeated each analysis 10 times, with different random seeds. All results were averaged across these random seeds before further processing.</p><p id="P50">Due to the variability in behavioral responses, as well as the rejection of trials containing eyeblink artefacts, we did not retain the same amount of trials from each condition for all participants. However, to accurately estimate neural information we needed to ensure that, first, there were trials of each condition, and second, the total number of trials was large enough in comparison to the dimensionality of the data to enable an unbiased estimate (<xref ref-type="bibr" rid="R1">Allefeld and Haynes, 2014</xref>). Specifically, each analysis requires at least N + K + 1 trials, where N is the number of channels and K is the number of independent variables in the model. For our main analyses (<xref ref-type="fig" rid="F2">Fig. 2</xref>, <xref ref-type="fig" rid="F3">Fig. 3</xref>, <xref ref-type="fig" rid="F4">Fig. 4</xref>, <xref ref-type="supplementary-material" rid="SD1">Fig. S3</xref>, <xref ref-type="supplementary-material" rid="SD1">Fig. S3</xref>), including task, stimulus, choice, response, mapping and accuracy as variables, data from 26 participants had sufficient trials. When additionally including confidence as a variable, but neglecting the task condition (<xref ref-type="fig" rid="F5">Fig. 5</xref>, <xref ref-type="supplementary-material" rid="SD1">Fig. S5</xref>), we retained 19 participants. To assess the effect of confidence separately for both task conditions, we used all variables apart from response, leading again to 19 useable participants. To assess the effect of the previous choice in relation to the current choice (<xref ref-type="supplementary-material" rid="SD1">Fig. S4A</xref>), we neglected the task condition as well as confidence, and included stimulus, choice, response, mapping, accuracy, and previous choice. This left us with data from 23 participants. To assess the effect of the previous motor response in relation to the current choice (<xref ref-type="supplementary-material" rid="SD1">Fig. S4B</xref>), we neglected the task condition as well as confidence, and included stimulus, choice, response, mapping, accuracy, and previous response. This left us with data from 25 participants. For all decoding analyses, we combined source level data from both recording runs per participant. Using source-level data allowed us to reduce between-run variance and reduce non-neural variability. To do so, we normalized the data per channel, time point and run over trials, and then concatenated data of both runs.</p></sec><sec id="S22"><title>Cross-validated MANOVA</title><p id="P51">We used cross-validated MANOVA (<xref ref-type="bibr" rid="R1">Allefeld and Haynes, 2014</xref>; <xref ref-type="bibr" rid="R5">Christophel et al., 2018</xref>) to estimate the amount of information in multivariate MEG data about the task variables of interest. CVMANOVA estimates the variability explained by the task variables in relation to unexplained noise variability. Here, we re-implemented cvMANOVA for time-resolved data, adding the capability of cross-decoding by training and testing the model on different time points, variables, or levels of any variable. To this end, we first estimated a baseline noise covariance matrix, using trials from all unique conditions. We then “trained” the model by estimating contrasts of beta weights of each unique condition in a cross-validation fold’s training set, and “tested” it by estimating contrasts of beta weights in the fold’s test set. An estimate of true pattern distinctness was computed as the dot product of these contrasts, normalized by the noise covariance: <disp-formula id="FD1"><mml:math id="M1"><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:msub><mml:msup><mml:mi>B</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:msup><mml:mi>X</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mi>Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P52">where X<sub>test</sub> is the design matrix indicating the unique condition of each trial in the test set, C<sub>train</sub> is the contrast vector the model is trained on, C<sub>test</sub> the test contrast vector and Σ<sup>-1</sup> the inverted noise covariance matrix. B<sub>train</sub> and B<sub>test</sub> contained the regression parameters of a multivariate general linear model <disp-formula id="FD2"><mml:math id="M2"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p id="P53">where Y<sub>train</sub> and Y<sub>test</sub> are the training and test data sets. The inverted noise covariance matrix Σ<sup>-1</sup> was estimated using data from a baseline timepoint (-0.5s with respect to the onset of the first cue): <disp-formula id="FD3"><mml:math id="M3"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>Ξ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mi>Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mi>E</mml:mi><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>·</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>Ξ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mi>Ξ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p id="P54">with fE being the degrees of freedom and p the number of sources used. Ξ was regularized towards the unity matrix using a regularization parameter of 0.05.</p><p id="P55">Because the design matrix and contrast vector include all unique conditions, i.e. all combinations of variable levels (<xref ref-type="supplementary-material" rid="SD1">Fig. S1</xref>), cvMANOVA independently quantifies information about each variable of interest, while not being confounded by information about the other, potentially correlated variables. In other words, cvMANOVA quantifies the pattern distinctness explained by each variable after discounting the patterns explained by all other variables included in the model.</p><p id="P56">While cvMANOVA technically constitutes an encoding framework – modelling data variability due to experimental variables – it shares many similarities with commonly used multivariate decoding methods (<xref ref-type="bibr" rid="R20">Hebart and Baker, 2018</xref>). Notably, cvMANOVA uses out-of-sample cross-validation to provide a measure of the information contained in neural data about the variables of interest. These estimates can, in principle, also be used to decode experimental variables on individual trials. Due to this close relationship, and to highlight the link to the extensive multivariate decoding literature, we often refer to our results as decoding results.</p></sec><sec id="S23"><title>Cross-decoding</title><p id="P57">To achieve cross-condition decoding, we constructed contrast vectors C<sub>train</sub> and C<sub>test</sub> to only contain the conditions to be trained or tested on, respectively. We applied this to estimate neural information within and across the two task conditions (pre and post), as well as the two confidence levels, and the two choices. Additionally, we also used a model trained on all trials, and tested it separately on correct and incorrect trials. To estimate whether information was shared between timepoints, we computed the pattern distinctness when using regression parameters B<sub>train</sub> from one time point, and B<sub>test</sub> from another. We repeated this for every pair of time points. In order to assess whether two variables shared a common representational space, we used cross-variable decoding. We implemented this by using a training contrast C<sub>train</sub> differentiating between the levels of one variable, and a test contrast C<sub>test</sub> differentiating between the levels of another. Before further processing, all decoding timecourses were smoothed using a Hanning window (500 ms, full width at half maximum). Time-time generalization matrices were smoothed using a 2-dimensional, 100 ms Hanning window.</p></sec><sec id="S24"><title>Geometric visualization of representational similarity</title><p id="P58">We reconstructed low-dimensional geometric representations of neural activity in multiple conditions using the decoding results. Decoding- and cross-decoding values between multiple variables define the distances and angles of condition difference vectors. We used these to plot subsets of conditions in 2D-spaces defined by the axes spanned by two variables of interest. For example, in <xref ref-type="fig" rid="F4">Figure 4G</xref> the length of the choice- and response vectors is given by the magnitude of choice- and response information, respectively; the angle between both is given by the cross-decoding between the two variables. The mapping vector reflects the projection of mapping information onto the 2D-space spanned by choice and response information, indicating that mapping is not represented as an interaction between choice and response.</p></sec><sec id="S25"><title>Searchlight analysis</title><p id="P59">We repeated our main analysis in a searchlight fashion, in order to estimate the spatiotemporal distribution of neural information throughout the trial. For each of the 457 sources, we used cvMANOVA on that source as well as its immediate neighbors, including all 3 dipole directions. In order to maintain comparability between sources, we normalized the resulting pattern distinctness values by the square root of the size of the searchlight (<xref ref-type="bibr" rid="R1">Allefeld and Haynes, 2014</xref>; <xref ref-type="bibr" rid="R5">Christophel et al., 2018</xref>). After averaging over both hemispheres, we split the searchlight decoding results of all 457 sources into four distinct groups (occipital, temporal, central, frontal) and averaged within each of these areas, to show the spatiotemporal dynamics of neural information. To quantify a shift in choice information from sensory to motor areas, we correlated, for each participant, the cortical distribution of choice information during each timepoint with the distribution of stimulus information during stimulus presentation (1.25 s to 3.25 s), and with the distribution of response information during response execution (from 5.5 s). Statistical significance was assessed using one-tailed cluster-permutation tests.</p></sec><sec id="S26"><title>Expected cross-decoding</title><p id="P60">The maximal amount of shared information between two contexts depends on the amount of information available in each individual context. Thus, in order to assess whether two representations are different, the strength of both representations has to be taken into account and compared with the strength of the shared representation. We thus estimated the expected cross-decoding <disp-formula id="FD4"><mml:math id="M4"><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>D</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:msqrt><mml:mo>·</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>·</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula></p><p id="P61">where D<sub>1</sub> and D<sub>2</sub> denote the pattern distinctness in the two contexts. The cross-decoding D<sub>12</sub> between both contexts would be expected to approach E<sub>12</sub> for identical representations. Any cross-decoding values smaller than E<sub>12</sub> indicate that the representations are not fully overlapping.</p></sec><sec id="S27"><title>Single-trial stimulus prediction</title><p id="P62">To test whether neural choice representations were informed by the stimulus, we projected each trial’s neural data onto the multivariate axis spanned by yes- and no choices as defined by the cvMANOVA model. We then computed the sign of these single-trial estimates to assess whether it corresponded to the stimulus class.</p></sec><sec id="S28"><title>Eye movement control</title><p id="P63">While we ensured continuous fixation using an online eye movement control at the beginning of each trial, small eye movements can still plausibly confound MEG signals (<xref ref-type="bibr" rid="R49">Quax et al., 2019</xref>). We thus repeated our main decoding analysis (<xref ref-type="fig" rid="F2">Fig. 2</xref>) using eye-tracking data. For this purpose, we selected the x-position, y-position, and pupil size signals and averaged them over both eyes. Additionally, we computed the eye position eccentricity as sqrt(x<sup>2</sup>+y<sup>2</sup>). We then applied the same decoding analysis using cvMANOVA, using these 4 channels. We split the 26 participants into the 13 with the highest and lowest choice information in their eye signals, respectively. This revealed that in a subset of participants eye signals were predictive of choice. To test whether this could plausibly explain the neural choice information, we compared the choice decoding timecourses in both splits. As neural choice decoding was, if anything, weaker in those participants with higher choice decoding from the eye signals, the neural decoding was unlikely to be explained by eye movements (<xref ref-type="supplementary-material" rid="SD1">Fig. S3</xref>).</p></sec><sec id="S29"><title>Statistical analysis</title><p id="P64">We assessed the statistical significance of information using cluster-based sign permutation tests. After determining temporally contiguous clusters during which pattern distinctness was higher than 0 (one-tailed t-test over participants, P &lt; 0.05), we randomly multiplied the information time-course of each participant 10,000 times with either 1 or −1. In each random permutation, we re-computed information clusters and determined the cluster-mass of the strongest cluster. Each original cluster was assigned a p-value by comparing its size to the distribution of sizes of the random permutation’s strongest clusters. The same procedure was used for cross-decoding analyses, however using two-tailed t-tests as true cross-decoding can also be negative. We also tested differences in information using this strategy, namely between response information during “yes” and “no”-choices (<xref ref-type="fig" rid="F4">Fig. 4E</xref>). To test for differences between high- and low-confidence correct and error trials, we averaged data over appropriate time-periods (1.25 to 5.5 s for choice information) and used one-tailed t-tests, as we had a clear unidirectional hypothesis derived from signal detection theory. To determine whether the multivariate patterns underlying two representations were significantly different, we tested whether the empirical cross-decoding was smaller than the expected cross-decoding, again using cluster-based sign permutation tests. Cross-temporal generalization and dynamics were assessed analogously, however using two-dimensional clusters.</p></sec><sec id="S30"><title>Software</title><p id="P65">All analyses were performed in MATLAB, using custom code as well as the Fieldtrip (<xref ref-type="bibr" rid="R45">Oostenveld et al., 2011</xref>) and SPM toolboxes. For meta-d’ analyses, we used code from <ext-link ext-link-type="uri" xlink:href="http://www.columbia.edu/%257Ebsm2105/type2sdt/">http://www.columbia.edu/~bsm2105/type2sdt/</ext-link> (<xref ref-type="bibr" rid="R34">Maniscalco and Lau, 2012</xref>).</p></sec></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary Material</label><media xlink:href="EMS152748-supplement-Supplementary_Material.pdf" mimetype="application" mime-subtype="pdf" id="d30aAdEbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S31"><title>Acknowledgements</title><p>We thank Katrina Quinn for helpful discussions of the manuscript. This study was supported by the European Research Council (ERC) StG 335880 and CoG 864491 (M.S), Deutsche Forschungsgemeinschaft (DFG; German Research Foundation) project 276693517 (SFB 1233) (M.S.) and the Centre for Integrative Neuroscience (DFG, EXC 307) (M.S.). The authors acknowledge support by the state of Baden-Württemberg through bwHPC and the German Research Foundation (DFG) through grant no INST 39/963-1 FUGG (bwForCluster NEMO).</p></ack><sec id="S32" sec-type="data-availability"><title>Data and materials availability</title><p id="P66">Preprocessed MEG data and analysis code to reproduce all reported results are available upon reasonable request.</p></sec><fn-group><fn fn-type="con" id="FN1"><p id="P67"><bold>Author Contributions:</bold> Conceptualization: M.S., F.S., A.A.P.; investigation: A.A.P.; formal analysis: F.S., N.O.; writing – original draft preparation: F.S.; writing – review and editing: F.S., N.O., A.A.P, M.S.; supervision: M.S.; resources: M.S.; funding acquisition: M.S.</p></fn></fn-group><ref-list><ref id="R1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allefeld</surname><given-names>C</given-names></name><name><surname>Haynes</surname><given-names>J-D</given-names></name></person-group><article-title>Searchlight-based multi-voxel pattern analysis of fMRI by cross-validated MANOVA</article-title><source>NeuroImage</source><year>2014</year><volume>89</volume><fpage>345</fpage><lpage>357</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.11.043</pub-id></element-citation></ref><ref id="R2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bennur</surname><given-names>S</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><article-title>Distinct Representations of a Perceptual Decision and the Associated Oculomotor Plan in the Monkey Lateral Intraparietal Area</article-title><source>Journal of Neuroscience</source><year>2011</year><volume>31</volume><fpage>913</fpage><lpage>921</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4417-10.2011</pub-id></element-citation></ref><ref id="R3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Britten</surname><given-names>KH</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Celebrini</surname><given-names>S</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><article-title>A relationship between behavioral choice and the visual responses of neurons in macaque MT</article-title><source>Visual Neuroscience</source><year>1996</year><volume>13</volume><fpage>87</fpage><lpage>100</lpage><pub-id pub-id-type="doi">10.1017/S095252380000715X</pub-id></element-citation></ref><ref id="R4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Cheveigné</surname><given-names>A</given-names></name><name><surname>Arzounian</surname><given-names>D</given-names></name></person-group><article-title>Robust detrending, rereferencing, outlier detection, and inpainting for multichannel data</article-title><source>NeuroImage</source><year>2018</year><volume>172</volume><fpage>903</fpage><lpage>912</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.01.035</pub-id></element-citation></ref><ref id="R5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christophel</surname><given-names>TB</given-names></name><name><surname>Iamshchinina</surname><given-names>P</given-names></name><name><surname>Yan</surname><given-names>C</given-names></name><name><surname>Allefeld</surname><given-names>C</given-names></name><name><surname>Haynes</surname><given-names>J-D</given-names></name></person-group><article-title>Cortical specialization for attended versus unattended working memory</article-title><source>Nature Neuroscience</source><year>2018</year><volume>21</volume><fpage>494</fpage><lpage>496</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0094-4</pub-id></element-citation></ref><ref id="R6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cichy</surname><given-names>RM</given-names></name><name><surname>Pantazis</surname><given-names>D</given-names></name><name><surname>Oliva</surname><given-names>A</given-names></name></person-group><article-title>Resolving human object recognition in space and time</article-title><source>Nature Neuroscience</source><year>2014</year><volume>17</volume><fpage>455</fpage><lpage>462</lpage><pub-id pub-id-type="doi">10.1038/nn.3635</pub-id></element-citation></ref><ref id="R7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cisek</surname><given-names>P</given-names></name></person-group><article-title>Making decisions through a distributed consensus</article-title><source>Current Opinion in Neurobiology</source><year>2012</year><volume>22</volume><fpage>927</fpage><lpage>936</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2012.05.007</pub-id></element-citation></ref><ref id="R8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cisek</surname><given-names>P</given-names></name><name><surname>Kalaska</surname><given-names>JF</given-names></name></person-group><article-title>Neural Correlates of Reaching Decisions in Dorsal Premotor Cortex: Specification of Multiple Direction Choices and Final Selection of Action</article-title><source>Neuron</source><year>2005</year><volume>45</volume><fpage>801</fpage><lpage>814</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.01.027</pub-id></element-citation></ref><ref id="R9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cisek</surname><given-names>P</given-names></name><name><surname>Kalaska</surname><given-names>JF</given-names></name></person-group><article-title>Neural Mechanisms for Interacting with a World Full of Action Choices</article-title><source>Annual Review of Neuroscience</source><year>2010</year><volume>33</volume><fpage>269</fpage><lpage>298</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.051508.135409</pub-id></element-citation></ref><ref id="R10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coallier</surname><given-names>É</given-names></name><name><surname>Kalaska</surname><given-names>JF</given-names></name></person-group><article-title>Reach target selection in humans using ambiguous decision cues containing variable amounts of conflicting sensory evidence supporting each target choice</article-title><source>Journal of Neurophysiology</source><year>2014</year><volume>112</volume><fpage>2916</fpage><lpage>2938</lpage><pub-id pub-id-type="doi">10.1152/jn.00145.2014</pub-id></element-citation></ref><ref id="R11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Donner</surname><given-names>TH</given-names></name><name><surname>Siegel</surname><given-names>M</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name><name><surname>Engel</surname><given-names>AK</given-names></name></person-group><article-title>Buildup of Choice-Predictive Activity in Human Motor Cortex during Perceptual Decision Making</article-title><source>Current Biology</source><year>2009</year><volume>19</volume><fpage>1581</fpage><lpage>1585</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2009.07.066</pub-id></element-citation></ref><ref id="R12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Driel</surname><given-names>J</given-names></name><name><surname>Olivers</surname><given-names>CNL</given-names></name><name><surname>Fahrenfort</surname><given-names>JJ</given-names></name></person-group><article-title>High-pass filtering artifacts in multivariate classification of neural time series data</article-title><source>Journal of Neuroscience Methods</source><year>2021</year><volume>352</volume><elocation-id>109080</elocation-id><pub-id pub-id-type="doi">10.1016/j.jneumeth.2021.109080</pub-id></element-citation></ref><ref id="R13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freedman</surname><given-names>DJ</given-names></name><name><surname>Assad</surname><given-names>JA</given-names></name></person-group><article-title>A proposed common neural mechanism for categorization and perceptual decisions</article-title><source>Nature Neuroscience</source><year>2011</year><volume>14</volume><fpage>143</fpage><lpage>146</lpage><pub-id pub-id-type="doi">10.1038/nn.2740</pub-id></element-citation></ref><ref id="R14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Gee</surname><given-names>JW</given-names></name><name><surname>Knapen</surname><given-names>T</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><article-title>Decision-related pupil dilation reflects upcoming choice and individual bias</article-title><source>Proc Natl Acad Sci USA</source><year>2014</year><volume>111</volume><pub-id pub-id-type="doi">10.1073/pnas.1317557111</pub-id></element-citation></ref><ref id="R15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><article-title>Representation of a perceptual decision in developing oculomotor commands</article-title><source>Nature</source><year>2000</year><volume>404</volume><fpage>390</fpage><lpage>394</lpage><pub-id pub-id-type="doi">10.1038/35006062</pub-id></element-citation></ref><ref id="R16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><article-title>The Influence of Behavioral Context on the Representation of a Perceptual Decision in Developing Oculomotor Commands</article-title><source>The Journal of Neuroscience</source><year>2003</year><volume>23</volume><fpage>632</fpage><lpage>651</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.23-02-00632.2003</pub-id></element-citation></ref><ref id="R17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><article-title>The Neural Basis of Decision Making</article-title><source>Annual Review of Neuroscience</source><year>2007</year><volume>30</volume><fpage>535</fpage><lpage>574</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.29.051605.113038</pub-id></element-citation></ref><ref id="R18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grimaldi</surname><given-names>P</given-names></name><name><surname>Lau</surname><given-names>H</given-names></name><name><surname>Basso</surname><given-names>MA</given-names></name></person-group><article-title>There are things that we know that we know, and there are things that we do not know we do not know: Confidence in decision-making</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><year>2015</year><volume>55</volume><fpage>88</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2015.04.006</pub-id></element-citation></ref><ref id="R19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haefner</surname><given-names>RM</given-names></name><name><surname>Berkes</surname><given-names>P</given-names></name><name><surname>Fiser</surname><given-names>J</given-names></name></person-group><article-title>Perceptual Decision-Making as Probabilistic Inference by Neural Sampling</article-title><source>Neuron</source><year>2016</year><volume>90</volume><fpage>649</fpage><lpage>660</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.03.020</pub-id></element-citation></ref><ref id="R20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hebart</surname><given-names>MN</given-names></name><name><surname>Baker</surname><given-names>CI</given-names></name></person-group><article-title>Deconstructing multivariate decoding for the study of brain function</article-title><source>NeuroImage</source><year>2018</year><volume>180</volume><fpage>4</fpage><lpage>18</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.08.005</pub-id></element-citation></ref><ref id="R21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hebart</surname><given-names>MN</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name><name><surname>Haynes</surname><given-names>J-D</given-names></name></person-group><article-title>Human visual and parietal cortex encode visual choices independent of motor plans</article-title><source>NeuroImage</source><year>2012</year><volume>63</volume><fpage>1393</fpage><lpage>1403</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.08.027</pub-id></element-citation></ref><ref id="R22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hebart</surname><given-names>MN</given-names></name><name><surname>Schriever</surname><given-names>Y</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name><name><surname>Haynes</surname><given-names>J-D</given-names></name></person-group><article-title>The Relationship between Perceptual Decision Variables and Confidence in the Human Brain</article-title><source>Cerebral Cortex</source><year>2016</year><volume>26</volume><fpage>118</fpage><lpage>130</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu181</pub-id></element-citation></ref><ref id="R23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herding</surname><given-names>J</given-names></name><name><surname>Ludwig</surname><given-names>S</given-names></name><name><surname>Blankenburg</surname><given-names>F</given-names></name></person-group><article-title>Response-Modality-Specific Encoding of Human Choices in Upper Beta Band Oscillations during Vibrotactile Comparisons</article-title><source>Frontiers in Human Neuroscience</source><year>2017</year><volume>11</volume><pub-id pub-id-type="doi">10.3389/fnhum.2017.00118</pub-id></element-citation></ref><ref id="R24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horwitz</surname><given-names>GD</given-names></name><name><surname>Batista</surname><given-names>AP</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><article-title>Representation of an Abstract Perceptual Decision in Macaque Superior Colliculus</article-title><source>Journal of Neurophysiology</source><year>2004</year><volume>91</volume><issue>2281</issue><lpage>2296</lpage><pub-id pub-id-type="doi">10.1152/jn.00872.2003</pub-id></element-citation></ref><ref id="R25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiani</surname><given-names>R</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><article-title>Representation of Confidence Associated with a Decision by Neurons in the Parietal Cortex</article-title><source>Science</source><year>2009</year><volume>324</volume><fpage>759</fpage><lpage>764</lpage><pub-id pub-id-type="doi">10.1126/science.1169405</pub-id></element-citation></ref><ref id="R26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiani</surname><given-names>R</given-names></name><name><surname>Corthell</surname><given-names>L</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><article-title>Choice Certainty Is Informed by Both Evidence and Decision Time</article-title><source>Neuron</source><year>2014</year><volume>84</volume><fpage>1329</fpage><lpage>1342</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.12.015</pub-id></element-citation></ref><ref id="R27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>King</surname><given-names>J-R</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><article-title>Characterizing the dynamics of mental representations: the temporal generalization method</article-title><source>Trends in Cognitive Sciences</source><year>2014</year><volume>18</volume><fpage>203</fpage><lpage>210</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2014.01.002</pub-id></element-citation></ref><ref id="R28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klaes</surname><given-names>C</given-names></name><name><surname>Westendorff</surname><given-names>S</given-names></name><name><surname>Chakrabarti</surname><given-names>S</given-names></name><name><surname>Gail</surname><given-names>A</given-names></name></person-group><article-title>Choosing Goals, Not Rules: Deciding among Rule-Based Action Plans</article-title><source>Neuron</source><year>2011</year><volume>70</volume><fpage>536</fpage><lpage>548</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.02.053</pub-id></element-citation></ref><ref id="R29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name><name><surname>Mur</surname><given-names>M</given-names></name><name><surname>Ruff</surname><given-names>DA</given-names></name><name><surname>Kiani</surname><given-names>R</given-names></name><name><surname>Bodurka</surname><given-names>J</given-names></name><name><surname>Esteky</surname><given-names>H</given-names></name><name><surname>Tanaka</surname><given-names>K</given-names></name><name><surname>Bandettini</surname><given-names>PA</given-names></name></person-group><article-title>Matching Categorical Object Representations in Inferior Temporal Cortex of Man and Monkey</article-title><source>Neuron</source><year>2008</year><volume>60</volume><fpage>1126</fpage><lpage>1141</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.10.043</pub-id></element-citation></ref><ref id="R30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li Hegner</surname><given-names>Y</given-names></name><name><surname>Lindner</surname><given-names>A</given-names></name><name><surname>Braun</surname><given-names>C</given-names></name></person-group><article-title>A somatosensory-to-motor cascade of cortical areas engaged in perceptual decision making during tactile pattern discrimination: Cortical Cascade During Tactile Decisions</article-title><source>Human Brain Mapping</source><year>2017</year><volume>38</volume><fpage>1172</fpage><lpage>1181</lpage><pub-id pub-id-type="doi">10.1002/hbm.23446</pub-id></element-citation></ref><ref id="R31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ludwig</surname><given-names>S</given-names></name><name><surname>Herding</surname><given-names>J</given-names></name><name><surname>Blankenburg</surname><given-names>F</given-names></name></person-group><article-title>Oscillatory EEG signatures of postponed somatosensory decisions</article-title><source>Human Brain Mapping</source><year>2018</year><volume>39</volume><fpage>3611</fpage><lpage>3624</lpage><pub-id pub-id-type="doi">10.1002/hbm.24198</pub-id></element-citation></ref><ref id="R32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lueckmann</surname><given-names>J-M</given-names></name><name><surname>Macke</surname><given-names>JH</given-names></name><name><surname>Nienborg</surname><given-names>H</given-names></name></person-group><article-title>Can Serial Dependencies in Choices and Neural Activity Explain Choice Probabilities?</article-title><source>The Journal of Neuroscience</source><year>2018</year><volume>38</volume><fpage>3495</fpage><lpage>3506</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2225-17.2018</pub-id></element-citation></ref><ref id="R33"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Macmillan</surname><given-names>NA</given-names></name><name><surname>Creelman</surname><given-names>CD</given-names></name></person-group><source>Detection Theory: A User’s Guide</source><publisher-name>Psychology Press</publisher-name><year>2004</year></element-citation></ref><ref id="R34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maniscalco</surname><given-names>B</given-names></name><name><surname>Lau</surname><given-names>H</given-names></name></person-group><article-title>A signal detection theoretic approach for estimating metacognitive sensitivity from confidence ratings</article-title><source>Consciousness and Cognition</source><year>2012</year><volume>21</volume><fpage>422</fpage><lpage>430</lpage><pub-id pub-id-type="doi">10.1016/j.concog.2011.09.021</pub-id></element-citation></ref><ref id="R35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maniscalco</surname><given-names>B</given-names></name><name><surname>Odegaard</surname><given-names>B</given-names></name><name><surname>Grimaldi</surname><given-names>P</given-names></name><name><surname>Cho</surname><given-names>SH</given-names></name><name><surname>Basso</surname><given-names>MA</given-names></name><name><surname>Lau</surname><given-names>H</given-names></name><name><surname>Peters</surname><given-names>MAK</given-names></name></person-group><article-title>Tuned inhibition in perceptual decision-making circuits can explain seemingly suboptimal confidence behavior</article-title><source>PLoS Comput Biol</source><year>2021</year><volume>17</volume><elocation-id>e1008779</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008779</pub-id></element-citation></ref><ref id="R36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merten</surname><given-names>K</given-names></name><name><surname>Nieder</surname><given-names>A</given-names></name></person-group><article-title>Active encoding of decisions about stimulus absence in primate prefrontal cortex neurons</article-title><source>Proceedings of the National Academy of Sciences</source><year>2012</year><volume>109</volume><fpage>6289</fpage><lpage>6294</lpage><pub-id pub-id-type="doi">10.1073/pnas.1121084109</pub-id></element-citation></ref><ref id="R37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merten</surname><given-names>K</given-names></name><name><surname>Nieder</surname><given-names>A</given-names></name></person-group><article-title>Comparison of abstract decision encoding in the monkey prefrontal cortex, the presupplementary, and cingulate motor areas</article-title><source>Journal of Neurophysiology</source><year>2013</year><volume>110</volume><fpage>19</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1152/jn.00686.2012</pub-id></element-citation></ref><ref id="R38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Minxha</surname><given-names>J</given-names></name><name><surname>Adolphs</surname><given-names>R</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name><name><surname>Mamelak</surname><given-names>AN</given-names></name><name><surname>Rutishauser</surname><given-names>U</given-names></name></person-group><article-title>Flexible recruitment of memory-based choice representations by the human medial frontal cortex</article-title><source>Science</source><year>2020</year><volume>368</volume><elocation-id>eaba3313</elocation-id><pub-id pub-id-type="doi">10.1126/science.aba3313</pub-id></element-citation></ref><ref id="R39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nieder</surname><given-names>A</given-names></name><name><surname>Wagener</surname><given-names>L</given-names></name><name><surname>Rinnert</surname><given-names>P</given-names></name></person-group><article-title>A neural correlate of sensory consciousness in a corvid bird</article-title><source>Science</source><year>2020</year><volume>369</volume><fpage>1626</fpage><lpage>1629</lpage></element-citation></ref><ref id="R40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nienborg</surname><given-names>H</given-names></name><name><surname>Cumming</surname><given-names>BG</given-names></name></person-group><article-title>Decision-related activity in sensory neurons reflects more than a neuron’s causal effect</article-title><source>Nature</source><year>2009</year><volume>459</volume><fpage>89</fpage><lpage>92</lpage><pub-id pub-id-type="doi">10.1038/nature07821</pub-id></element-citation></ref><ref id="R41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nolte</surname><given-names>G</given-names></name></person-group><article-title>The magnetic lead field theorem in the quasi-static approximation and its use for magnetoencephalography forward calculation in realistic volume conductors</article-title><source>Physics in Medicine and Biology</source><year>2003</year><volume>48</volume><fpage>3637</fpage><lpage>3652</lpage><pub-id pub-id-type="doi">10.1088/0031-9155/48/22/002</pub-id></element-citation></ref><ref id="R42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Connell</surname><given-names>RG</given-names></name><name><surname>Dockree</surname><given-names>PM</given-names></name><name><surname>Kelly</surname><given-names>SP</given-names></name></person-group><article-title>A supramodal accumulation-to-bound signal that determines perceptual decisions in humans</article-title><source>Nature Neuroscience</source><year>2012</year><volume>15</volume><fpage>1729</fpage><lpage>1735</lpage><pub-id pub-id-type="doi">10.1038/nn.3248</pub-id></element-citation></ref><ref id="R43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Odegaard</surname><given-names>B</given-names></name><name><surname>Grimaldi</surname><given-names>P</given-names></name><name><surname>Cho</surname><given-names>SH</given-names></name><name><surname>Peters</surname><given-names>MAK</given-names></name><name><surname>Lau</surname><given-names>H</given-names></name><name><surname>Basso</surname><given-names>MA</given-names></name></person-group><article-title>Superior colliculus neuronal ensemble activity signals optimal rather than subjective confidence</article-title><source>Proc Natl Acad Sci USA</source><year>2018</year><volume>115</volume><fpage>E1588</fpage><lpage>E1597</lpage><pub-id pub-id-type="doi">10.1073/pnas.1711628115</pub-id></element-citation></ref><ref id="R44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Okazawa</surname><given-names>G</given-names></name><name><surname>Hatch</surname><given-names>CE</given-names></name><name><surname>Mancoo</surname><given-names>A</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name><name><surname>Kiani</surname><given-names>R</given-names></name></person-group><article-title>Representational geometry of perceptual decisions in the monkey parietal cortex</article-title><source>Cell</source><year>2021</year><volume>184</volume><fpage>3748</fpage><lpage>3761</lpage><elocation-id>e18</elocation-id><pub-id pub-id-type="doi">10.1016/j.cell.2021.05.022</pub-id></element-citation></ref><ref id="R45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oostenveld</surname><given-names>R</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name><name><surname>Maris</surname><given-names>E</given-names></name><name><surname>Schoffelen</surname><given-names>J-M</given-names></name></person-group><article-title>FieldTrip: Open Source Software for Advanced Analysis of MEG, EEG, and Invasive Electrophysiological Data</article-title><source>Computational Intelligence and Neuroscience</source><year>2011</year><volume>2011</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1155/2011/156869</pub-id></element-citation></ref><ref id="R46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Padoa-Schioppa</surname><given-names>C</given-names></name></person-group><article-title>Neurobiology of Economic Choice: A Good-Based Model</article-title><source>Annual Review of Neuroscience</source><year>2011</year><volume>34</volume><fpage>333</fpage><lpage>359</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-061010-113648</pub-id></element-citation></ref><ref id="R47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pape</surname><given-names>A-A</given-names></name><name><surname>Siegel</surname><given-names>M</given-names></name></person-group><article-title>Motor cortex activity predicts response alternation during sensorimotor decisions</article-title><source>Nature Communications</source><year>2016</year><volume>7</volume><pub-id pub-id-type="doi">10.1038/ncomms13098</pub-id></element-citation></ref><ref id="R48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pape</surname><given-names>A-A</given-names></name><name><surname>Noury</surname><given-names>N</given-names></name><name><surname>Siegel</surname><given-names>M</given-names></name></person-group><article-title>Motor actions influence subsequent sensorimotor decisions</article-title><source>Scientific Reports</source><year>2017</year><volume>7</volume><pub-id pub-id-type="doi">10.1038/s41598-017-16299-0</pub-id></element-citation></ref><ref id="R49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quax</surname><given-names>SC</given-names></name><name><surname>Dijkstra</surname><given-names>N</given-names></name><name><surname>van Staveren</surname><given-names>MJ</given-names></name><name><surname>Bosch</surname><given-names>SE</given-names></name><name><surname>van Gerven</surname><given-names>MAJ</given-names></name></person-group><article-title>Eye movements explain decodability during perception and cued attention in MEG</article-title><source>NeuroImage</source><year>2019</year><volume>195</volume><fpage>444</fpage><lpage>453</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.03.069</pub-id></element-citation></ref><ref id="R50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quinn</surname><given-names>KR</given-names></name><name><surname>Seillier</surname><given-names>L</given-names></name><name><surname>Butts</surname><given-names>DA</given-names></name><name><surname>Nienborg</surname><given-names>H</given-names></name></person-group><article-title>Decision-related feedback in visual cortex lacks spatial selectivity</article-title><source>Nat Commun</source><year>2021</year><volume>12</volume><fpage>4473</fpage><pub-id pub-id-type="doi">10.1038/s41467-021-24629-0</pub-id></element-citation></ref><ref id="R51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sandhaeger</surname><given-names>F</given-names></name><name><surname>von Nicolai</surname><given-names>C</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Siegel</surname><given-names>M</given-names></name></person-group><article-title>Monkey EEG links neuronal color and motion information across species and scales</article-title><source>ELife</source><year>2019</year><volume>8</volume><elocation-id>e45645</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.45645</pub-id></element-citation></ref><ref id="R52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Kiani</surname><given-names>R</given-names></name></person-group><article-title>Decision Making as a Window on Cognition</article-title><source>Neuron</source><year>2013</year><volume>80</volume><fpage>791</fpage><lpage>806</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.10.047</pub-id></element-citation></ref><ref id="R53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><article-title>Neural Basis of a Perceptual Decision in the Parietal Cortex (Area LIP) of the Rhesus Monkey</article-title><source>Journal of Neurophysiology</source><year>2001</year><volume>86</volume><fpage>1916</fpage><lpage>1936</lpage><pub-id pub-id-type="doi">10.1152/jn.2001.86.4.1916</pub-id></element-citation></ref><ref id="R54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Siegel</surname><given-names>M</given-names></name><name><surname>Buschman</surname><given-names>TJ</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name></person-group><article-title>Cortical information flow during flexible sensorimotor decisions</article-title><source>Science</source><year>2015</year><volume>348</volume><fpage>1352</fpage><lpage>1355</lpage><pub-id pub-id-type="doi">10.1126/science.aab0551</pub-id></element-citation></ref><ref id="R55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spaak</surname><given-names>E</given-names></name><name><surname>Watanabe</surname><given-names>K</given-names></name><name><surname>Funahashi</surname><given-names>S</given-names></name><name><surname>Stokes</surname><given-names>MG</given-names></name></person-group><article-title>Stable and Dynamic Coding for Working Memory in Primate Prefrontal Cortex</article-title><source>The Journal of Neuroscience</source><year>2017</year><volume>37</volume><fpage>6503</fpage><lpage>6516</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3364-16.2017</pub-id></element-citation></ref><ref id="R56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Summerfield</surname><given-names>C</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><article-title>Expectation in perceptual decision making: neural and computational mechanisms</article-title><source>Nature Reviews Neuroscience</source><year>2014</year><volume>15</volume><fpage>745</fpage><lpage>756</lpage><pub-id pub-id-type="doi">10.1038/nrn3838</pub-id></element-citation></ref><ref id="R57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsetsos</surname><given-names>K</given-names></name><name><surname>Pfeffer</surname><given-names>T</given-names></name><name><surname>Jentgens</surname><given-names>P</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><article-title>Action Planning and the Timescale of Evidence Accumulation</article-title><source>PLOS ONE</source><year>2015</year><volume>10</volume><elocation-id>e0129473</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0129473</pub-id></element-citation></ref><ref id="R58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Twomey</surname><given-names>DM</given-names></name><name><surname>Kelly</surname><given-names>SP</given-names></name><name><surname>O’Connell</surname><given-names>RG</given-names></name></person-group><article-title>Abstract and Effector-Selective Decision Signals Exhibit Qualitatively Distinct Dynamics before Delayed Perceptual Reports</article-title><source>Journal of Neuroscience</source><year>2016</year><volume>36</volume><fpage>7346</fpage><lpage>7352</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4162-15.2016</pub-id></element-citation></ref><ref id="R59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Urai</surname><given-names>AE</given-names></name><name><surname>de Gee</surname><given-names>JW</given-names></name><name><surname>Tsetsos</surname><given-names>K</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><article-title>Choice history biases subsequent evidence accumulation</article-title><source>ELife</source><year>2019</year><volume>8</volume><pub-id pub-id-type="doi">10.7554/eLife.46331</pub-id></element-citation></ref><ref id="R60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Veen</surname><given-names>BD</given-names></name><name><surname>van Drongelen</surname><given-names>W</given-names></name><name><surname>Yuchtman</surname><given-names>M</given-names></name><name><surname>Suzuki</surname><given-names>A</given-names></name></person-group><article-title>Localization of brain electrical activity via linearly constrained minimum variance spatial filtering</article-title><source>IEEE Transactions on Biomedical Engineering</source><year>1997</year><volume>44</volume></element-citation></ref><ref id="R61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>M</given-names></name><name><surname>Montanède</surname><given-names>C</given-names></name><name><surname>Chandrasekaran</surname><given-names>C</given-names></name><name><surname>Peixoto</surname><given-names>D</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name><name><surname>Kalaska</surname><given-names>JF</given-names></name></person-group><article-title>Macaque dorsal premotor cortex exhibits decision-related activity only when specific stimulus–response associations are known</article-title><source>Nature Communications</source><year>2019</year><volume>10</volume><pub-id pub-id-type="doi">10.1038/s41467-019-09460-y</pub-id></element-citation></ref><ref id="R62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilming</surname><given-names>N</given-names></name><name><surname>Murphy</surname><given-names>PR</given-names></name><name><surname>Meyniel</surname><given-names>F</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><article-title>Large-scale dynamics of perceptual decision information across human cortex</article-title><source>Nature Communications</source><year>2020</year><volume>11</volume><pub-id pub-id-type="doi">10.1038/s41467-020-18826-6</pub-id></element-citation></ref><ref id="R63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>Y</given-names></name><name><surname>Velenosi</surname><given-names>LA</given-names></name><name><surname>Schröder</surname><given-names>P</given-names></name><name><surname>Ludwig</surname><given-names>S</given-names></name><name><surname>Blankenburg</surname><given-names>F</given-names></name></person-group><article-title>Decoding vibrotactile choice independent of stimulus order and saccade selection during sequential comparisons</article-title><source>Human Brain Mapping</source><year>2019</year><volume>40</volume><fpage>1898</fpage><lpage>1907</lpage><pub-id pub-id-type="doi">10.1002/hbm.24499</pub-id></element-citation></ref><ref id="R64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>Y</given-names></name><name><surname>Velenosi</surname><given-names>LA</given-names></name><name><surname>Blankenburg</surname><given-names>F</given-names></name></person-group><article-title>Response modality-dependent categorical choice representations for vibrotactile comparisons</article-title><source>NeuroImage</source><year>2021</year><volume>226</volume><elocation-id>117592</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117592</pub-id></element-citation></ref><ref id="R65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>Y</given-names></name><name><surname>Yates</surname><given-names>JL</given-names></name><name><surname>Levi</surname><given-names>AJ</given-names></name><name><surname>Huk</surname><given-names>AC</given-names></name><name><surname>Park</surname><given-names>IM</given-names></name></person-group><article-title>Stimulus-choice (mis)alignment in primate area MT</article-title><source>PLOS Computational Biology</source><year>2020</year><volume>16</volume><elocation-id>e1007614</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007614</pub-id></element-citation></ref><ref id="R66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>Y</given-names></name><name><surname>Freedman</surname><given-names>DJ</given-names></name></person-group><article-title>Posterior parietal cortex plays a causal role in perceptual and categorical decisions</article-title><source>Science</source><year>2019</year><volume>6</volume></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Fig 1</label><caption><title>Flexible sensorimotor decision-making task and reaction times.</title><p><bold>(A)</bold> In each trial, participants viewed one of two random dot stimuli either containing coherent downwards motion (“signal” trials) or containing only random motion (“noise” trials), and reported the presence of coherent motion (“yes” or “no”) with a right- or left-hand button press. Mapping between choice and response was instructed by an informative cue either before (pre-condition, cue 1) or after the stimulus (post-condition, cue 2). Additionally, there was an irrelevant cue offering no additional information either after (pre-condition, cue 2) or before (post-condition, cue 1). Participants additionally used the same button press to indicate their decision confidence, using an inner or an outer button. <bold>(B)</bold> Difference between relative reaction times depending on task, choice, stimulus, response and accuracy. For each comparison, all other variables were accounted for, and the difference in reaction times was computed after normalizing by the average of both options. Darker and brighter dots indicate participants performing task versions A and B, respectively. Horizontal and vertical bars indicate mean +/- SEM across participants.</p></caption><graphic xlink:href="EMS152748-f001"/></fig><fig id="F2" position="float"><label>Fig 2</label><caption><title>Neural information about the stimulus, response, mapping and choice.</title><p>Darker lines indicate information during the pre-condition, brighter lines during the post-condition. Gray lines show the cross-decoding (‘X-dec.’) between both conditions, dashed gray lines the cross-decoding expected if representations in both contexts were identical. Horizontal lines denote temporal clusters of significant information (colored lines, P &lt; 0.01, cluster-permutation, one-tailed, N = 26), cross-information (gray, two-tailed) or significantly less cross-information than expected (dashed gray, one-tailed). Coloured lines and shaded regions indicate the mean +/- SEM of information across participants.</p></caption><graphic xlink:href="EMS152748-f002"/></fig><fig id="F3" position="float"><label>Fig 3</label><caption><title>Spatiotemporal dynamics of neural information.</title><p><bold>(A)</bold> Time-resolved stimulus (top), response (middle) and choice (bottom) information in four groups of sources (in descending order of brightness: occipital, temporal, central, frontal). Data from both hemispheres was averaged. The cortical distribution of information during different time intervals is shown underneath the time-courses. <bold>(B)</bold> Correlation of the cortical distribution of choice information with the distribution of peak stimulus information (red) and peak response information (yellow). Horizontal lines denote temporal clusters of significant information (A, <italic>P</italic> &lt; 0.05, cluster-permutation, one-tailed, N = 26) or correlation (B, <italic>P</italic> &lt; 0.05, cluster-permutation, one-tailed, N = 26). Coloured lines and shaded regions indicate the mean +/- SEM of information or correlation across participants.</p></caption><graphic xlink:href="EMS152748-f003"/></fig><fig id="F4" position="float"><label>Fig 4</label><caption><title>Relationship between stimulus, choice, and response representations.</title><p><bold>(A)</bold> Cross-temporal and cross-variable decoding. Colors indicate neural information when trained and tested on any pair of time-points and variables. Pink outlines indicate clusters of shared information between timepoints and variables, i.e. pairs of time-points and/or variables during which cross-information is significantly different from 0 (|X-dec.| &gt; 0, cluster-permutation, <italic>P</italic> &lt; 0.01, N = 26, two-tailed), blue outlines indicate different representations between timepoints and variables, i.e. pairs of time-points and/or variables during which cross-information is significantly smaller than expected for identical representations (|X-dec.| &lt; expected, one-tailed). <bold>(B)</bold> Possible relationships between the representations of two variables. Points indicate average activity patterns for different conditions, distances between points the strength of information. Representations may be orthogonal, collinear, or orthogonal but linked with an interaction. <bold>(C)</bold> and <bold>(D)</bold>, Cross-variable decoding between choice and stimulus, and choice and response, respectively. Colored lines show neural information about each variable, gray lines cross-variable information (X-dec.), and dashed gray lines the expected cross-information if both variables were represented identically. Horizontal lines indicate clusters of significant information (colored, <italic>P</italic> &lt; 0.01, one-tailed), or significantly less cross-information than expected (dashed gray, <italic>P</italic> &lt; 0.01, one-tailed). <bold>(E)</bold>, Response information for “yes” and “no” choices. Coloured lines and shaded regions in panels C, D and E indicate the mean +/- SEM of information across participants. <bold>(F)</bold>, Visualization of the relationship between stimulus and choice representations, based on the cross-decoding values in (C). Stimulus and choice are nearly orthogonal. <bold>(G)</bold>, Visualization of the relationship between choice and response representations, including mapping as their interaction, based on (D) and (E). Choice and response representations are nearly orthogonal, and response representations are equally strong for both choices. Thus, there is no systematic relation between the neural patterns encoding choice, stimulus and response.</p></caption><graphic xlink:href="EMS152748-f004"/></fig><fig id="F5" position="float"><label>Fig 5</label><caption><title>Choice representations behave like a decision variable.</title><p><bold>(A)</bold>, Prediction of stimulus class from the sign of single trial choice information. Mean +/- SEM across participants <bold>(B)</bold>, Behavioral sensitivity (d’) and meta-cognitive sensitivity (meta-d’). <bold>(C)</bold>, The relationship between decision variable, confidence, and accuracy as predicted by signal detection theory. For each of the two stimuli, the distribution of values of the decision variable is centered on the respective side of the decision boundary at 0. When the absolute distance to the decision boundary is larger, the observer is more confident in their choice. Correct and incorrect, confident and unconfident trials are color-coded as in (D). <bold>(D)</bold>, Time-averaged choice information (1.25 to 4s) in trials split by confidence and accuracy. Stars denote significance (<italic>P</italic> &lt; 0.05, one-tailed t-test, N=19). <bold>(E)</bold>, The relationship between decision variable, accuracy and choice as predicted by signal detection theory. For both yes- and no-choices, the decision variable has a higher absolute magnitude in correct trials. Correct and incorrect, yes and no trials are color-coded as in (F). <bold>(F)</bold>, Time-averaged (1.25 to 4s), normalized placement on the choice axis of trials split by choice and accuracy. Stars denote significance (<italic>P</italic> &lt; 0.05, one-tailed t-test, N=19).</p></caption><graphic xlink:href="EMS152748-f005"/></fig></floats-group></article>