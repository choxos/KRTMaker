<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS156315</article-id><article-id pub-id-type="doi">10.1101/2022.10.24.513513</article-id><article-id pub-id-type="archive">PPR563118</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Reward modulates visual responses in the superficial superior colliculus of mice</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Baruchin</surname><given-names>Liad J.</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Alleman</surname><given-names>Matteo</given-names></name><xref ref-type="aff" rid="A2">2</xref><xref ref-type="fn" rid="FN1">3</xref></contrib><contrib contrib-type="author"><name><surname>Schröder</surname><given-names>Sylvia</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib></contrib-group><aff id="A1"><label>1</label>School of Life Sciences, University of Sussex, Brighton BN1 9QG, UK</aff><aff id="A2"><label>2</label>UCL Institute of Ophthalmology, University College London, London WC1E 6BT, UK</aff><author-notes><corresp id="CR1"><label>*</label>Correspondence: <email>s.schroeder@sussex.ac.uk</email></corresp><fn id="FN1" fn-type="present-address"><label>3</label><p id="P1">Present address: Center for Theoretical Neuroscience, Columbia University, NY, New York 10027, USA</p></fn></author-notes><pub-date pub-type="nihms-submitted"><day>28</day><month>10</month><year>2022</year></pub-date><pub-date pub-type="preprint"><day>25</day><month>10</month><year>2022</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P2">The superficial layers of the superior colliculus (SC) are highly visual and receive direct input from the retina. Nonetheless, neural activity in the superficial SC (sSC) is modulated by locomotion and pupil-linked arousal. Here we show that visual responses of neurons in the sSC are additionally modulated by reward delivered prior to the visual stimulus. We trained mice to perform a visual detection task and recorded the activity of neurons in the SC using two-photon calcium imaging and electrophysiological recordings using high-density silicone probes (Neuropixels). Neurons across all layers of the SC responded to various task events, including reward delivery. However, responses to events like licking or movements did not explain the visual response modulation by reward. Electrophysiological recordings showed that most of the reward modulation occurred in the superficial rather than the deeper layers of the SC. Neurons also exhibited modulation by pupil-linked arousal, which was independent of the reward modulation. Performance of a population decoder to detect visual stimuli improved significantly by reward modulation but not by pupil-linked arousal modulation. Our results indicate that behavioural factors other than locomotion and arousal modulate visual activity in the SC.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P3">The superior colliculus (SC) is a sensory-motor area in the mammalian midbrain, which receives visual input to its superficial layers (sSC) directly from the retina (<xref ref-type="bibr" rid="R4">Cang et al., 2018</xref>). Due to the strong retinal input, the sSC is considered mostly visual while the deeper layers of the SC (dSC) are thought to integrate this visual information to control orienting, attention and decision making (<xref ref-type="bibr" rid="R2">Basso and May, 2017</xref>; <xref ref-type="bibr" rid="R8">Felsen and Mainen, 2012</xref>; <xref ref-type="bibr" rid="R15">Jun et al., 2021</xref>; <xref ref-type="bibr" rid="R31">Wang et al., 2022</xref>, <xref ref-type="bibr" rid="R32">2020</xref>; <xref ref-type="bibr" rid="R34">Zénon and Krauzlis, 2012</xref>). Visual processing in the sSC is modulated by locomotion and pupil-linked arousal (<xref ref-type="bibr" rid="R12">Ito et al., 2017</xref>; <xref ref-type="bibr" rid="R14">Joshi et al., 2016</xref>; <xref ref-type="bibr" rid="R25">Savier et al., 2019</xref>; <xref ref-type="bibr" rid="R26">Schröder et al., 2020</xref>), similar to the modulation by ongoing behaviour in the primary visual cortex (V1) (<xref ref-type="bibr" rid="R29">Vinck et al., 2015</xref>) and other brain areas (<xref ref-type="bibr" rid="R17">Kaplan and Zimmer, 2020</xref>). Here we show that, when mice are engaged in a visual detection task, visual responses in sSC neurons are additionally modulated by reward experienced in the previous trial.</p></sec><sec id="S2" sec-type="results"><title>Results</title><p id="P4">We trained four mice to perform a visual detection task (<xref ref-type="fig" rid="F1">Figure 1A-C</xref>). In each trial, a grating stimulus of varying contrast appeared in the left or right visual field. After an auditory go cue, the mouse had to move the stimulus towards the centre of the visual field by turning a steering wheel, or to hold the wheel still if no stimulus was presented. After correct choices, the mouse was rewarded with a drop of water, while incorrect choices were followed by auditory white noise.</p><p id="P5">Using two-photon imaging, we found that neurons in the sSC responded to several non-visual task events such as wheel movement or licking (<xref ref-type="fig" rid="F1">Figure 1D-G</xref>). We recorded 2,855 neurons across 16 sessions from all four mice. 41% (1,163) of all neurons responded to at least one task event (termed <italic>task responsive neurons</italic>), while 11% (303) responded to more than one task event (<xref ref-type="fig" rid="F1">Figure 1F</xref>). Task responsive sSC neurons exhibited significant responses to contralateral visual stimuli (367, 31%), ipsilateral stimuli (21, 2%), the auditory go cue (153, 13%), wheel movements in either direction (292, 25%), positive feedback/reward (394, 34%), negative feedback (96, 8%), and licking (296, 25%) (<xref ref-type="fig" rid="F1">Figure 1D,E</xref>). Only few neurons that were responsive to reward also responded to wheel movements or licking (<xref ref-type="fig" rid="F1">Figure 1G</xref>), indicating that bodily movements do not explain reward responses. Similarly, largely non-overlapping populations of sSC neurons responded to either wheel movements or licking (<xref ref-type="fig" rid="F1">Figure 1G</xref>), indicating that sSC neurons differentiate between different actions. While these results confirm that sSC neurons are not purely visual, determining which events cause a response is difficult as they often occur near-simultaneously. We focused further analyses on responses to visual stimuli, which occur in relative isolation from other task events.</p><p id="P6">Visual responses of sSC neurons were most strongly affected by previous feedback and pupil-linked arousal (<xref ref-type="fig" rid="F2">Figure 2A-N</xref>). We quantified tuning to visual contrast by fitting a hyperbolic ratio function (see <italic><xref ref-type="sec" rid="S17">Contrast response fitting</xref></italic> in <italic><xref ref-type="sec" rid="S4">Materials and Methods</xref></italic>) to stimulus responses for all neurons with significant responses to contralateral stimuli (<xref ref-type="fig" rid="F2">Figure 2A,B</xref>). If this fit explained the data better than a flat line, the neuron was considered <italic>visually responsive</italic>. For these neurons, we determined the modulation of visual responses by four task variables: pupil-linked arousal (small or large pupil), previous feedback (positive or negative), upcoming action (Go or NoGo), and upcoming outcome (correct or incorrect). Examples of neurons modulated by arousal and previous feedback are shown in <xref ref-type="fig" rid="F2">Figure 2C-F</xref>. Of all visually responsive neurons, 64% (204/319) were modulated by at least one task variable. Pupil-linked arousal affected 19% of neurons causing increases and decreases of visual responses (<xref ref-type="fig" rid="F2">Figure 2G,K</xref>, <xref ref-type="supplementary-material" rid="SD1">S1A</xref>). Previous feedback affected a similar percentage of neurons (20%) with reward mostly increasing visual responses (<xref ref-type="fig" rid="F2">Figure 2H,L</xref>, <xref ref-type="supplementary-material" rid="SD1">S1B</xref>). Only 14% (9/62) of these neurons with reward modulated visual responses also responded directly to positive reward, and none responded to negative reward. Finally, upcoming action (<xref ref-type="fig" rid="F2">Figure 2I,M</xref>, <xref ref-type="supplementary-material" rid="SD1">S1C</xref>) or outcome (<xref ref-type="fig" rid="F2">Figure 2J,N</xref>, <xref ref-type="supplementary-material" rid="SD1">S1D</xref>) modulated only very few neurons.</p><p id="P7">After rewarded trials, decoding the presence of a visual stimulus improved in populations of sSC neurons (<xref ref-type="fig" rid="F2">Figure 2O-R</xref>). We trained a logistic regression decoder on the neuronal population of each session to detect contralateral stimuli based on peri-stimulus activity. The decoder was trained on a subset of trials and then tested on the held-out trials grouped by either pupil size, previous feedback, upcoming outcome, or action. Decoding performance was not influenced by pupil size (<xref ref-type="fig" rid="F2">Figure 2O</xref>), but was improved by previous reward, correct choices, and Go actions (<xref ref-type="fig" rid="F2">Figure 2P-R</xref>). The distributions of stimulus contrasts were similar across values of each task variable (<xref ref-type="supplementary-material" rid="SD1">Figure S2A</xref>). To account for the small differences, we balanced the data when training and testing the decoder so that stimulus contrast would not cause differences in decoding performance. Another confound of this analysis is that task variables may be correlated with each other. Animals were more likely to make a correct choice after a rewarded compared to an unrewarded trial (P(correct | positive feedback) = 0.665 ± 0.011, P(correct | negative feedback) = 0.588 ± 0.024, mean ± SEM, p &lt; 0.01, t-test). Go actions were as likely after rewarded and unrewarded trials (P(Go | positive feedback) = 0.661 ± 0.041, P(Go | negative feedback) = 0.637 ± 0.031, p = 0.65). To control for the lack of independence between previous feedback, action, and outcome, we repeated the decoding analysis and determined the effect of each task variable while fixing another task variable to one value (<xref ref-type="supplementary-material" rid="SD1">Figure S2B</xref>). We found that decoding following reward was consistently better than following negative feedback using this control. In contrast, outcome and action had no effect on decoding performance when only trials following negative feedback were considered. To test whether previous reward had behavioural consequences, we used a logistic regression decoder to predict the outcome of a trial (correct or incorrect) based on stimulus contrast and outcome of the previous three trials. The results show that reward on the previous trial increased the likelihood of correct choice beyond the effect of stimulus contrast (<xref ref-type="supplementary-material" rid="SD1">Figure S2C,D</xref>).</p><p id="P8">Pupil-linked arousal and previous feedback were independent modulators of visual responses (<xref ref-type="fig" rid="F3">Figure 3A-C</xref>). To test whether effects by arousal and reward had a common underlying cause, we compared pupil size during stimulus presentation after positive and negative feedback and found no difference (<xref ref-type="fig" rid="F3">Figure 3A,B</xref>). In support of this conclusion, significant modulations by pupil size and previous feedback were independent of each other (<xref ref-type="fig" rid="F3">Figure 3C</xref>).</p><p id="P9">Modulation by reward and pupil-linked arousal were independent of licking (<xref ref-type="fig" rid="F3">Figure 3D-F,J,K</xref>). We found that reward induced a higher lick rate compared to negative feedback at the time of delivery, and that the lick rate after reward stayed high beyond the beginning of the next trial (<xref ref-type="fig" rid="F3">Figure 3D,E</xref>). However, lick rate stayed constant before and after the onset of the visual stimulus (<xref ref-type="fig" rid="F3">Figure 3F</xref>). Thus, licking was unlikely to induce larger visual responses, which were baseline subtracted. Similarly, lick rates were higher during large pupil trials but did not change around the time of stimulus onset (<xref ref-type="supplementary-material" rid="SD1">Figure S3A</xref>). To control for any effects related to licking, we repeated analyses while removing trials in which the animal licked during the tested time window (<xref ref-type="fig" rid="F3">Figure 3J,K</xref>). This did not change the results regarding the modulation by reward.</p><p id="P10">Lastly, reward modulation was independent of response drift and specific to visual responses immediately following the reward (<xref ref-type="fig" rid="F3">Figure 3G-I,L,M</xref>). Task engagement and motivation can affect both task performance and neural responses across the duration of an experimental session (<xref ref-type="bibr" rid="R13">Jacobs et al., 2020</xref>; <xref ref-type="bibr" rid="R22">Ortiz et al., 2020</xref>), which may explain the observed reward modulation. To quantify slow response fluctuations, we calculated the autocorrelation of stimulus-independent activity (<xref ref-type="fig" rid="F3">Figure 3G</xref>). Hardly any neurons showed consistent response fluctuations exceeding two consecutive trials (<xref ref-type="fig" rid="F3">Figure 3H,I</xref>). As a further test, we included stimulus-independent activity from the previous trial as additional predictor variable when fitting the contrast tuning curve. This did not significantly change the results (<xref ref-type="fig" rid="F3">Figure 3L,M</xref>). Finally, to test the time scale of reward effects, we modelled visual responses using positive and negative feedback delivered two trials prior to the visual stimulus instead of one trial prior. We found that the number of neurons modulated by feedback two trials before was largely reduced compared to feedback in the directly preceding trial (<bold>Figure S3B</bold>). This finding highlights the temporal specificity of reward modulation.</p><p id="P11">Reward and pupil modulation mostly affected neurons in the superficial rather than deep layers of the SC (<xref ref-type="fig" rid="F4">Figure 4</xref>). Using Neuropixels probes, we recorded single neurons across the depth of SC in mice performing the a visual decision task similar to the one previously presented (see <italic><xref ref-type="sec" rid="S4">Materials and Methods</xref></italic>) (6 mice, 15 sessions). The response patterns in the sSC (416 neurons recorded) and dSC (621 neurons recorded) were similar to those obtained using two-photon imaging (<xref ref-type="fig" rid="F4">Figure 4A,B</xref>, <xref ref-type="supplementary-material" rid="SD1">S4A-D</xref>). As before, visual responses tended to be positively modulated by previous reward, while pupil size led to increased and decreased responses (<xref ref-type="fig" rid="F4">Figure 4C,D</xref>, <xref ref-type="supplementary-material" rid="SD1">S4E,F</xref>). Similarly to the two-photon recordings, only 6 neurons (17%) of the reward modulated neurons responded immediately to positive feedback, and none to negative feedback. While the distribution of visually responsive neurons was balanced across depth, the sSC contained 69% of all reward modulated neurons and 53% of all pupil modulated neurons (<xref ref-type="fig" rid="F4">Figure 4E</xref>).</p></sec><sec id="S3" sec-type="discussion"><title>Discussion</title><p id="P12">We found that neurons in the SC responded to various task events and that reward modulated subsequent responses to visual stimuli. This modulation was independent of the modulation by pupil-linked arousal and appeared mostly in the superficial layers of the superior colliculus.</p><p id="P13">The SC has previously been shown to represent reward information (<xref ref-type="bibr" rid="R8">Felsen and Mainen, 2012</xref>; <xref ref-type="bibr" rid="R11">Ikeda and Hikosaka, 2003</xref>; <xref ref-type="bibr" rid="R33">Weldon et al., 2007</xref>), but modulation by reward in those studies was anticipatory as a result of learning, i.e. visual responses were affected before the expected reward was delivered, and was concentrated in the intermediated and deep layers of SC. Here instead we find that visual responses were modulated following reward delivery and that this modulation was exhibited by neurons across all layers of the SC and particular in the superficial layers.</p><p id="P14">We do not yet know the behavioural purpose of the modulation by reward. One possibility is that it serves a role in learning. Anticipatory reward modulation where stimuli associated with reward lead to larger responses has the advantage of increasing the neural decoding performance of behaviourally relevant sensory input. Such modulation has also been observed in other visual areas like V1 (<xref ref-type="bibr" rid="R9">Goltstein et al., 2018</xref>; <xref ref-type="bibr" rid="R10">Henschke et al., 2020</xref>; <xref ref-type="bibr" rid="R16">Jurjut et al., 2017</xref>). The retroactive reward modulation we observed here cannot fulfil the same purpose as it affects the response to a stimulus that in our task paradigm is irrelevant to the previously experienced reward. In a natural environment, however, sensory stimuli following reward may be highly relevant to associate the external circumstances with the reward. Thus, retroactive reward modulation can be beneficial depending on stimulus and reward statistics. A testable hypothesis then is that any reward, regardless of task, should increase visual responses in the SC.</p><p id="P15">The mechanism underlying the observed reward modulation is unclear. Potential candidates are other cortical areas, e.g., the cortical eye fields as shown in monkeys (<xref ref-type="bibr" rid="R6">Coe et al., 2002</xref>; <xref ref-type="bibr" rid="R11">Ikeda and Hikosaka, 2003</xref>; <xref ref-type="bibr" rid="R18">Leon and Shadlen, 1999</xref>). Another possibility is a contribution from serotonin, which encodes reward (<xref ref-type="bibr" rid="R19">Li et al., 2016</xref>) and specifically targets the sSC (<xref ref-type="bibr" rid="R28">Villar et al., 1988</xref>).</p></sec><sec id="S4" sec-type="materials | methods" specific-use="web-only"><title>Materials and Methods</title><p id="P16">All procedures were conducted in accordance with the UK Animals Scientific Procedures Act (1986) under personal and project licenses released by the Home Office following appropriate ethics review.</p><sec id="S5"><title>Animals</title><p id="P17">For two-photon imaging, we used 4 mice (3 male, 1 female) obtained by crossing Gad2-IRES-Cre (<ext-link ext-link-type="uri" xlink:href="https://www.jax.org/strain/010802">www.jax.org/strain/010802</ext-link>) and Ai9 (<ext-link ext-link-type="uri" xlink:href="https://www.jax.org/strain/007909">www.jax.org/strain/007909</ext-link>). The heterozygous offspring expressed TdTomato in glutamate decarboxylase 2-positive (GAD2+) cells. For electrophysiological recordings, we used 3 inbred C57Bl/6J mice (<ext-link ext-link-type="uri" xlink:href="https://www.jax.org/strain/000664">www.jax.org/strain/000664</ext-link>; 2 male, 1 female) and 3 mice (3 male) obtained by crossing PV-Cre (<ext-link ext-link-type="uri" xlink:href="https://www.jax.org/strain/008069">www.jax.org/strain/008069</ext-link>) and Ai32 (RCL-ChR2(H134R)/EYFP, <ext-link ext-link-type="uri" xlink:href="https://www.jax.org/strain/012569">www.jax.org/strain/012569</ext-link>). The heterozygous offspring expressed ChR2 in parvalbumin-positive cells, however, no optogenetic manipulations were performed.</p><p id="P18">Animals were 6-29 weeks old at the time of surgery with a mean weight of 27.4 g (20.0-43.2 g) and were used for experiments up to the age of 77 weeks. Mice were kept on a 12-h light: 12-h dark cycle. Most animals were single housed after the first surgery.</p></sec><sec id="S6"><title>Surgery</title><p id="P19">Animals were anesthetized with isoflurane (Merial) at 3.5% for induction, and 1-2% during surgery. Carprofen (5 mg/kg; Rimadyl, Pfizer) was administered subcutaneously for systemic analgesia, and dexamethasone (0.5 mg/kg; Colvasone, Norbrook) was administered as an anti-inflammatory agent to prevent brain swelling. The scalp was shaved and disinfected, and local analgesia (Lidocaine, 6 mg/kg, Hameln pharmaceuticals ltd) was injected subcutaneously under the scalp prior to the incision. Eyes were covered with eye-protective gel (Chloramphenicol, Martindale Pharmaceuticals Ltd). After the animal was placed into a stereotaxic apparatus (5% Lidocaine ointment, TEVA UK, was applied to ear bars), the skin covering and surrounding the area of interest was removed, and the skull was cleaned of connective tissue. A custom made headplate was positioned above the area of interest and attached to the bone with Superbond C&amp;B (Sun Medical). Throughout all surgical procedures, the animal was kept on a heating pad to stabilize body temperature at 37°C. Subcutaneous injections of 0.01 ml/g/h of Sodium Lactate (Hartmann’s solution) were given. After the surgery, the animal was placed into a heated cage for recovery from anaesthesia. Mice were given three days to recover while being treated with Carprofen.</p><p id="P20">In animals used for two-photon imaging, a circular 4 mm craniotomy (centred at approximately 4.2 mm AP and 0.5 mm ML from Bregma) was made using a biopsy punch (Kai medical) and a fine-tipped diamond drill (Type 250-012 F, Heraeus). To reduce bleeding from the bone and from the dura we used bone wax and gel foam, and we cooled the area by applying cold cortex buffer. As the posterior SC is covered by a large sinus running through the dura, we permanently pushed the sinus anteriorly to gain optical access to the SC. We first made a cut into the dura directly posterior to the transverse sinus spanning the whole width of the craniotomy. Then we inserted a custom-made implant into the cut and pushed it anteriorly and a few 100 microns down to apply some pressure on the brain and thus stabilize the imaging. The implant was made of a short tube (2.29 mm inner diameter, 1 mm length) made of stainless steel (MicroGroup, Medway, Massachusetts). A 3 mm glass coverslip (#1 thickness, World Precision Instruments) was glued onto the tube to seal the end that was inserted into the craniotomy. A stainless-steel washer was glued onto the other end of the tube. The washer had an inner diameter that fit exactly around the tube and an outer diameter of 5 mm (Boker’s, Minneapolis, Minnesota). All three pieces were glued to each other using a UV curing adhesive (NOA61, Thorlabs). The glass coverslip was slightly larger than the outer diameter of the tube so that it could be slipped underneath the dura. The implant was placed into the craniotomy so that the washer was sitting on top of the skull and provided stability for the implant. The implant was fixed to the skull with Vetbond (3M) and Superbond C&amp;B (Sun Medical). To prevent any dirt from staining the glass coverslip, we filled the tube of the implant with Kwik-Cast (World Precision Instruments), which could be easily removed before imaging.</p><p id="P21">For two-photon calcium imaging of activity in SC neurons, we injected the virus AAV2/1.Syn.GCaMP6f.WPRE.SV40 at a final concentration of 2.30-4.39e12 GC/ml after making the cut into the dura. 115-138 nl of the virus were injected 300-500 μm below the brain surface of the SC. The virus was injected at a rate of 2.3 nl every 6 s (Nanoject II, Drummond). The injection pipette was kept in place for about 10 min after the end of the injection.</p><p id="P22">For electrophysiological recordings, craniotomies were centred above the SC, -4.16 mm AP and 1.0 mm ML from Bregma, and performed the day before the first recording session (in one case 3 h before).</p></sec><sec id="S7"><title>Animal training</title><p id="P23">The training procedure has been described in detail previously (<xref ref-type="bibr" rid="R3">Burgess et al., 2017</xref>). After at least four days of recovery after surgery, mice were acclimatized to being handled and head-fixed on the experimental apparatus for at least three days. Before training, they were placed on a water control schedule, in which they received at least 40 ml/kg/day. During training, mice received about 3 μl of water at the end of each correct trial. After the daily training, they received top-up fluids to achieve the minimum daily rate. Body weight and potential signs of dehydration were monitored daily, and mice were given free access to water when they were dehydrated, or their weight fell below threshold. The training started with a simplified version of the task involving only high-contrast stimuli and longer response times. As performance improved, lower contrast stimuli were introduced and response times were reduced.</p></sec><sec id="S8"><title>Experimental apparatus</title><p id="P24">The experimental apparatus was described in detail before (<xref ref-type="bibr" rid="R3">Burgess et al., 2017</xref>). The mouse was head-fixed and surrounded by three computer screens (for two-photon imaging: Iiyama ProLite E1980SD placed ~20 cm from the mouse’s eyes; for electrophysiology: Adafruit, LP097QX1 placed ~11 cm from the mouse’s eyes; 60 Hz refresh rate for both models) at right angles covering approximately 270 × 70 degrees of visual angle. In some experiments, Fresnel lenses (BHPA220-2-6 or BHPA220-2-5, Wuxi Bohai Optics) were mounted in front of the monitors to compensate for reduction in luminance and contrast at steeper viewing angles relative to the monitors. In some of these experiments, lenses were coated with scattering window film (frostbite, The Window Film Company) to prevent specular reflections. A wheel was placed below the mouse’s forepaws and a rotary encoder (Kübler) measured the rotational movements of the wheel. A plastic tube for water delivery was placed in front of the mouse’s snout and calibrated amounts of water were released using a solenoid valve. Licking behavior was monitored by attaching a piezo film (TE Connectivity, CAT-PFS0004) to the plastic tube and recording its voltage. A detailed parts list of the apparatus can be found at <ext-link ext-link-type="uri" xlink:href="http://www.ucl.ac.uk/cortexlab/tools/wheel">http://www.ucl.ac.uk/cortexlab/tools/wheel</ext-link>. To track pupil size, we illuminated one of both eyes with an infrared LED (850 nm, Mightex SLS-0208-A or Mightex SLS-0208-B). Videos of the eye were captured at 30 Hz with a camera (DMK 23U618 or DMK 21BU04.H, The Imaging Source) equipped with a zoom lens (Thorlabs MVL7000) and a filter (long-pass, Thorlabs FEL0750; or band-pass, combining long-pass 092/52x0.75, The Imaging Source, and short-pass FES0900, Thorlabs).</p></sec><sec id="S9"><title>Behavioural tasks</title><p id="P25">The task in the two-photon imaging experiments closely followed the paradigm described earlier (<xref ref-type="bibr" rid="R27">Steinmetz et al., 2019</xref>). To start a trial, the mouse had to keep the wheel still for 0.8-1.4 s (randomly chosen from uniform distribution). At initiation of 60-90% of all trials, a visual stimulus was presented at 95-115 deg either to the left or the right of the vertical meridian. The stimulus was a Gabor patch with vertical orientation (90 deg), sigma of 9 deg, spatial frequency of 0.1 cycles per deg and contrast of 12.5-100% (the range of presented contrasts depended on each animal’s task performance). In the rest of the trials, no stimulus was presented. After 0.5-1.2 s (randomly chosen from uniform distribution), an auditory go cue (8 kHz for 0.2 s) signalled that the position of the stimulus (if present) was now coupled to the wheel movement. The time count between stimulus onset and go cue was reset if the mouse moved the wheel during this period. After the go cue, the mouse had to either move the presented stimulus towards the vertical meridian (to 50-60 deg in the two-photon paradigm, to 30-80 deg in the electrophysiology paradigm), or, if no stimulus was presented, to hold the wheel still (more precisely: not cross the threshold for moving a stimulus to the target position). The mouse had to perform its choice within a fixed interval (“response time”) of 1.5 s after the go cue. After a correct choice, the mouse was given a water reward of 2-2.3 μl as soon as the stimulus reached its target position or at the end of the response time. The visual stimulus (if present) disappeared 1-1.3 s after reward delivery. After an incorrect choice, i.e. moving the stimulus by 50-60 deg towards the periphery, not reaching the target position within the response time, or moving the wheel too far while no stimulus was presented, an auditory white noise stimulus was played for 1 s, after which the visual stimulus (if present) disappeared. The mouse could then start the next trial. Trials of different contrast conditions were randomly interleaved. However, the same condition was repeated when the mouse responded incorrectly.</p><p id="P26">The task in the electrophysiology experiments was very similar to the task just described. The only differences were the following: (1) The mouse had to keep the wheel still for 0.2-0.5 s to start a trial. (2) Two Gabor patches were presented simultaneously, one to the left and one to the right, at 26-80 deg from the vertical meridian. The mouse had to choose the patch with the higher contrast. (3) The width of the Gabor patches (sigma) varied between 8-11 deg and contrasts varied between 25-100%. (4) Any wheel movements between stimulus onset and go cue were simply ignored. (5) The go cue appeared 0.4-0.8 s after stimulus onset. (6) The negative feedback (auditory white noise) was played for 1.5-2 s. (7) The response time was 1.3-1.6 s long.</p></sec><sec id="S10"><title>2p imaging</title><p id="P27">Two-photon imaging was performed using a standard resonant microscope (B-Scope, ThorLabs Inc.) equipped with a 16x, 0.8 NA water immersion objective (N16XLWD-PF, Nikon) and controlled by ScanImage 4.2 (Pologruto et al., 2003). Excitation light at 970-980 nm was delivered by a femtosecond laser (Chameleon Ultra II, Coherent). Multi-plane imaging was performed using a piezo focusing device (P-725.4CA PIFOC, Physik Instrumente, 400 μm range). Laser power was depth-adjusted and synchronized with piezo position using an electro-optical modulator (M350-80LA, Conoptics Inc.). The imaging objective and the piezo device were light-shielded using a custom-made metal cone, a tube, and black cloth to prevent contamination of the fluorescent signal caused by the monitors’ light. Emission light was collected using two separate channels, one for green fluorescence (525/50 nm emission filter) capturing the calcium transients and one for red fluorescence (607/70 nm emission filter) capturing the expression of TdTomato in inhibitory neurons of Gad-Cre × TdTomato mice.</p><p id="P28">For imaging neurons in SC, we used 2-4 imaging planes separated by 30-55 μm at depths of 12-260 μm from the surface of SC. The field of view spanned 410-770 μm in both directions at a resolution of 512 × 512 pixels. The frame rate per plane was 6-10 Hz. For one dataset, a single plane was captured at a frame rate of 30 Hz.</p></sec><sec id="S11"><title>Electrophysiology</title><p id="P29">Recordings were made using Neuropixels 1.0 electrode arrays (Jun et al., 2017). Probes were mounted to a custom 3D-printed piece and affixed to a steel rod held by a micromanipulator (uMP-4, Sensapex Inc.). Prior to insertion, probes were coated with a solution of DiI (ThermoFisher Vybrant V22888 or V22885) or DiO (ThermoFisher Vybrant V22886) by holding 2 μl in a droplet on the end of a micropipette and touching the droplet to the probe shank, letting it dry, and repeating until the droplet was gone. Probes had a soldered connection to short external reference to ground; the ground connection at the headstage was subsequently connected to an Ag/AgCl wire positioned on the skull. The craniotomies and the wire were covered with saline-based agar. The agar was covered with silicone oil to prevent drying. In some experiments a saline bath was used rather than agar. Probes were advanced through the agar and the dura, then lowered to their final position at ~10 μm/sec. Electrodes were allowed to settle for ~10 min before starting recording. Recordings were made in external reference mode with LFP gain = 250 and AP gain = 500. Data were filtered in hardware with a 300 Hz 1-pole high pass filter and digitized at 30 kHz. Recordings were repeated at different locations on each of multiple subsequent days.</p></sec><sec id="S12"><title>Pre-processing of imaging data</title><p id="P30">All raw two-photon imaging movies were analysed using suite2p (implemented in MATLAB, Mathworks) to align frames and detect regions of interest (<xref ref-type="bibr" rid="R24">Pachitariu et al., 2016b</xref>). We used the red channel representing TdTomato expressed in all inhibitory neurons to align frames, which yielded better results than alignment using calcium dependent fluorescence. Every aligned movie was inspected manually to check for failures in automatic alignment. Failures were corrected using different parameter settings where possible. Misaligned movie frames were discarded and ROIs in unstable regions of the field of view were not considered for further analysis.</p><p id="P31">Using the aligned movies and detected ROIs resulting from suite2p analysis, we extracted the fluorescence from the green and the red channel within each ROI. To correct the calcium traces for contamination by surrounding neuropil, we also extracted the fluorescence of the surrounding neuropil for each ROI using the green channel. The neuropil mask resembled a band surrounding the ROI with its inner edge having a distance of 3 microns away from the edge of ROI and its outer edge having a distance of 30 microns from the edge of the ROI. Pixels belonging to other ROIs were excluded. To correct for contamination, the resulting neuropil trace, N, was subtracted from the calcium trace, F, using a correction factor α: F<sub>c</sub>(t) = F(t) - α·N(t). The correction factor was determined for each ROI as follows. First, F and N were low-pass filtered using the 8th percentile in a moving window of 180 s, resulting in F<sub>0</sub> an N<sub>0</sub>. The resulting traces F<sub>f</sub>(t) = F(t)-F<sub>0</sub>(t) and N<sub>f</sub>(t) = N(t)-N<sub>0</sub>(t) were then used to estimate α as described previously (<xref ref-type="bibr" rid="R7">Dipoppa et al., 2018</xref>). In short, N<sub>f</sub> was linearly fitted to F<sub>f</sub> using only time points when values of F<sub>f</sub> were relatively low and thus unlikely to reflect neural spiking. F<sub>c</sub> was then low-pass filtered as above (8th percentile in a moving window of 180 s) to determine F<sub>c,0</sub>. These traces corrected for neuropil contamination were then used to determine ΔF/F = (F<sub>c</sub>(t) - F<sub>c,0</sub>(t)) / max(1, meant(F<sub>c,0</sub>(t)).</p><p id="P32">To correct for potential brain movements, we used the red fluorescence traces of each ROI to regress out changes in fluorescence that were not due to neural activity. First, we low-pass filtered the red trace of each ROI (8th percentile in a moving window of 180 s) and subtracted it from the unfiltered trace to remove slow drifts and bleaching effects. Second, we applied a median filter to the resulting red trace (moving median in window of 10 s). Third, this trace was regressed out of ΔF/F.</p><p id="P33">We avoided sampling the same neurons more than once. We detected ROI pairs that were close to each other in neighbouring imaging planes and that had highly correlated calcium traces (ρ &gt; 0.4, correlation between traces filtered using a moving median in a window of 5 samples). Only the ROI of each pair with the highest signal-to-noise ratio was used for further analyses. ROIs that had very long-lasting calcium transients (&gt; 25 s) were removed.</p></sec><sec id="S13"><title>Spike sorting and firing rates</title><p id="P34">Extracellular voltage traces were pre-processed using common-average referencing: subtracting each channel’s median to remove baseline offsets, then subtracting the median across all channels at each time point to remove artifacts. Electrophysiological data collected in SC was spike sorted using Kilosort2 (available at <ext-link ext-link-type="uri" xlink:href="https://www.github.com/MouseLand/Kilosort2">https://www.github.com/MouseLand/Kilosort2</ext-link>) with standard parameters (<xref ref-type="bibr" rid="R23">Pachitariu et al., 2016a</xref>). After sorting, all automatically-detected spike clusters were curated manually using phy (<ext-link ext-link-type="uri" xlink:href="https://github.com/kwikteam/phy">https://github.com/kwikteam/phy</ext-link>). The spiking data of each neuron was then converted into a firing rate using a 5 ms window.</p></sec><sec id="S14"><title>Depth of electrophysiological recordings</title><p id="P35">We used the LFP recorded on each channel of the Neuropixels probes to determine the surface of the SC (<xref ref-type="bibr" rid="R12">Ito et al., 2017</xref>). We used LFP responses to the following visual noise stimulus: We presented white squares of 8 visual degrees edge length, positioned on a 10 × 36 grid (some stimulus positions were located partially off-screen) on a black background. The presentation of each white square lasted on average 6 monitor frames (100 ms), and their times of appearance were independently randomly selected to yield an average rate of approximately 0.12 Hz. We then determined the stimulus square that elicited the most negative LFP amplitudes based on the average LFP waveform triggered by a change of luminance in each square. At the time of peak negative LFP amplitude measured on the probe channel with the most negative peak, we calculated the LFP amplitude as a function of depth for all probe channels separately. We then determined the depth at half height of the negative peak (located below the depth of the peak) for all right and left channels on the probe. The average result of the right and left probe channels was defined as the surface of the SC. We defined the depth of 400 μm below the SC surface as the border between superficial and deep SC (<xref ref-type="bibr" rid="R12">Ito et al., 2017</xref>).</p></sec><sec id="S15"><title>Pupil Tracking</title><p id="P36">We used DeepLabCut (<xref ref-type="bibr" rid="R20">Mathis et al., 2018</xref>) to detect 8 landmarks in our eye videos: top/bottom/left/right edge of the pupil and top/bottom/left/right edge of the eye lids. The trained network is available from <ext-link ext-link-type="uri" xlink:href="https://github.com/sylviaschroeder/PupilDetection_DLC">https://github.com/sylviaschroeder/PupilDetection_DLC</ext-link>. Pupil diameter was defined as the distance between the top and bottom edges (height) of the pupil. This measure was chosen as it is relatively independent from horizontal eye movements (the most common eye movements mice perform), while the distance between left and right pupil edges (width) changes with eye movements. For time points when the lids covered top or bottom pupil edges (i.e. certainty of top/bottom markers returned by DLC was low or the markers were very close to markers for top/bottom edges of the lid), we used eye position and left and right pupil edges to estimate pupil diameter. Based on samples where the pupil was not covered by the lid, we used local linear regression (Matlab function fit, with method lowess and span = 0.1) to fit pupil height given pupil width and horizontal position of pupil center. Times when the eye was closed, including 5 frames before and after detected closure, were ignored for further analysis. The eye was defined closed when one of the following criteria was true: (1) certainties of left or right pupil marker was low, (2) small distance between top and bottom lid, (3) certainties of top and bottom pupil marker was low, or (4) lid too close to centre of pupil. Values of pupil diameter were median filtered with a span of 5 frames. Pupil size per trial was determined by averaging pupil size in a -0.5–0.5 s window from stimulus onset. A trial was considered a large-pupil trial if the average value was above the median pupil size for the session.</p></sec><sec id="S16"><title>Responsiveness to task events</title><p id="P37">We tested responses to the following events: (1) contralateral visual stimulus in trials without wheel movements within test window (to dissociate visual from movement responses), (2) ipsilateral visual stimulus in trials without wheel movements, (3) auditory go cue in trials without wheel movements (to dissociate auditory from movement responses), (4) ipsilateral and contralateral wheel movements in no-stimulus trials (to dissociate wheel from visual movement responses), (5) positive and negative feedback in no-stimulus trials (to dissociate feedback from visual responses), and (6) licks at least 0.5 s outside the reward delivery time to dissociate licking from reward responses. In the case of lick bursts (licks within less than 0.3 s from each other), only the first lick was taken into consideration. We measured average calcium responses or firing rates in windows of 0–500 ms after event onset (post-event responses) and compared these to average responses in windows of 0–500 ms before event onset (pre-event responses) using paired t-tests. For responses to visual stimuli (contra- or ipsilateral, respectively), we used a two-way ANOVA with pre- and post-event time as one factor and stimulus contrast as second factor. A neuron was considered responsive to a task event if p &lt; 0.05, after Bonferroni multiple test correction.</p></sec><sec id="S17"><title>Contrast response fitting</title><p id="P38">Responses to visual stimuli were determined by averaging neuronal activity across a window of 500 ms after stimulus onset for two-photon recordings and 200 ms after stimulus onset for electrophysiology recordings. The time window was chosen based on the peak latency of the visual response recorded by the two methods. These responses were used to fit a hyperbolic ratio function (<xref ref-type="bibr" rid="R1">Albrecht and Hamilton, 1982</xref>): <disp-formula id="FD1"><mml:math id="M1"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mo>*</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>c</mml:mi><mml:mi>n</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mi>c</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mn>50</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p id="P39">where R is gain, c is stimulus contrast, c<sub>50</sub> is contrast at half-saturation, and n is rate of change. For the electrophysiological data where two Gabor patches were presented simultaneously only the contrast at the contralateral side was taken into account while the ipsilateral contrast was ignored because ipsilateral stimuli did not influence visual responses. The curve was only fit to neurons that exhibited a significant difference in response amplitude after stimulus onset compared to baseline activity before stimulus onset (see <italic><xref ref-type="sec" rid="S16">Responsiveness to task events</xref></italic>). If the fit resulted in an explained variance larger than that of flat line fitted to the responses, the neuron was considered <italic>visually responsive</italic>. 48 neurons in the two-photon recordings and 92 neurons in the Neuropixels recordings had significant responses to contralateral visual stimuli but could not be fit well with the hyperbolic ratio function. Only visually responsive neurons were tested for modulation by task variables. To test for the effect of pupil-linked arousal (small or large pupil), previous feedback (reward or negative feedback), upcoming action (Go or NoGo), and upcoming outcome (correct or incorrect) on response amplitude, we fitted the individual neuronal responses to the same function as above, but modified the gain as follows: <disp-formula id="FD2"><mml:math id="M2"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>g</mml:mi></mml:msub></mml:mrow></mml:math></disp-formula></p><p id="P40">Where the factors represented by <italic>a</italic> are weights and <italic>δ</italic> ∈ {0,1} represented the presence or absence of a specific task variable, e.g., correct outcome, in each trial. To find the best model explaining the visual responses, we fitted variations of this function, leaving out any possible combination of <italic>δs</italic> so that either all or only some of the behavioural conditions would be considered for the modulation of visual responses. The function with the highest cross-validated explained variance determined which task variables had significant impact.</p><p id="P41">The cross-validated explained variance was calculated using a 10-fold cross-validation, whereby the dataset was divided into 10 parts, and the model trained on 9 of those, while the remaining dataset was used to test the fit. To verify the choice of model, we employed a permutation test (see <italic><xref ref-type="sec" rid="S24">Permutation Test</xref></italic>) and only used models that resulted in p-values smaller than 0.05.</p></sec><sec id="S18"><title>Response modulation</title><p id="P42">Response modulation of visually responsive neurons was calculated using the following formula: <disp-formula id="FD3"><mml:math id="M3"><mml:mrow><mml:mi>R</mml:mi><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>A</mml:mi><mml:mo>−</mml:mo><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>0.5</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p id="P43">where <italic>A</italic> was the gain in either large pupil, previously rewarded, Go, or correct trials; and <italic>B</italic> was the gain in either small pupil, previously negative feedback, NoGo, or incorrect trials.</p></sec><sec id="S19"><title>Control for licking</title><p id="P44">We controlled for licking by removing trials where the mouse licked during the response window used to measure the visual response (0–500 ms after stimulus onset). The contrast response fitting was then performed on the rest of the trials as described above.</p></sec><sec id="S20"><title>Response fluctuation analysis</title><p id="P45">Response fluctuations of neural response can occur across long timescales of many seconds to minutes. To measure response fluctuations across a recording session, we accounted for response variation due to the different visual contrasts in the following way. For each neuron, response amplitudes to each visual stimulus were calculated. The time windows were the same as those described in <italic>Contrast response fitting</italic>. For each contrast, single trial responses were z-scored by the contrast specific mean and standard deviation. To measure the time scale of fluctuations, we calculated the auto-correlogram of this fluctuation signal. To test if any point in the auto-correlogram is significantly larger than expected, we generated a null distribution by randomly drawing 500 values from the auto-correlogram. We used the 2.5th to 97.5th percentile interval of the null distribution to determine significant values as consecutive lags (from 0) that were outside the interval.</p></sec><sec id="S21"><title>Control for response fluctuations</title><p id="P46">To control for response fluctuations, i.e., trial-to-trial variability, the tested function was modified to include a signal fluctuation variable, as follows: <disp-formula id="FD4"><mml:math id="M4"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p id="P47">where <italic>d</italic> is the fluctuation signal of the previous trial, calculated as explained in <italic>Response fluctuation analysis</italic>.</p></sec><sec id="S22"><title>Decoding stimulus presence</title><p id="P48">We used responses, averaged across a 0.5 s time window after stimulus onset, of all neurons in the recorded population to decode the presence or absence of a contralateral visual stimulus. We trained a logistic regression model on 50% of the data, and used the other 50% to test the model (<xref ref-type="bibr" rid="R5">Christensen and Pillow, 2022</xref>). The fitted function was: <disp-formula id="FD5"><mml:math id="M5"><mml:mrow><mml:mi>ln</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>X</mml:mi><mml:mi>b</mml:mi></mml:mrow></mml:math></disp-formula></p><p id="P49">where p is the probability that stimulus is present, X is the neuronal response matrix [trial × number of neurons], and b is the coefficient vector [number of neurons × 1].</p><p id="P50">We split the test data into two groups. The split was either according to large/small pupil, previously positive/negative feedback, Go/NoGo, or correct/incorrect. We stratified the data so that both splits were of equal size. We repeated the procedure 10 times and used the mean prediction score of each group for comparison. We scored the prediction using the Matthew Correlation Coefficient (<xref ref-type="bibr" rid="R21">Matthews, 1975</xref>). The score ranges from -1 to 1, where 0 is chance level, 1 is a perfect prediction, and -1 is a perfectly opposite prediction. This measure combines prediction accuracy and recall. To control for possible covariance between the task variables (pupil size, previous feedback, action, and outcome), we repeated the procedure described above while keeping one variable constant (e.g., by only considering trials where pupil size is large).</p></sec><sec id="S23"><title>Predicting trial outcome</title><p id="P51">To predict trial outcome, we used a logistic regression model with 7 independent variables: an intercept, a stimulus of 0% contrast on both sides (<italic>Zero</italic> ∈ {0, 1}), a stimulus with left contrast &gt; 0% (<italic>Left</italic> ∈ {0, 0.125, 0.25, 0.5, 0.75, 1}), a stimulus with right contrast &gt; 0% (<italic>Right</italic> ∈ {0, 0.125, 0.25, 0.5, 0.75, 1}), and correct choice on each of the previous 3 trials (<italic>R<sub>T-1</sub></italic>, <italic>R<sub>T-2</sub></italic>, <italic>R<sub>T-3</sub></italic> ∈ {0, 1}). The model was trained on 80% of the data and tested on the remaining 20%. The formula was: <disp-formula id="FD6"><mml:math id="M6"><mml:mrow><mml:mi>ln</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mi mathvariant="italic">Zero</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mi mathvariant="italic">Left</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mi mathvariant="italic">Right</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>4</mml:mn></mml:msub><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>5</mml:mn></mml:msub><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>6</mml:mn></mml:msub><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p id="P52">where a<sub>0</sub>-a<sub>6</sub> are the coefficients and the variables are as described above.</p><p id="P53">Like for the logistic regression to predict stimulus presence (see previous paragraph), we used the Matthew Correlation Coefficient (<xref ref-type="bibr" rid="R21">Matthews, 1975</xref>) to score the model prediction. To measure the significance of the parameter coefficients, we performed a Wald test (<xref ref-type="bibr" rid="R30">Wald, 1943</xref>) with the null hypothesis of the parameter being equal to 0.</p></sec><sec id="S24"><title>Permutation Test</title><p id="P54">Permutation tests were performed by generating surrogate datasets from the recorded data, computing the test statistic for each surrogate dataset, and comparing the resulting null distribution to the test statistic of the recorded data. Surrogate datasets were generated by randomly permuting the values of the task variables, e.g., small and large pupil size.</p><p id="P55">To determine significance of gain changes in the contrast response function due to task variables (<xref ref-type="fig" rid="F2">Figure 2G-J</xref>, <xref ref-type="fig" rid="F3">Figure 3C,J-M</xref>, <xref ref-type="fig" rid="F4">Figure 4C,D</xref>, <xref ref-type="supplementary-material" rid="SD1">Figure S2B</xref>), we generated 200 surrogate datasets per recorded dataset by permuting the values of the task variable (e.g. small and large pupil). For each neuron, we fitted the hyperbolic ratio function to each of the permuted datasets to generate a null distribution of 200 instances of cross-validated (10-fold) variance explained. We used the same fits to the surrogate datasets to derive the null distribution of response modulations and to determine the 2.5<sup>th</sup> to 97.5<sup>th</sup> percentile interval of null distribution for each possible value of response modulation (<xref ref-type="fig" rid="F2">Figure 2K-N</xref>, <xref ref-type="supplementary-material" rid="SD1">Figure S3E,F</xref>).</p><p id="P56">To determine significance for the performance of the logistic regression model that predicts stimulus presence (<xref ref-type="fig" rid="F2">Figure 2O-R</xref>, <xref ref-type="supplementary-material" rid="SD1">Figure S1C</xref>), we generated 200 surrogate datasets per recorded dataset by permuting the values of the task variable (e.g. previous positive and negative feedback). The test statistic was the difference between prediction scores for the two splits of the test data (according to value of the task variable). In order to determine significance across datasets, the mean across sessions of the actual test statistic was then compared to the distribution of test statistics across the surrogate datasets.</p><p id="P57">To determine significance for the logistic regression model that predicts behavioural outcome (<xref ref-type="supplementary-material" rid="SD1">Figure S2C,D</xref>), we generated 500 surrogate datasets per recorded dataset by permuting the value of the trial outcome, i.e. correct and incorrect choices. Only scores larger than the 95<sup>th</sup> percentile of the surrogate scores were considered significant.</p></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary Figures</label><media xlink:href="EMS156315-supplement-Supplementary_Figures.pdf" mimetype="application" mime-subtype="pdf" id="d42aAdEbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S25"><title>Acknowledgments</title><p>We thank Profs Matteo Carandini (MC) and Kenneth D. Harris (KDH) for supervision and support of this project in their laboratory during data acquisition; we thank Miles Wells, Laura Funnell, Hamish Forrest, and Rakesh Raghupathy for help with training of animals and histology; we thank Charu Reddy for help with mouse husbandry; we thank Chris Burgess for help with setting up the behavioural paradigm and fixing various problems regarding experimental rigs and mouse training; we thank Michael Krumin for help with performing two-photon imaging experiments; we thank Nicholas A. Steinmetz for help with performing electrophysiological experiments; we thank Prof Miguel Maravall and Dr Benjamin Evans for feedback on the manuscript.</p><p>This work was supported by the People Programme (Marie Curie Actions) of the European Union’s Seventh Framework Programme (FP7/2007-2013) under REA Grant Agreement No 62387 (to SS), by the Biotechnology and Biological Sciences Research Council (grant BB/P003273/1 to MC and SS), by Wellcome Trust grants (095669 and 205093 to MC and KDH), and by a Sir Henry Dale Fellowship jointly funded by the Wellcome Trust and the Royal Society (grant 220169/Z/20/Z to SS). For the purpose of open access, the author has applied a CC BY public copyright licence to any Author Accepted Manuscript version arising from this submission.</p></ack><sec id="S26" sec-type="data-availability"><title>Data and code availability</title><p id="P58">The pre-processed data generated in this study are available at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.25377/sussex.c.6208999">https://doi.org/10.25377/sussex.c.6208999</ext-link>; code used to analyse pre-processed data is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/liadJB/Baruchin-et-al-2022">https://github.com/liadJB/Baruchin-et-al-2022</ext-link>. The raw data are available on reasonable request.</p></sec><fn-group><fn id="FN2" fn-type="con"><p id="P59"><bold>Author Contributions</bold></p><p id="P60">Conceptualization: S.S., L.B.; animal training: M.A., S.S.; data collection: S.S., M.A.; data curation: S.S., M.A.; data analysis: L.B.; supervision: S.S.; writing: L.B., S.S.</p></fn></fn-group><ref-list><ref id="R1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Albrecht</surname><given-names>DG</given-names></name><name><surname>Hamilton</surname><given-names>DB</given-names></name></person-group><article-title>Striate cortex of monkey and cat: contrast response function</article-title><source>Journal of Neurophysiology</source><year>1982</year><volume>48</volume><fpage>217</fpage><lpage>237</lpage><pub-id pub-id-type="doi">10.1152/jn.1982.48.1.217</pub-id></element-citation></ref><ref id="R2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Basso</surname><given-names>MA</given-names></name><name><surname>May</surname><given-names>PJ</given-names></name></person-group><article-title>Circuits for Action and Cognition: A View from the Superior Colliculus</article-title><source>Annu Rev Vis Sci</source><year>2017</year><volume>3</volume><fpage>197</fpage><lpage>226</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-102016-061234</pub-id></element-citation></ref><ref id="R3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burgess</surname><given-names>CP</given-names></name><name><surname>Lak</surname><given-names>A</given-names></name><name><surname>Steinmetz</surname><given-names>NA</given-names></name><name><surname>Zatka-Haas</surname><given-names>P</given-names></name><name><surname>Bai Reddy</surname><given-names>C</given-names></name><name><surname>Jacobs</surname><given-names>EAK</given-names></name><name><surname>Linden</surname><given-names>JF</given-names></name><name><surname>Paton</surname><given-names>JJ</given-names></name><name><surname>Ranson</surname><given-names>A</given-names></name><name><surname>Schröder</surname><given-names>S</given-names></name><name><surname>Soares</surname><given-names>S</given-names></name><etal/></person-group><article-title>High-Yield Methods for Accurate Two-Alternative Visual Psychophysics in Head-Fixed Mice</article-title><source>Cell reports</source><year>2017</year><volume>20</volume><fpage>2513</fpage><lpage>2524</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2017.08.047</pub-id></element-citation></ref><ref id="R4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cang</surname><given-names>J</given-names></name><name><surname>Savier</surname><given-names>E</given-names></name><name><surname>Barchini</surname><given-names>J</given-names></name><name><surname>Liu</surname><given-names>X</given-names></name></person-group><article-title>Visual Function, Organization, and Development of the Mouse Superior Colliculus</article-title><source>Annu Rev Vis Sci</source><year>2018</year><volume>4</volume><fpage>239</fpage><lpage>262</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-091517-034142</pub-id></element-citation></ref><ref id="R5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christensen</surname><given-names>AJ</given-names></name><name><surname>Pillow</surname><given-names>JW</given-names></name></person-group><article-title>Reduced neural activity but improved coding in rodent higher-order visual cortex during locomotion</article-title><source>Nat Commun</source><year>2022</year><volume>13</volume><fpage>1676</fpage><pub-id pub-id-type="doi">10.1038/s41467-022-29200-z</pub-id></element-citation></ref><ref id="R6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coe</surname><given-names>B</given-names></name><name><surname>Tomihara</surname><given-names>K</given-names></name><name><surname>Matsuzawa</surname><given-names>M</given-names></name><name><surname>Hikosaka</surname><given-names>O</given-names></name></person-group><article-title>Visual and Anticipatory Bias in Three Cortical Eye Fields of the Monkey during an Adaptive Decision-Making Task</article-title><source>J Neurosci</source><year>2002</year><volume>22</volume><fpage>5081</fpage><lpage>5090</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.22-12-05081.2002</pub-id></element-citation></ref><ref id="R7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dipoppa</surname><given-names>M</given-names></name><name><surname>Ranson</surname><given-names>A</given-names></name><name><surname>Krumin</surname><given-names>M</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><article-title>Vision and Locomotion Shape the Interactions between Neuron Types in Mouse Visual Cortex</article-title><source>Neuron</source><year>2018</year><volume>98</volume><fpage>602</fpage><lpage>615</lpage><elocation-id>e8</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuron.2018.03.037</pub-id></element-citation></ref><ref id="R8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Felsen</surname><given-names>G</given-names></name><name><surname>Mainen</surname><given-names>ZF</given-names></name></person-group><article-title>Midbrain contributions to sensorimotor decision making</article-title><source>Journal of Neurophysiology</source><year>2012</year><volume>108</volume><fpage>135</fpage><lpage>147</lpage><pub-id pub-id-type="doi">10.1152/jn.01181.2011</pub-id></element-citation></ref><ref id="R9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goltstein</surname><given-names>PM</given-names></name><name><surname>Meijer</surname><given-names>GT</given-names></name><name><surname>Pennartz</surname><given-names>CM</given-names></name></person-group><article-title>Conditioning sharpens the spatial representation of rewarded stimuli in mouse primary visual cortex</article-title><source>eLife</source><year>2018</year><volume>7</volume><elocation-id>e37683</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.37683</pub-id></element-citation></ref><ref id="R10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henschke</surname><given-names>JU</given-names></name><name><surname>Dylda</surname><given-names>E</given-names></name><name><surname>Katsanevaki</surname><given-names>D</given-names></name><name><surname>Dupuy</surname><given-names>N</given-names></name><name><surname>Currie</surname><given-names>SP</given-names></name><name><surname>Amvrosiadis</surname><given-names>T</given-names></name><name><surname>Pakan</surname><given-names>JMP</given-names></name><name><surname>Rochefort</surname><given-names>NL</given-names></name></person-group><article-title>Reward Association Enhances Stimulus-Specific Representations in Primary Visual Cortex</article-title><source>Current Biology</source><year>2020</year><volume>30</volume><fpage>1866</fpage><lpage>1880</lpage><elocation-id>e5</elocation-id><pub-id pub-id-type="doi">10.1016/j.cub.2020.03.018</pub-id></element-citation></ref><ref id="R11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ikeda</surname><given-names>T</given-names></name><name><surname>Hikosaka</surname><given-names>O</given-names></name></person-group><article-title>Reward-Dependent Gain and Bias of Visual Responses in Primate Superior Colliculus</article-title><source>Neuron</source><year>2003</year><volume>39</volume><fpage>693</fpage><lpage>700</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(03)00464-1</pub-id></element-citation></ref><ref id="R12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ito</surname><given-names>S</given-names></name><name><surname>Feldheim</surname><given-names>DA</given-names></name><name><surname>Litke</surname><given-names>AM</given-names></name></person-group><article-title>Segregation of Visual Response Properties in the Mouse Superior Colliculus and Their Modulation during Locomotion</article-title><source>J Neurosci</source><year>2017</year><volume>37</volume><fpage>8428</fpage><lpage>8443</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3689-16.2017</pub-id></element-citation></ref><ref id="R13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jacobs</surname><given-names>EAK</given-names></name><name><surname>Steinmetz</surname><given-names>NA</given-names></name><name><surname>Peters</surname><given-names>AJ</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><article-title>Cortical State Fluctuations during Sensory Decision Making</article-title><source>Current Biology</source><year>2020</year><volume>30</volume><fpage>4944</fpage><lpage>4955</lpage><elocation-id>e7</elocation-id><pub-id pub-id-type="doi">10.1016/j.cub.2020.09.067</pub-id></element-citation></ref><ref id="R14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joshi</surname><given-names>S</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Kalwani</surname><given-names>RM</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><article-title>Relationships between Pupil Diameter and Neuronal Activity in the Locus Coeruleus, Colliculi, and Cingulate Cortex</article-title><source>Neuron</source><year>2016</year><volume>89</volume><fpage>221</fpage><lpage>234</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.028</pub-id></element-citation></ref><ref id="R15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jun</surname><given-names>EJ</given-names></name><name><surname>Bautista</surname><given-names>AR</given-names></name><name><surname>Nunez</surname><given-names>MD</given-names></name><name><surname>Allen</surname><given-names>DC</given-names></name><name><surname>Tak</surname><given-names>JH</given-names></name><name><surname>Alvarez</surname><given-names>E</given-names></name><name><surname>Basso</surname><given-names>MA</given-names></name></person-group><article-title>Causal role for the primate superior colliculus in the computation of evidence for perceptual decisions</article-title><source>Nat Neurosci</source><year>2021</year><volume>24</volume><fpage>1121</fpage><lpage>1131</lpage><pub-id pub-id-type="doi">10.1038/s41593-021-00878-6</pub-id></element-citation></ref><ref id="R16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jurjut</surname><given-names>O</given-names></name><name><surname>Georgieva</surname><given-names>P</given-names></name><name><surname>Busse</surname><given-names>L</given-names></name><name><surname>Katzner</surname><given-names>S</given-names></name></person-group><article-title>Learning Enhances Sensory Processing in Mouse V1 before Improving Behavior</article-title><source>J Neurosci</source><year>2017</year><volume>37</volume><fpage>6460</fpage><lpage>6474</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3485-16.2017</pub-id></element-citation></ref><ref id="R17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaplan</surname><given-names>HS</given-names></name><name><surname>Zimmer</surname><given-names>M</given-names></name></person-group><article-title>Brain-wide representations of ongoing behavior: a universal principle?</article-title><source>Current Opinion in Neurobiology</source><year>2020</year><volume>64</volume><fpage>60</fpage><lpage>69</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2020.02.008</pub-id></element-citation></ref><ref id="R18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leon</surname><given-names>MI</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><article-title>Effect of Expected Reward Magnitude on the Response of Neurons in the Dorsolateral Prefrontal Cortex of the Macaque</article-title><source>Neuron</source><year>1999</year><volume>24</volume><fpage>415</fpage><lpage>425</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(00)80854-5</pub-id></element-citation></ref><ref id="R19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Zhong</surname><given-names>W</given-names></name><name><surname>Wang</surname><given-names>D</given-names></name><name><surname>Feng</surname><given-names>Q</given-names></name><name><surname>Liu</surname><given-names>Z</given-names></name><name><surname>Zhou</surname><given-names>J</given-names></name><name><surname>Jia</surname><given-names>C</given-names></name><name><surname>Hu</surname><given-names>F</given-names></name><name><surname>Zeng</surname><given-names>J</given-names></name><name><surname>Guo</surname><given-names>Q</given-names></name><name><surname>Fu</surname><given-names>L</given-names></name><etal/></person-group><article-title>Serotonin neurons in the dorsal raphe nucleus encode reward signals</article-title><source>Nat Commun</source><year>2016</year><volume>7</volume><elocation-id>10503</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms10503</pub-id></element-citation></ref><ref id="R20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathis</surname><given-names>A</given-names></name><name><surname>Mamidanna</surname><given-names>P</given-names></name><name><surname>Cury</surname><given-names>KM</given-names></name><name><surname>Abe</surname><given-names>T</given-names></name><name><surname>Murthy</surname><given-names>VN</given-names></name><name><surname>Mathis</surname><given-names>MW</given-names></name><name><surname>Bethge</surname><given-names>M</given-names></name></person-group><article-title>DeepLabCut: markerless pose estimation of user-defined body parts with deep learning</article-title><source>Nature Neuroscience</source><year>2018</year><volume>21</volume><fpage>1281</fpage><lpage>1289</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0209-y</pub-id></element-citation></ref><ref id="R21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Matthews</surname><given-names>BW</given-names></name></person-group><article-title>Comparison of the predicted and observed secondary structure of T4 phage lysozyme</article-title><source>Biochimica et Biophysica Acta (BBA) - Protein Structure</source><year>1975</year><volume>405</volume><fpage>442</fpage><lpage>451</lpage><pub-id pub-id-type="doi">10.1016/0005-2795(75)90109-9</pub-id></element-citation></ref><ref id="R22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ortiz</surname><given-names>AV</given-names></name><name><surname>Aziz</surname><given-names>D</given-names></name><name><surname>Hestrin</surname><given-names>S</given-names></name></person-group><article-title>Motivation and Engagement during Visually Guided Behavior</article-title><source>Cell Reports</source><year>2020</year><volume>33</volume><elocation-id>108272</elocation-id><pub-id pub-id-type="doi">10.1016/j.celrep.2020.108272</pub-id></element-citation></ref><ref id="R23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Steinmetz</surname><given-names>N</given-names></name><name><surname>Kadir</surname><given-names>S</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Kenneth</surname><given-names>DH</given-names></name></person-group><article-title>Kilosort: realtime spike-sorting for extracellular electrophysiology with hundreds of channels (preprint)</article-title><source>Neuroscience</source><year>2016a</year><pub-id pub-id-type="doi">10.1101/061481</pub-id></element-citation></ref><ref id="R24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Stringer</surname><given-names>C</given-names></name><name><surname>Schröder</surname><given-names>S</given-names></name><name><surname>Dipoppa</surname><given-names>M</given-names></name><name><surname>Rossi</surname><given-names>LF</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><article-title>Suite2p: beyond 10,000 neurons with standard two-photon microscopy</article-title><source>bioRxiv</source><year>2016b</year><elocation-id>061507</elocation-id><pub-id pub-id-type="doi">10.1101/061507</pub-id></element-citation></ref><ref id="R25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Savier</surname><given-names>EL</given-names></name><name><surname>Chen</surname><given-names>H</given-names></name><name><surname>Cang</surname><given-names>J</given-names></name></person-group><article-title>Effects of Locomotion on Visual Responses in the Mouse Superior Colliculus</article-title><source>J Neurosci</source><year>2019</year><volume>39</volume><fpage>9360</fpage><lpage>9368</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1854-19.2019</pub-id></element-citation></ref><ref id="R26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schröder</surname><given-names>S</given-names></name><name><surname>Steinmetz</surname><given-names>NA</given-names></name><name><surname>Krumin</surname><given-names>M</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Rizzi</surname><given-names>M</given-names></name><name><surname>Lagnado</surname><given-names>L</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name></person-group><article-title>Arousal Modulates Retinal Output</article-title><source>Neuron</source><year>2020</year><volume>107</volume><fpage>487</fpage><lpage>495</lpage><elocation-id>e9</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuron.2020.04.026</pub-id></element-citation></ref><ref id="R27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steinmetz</surname><given-names>NA</given-names></name><name><surname>Zatka-Haas</surname><given-names>P</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><article-title>Distributed coding of choice, action and engagement across the mouse brain</article-title><source>Nature</source><year>2019</year><volume>576</volume><fpage>266</fpage><lpage>273</lpage><pub-id pub-id-type="doi">10.1038/s41586-019-1787-x</pub-id></element-citation></ref><ref id="R28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Villar</surname><given-names>MJ</given-names></name><name><surname>Vitale</surname><given-names>ML</given-names></name><name><surname>Hökfelt</surname><given-names>T</given-names></name><name><surname>Verhofstad</surname><given-names>AA</given-names></name></person-group><article-title>Dorsal raphe serotoninergic branching neurons projecting both to the lateral geniculate body and superior colliculus: a combined retrograde tracing-immunohistochemical study in the rat</article-title><source>J Comp Neurol</source><year>1988</year><volume>277</volume><fpage>126</fpage><lpage>140</lpage><pub-id pub-id-type="doi">10.1002/cne.902770109</pub-id></element-citation></ref><ref id="R29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vinck</surname><given-names>M</given-names></name><name><surname>Batista-Brito</surname><given-names>R</given-names></name><name><surname>Knoblich</surname><given-names>U</given-names></name><name><surname>Cardin</surname><given-names>JA</given-names></name></person-group><article-title>Arousal and Locomotion Make Distinct Contributions to Cortical Activity Patterns and Visual Encoding</article-title><source>Neuron</source><year>2015</year><volume>86</volume><fpage>740</fpage><lpage>754</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.03.028</pub-id></element-citation></ref><ref id="R30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wald</surname><given-names>A</given-names></name></person-group><article-title>Tests of statistical hypotheses concerning several parameters when the number of observations is large</article-title><source>Trans Amer Math Soc</source><year>1943</year><volume>54</volume><fpage>426</fpage><lpage>482</lpage><pub-id pub-id-type="doi">10.1090/S0002-9947-1943-0012401-3</pub-id></element-citation></ref><ref id="R31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Herman</surname><given-names>JP</given-names></name><name><surname>Krauzlis</surname><given-names>RJ</given-names></name></person-group><article-title>Neuronal modulation in the mouse superior colliculus during covert visual selective attention</article-title><source>Sci Rep</source><year>2022</year><volume>12</volume><fpage>2482</fpage><pub-id pub-id-type="doi">10.1038/s41598-022-06410-5</pub-id></element-citation></ref><ref id="R32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>McAlonan</surname><given-names>K</given-names></name><name><surname>Goldstein</surname><given-names>S</given-names></name><name><surname>Gerfen</surname><given-names>CR</given-names></name><name><surname>Krauzlis</surname><given-names>RJ</given-names></name></person-group><article-title>A Causal Role for Mouse Superior Colliculus in Visual Perceptual Decision-Making</article-title><source>J Neurosci</source><year>2020</year><volume>40</volume><fpage>3768</fpage><lpage>3782</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2642-19.2020</pub-id></element-citation></ref><ref id="R33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weldon</surname><given-names>DA</given-names></name><name><surname>DiNieri</surname><given-names>JA</given-names></name><name><surname>Silver</surname><given-names>MR</given-names></name><name><surname>Thomas</surname><given-names>AA</given-names></name><name><surname>Wright</surname><given-names>RE</given-names></name></person-group><article-title>Reward-related neuronal activity in the rat superior colliculus</article-title><source>Behavioural Brain Research</source><year>2007</year><volume>177</volume><fpage>160</fpage><lpage>164</lpage><pub-id pub-id-type="doi">10.1016/j.bbr.2006.11.004</pub-id></element-citation></ref><ref id="R34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zénon</surname><given-names>A</given-names></name><name><surname>Krauzlis</surname><given-names>RJ</given-names></name></person-group><article-title>Attention deficits without cortical neuronal deficits</article-title><source>Nature</source><year>2012</year><volume>489</volume><fpage>434</fpage><lpage>437</lpage><pub-id pub-id-type="doi">10.1038/nature11497</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>Superficial superior colliculus neurons respond to various task events.</title><p><bold>A.</bold> Top left: Experimental setup. Top right: Mouse has to choose left (right) when visual stimulus is presented on the left (right) and has to choose NoGo when no stimulus is presented. Bottom: Time course of each trial. Trial starts when wheel is kept still (quiescent). Visual stimulus appears. After a delay, auditory go cue signals that stimulus can be moved using wheel. Choice is recorded either when stimulus reaches decision threshold (at or away from target position), or at fixed delay after go cue. At time of choice, feedback is delivered: water reward for correct choices, auditory noise for incorrect choices. After a delay, visual stimulus disappears and new trial can be initiated. <bold>B.</bold> Psychometric curve. Percentage of left (green), right (blue), or NoGo (yellow) choices (mean ± SEM, 16 sessions, 4 mice) depending on stimulus contrast. Average performance, i.e., percentage of correct choices, across 16 sessions: 65.3 ± 0.3%; across 4 mice: 64.4 ± 0.2%. Trials in which the animal was disengaged, i.e., ≥3 consecutive NoGo trials, were discarded. <bold>C.</bold> Reaction time (mean ± SEM, 16 sessions) measured as time from go cue to time when stimulus reached its target. Only Go trials were considered. <bold>D.</bold> Mean calcium traces of 1,163 task responsive neurons (significant response to at least one task event; 2,855 neurons recorded) locked to onsets (dashed lines) of the visual stimulus (at 100% contrast), auditory go cue, wheel move, and feedback. Trace of each neuron was z-scored across session before averaging across trials. Order of neurons is the same across all plots. Neurons were first grouped by the first event they responded to (order of tested events as shown in plot), and then sorted by response amplitude. <bold>E.</bold> Mean calcium traces of 296 neurons (from 13 sessions) locked to onset of a lick outside the reward period. Only neurons with significant responses to licks shown. <bold>F.</bold> Distribution of number of task events eliciting significant responses. <bold>G.</bold> Number of neurons with significant responses to pairs of task events. Diagonal shows number of neurons responding to each task event.</p></caption><graphic xlink:href="EMS156315-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Visual responses in the superficial superior colliculus are modulated by task variables.</title><p><bold>A.</bold> Calcium traces (mean ± SEM) of one sSC neuron in response to visual stimuli of different contrasts. Vertical lines: stimulus onset; horizontal line at o ΔF/F. Shaded region: 0.0–0.5 s after stimulus onset, window used to determine response amplitudes (in <bold>B,D,F</bold>). <bold>B.</bold> Visual responses (mean ± SEM, same neuron as in <bold>A</bold>) fitted (dashed line) using a hyperbolic ratio function. Responses were baseline subtracted (mean of 0-0.5 s before stimulus onset). <bold>C-F.</bold> Same as in <bold>A,B</bold> for two different neurons. Trials were split according to pupil size (<bold>C,D</bold>) or previous feedback (<bold>E,F</bold>). <bold>G-J.</bold> Gain (R) of visually responsive neurons (319, 15 sessions, 4 mice) for pupil size (<bold>G</bold>), previous feedback (<bold>H</bold>), action (<bold>I</bold>), and outcome (<bold>J</bold>). Black dots: significantly different gains, p &lt; 0.05, permutation test. Neurons with significantly increased/decreased responses: 21/41 during large pupil (<bold>G</bold>), 53/12 following reward (<bold>H</bold>), 14/10 during Go trials (<bold>I</bold>), 5/5 before correct choices (<bold>J</bold>). <bold>K-N.</bold> Cumulative distributions of response modulation (black line) by task variables. Grey shade: 2.5th to 97.5th interval of null distribution. <bold>O-R.</bold> Decoding scores of logistic regression models to detect presence of visual stimulus, tested on trials with different values of each task variable, e.g., small versus large pupil (<bold>O</bold>). Significant difference in predictive power per dataset (black dots) and across datasets (star) determined with permutation test (p &lt; 0.05).</p></caption><graphic xlink:href="EMS156315-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Modulation by previous feedback is independent of pupil size, licking, and response fluctuations.</title><p><bold>A.</bold> Example trace of pupil size and trial outcomes. <bold>B.</bold> Pupil size (mean across trials) following positive versus negative feedback (t(15) = 0.428, p = 0.675, paired t-test). <bold>C.</bold> Response modulation (RM) by pupil size versus previous feedback. Black dots: both RMs significant. Tests: all data: Pearson’s r = 0.13, p &lt; 0.05, 319 neurons; black dots only: Pearson’s r = -0.07, p = 0.75, 21 neurons. <bold>D,E.</bold> Lick rate (mean ± SEM) locked to feedback onset (<bold>D</bold>) and stimulus onset following positive and negative feedback (<bold>E</bold>) for one session. <bold>F.</bold> Lick rate (mean ± SEM, 12 sessions) before (-0.5–0 s) and after (0–0.5 s) visual stimulus onset following positive or negative feedback. Mice licked more following rewarded than non-rewarded trials (F(1,44) = 9,543, p &lt; 0.01), but lick rate was not significantly different between pre- and post-stimulus periods (F(1,44) = 0.0.23, p = 0.880). Test: two-way ANOVA (factors: time (pre-/post-stimulus) × feedback). <bold>G.</bold> Quantification of visual response fluctuation (see <italic><xref ref-type="sec" rid="S20">Response fluctuation analysis</xref></italic> in <xref ref-type="sec" rid="S4">Materials and Methods</xref>). <bold>H.</bold> Auto-correlogram of fluctuation trace (mean across visually responsive neurons in one session). Grey shade: 2.5th to 97.5th percentile interval of null distribution. <bold>I.</bold> Histogram of largest absolute lags with significant correlation strengths. <bold>J,K.</bold> Response modulation (RM) by pupil size (<bold>J</bold>) and previous feedback (<bold>K</bold>) for all trials (“control”) versus for no-lick trials (no licks in response window). RMs were not significantly different (pupil size: z = -0.05, p = 0.96, 62 neurons; feedback: z = 0.47, p = 0.64, 65 neurons; linear mixed-effects model). <bold>L,M.</bold> RM by pupil size (<bold>L</bold>) and previous feedback (<bold>M</bold>) as determined previously (“control”) and when accounting for response fluctuations. RMs were not significantly different (pupil size: z = 0.031, p = 0.98, 62 neurons; feedback: z = 0.44, p=0.66, 65 neurons; linear mixed effects model). <bold>J-M.</bold> Only neurons with significant RMs in control condition were considered (see <xref ref-type="fig" rid="F2">Figure 2G,H</xref>).</p></caption><graphic xlink:href="EMS156315-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Responses to task events and modulation of visual responses by task variables extends to deep SC.</title><p><bold>A.</bold> Mean firing rates of 225 neurons (significant response to at least one task event; 416 neurons recorded, 15 sessions) in the sSC locked to onsets (dashed lines) of task events (for visual stimuli: only trials with 100% contrast on one side and 0% contrast on other side). Neurons significantly responded to contralateral stimuli (113, 50%), ipsilateral stimuli (21, 9%), auditory go cue (41, 18%), wheel movement (124, 55%), reward (82, 36%), negative feedback (13, 6%), and licking (79, 35%). <bold>B.</bold> As in <bold>A</bold>, but for 381 task responsive neurons (621 neurons recorded, 15 sessions) in the deep SC. Neurons significantly responded to contralateral stimuli (137, 36%), ipsilateral stimuli (63, 7%), auditory go cue (134, 35%), wheel movement (254, 67%), reward (178, 47%), negative feedback (49, 13%), and licking (155, 41%). <bold>C,D.</bold> Gain (R) of visually responsive neurons (158 neurons, 15 sessions, 6 mice) for pupil size (<bold>C</bold>), and previous feedback (<bold>D</bold>). Black dots: significantly different gains, p &lt; 0.05, permutation test. Neurons with significantly increased/decreased responses: 13/5 during large pupil (<bold>C</bold>), 26/9 following reward (<bold>D</bold>). <bold>E.</bold> Depth of neurons within SC modulated by different task behaviours. Number of significantly modulated sSC/dSC neurons: 10/8 by pupil size, 24/11 by previous feedback, 4/10 by action, and 5/12 by outcome. Dashed line: border between superficial and deep superior colliculus at -400 μm.</p></caption><graphic xlink:href="EMS156315-f004"/></fig></floats-group></article>