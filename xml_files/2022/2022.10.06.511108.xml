<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS155700</article-id><article-id pub-id-type="doi">10.1101/2022.10.06.511108</article-id><article-id pub-id-type="archive">PPR555650</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Feedback-based motor control can guide plasticity and drive rapid learning</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Feulner</surname><given-names>Barbara</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Perich</surname><given-names>Matthew G.</given-names></name><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Miller</surname><given-names>Lee E.</given-names></name><xref ref-type="aff" rid="A3">3</xref><xref ref-type="aff" rid="A4">4</xref><xref ref-type="aff" rid="A5">5</xref></contrib><contrib contrib-type="author"><name><surname>Clopath</surname><given-names>Claudia</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="fn" rid="FN1">¶</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><contrib contrib-type="author"><name><surname>Gallego</surname><given-names>Juan A.</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="fn" rid="FN1">¶</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib></contrib-group><aff id="A1"><label>1</label>Department of Bioengineering, Imperial College London, London, UK</aff><aff id="A2"><label>2</label>Département de neurosciences, Université de Montréal, Montréal, Canada</aff><aff id="A3"><label>3</label>Department of Neuroscience, Northwestern University, USA</aff><aff id="A4"><label>4</label>Department of Biomedical Engineering, Northwestern University, Evanston, IL, USA</aff><aff id="A5"><label>5</label>Department of Physical Medicine and Rehabilitation, Northwestern University, and Shirley Ryan Ability Lab, Chicago, IL, USA</aff><author-notes><corresp id="CR1">
<label>*</label>Corresponding authors: <email>c.clopath@imperial.ac.uk</email> and <email>jgallego@imperial.ac.uk</email></corresp><fn id="FN1"><label>¶</label><p id="P1">These authors jointly supervised this work.</p></fn></author-notes><pub-date pub-type="nihms-submitted"><day>14</day><month>10</month><year>2022</year></pub-date><pub-date pub-type="preprint"><day>08</day><month>10</month><year>2022</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nd/4.0/">CC BY-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P2">Animals use afferent feedback to rapidly correct ongoing movements in the presence of a perturbation. Repeated exposure to a predictable perturbation leads to behavioural adaptation that counteracts its effects. Primary motor cortex (M1) is intimately involved in both processes, integrating inputs from various sensorimotor brain regions to update the motor output. Here, we investigate whether feedback-based motor control and motor adaptation may share a common implementation in M1 circuits. We trained a recurrent neural network to control its own output through an error feedback signal, which allowed it to recover rapidly from external perturbations. Implementing a biologically plausible plasticity rule based on this same feedback signal also enabled the network to learn to counteract persistent perturbations through a trial-by-trial process, in a manner that reproduced several key aspects of human adaptation. Moreover, the resultant network activity changes were also present in neural population recordings from monkey M1. Online movement correction and longer-term motor adaptation may thus share a common implementation in neural circuits.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P3">Animals, including humans, have a remarkable ability to rapidly correct their ongoing movements based on perceived errors, even when feedback may be distorted, such as when reaching into a pond to recover an object one has dropped. In the laboratory, these movement corrections and subsequent adaptation can be evoked and studied systematically using the classic visuomotor rotation (VR) perturbation paradigm<sup><xref ref-type="bibr" rid="R1">1</xref>, <xref ref-type="bibr" rid="R2">2</xref></sup>. In this paradigm, the subject receives distorted visual feedback (typically a rotation about the centre of the workspace) of a reaching movement, thereby creating a perceived error due to the mismatch of expected and observed hand trajectory. Humans can correct their ongoing movements even during the very first trial after perturbation onset<sup><xref ref-type="bibr" rid="R3">3</xref></sup>, a process that is mediated by primary motor cortex (M1) integrating multiple feedback signals arriving from various sensory and motor brain regions<sup><xref ref-type="bibr" rid="R4">4</xref>–<xref ref-type="bibr" rid="R17">17</xref></sup>.</p><p id="P4">When repeatedly exposed to a predictable perturbation, animals progressively learn to use their perceived errors to anticipate its effect. For the case of the VR paradigm described above, this leads to a gradual reaiming of the reach, until it starts out in the correct direction<sup><xref ref-type="bibr" rid="R2">2</xref></sup>, thereby eliminating the need for further online corrections. This requires some form of rapid learning along the sensorimotor pathways, likely guided by trial-by-trial error information<sup><xref ref-type="bibr" rid="R3">3</xref>, <xref ref-type="bibr" rid="R18">18</xref>, <xref ref-type="bibr" rid="R19">19</xref></sup>. How and where in the brain this “motor adaptation” happens remains inconclusive<sup><xref ref-type="bibr" rid="R1">1</xref>, <xref ref-type="bibr" rid="R20">20</xref>–<xref ref-type="bibr" rid="R45">45</xref></sup>, and may depend on the characteristics of the perturbation, such as whether it is a rotation of the visual feedback or a force acting on the limb<sup><xref ref-type="bibr" rid="R28">28</xref>, <xref ref-type="bibr" rid="R46">46</xref>–<xref ref-type="bibr" rid="R51">51</xref></sup>.</p><p id="P5">Feedback-based movement correction and motor adaptation have been mostly studied in isolation and are often assumed to involve different neural substrates<sup><xref ref-type="bibr" rid="R2">2</xref>, <xref ref-type="bibr" rid="R11">11</xref></sup>. What if that were not the case, but instead, they shared a common implementation in neural circuitry? A recent behavioural study proposed that movement correction and adaptation may indeed be tightly linked: fast feedback responses could act as teacher signals that drive trial-by-trial adaptation<sup><xref ref-type="bibr" rid="R21">21</xref>, <xref ref-type="bibr" rid="R52">52</xref>, <xref ref-type="bibr" rid="R53">53</xref></sup>. Despite the conceptual beauty of this idea, its feasibility and implementation details remain unexplored.</p><p id="P6">Here, we hypothesised that the neural circuitry for feedback control may be exploited to drive the “plasticity” that enables successful motor adaptation. To address this hypothesis, we use a recurrent neural network (RNN) model<sup><xref ref-type="bibr" rid="R54">54</xref>–<xref ref-type="bibr" rid="R62">62</xref></sup> trained not only to produce a certain output, but to <italic>control</italic> it. The key difference here is that this model should be able to flexibly correct its output in the case of unexpected external perturbations. Having such a model allowed us to test whether feedback signals used for motor control could guide plastic changes within the network that lead to successful trial-by-trial learning.</p><p id="P7">We first show that an RNN can be trained to perform feedback-based motor control, even in the presence of a relatively long, biologically plausible feedback delay. We then demonstrate how feedback signals, modelled as inputs to the RNN, can guide synaptic plasticity within the network that drives successful trial-by-trial adaptation. Intriguingly, this form of learning through feedback-driven plasticity led to behavioural adaptation that was similar to that of a human in terms of time course<sup><xref ref-type="bibr" rid="R63">63</xref>, <xref ref-type="bibr" rid="R64">64</xref></sup>, generalisation<sup><xref ref-type="bibr" rid="R2">2</xref></sup>, and sensitivity to perturbation variability<sup><xref ref-type="bibr" rid="R65">65</xref>,<xref ref-type="bibr" rid="R66">66</xref></sup>. Moreover, both effective control and learning could be achieved with sparse feedback signals. Finally, comparison with neural population recordings from monkey M1 (data from<sup><xref ref-type="bibr" rid="R51">51</xref></sup>) supports the plausibility of the proposed plasticity rule: the temporally dissociable activity changes that followed adaptation in our model could also be found in the actual neural activity. This work not only introduces the potential of a combined implementation of motor control and learning in recurrent circuits, but it also relates several aspects of human adaptation behaviour to a single unifying neural process.</p></sec><sec id="S2" sec-type="results"><title>Results</title><sec id="S3"><title>A recurrent neural network that performs feedback-based motor control</title><p id="P8">We used an RNN model to investigate whether the same feedback signals used to control ongoing behaviour could also mediate motor adaptation. This work was divided into two phases: 1) training the RNN to perform feedback-based motor control (using a gradient-based algorithm), and 2) using this trained RNN to implement trial-by-trial motor adaptation via a local, biologically plausible learning rule acting on the recurrent weights of the network. We validated our model by comparing it to several behavioural and electrophysiological studies.</p><p id="P9">First, we trained an RNN to control its own output to produce the desired movement (<xref ref-type="fig" rid="F1">Figure 1A,B</xref>). Our goal was to have a model that, after training, could dynamically adjust the ongoing movement according to incoming sensory feedback. Feedback control was based on an instantaneous position error signal, <italic>ϵ<sub>t</sub></italic>, defined as the difference between the produced position, <italic>p<sub>t</sub></italic>, and the target position, <inline-formula><mml:math id="M1"><mml:msubsup><mml:mi>p</mml:mi><mml:mi>t</mml:mi><mml:mo>∗</mml:mo></mml:msubsup></mml:math></inline-formula>, which we computed assuming a straight line between the start and end points (<xref ref-type="fig" rid="F1">Figure 1C</xref>). This error signal was fed back as an input to the RNN with a biologically realistic delay of 120 ms<sup><xref ref-type="bibr" rid="R12">12</xref></sup> (<xref ref-type="fig" rid="F1">Figure 1B</xref>).</p><p id="P10">After the initial training phase (<xref ref-type="fig" rid="F1">Figure 1D</xref>, examples in <xref ref-type="supplementary-material" rid="SD1">Figure S1</xref>; <xref ref-type="sec" rid="S12">Methods</xref>), we tested the RNN on a standard centre-out reaching task with eight equally distributed targets. As expected due to our training procedure, the model was readily able to produce the required straight movement trajectories even without explicit training on this task (<xref ref-type="fig" rid="F1">Figure 1E</xref>).</p><p id="P11">To test the network’s ability flexibly correct its output, we replicated the classic VR paradigm<sup><xref ref-type="bibr" rid="R2">2</xref></sup>. If the RNN could indeed <italic>control</italic> its output, it should still be able to reach to the desired target by correcting the produced movement to counteract the 30° rotations online. Inspecting the movement trajectories after VR onset confirmed that the model could use the error signal to correct its ongoing output (<xref ref-type="fig" rid="F1">Figure 1F</xref>; the curved trajectories indicate ongoing correction). Importantly, successful correction relied on the error signal being fed back into the model: trajectory correction only started after the delayed feedback had had enough time to propagate to the model (<xref ref-type="fig" rid="F1">Figure 1F</xref>), and an RNN trained without feedback connections (<xref ref-type="sec" rid="S12">Methods</xref>) could not reach to the targets (<xref ref-type="fig" rid="F1">Figure 1G</xref>).</p></sec><sec id="S4"><title>An error feedback signal used for feedback-driven motor control can drive trial-by-trial adaptation</title><p id="P12">We have shown that an RNN that has learnt to use feedback signals to control its output can readily counteract an external perturbation, exhibiting a behaviour upon VR onset that is very similar to that of humans<sup><xref ref-type="bibr" rid="R2">2</xref></sup> and monkeys (compare the monkey data from <xref ref-type="bibr" rid="R51">Ref. 51</xref> in <xref ref-type="fig" rid="F2">Figure 2A</xref> to the model data in <xref ref-type="fig" rid="F2">Figure 2D</xref>). However, when repeatedly exposed to a VR, both humans and monkeys learn to adjust their initial “motor plan,” which results in their reach take-off angle pointing in the correct direction after dozens of trials<sup><xref ref-type="bibr" rid="R2">2</xref>, <xref ref-type="bibr" rid="R51">51</xref></sup> (<xref ref-type="fig" rid="F2">Figure 2B,C</xref>). Can our relatively simple error feedback signal enable persistent learning across trials?</p><p id="P13">Since the feedback inputs acting on the network correctly modulate each neuron’s activity to minimize the ongoing motor error (<xref ref-type="fig" rid="F1">Figure 1F</xref>), we hypothesised that they could also act as a “teacher signal” for local, recurrent synaptic plasticity. To test this, we devised a local biologically-plausible synaptic plasticity rule causing the connection weight from neuron <italic>i</italic> to neuron <italic>j</italic> to change in proportion to the feedback signal received by neuron <italic>j</italic> (<xref ref-type="sec" rid="S12">Methods</xref>). Implementing this plasticity rule led to behaviour that was similar to that of monkeys’: the initially large errors in take-off angle became progressively smaller over time, until they reached a plateau close to zero error (note the similarities between <xref ref-type="fig" rid="F2">Figure 2D-F</xref> and <xref ref-type="fig" rid="F2">Figure 2A-C</xref>). Moreover, when the perturbation was turned off, the model underwent a de-adaptation phase similar to the “wash-out” effect exhibited by monkeys (compare <xref ref-type="fig" rid="F2">Figure 2C and Figure 2F</xref>) and humans<sup><xref ref-type="bibr" rid="R67">67</xref></sup>. These results confirm our main hypothesis: an error feedback signal used for online motor control can be leveraged to guide recurrent synaptic plasticity that drives successful trial-by-trial motor adaptation.</p></sec><sec id="S5"><title>Feedback-based learning recapitulates key features of human motor adaptation</title><p id="P14">The previous simulation results suggest that a relatively simple plasticity rule based on an error feedback signal may mediate motor adaptation. Could this type of learning be implemented in actual brains? To investigate the biological plausibility of our feedback-based plasticity rule, we tested whether our model replicated various key observations from human and monkey motor adaptation studies.</p><p id="P15">We first addressed the finding that humans learn more from a given trial if they experience a larger error<sup><xref ref-type="bibr" rid="R52">52</xref></sup>. Indeed, our model reproduced this trend; the measured correlations between movement error and amount of learning in the next trial were comparable in magnitude and sign to those of monkeys performing the same VR task (<xref ref-type="fig" rid="F3">Figure 3A</xref>; data from <xref ref-type="bibr" rid="R51">Ref. 51</xref>). Moreover, as in human adaptation studies<sup><xref ref-type="bibr" rid="R65">65</xref>, <xref ref-type="bibr" rid="R66">66</xref></sup>, our model’s ability to learn was also hindered when the perturbation was inconsistent across trials, with greater perturbation variance leading to progressively less learning (<xref ref-type="fig" rid="F3">Figure 3B</xref>). Thus, the amount of trial-by-trial adaptation matched experimental observations well.</p><p id="P16">When examining the timescale of learning during an experimental session, human motor adaptation seems to be mediated by two simultaneous learning processes: one fast, and another slow<sup><xref ref-type="bibr" rid="R63">63</xref>, <xref ref-type="bibr" rid="R64">64</xref></sup>. Using the same analysis as in <xref ref-type="bibr" rid="R63">Ref. 63</xref>, we found that the adaptation time course of our model is also best described by a combination of two learning processes with different time constants (<xref ref-type="fig" rid="F3">Figure 3C</xref>). Even the parameters describing these processes were comparable to values reported in a human VR adaptation study (<xref ref-type="fig" rid="F3">Figure 3D</xref>; data from <xref ref-type="bibr" rid="R64">Ref. 64</xref>), indicating that, as in actual experiments, our feedback-driven plasticity rule is dominated by fast learning early in adaptation and slow learning later on.</p><p id="P17">Finally, animals, including humans, have a remarkable ability to generalise what they have learned to novel situations, yet, the amount of generalisation seems to depend on the similarity between the current and the past situation. During a VR experiment, participants who have adapted to a perturbation applied on a single reach direction generalize when reaching to neighbouring targets, to an extent that decreases as the angle between the new and adapted direction increases<sup><xref ref-type="bibr" rid="R2">2</xref></sup>. Repeating this single target adaptation experiment in our model revealed the same kind of generalization: the model readily anticipated perturbations applied on adjacent targets and adaptation decreased as the angle between the probed target and the adapted target increased (<xref ref-type="fig" rid="F3">Figure 3E-F</xref>). In summary, our model reproduced key features of primate motor adaptation, supporting our unified view of how rapid motor learning could be implemented in the brain by leveraging signals mediating online feedback correction.</p></sec><sec id="S6"><title>Sparse feedback is sufficient for both motor control and adaptation</title><p id="P18">The fact that our model recapitulates many aspects of human and monkey adaptation behaviour supports the hypothesis that a similar feedback-based learning process may be implemented in actual neural circuits. Yet, in the model we have examined so far, every unit received a feedback signal, whereas only a relatively large subset of primary motor cortical neurons seem to be modulated by sensory feedback (73% of neurons in M1 respond to either visual or proprioceptive feedback<sup><xref ref-type="bibr" rid="R16">16</xref></sup>). Thus, to further probe the plausibility of our model, we explored how our results were influenced by feedback connection density.</p><p id="P19">We quantified model performance in terms of both control accuracy and degree of learning for feedback projection densities ranging from 1% to 100%. Critically, the model could control its output effectively with density as low as 25%; even the extremely sparse 1% projection density decreased endpoint error considerably compared to a model without feedback (compare the solid and dashed lines in <xref ref-type="fig" rid="F4">Figure 4A</xref>). Likewise, the model did learn substantially for all feedback projection densities (compare the solid and empty markers in <xref ref-type="fig" rid="F4">Figure 4B</xref>), and, although the amount of learning decreased almost linearly as feedback projections became sparser, as few as 1% of the neurons receiving feedback sufficed to drive meaningful learning that reduced take-off errors by 30%. Notably, these results were robust to changes in RNN connectivity, as control accuracy and degree of learning were similar for recurrent connection probabilities of 50% and 80% (<xref ref-type="supplementary-material" rid="SD1">Figure S2</xref>).</p><p id="P20">Finally, to understand how feedback inputs enabled successful behaviour, we compared their contribution to that of the recurrent inputs, both early in the perturbation block (<xref ref-type="fig" rid="F4">Figure 4C,D</xref>), where feedback is crucial to correct the output, and after successful adaptation (<xref ref-type="fig" rid="F4">Figure 4E,F</xref>), where we expected feedback to only play a minor role. Even at perturbation onset, the network activity was mostly driven by recurrent inputs, with the feedback making up only a minor part of the overall input (compare the blue and red traces in <xref ref-type="fig" rid="F4">Figure 4C,D</xref>, respectively); this was the case for all feedback densities. Thus, feedback signals did not directly drive accurate movements; instead their contribution was amplified through recurrent dynamics —note the different temporal patterns of recurrent input between before and after adaptation (<xref ref-type="fig" rid="F4">Figure 4C and Figure 4E</xref>, respectively). This likely explains why movement accuracy remained stable across a broad range of feedback projection densities (<xref ref-type="fig" rid="F4">Figure 4A</xref>). As expected, after successful adaptation, feedback inputs were much smaller than recurrent inputs, regardless of the feedback projection density (<xref ref-type="fig" rid="F4">Figure 4E,F</xref>). Combined, these results suggest that actual brains may perform effective motor control and adaptation even with a relatively small number of feedback connections, and feedback signals may make relatively small contribution to the overall neural activity.</p></sec><sec id="S7"><title>Two temporally dissociable adaptation-related activity changes in the model can be uncovered in monkey primary motor cortex</title><p id="P21">Our previous simulations suggest that sparse feedback projections may suffice to enable effective motor control and adaptation (<xref ref-type="fig" rid="F4">Figure 4A,B</xref>), and that feedback inputs account for only a minor portion of a unit’s overall input (<xref ref-type="fig" rid="F4">Figure 4C,D</xref>). Combined, these observations indicate that identifying a “signature” of feedback-driven plasticity in neural recordings or even in the RNN activity may be difficult. Our approach to tackle this was to focus on the within-trial timing: we devised an analysis to isolate activity changes related to the two temporally distinct processes that we expected to occur during feedback-driven adaptation: 1) an early feedforward change, reflecting updated pre-planned movement intent, and 2) a change in feedback signals later in the trial, as the error decreased over trial-by-trial learning.</p><p id="P22">To measure feedback related changes (<xref ref-type="fig" rid="F5">Figure 5A</xref>; green) we focused on the activity changes from the baseline epoch (box A in <xref ref-type="fig" rid="F5">Figure 5A</xref>) to right after perturbation onset (box B in <xref ref-type="fig" rid="F5">Figure 5A</xref>), by simply taking the difference between the single neuron activities in those two epochs. Similarly, the learning related changes (<xref ref-type="fig" rid="F5">Figure 5A</xref>; blue) represent the activity changes between the baseline epoch and the late adaptation epoch (box C in <xref ref-type="fig" rid="F5">Figure 5A</xref>), where we expect the feedback component to have reached baseline levels again as the model no longer needs to correct its movement online. The adaptation related change (<xref ref-type="fig" rid="F5">Figure 5A</xref>; dark grey) is defined as the difference between early and late adaptation epochs, respectively.</p><p id="P23">Inspecting the RNN activity changes during adaptation indeed revealed two distinct peaks in the average activity change during adaptation (<xref ref-type="fig" rid="F5">Figure 5B</xref>), assigned to learning (blue) and feedback (green), respectively. To confirm that these early and late “activity change peaks” did reflect feedforward and feedback processes, respectively, we trained a different set of models that used simple gradient descent instead of feedback-driven plasticity to achieve motor adaptation (<xref ref-type="sec" rid="S12">Methods</xref>). As expected, these models also exhibited a change in activity early during the movement (compare the blue traces in <xref ref-type="fig" rid="F5">Figure 5B and Figure 5C</xref>), confirming that it does represent learning. In contrast, the second peak (green trace in <xref ref-type="fig" rid="F5">Figure 5B</xref>) was absent from these models without feedback-driven plasticity, confirming its source.</p><p id="P24">Having uncovered a signature of feedback-driven adaptation in our model, we sought to identify a similar change in neural population recordings from monkey M1 (<xref ref-type="fig" rid="F5">Figure 5D</xref>; data from <xref ref-type="bibr" rid="R51">Ref. 51</xref>; <xref ref-type="sec" rid="S12">Methods</xref>). <xref ref-type="fig" rid="F5">Figure 5E</xref> shows the average change in M1 activity during a representative VR adaptation session, qualitatively confirming our prediction of a feedback signal during early adaptation trials (circle in <xref ref-type="fig" rid="F5">Figure 5E</xref>). Reassuringly, this feedback signal occurred 300 ms after peak speed (which happened 500 ms after the go cue), as it did in other studies exploring feedback-based movement corrections<sup><xref ref-type="bibr" rid="R12">12</xref>, <xref ref-type="bibr" rid="R16">16</xref></sup>. To further compare the monkey data to our model, we calculated the ratio of the adaptation-related activity change at the “feedback peak” (green circle in <xref ref-type="fig" rid="F5">Figure 5B,C,E</xref>) and the learning-related “feedforward peak” (blue star in <xref ref-type="fig" rid="F5">Figure 5B,C,E</xref>) (<xref ref-type="sec" rid="S12">Methods</xref>). For both monkeys, there was a substantial change in neural activity at the feedback peak during adaptation (<xref ref-type="fig" rid="F5">Figure 5G</xref>), as predicted by our model (<xref ref-type="fig" rid="F5">Figure 5F</xref>). Moreover, the value of this ratio was similar across both monkeys and sessions, and best matched, in terms of mean and variability, that of models with high feedback projection densities (<xref ref-type="fig" rid="F5">Figure 5F,G</xref>). The fact that models with dense feedback projections best replicated the experimental data is in good agreement with observations suggesting that as many as 73% of M1 neurons are driven by feedback<sup><xref ref-type="bibr" rid="R16">16</xref></sup>. The similarities in the activity changes during adaptation between our model and monkey M1 suggest that error feedback signals in M1 may indeed guide local plasticity relevant for rapid motor learning.</p></sec></sec><sec id="S8" sec-type="discussion"><title>Discussion</title><p id="P25">Both the rapid correction of ongoing movements and progressive adaptation to changing conditions are key landmarks of behaviour that are often studied separately. Here, we have shown that an RNN that can dynamically control its output based on feedback inputs can use those same inputs to achieve motor adaptation through recurrent connectivity changes. Interestingly, this form of feedback-driven plasticity recapitulated key aspects of primate adaptation behaviour<sup><xref ref-type="bibr" rid="R2">2</xref>, <xref ref-type="bibr" rid="R63">63</xref>–<xref ref-type="bibr" rid="R66">66</xref></sup>, and led to identifiable activity changes in the model that we subsequently discovered in neural recordings made in the primary motor cortex of two monkeys. These results, which were robust across a broad change of model parameters (<xref ref-type="fig" rid="F4">Figure 4</xref>, <xref ref-type="supplementary-material" rid="SD1">Figure S2</xref>), support the hypothesis that online movement correction and motor adaptation may share a common implementation in neural circuits.</p><sec id="S9"><title>Implementation of feedback-based motor control in neural circuitry</title><p id="P26">Most modelling studies on motor control have focused on understanding it at an abstract computational level, mostly ignoring neurons and connections between them<sup><xref ref-type="bibr" rid="R52">52</xref>, <xref ref-type="bibr" rid="R63">63</xref>, <xref ref-type="bibr" rid="R68">68</xref></sup>. One potential reason is the challenge of mapping the abstract concepts of optimal feedback control theory into brain regions<sup><xref ref-type="bibr" rid="R5">5</xref>, <xref ref-type="bibr" rid="R17">17</xref></sup>. Our work differs from those previous attempts in that it approaches the problem from a bottom-up, not a top-down perspective: instead of explicitly training neural networks to match the behavioural components predicted by optimal feedback control theory, such as a forward model or a controller<sup><xref ref-type="bibr" rid="R69">69</xref></sup>, we let error minimization guide the emergence of an efficient control strategy, potentially mimicking how brain connectivity developed over evolutionary timescales<sup><xref ref-type="bibr" rid="R70">70</xref>–<xref ref-type="bibr" rid="R72">72</xref></sup>. Given that this bottom-up approach led to a feedback-based learning process that recapitulated key aspects of human behavioural adaptation (<xref ref-type="fig" rid="F2">Figure 2</xref>,<xref ref-type="fig" rid="F3">Figure 3</xref>), we believe that our model could help map specific functions that have been formalized in optimal feedback control onto neural circuits, adding to existing approaches<sup><xref ref-type="bibr" rid="R15">15</xref>, <xref ref-type="bibr" rid="R17">17</xref>, <xref ref-type="bibr" rid="R73">73</xref>–<xref ref-type="bibr" rid="R76">76</xref></sup>.</p><p id="P27">While in this paper we have compared the network activity to recordings from monkey M1, our model (<xref ref-type="fig" rid="F5">Figure 5</xref>) does not necessarily encompass only M1 function. On the contrary, it is likely that it captures functions mediated in part through multi-region interactions with a variety of cortical and subcortical regions<sup><xref ref-type="bibr" rid="R77">77</xref>, <xref ref-type="bibr" rid="R78">78</xref></sup>, such as feedback processing, or sensory gating. Extending our work to modular, multi-region RNNs whose activity is compared to neural population recordings across the sensorimotor network (such as in <xref ref-type="bibr" rid="R59">Ref. 59</xref>,<xref ref-type="bibr" rid="R61">61</xref>,<xref ref-type="bibr" rid="R62">62</xref>) may shed light into the distributed implementation across brain circuits of the different computations underlying feedback control.</p><p id="P28">Early studies proposed the cerebellum as the key structure for motor adaptation<sup><xref ref-type="bibr" rid="R5">5</xref>, <xref ref-type="bibr" rid="R22">22</xref>, <xref ref-type="bibr" rid="R25">25</xref>, <xref ref-type="bibr" rid="R31">31</xref>, <xref ref-type="bibr" rid="R41">41</xref>, <xref ref-type="bibr" rid="R79">79</xref>–<xref ref-type="bibr" rid="R84">84</xref></sup>. Their central premise was that the cerebellum stores both “forward” and “inverse” internal models of the sensorimotor system which are used to generate and update predicted outcomes of motor commands, respectively<sup><xref ref-type="bibr" rid="R50">50</xref>, <xref ref-type="bibr" rid="R85">85</xref>–<xref ref-type="bibr" rid="R87">87</xref></sup>. The importance of internal models in the cerebellum received additional support from evidence of adaptation deficits in cerebellar patients<sup><xref ref-type="bibr" rid="R88">88</xref></sup>, although this view has recently been challenged by a proposal that adaptation is better described by a direct update of a control policy<sup><xref ref-type="bibr" rid="R53">53</xref></sup>. Our study does not contradict this work; it illustrates an alternative, perhaps parallel learning process relevant for motor adaptation. Moreover, the cerebellum could readily fit into our model as the brain region responsible for calculating error estimates based on the sensory feedback, which we simply assumed to exist. Interestingly, the fact that cerebellar patients have impairments in motor control as well as learning<sup><xref ref-type="bibr" rid="R25">25</xref>, <xref ref-type="bibr" rid="R89">89</xref></sup> also fits with our model, since both processes are critically dependent on the availability of an accurate error signal. Combining our bottom-up model of feedback-based learning in M1 with previous models of the cerebellum<sup><xref ref-type="bibr" rid="R22">22</xref>, <xref ref-type="bibr" rid="R76">76</xref></sup> might provide a fruitful route to uncover how each of these two brain regions contributes to motor adaptation.</p></sec><sec id="S10"><title>Biologically plausible learning rules</title><p id="P29">Our proposed feedback-driven learning rule adds to recent efforts to implement biologically plausible learning in RNNs<sup><xref ref-type="bibr" rid="R90">90</xref>–<xref ref-type="bibr" rid="R96">96</xref></sup> —a challenging temporal credit assignment problem. Most of these learning rules share the same basic idea: the weight change is proportional to the error signal arriving at the postsynaptic neuron times the activity history of the presynaptic neuron. What makes those learning rules biologically plausible is that both pieces of information could in principle be locally available at a synapse.</p><p id="P30">The crucial difference between our model and previous studies is that the error signal is a direct input to the neuron, which allows it to simultaneously guide weight update and affect the ongoing network dynamics. This feature is desirable because it avoids the need to have two distinct pathways for error signals and ongoing network dynamics, respectively<sup><xref ref-type="bibr" rid="R97">97</xref>–<xref ref-type="bibr" rid="R99">99</xref></sup>. Moreover, our approach makes weight update dependent on the error signal in two ways: directly, through the error term in the plasticity rule, and indirectly, through the change in ongoing dynamics, which influences the activity of the presynaptic neuron. This could be beneficial for learning and should be compared to standard learning algorithms like gradient descent.</p><p id="P31">Finally, our feedback-driven plasticity rule led to an adaptation time course that replicated the simultaneous fast and slow processes found in human behavioural studies (<xref ref-type="fig" rid="F3">Figure 3C</xref>;<sup><xref ref-type="bibr" rid="R63">63</xref>, <xref ref-type="bibr" rid="R64">64</xref></sup>). This seems puzzling given that the fast process is often assumed to be explicit<sup><xref ref-type="bibr" rid="R64">64</xref>, <xref ref-type="bibr" rid="R100">100</xref></sup>, a component not possible in our RNN implementation. Therefore, the observation of a fast component despite adaptation being mediated purely by an error feedback signal suggests that, in principle, error minimisation alone can give rise to learning at multiple timescales.</p></sec></sec><sec id="S11" sec-type="conclusions"><title>Conclusions</title><p id="P32">We have shown how the same error feedback signal that mediates ongoing motor corrections can drive trial-by-trial motor adaptation by guiding synaptic plasticity using a relatively simple, biologically plausible plasticity rule. Crucially, this bottom-up model of a shared implementation of feedback-based motor control and rapid learning recapitulated key observations from behavioural and neurophysiological adaptation studies in humans and monkeys. Thus, these two landmarks of animal behaviour may be unified in their implementation by the same neural circuitry.</p></sec><sec id="S12" sec-type="methods"><title>Methods</title><sec id="S13"><title>Recurrent Neural Network model</title><p id="P33">Neural activity <italic>x</italic> was simulated using the following dynamical equations, <disp-formula id="FD1"><mml:math id="M2"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mtext>dt</mml:mtext></mml:mrow><mml:mi>τ</mml:mi></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munder><mml:mi>∑</mml:mi><mml:mi>i</mml:mi></mml:munder><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mtext>Φ</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:munder><mml:mi>∑</mml:mi><mml:mi>i</mml:mi></mml:munder><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munder><mml:mi>∑</mml:mi><mml:mi>i</mml:mi></mml:munder><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mtext>Δ</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mi>∑</mml:mi><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>&lt;</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:munderover><mml:mtext>Φ</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:munder><mml:mi>∑</mml:mi><mml:mi>i</mml:mi></mml:munder><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msubsup><mml:mtext>Φ</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mi>b</mml:mi><mml:mi>k</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msubsup></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mtext>dt</mml:mtext><mml:mo>⋅</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mi>k</mml:mi><mml:mo>∗</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> where the network output <italic>v</italic> represents velocity, and <italic>p</italic> position, of the simulated planar hand movement (cf. definitions in <xref ref-type="table" rid="T1">Table 1</xref>). The instantaneous error signal <italic>ϵ</italic> is given by the difference between the target <italic>p*</italic> and the produced position <italic>p</italic>, and is fed back to the network with a time delay Δ. How we constructed the network input <italic>s</italic> and the target position <italic>p</italic>* are described in the “Reaching datasets for model training and testing” section below. Each trial was initialized by setting all <italic>x<sub>j</sub></italic> to random numbers uniformly distributed between -0.2 and 0.2. All simulations were performed on RNN models consisting of 400 neurons, which were connected all-to-all. Varying the recurrent connection probability did not change the results (<xref ref-type="supplementary-material" rid="SD1">Figure S2</xref>).</p></sec><sec id="S14"><title>Model training procedure</title><p id="P34">The first step was to train the RNN to control its own output, that is, to minimize the position error, <italic>ϵ</italic>. This training was performed using standard gradient descent to find the right set of parameters. The initial training procedure was implemented in Pytorch<sup><xref ref-type="bibr" rid="R101">101</xref></sup> using the Adam optimizer with learning rate <italic>α</italic> = 0.001 (<italic>β</italic><sub>1</sub> = 0.9, <italic>β<sub>2</sub></italic> = 0.999)<sup><xref ref-type="bibr" rid="R102">102</xref></sup>. The weights (<italic>W</italic>,<italic>W<sup>in</sup>,W<sup>out</sup>,F</italic>) and biases (<italic>b,b<sup>out</sup></italic>) were initialized by drawing random, uniformly distributed numbers between <inline-formula><mml:math id="M3"><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msqrt><mml:mi>l</mml:mi></mml:msqrt></mml:math></inline-formula> and <inline-formula><mml:math id="M4"><mml:mn>1</mml:mn><mml:msqrt><mml:mi>l</mml:mi></mml:msqrt></mml:math></inline-formula>, where <italic>l</italic> is either the number of neurons in the network (for <italic>W</italic>,<italic>W<sup>in</sup>,F,b</italic>) or the dimensionality of the output (for <italic>W<sup>out</sup>,b<sup>out</sup></italic>). The gradient norm was clipped at 0.2 prior to the optimization step. The loss function used for this initial training phase was defined as <disp-formula id="FD2"><mml:math id="M5"><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mi>B</mml:mi><mml:mi>T</mml:mi></mml:mrow></mml:mfrac><mml:munderover><mml:mi>∑</mml:mi><mml:mi>b</mml:mi><mml:mi>B</mml:mi></mml:munderover><mml:munderover><mml:mi>∑</mml:mi><mml:mi>t</mml:mi><mml:mi>T</mml:mi></mml:munderover><mml:munder><mml:mi>∑</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:munder><mml:mi>∑</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>W</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:munder><mml:mo>∥</mml:mo><mml:mi>M</mml:mi><mml:msub><mml:mo>∥</mml:mo><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>N</mml:mi><mml:mi>B</mml:mi><mml:mi>T</mml:mi></mml:mrow></mml:mfrac><mml:munderover><mml:mi>∑</mml:mi><mml:mi>b</mml:mi><mml:mi>B</mml:mi></mml:munderover><mml:munderover><mml:mi>∑</mml:mi><mml:mi>t</mml:mi><mml:mi>T</mml:mi></mml:munderover><mml:munderover><mml:mi>∑</mml:mi><mml:mi>j</mml:mi><mml:mi>N</mml:mi></mml:munderover><mml:mtext>Φ</mml:mtext><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:math></disp-formula> where <italic>B</italic> is the batch size, <italic>T</italic> the number of time steps, <italic>N</italic> the number of neurons, <italic>β</italic> the regularization parameter for the weights and bias terms and <italic>γ</italic> the regularization parameter for the activity in the network (cf. definitions in <xref ref-type="table" rid="T1">Table 1</xref>). The network was trained for 1100 epochs, divided into three blocks of different lengths (100, 500, 500). For the first 100 epochs, the feedback weights <italic>F</italic> were kept fixed while the remaining parameters where allowed to change. This ensured that the model learnt to self-generate the appropriate network dynamics to produce a variety of reaching trajectories. In the next 500 epochs, the feedback connections were also allowed to change. In the last 500 epochs, we introduced perturbations on the produced output (see “Reaching datasets for model training and testing”), with all parameters plastic, to make the model learn to use the feedback inputs to compensate for ongoing errors.</p></sec><sec id="S15"><title>A feedback-driven plasticity rule to drive trial-by-trial learning</title><p id="P35">Having set up the model to control its own output, we next examined how feedback inputs <italic>ϵ</italic> could guide learning, implemented through synaptic plasticity within the recurrent weights <italic>W</italic> of the network. To this end, we devised the following <italic>feedback-driven plasticity rule:</italic> <disp-formula id="FD3"><mml:math id="M6"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mtext>dt</mml:mtext><mml:mi>η</mml:mi><mml:mstyle displaystyle="true"><mml:munder><mml:mi>∑</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mstyle><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mi>∑</mml:mi><mml:mi>t</mml:mi></mml:munder><mml:mi>d</mml:mi><mml:mi>W</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>5</mml:mn><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p id="P36">The weight update <italic>dW</italic> was calculated online and summed up taking into account every fifth time step until the end of a trial <italic>k</italic>. After each trial, we applied this accumulated weight change and updated the recurrent weights <italic>W</italic> accordingly.</p></sec><sec id="S16"><title>Reaching datasets for model training and testing</title><p id="P37">The network model was trained to produce a broad set of synthetic planar reaching trajectories following an instructed delay phase. The <italic>x</italic> and <italic>y</italic> positions of the starting (<italic>p<sup>start</sup></italic>) and ending points (<italic>p<sup>end</sup></italic>) of those trajectories were randomly drawn from a uniform distribution ranging from -6 cm to 6 cm. To simulate natural reaching behaviour, we interpolated between these points using a sigmoid function <disp-formula id="FD4"><mml:math id="M7"><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>exp</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mi>t</mml:mi><mml:mo>⋅</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:math></disp-formula> where <italic>κ</italic>=10/s. The manually constructed reach trajectories were thus given by <disp-formula id="FD5"><mml:math id="M8"><mml:msubsup><mml:mi>p</mml:mi><mml:mi>t</mml:mi><mml:mo>∗</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>p</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>p</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mi>p</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></disp-formula> which resulted in bell-shaped velocity profiles.</p><p id="P38">Each trial lasted 3 s and included an instructed delay period, randomly drawn from 0 s to 1.5 s.</p><p id="P39">The network received an input signal consisting of a two-dimensional target signal and a one-dimensional timing signal. The target signal was defined as (<italic>p<sup>end</sup></italic> — <italic>p<sup>start</sup></italic>). It was delivered to the network 0.2 s after trial onset, and was fixed until the end of the trial. The timing signal was given in form of a constant, and was switched to zero at the time corresponding to the “go” signal, which varied between 0.2 s and 1.7 s for the random reaching task used during training (that is, when the network generated reaches of random direction and lengths up to 8.5cm), and between 1.2 s and 1.7 s for the centre-out-reaching task.</p><p id="P40">As mentioned above, during the last phase of the initial training phase we included brief “bump” perturbations to the output of the network so it had to learn to use the feedback input to correct its output online. In 75 % of the trials, we added a pulse of 0.1 s duration and amplitude 10 cm/s on the velocity output of the model, either in <italic>x</italic> or <italic>y</italic> direction. This pulse occurred randomly between 0.2 s and 1.9 s after trial onset, to mimic perturbations at various movement periods.</p><p id="P41">After training, we tested the model on a centre-out-reaching task with eight targets equally distributed on a circle of 5 cm radius. In this task, the go signal occurred randomly between 1.2 s and 1.7 s, as before.</p><p id="P42">To probe online feedback correction and motor adaptation, we introduced a visuomotor rotation (VR) perturbation that rotated the output of the model by 30°, similar to previous visuomotor rotation experiments in humans<sup><xref ref-type="bibr" rid="R2">2</xref></sup> and monkeys<sup><xref ref-type="bibr" rid="R51">51</xref></sup>.</p></sec><sec id="S17"><title>Neural recordings from behaving monkeys</title><p id="P43">We reanalysed previously published data from two macaque monkeys performing a visuomotor adaptation reaching task with a cursor controlled by movements of a manipulandum. In each session the monkeys performed 154–217 successful trials of an eight target centre-out reaching task. After this baseline period, a 30° rotation (clockwise or counter clockwise, depending on the session) of the cursor position feedback presented on a screen was introduced. Finally, after 219–316 successful adaptation trials, the perturbation was removed in order to study de-adaptation during this “washout” period.</p><p id="P44">We analysed the activity of populations of putative single neurons recorded using 96-channel microelectrode arrays chronically implanted in the arm area of primary motor cortex (details in <xref ref-type="bibr" rid="R51">Ref. 51</xref>). We quantified trial-by-trial learning by examining the monkey’s hand trajectories, which was tracked by recording the position of the handle of the manipulandum. All surgical and behavioural procedures were approved by the Institutional Animal Care and Use Committee at Northwestern University (Chicago, USA).</p></sec></sec><sec id="S18"><title>Data analysis</title><sec id="S19"><title>Movement error metrics to quantify learning</title><p id="P45">The take-off angle was defined as the initial reach direction, calculated between the go cue and peak velocity. When pooling the angular error across monkeys in <xref ref-type="fig" rid="F2">Figure 2</xref>, we smoothed the mean across all sessions from both animals using a Gaussian filter with s.d. of ten trials.</p><p id="P46">When studying how error magnitude influences learning in the next trial (<xref ref-type="fig" rid="F3">Figure 3A</xref>), we computed the Pearson’s correlation (<italic>pearsonr</italic> from <monospace>scipy.stats</monospace> package) between the absolute value of the angular error and the difference in angular error between the current trial and the next trial. To assess whether these correlations were significant, we compared them to a null distribution under the assumption of joint normality. The movement error in <xref ref-type="fig" rid="F3">Figure 3B</xref> is defined as the averaged squared position error <italic>ϵ</italic>.</p></sec><sec id="S20"><title>Analysis of learning timescales</title><p id="P47">We investigated whether our model’s learning time course is composed of two processes with different timescales by implementing the analysis used in earlier studies <xref ref-type="bibr" rid="R63">Ref. 63</xref>, <xref ref-type="bibr" rid="R64">64</xref>. We fitted a dual-rate state-space model to the angular error data, defined as below: <disp-formula id="FD6"><label>(1)</label><mml:math id="M9"><mml:msub><mml:mi>x</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mi>e</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula> <disp-formula id="FD7"><label>(2)</label><mml:math id="M10"><mml:msub><mml:mi>x</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mi>e</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula> <disp-formula id="FD8"><label>(3)</label><mml:math id="M11"><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula> subject to the constraints <italic>A<sub>f</sub></italic> &lt; <italic>A<sub>s</sub></italic>, <italic>B<sub>f</sub></italic> &gt; <italic>B<sub>s</sub></italic>. <italic>A<sub>f</sub></italic> and <italic>B<sub>f</sub></italic> are the parameters describing the fast process, whereas <italic>A<sub>s</sub></italic> and <italic>B<sub>s</sub></italic> are the parameters describing the slow process. The <italic>Adaptation</italic> variable, <italic>x</italic> (cf. <xref ref-type="fig" rid="F3">Figure 3C</xref>), is defined as the amount of change in the take-off reaching direction. The error <italic>e</italic> is given by the take-off angular error scaled to [-1,1]. The four parameters <italic>A<sub>f</sub></italic>, <italic>A<sub>s</sub></italic>, <italic>B<sub>f</sub></italic>, <italic>B<sub>s</sub></italic> were obtained by fitting the model to the adaptation time course observed in the simulated data. For this, we used the <italic>Sequential Least Squares Programming</italic> method from the <monospace>scipy</monospace> optimization package.</p></sec><sec id="S21"><title>Analysis of temporally dissociable adaptation-related activity changes</title><p id="P48">We sought to identify a “neural signature” of adaptation-related activity changes in the network that could be seen in neural recordings from behaving monkeys. To this end, we probed three different “behavioural epochs” as follows (<xref ref-type="fig" rid="F5">Figure 5A</xref>). For the model data, we simulated 200 baseline trials (epoch A in <xref ref-type="fig" rid="F5">Figure 5A</xref>), 200 trials beginning immediately after perturbation onset (prior to any learning; epoch B), and 200 trials beginning 300 trials after the onset of learning (epoch C). For the monkey data, we considered the following: 100 baseline trials (epoch A), the first 100 trials after perturbation onset, during which monkeys were beginning to adapt (epoch B), and the last 100 perturbation trials, when monkeys had learned to counteract the perturbation (epoch C). Note that for the monkey data, the feedback epoch B was not as clearly defined as for the simulation data, since the monkeys had already started learning within epoch B.</p><p id="P49">The activity change in the simulation data was calculated by measuring, for each unit, the activity difference between all pairs of behavioural epochs (A, B, C in <xref ref-type="fig" rid="F5">Figure 5A</xref>). For this, we simulated the same trials (using the same random seed) without perturbations (A), with perturbations (B), and with perturbations after the network had adapted (C). To identify the time point within a trial at which the largest activity change happened, we computed the absolute value of activity change, and averaged the respective differences across neurons and trials. This resulted in the time courses shown in <xref ref-type="fig" rid="F5">Figure 5A,B</xref>. For the monkey data (<xref ref-type="fig" rid="F5">Figure 5E</xref>), since we could not have the exact trials in different epochs, we calculated the difference between trials in different epochs in an all-to-all fashion, then averaged over those trial pairs.</p><p id="P50">After an initial analysis of the average activity change across all ten RNN models, we could define a “feedforward” time point (0.5 s after the go cue), in which the largest activity change between late adaptation (epoch C) and early adaptation (epoch B) happened, and a “feedback” time point (0.8 s after the go cue), in which the largest activity change between early adaptation (epoch B) and baseline (epoch A) happened. These values were very similar to those identified in the analysis of neural recordings from monkey M1: feedforward time point, 0.4 s after the go cue; feedback time point, 0.8 s after the go cue. For the pooled analysis presented in <xref ref-type="fig" rid="F5">Figure 5F,G</xref>, we took the values of the activity change traces at those time points and calculated the ratio between the value at the feedforward time point and the value at the feedback time point.</p></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary Figures</label><media xlink:href="EMS155700-supplement-Supplementary_Figures.pdf" mimetype="application" mime-subtype="pdf" id="d84aAdGbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S22"><title>Acknowledgements</title><p>L.E.M. received funding from the NIH National Institute of Neurological Disorders and Stroke (NS053603 and NS074044). C.C received funding from the BBSRC (BB/N013956/1 and BB/N019008/1), the EPSRC (EP/R035806/1), the Wellcome Trust (200790/Z/16/Z), and Simons Foundation (564408). J.A.G. received funding from the EPSRC (EP/T020970/1) and the European Research Council (ERC-2020-StG-949660). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p></ack><sec id="S23" sec-type="data-availability"><title>Data availability</title><p id="P51">The data that support the findings in this study are available from the corresponding authors upon reasonable request.</p><sec id="S24" sec-type="data-availability"><title>Code availability</title><p id="P52">All code to reproduce the main simulation results will be made freely available upon publication on GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/babaf/feedback-driven-plasticity">https://github.com/babaf/feedback-driven-plasticity</ext-link>).</p></sec></sec><fn-group><fn id="FN2" fn-type="con"><p id="P53"><bold>Author contributions</bold></p><p id="P54">B.F., C.C. and J.A.G. devised the project. M.G.P. and L.E.M. provided the monkey datasets. B.F. ran simulations, analysed data and generated figures. B.F., C.C. and J.A.G. interpreted the data. B.F., C.C. and J.A.G. wrote the manuscript. All authors discussed and edited the manuscript. C.C. and J.A.G. jointly supervised the work.</p></fn><fn id="FN3" fn-type="conflict"><p id="P55"><bold>Competing Interests</bold></p><p id="P56">J.A.G. receives funding from Meta Platform Technologies, LLC.</p></fn></fn-group><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wise</surname><given-names>SP</given-names></name><name><surname>Moody</surname><given-names>SL</given-names></name><name><surname>Blomstrom</surname><given-names>KJ</given-names></name><name><surname>Mitz</surname><given-names>AR</given-names></name></person-group><article-title>Changes in motor cortical activity during visuomotor adaptation</article-title><source>Experimental Brain Research</source><year>1998</year><volume>121</volume><issue>3</issue><fpage>285</fpage><lpage>299</lpage></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krakauer</surname><given-names>John W</given-names></name><name><surname>Pine</surname><given-names>Zachary M</given-names></name><name><surname>Ghilardi</surname><given-names>Maria-Felice</given-names></name><name><surname>Ghez</surname><given-names>Claude</given-names></name></person-group><article-title>Learning of visuomotor transformations for vectorial planning of reaching trajectories</article-title><source>Journal of Neuroscience</source><year>2000</year><volume>20</volume><issue>23</issue><fpage>8916</fpage><lpage>8924</lpage></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thoroughman</surname><given-names>Kurt A</given-names></name><name><surname>Shadmehr</surname><given-names>Reza</given-names></name></person-group><article-title>Learning of action through adaptive combination of motor primitives</article-title><source>Nature</source><year>2000</year><volume>407</volume><issue>6805</issue><fpage>742</fpage><lpage>747</lpage></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scott</surname><given-names>Stephen H</given-names></name></person-group><article-title>Optimal feedback control and the neural basis of volitional motor control</article-title><source>Nature Reviews Neuroscience</source><year>2004</year><volume>5</volume><issue>7</issue><fpage>532</fpage><lpage>545</lpage></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadmehr</surname><given-names>Reza</given-names></name><name><surname>Krakauer</surname><given-names>John W</given-names></name></person-group><article-title>A computational neuroanatomy for motor control</article-title><source>Experimental brain research</source><year>2008</year><volume>185</volume><issue>3</issue><fpage>359</fpage><lpage>381</lpage></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hatsopoulos</surname><given-names>Nicholas G</given-names></name><name><surname>Suminski</surname><given-names>Aaron J</given-names></name></person-group><article-title>Sensing with the motor cortex</article-title><source>Neuron</source><year>2011</year><volume>72</volume><issue>3</issue><fpage>477</fpage><lpage>487</lpage></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pruszynski</surname><given-names>J Andrew</given-names></name><name><surname>Kurtzer</surname><given-names>Isaac</given-names></name><name><surname>Nashed</surname><given-names>Joseph Y</given-names></name><name><surname>Omrani</surname><given-names>Mohsen</given-names></name><name><surname>Brouwer</surname><given-names>Brenda</given-names></name><name><surname>Scott</surname><given-names>Stephen H</given-names></name></person-group><article-title>Primary motor cortex underlies multi-joint integration for fast feedback control</article-title><source>Nature</source><year>2011</year><volume>478</volume><issue>7369</issue><fpage>387</fpage><lpage>390</lpage></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scott</surname><given-names>Stephen H</given-names></name></person-group><article-title>The computational and neural basis of voluntary motor control and planning</article-title><source>Trends in cognitive sciences</source><year>2012</year><volume>16</volume><issue>11</issue><fpage>541</fpage><lpage>549</lpage></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nashed</surname><given-names>Joseph Y</given-names></name><name><surname>Crevecoeur</surname><given-names>Frédéric</given-names></name><name><surname>Scott</surname><given-names>Stephen H</given-names></name></person-group><article-title>Influence of the behavioral goal and environmental obstacles on rapid feedback responses</article-title><source>Journal of neurophysiology</source><year>2012</year><volume>108</volume><issue>4</issue><fpage>999</fpage><lpage>1009</lpage></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andrew Pruszynski</surname><given-names>J</given-names></name><name><surname>Omrani</surname><given-names>Mohsen</given-names></name><name><surname>Scott</surname><given-names>Stephen H</given-names></name></person-group><article-title>Goal-dependent modulation of fast feedback responses in primary motor cortex</article-title><source>Journal of Neuroscience</source><year>2014</year><volume>34</volume><issue>13</issue><fpage>4608</fpage><lpage>4617</lpage></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scott</surname><given-names>Stephen H</given-names></name><name><surname>Cluff</surname><given-names>Tyler</given-names></name><name><surname>Lowrey</surname><given-names>Catherine R</given-names></name><name><surname>Takei</surname><given-names>Tomohiko</given-names></name></person-group><article-title>Feedback control during voluntary motor actions</article-title><source>Current opinion in neurobiology</source><year>2015</year><volume>33</volume><fpage>85</fpage><lpage>94</lpage></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scott</surname><given-names>Stephen H</given-names></name></person-group><article-title>A functional taxonomy of bottom-up sensory feedback processing for motor actions</article-title><source>Trends in neurosciences</source><year>2016</year><volume>39</volume><issue>8</issue><fpage>512</fpage><lpage>526</lpage></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Omrani</surname><given-names>Mohsen</given-names></name><name><surname>Murnaghan</surname><given-names>Chantelle D</given-names></name><name><surname>Andrew Pruszynski</surname><given-names>J</given-names></name><name><surname>Scott</surname><given-names>Stephen H</given-names></name></person-group><article-title>Distributed task-specific processing of somatosensory feedback for voluntary motor control</article-title><source>Elife</source><year>2016</year><volume>5</volume><elocation-id>e13141</elocation-id></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Inoue</surname><given-names>Masato</given-names></name><name><surname>Uchimura</surname><given-names>Motoaki</given-names></name><name><surname>Kitazawa</surname><given-names>Shigeru</given-names></name></person-group><article-title>Error signals in motor cortices drive adaptation in reaching</article-title><source>Neuron</source><year>2016</year><volume>90</volume><issue>5</issue><fpage>1114</fpage><lpage>1126</lpage></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kalidindi</surname><given-names>Hari Teja</given-names></name><name><surname>Cross</surname><given-names>Kevin P</given-names></name><name><surname>Lillicrap</surname><given-names>Timothy P</given-names></name><name><surname>Omrani</surname><given-names>Mohsen</given-names></name><name><surname>Falotico</surname><given-names>Egidio</given-names></name><name><surname>Sabes</surname><given-names>Philip N</given-names></name><name><surname>Scott</surname><given-names>Stephen H</given-names></name></person-group><article-title>Rotational dynamics in motor cortex are consistent with a feedback controller</article-title><source>Elife</source><year>2021</year><volume>10</volume><elocation-id>e67256</elocation-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cross</surname><given-names>Kevin P</given-names></name><name><surname>Cook</surname><given-names>Douglas J</given-names></name><name><surname>Scott</surname><given-names>Stephen H</given-names></name></person-group><article-title>Convergence of proprioceptive and visual feedback on neurons in primary motor cortex</article-title><source>bioRxiv</source><year>2021</year></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takei</surname><given-names>Tomohiko</given-names></name><name><surname>Lomber</surname><given-names>Stephen G</given-names></name><name><surname>Cook</surname><given-names>Douglas J</given-names></name><name><surname>Scott</surname><given-names>Stephen H</given-names></name></person-group><article-title>Transient deactivation of dorsal premotor cortex or parietal area 5 impairs feedback control of the limb in macaques</article-title><source>Current Biology</source><year>2021</year><volume>31</volume><issue>7</issue><fpage>1476</fpage><lpage>1487</lpage></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolpert</surname><given-names>Daniel M</given-names></name><name><surname>Diedrichsen</surname><given-names>Jörn</given-names></name><name><surname>Randall Flanagan</surname><given-names>J</given-names></name></person-group><article-title>Principles of sensorimotor learning</article-title><source>Nature reviews neuroscience</source><year>2011</year><volume>12</volume><issue>12</issue><fpage>739</fpage><lpage>751</lpage></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Izawa</surname><given-names>Jun</given-names></name><name><surname>Shadmehr</surname><given-names>Reza</given-names></name></person-group><article-title>Learning from sensory and reward prediction errors during motor adaptation</article-title><source>PLoS computational biology</source><year>2011</year><volume>7</volume><issue>3</issue><elocation-id>e1002012</elocation-id></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kawato</surname><given-names>Mitsuo</given-names></name><name><surname>Furukawa</surname><given-names>Kazunori</given-names></name><name><surname>Suzuki</surname><given-names>Ryoji</given-names></name></person-group><article-title>A hierarchical neural-network model for control and learning of voluntary movement</article-title><source>Biological cybernetics</source><year>1987</year><volume>57</volume><issue>3</issue><fpage>169</fpage><lpage>185</lpage></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kawato</surname><given-names>Mitsuo</given-names></name></person-group><chapter-title>Feedback-error-learning neural network for supervised motor learning</chapter-title><source>Advanced neural computers</source><publisher-name>Elsevier</publisher-name><year>1990</year><fpage>365</fpage><lpage>372</lpage></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kawato</surname><given-names>Mitsuo</given-names></name><name><surname>Gomi</surname><given-names>Hiroaki</given-names></name></person-group><article-title>A computational model of four regions of the cerebellum based on feedback-error learning</article-title><source>Biological cybernetics</source><year>1992</year><volume>68</volume><issue>2</issue><fpage>95</fpage><lpage>103</lpage></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paz</surname><given-names>Rony</given-names></name><name><surname>Boraud</surname><given-names>Thomas</given-names></name><name><surname>Natan</surname><given-names>Chen</given-names></name><name><surname>Bergman</surname><given-names>Hagai</given-names></name><name><surname>Vaadia</surname><given-names>Eilon</given-names></name></person-group><article-title>Preparatory activity in motor cortex reflects learning of local visuomotor skills</article-title><source>Nature neuroscience</source><year>2003</year><volume>6</volume><issue>8</issue><fpage>882</fpage><lpage>890</lpage></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diedrichsen</surname><given-names>Jöorn</given-names></name><name><surname>Hashambhoy</surname><given-names>Yasmin</given-names></name><name><surname>Rane</surname><given-names>Tushar</given-names></name><name><surname>Shadmehr</surname><given-names>Reza</given-names></name></person-group><article-title>Neural correlates of reach errors</article-title><source>Journal of Neuroscience</source><year>2005</year><volume>25</volume><issue>43</issue><fpage>9919</fpage><lpage>9931</lpage></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tseng</surname><given-names>Ya-weng</given-names></name><name><surname>Diedrichsen</surname><given-names>Joern</given-names></name><name><surname>Krakauer</surname><given-names>John W</given-names></name><name><surname>Shadmehr</surname><given-names>Reza</given-names></name><name><surname>Bastian</surname><given-names>Amy J</given-names></name></person-group><article-title>Sensory prediction errors drive cerebellum-dependent adaptation of reaching</article-title><source>Journal of neurophysiology</source><year>2007</year><volume>98</volume><issue>1</issue><fpage>54</fpage><lpage>62</lpage></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hadipour-Niktarash</surname><given-names>Arash</given-names></name><name><surname>Lee</surname><given-names>Christine K</given-names></name><name><surname>Desmond</surname><given-names>John E</given-names></name><name><surname>Shadmehr</surname><given-names>Reza</given-names></name></person-group><article-title>Impairment of retention but not acquisition of a visuomotor skill through time-dependent disruption of primary motor cortex</article-title><source>Journal of Neuroscience</source><year>2007</year><volume>27</volume><issue>49</issue><fpage>13413</fpage><lpage>13419</lpage></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>Tonghui</given-names></name><name><surname>Yu</surname><given-names>Xinzhu</given-names></name><name><surname>Perlik</surname><given-names>Andrew J</given-names></name><name><surname>Tobin</surname><given-names>Willie F</given-names></name><name><surname>Zweig</surname><given-names>Jonathan A</given-names></name><name><surname>Tennant</surname><given-names>Kelly</given-names></name><name><surname>Jones</surname><given-names>Theresa</given-names></name><name><surname>Zuo</surname><given-names>Yi</given-names></name></person-group><article-title>Rapid formation and selective stabilization of synapses for enduring motor memories</article-title><source>Nature</source><year>2009</year><volume>462</volume><issue>7275</issue><fpage>915</fpage><lpage>919</lpage></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rabe</surname><given-names>Kasja</given-names></name><name><surname>Livne</surname><given-names>Ofer</given-names></name><name><surname>Gizewski</surname><given-names>Elke R</given-names></name><name><surname>Aurich</surname><given-names>Volker</given-names></name><name><surname>Beck</surname><given-names>Andreas</given-names></name><name><surname>Timmann</surname><given-names>Dagmar</given-names></name><name><surname>Donchin</surname><given-names>Opher</given-names></name></person-group><article-title>Adaptation to visuomotor rotation and force field perturbation is correlated to different brain areas in patients with cerebellar degeneration</article-title><source>Journal of neurophysiology</source><year>2009</year><volume>101</volume><issue>4</issue><fpage>1961</fpage><lpage>1971</lpage></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tanaka</surname><given-names>Hirokazu</given-names></name><name><surname>Sejnowski</surname><given-names>Terrence J</given-names></name><name><surname>Krakauer</surname><given-names>John W</given-names></name></person-group><article-title>Adaptation to visuomotor rotation through interaction between posterior parietal and motor cortical areas</article-title><source>Journal of neurophysiology</source><year>2009</year><volume>102</volume><issue>5</issue><fpage>2921</fpage><lpage>2932</lpage></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saijo</surname><given-names>Naoki</given-names></name><name><surname>Gomi</surname><given-names>Hiroaki</given-names></name></person-group><article-title>Multiple motor learning strategies in visuomotor rotation</article-title><source>PLoS One</source><year>2010</year><volume>5</volume><issue>2</issue><elocation-id>e9399</elocation-id></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Galea</surname><given-names>Joseph M</given-names></name><name><surname>Vazquez</surname><given-names>Alejandro</given-names></name><name><surname>Pasricha</surname><given-names>Neel</given-names></name><name><surname>de Xivry</surname><given-names>Jean-Jacques Orban</given-names></name><name><surname>Celnik</surname><given-names>Pablo</given-names></name></person-group><article-title>Dissociating the roles of the cerebellum and motor cortex during adaptive learning: the motor cortex retains what the cerebellum learns</article-title><source>Cerebral cortex</source><year>2011</year><volume>21</volume><issue>8</issue><fpage>1761</fpage><lpage>1770</lpage></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schlerf</surname><given-names>John E</given-names></name><name><surname>Galea</surname><given-names>Joseph M</given-names></name><name><surname>Bastian</surname><given-names>Amy J</given-names></name><name><surname>Celnik</surname><given-names>Pablo A</given-names></name></person-group><article-title>Dynamic modulation of cerebellar excitability for abrupt, but not gradual, visuomotor adaptation</article-title><source>Journal of Neuroscience</source><year>2012</year><volume>32</volume><issue>34</issue><fpage>11610</fpage><lpage>11617</lpage></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Xivry</surname><given-names>Jean-Jacques Orban</given-names></name><name><surname>Criscimagna-Hemminger</surname><given-names>Sarah E</given-names></name><name><surname>Shadmehr</surname><given-names>Reza</given-names></name></person-group><article-title>Contributions of the motor cortex to adaptive control of reaching depend on the perturbation schedule</article-title><source>Cerebral Cortex</source><year>2011</year><volume>21</volume><issue>7</issue><fpage>1475</fpage><lpage>1484</lpage></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krakauer</surname><given-names>John W</given-names></name><name><surname>Mazzoni</surname><given-names>Pietro</given-names></name></person-group><article-title>Human sensorimotor learning: adaptation, skill, and beyond</article-title><source>Current opinion in neurobiology</source><year>2011</year><volume>21</volume><issue>4</issue><fpage>636</fpage><lpage>644</lpage></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Ling</given-names></name><name><surname>Conner</surname><given-names>James M</given-names></name><name><surname>Rickert</surname><given-names>Jessica</given-names></name><name><surname>Tuszynski</surname><given-names>Mark H</given-names></name></person-group><article-title>Structural plasticity within highly specific neuronal populations identifies a unique parcellation of motor learning in the adult brain</article-title><source>Proceedings of the National Academy of Sciences</source><year>2011</year><volume>108</volume><issue>6</issue><fpage>2545</fpage><lpage>2550</lpage></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kawai</surname><given-names>Risa</given-names></name><name><surname>Markman</surname><given-names>Timothy</given-names></name><name><surname>Poddar</surname><given-names>Rajesh</given-names></name><name><surname>Ko</surname><given-names>Raymond</given-names></name><name><surname>Fantana</surname><given-names>Antoniu L</given-names></name><name><surname>Dhawale</surname><given-names>Ashesh K</given-names></name><name><surname>Kampff</surname><given-names>Adam R</given-names></name><name><surname>Ölveczky</surname><given-names>Bence P</given-names></name></person-group><article-title>Motor cortex is required for learning but not for executing a motor skill</article-title><source>Neuron</source><year>2015</year><volume>86</volume><issue>3</issue><fpage>800</fpage><lpage>812</lpage></element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stavisky</surname><given-names>Sergey D</given-names></name><name><surname>Kao</surname><given-names>Jonathan C</given-names></name><name><surname>Ryu</surname><given-names>Stephen I</given-names></name><name><surname>Shenoy</surname><given-names>Krishna V</given-names></name></person-group><article-title>Motor cortical visuomotor feedback activity is initially isolated from downstream targets in output-null neural state space dimensions</article-title><source>Neuron</source><year>2017</year><volume>95</volume><issue>1</issue><fpage>195</fpage><lpage>208</lpage></element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathis</surname><given-names>Mackenzie Weygandt</given-names></name><name><surname>Mathis</surname><given-names>Alexander</given-names></name><name><surname>Uchida</surname><given-names>Naoshige</given-names></name></person-group><article-title>Somatosensory cortex plays an essential role in forelimb motor adaptation in mice</article-title><source>Neuron</source><year>2017</year><volume>93</volume><issue>6</issue><fpage>1493</fpage><lpage>1503</lpage></element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Golub</surname><given-names>Matthew D</given-names></name><name><surname>Sadtler</surname><given-names>Patrick T</given-names></name><name><surname>Oby</surname><given-names>Emily R</given-names></name><name><surname>Quick</surname><given-names>Kristin M</given-names></name><name><surname>Ryu</surname><given-names>Stephen I</given-names></name><name><surname>Tyler-Kabara</surname><given-names>Elizabeth C</given-names></name><name><surname>Batista</surname><given-names>Aaron P</given-names></name><name><surname>Chase</surname><given-names>Steven M</given-names></name><name><surname>Yu</surname><given-names>Byron M</given-names></name></person-group><article-title>Learning by neural reassociation</article-title><source>Nature neuroscience</source><year>2018</year><volume>21</volume><issue>4</issue><fpage>607</fpage><lpage>616</lpage></element-citation></ref><ref id="R40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Inoue</surname><given-names>Masato</given-names></name><name><surname>Kitazawa</surname><given-names>Shigeru</given-names></name></person-group><article-title>Motor error in parietal area 5 and target error in area 7 drive distinctive adaptation in reaching</article-title><source>Current Biology</source><year>2018</year><volume>28</volume><issue>14</issue><fpage>2250</fpage><lpage>2262</lpage></element-citation></ref><ref id="R41"><label>41</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herzfeld</surname><given-names>David J</given-names></name><name><surname>Kojima</surname><given-names>Yoshiko</given-names></name><name><surname>Soetedjo</surname><given-names>Robijanto</given-names></name><name><surname>Shadmehr</surname><given-names>Reza</given-names></name></person-group><article-title>Encoding of error and learning to correct that error by the purkinje cells of the cerebellum</article-title><source>Nature neuroscience</source><year>2018</year><volume>21</volume><issue>5</issue><fpage>736</fpage><lpage>743</lpage></element-citation></ref><ref id="R42"><label>42</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vyas</surname><given-names>Saurabh</given-names></name><name><surname>Even-Chen</surname><given-names>Nir</given-names></name><name><surname>Stavisky</surname><given-names>Sergey D</given-names></name><name><surname>Ryu</surname><given-names>Stephen I</given-names></name><name><surname>Nuyujukian</surname><given-names>Paul</given-names></name><name><surname>Shenoy</surname><given-names>Krishna V</given-names></name></person-group><article-title>Neural population dynamics underlying motor learning transfer</article-title><source>Neuron</source><year>2018</year><volume>97</volume><issue>5</issue><fpage>1177</fpage><lpage>1186</lpage></element-citation></ref><ref id="R43"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vyas</surname><given-names>Saurabh</given-names></name><name><surname>O’Shea</surname><given-names>Daniel J</given-names></name><name><surname>Ryu</surname><given-names>Stephen I</given-names></name><name><surname>Shenoy</surname><given-names>Krishna V</given-names></name></person-group><article-title>Causal role of motor preparation during error-driven learning</article-title><source>Neuron</source><year>2020</year><volume>106</volume><issue>2</issue><fpage>329</fpage><lpage>339</lpage></element-citation></ref><ref id="R44"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tzvi</surname><given-names>Elinor</given-names></name><name><surname>Koeth</surname><given-names>Fabian</given-names></name><name><surname>Karabanov</surname><given-names>Anke N</given-names></name><name><surname>Siebner</surname><given-names>Hartwig R</given-names></name><name><surname>Krämer</surname><given-names>Ulrike M</given-names></name></person-group><article-title>Cerebellar–premotor cortex interactions underlying visuomotor adaptation</article-title><source>NeuroImage</source><year>2020</year><volume>220</volume><elocation-id>117142</elocation-id></element-citation></ref><ref id="R45"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sohn</surname><given-names>Hansem</given-names></name><name><surname>Meirhaeghe</surname><given-names>Nicolas</given-names></name><name><surname>Rajalingham</surname><given-names>Rishi</given-names></name><name><surname>Jazayeri</surname><given-names>Mehrdad</given-names></name></person-group><article-title>A network perspective on sensorimotor learning</article-title><source>Trends in Neurosciences</source><year>2021</year><volume>44</volume><issue>3</issue><fpage>170</fpage><lpage>181</lpage></element-citation></ref><ref id="R46"><label>46</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krakauer</surname><given-names>John W</given-names></name><name><surname>Ghilardi</surname><given-names>Maria-Felice</given-names></name><name><surname>Ghez</surname><given-names>Claude</given-names></name></person-group><article-title>Independent learning of internal models for kinematic and dynamic control of reaching</article-title><source>Nature neuroscience</source><year>1999</year><volume>2</volume><issue>11</issue><fpage>1026</fpage><lpage>1031</lpage></element-citation></ref><ref id="R47"><label>47</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadmehr</surname><given-names>Reza</given-names></name><name><surname>Mussa-Ivaldi</surname><given-names>Ferdinando A</given-names></name></person-group><article-title>Adaptive representation of dynamics during learning of a motor task</article-title><source>Journal of neuroscience</source><year>1994</year><volume>14</volume><issue>5</issue><fpage>3208</fpage><lpage>3224</lpage></element-citation></ref><ref id="R48"><label>48</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolpert</surname><given-names>Daniel M</given-names></name><name><surname>Ghahramani</surname><given-names>Zoubin</given-names></name><name><surname>Jordan</surname><given-names>Michael I</given-names></name></person-group><article-title>Are arm trajectories planned in kinematic or dynamic coordinates? an adaptation study</article-title><source>Experimental brain research</source><year>1995</year><volume>103</volume><issue>3</issue><fpage>460</fpage><lpage>470</lpage></element-citation></ref><ref id="R49"><label>49</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadmehr</surname><given-names>Reza</given-names></name><name><surname>Moussavi</surname><given-names>Zahra MK</given-names></name></person-group><article-title>Spatial generalization from learning dynamics of reaching movements</article-title><source>Journal of Neuroscience</source><year>2000</year><volume>20</volume><issue>20</issue><fpage>7807</fpage><lpage>7815</lpage></element-citation></ref><ref id="R50"><label>50</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadmehr</surname><given-names>Reza</given-names></name><name><surname>Smith</surname><given-names>Maurice A</given-names></name><name><surname>Krakauer</surname><given-names>John W</given-names></name></person-group><article-title>Error correction, sensory prediction, and adaptation in motor control</article-title><source>Annual review of neuroscience</source><year>2010</year></element-citation></ref><ref id="R51"><label>51</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perich</surname><given-names>Matthew G</given-names></name><name><surname>Gallego</surname><given-names>Juan A</given-names></name><name><surname>Miller</surname><given-names>Lee E</given-names></name></person-group><article-title>A neural population mechanism for rapid learning</article-title><source>Neuron</source><year>2018</year><volume>100</volume><issue>4</issue><fpage>964</fpage><lpage>976</lpage></element-citation></ref><ref id="R52"><label>52</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Albert</surname><given-names>Scott T</given-names></name><name><surname>Shadmehr</surname><given-names>Reza</given-names></name></person-group><article-title>The neural feedback response to error as a teaching signal for the motor learning system</article-title><source>Journal of Neuroscience</source><year>2016</year><volume>36</volume><issue>17</issue><fpage>4832</fpage><lpage>4845</lpage></element-citation></ref><ref id="R53"><label>53</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hadjiosif</surname><given-names>Alkis M</given-names></name><name><surname>Krakauer</surname><given-names>John W</given-names></name><name><surname>Haith</surname><given-names>Adrian M</given-names></name></person-group><article-title>Did we get sensorimotor adaptation wrong? implicit adaptation as direct policy updating rather than forward-model-based learning</article-title><source>Journal of Neuroscience</source><year>2021</year><volume>41</volume><issue>12</issue><fpage>2747</fpage><lpage>2761</lpage></element-citation></ref><ref id="R54"><label>54</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mante</surname><given-names>Valerio</given-names></name><name><surname>Sussillo</surname><given-names>David</given-names></name><name><surname>Shenoy</surname><given-names>Krishna V</given-names></name><name><surname>Newsome</surname><given-names>William T</given-names></name></person-group><article-title>Context-dependent computation by recurrent dynamics in prefrontal cortex</article-title><source>nature</source><year>2013</year><volume>503</volume><issue>7474</issue><fpage>78</fpage><lpage>84</lpage></element-citation></ref><ref id="R55"><label>55</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sussillo</surname><given-names>David</given-names></name><name><surname>Churchland</surname><given-names>Mark M</given-names></name><name><surname>Kaufman</surname><given-names>Matthew T</given-names></name><name><surname>Shenoy</surname><given-names>Krishna V</given-names></name></person-group><article-title>A neural network that finds a naturalistic solution for the production of muscle activity</article-title><source>Nature neuroscience</source><year>2015</year><volume>18</volume><issue>7</issue><fpage>1025</fpage><lpage>1033</lpage></element-citation></ref><ref id="R56"><label>56</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rajan</surname><given-names>Kanaka</given-names></name><name><surname>Harvey</surname><given-names>Christopher D</given-names></name><name><surname>Tank</surname><given-names>David W</given-names></name></person-group><article-title>Recurrent network models of sequence generation and memory</article-title><source>Neuron</source><year>2016</year><volume>90</volume><issue>1</issue><fpage>128</fpage><lpage>142</lpage></element-citation></ref><ref id="R57"><label>57</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Francis Song</surname><given-names>H</given-names></name><name><surname>Yang</surname><given-names>Guangyu R</given-names></name><name><surname>Wang</surname><given-names>Xiao-Jing</given-names></name></person-group><article-title>Reward-based training of recurrent neural networks for cognitive and value-based tasks</article-title><source>Elife</source><year>2017</year><volume>6</volume><elocation-id>e21492</elocation-id></element-citation></ref><ref id="R58"><label>58</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Jing</given-names></name><name><surname>Narain</surname><given-names>Devika</given-names></name><name><surname>Hosseini</surname><given-names>Eghbal A</given-names></name><name><surname>Jazayeri</surname><given-names>Mehrdad</given-names></name></person-group><article-title>Flexible timing by temporal scaling of cortical responses</article-title><source>Nature neuroscience</source><year>2018</year><volume>21</volume><issue>1</issue><fpage>102</fpage><lpage>110</lpage></element-citation></ref><ref id="R59"><label>59</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Michaels</surname><given-names>Jonathan A</given-names></name><name><surname>Schaffelhofer</surname><given-names>Stefan</given-names></name><name><surname>Agudelo-Toro</surname><given-names>Andres</given-names></name><name><surname>Scherberger</surname><given-names>Hansjörg</given-names></name></person-group><article-title>A goal-driven modular neural network predicts parietofrontal neural dynamics during grasping</article-title><source>Proceedings of the national academy of sciences</source><year>2020</year><volume>117</volume><issue>50</issue><fpage>32124</fpage><lpage>32135</lpage></element-citation></ref><ref id="R60"><label>60</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feulner</surname><given-names>Barbara</given-names></name><name><surname>Clopath</surname><given-names>Claudia</given-names></name></person-group><article-title>Neural manifold under plasticity in a goal driven learning behaviour</article-title><source>PLoS computational biology</source><year>2021</year><volume>17</volume><issue>2</issue><elocation-id>e1008621</elocation-id></element-citation></ref><ref id="R61"><label>61</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perich</surname><given-names>Matthew G</given-names></name><name><surname>Arlt</surname><given-names>Charlotte</given-names></name><name><surname>Soares</surname><given-names>Sofia</given-names></name><name><surname>Young</surname><given-names>Megan E</given-names></name><name><surname>Mosher</surname><given-names>Clayton P</given-names></name><name><surname>Minxha</surname><given-names>Juri</given-names></name><name><surname>Carter</surname><given-names>Eugene</given-names></name><name><surname>Rutishauser</surname><given-names>Ueli</given-names></name><name><surname>Rudebeck</surname><given-names>Peter H</given-names></name><name><surname>Harvey</surname><given-names>Christopher D</given-names></name><etal/></person-group><article-title>Inferring brainwide interactions using data-constrained recurrent neural network models</article-title><source>bioRxiv</source><year>2021</year><fpage>2020</fpage><lpage>12</lpage></element-citation></ref><ref id="R62"><label>62</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feulner</surname><given-names>Barbara</given-names></name><name><surname>Perich</surname><given-names>Matthew G</given-names></name><name><surname>Chowdhury</surname><given-names>Raeed H</given-names></name><name><surname>Miller</surname><given-names>Lee E</given-names></name><name><surname>Gallego</surname><given-names>Juan A</given-names></name><name><surname>Clopath</surname><given-names>Claudia</given-names></name></person-group><article-title>Small, correlated changes in synaptic connectivity may facilitate rapid motor learning</article-title><source>Nature communications</source><year>2022</year><volume>13</volume><issue>1</issue><fpage>1</fpage><lpage>14</lpage></element-citation></ref><ref id="R63"><label>63</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>Maurice A</given-names></name><name><surname>Ghazizadeh</surname><given-names>Ali</given-names></name><name><surname>Shadmehr</surname><given-names>Reza</given-names></name></person-group><article-title>Interacting adaptive processes with different timescales underlie short-term motor learning</article-title><source>PLoS biology</source><year>2006</year><volume>4</volume><issue>6</issue><elocation-id>e179</elocation-id></element-citation></ref><ref id="R64"><label>64</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McDougle</surname><given-names>Samuel D</given-names></name><name><surname>Bond</surname><given-names>Krista M</given-names></name><name><surname>Taylor</surname><given-names>Jordan A</given-names></name></person-group><article-title>Explicit and implicit processes constitute the fast and slow processes of sensorimotor learning</article-title><source>Journal of Neuroscience</source><year>2015</year><volume>35</volume><issue>26</issue><fpage>9568</fpage><lpage>9579</lpage></element-citation></ref><ref id="R65"><label>65</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fernandes</surname><given-names>Hugo L</given-names></name><name><surname>Stevenson</surname><given-names>Ian H</given-names></name><name><surname>Kording</surname><given-names>Konrad P</given-names></name></person-group><article-title>Generalization of stochastic visuomotor rotations</article-title><source>PLOS ONE</source><year>2012</year><month>08</month><volume>7</volume><issue>8</issue><fpage>1</fpage><lpage>9</lpage></element-citation></ref><ref id="R66"><label>66</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Albert</surname><given-names>Scott T</given-names></name><name><surname>Jang</surname><given-names>Jihoon</given-names></name><name><surname>Sheahan</surname><given-names>Hannah R</given-names></name><name><surname>Teunissen</surname><given-names>Lonneke</given-names></name><name><surname>Vandevoorde</surname><given-names>Koenraad</given-names></name><name><surname>Herzfeld</surname><given-names>David J</given-names></name><name><surname>Shadmehr</surname><given-names>Reza</given-names></name></person-group><article-title>An implicit memory of errors limits human sensorimotor adaptation</article-title><source>Nature human behaviour</source><year>2021</year><volume>5</volume><issue>7</issue><fpage>920</fpage><lpage>934</lpage></element-citation></ref><ref id="R67"><label>67</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kitago</surname><given-names>Tomoko</given-names></name><name><surname>Ryan</surname><given-names>Sophia L</given-names></name><name><surname>Mazzoni</surname><given-names>Pietro</given-names></name><name><surname>Krakauer</surname><given-names>John W</given-names></name><name><surname>Haith</surname><given-names>Adrian M</given-names></name></person-group><article-title>Unlearning versus savings in visuomotor adaptation: comparing effects of washout, passage of time, and removal of errors on motor memory</article-title><source>Frontiers in human neuroscience</source><year>2013</year><volume>7</volume><elocation-id>307</elocation-id></element-citation></ref><ref id="R68"><label>68</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Todorov</surname><given-names>Emanuel</given-names></name><name><surname>Jordan</surname><given-names>Michael I</given-names></name></person-group><article-title>Optimal feedback control as a theory of motor coordination</article-title><source>Nature neuroscience</source><year>2002</year><volume>5</volume><issue>11</issue><fpage>1226</fpage><lpage>1235</lpage></element-citation></ref><ref id="R69"><label>69</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedrich</surname><given-names>Johannes</given-names></name><name><surname>Golkar</surname><given-names>Siavash</given-names></name><name><surname>Farashahi</surname><given-names>Shiva</given-names></name><name><surname>Genkin</surname><given-names>Alexander</given-names></name><name><surname>Sengupta</surname><given-names>Anirvan</given-names></name><name><surname>Chklovskii</surname><given-names>Dmitri</given-names></name></person-group><article-title>Neural optimal feedback control with local learning rules</article-title><source>Advances in Neural Information Processing Systems</source><year>2021</year><volume>34</volume><fpage>16358</fpage><lpage>16370</lpage></element-citation></ref><ref id="R70"><label>70</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zador</surname><given-names>Anthony M</given-names></name></person-group><article-title>A critique of pure learning and what artificial neural networks can learn from animal brains</article-title><source>Nature communications</source><year>2019</year><volume>10</volume><issue>1</issue><fpage>1</fpage><lpage>7</lpage></element-citation></ref><ref id="R71"><label>71</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cisek</surname><given-names>Paul</given-names></name></person-group><article-title>Evolution of behavioural control from chordates to primates</article-title><source>Philosophical Transactions of the Royal Society B</source><year>2022</year><volume>377</volume><issue>1844</issue><elocation-id>20200522</elocation-id></element-citation></ref><ref id="R72"><label>72</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cisek</surname><given-names>Paul</given-names></name><name><surname>Hayden</surname><given-names>Benjamin Y</given-names></name></person-group><article-title>Neuroscience needs evolution</article-title><year>2022</year></element-citation></ref><ref id="R73"><label>73</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kao</surname><given-names>Ta-Chu</given-names></name><name><surname>Hennequin</surname><given-names>Guillaume</given-names></name></person-group><article-title>Neuroscience out of control: control-theoretic perspectives on neural circuit dynamics</article-title><source>Current Opinion in Neurobiology</source><year>2019</year><volume>58</volume><fpage>122</fpage><lpage>129</lpage></element-citation></ref><ref id="R74"><label>74</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kao</surname><given-names>Ta-Chu</given-names></name><name><surname>Sadabadi</surname><given-names>Mahdieh S</given-names></name><name><surname>Hennequin</surname><given-names>Guillaume</given-names></name></person-group><article-title>Optimal anticipatory control as a theory of motor preparation: A thalamo-cortical circuit model</article-title><source>Neuron</source><year>2021</year><volume>109</volume><issue>9</issue><fpage>1567</fpage><lpage>1581</lpage></element-citation></ref><ref id="R75"><label>75</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Logiaco</surname><given-names>Laureline</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name><name><surname>Escola</surname><given-names>Sean</given-names></name></person-group><article-title>Thalamic control of cortical dynamics in a model of flexible motor sequencing</article-title><source>Cell Reports</source><year>2021</year><volume>35</volume><issue>9</issue><elocation-id>109090</elocation-id></element-citation></ref><ref id="R76"><label>76</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pemberton</surname><given-names>Joseph</given-names></name><name><surname>Boven</surname><given-names>Ellen</given-names></name><name><surname>Apps</surname><given-names>Richard</given-names></name><name><surname>Costa</surname><given-names>Rui Ponte</given-names></name></person-group><article-title>Cortico-cerebellar networks as decoupling neural interfaces</article-title><source>Advances in Neural Information Processing Systems</source><year>2021</year><volume>34</volume><fpage>7745</fpage><lpage>7759</lpage></element-citation></ref><ref id="R77"><label>77</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perich</surname><given-names>Matthew G</given-names></name><name><surname>Rajan</surname><given-names>Kanaka</given-names></name></person-group><article-title>Rethinking brain-wide interactions through multi-region ‘network of networks’ models</article-title><source>Current Opinion in Neurobiology</source><year>2020</year><month>December</month><volume>65</volume><fpage>146</fpage><lpage>151</lpage></element-citation></ref><ref id="R78"><label>78</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallego</surname><given-names>Juan A</given-names></name><name><surname>Makin</surname><given-names>Tamar R</given-names></name><name><surname>McDougle</surname><given-names>Samuel D</given-names></name></person-group><article-title>Going beyond primary motor cortex to improve brain–computer interfaces</article-title><source>Trends in Neurosciences</source><year>2022</year><month>March</month><volume>45</volume><issue>3</issue><fpage>176</fpage><lpage>183</lpage></element-citation></ref><ref id="R79"><label>79</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Marr</surname><given-names>David</given-names></name><name><surname>Thomas Thach</surname><given-names>W</given-names></name></person-group><chapter-title>A theory of cerebellar cortex</chapter-title><source>From the Retina to the Neocortex</source><publisher-name>Springer</publisher-name><year>1991</year><fpage>11</fpage><lpage>50</lpage></element-citation></ref><ref id="R80"><label>80</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martin</surname><given-names>TA</given-names></name><name><surname>Keating</surname><given-names>JG</given-names></name><name><surname>Goodkin</surname><given-names>HP</given-names></name><name><surname>Bastian</surname><given-names>AJ</given-names></name><name><surname>Thach</surname><given-names>WT</given-names></name></person-group><article-title>Throwing while looking through prisms: I. focal olivocerebellar lesions impair adaptation</article-title><source>Brain</source><year>1996</year><volume>119</volume><issue>4</issue><fpage>1183</fpage><lpage>1198</lpage></element-citation></ref><ref id="R81"><label>81</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ito</surname><given-names>Masao</given-names></name></person-group><article-title>Mechanisms of motor learning in the cerebellum</article-title><source>Brain research</source><year>2000</year><volume>886</volume><issue>1-2</issue><fpage>237</fpage><lpage>245</lpage></element-citation></ref><ref id="R82"><label>82</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Izawa</surname><given-names>Jun</given-names></name><name><surname>Criscimagna-Hemminger</surname><given-names>Sarah E</given-names></name><name><surname>Shadmehr</surname><given-names>Reza</given-names></name></person-group><article-title>Cerebellar contributions to reach adaptation and learning sensory consequences of action</article-title><source>Journal of Neuroscience</source><year>2012</year><volume>32</volume><issue>12</issue><fpage>4230</fpage><lpage>4239</lpage></element-citation></ref><ref id="R83"><label>83</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herzfeld</surname><given-names>David J</given-names></name><name><surname>Pastor</surname><given-names>Damien</given-names></name><name><surname>Haith</surname><given-names>Adrian M</given-names></name><name><surname>Rossetti</surname><given-names>Yves</given-names></name><name><surname>Shadmehr</surname><given-names>Reza</given-names></name><name><surname>O’Shea</surname><given-names>Jacinta</given-names></name></person-group><article-title>Contributions of the cerebellum and the motor cortex to acquisition and retention of motor memories</article-title><source>Neuroimage</source><year>2014</year><volume>98</volume><fpage>147</fpage><lpage>158</lpage></element-citation></ref><ref id="R84"><label>84</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tzvi</surname><given-names>Elinor</given-names></name><name><surname>Loens</surname><given-names>Sebastian</given-names></name><name><surname>Donchin</surname><given-names>Opher</given-names></name></person-group><article-title>Mini-review: the role of the cerebellum in visuomotor adaptation</article-title><source>The Cerebellum</source><year>2021</year><fpage>1</fpage><lpage>8</lpage></element-citation></ref><ref id="R85"><label>85</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miall</surname><given-names>R Chris</given-names></name><name><surname>Wolpert</surname><given-names>Daniel M</given-names></name></person-group><article-title>Forward models for physiological motor control</article-title><source>Neural networks</source><year>1996</year><volume>9</volume><issue>8</issue><fpage>1265</fpage><lpage>1279</lpage></element-citation></ref><ref id="R86"><label>86</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolpert</surname><given-names>Daniel M</given-names></name><name><surname>Miall</surname><given-names>R Chris</given-names></name><name><surname>Kawato</surname><given-names>Mitsuo</given-names></name></person-group><article-title>Internal models in the cerebellum</article-title><source>Trends in cognitive sciences</source><year>1998</year><volume>2</volume><issue>9</issue><fpage>338</fpage><lpage>347</lpage></element-citation></ref><ref id="R87"><label>87</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bastian</surname><given-names>Amy J</given-names></name></person-group><article-title>Learning to predict the future: the cerebellum adapts feedforward movement control</article-title><source>Current opinion in neurobiology</source><year>2006</year><volume>16</volume><issue>6</issue><fpage>645</fpage><lpage>649</lpage></element-citation></ref><ref id="R88"><label>88</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nawrot</surname><given-names>Mark</given-names></name><name><surname>Rizzo</surname><given-names>Matthew</given-names></name></person-group><article-title>Motion perception deficits from midline cerebellar lesions in human</article-title><source>Vision research</source><year>1995</year><volume>35</volume><issue>5</issue><fpage>723</fpage><lpage>731</lpage></element-citation></ref><ref id="R89"><label>89</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Criscimagna-Hemminger</surname><given-names>Sarah E</given-names></name><name><surname>Bastian</surname><given-names>Amy J</given-names></name><name><surname>Shadmehr</surname><given-names>Reza</given-names></name></person-group><article-title>Size of error affects cerebellar contributions to motor learning</article-title><source>Journal of neurophysiology</source><year>2010</year><volume>103</volume><issue>4</issue><fpage>2275</fpage><lpage>2284</lpage></element-citation></ref><ref id="R90"><label>90</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Williams</surname><given-names>Ronald J</given-names></name><name><surname>Zipser</surname><given-names>David</given-names></name></person-group><article-title>A learning algorithm for continually running fully recurrent neural networks</article-title><source>Neural computation</source><year>1989</year><volume>1</volume><issue>2</issue><fpage>270</fpage><lpage>280</lpage></element-citation></ref><ref id="R91"><label>91</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marschall</surname><given-names>Owen</given-names></name><name><surname>Cho</surname><given-names>Kyunghyun</given-names></name><name><surname>Savin</surname><given-names>Cristina</given-names></name></person-group><article-title>A unified framework of online learning algorithms for training recurrent neural networks</article-title><source>Journal of machine learning research</source><year>2020</year></element-citation></ref><ref id="R92"><label>92</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murray</surname><given-names>James M</given-names></name></person-group><article-title>Local online learning in recurrent networks with random feedback</article-title><source>Elife</source><year>2019</year><volume>8</volume><elocation-id>e43299</elocation-id></element-citation></ref><ref id="R93"><label>93</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mujika</surname><given-names>Asier</given-names></name><name><surname>Meier</surname><given-names>Florian</given-names></name><name><surname>Steger</surname><given-names>Angelika</given-names></name></person-group><article-title>Approximating real-time recurrent learning with random kronecker factors</article-title><source>Advances in Neural Information Processing Systems</source><year>2018</year><volume>31</volume></element-citation></ref><ref id="R94"><label>94</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bellec</surname><given-names>Guillaume</given-names></name><name><surname>Scherr</surname><given-names>Franz</given-names></name><name><surname>Subramoney</surname><given-names>Anand</given-names></name><name><surname>Hajek</surname><given-names>Elias</given-names></name><name><surname>Salaj</surname><given-names>Darjan</given-names></name><name><surname>Legenstein</surname><given-names>Robert</given-names></name><name><surname>Maass</surname><given-names>Wolfgang</given-names></name></person-group><article-title>A solution to the learning dilemma for recurrent networks of spiking neurons</article-title><source>Nature communications</source><year>2020</year><volume>11</volume><issue>1</issue><fpage>1</fpage><lpage>15</lpage></element-citation></ref><ref id="R95"><label>95</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilra</surname><given-names>Aditya</given-names></name><name><surname>Gerstner</surname><given-names>Wulfram</given-names></name></person-group><article-title>Predicting non-linear dynamics by stable local learning in a recurrent spiking neural network</article-title><source>Elife</source><year>2017</year><volume>6</volume><elocation-id>e28295</elocation-id></element-citation></ref><ref id="R96"><label>96</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Denève</surname><given-names>Sophie</given-names></name><name><surname>Alemi</surname><given-names>Alireza</given-names></name><name><surname>Bourdoukan</surname><given-names>Ralph</given-names></name></person-group><article-title>The brain as an efficient and robust adaptive learner</article-title><source>Neuron</source><year>2017</year><volume>94</volume><issue>5</issue><fpage>969</fpage><lpage>977</lpage></element-citation></ref><ref id="R97"><label>97</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Naud</surname><given-names>Richard</given-names></name><name><surname>Sprekeler</surname><given-names>Henning</given-names></name></person-group><article-title>Sparse bursts optimize information transmission in a multiplexed neural code</article-title><source>Proceedings of the National Academy of Sciences</source><year>2018</year><volume>115</volume><issue>27</issue><fpage>E6329</fpage><lpage>E6338</lpage></element-citation></ref><ref id="R98"><label>98</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Podlaski</surname><given-names>Bill</given-names></name><name><surname>Machens</surname><given-names>Christian K</given-names></name></person-group><article-title>Biological credit assignment through dynamic inversion of feedforward networks</article-title><source>Advances in Neural Information Processing Systems</source><year>2020</year><volume>33</volume><fpage>10065</fpage><lpage>10076</lpage></element-citation></ref><ref id="R99"><label>99</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Payeur</surname><given-names>Alexandre</given-names></name><name><surname>Guerguiev</surname><given-names>Jordan</given-names></name><name><surname>Zenke</surname><given-names>Friedemann</given-names></name><name><surname>Richards</surname><given-names>Blake A</given-names></name><name><surname>Naud</surname><given-names>Richard</given-names></name></person-group><article-title>Burst-dependent synaptic plasticity can coordinate learning in hierarchical circuits</article-title><source>Nature neuroscience</source><year>2021</year><volume>24</volume><issue>7</issue><fpage>1010</fpage><lpage>1019</lpage></element-citation></ref><ref id="R100"><label>100</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taylor</surname><given-names>Jordan A</given-names></name><name><surname>Krakauer</surname><given-names>John W</given-names></name><name><surname>Ivry</surname><given-names>Richard B</given-names></name></person-group><article-title>Explicit and implicit contributions to learning in a sensorimotor adaptation task</article-title><source>Journal of Neuroscience</source><year>2014</year><volume>34</volume><issue>8</issue><fpage>3023</fpage><lpage>3032</lpage></element-citation></ref><ref id="R101"><label>101</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paszke</surname><given-names>Adam</given-names></name><name><surname>Gross</surname><given-names>Sam</given-names></name><name><surname>Massa</surname><given-names>Francisco</given-names></name><name><surname>Lerer</surname><given-names>Adam</given-names></name><name><surname>Bradbury</surname><given-names>James</given-names></name><name><surname>Chanan</surname><given-names>Gregory</given-names></name><name><surname>Killeen</surname><given-names>Trevor</given-names></name><name><surname>Lin</surname><given-names>Zeming</given-names></name><name><surname>Gimelshein</surname><given-names>Natalia</given-names></name><name><surname>Antiga</surname><given-names>Luca</given-names></name><etal/></person-group><article-title>Pytorch: An imperative style, high-performance deep learning library</article-title><source>Advances in neural information processing systems</source><year>2019</year><volume>32</volume></element-citation></ref><ref id="R102"><label>102</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kingma</surname><given-names>Diederik P</given-names></name><name><surname>Ba</surname><given-names>Jimmy</given-names></name></person-group><article-title>Adam: A method for stochastic optimization</article-title><source>arXiv preprint</source><year>2014</year><elocation-id>arXiv:1412.6980</elocation-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>Proposed recurrent neural network that controls its output based on feedback.</title><p><bold>A</bold>. Afferent and efferent pathways act together to produce precise movements, and to flexibly correct them in the presence of perturbations. <bold>B</bold>. A recurrent neural network (RNN) model to explore a shared implementation of motor control and adaptation based on a common error feedback loop. <bold>C</bold>. We defined the ongoing error during movement as the difference between the observed and the optimal hand position. <bold>D</bold>. Initial RNN training included reaches of varying lengths and to different locations (grey lines) with occasional random velocity “bump” perturbations (cf. <xref ref-type="supplementary-material" rid="SD1">Figure S1</xref>). <bold>E</bold>. Hand trajectories produced by a trained RNN required to perform a standard eight-target centre-out reaching task. <bold>F</bold>. Hand trajectories after introducing a 30° rotation of the RNN’s output, to mimic a visuomotor rotation perturbation; note that feedback allowed the network to correct its output online and reach to the target. <bold>G</bold>. Hand trajectories for a model without a feedback loop, which could not counteract the same perturbation.</p></caption><graphic xlink:href="EMS155700-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Feedback signals can guide local synaptic plasticity that enables successful motor adaptation.</title><p><bold>A</bold>. Example hand trajectories as a monkey reached to each of eight targets after a 30°rotation of the visual feedback was introduced (first 30 trials after perturbation onset; data from Perich et al.<sup><xref ref-type="bibr" rid="R51">51</xref></sup>). <bold>B</bold>. Example hand trajectories after the monkey had adapted to the perturbation by reaiming the reach direction (last 30 trials of the perturbation phase for the same session as in A). <bold>C</bold>. Angular reaching take-off error for the baseline (left, black), perturbation (middle, red), and wash-out phases (right, black). Transparent lines, single trial errors; solid lines, smoothed mean error (Gaussian filter, s.d., 10 trials). <bold>D-F</bold>. Simulation results for an RNN implementing the proposed feedback-driven plasticity rule, by which recurrent weights are modified according to the error signal received by the postsynaptic neuron. The first and last 80 trials of adaptation are shown; otherwise data is presented as in A-C. Note the strong similarities between the behaviour of the network and that of the monkey.</p></caption><graphic xlink:href="EMS155700-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Motor adaptation based on feedback-driven plasticity recapitulates key aspects of human and monkey behaviour.</title><p><bold>A</bold>. Correlation between the take-off error in the current trial and the amount of learning from this trial to the next for both simulation (Model) and behavioural data (Monkey C and Monkey M; data from Perich et al.<sup><xref ref-type="bibr" rid="R51">51</xref></sup>). Individual circles, a different network (Model) or experimental session (Monkey); numbers, proportion of networks or experimental sessions exhibiting a significant correlation (<italic>P</italic>&lt;0.05). <bold>B</bold>. Movement error after adaptation to VR perturbations with different perturbation angle variability (cf. <xref ref-type="bibr" rid="R65">Ref. 65</xref>,<xref ref-type="bibr" rid="R66">66</xref> for human behaviour). <bold>C</bold>. As in human experiments, the time course of adaptation in the model is well fitted by a dual-rate model<sup><xref ref-type="bibr" rid="R63">63</xref></sup>. Grey line, single trial errors of simulated adaptation behaviour in an example simulation. Purple line, model fit; dark brown line, fast process; light brown line, slow process. <bold>D</bold>. Fitted parameters of the dual rate model (black) match those from a visuomotor adaptation study in humans<sup><xref ref-type="bibr" rid="R64">64</xref></sup> (blue). Individual circles, ten different networks; square and error bars, mean and 95 % confidence interval. <bold>E</bold>. Hand trajectories produced by the model after visuomotor adaptation to a single target (“Adaptation target”, in red). <bold>F</bold>. Take-off error after adaptation to visuomotor perturbations applied to a single target, as shown in E (red), or to eight targets (dark grey) (cf. <xref ref-type="bibr" rid="R2">Ref. 2</xref> for human behaviour). Lines and error bars, mean and s.d. across ten networks.</p></caption><graphic xlink:href="EMS155700-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Both feedback-based motor control and adaptation can be achieved with sparse feedback signals which are small compared to recurrent signals.</title><p><bold>A</bold>. Angular error between produced and target position at the end of the reach immediately after onset of visuomotor rotation for networks with different percentages of neurons receiving afferent feedback (black markers), including no feedback (dashed line). Lines and error bars, mean and s.d. across ten networks. <bold>B</bold>. Take-off error at visuomotor rotation onset (solid circles), and after adaptation (empty circles) for networks with different percentages of neurons receiving afferent feedback. Lines and error bars, mean and s.d. across ten networks. <bold>C</bold>. Average recurrent (blue) and feedback (red) inputs to an RNN neuron before adaptation. Average input strength is defined as the mean across incoming signals and neurons. Legend, percentage of neurons receiving feedback. <bold>D</bold>. Average magnitude of the peak input strength of the recurrent (blue) and feedback (red) inputs before adaptation. Same colour scheme as in C. Lines and error bars, mean and s.d. across ten networks. <bold>E</bold>. Average recurrent (blue) and feedback (red) inputs to an RNN neuron after adaptation. Data presented as in C. <bold>F</bold>. Average magnitude of the peak input strength of the recurrent (blue) and feedback (red) inputs after adaptation. Data presented as in D.</p></caption><graphic xlink:href="EMS155700-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>Two temporally dissociated activity changes may indicate feedback-driven plasticity in monkey M1 during visuomotor adaptation.</title><p><bold>A</bold>. Epochs used to identify feedback-related (green) and learning-related (blue) activity changes. <bold>B</bold>. The average RNN activity change across pairs of behavioural epochs (as shown in A) reveals putative feedforward-related (blue star) and feedback-related (green circle) activity changes for an example network. Black trace, activity change between perturbation onset and successful adaptation; green, activity change between baseline and perturbation onset; blue, activity change between baseline and successful adaptation. Note that the peak timings are chosen based on ten different network simulations. <bold>C</bold>. An RNN without a feedback loop has only feedforward-related activity changes. Data presented as in A. <bold>D</bold>. Approximate location of the recording array for each of monkey (legend). <bold>E</bold>. The average activity change of monkey M1 neurons between perturbation onset and successful adaptation resembles that of the network (compare with A). Data from one representative session from Monkey C, presented as in B. <bold>F</bold>. Comparison between the ratio of the feedback-related (green circle in B,C,E) to feedforward-related (blue star in B,C,E) activity changes from perturbation onset until successful adaptation for networks with different feedback densities. Individual markers, individual networks. Horizontal line, mean. <bold>G</bold>. Same as F, but for monkey M1 (data shown for each monkey separately). Individual markers, individual sessions. Horizontal line, mean. FB, feedback; FF, feedforward.</p></caption><graphic xlink:href="EMS155700-f005"/></fig><table-wrap id="T1" position="float" orientation="portrait"><label>Table 1</label><caption><title>Simulation parameters.</title></caption><table frame="hsides" rules="cols"><thead><tr style="border-top: hidden; border-bottom: 1px solid"><th align="center" valign="top">Parameter</th><th align="center" valign="top">Definition</th><th align="center" valign="top">Value</th></tr></thead><tbody><tr><td align="center" valign="top">dt</td><td align="center" valign="top">Time step</td><td align="center" valign="top">10ms</td></tr><tr><td align="center" valign="top"><italic>τ</italic></td><td align="center" valign="top">Time constant</td><td align="center" valign="top">50ms</td></tr><tr><td align="center" valign="top">Δ</td><td align="center" valign="top">Feedback delay</td><td align="center" valign="top">120ms</td></tr><tr><td align="center" valign="top"><italic>N</italic></td><td align="center" valign="top">Number of neurons</td><td align="center" valign="top">400</td></tr><tr style="border-bottom: 1px solid"><td align="center" valign="top">Φ</td><td align="center" valign="top">Nonlinearity</td><td align="center" valign="top">ReLU</td></tr><tr><td align="center" valign="top">Φ(<italic>x</italic>)</td><td align="center" valign="top">Neural activity</td><td align="center" valign="top">-</td></tr><tr><td align="center" valign="top"><italic>s</italic></td><td align="center" valign="top">Stimulus</td><td align="center" valign="top">-</td></tr><tr><td align="center" valign="top"><italic>ϵ</italic></td><td align="center" valign="top">Position error</td><td align="center" valign="top">-</td></tr><tr><td align="center" valign="top"><italic>r</italic></td><td align="center" valign="top">Eligibility trace</td><td align="center" valign="top">-</td></tr><tr><td align="center" valign="top"><italic>W</italic></td><td align="center" valign="top">Recurrent weight matrix</td><td align="center" valign="top">-</td></tr><tr><td align="center" valign="top"><italic>b</italic></td><td align="center" valign="top">Recurrent offset</td><td align="center" valign="top">-</td></tr><tr><td align="center" valign="top"><italic>W<sup>in</sup></italic></td><td align="center" valign="top">Input weight matrix</td><td align="center" valign="top">-</td></tr><tr><td align="center" valign="top"><italic>W<sup>out</sup></italic></td><td align="center" valign="top">Output weight matrix</td><td align="center" valign="top">-</td></tr><tr><td align="center" valign="top"><italic>b<sup>out</sup></italic></td><td align="center" valign="top">Output offset</td><td align="center" valign="top">-</td></tr><tr><td align="center" valign="top"><italic>F</italic></td><td align="center" valign="top">Feedback weight matrix</td><td align="center" valign="top">-</td></tr><tr><td align="center" valign="top"><italic>v</italic></td><td align="center" valign="top">Velocity (2D)</td><td align="center" valign="top">-</td></tr><tr style="border-bottom: 1px solid"><td align="center" valign="top"><italic>p</italic></td><td align="center" valign="top">Position (2D)</td><td align="center" valign="top">-</td></tr><tr><td align="center" valign="top"><italic>α</italic></td><td align="center" valign="top">Gradient Descent: Learning rate</td><td align="center" valign="top">0.001</td></tr><tr><td align="center" valign="top"><italic>B</italic></td><td align="center" valign="top">Gradient Descent: batch size</td><td align="center" valign="top">20</td></tr><tr><td align="center" valign="top"><italic>β</italic></td><td align="center" valign="top">Gradient Descent: weight regularization</td><td align="center" valign="top">0.001</td></tr><tr style="border-bottom: 1px solid"><td align="center" valign="top"><italic>γ</italic></td><td align="center" valign="top">Gradient Descent: activity regularization</td><td align="center" valign="top">0.002</td></tr><tr style="border-bottom: 1px solid"><td align="center" valign="top"><italic>η</italic></td><td align="center" valign="top">Feedback-driven plasticity: learning rate</td><td align="center" valign="top">0.000001</td></tr><tr style="border-bottom: hidden"><td align="center" valign="top"><italic>T</italic></td><td align="center" valign="top">Reach trajectories: number of time steps in a trial</td><td align="center" valign="top">300</td></tr></tbody></table></table-wrap></floats-group></article>