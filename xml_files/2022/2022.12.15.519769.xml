<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS158902</article-id><article-id pub-id-type="doi">10.1101/2022.12.15.519769</article-id><article-id pub-id-type="archive">PPR585447</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">2</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>A reductionist paradigm for high-throughput behavioural fingerprinting in <italic>Drosophila melanogaster</italic></article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Jones</surname><given-names>Hannah</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Willis</surname><given-names>Jenny A</given-names></name><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Firth</surname><given-names>Lucy C</given-names></name><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Giachello</surname><given-names>Carlo N G</given-names></name><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Gilestro</surname><given-names>Giorgio F</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="corresp" rid="CR1">#</xref></contrib></contrib-group><aff id="A1"><label>1</label>Department of Life Sciences, Imperial College London, London, UK</aff><aff id="A2"><label>2</label>Syngenta, Jealott’s Hill International Research Centre, Bracknell, UK</aff><author-notes><corresp id="CR1"><label>#</label>To whom correspondence should be addressed. <email>giorgio@gilest.ro</email></corresp></author-notes><pub-date pub-type="nihms-submitted"><day>23</day><month>12</month><year>2022</year></pub-date><pub-date pub-type="preprint"><day>15</day><month>12</month><year>2022</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Understanding how the brain encodes behaviour is the ultimate goal of neuroscience and the ability to objectively and reproducibly describe and quantify behaviour is a necessary milestone on this path. Recent technological progresses in machine learning and computational power have boosted the development and adoption of systems leveraging on high-resolution video recording to track an animal pose and describe behaviour in all four dimensions. However, the high temporal and spatial resolution that these systems offer must come as a compromise with their throughput and accessibility. Here we describe <italic>coccinella</italic>, an open-source reductionist framework combining high-throughput analysis of behaviour using real-time tracking on a distributed mesh of microcomputers (ethoscopes) with resource-lean statistical learning (HCTSA/Catch22). Coccinella is a reductionist system, yet outperforms state-of-the-art alternatives when exploring the pharmacobehaviour in <italic>Drosophila melanogaster</italic>.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">The nervous system integrates stimuli, internal states, expectations, and previous experience to regulate behavioural output. Describing, quantifying, and modulating behaviour are critical aspects of modern neuroscience and, ever since its inception, the field has spent considerable effort into building and sharing paradigms or tools aimed at objectively and reproducibly quantify behaviours in the most disparate animal models, to the point that this exercise is now recognised as an exciting subfield of neuroscience in its own right: ethomics<sup><xref ref-type="bibr" rid="R1">1</xref>,<xref ref-type="bibr" rid="R2">2</xref></sup>. As the portmanteau name itself suggests, ethomics is not just about describing behaviour (<italic>etho-</italic>) but also about doing so in a high-throughput fashion (<italic>-omics</italic>), collecting data simultaneously from a large number of individuals, which can remain undisturbed throughout recording. Irrespective of the behaviour or the animal model to be analysed, the first compromise a researcher will face when choosing a tool for behavioural quantification will always be between throughput and resolution: a high-throughput analysis will allow for powerful experimental manipulations – such as genetics or pharmacological screens – offering unbiased approaches in identifying neuronal circuits, genes, molecules underpinning behaviour; high-resolution analysis, on the other hand, promises to identify and discriminate even minuscule differences that may not be immediately visible to the human eye, and to label behaviours into identifiable classes (<italic>e.g.:</italic> “grooming”, “courting”, “shaking”) that may be more relevant to researchers interested in modelling disease or in anthropomorphic descriptions. In the past years, the field has generally converged towards the adoption of high-resolution video recording of activity, in some cases adopting cameras that have milliseconds temporal resolution or developing setups that provide depth information for three-dimensional reconstruction of motion or posture<sup><xref ref-type="bibr" rid="R3">3</xref>–<xref ref-type="bibr" rid="R7">7</xref></sup>. Given the recent evolution in machine learning and progresses in computational power, even these high-resolution analyses can be at least in part compatible with high-throughput approaches<sup><xref ref-type="bibr" rid="R8">8</xref></sup>, especially when employed on small invertebrate animal models<sup><xref ref-type="bibr" rid="R9">9</xref>–<xref ref-type="bibr" rid="R12">12</xref></sup> or when aided by robotic handling<sup><xref ref-type="bibr" rid="R13">13</xref></sup>. These systems, however, can still be prohibitively expensive for most laboratories, and not easily compatible with throughput in the ‘<italic>omics</italic> scale. Moreover, besides the technical urge of removing entry barrier and make ethomics an accessible tool, an equally important underlying question concerns what is the minimal amount of information that needs to be extracted to identify and classify behaviour. Do we always necessarily gain information from extracting micro-postural features or by analysing activity in three dimensions? To what extent this may actually add counterproductive biological noise to some assays?</p><p id="P3">Here we introduce <italic>coccinella</italic>: a new experimental framework that combines high-throughput, inexpensive, real-time ethomics<sup><xref ref-type="bibr" rid="R14">14</xref></sup> with state-of-the-art statistical analysis<sup><xref ref-type="bibr" rid="R15">15</xref>,<xref ref-type="bibr" rid="R16">16</xref></sup> to characterise and discriminate complex behaviours using a reductionist approach based solely on one simple feature (<ext-link ext-link-type="uri" xlink:href="https://lab.gilest.ro/coccinella">https://lab.gilest.ro/coccinella</ext-link>). <italic>Coccinella</italic> builds on ethoscopes<sup><xref ref-type="bibr" rid="R14">14</xref></sup>, an accessible open-source platform, to extract, in real-time, minimalist information from flies. Despite its minimalist nature, <italic>coccinella</italic> outperforms state-of-the-art alternatives in recognising the pharmacobehavioural space, providing better discernibility at a fraction of the cost, thus opening a new path to high-throughput ethomics.</p></sec><sec id="S2" sec-type="results"><title>Results</title><p id="P4"><italic>Drosophila</italic> ethomics studies generally rely on image acquisition through so called industrial-cameras, able to collect videos with high temporal and spatial resolution and featuring mounts for a large selection of lenses. Some of the cameras commonly used for these purposes (<italic>e.g.:</italic> FLIR, Point Grey, Basler)<sup><xref ref-type="bibr" rid="R17">17</xref></sup> are expensive and normally employed in close-up imaging that microscopically highlights the smallest anatomical features of the animal but at the same time greatly limits the number of experimental subjects that can be recorded by a single device. Normally, one or few more camera would be connected to a dedicated powerful computer for acquisition and storage of videos. The cost and physical footprint of these setups makes them incompatible, at least for most laboratories, with high-throughput simultaneous acquisition. To lower this barrier, we created a framework that employs the distributing computing power of ethoscopes<sup><xref ref-type="bibr" rid="R14">14</xref></sup>, thus allowing for inexpensive analysis of activity in hundreds or thousands of flies at once. Ethoscopes are open source and can be manufactured by a skilled end-user at a cost of about £75 per machine, mostly building on two off-the-shelf component: a Raspberry Pi microcomputer and a Raspberry Pi NoIR camera overlooking a bespoke 3D printed arena hosting freely moving flies. The temporal and spatial resolution of the collected images depends on the working modality the user chooses. When operating in offline mode, ethoscopes are capable to acquire 720p videos at 60 fps, which is a convenient option with fast moving animals. In this study, we instead opted for the default ethoscope working settings, providing online tracking and real-time parametric extraction, meaning that images are analysed by each raspberry Pi at the very moment they are acquired (<xref ref-type="fig" rid="F1">Figure 1b</xref>). This latter modality limits the temporal resolution of information being processed (one frame every 444 ms ± 127 ms, equivalent to 2.2 fps on a Raspberry Pi3 at a resolution of 1280x960 pixels with each animal being constricted in an ellipse measuring 25.8 ± 1.4 x 9.85 ± 1.4 pixels – <xref ref-type="fig" rid="F1">Figure 1a</xref>) but provides the most affordable and high-throughput solution, dispensing the researcher from organising video storage or asynchronous video processing for tracking the animals. In the work here described, flies moved freely in a circular two-dimensional space with a diameter of 11.5 mm designed to maintain the animal in the walking position<sup><xref ref-type="bibr" rid="R18">18</xref></sup> while venturing on solidified agar providing nutrients alone or nutrients and drugs. In previous analysis of activity and sleep<sup><xref ref-type="bibr" rid="R14">14</xref>,<xref ref-type="bibr" rid="R19">19</xref></sup>, we found that the maximal velocity of the fly over a period of 10 seconds best described the basic motion features of the animal, allowing us to accurately differentiate between different activity patterns, such as walking, grooming, feeding<sup><xref ref-type="bibr" rid="R14">14</xref></sup>. We therefore adopted this measure for <italic>coccinella</italic> too, ultimately producing monodimensional time-series of a behavioural correlate, which were then digested using highly comparative time-series analysis (HCTSA)<sup><xref ref-type="bibr" rid="R15">15</xref></sup>, a computational framework that effortlessly subjects time-series to more than 7700 literature-relevant statistical tests, looking for meaningful discriminative features. Features successfully extracted through HCTSA were then used to classify behaviour using a linear support vector machine (SVM<sub>linear</sub>)<sup><xref ref-type="bibr" rid="R20">20</xref></sup> (<xref ref-type="fig" rid="F1">Figure 1b</xref>) and here presented and compared using confusion matrices (<xref ref-type="supplementary-material" rid="SD2">Figure 1 - Figure Supplement 1a</xref>). To test the ability of this system to discriminate behaviour, we started by exploring the pharmacobehavioral space of flies fed with a panel of known or putative neurotropic chemicals, comprising molecules previously described in the literature along with uncharacterised ones being considered as potential insecticides (<xref ref-type="fig" rid="F1">Figure 1c, 1d</xref> and <xref ref-type="supplementary-material" rid="SD2">Supplementary Table 1</xref>). Using an initial panel of 17 treatments (16 drugs and one solvent control) we were able to discern compounds with an accuracy of 71.4% (vs. 5.8% of a random classifier – <xref ref-type="fig" rid="F1">Figure 1c</xref>). Some compounds induced behaviours with a particularly high predictive fingerprint: dieldrin, for instance, was predicted with an accuracy of 94% and flonicamid with an accuracy of 87%. For others, our system fared more poorly (<italic>e.g.</italic> tetramethrin showed 41% accuracy). In all cases, however, the relative confusion was negligible, with all compounds being correctly identified as the first choice and with the first predicted compounds having, on average, a score that was 15-times greater compared to the second-best choices (<xref ref-type="fig" rid="F1">Figure 1c</xref> – min.: 3.3x; max.: 65x). To validate our framework and exclude artifacts operated by overfitting biologically irrelevant information we followed two lines of control. Firstly, we fed flies with lower concentrations of the same compounds (<xref ref-type="fig" rid="F1">Figure 1c</xref>). Feeding flies with different concentrations of drugs unsurprisingly showed a different effect on short term lethality (<xref ref-type="supplementary-material" rid="SD2">Figure 1 - Figure Supplement 1b</xref>), with several compounds hitting a 25% lethality rate before the end of the experiment when fed at the highest concentration (1000ppm – <xref ref-type="supplementary-material" rid="SD2">Figure 1 - Figure Supplement 1b</xref>). Lowering the compound concentration, the predictive accuracy of the system decreased from 71.4% (1000ppm) to 61.8% (100ppm), falling to 36.1% with the lowest concentrations (1ppm), indicating that the system does operate on pharmacologically induced, biologically meaningful behavioural correlates (<xref ref-type="fig" rid="F1">Figure 1c</xref>). A similar drop in accuracy was observed using a smaller panel of 12 treatments (<xref ref-type="supplementary-material" rid="SD2">Figure 1 - Figure Supplement 1c</xref>). As a second line of work to test specificity, we obtained genetic mutants known to be resistant to specific pharmacological treatments: the <italic>para<sup>L1029F</sup></italic> allele encodes for a version of the α-subunit of voltage-gated sodium channel conferring resistance to DDT and pyrethroids<sup><xref ref-type="bibr" rid="R21">21</xref></sup>; the <italic>Rdl<sup>A301S</sup></italic> allele encodes for a version of the ligand-gated chloride channel conferring resistance to dieldrin and fiproles<sup><xref ref-type="bibr" rid="R22">22</xref></sup>. Challenging these mutants with their respective compounds created confusion in the clustering algorithm for which discerning between drug treatment and solvent control became a harder task, especially in the case of DDT and <italic>para<sup>L1029F</sup></italic> (<xref ref-type="supplementary-material" rid="SD2">Figure 1 - Figure Supplement 2a</xref>). The observed drop in accuracy suggests again that <italic>coccinella</italic> is working on biologically relevant behavioural signatures and the fact that some discrimination can still be observed with targets harbouring point mutations – which should severely affect compound efficacy – is indicative of high sensitivity.</p><p id="P5">Having established the accuracy and sensitivity of the system, we next wanted to test its usefulness in a genuine high-throughput scenario. We subjected a total of 2192 flies to a panel of 40 treatments (<xref ref-type="fig" rid="F1">Figure 1d</xref>), mostly featuring known compounds but also two unexplored molecules (<xref ref-type="supplementary-material" rid="SD2">Supplementary Table 1</xref>). Given that the 100ppm intermediate concentrations showed the best compromise between accuracy and lethality in the previous pilot experiment (<xref ref-type="supplementary-material" rid="SD2">Figure 1 - Figure Supplement 1b</xref>), we performed this larger screen using compounds diluted at 100ppm only. Even with such a large panel, the system was able to first-guess 39 out of 40 of the tested treatments (the only exception being the Syngenta Compound #5) with an overall accuracy of 44.5% vs 2.5% of the random classifier.</p><p id="P6">A reductionist approach served us well so far, identifying with remarkable accuracy even subtle changes when we explored the pharmacobehavioural space of a large number of neuroactive compounds in wild type and mutant flies. But how does it compare to other more established paradigms? <italic>Coccinella</italic> is arguably to be preferred in terms of accessibility and throughput, but what is the amount of useful information that we are sacrificing by adopting a reductionist approach? To quantify any possible loss in information content, we ran a series of parallel experiments in which flies were fed with a selected panel of 12 treatments (11 drugs and a solvent control, <xref ref-type="fig" rid="F2">Figure 2</xref>) and their behaviour analysed either using <italic>coccinella</italic> or using other widely adopted state-of-the-art methods, which started with high-resolution imaging and employed supervised machine learning for pose estimation (DeepLabCut<sup><xref ref-type="bibr" rid="R17">17</xref></sup>) followed by unsupervised identification of behavioural grammar (B-SOiD<sup><xref ref-type="bibr" rid="R4">4</xref></sup>). To widen the range of comparisons, data were then either immediately clustered using different common clustering algorithms (K-nearest neighbours, random forest) or first processed through a smaller, selected subsample of the HCTSA array (Catch22<sup><xref ref-type="bibr" rid="R16">16</xref></sup>) before being clustered using SVM<sub>linear</sub> (<xref ref-type="fig" rid="F2">Figure 2a</xref>). In this challenge, <italic>coccinella</italic> unambiguously identified 10 out of 12 compounds, with poor performance only for two of them (flubendiamide and tetramethrin) and an overall accuracy of 42.4%, vs 8.3% of the random classifier (<xref ref-type="fig" rid="F2">Figure 2b</xref>). Surprisingly, none of the state-of-the-art high-resolution paths did better than this. The combination of pose-estimation → grammar extraction → random forest classification scored as the second best, with an accuracy of 25.4% but with only three compounds being unambiguously identified (<xref ref-type="fig" rid="F2">Figure 2c</xref>). The same experimental dataset clustered with even poorer performance when using K-nearest neighbours (<xref ref-type="fig" rid="F2">Figure 2e</xref>) and even the application of HCTSA features extraction to the B-SoID output still could not match the accuracy observed with <italic>coccinella</italic>’s reductionist approach (<xref ref-type="fig" rid="F2">Figure 2d</xref>). This analysis is not meant to be conclusive. We expect that some alternative combination of state-of-the-art approaches will probably manage to match or likely improve over <italic>coccinella</italic>’s performance, yet the fact we could obtain such an impressive result with a system that is arguably unmatched in terms of throughput and economic cost is, alone, an argument that gives new weight to this (and future) reductionist approaches.</p><p id="P7">Finally, to push the system to its limit, we asked <italic>coccinella</italic> to find qualitative differences not in pharmacologically induced changes in activity, but in a type of spontaneous behaviour mostly characterised by lack of movement: sleep. In particular, we wondered whether <italic>coccinella</italic> could provide biological insights comparing conditions of sleep rebound observed after different regimes of sleep deprivation. <italic>Drosophila melanogaster</italic> is known to show a strong, conserved homeostatic regulation of sleep that forces flies to recover at least in part lost sleep, for instance after a night of forceful sleep deprivation<sup><xref ref-type="bibr" rid="R23">23</xref>,<xref ref-type="bibr" rid="R24">24</xref></sup>. We previously showed that the extent of sleep rebound observed after sleep deprivation only loosely correlates with the amount of lost sleep<sup><xref ref-type="bibr" rid="R25">25</xref></sup> and it remains an open question whether similar amounts of sleep rebound may in fact differ from each other in some inscrutable feature that would underpin a different “sleep depth”<sup><xref ref-type="bibr" rid="R26">26</xref>,<xref ref-type="bibr" rid="R27">27</xref></sup>, similarly to what it is believed to happen in mammals. Here, we analysed a dataset of 727 flies that experienced different regimes of mechanically enforced sleep deprivation during the 12 hours of the night (<xref ref-type="fig" rid="F3">Figure 3</xref>). Flies were housed in tubes that would rotate after a set time of inactivity ranging from 20 to 1000 seconds leading to different degrees of sleep restriction (<xref ref-type="fig" rid="F3">Figure 3a</xref>, dataset from<sup><xref ref-type="bibr" rid="R25">25</xref></sup>). In this experimental paradigm, all treatments led to a statistically significant rebound compared to the undisturbed control animals (<xref ref-type="fig" rid="F3">Figure 3b</xref>). We then ran <italic>coccinella</italic> on the two subsets of the panel: the baseline data, acquired the morning before the sleep deprivation (<xref ref-type="fig" rid="F3">Figure 3c</xref>), and the rebound data, on the morning after (<xref ref-type="fig" rid="F3">Figure 3d</xref>). Unsurprisingly, we could not detect any internal biological difference in the pre sleep deprivation control set, featuring flies of identical genotype and age housed in different tubes before the sleep deprivation treatment. In these conditions, <italic>coccinella</italic> could not discern, and performed exactly as a random classifier would (9% vs 9% – <xref ref-type="fig" rid="F3">Figure 3c</xref>). However, analysis of those same animals during rebound after sleep deprivation showed a clear clustering, segregating the samples in two subsets with separation around the 300 seconds inactivity trigger (<xref ref-type="fig" rid="F3">Figure 3d</xref>). This result is important for two reasons: on one hand, it provides, for the third time, strong evidence that the system is not simply overfitting data of nought biological significance, given that it could not perform any better than a random classifier on the baseline control. On the other hand, <italic>coccinella</italic> could find biologically relevant differences on rebound data after different regimes of sleep deprivation. Interestingly enough, the 300 seconds threshold that <italic>coccinella</italic> independently identified has a deep intrinsic significance for the field, for it is considered to be the threshold beyond which flies lose arousal response to external stimuli, defining a “sleep quantum” (<italic>i.e.:</italic> the minimum amount of time required for transforming inactivity bouts into sleep bouts<sup><xref ref-type="bibr" rid="R23">23</xref>,<xref ref-type="bibr" rid="R24">24</xref>,<xref ref-type="bibr" rid="R28">28</xref></sup>). Coccinella’s analysis ran agnostic of the arbitrary 5-minutes threshold and yet identified the same value as the one able to segregate the two clusters, thus providing an independent confirmation of the five-minutes rule in <italic>D. melanogaster</italic>.</p></sec><sec id="S3" sec-type="discussion"><title>Discussion</title><p id="P8">System neuroscience is living a period of renaissance, and <italic>Drosophila</italic> is driving this revolution strong of the first full-brain connectome, a plethora of new genetic reagents that allow thermo- and opto-genetic manipulations, a galore of genetic transformants for circuit tracking and manipulation, and multiple tools for large-scale quantification of behaviour. Progresses in machine learning and computer power have had a massive impact on the field of ethomics, especially in achieving levels of anatomical tracking that allow mapping of the tiniest movements on an experimental animal model with the highest temporal resolution and with little human supervision<sup><xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R17">17</xref></sup>. Most of these systems, however, rely on relatively expensive setups and do not scale easily to high-throughput experimental paradigms. They are ideal – and irreplaceable – to identify behavioural patterns and study fine motor control but may be undue for other uses. Here we introduce a new framework, <italic>coccinella</italic>, that merges an open-source, economically accessible hardware platform (ethoscopes<sup><xref ref-type="bibr" rid="R14">14</xref>,<xref ref-type="bibr" rid="R29">29</xref></sup>) with a powerful toolbox for statistical analysis and clustering (HCTSA<sup><xref ref-type="bibr" rid="R15">15</xref></sup> / Catch22<sup><xref ref-type="bibr" rid="R16">16</xref></sup>). <italic>Coccinella</italic> is a reductionist tool, not meant to replace the behavioural categorization that other tools can offer but to complement it. It relies on raspberry PIs as main acquisition devices, with associated advantages and limitations. Ethoscopes are inexpensive and versatile but are limited in terms of computing power and acquisition rates. Their online acquisition speed is fast enough to successfully capture the motor activity of different species of Drosophilae<sup><xref ref-type="bibr" rid="R28">28</xref></sup>, but may not be sufficient for other animals moving more swiftly, such as zebrafish larvae. Moreover, <italic>coccinella</italic> cannot – and is not meant to – apply labels to behaviour (“courting”, “lounging”, “sipping”, “jumping” <italic>etc.</italic>) but it can successfully identify large behavioural phenotypes and generate unbiased hypothesis on how behaviour, and a nervous system at large, can be influenced by chemicals, genetics, artificial manipulations in general. Here, we provided evidence that <italic>coccinella</italic> can be used to successfully explore and compartmentalise the pharmacobehavioural space and also showed that a reductionist approach can be employed to discern otherwise invisible shades of a very subtle naturally occurring behavior: sleep. The success of <italic>Drosophila</italic> as experimental model was built on the many genetic screens of the 1900s. We propose <italic>coccinella</italic> as an accessible, pivotal tool to boost again this important line of work in any laboratory, without funding or access to technology being a discriminative factor.</p></sec><sec id="S4" sec-type="methods"><title>Methods</title><sec id="S5"><title><italic>Drosophila</italic> rearing</title><p id="P9">Fly lines were maintained on a 12-hour light: 12-hour dark (LD) cycle and raised on polenta and yeast-based fly media (agar 96 g, polenta 240 g, fructose 960 g and Brewer’s yeast 1,200 g in 12 litres of water). Canton-Special (CS) <italic>Drosophila melanogaster</italic> were used as the wild-type line for all experiments.</p></sec><sec id="S6"><title>Drug resistant mutants</title><p id="P10"><italic>Rdl<sup>A301S</sup></italic> is derived from <italic>Rdl<sup>MDRR</sup></italic> (RRID:BDSC_1675), an <italic>Rdl</italic> allele isolated from a natural population in Maryland<sup><xref ref-type="bibr" rid="R30">30</xref></sup>, and underwent isogenization and selection on dieldrin to eliminate the metabolic resistance and maintain the dieldrin target site resistance<sup><xref ref-type="bibr" rid="R31">31</xref></sup>. The <italic>Rdl</italic><sup>MDRR</sup> was obtained from the Bloomington Drosophila Stock Center. For <italic>para:</italic> the L1029F mutation, located in the voltage gated sodium channel paralytic, has been extensively reported to confer resistance to DDT and pyrethroids in many other insect species (called kdr, knockdown resistance, reviewed in<sup><xref ref-type="bibr" rid="R32">32</xref></sup>). In the <italic>Drosophila</italic> gene, kdr maps to L1029F and is equivalent to the often cited L1014F in other insects (e.g. <italic>Musca domestica</italic><sup><xref ref-type="bibr" rid="R33">33</xref></sup>). The kdr L1029F mutation in <italic>Drosophila</italic> Para was introduced via CRISPR/Cas9-mediated genome editing (see below). This genome edited generated mutation resulted in a similar resistance to DDT as previously reported<sup><xref ref-type="bibr" rid="R34">34</xref></sup>.</p></sec><sec id="S7"><title>Generation of Para<sup>L1029F</sup> via CRISPR-CAS9 based genome editing</title><p id="P11">CRISPR/Cas9-mediated genome editing was used to introduce a point mutation L1029F in para-PBG isoform, CTT to TTT, L to F by homology-dependent repair (HDR) using one guide RNA and a dsDNA plasmid donor. The strategy design, molecular biology and screening was completed by Well Genetics Inc., Taiwan (R.O.C.). The cassette PBacDsRed contains Piggy Bac 3’ terminal repeats, the selection marker 3xP3-DsRed, and Piggy Bac 5’ terminal repeats. The selection marker 3xP3-DsRed contains Piggy Bac 3’ terminal repeats, 3x Pax3 and hsp70 promoter, DsRed2, SV40 3’UTR, and Piggy Bac 5’ terminal repeats. The dsRed marker facilitates the genetic screening and was excised by Piggy Bac transposase. Only one TTAA motif was left after transposition embedded in mutated intron sequence, and create a mutation G to A on X:16,486,649; X:16,486,649∼ X:16,486,646, CTAA to T TAA in intron. The CRISPR Target Site [PAM]: CACAAGATTGCCGATGACAA[CGG]. Guide RNA Primers: Sense oligo5’-CTTCGCACAAGATTGCCGATGACAA and Antisense oligo5’ - AAACTTGTCATCGGCAATCTTGTGC. Upstream Homology Arm: 1,027bp,the +34,097nt to +35,123 nt from ATG of para. Forward Oligo5’-GTTCACCAAACTCGGAATCG; Reverse Oligo5’- GTGGCCAAGAAGAAGGGAAT. Downstream Homology Arm: 1,022 bp, the +35,128nt to +3,6149 nt from ATG of para Forward Oligo: 5’-CCATGGCTTTAAGCATCGCA; Reverse Oligo: 5’- TTATGACGGATACGGTTACGG. Synthesis fragment: 5’– GGTTGTCATCGGCAATTTTGTGgtgagtactcttatcgaactgctgacttgtaaacgatgtttactggctataatgctgacttatcgcct</p><p id="P12">The <italic>Drosophila</italic> injection strain was <italic>white</italic><sup>1118</sup>. 206 embryos were injected. 36 G0 crosses were established. Of the 78 positive lines crosses, in the F1 screen 25 positive lines were identified. Seven lines were positively validated by PCR and 1 line was sequenced confirming no unexpected changes in <italic>para</italic>. Lines were isogenized and balanced. DsRed was excised using PiggyBac (PBac) Transposase Bloomington Stock RRID:BDSC_8285. Excision was validated by genomic PCR and sequencing. Resulting lines were hemizygous viable. The line used in study had internal identifier: 20256ex1.</p></sec><sec id="S8"><title>Choice, handling and preparation of drugs</title><p id="P13">The initial preliminary analysis was conducted using a group of 12 compounds “proof of principle” compounds and a solvent control. These compounds were initially used to compare both the video method and ethoscope method. After testing these initial compounds, it was found that the ethoscope methodology was more successful, and then the compound list was expanded to 17 (including the control) only using the ethoscope method. As a final test, we included additional compounds for a single concentration, bringing up the total to 40 (including control), also for the ethoscope method. All insecticide compounds were supplied by Syngenta Ltd. from their in-house stock (see Supplementary Table 1 for a full list of compounds used). Compounds were received in solid form and diluted in solvent containing 5% ethanol (VWR, 20821), 5% acetone (Sigma,179124) and 10% dimethylsulfoxide (DMSO) (D2650, Sigma) in distilled water to 1000ppm initially, then further diluted in the solvent mixture to 100ppm and 1ppm (where 1mL/L = 1000ppm). For insecticide assays, 0.5mL of 5% sucrose (Sigma, S0389), 1% agarose (Sigma, A6236) solution was pipetted into each well and allowed to set. Following this, 2µL of compound solution were placed on the surface and allowed to dry for 30 minutes or more. Male flies were then placed on the surface with a small glass cover slip placed on top (13mm circular cover slip, VWR631-0150). Flies were briefly anaesthetised (&gt;1 minute) before being placed onto the surface of the plate. Once each well had been filled with a single male fly, arenas were placed into the ethoscope and recorded for a minimum of two days. All experiments were started between ZT0 and ZT1 and within 30 minutes of the flies being placed in the wells. For each compound in <xref ref-type="fig" rid="F1">Figures 1c</xref> and <xref ref-type="supplementary-material" rid="SD2">Figure 1 - Figure Supplement 1c</xref>, three repeats were done at different time points. For <xref ref-type="fig" rid="F1">Figure 1D</xref>, two repeats to three biological repeats per compound.</p></sec><sec id="S9"><title>Data acquisition and processing</title><p id="P14">Ethoscope data were first processed in R using rethomics<sup><xref ref-type="bibr" rid="R29">29</xref></sup>. Each time series was exported (.csv) and converted using Python to individual time series in a file format (.dat) compatible with MatLab. A metadata (.txt) file served as a reference file of each individual time series with keywords outlining compound groups and concentrations for processing data using HCTSA.</p></sec><sec id="S10"><title>HCTSA / Catch22</title><p id="P15">Following this process, HCTSA feature extraction was performed on the time-series data (for <xref ref-type="fig" rid="F1">figures 1c, 1d</xref>, <xref ref-type="fig" rid="F3">3c, 3d</xref>, <xref ref-type="fig" rid="F1">Figure 1</xref> – <xref ref-type="supplementary-material" rid="SD2">Figure Supplements 1 and 2a</xref>). After the features were extracted, outputs of error-producing operations were removed through a normalization process using a sigmoidal transformation. HCTSA inbuilt functions were then used to classify data using a linear SVM classifier and a confusion matrix comparing the time series was generated. For some of the time-series data (that in <xref ref-type="fig" rid="F2">Figure 2B, 2D</xref>, <xref ref-type="supplementary-material" rid="SD2">Figure 1 - Figure Supplement 2b</xref>), a smaller feature set of HCTSA, Catch-22 was used for feature extraction. Due to the smaller number of features used with this method, normalization was not required before using a linear SVM classifier to generate a confusion matrix comparing the results. A time series of 12 hours was used for the HCTSA analysis in <xref ref-type="fig" rid="F1">Figure 1</xref> and <xref ref-type="supplementary-material" rid="SD2">Figure 1 - Figure Supplement 1,2</xref>. A length of 3 hours was used for the HCTSA analysis in <xref ref-type="fig" rid="F3">Figure 3</xref>. All video data in <xref ref-type="fig" rid="F2">Figure 2</xref> are from time series of 15 minutes. By always running the full set of features on aggregate to train a classifier (e.g., TS_Classify in HCTSA), no post-hoc correction is necessary because the trained classifier only ever makes a single prediction (only one test is performed).</p></sec><sec id="S11"><title>Video generation for flies on insecticides</title><p id="P16">Custom 3D-printed squares were designed using the online CAD software Onshape and printed using Ultimaker 2+ 3D printers using PLA plastic. For insecticide assays, 0.5mL of 5% sucrose (Sigma, S0389), 1% agarose (Sigma, A6236) solution was pipetted into each well and allowed to set. Following this, 2µL of compound solution were placed on the surface and allowed to dry for 30 minutes or more before male flies were placed on the surface with a small glass cover slip placed on top (13mm circular cover slip, VWR631-0150). Flies were briefly anaesthetised (&gt;1 minute) before being placed onto the surface of the square. Once each well had been filled with a single male fly, squares were placed in the arena and a video was recorded for a minimum of 12 hours using an ELP 8 megapixel camera with an IMX179 Sensor and 2.8-12 mm variable focus manual lens. All video recordings were started between ZT0 and ZT1. Recordings of flies exposed to compounds were done in a randomised manner. Video data was then broken down into shorter segments of 15-minute videos for processing. The first 15-minutes following 1 hour of fly exposure to compound or control was used for pose extraction.</p></sec><sec id="S12"><title>Deeplabcut / B-SoID</title><p id="P17">The use of DeepLabCut (version 2.1) followed the detailed protocol outlined by<sup><xref ref-type="bibr" rid="R5">5</xref></sup> . Briefly, frames for labelling were extracted from 3 representative videos using a K-means algorithm and frames were labelled with 22 unique body parts (head, left eye, right eye, thorax top, thorax bottom, abdomen top, abdomen middle, abdomen bottom, left wing tip, right wing tip, left foreleg tip, left foreleg middle, right foreleg tip, right foreleg middle, left middle leg tip, left middle leg middle, right middle leg tip, right middle leg middle, left back leg tip, left back leg middle, right back leg tip, right back leg middle). These frames were labelled locally with a DeepLabCut graphical user interface (GUI) before the project file was uploaded to Google Drive for training and video analysis to be done using Google Colab. The data was split into a 9:1 test:train dataset and training was run for more than 150,000 iterations before the average Euclidean error was computed between labels and predictions. The model at the best performing checkpoint was used to predict pose in novel videos. Following this, B-SOID was used to de-structure behaviour using the output of DeepLabCut and generate fly-specific time-series of behavioural grammar as in<sup><xref ref-type="bibr" rid="R4">4</xref></sup>.</p></sec><sec id="S13"><title>Sleep deprivation</title><p id="P18">Maximal velocity time series data generated from recording flies exposed to either control conditions (no SD) or incrementally increasing immobility-triggered SD conditions were taken from the dataset generated by Geissmann <italic>et al</italic><sup><xref ref-type="bibr" rid="R25">25</xref></sup>. Only data for female flies were taken, and where groups consisted of more than 60 individuals, a sample of 60 random individual flies were chosen to take time series data from. Time series data were processed in the same way as described in section 4.2 using the raw ethoscope data.</p></sec><sec id="S14"><title>Survival</title><p id="P19">Flies were fed with the specified compounds at the desired concentrations and concomitantly analysed in ethoscopes for 24 hours. Time of death was calculated as the last moment of detected motion.</p></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary Jupyter Notebooks</label><media xlink:href="EMS158902-supplement-Supplementary_Jupyter_Notebooks.zip" mimetype="application" mime-subtype="zip" id="d146aAdEbB" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD2"><label>Supplementary</label><media xlink:href="EMS158902-supplement-Supplementary.pdf" mimetype="application" mime-subtype="pdf" id="d146aAdEcB" position="anchor"/></supplementary-material></sec></body><back><ack id="S15"><title>Acknowledgements</title><p>We thank the Gilestro lab at Imperial College London and Robert Lind at Syngenta for useful discussions. HJ was supported by a BBSRC/CASE studentship in partnership with Syngenta (project reference BB/M011178/1/1958700). Stocks obtained from the Bloomington Drosophila Stock Center (NIH P40OD018537) were used in this study.</p></ack><sec id="S16" sec-type="data-availability"><title>Code and data availability</title><p id="P20">A notebook version of the source code used to generate all figures is available on the Zenodo public repository, along with all the metadata and the raw data collected in this study (DOIs: 10.5281/zenodo.7335575 and 10.5281/zenodo.7393689). Data were analysed using rethomics<sup><xref ref-type="bibr" rid="R35">35</xref></sup> and ethoscopy<sup><xref ref-type="bibr" rid="R36">36</xref></sup>. Two notebooks showing how to use the system for multiple uses are provided as <xref ref-type="supplementary-material" rid="SD2">supplementary material</xref>.</p></sec><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>AEX</given-names></name><name><surname>de Bivort</surname><given-names>B</given-names></name></person-group><article-title>Ethology as a physical science</article-title><source>Nat Phys</source><year>2018</year><volume>1</volume><pub-id pub-id-type="doi">10.1038/s41567-018-0093-0</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Datta</surname><given-names>SR</given-names></name><name><surname>Anderson</surname><given-names>DJ</given-names></name><name><surname>Branson</surname><given-names>K</given-names></name><name><surname>Perona</surname><given-names>P</given-names></name><name><surname>Leifer</surname><given-names>A</given-names></name></person-group><article-title>Computational Neuroethology: A Call to Action</article-title><source>Neuron</source><year>2019</year><volume>104</volume><fpage>11</fpage><lpage>24</lpage><pub-id pub-id-type="pmcid">PMC6981239</pub-id><pub-id pub-id-type="pmid">31600508</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2019.09.038</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiltschko</surname><given-names>AB</given-names></name><etal/></person-group><article-title>Mapping Sub-Second Structure in Mouse Behavior</article-title><source>Neuron</source><year>2015</year><volume>88</volume><fpage>1121</fpage><lpage>1135</lpage><pub-id pub-id-type="pmcid">PMC4708087</pub-id><pub-id pub-id-type="pmid">26687221</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.031</pub-id></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hsu</surname><given-names>AI</given-names></name><name><surname>Yttri</surname><given-names>EA</given-names></name></person-group><article-title>B-SOiD, an open-source unsupervised algorithm for identification and fast prediction of behaviors</article-title><source>Nat Commun</source><year>2021</year><volume>12</volume><elocation-id>5188</elocation-id><pub-id pub-id-type="pmcid">PMC8408193</pub-id><pub-id pub-id-type="pmid">34465784</pub-id><pub-id pub-id-type="doi">10.1038/s41467-021-25420-x</pub-id></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nath</surname><given-names>T</given-names></name><etal/></person-group><article-title>Using DeepLabCut for 3D markerless pose estimation across species and behaviors</article-title><source>Nat Protoc</source><year>2019</year><volume>14</volume><fpage>2152</fpage><lpage>2176</lpage><pub-id pub-id-type="pmid">31227823</pub-id></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pereira</surname><given-names>TD</given-names></name><etal/></person-group><article-title>Fast animal pose estimation using deep neural networks</article-title><source>Nat Methods</source><year>2019</year><volume>16</volume><fpage>117</fpage><lpage>125</lpage><pub-id pub-id-type="pmcid">PMC6899221</pub-id><pub-id pub-id-type="pmid">30573820</pub-id><pub-id pub-id-type="doi">10.1038/s41592-018-0234-5</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gosztolai</surname><given-names>A</given-names></name><etal/></person-group><article-title>LiftPose3D, a deep learning-based approach for transforming two-dimensional to three-dimensional poses in laboratory animals</article-title><source>Nat Methods</source><year>2021</year><volume>18</volume><fpage>975</fpage><lpage>981</lpage><pub-id pub-id-type="pmcid">PMC7611544</pub-id><pub-id pub-id-type="pmid">34354294</pub-id><pub-id pub-id-type="doi">10.1038/s41592-021-01226-z</pub-id></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiltschko</surname><given-names>AB</given-names></name><etal/></person-group><article-title>Revealing the structure of pharmacobehavioral space through motion sequencing</article-title><source>Nat Neurosci</source><year>2020</year><volume>23</volume><fpage>1433</fpage><lpage>1443</lpage><pub-id pub-id-type="pmcid">PMC7606807</pub-id><pub-id pub-id-type="pmid">32958923</pub-id><pub-id pub-id-type="doi">10.1038/s41593-020-00706-3</pub-id></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McDermott-Rouse</surname><given-names>A</given-names></name><etal/></person-group><article-title>Behavioral fingerprints predict insecticide and anthelmintic mode of action</article-title><source>Mol Syst Biol</source><year>2021</year><volume>17</volume><elocation-id>e10267</elocation-id><pub-id pub-id-type="pmcid">PMC8144879</pub-id><pub-id pub-id-type="pmid">34031985</pub-id><pub-id pub-id-type="doi">10.15252/msb.202110267</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ayroles</surname><given-names>JF</given-names></name><etal/></person-group><article-title>Behavioral idiosyncrasy reveals genetic control of phenotypic variability</article-title><source>Proc Natl Acad Sci</source><year>2015</year><volume>112</volume><fpage>6706</fpage><lpage>6711</lpage><pub-id pub-id-type="pmcid">PMC4450409</pub-id><pub-id pub-id-type="pmid">25953335</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1503830112</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Branson</surname><given-names>K</given-names></name><name><surname>Robie</surname><given-names>AA</given-names></name><name><surname>Bender</surname><given-names>J</given-names></name><name><surname>Perona</surname><given-names>P</given-names></name><name><surname>Dickinson</surname><given-names>MH</given-names></name></person-group><article-title>High-throughput ethomics in large groups of Drosophila</article-title><source>Nat Methods</source><year>2009</year><volume>6</volume><fpage>451</fpage><lpage>457</lpage><pub-id pub-id-type="pmcid">PMC2734963</pub-id><pub-id pub-id-type="pmid">19412169</pub-id><pub-id pub-id-type="doi">10.1038/nmeth.1328</pub-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kabra</surname><given-names>M</given-names></name><name><surname>Robie</surname><given-names>AA</given-names></name><name><surname>Rivera-Alba</surname><given-names>M</given-names></name><name><surname>Branson</surname><given-names>S</given-names></name><name><surname>Branson</surname><given-names>K</given-names></name></person-group><article-title>JAABA: interactive machine learning for automatic annotation of animal behavior</article-title><source>Nat Methods</source><year>2013</year><volume>10</volume><fpage>64</fpage><lpage>67</lpage><pub-id pub-id-type="pmid">23202433</pub-id></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alisch</surname><given-names>T</given-names></name><name><surname>Crall</surname><given-names>JD</given-names></name><name><surname>Kao</surname><given-names>AB</given-names></name><name><surname>Zucker</surname><given-names>D</given-names></name><name><surname>de Bivort</surname><given-names>BL</given-names></name></person-group><article-title>MAPLE (modular automated platform for large-scale experiments), a robot for integrated organism-handling and phenotyping</article-title><source>eLife</source><year>2018</year><volume>7</volume><elocation-id>e37166</elocation-id><pub-id pub-id-type="pmcid">PMC6193762</pub-id><pub-id pub-id-type="pmid">30117804</pub-id><pub-id pub-id-type="doi">10.7554/eLife.37166</pub-id></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geissmann</surname><given-names>Q</given-names></name><etal/></person-group><article-title>Ethoscopes: An Open Platform For High-Throughput Ethomics</article-title><source>PLOS Biol</source><year>2017</year><volume>15</volume><elocation-id>e2003026</elocation-id><pub-id pub-id-type="pmcid">PMC5648103</pub-id><pub-id pub-id-type="pmid">29049280</pub-id><pub-id pub-id-type="doi">10.1371/journal.pbio.2003026</pub-id></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fulcher</surname><given-names>BD</given-names></name><name><surname>Jones</surname><given-names>N</given-names></name></person-group><article-title>S. hctsa: A Computational Framework for Automated Time-Series Phenotyping Using Massive Feature Extraction</article-title><source>Cell Syst</source><year>2017</year><volume>5</volume><fpage>527</fpage><lpage>531</lpage><elocation-id>e3</elocation-id><pub-id pub-id-type="pmid">29102608</pub-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lubba</surname><given-names>CH</given-names></name><etal/></person-group><article-title>catch22: CAnonical Time-series CHaracteristics</article-title><source>Data Min Knowl Discov</source><year>2019</year><volume>33</volume><fpage>1821</fpage><lpage>1852</lpage></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathis</surname><given-names>A</given-names></name><etal/></person-group><article-title>DeepLabCut: markerless pose estimation of user-defined body parts with deep learning</article-title><source>Nat Neurosci</source><year>2018</year><volume>21</volume><fpage>1281</fpage><lpage>1289</lpage><pub-id pub-id-type="pmid">30127430</pub-id></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simon</surname><given-names>JC</given-names></name><name><surname>Dickinson</surname><given-names>MH</given-names></name></person-group><article-title>A New Chamber for Studying the Behavior of Drosophila</article-title><source>PLOS ONE</source><year>2010</year><volume>5</volume><elocation-id>e8793</elocation-id><pub-id pub-id-type="pmcid">PMC2811731</pub-id><pub-id pub-id-type="pmid">20111707</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0008793</pub-id></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geissmann</surname><given-names>Q</given-names></name></person-group><article-title>High-throughput recording, analysis and manipulation of sleep in drosophila</article-title><year>2018</year><pub-id pub-id-type="doi">10.25560/69514</pub-id></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Chatterjee</surname><given-names>S</given-names></name><name><surname>Dey</surname><given-names>D</given-names></name><name><surname>Munshi</surname><given-names>S</given-names></name></person-group><chapter-title>Chapter 4 - Feature selection and classification</chapter-title><person-group person-group-type="editor"><name><surname>Chatterjee</surname><given-names>S</given-names></name><name><surname>Dey</surname><given-names>D</given-names></name><name><surname>Munshi</surname><given-names>S</given-names></name></person-group><source>Recent Trends in Computer-Aided Diagnostic Systems for Skin Diseases</source><publisher-name>Academic Press</publisher-name><year>2022</year><fpage>95</fpage><lpage>135</lpage><pub-id pub-id-type="doi">10.1016/B978-0-323-91211-2.00001-9</pub-id></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaduskar</surname><given-names>B</given-names></name><etal/></person-group><article-title>Reversing insecticide resistance with allelic-drive in Drosophila melanogaster</article-title><source>Nat Commun</source><year>2022</year><volume>13</volume><fpage>291</fpage><pub-id pub-id-type="pmcid">PMC8755802</pub-id><pub-id pub-id-type="pmid">35022402</pub-id><pub-id pub-id-type="doi">10.1038/s41467-021-27654-1</pub-id></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Remnant</surname><given-names>EJ</given-names></name><etal/></person-group><article-title>The role of Rdl in resistance to phenylpyrazoles in Drosophila melanogaster</article-title><source>Insect Biochem Mol Biol</source><year>2014</year><volume>54</volume><fpage>11</fpage><lpage>21</lpage><pub-id pub-id-type="pmid">25193377</pub-id></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shaw</surname><given-names>PJ</given-names></name><name><surname>Cirelli</surname><given-names>C</given-names></name><name><surname>Greenspan</surname><given-names>RJ</given-names></name><name><surname>Tononi</surname><given-names>G</given-names></name></person-group><article-title>Correlates of Sleep and Waking in Drosophila melanogaster</article-title><source>Science</source><year>2000</year><volume>287</volume><fpage>1834</fpage><lpage>1837</lpage><pub-id pub-id-type="pmid">10710313</pub-id></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hendricks</surname><given-names>JC</given-names></name><etal/></person-group><article-title>Rest in Drosophila Is a Sleep-like State</article-title><source>Neuron</source><year>2000</year><volume>25</volume><fpage>129</fpage><lpage>138</lpage><pub-id pub-id-type="pmid">10707978</pub-id></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geissmann</surname><given-names>Q</given-names></name><name><surname>Beckwith</surname><given-names>EJ</given-names></name><name><surname>Gilestro</surname><given-names>GF</given-names></name></person-group><article-title>Most sleep does not serve a vital function: Evidence from Drosophila melanogaster</article-title><source>Sci Adv</source><year>2019</year><volume>5</volume><elocation-id>eaau9253</elocation-id><pub-id pub-id-type="pmcid">PMC6382397</pub-id><pub-id pub-id-type="pmid">30801012</pub-id><pub-id pub-id-type="doi">10.1126/sciadv.aau9253</pub-id></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>French</surname><given-names>AS</given-names></name><name><surname>Geissmann</surname><given-names>Q</given-names></name><name><surname>Beckwith</surname><given-names>EJ</given-names></name><name><surname>Gilestro</surname><given-names>GF</given-names></name></person-group><article-title>Sensory processing during sleep in Drosophila melanogaster</article-title><source>Nature</source><pub-id pub-id-type="pmid">34588694</pub-id></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiggin</surname><given-names>TD</given-names></name><etal/></person-group><article-title>Covert sleep-related biological processes are revealed by probabilistic analysis in Drosophila</article-title><source>Proc Natl Acad Sci</source><year>2020</year><volume>117</volume><fpage>10024</fpage><lpage>10034</lpage><pub-id pub-id-type="pmcid">PMC7211995</pub-id><pub-id pub-id-type="pmid">32303656</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1917573117</pub-id></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joyce</surname><given-names>M</given-names></name><etal/></person-group><article-title>Divergent evolution of sleep functions</article-title><year>2023</year><elocation-id>2023.05.27.541573</elocation-id><comment>Preprint at</comment><pub-id pub-id-type="doi">10.1101/2023.05.27.541573</pub-id></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geissmann</surname><given-names>Q</given-names></name><name><surname>Rodriguez</surname><given-names>LG</given-names></name><name><surname>Beckwith</surname><given-names>EJ</given-names></name><name><surname>Gilestro</surname><given-names>GF</given-names></name></person-group><article-title>Rethomics: an R framework to analyse high-throughput behavioural data</article-title><source>bioRxiv</source><year>2018</year><elocation-id>305664</elocation-id><pub-id pub-id-type="pmcid">PMC6334930</pub-id><pub-id pub-id-type="pmid">30650089</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0209331</pub-id></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ffrench-Constant</surname><given-names>RH</given-names></name><name><surname>Roush</surname><given-names>RT</given-names></name><name><surname>Mortlock</surname><given-names>D</given-names></name><name><surname>Dively</surname><given-names>GP</given-names></name></person-group><article-title>Isolation of Dieldrin Resistance from Field Populations of Drosophila melanogaster (Diptera: Drosophilidae)</article-title><source>J Econ Entomol</source><year>1990</year><volume>83</volume><fpage>1733</fpage><lpage>1737</lpage><pub-id pub-id-type="pmid">2124226</pub-id></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blythe</surname><given-names>J</given-names></name><etal/></person-group><article-title>The mode of action of isocycloseram: A novel isoxazoline insecticide</article-title><source>Pestic Biochem Physiol</source><year>2022</year><volume>187</volume><elocation-id>105217</elocation-id><pub-id pub-id-type="pmid">36127059</pub-id></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arena</surname><given-names>JP</given-names></name><name><surname>Liu</surname><given-names>KK</given-names></name><name><surname>Paress</surname><given-names>PS</given-names></name><name><surname>Schaeffer</surname><given-names>JM</given-names></name><name><surname>Cully</surname><given-names>DF</given-names></name></person-group><article-title>Expression of a glutamate-activated chloride current in Xenopus oocytes injected with Caenorhabditis elegans RNA: evidence for modulation by avermectin</article-title><source>Mol Brain Res</source><year>1992</year><volume>15</volume><fpage>339</fpage><lpage>348</lpage><pub-id pub-id-type="pmid">1279355</pub-id></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dong</surname><given-names>K</given-names></name></person-group><article-title>Insect sodium channels and insecticide resistance</article-title><source>Invert Neurosci</source><year>2007</year><volume>7</volume><fpage>17</fpage><pub-id pub-id-type="pmcid">PMC3052376</pub-id><pub-id pub-id-type="pmid">17206406</pub-id><pub-id pub-id-type="doi">10.1007/s10158-006-0036-9</pub-id></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Samantsidis</surname><given-names>G-R</given-names></name><etal/></person-group><article-title>‘What I cannot create, I do not understand’: functionally validated synergism of metabolic and target site insecticide resistance</article-title><source>Proc R Soc B Biol Sci</source><year>2020</year><volume>287</volume><elocation-id>20200838</elocation-id><pub-id pub-id-type="pmcid">PMC7287358</pub-id><pub-id pub-id-type="pmid">32453986</pub-id><pub-id pub-id-type="doi">10.1098/rspb.2020.0838</pub-id></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geissmann</surname><given-names>Q</given-names></name><name><surname>Rodriguez</surname><given-names>LG</given-names></name><name><surname>Beckwith</surname><given-names>EJ</given-names></name><name><surname>Gilestro</surname><given-names>GF</given-names></name></person-group><article-title>Rethomics: An R framework to analyse high-throughput behavioural data</article-title><source>PLOS ONE</source><year>2019</year><volume>14</volume><elocation-id>e0209331</elocation-id></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blackhurst</surname><given-names>L</given-names></name><name><surname>Gilestro</surname><given-names>GF</given-names></name></person-group><article-title>ethoscopy &amp; ethoscope-lab: a framework for behavioural analysis to lower entrance barrier and aid reproducibility</article-title><year>2022</year><elocation-id>2022.11.28.517675</elocation-id><comment>Preprint at</comment><pub-id pub-id-type="pmcid">PMC10561991</pub-id><pub-id pub-id-type="pmid">37818176</pub-id><pub-id pub-id-type="doi">10.1093/bioadv/vbad132</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title><italic>Coccinella</italic> successfully classifies pharmacobehaviours.</title><p><bold>a)</bold> Bespoke 3D printed arena can house 24 individual flies in a two-dimensional circular space. Each arena measures 11.5 mm in diameter and allows for back illumination either by visible or infrared light sources embedded in the ethoscope base. The red ellipse shows the data being extracted by the ethoscope in real time. w, <italic>h</italic>: width and height of the ellipse inscribing the animal. <italic>φ</italic>: the angle of the ellipse in reference to the region of interest. <italic>max. vel.</italic>: maximal velocity over the last 10 seconds. <bold>b)</bold> Flowchart describing the analytical pipeline and the tools that compose <italic>coccinella</italic>. <bold>c)</bold> Confusion matrices for treatments with 16 compounds and a solvent control, with drugs used at concentrations of 1000ppm (left), 100ppm (center), 1ppm (right). The target icon indicates calculated accuracy while the rolling die indicate the accuracy of a random classifier. <bold>d)</bold> Confusion matrix for the largest panel of 40 treatments at 100ppm.</p></caption><graphic xlink:href="EMS158902-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Comparison between <italic>coccinella</italic> and the state-of-the-art.</title><p><bold>a)</bold> Experimental pipeline illustrating the four experimental analysis. <bold>b)</bold> Confusion matrix for 12 treatments (11 drugs at 1000ppm and one solvent control) analysed using <italic>coccinella</italic>. <bold>c)</bold> Same experimental treatments as in b, analysed using the DeepLabCut → B-SoID → Random forest pipeline starting from high resolution images. The Random forest classifier was trained on a 4:1 training:testing ratio. <bold>d)</bold> Same as c but with Catch22 identification and SVM clustering after B-SoID grammar dissection. This is a hybrid treatment combining HCTSA feature extraction to the high resolution pipeline. <bold>e)</bold> Same as c but using K-nearest neighbours (KNN) as cluster algorithm. KNN required a much higher training:testing ratio of 9:1, dramatically reducing the size of the testing dataset. The accuracy of a random classifier for all matrices on this figure would be 8.3% (not shown on figures for lack of space).</p></caption><graphic xlink:href="EMS158902-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title><italic>Coccinella</italic> finds differences in type of sleep rebound after sleep deprivation.</title><p><bold>a)</bold> Sleep profile of flies over the period of three days. A 12 hours sleep deprivation regime starts at the beginning of the dark phase of day 0 (purple bar). The three-hours windows labelled with green boxes were analysed by <italic>coccinella</italic> in search of meaningful differences. The letters above refer to the panels using data in those time windows <bold>b)</bold> Extent of rebound as observed following sleep deprivation as performed in a. Panel a and b reproduce data from<sup><xref ref-type="bibr" rid="R25">25</xref></sup>. <bold>c)</bold> Confusion matrix showing the classification using <italic>coccinella</italic> of the baseline time-series. No accuracy gain compared to the random classifier. <bold>d)</bold> Confusion matrix of the rebound data. The classification finds two clusters, separated by the 300 seconds threshold (thick black lines).</p></caption><graphic xlink:href="EMS158902-f003"/></fig></floats-group></article>