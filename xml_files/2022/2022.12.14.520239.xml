<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS158895</article-id><article-id pub-id-type="doi">10.1101/2022.12.14.520239</article-id><article-id pub-id-type="archive">PPR585390</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">2</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Prediction of white matter hyperintensities evolution one-year post-stroke from a single-point brain MRI and stroke lesions information</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Rachmadi</surname><given-names>Muhammad Febrian</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Vald√©s-Hern√°ndez</surname><given-names>Maria del C.</given-names></name><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Makin</surname><given-names>Stephen</given-names></name><xref ref-type="aff" rid="A4">4</xref></contrib><contrib contrib-type="author"><name><surname>Wardlaw</surname><given-names>Joanna</given-names></name><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Skibbe</surname><given-names>Henrik</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><aff id="A1"><label>1</label>RIKEN Center for Brain Science, Brain Image Analysis Unit, Wako-shi, 351-0106, Japan</aff><aff id="A2"><label>2</label>Universitas Indonesia, Faculty of Computer Science, Depok, 16424, Indonesia</aff><aff id="A3"><label>3</label>University of Edinburgh, Centre for Clinical Brain Sciences, Edinburgh, EH16 4SB, United Kingdom</aff><aff id="A4"><label>4</label>University of Aberdeen, Centre for Rural Health, Inverness, IV2 3JH, United Kingdom</aff></contrib-group><author-notes><corresp id="CR1"><label>*</label><email>febrian.rachmadi@riken.jp</email></corresp><corresp id="CR2"><label>+</label><email>M.Valdes-Hernan@ed.ac.uk</email></corresp></author-notes><pub-date pub-type="nihms-submitted"><day>23</day><month>12</month><year>2022</year></pub-date><pub-date pub-type="preprint"><day>16</day><month>12</month><year>2022</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Predicting the evolution of white matter hyperintensities (WMH), a common feature in brain magnetic resonance imaging (MRI) scans of older adults (i.e., whether WMH will grow, remain stable, or shrink with time) is important for personalised therapeutic interventions. However, this task is difficult mainly due to the myriad of vascular risk factors and comorbidities that influence it, and the low specificity and sensitivity of the image intensities and textures alone for predicting WMH evolution. Given the predominantly vascular nature of WMH, in this study, we evaluate the impact of incorporating stroke lesion information to a probabilistic deep learning model to predict the evolution of WMH 1-year after the baseline image acquisition, taken soon after a mild stroke event, using T2-FLAIR brain MRI. The Probabilistic U-Net was chosen for this study due to its capability of simulating and quantifying the uncertainties involved in the prediction of WMH evolution. We propose to use an additional loss called volume loss to train our model, and incorporate stroke lesions information, an influential factor in WMH evolution. Our experiments showed that jointly segmenting the disease evolution map (DEM) of WMH and stroke lesions, improved the accuracy of the DEM representing WMH evolution. The combination of introducing the volume loss and joint segmentation of DEM of WMH and stroke lesions outperformed other model configurations with mean volumetric absolute error of 0.0092 <italic>ml</italic> (down from 1.7739 <italic>ml</italic>) and 0.47% improvement on average Dice similarity coefficient in shrinking, growing and stable WMH.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><sec id="S2"><title>White matter hyperintensities and their progression</title><p id="P2">White matter hyperintensities (WMH) are one of the main neuroradiological features of cerebral small vessel disease (SVD) and have been commonly associated with stroke, aging, and dementia progression<sup><xref ref-type="bibr" rid="R1">1</xref>‚Äì<xref ref-type="bibr" rid="R3">3</xref></sup>. They are often observed in T2-weighted and T2-fluid attenuated inversion recovery (T2-FLAIR) brain magnetic resonance images (MRI), appearing as bright regions. Small subcortical infarcts may be indistinguishable from WMH on structural MRI in absence of intravenous contrast due to sharing similar image intensity characteristics<sup><xref ref-type="bibr" rid="R4">4</xref></sup>, and if mistaken for WMH could negatively impact the design of clinical research trials<sup><xref ref-type="bibr" rid="R5">5</xref></sup>.</p><p id="P3">Clinical studies have indicated that some patients exhibit WMH progression over time (i.e., increasing in volume)<sup><xref ref-type="bibr" rid="R6">6</xref>‚Äì<xref ref-type="bibr" rid="R8">8</xref></sup> while some show WMH regression over time (i.e., shrinking in volume)<sup><xref ref-type="bibr" rid="R9">9</xref>, <xref ref-type="bibr" rid="R10">10</xref></sup>, although these are fewer in proportion compared to those reporting an increase in volume<sup><xref ref-type="bibr" rid="R10">10</xref></sup>. Another study indicated that WMH dynamically change over time with clusters of WMH individually shrinking, staying unchanged (i.e., stable), or growing, these being observed at the same time point within the same individual<sup><xref ref-type="bibr" rid="R11">11</xref></sup>. These variations have been associated with patients‚Äô comorbidities and clinical outcome<sup><xref ref-type="bibr" rid="R3">3</xref>, <xref ref-type="bibr" rid="R12">12</xref></sup>. A meta-analysis on rate and risk factors for WMH volume growth specifically, concluded that these vary with the characteristics of the sample, although hypertension, age, baseline WMH volume and smoking seemed to be the main contributors<sup><xref ref-type="bibr" rid="R13">13</xref></sup>. And a growing number of clinical studies have indicated that, in addition to age<sup><xref ref-type="bibr" rid="R8">8</xref></sup>, previous strokes<sup><xref ref-type="bibr" rid="R14">14</xref></sup> and genetics<sup><xref ref-type="bibr" rid="R15">15</xref>‚Äì<xref ref-type="bibr" rid="R18">18</xref></sup> also influence the rate and direction of WMH evolution. But, as one clinical study and another meta-analysis acknowledged, current knowledge about factors influencing WMH evolution is still incomplete and poorly understood<sup><xref ref-type="bibr" rid="R3">3</xref>, <xref ref-type="bibr" rid="R10">10</xref></sup>.</p><p id="P4">Interestingly, despite increasing evidence on WMH burden at baseline being the determinant factor on the rate and magnitude of WMH progression (and regression)<sup><xref ref-type="bibr" rid="R13">13</xref></sup>, increase in WMH volume has been found to be a better predictor of persistent cognitive impairment (i.e., a potential precursor to Alzheimer or vascular dementia) than baseline WMH burden<sup><xref ref-type="bibr" rid="R19">19</xref></sup>. However, evidence that overall reduction of WMH volume over time can prevent functional decline is scarce<sup><xref ref-type="bibr" rid="R2">2</xref></sup>. In terms of spatial WMH evolution, a study on patients that had a mild stroke of type lacunar found that post-stroke cognition at 1 and 3 years was affected by the location of WMH<sup><xref ref-type="bibr" rid="R20">20</xref></sup>. But despite evidence on the importance and benefit of studying WMH spatial distribution<sup><xref ref-type="bibr" rid="R21">21</xref></sup>, there are limited approaches to predict spatial WMH evolution. Predicting the evolution of WMH is crucial for understanding the dynamics of small vessel disease and ultimately provide better care and prognosis for individual patients, but it remains a difficult task because of the different rate and direction of the evolution of individual WMH clusters and their interplay with other imaging features of vascular disease and brain parenchymal changes<sup><xref ref-type="bibr" rid="R14">14</xref></sup>. Specifically, 1 year after stroke, reported WMH changes are mild<sup><xref ref-type="bibr" rid="R13">13</xref></sup>, thus posing an additional challenge for their accurate identification.</p></sec><sec id="S3"><title>Precedent work in estimating WMH evolution</title><p id="P5">Despite the high accuracy displayed by several fully-automatic deep learning schemes segmenting WMH<sup><xref ref-type="bibr" rid="R22">22</xref></sup>, most of the algorithms applied in longitudinal studies on WMH evolution have been so far semi-automatic<sup><xref ref-type="bibr" rid="R13">13</xref></sup>. Various deep learning models have been proposed to predict the spatial evolution of WMH<sup><xref ref-type="bibr" rid="R23">23</xref>‚Äì<xref ref-type="bibr" rid="R25">25</xref></sup>. These studies, have represented WMH spatial evolution by a map called <italic>disease evolution map</italic> (DEM) which indicates the WMH voxels that shrink, grow, or remain stable at a further time point. DEM can be generated by subtracting images of manually labeled WMH from different time points. Previous studies generated the DEM by subtracting a baseline image of semi- or fully-automatically labeled WMH of a patient (Visit 1, V1) from a follow-up image of semi- or fully-automatically labeled WMH from the same patient one year after (Visit 2, V2)<sup><xref ref-type="bibr" rid="R24">24</xref>, <xref ref-type="bibr" rid="R25">25</xref></sup>. An example of DEM is visualised in <xref ref-type="fig" rid="F1">Figure 1B</xref>.</p><p id="P6">A recently proposed model for predicting the DEM of WMH based on a Probabilistic U-Net<sup><xref ref-type="bibr" rid="R26">26</xref></sup>, generates multiple DEM predictions for a single brain MRI data<sup><xref ref-type="bibr" rid="R25">25</xref></sup>. This model was proposed to solve the challenge of representing spatial uncertainty<sup><xref ref-type="bibr" rid="R24">24</xref></sup>, given difficulties in distinguishing intensities and textures of shrinking and growing WMH in T2-FLAIR brain MRI. Models using Probabilistic U-Net performed significantly better than the classical U-Net models in predicting the evolution of WMH using DEM<sup><xref ref-type="bibr" rid="R25">25</xref></sup>.</p><p id="P7">All these previous approaches have focused, almost exclusively, on the image modality as input and the appearance of WMH themselves, ignoring other clinically relevant factors. A subsequent study incorporated volume of stroke lesions as auxiliary input to the prediction model, but it did not improve the prediction results<sup><xref ref-type="bibr" rid="R24">24</xref></sup>. Another study<sup><xref ref-type="bibr" rid="R27">27</xref></sup> used radiomic signatures of the normal-appearing tissue as auxiliary variables to vascular risk factors in a logistic regression model to predict general ‚Äúprogression‚Äù vs. ‚Äúno progression‚Äù of WMH, and reported that radiomics improved the accuracy of the model by approximately 10%, but did not analyse the spatial change of WMH. Thus, incorporating clinically associated factors into the predictive model remains a challenge for estimating the spatial evolution of WMH.</p></sec><sec id="S4"><title>Related Approaches</title><p id="P8">Studies that develop predictive models for disease progression from medical image modalities using machine/deep learning can be categorised, generally, into the three different approaches listed below. <list list-type="order" id="L1"><list-item><p id="P9"><bold>Approaches predicting the outcomes of a disease</bold>. These approaches are commonly used for diseases with high rates of mortality and disability. Some examples are those predicting the outcomes of COVID-19<sup><xref ref-type="bibr" rid="R28">28</xref></sup>, multiple sclerosis<sup><xref ref-type="bibr" rid="R29">29</xref></sup>, and traumatic brain injury<sup><xref ref-type="bibr" rid="R30">30</xref>, <xref ref-type="bibr" rid="R31">31</xref></sup>.</p></list-item><list-item><p id="P10"><bold>Approaches predicting the progression of a disease with regards to the pathological timeline and/or commonly associated disease markers</bold>. These approaches are commonly used for diseases with multiple stages of development and which take time to progress, such as dementia and Alzheimer‚Äôs Disease (AD), with mild cognitive impairment (MCI) being their transitional stage<sup><xref ref-type="bibr" rid="R32">32</xref></sup>. Some examples are predicting conversion of MCI patients to AD<sup><xref ref-type="bibr" rid="R33">33</xref></sup>, conversion of healthy individuals to MCI and AD<sup><xref ref-type="bibr" rid="R34">34</xref></sup>, and predicting the progression of multimodal AD markers (e.g., ventricular volume, cognitive scores, etc.)<sup><xref ref-type="bibr" rid="R35">35</xref></sup>.</p></list-item><list-item><p id="P11"><bold>Approaches predicting dynamic changes (evolution) of specific disease features</bold>. These approaches model and predict spatial changes of specific disease features such as evolution of WMH, enlargement of ventricles, and brain atrophy. Other examples are predicting lung nodule progression of pulmonary tumour<sup><xref ref-type="bibr" rid="R36">36</xref></sup>, predicting dynamic change of brain structures from healthy individuals to MCI and AD patients<sup><xref ref-type="bibr" rid="R37">37</xref></sup>, and studies for predicting the evolution of WMH in brain images of stroke patients<sup><xref ref-type="bibr" rid="R23">23</xref>‚Äì<xref ref-type="bibr" rid="R25">25</xref></sup></p></list-item></list></p><p id="P12">This study belongs to the third category, in which a predictive model is used to spatially estimate the dynamic changes of WMH on an MRI scan at a certain time point. This third category is the most challenging because of the complexity and resolution of the data/image being predicted, especially when the time-point estimated is close to the baseline scan. While approaches in the first and second categories predict classes which are the disease outcomes (e.g., survive, death), classes of disease stages (e.g., MCI, AD), or associated disease markers (e.g., age, cognitive scores) from medical imaging data, approaches in the third category predict the evolution of disease‚Äôs imaging features (e.g., lesions and their volumes) spatially, i.e., throughout the entire image space.</p></sec><sec id="S5"><title>Our Contributions</title><p id="P13">The <bold>main contributions</bold> of this study are two-fold, and show that they considerably improve the prediction of WMH volume and spatial change 1 year after a mild-to-moderate stroke event: <list list-type="order" id="L2"><list-item><p id="P14"><bold>incorporating stroke lesions‚Äô information to the prediction model</bold> and</p></list-item><list-item><p id="P15"><bold>adding a volume loss to the cost function</bold> (formulated as the mean squared error between the predicted and the reference future WMH volumes) to improve prediction of WMH evolution voxel-wise.</p></list-item></list></p><p id="P16">As part of a comprehensive set of evaluations, We also evaluate the output from our schemes against the clinical visual scores for WMH evolution<sup><xref ref-type="bibr" rid="R38">38</xref></sup>, and analyse the degree of uncertainty in our predictions.</p></sec></sec><sec id="S6"><title>Proposed Deep Learning Model</title><p id="P17">Uncertainties are unavoidable when predicting the progression of WMH. Previous studies showed that incorporating uncertainties into a deep learning model, either by incorporating Gaussian noise as auxiliary input<sup><xref ref-type="bibr" rid="R24">24</xref></sup> or using a conditional variational autoencoder in the shape of a Probabilistic U-Net with adversarial training<sup><xref ref-type="bibr" rid="R25">25</xref></sup>, improved prediction results, thus justifying the use of a Probabilistic U-Net with adversarial training in the present study.</p><sec id="S7"><title>Probabilistic U-Net with adversarial training</title><p id="P18">The uncertainty associated with the randomness in the dynamism of the WMH clusters is commonly known as <italic>aleatoric uncertainty</italic><sup><xref ref-type="bibr" rid="R41">41</xref></sup>. It constitutes the biggest challenge in predicting WMH evolution, due to differences between experts in WMH delineation (i.e., ground truth reliability issues), and difficulty in differentiating textures and intensities of shrinking and growing WMH in the T2-FLAIR MRI sequence<sup><xref ref-type="bibr" rid="R24">24</xref></sup>. This uncertainty cannot be reduced by simply adding more training data<sup><xref ref-type="bibr" rid="R41">41</xref></sup>. The use of a Bayesian deep learning model named Probabilistic U-Net<sup><xref ref-type="bibr" rid="R26">26</xref></sup> was previously proposed to overcome this challenge, and generated better prediction results than non-probabilistic models<sup><xref ref-type="bibr" rid="R25">25</xref></sup>. In this study, we modify the previously proposed approach, as <xref ref-type="fig" rid="F2">Figure 2A</xref> schematically illustrates.</p><p id="P19">The probabilistic U-Net with adversarial training consists of a U-Net configuration<sup><xref ref-type="bibr" rid="R42">42</xref></sup>, two variational encoders called Prior Net and Posterior Net, and a discriminator network for adversarial training. In this study, the U-Net was used as segmentation network for predicting the DEM. Meanwhile, Prior Net and Posterior Net were used for variational inference so that uncertainty in predicting future WMH evolution is modeled probabilistically. Prior Net estimates a low-dimensional Gaussian distribution called prior latent space by producing its mean(s) and variance(s) from T2-FLAIR MRI at baseline (i.e., V1, denoted <italic>x</italic><sub><italic>V</italic>1</sub>). Whereas, Posterior Net estimates another low-dimensional Gaussian distribution called posterior latent space by producing its mean(s) and variance(s) from the follow-up T2-FLAIR MRI (i.e., V2, denoted <italic>x</italic><sub><italic>V</italic>2</sub>) and ground truth DEM (<italic>y</italic><sub><italic>DEM</italic></sub>). In reality, the posterior latent space is unknown because the follow-up T2-FLAIR MRI and the ground truth DEM are not present. Because of that, <italic>Kullback-Leibler</italic> divergence is used during training to estimate a posterior latent space from the prior latent space, which is obtained from the baseline T2-FLAIR MRI. In training, a sample <bold><italic>z</italic></bold><sub><italic>post</italic></sub> is taken from the posterior latent space (<bold><italic>z</italic></bold><sub><italic>post</italic></sub> ~ <italic>ùí©</italic> (<bold><italic>¬µ</italic></bold> <sub><italic>post</italic></sub>, <bold><italic>œÉ</italic></bold> <sub><italic>post</italic></sub>)) and then broadcasted and concatenated to the segmentation network. Multiple predictions of <inline-formula><mml:math id="M1"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>D</mml:mi><mml:mi>E</mml:mi><mml:mi>M</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>D</mml:mi><mml:mi>E</mml:mi><mml:mi>M</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:mo>‚ãØ</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>D</mml:mi><mml:mi>E</mml:mi><mml:mi>M</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> can be generated by using multiple samples <inline-formula><mml:math id="M2"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>z</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mspace width="0.2em"/></mml:mrow><mml:mn>1</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>z</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mspace width="0.2em"/></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:mo>‚ãØ</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi>z</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mspace width="0.2em"/></mml:mrow><mml:mi>n</mml:mi></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> from the prior latent space (<bold><italic>z</italic></bold><sub><italic>prior</italic></sub> ~ ùí© (<bold><italic>¬µ</italic></bold> <sub><italic>prior</italic></sub>, <bold><italic>œÉ</italic></bold> <sub><italic>prior</italic></sub>)). In this study 30 different DEM predictions were generated from 30 samples of <italic>z</italic><sub><italic>prior</italic></sub> from Prior Net for each input data/patient in the inference, and then averaged to get the final DEM prediction. Lastly, a discriminator network is used for adversarial training to enforce anatomically realistic DEM with regards to the T2-FLAIR MRI at V1 and V2, similar to previous work<sup><xref ref-type="bibr" rid="R24">24</xref></sup>. The discriminator network has 13.3M trainable parameters.</p></sec><sec id="S8"><title>Incorporation of stroke lesions information</title><p id="P20">Clinical studies have indicated that there are strong correlations between stroke occurrence and progression of WMH over time<sup><xref ref-type="bibr" rid="R14">14</xref></sup>. In a previous study<sup><xref ref-type="bibr" rid="R24">24</xref></sup>, stroke lesion volume was used as an auxiliary input to a framework designed to estimate WMH evolution, but it was outperformed by the use of Gaussian noises as auxiliary input representing uncertainty. Thus, in this study, we explore how information on stroke lesions can be incorporated to the probabilistic framework for better prediction of WMH evolution. We propose two different approaches: 1) jointly segmenting the WMH DEM and stroke lesions, and 2) incorporating probabilistic maps of WMH change in relation to stroke lesions‚Äô locations. The second proposed approach is more complex than the first proposed approach because it needs multiple preprocessing steps.</p><sec id="S9"><title>Joint segmentation of DEM and stroke lesions</title><p id="P21">Due to the similar tissue signal intensity of WMH and ischaemic stroke lesions in T2-FLAIR brain MRI, we hypothesised that performing a joint segmentation of the WMH DEM and stroke lesions will improve the accuracy in the prediction of the WMH DEM because the deep learning model will automatically learn the spatial correlation between both features. In this proposed approach stroke lesions do not need to be excluded in the preprocessing steps like in preceding works<sup><xref ref-type="bibr" rid="R24">24</xref>, <xref ref-type="bibr" rid="R25">25</xref></sup>. This approach can be implemented by adding an output channel to the segmentation layer of the segmentation network, thus increasing the number of output channels from the originally four (i.e., channels for background, shrinking WMH, growing WMH, and stable WMH), to five channels. Note in <xref ref-type="fig" rid="F1">Figure 1B</xref> that the label ‚Äòstroke lesions‚Äô has been added to the DEM of WMH. In this setting, the generator has 31.5M trainable parameters.</p></sec><sec id="S10"><title>Probabilistic maps of WMH change in relation to stroke lesions‚Äô locations</title><p id="P22">Results from a clinical study indicate that there are strong correlations between stroke lesions‚Äô location at baseline (V1) and WMH evolution after 1 year (V2)<sup><xref ref-type="bibr" rid="R20">20</xref></sup> for patients with a stroke of type lacunar. Specifically, if stroke lesions are subcortical and located in either the <italic>centrum semiovale</italic> or the <italic>lentiform nucleus</italic> at V1, then there are significant changes to the WMH at V2 (both in volume and location) specific to the location of the stroke lesions at V1. This clinical study made available probability maps of WMH change indicating brain locations where changes of WMH are significant at V2 depending on the infarcted region after accounting for vascular risk factors (VRF)<sup><xref ref-type="bibr" rid="R43">43</xref></sup>.</p><p id="P23">We use these probability maps as auxiliary data input to an attention U-Net<sup><xref ref-type="bibr" rid="R40">40</xref></sup> within the Probabilistic U-Net‚Äôs segmentation network. In it, the information of the probability maps is encoded through the gating signal encoder (GSE), with outputs used as gating signal in multiple resolutions (see <xref ref-type="fig" rid="F2">Figure 2B</xref>). The general idea of this approach is to focus the attention of the segmentation network on the areas that have high probability of WMH change according to the locations of the stroke lesions. For this approach, we performed brain parcellation and registration of the probability maps (in standard image space) to each patient‚Äôs space to identify the locations of stroke lesions for each specific patient. In this setting, the generator has 32.2M trainable parameters.</p><p id="P24">Similar to the original Attention U-Net<sup><xref ref-type="bibr" rid="R40">40</xref></sup>, this study uses an additive attention gate (AG), but obtains the gating signals from the GSE instead of from the outputs of the next (coarser) convolutional block. The schematic of the additive AG can be seen in <xref ref-type="fig" rid="F2">Figure 2C</xref>. Input features (<italic>x</italic><sub><italic>l</italic></sub>) are from the U-Net‚Äôs skip connections, gating signals (<italic>g</italic><sub><italic>l</italic></sub>) are from the gating signal encoder (GSE), <italic>Œ±</italic> are the attention coefficients learned in the training process used to scale input features <italic>x</italic><sub><italic>l</italic></sub> to highlight important areas, ‚®Å is an element-wise addition, ‚®Ç is an element-wise multiplication, and <italic>W</italic><sub><italic>g</italic></sub>, <italic>W</italic><sub><italic>x</italic></sub>, and <italic>œà</italic> are 1 √ó 1 √ó 1 convolution operations.</p></sec></sec><sec id="S11"><title>Configurations of the proposed approach</title><p id="P25">In this study we evaluate four configurations of the segmentation network. Three different configurations incorporating probabilistic maps of WMH and/or stroke lesions were compared with the vanilla U-Net. All of them took 5-8 minutes to train per epoch. <list list-type="order" id="L3"><list-item><p id="P26"><bold>PUNet</bold>: The original U-Net<sup><xref ref-type="bibr" rid="R42">42</xref></sup> is used for the segmentation network.</p></list-item><list-item><p id="P27"><bold>PUNet-wSL</bold>: The original U-Net<sup><xref ref-type="bibr" rid="R42">42</xref></sup> is used for the segmentation network, and joint segmentation of DEM of WMH and stroke lesions is performed.</p></list-item><list-item><p id="P28"><bold>Att-PUNet</bold>: Attention U-Net with probabilistic maps of WMH change is used for the segmentation network, instead of the original U-Net.</p></list-item><list-item><p id="P29"><bold>Att-PUNet-wSL</bold>: Attention U-Net with probabilistic maps of WMH change is used for the segmentation network, and, simultaneously, joint segmentation of DEM and stroke lesions is performed.</p></list-item></list></p></sec></sec><sec id="S12"><title>Experimental Setting</title><p id="P30">This section describes the dataset, training scheme, cost function, and evaluation metrics this study uses.</p><sec id="S13"><title>Dataset</title><p id="P31">For comparability of our results with those previously published, we use the same dataset as<sup><xref ref-type="bibr" rid="R24">24</xref></sup>, which comprises MRI data from <italic>n</italic> = 152 patients that had a mild-to-moderate stroke and consented to participate in a study of stroke mechanisms<sup><xref ref-type="bibr" rid="R3">3</xref></sup>. The study protocols were approved by the Lothian Ethics of Medical Research Committee (REC 09/81101/54) and NHS Lothian R+D Office (2009/W/NEU/14), on the 29th of October 2009. All patients were imaged with the same acquisition protocol at two time points (i.e., baseline scan (V1), and a year after the baseline scan (V2)). In total, 304 MRI from 152 stroke patients (i.e., 152 V1 MRI and 152 V2 MRI) were used. Overall increase in WMH volume was identified in 98 of the 152 patients and reduction of WMH total volume in 54 patients. The magnitudes of WMH change (in <italic>ml</italic>) and their distribution for all patients can be seen in <xref ref-type="fig" rid="F1">Figure 1C and 1D</xref>.</p><p id="P32">All T2-FLAIR brain MRI were acquired with a GE 1.5T scanner, and a semi-automatic multi-spectral method was used to produce several brain masks including intracranial volume, cerebrospinal fluid, stroke lesions, and WMH, all which were visually checked and manually edited by an expert<sup><xref ref-type="bibr" rid="R44">44</xref></sup>. For the prediction of WMH evolution from V1 to V2, T2-FLAIR brain MRI at follow-up (V2) and T2-FLAIR brain MRI at baseline (V1) were linearly and rigidly aligned to a common space using FSL-FLIRT<sup><xref ref-type="bibr" rid="R45">45</xref></sup>. The space transformations were applied to all labels (i.e., binary/indexed masks) including manually-derived (i.e., after manually correcting results from a semi-automatic segmentation) labels of WMH. The spatial resolution of the images was 256 √ó 256 √ó 42 with slice thickness of 0.9375 √ó 0.9375 √ó 4 mm. We generated a DEM for each patient by subtracting the manually corrected segmentation of WMH at V1 from the manually corrected segmentation of WMH at V2.</p></sec><sec id="S14"><title>Data pre-processing for incorporation of probabilistic maps of WMH change</title><p id="P33">Given the influence of stroke lesion location in WMH change and evolution patterns when the stroke lesions are located at the <italic>centrum semiovale</italic> or the <italic>lentiform nucleus</italic><sup><xref ref-type="bibr" rid="R20">20</xref></sup>, we only used probability maps of WMH change based on stroke lesions incident at <italic>centrum semiovale</italic> or <italic>lentiform nucleus</italic>, publicly available<sup><xref ref-type="fn" rid="FN3">1</xref></sup>.</p><p id="P34">Probability maps in the standard space were obtained from a clinical study<sup><xref ref-type="bibr" rid="R20">20</xref></sup> and then registered to each patient‚Äôs native space using niftyreg through TractoR<sup><xref ref-type="bibr" rid="R46">46</xref></sup>. To identify the location of stroke lesions within a human brain, an age-relevant brain template and its corresponding brain parcellation), also publicly available<sup><xref ref-type="bibr" rid="R47">47</xref></sup>, were registered to each patient‚Äôs native space. If there were no stroke lesions at <italic>centrum semiovale</italic> or <italic>lentiform nucleus</italic> in a patient, then zero matrices were used as probabilistic maps (i.e., there are no specific areas of the brain or feature maps that the neural networks should look for via attention). Both probabilistic maps for <italic>centrum semiovale</italic> or <italic>lentiform nucleus</italic> were concatenated before being used as auxiliary input in the segmentation network (see <xref ref-type="fig" rid="F2">Figure 2B</xref> for illustration).</p></sec><sec id="S15"><title>Training scheme</title><p id="P35">To facilitate comparability between methods and results, we used the same preprocessing pipeline as previous studies<sup><xref ref-type="bibr" rid="R24">24</xref>, <xref ref-type="bibr" rid="R25">25</xref></sup>. To make sure all patients are used in both training and testing, 4-fold cross validation with 512 epochs was performed with each fold consisting of 114 MRI for training and 38 for testing. In the training phase, we randomly chose 14 out of 114 MRI training data for validation and used that for selecting the best model that produced the lowest validation loss (i.e., error difference during training). Values of T2-FLAIR brain MRI were normalised into zero mean and unit variance for each patient. Data augmentations of shifting, scaling, horizontal and vertical flip, and elastic transformations were performed.</p></sec><sec id="S16"><title>Cost function</title><p id="P36">We used three lost functions in training to optimize the different networks. These were: 1) segmentation loss (<italic>‚Ñí</italic><sub><italic>seg</italic></sub>), 2) probabilistic loss using <italic>Kullback-Leibler</italic> Divergence (<italic>ùíü</italic><sub><italic>KL</italic></sub>), and 3) adversarial loss (<italic>‚Ñí</italic><sub><italic>adv</italic></sub>). We used the segmentation loss to compare the output of the segmentation network (i.e., the predicted DEM segmentation) against the ground truth of the DEM. The probabilistic loss was used to compare the similarity between prior and posterior latent spaces. And the adversarial loss was used to compare the similarity between the ground truth DEM and the predicted DEM.</p><sec id="S17"><title>Segmentation loss</title><p id="P37">For the segmentation loss, we used the weighted focal loss with <italic>Œ≥</italic> (i.e., focal loss‚Äô hyperparameter) set to <italic>Œ≥</italic> = 2 following the recommendation of the original paper<sup><xref ref-type="bibr" rid="R48">48</xref></sup>. <xref ref-type="disp-formula" rid="FD1">Equation 1</xref> describes the weighted focal loss function for all pixels from an MRI slice where <italic>y</italic><sub><italic>i</italic>,<italic>c</italic></sub> ‚àà {0, 1} indicates the class membership for pixel <italic>i</italic> to class <italic>c, p</italic><sub><italic>i</italic></sub> the predicted probability that pixel <italic>i</italic> belongs to class <italic>c</italic>, and <italic>Œ±</italic><sub><italic>c</italic></sub> is the weight for class <italic>c</italic>. The larger the value of <italic>Œ±</italic><sub><italic>c</italic></sub>, the larger the contribution of class <italic>c</italic> to the loss value. <italic>P</italic> is the random variable for the predicted probability, <italic>Y</italic> is the random variable for the target classes, <italic>Œ±</italic> are the weights for all classes, <italic>N</italic> is the number of pixels in an axial MRI slice (i.e., <italic>N</italic> = 256), and <italic>M</italic> is the number of classes in the DEM (i.e., <italic>N</italic> = 4 if stroke lesions are not automatically segmented and <italic>N</italic> = 5 if otherwise). Based on our preliminary experiments, the best weights were <italic>Œ±</italic><sub><italic>c</italic>=0</sub> = 0.25 for background, <italic>Œ±</italic><sub><italic>c</italic>=1</sub> = 0.75 for shrinking WMH, <italic>Œ±</italic><sub><italic>c</italic>=2</sub> = 0.75 for growing WMH, <italic>Œ±</italic><sub><italic>c</italic>=3</sub> = 0.5 for stable WMH, and <italic>Œ±</italic><sub><italic>c</italic>=4</sub> = 0.75 for stroke lesions. <disp-formula id="FD1"><label>(1)</label><mml:math id="M3"><mml:mrow><mml:mtext>FL</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>Œ±</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>‚àí</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mi>‚àë</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mi>‚àë</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mi>Œ±</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>‚àí</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>Œ≥</mml:mi></mml:msup><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p id="P38">Note that the predicted segmentation of the DEM produced by the Probabilistic U-Net is conditioned to either the posterior or the prior latent space. In training, the predicted DEM segmentation is conditioned to the posterior latent space defined by <bold><italic>z</italic></bold><sub><italic>prior</italic></sub> ~ <italic>ùí©</italic> (<bold><italic>¬µ</italic></bold><sub><italic>prior</italic></sub>, <bold><italic>œÉ</italic></bold><sub><italic>prior</italic></sub>) and modelled by the Posterior Net. On the other hand, the predicted DEM segmentation is conditioned by the prior latent space that is formulated as <bold><italic>z</italic></bold><sub><italic>post</italic></sub> ~ <italic>ùí©</italic> (<bold><italic>¬µ</italic></bold><sub><italic>post</italic></sub>, <bold><italic>œÉ</italic></bold><sub><italic>post</italic></sub>) and modelled by the Prior Net in testing/inference. Thus, the probabilistic segmentation loss <italic>‚Ñí</italic><sub><italic>seg</italic></sub> can be formulated as <xref ref-type="disp-formula" rid="FD2">Equation 2</xref>, where <italic>≈∂</italic><sub><italic>DEM</italic></sub> is the predicted DEM segmentation and vol(<italic>≈∂</italic><sub><italic>DEM</italic></sub>, <italic>Y</italic><sub><italic>DEM</italic></sub>) is the newly proposed volume loss to avoid over- and under-segmentation in relation to the future volume of WMH (discussed in the next section). <disp-formula id="FD2"><label>(2)</label><mml:math id="M4"><mml:mrow><mml:msub><mml:mi>‚Ñí</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext>FL</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>D</mml:mi><mml:mi>E</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>‚à£</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>V</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>z</mml:mi></mml:mstyle><mml:mrow><mml:mtext>post</mml:mtext><mml:mspace width="0.2em"/></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>Œ±</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>vol</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>D</mml:mi><mml:mi>E</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>E</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p></sec><sec id="S18"><title>Volume loss</title><p id="P39">To avoid over- and under-segmentation in relation to the future volume of WMH, a volume-loss (that is formulated as <xref ref-type="disp-formula" rid="FD3">Equation 3</xref>) is added to <xref ref-type="disp-formula" rid="FD2">Equation 2</xref> as regularization term. The term keeps the predicted future volume of WMH (i.e., calculated from the predicted DEM (<italic>≈∂</italic><sub><italic>DEM</italic></sub>)) close to the reference future volume of the WMH (i.e., calculated from the ground truth DEM (<italic>Y</italic><sub><italic>DEM</italic></sub>)) by using mean squared error (MSE). Note that only class <italic>c</italic> = 2 (for growing WMH) and class <italic>c</italic> = 3 (for stable WMH) that matter in the calculation of future volume of WMH at V2. A denominator of 1000 was used to estimate the volume of WMH in <italic>ml</italic> (i.e., as voxel dimensions are in <italic>mm</italic><sup><xref ref-type="bibr" rid="R3">3</xref></sup>). In preliminary experiments, we found that having the same weights for segmentation loss of FL (<italic>P</italic>(<italic>≈∂</italic><sub><italic>DEM</italic></sub>|<italic>X</italic><sub><italic>V</italic>1</sub>, <bold><italic>z</italic></bold><sub><italic>post</italic></sub>),<italic>Y, Œ±</italic>) and volume loss of vol (<italic>≈∂</italic><sub><italic>DEM</italic></sub>, <italic>Y</italic><sub><italic>DEM</italic></sub>) in <xref ref-type="disp-formula" rid="FD3">Equation 3</xref> produced the best results for predicting both future volume and spatial dynamic changes of WMH. <disp-formula id="FD3"><label>(3)</label><mml:math id="M5"><mml:mrow><mml:mi>vol</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>D</mml:mi><mml:mi>E</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>E</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>MSE</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>‚àë</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:mn>1000</mml:mn></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>‚àë</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:mn>1000</mml:mn></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p></sec><sec id="S19"><title>Probabilistic loss</title><p id="P40">We used <italic>Kullback-Leibler</italic> Divergence score (<italic>ùíü</italic><sub><italic>KL</italic></sub>) in the training process for training the Prior Net and Posterior Net. In this setting, Prior Net and Posterior Net were trained together with the Segmentation Net for predicting the DEM. Let <italic>Q</italic> be the posterior distribution from the Posterior Net and <italic>P</italic> be the prior distribution from the Prior Net. The difference between the posterior distribution <italic>Q</italic> and the prior distribution <italic>P</italic> is described by <italic>ùíü</italic><sub><italic>KL</italic></sub> in <xref ref-type="disp-formula" rid="FD4">Equation 4</xref> where <italic>X</italic><sub><italic>V</italic>2</sub> is the T2-FLAIR at V2, <italic>Y</italic><sub><italic>DEM</italic></sub> is the true DEM, and <italic>X</italic><sub><italic>V</italic>1</sub> is the T2-FLAIR at V1. Based on our preliminary experiments, the dimension for both <bold><italic>z</italic></bold><sub><italic>post</italic></sub> and <bold><italic>z</italic></bold><sub><italic>prior</italic></sub> is 4 (smaller than the original paper<sup><xref ref-type="bibr" rid="R26">26</xref></sup> which used 6). <disp-formula id="FD4"><label>(4)</label><mml:math id="M6"><mml:mrow><mml:msub><mml:mo>ùíü</mml:mo><mml:mrow><mml:mi>K</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>Q</mml:mi><mml:mo>‚Äñ</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mo>ùîº</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mtext>post</mml:mtext><mml:mspace width="0.2em"/></mml:mrow></mml:msub><mml:mo>~</mml:mo><mml:mi>Q</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mtext>prior</mml:mtext><mml:mspace width="0.2em"/></mml:mrow></mml:msub><mml:mo>~</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>log</mml:mi><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>V</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>E</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>‚àí</mml:mo><mml:mi>log</mml:mi><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>V</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p></sec><sec id="S20"><title>Adversarial loss</title><p id="P41">Similar to a previous study<sup><xref ref-type="bibr" rid="R25">25</xref></sup>, the original adversarial loss proposed by<sup><xref ref-type="bibr" rid="R39">39</xref></sup> was slightly modified by adding a segmentation loss (<italic>‚Ñí</italic><sub><italic>seg</italic></sub>) so that the Segmentation Net was also optimised to produce better segmentation result. Similar to the original paper<sup><xref ref-type="bibr" rid="R39">39</xref></sup>, the Segmentation Net aims at minimising <xref ref-type="disp-formula" rid="FD5">Equation 5</xref> while the discriminator network aims at maximising it. In <xref ref-type="disp-formula" rid="FD5">Equation 5</xref>, <italic>G</italic> is the Segmentation Net, <italic>D</italic> is the discriminator network, <italic>y</italic> ~ (<italic>X</italic><sub><italic>V</italic>1</sub>, <italic>X</italic><sub><italic>V</italic>2</sub>,<italic>Y</italic><sub><italic>DEM</italic></sub>) is the joint distribution of T2-FLAIR MRI at V1 and V2 and ground truth DEM (i.e., <italic>X</italic><sub><italic>V</italic>1</sub>, <italic>X</italic><sub><italic>V</italic>2</sub>, and <italic>Y</italic><sub><italic>DEM</italic></sub> respectively), <italic>x</italic> ~ (<italic>X</italic><sub><italic>V</italic>1</sub>, <italic>X</italic><sub><italic>V</italic>2</sub>,<italic>≈∂</italic><sub><italic>DEM</italic></sub>) is the joint distribution of T2-FLAIR MRI at V1 and V2 and predicted DEM (i.e., <italic>X</italic><sub><italic>V</italic>1</sub>, <italic>X</italic><sub><italic>V</italic>2</sub>, and <italic>≈∂</italic><sub><italic>DEM</italic></sub> respectively), ùîº<sub><italic>y</italic></sub> ~ <italic>Y</italic><sub><italic>GAN</italic></sub> is the expected value over <italic>Y</italic><sub><italic>GAN</italic></sub>, and ùîº<sub><italic>x</italic></sub> is the expected value over <italic>X</italic><sub><italic>GAN</italic></sub>. <disp-formula id="FD5"><label>(5)</label><mml:math id="M7"><mml:mrow><mml:msub><mml:mi>‚Ñí</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mo>ùîº</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>~</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>A</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mi>log</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mo>ùîº</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>~</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>A</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>log</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>‚àí</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>G</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>‚Ñí</mml:mi><mml:mrow><mml:mtext>seg</mml:mtext><mml:mspace width="0.2em"/></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>G</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p></sec></sec><sec id="S21"><title>Evaluation measurements</title><p id="P42">In this study, we used the following evaluation measurements to assess the performance of all configurations. <list list-type="order" id="L4"><list-item><p id="P43"><bold>Volume error</bold> measures how close the predicted WMH volumes are with the real WMH volumes at the follow-up assessment (V2). This is the main performance measurement. Volume error can be calculated by using <xref ref-type="disp-formula" rid="FD6">Equation 6</xref> where <inline-formula><mml:math id="M8"><mml:mrow><mml:msubsup><mml:mtext>vol</mml:mtext><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.2em"/></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> is the true volume of WMH at V2, <inline-formula><mml:math id="M9"><mml:mrow><mml:msubsup><mml:mtext>vol</mml:mtext><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> is the predicted volume of WMH at V2, and <inline-formula><mml:math id="M10"><mml:msubsup><mml:mtext>vol</mml:mtext><mml:mrow><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mspace width="0.2em"/></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> is the volume error. <disp-formula id="FD6"><label>(6)</label><mml:math id="M11"><mml:mrow><mml:msubsup><mml:mrow><mml:mtext>vol</mml:mtext></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mspace width="0.2em"/></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mtext>vol</mml:mtext></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mspace width="0.2em"/></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>‚àí</mml:mo><mml:msubsup><mml:mrow><mml:mtext>vol</mml:mtext></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.2em"/></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></disp-formula></p></list-item><list-item><p id="P44"><bold>Accuracy of prediction</bold> assesses how good our proposed models predict WMH evolution for all patients (i.e., growing or shrinking). Accuracy of prediction for growing and shrinking WMH (i.e., subjects with growing and shrinking WMH are correctly predicted to have growing and shrinking WMH respectively) is calculated by the <xref ref-type="disp-formula" rid="FD7">Equations 7</xref> and <xref ref-type="disp-formula" rid="FD8">8</xref> respectively. <italic>N</italic><sub>GRW</sub> and <italic>N</italic><sub>SHR</sub> are the number of subjects in our dataset who have growing and shrinking WMH. Whereas, <italic>P</italic><sub>GRW</sub> and <italic>P</italic><sub>SHR</sub> are the number of subjects correctly predicted as having growing and shrinking WMH. <disp-formula id="FD7"><label>(7)</label><mml:math id="M12"><mml:mtext>GRW</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mtext>GRW</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>R</mml:mi><mml:mi>W</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math></disp-formula>
<disp-formula id="FD8"><label>(8)</label><mml:math id="M13"><mml:mtext>SHR</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mtext>GRW</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mtext>SHR</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math></disp-formula></p></list-item><list-item><p id="P45"><bold>Estimated volume interval (EVI)</bold> measures the deviation of the predicted WMH volume at follow-up (V2) from the lowest and highest possible predicted volumes of WMH<sup><xref ref-type="bibr" rid="R25">25</xref></sup>. The lowest and highest possible predicted volumes of WMH at V2 are estimated by ignoring the prediction channel for growing WMH and shrinking WMH respectively. In other words, the lowest possible volume of WMH (dubbed as Minimum Volume Estimation or ‚ÄòMinVE‚Äô) is assumed to occur when there are no growing WMH in the patient‚Äôs brain. Whereas, the highest possible volume of WMH (dubbed as Maximum Volume Estimation or ‚ÄòMaxVE‚Äô) is assumed to occur when there are no shrinking WMH in the patient‚Äôs brain. There are 3 metrics in this evaluation: ‚ÄúCP‚Äù which stands for ‚ÄúCorrect Prediction‚Äù (calculated by using <xref ref-type="disp-formula" rid="FD9">Equation 9</xref>), ‚ÄúCPinEVI‚Äù which stands for ‚ÄúCorrect Prediction in Estimated Volume Interval‚Äù (calculated by using <xref ref-type="disp-formula" rid="FD10">Equation 10</xref>), and ‚Äú(CP+WP)inEVI‚Äù which stands for ‚ÄúCorrect Prediction + Wrong Prediction but still in EVI‚Äù (calculated by using <xref ref-type="disp-formula" rid="FD11">Equation 11</xref>). In these equations, <inline-formula><mml:math id="M14"><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mtext>GRW</mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="M15"><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mtext>SHR</mml:mtext><mml:mspace width="0.2em"/></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> are the number of subjects that are correctly predicted as having growing and shrinking WMH and have their estimated volumes of WMH at V2 are located between ‚ÄòMinVE‚Äô and ‚ÄòMaxVE‚Äô. Whereas, <italic>P</italic><sup><italic>in</italic></sup> is the number of subjects whose estimated volumes of WMH at V2 are located between ‚ÄòMinVE‚Äô and ‚ÄòMaxVE‚Äô. <disp-formula id="FD9"><label>(9)</label><mml:math id="M16"><mml:mtext>CP</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mtext>GRW</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mtext>SHR</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mtext>GRW</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mtext>SHR</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math></disp-formula>
<disp-formula id="FD10"><label>(10)</label><mml:math id="M17"><mml:mtext>CPinEVI</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mtext>GRW</mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mtext>SHR</mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mtext>GRW</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mtext>SHR</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math></disp-formula>
<disp-formula id="FD11"><label>(11)</label><mml:math id="M18"><mml:mo stretchy="false">(</mml:mo><mml:mtext>CP</mml:mtext><mml:mo>+</mml:mo><mml:mtext>WP</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mspace width="0.2em"/><mml:mtext>inEVI</mml:mtext><mml:mspace width="0.2em"/><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mtext>GRW</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mtext>SHR</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math></disp-formula></p></list-item><list-item><p id="P46"><bold>Spearman correlation with Prins clinical scores</bold> The clinical scoring system for progression of WMH, known as Prins visual scores<sup><xref ref-type="bibr" rid="R38">38</xref></sup>, gives a +1 for each WMH cluster that increases or appears <italic>de nuovo</italic> in a subsequent scan compared with a previous scan in the periventricular or deep white matter of each lobe (i.e., frontal, parietal, temporal and occipital), -1 if a reduction in volume or disappearance of a WMH cluster is detected, and 0 if no change can be appreciated. For our evaluation, we summed the overall scores in each region to obtain a total Prins score. We calculate the Spearman correlation between the total Prins scores and the spatial volume growth, shrinkage, and overall change that each scheme outputs.</p></list-item><list-item><p id="P47"><bold>Spatial agreement</bold> between predicted and ground truth DEM is measured by the Dice similarity coefficient (DSC)<sup><xref ref-type="bibr" rid="R49">49</xref></sup>. Higher values of DSC mean better performance. DSC can be calculated by using <xref ref-type="disp-formula" rid="FD12">Equation 12</xref>, where <italic>TP</italic> is true positive, <italic>FP</italic> is false positive and <italic>FN</italic> is false negative. This is a secondary performance measurement as predicted future WMH volumes at V2 are calculated from segmentation masks. <disp-formula id="FD12"><label>(12)</label><mml:math id="M19"><mml:mtext>DSC</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>√ó</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo>√ó</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:math></disp-formula></p></list-item><list-item><p id="P48"><bold>Uncertainty quantification and correlation analysis</bold> to measure correlation between uncertainty values in predicted DEM and DSC values, is calculated as the Cross Entropy (CE) between the mean sample and all samples as per <xref ref-type="disp-formula" rid="FD13">Equation 13</xref> where <italic>Œ≥</italic> is the uncertainty map, <italic>s</italic> is a set of predictions from an input, <italic>≈ù</italic> is the mean sample of set <italic>s</italic>, CE is the cross entropy function, and ùîº is the expected value function. <disp-formula id="FD13"><label>(13)</label><mml:math id="M20"><mml:mi>Œ≥</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mtext>s</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>ùîº</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mtext>CE</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mtext>s</mml:mtext><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mtext>s</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:math></disp-formula></p></list-item></list></p></sec></sec><sec id="S22" sec-type="results | discussion"><title>Results and Discussion</title><p id="P49">In this section, we show and discuss the results of the evaluations using the four performance measurements, namely volume based evaluation, qualitative/visual evaluation, spatial agreement evaluation,uncertainty quantification, and correlation with clinical visual scores.</p><sec id="S23"><title>Evaluation against clinical visual scores of WMH progression</title><p id="P50"><xref ref-type="fig" rid="F4">Figure 4</xref> shows the results from calculating the non-parametric correlations between Prins clinical visual scores and the spatial volume growth and shrinkage from each scheme. The spatial growth from all models correlated with Prins scores, with the output from PUNet-vol showing the highest correlation following the ground truth (Spearman rho = 0.40 and 0.58 respectively). This correlation slightly improved (i.e., to Spearman rho = 0.42) when attention was incorporated in the scheme. Prins showed net shrinkage for only six patients, as shrinkage in individual clusters were nullified by growth in others. The ground truth showed the worst correlation with Prins in terms of shrinkage (Spearman rho = 0.45), followed by PUnet-wSL (Spearman rho = 0.47 without attention and 0.50 with it). The highest correlation values in shrinkage were achieved with PUNet-vol without attention (Spearman rho = 0.59), and PUNet with attention (Spearman rho = 0.60). In general, in models without attention WMH shrinkage and growth correlated better with Prins than when attention was used. In line with a previous study<sup><xref ref-type="bibr" rid="R50">50</xref></sup>, the spatial net change did not correlate with Prins, neither improving when attention was used.</p></sec><sec id="S24"><title>Results on predicting future volumes of WMH</title><p id="P51">WMH volume change is an important clinical feature for clinical research and could be an important biomarker if available for clinical practice. Hence, we evaluated how well WMH volume at V2 (1 year later) can be estimated by using our proposed models. <xref ref-type="table" rid="T1">Table 1</xref> shows the prediction accuracy of WMH volumetric progression (i.e., whether WMH volume will grow or shrink at V2 for each patient) calculated using <xref ref-type="disp-formula" rid="FD7">Equations 7</xref> and <xref ref-type="disp-formula" rid="FD8">8</xref>, the estimated volume interval (EVI) calculated using <xref ref-type="disp-formula" rid="FD9">Equations 9</xref>, <xref ref-type="disp-formula" rid="FD10">10</xref>, and <xref ref-type="disp-formula" rid="FD11">11</xref>, and the volumetric error calculated using <xref ref-type="disp-formula" rid="FD6">Equation 6</xref>.</p><p id="P52">As <xref ref-type="table" rid="T1">Table 1</xref> shows, PUNet-wSL-vol performed better than the rest of the models producing either the best or second best results for almost all evaluation metrics except predicting growing WMH (GRW). There were more patients with net growing WMH than with net shrinking WMH in the dataset, thus hinting to a possible bias by the other models towards growing WMH. Reduction in WMH volume was mainly observed in patients with high WMH volume (see <xref ref-type="fig" rid="F3">Figure 3B</xref>).</p><p id="P53">As <xref ref-type="fig" rid="F3">Figure 3A</xref> shows, the average progression of WMH volume from V1 to V2 (in <italic>ml</italic>) was well estimated by PUNet-wSL-vol (i.e., brown dashed line representing PUNet-wSL-vol is coincident with the red line representing the ground truth). In general, as expected, models trained using volume loss (<xref ref-type="disp-formula" rid="FD3">Equation 3</xref>) (i.e., PUNet-vol (green line), Att-PUNet-vol (orange line), PUNet-wSL-vol (brown line), and Att-PUNet-wSL-vol (grey line)) produced more accurate progression of WMH volume from V1 to V2 than those which did not use volume loss during training. Of note, however, PUNet-wSL (yellow line) and Att-PUNet-wSL (pink line), had lines close to the red line of the ground truth. Overall, models jointly segmenting stroke lesions and WMH improved the estimation of future volume of WMH at V2.</p><p id="P54">To further analyse the accuracy of the winner scheme in estimating the WMH volume change, we grouped the patients in quintiles according to their WMH volume at baseline and calculated the WMH change produced by the reference (i.e., ground truth) segmentation, and the PUNet model using volume loss with and without jointly segmenting the DEM and the stroke lesions. As can be appreciated from <xref ref-type="fig" rid="F3">Figure 3B</xref>, the scheme that jointly segmented the stroke lesions and the DEM of WMH change produced mean, median and a distribution of WMH volume change values across the sample more similar to those from the reference segmentation, than the scheme that only segmented the DEM of WMH change for all but the highest quintile.</p><p id="P55">We also divided the reference WMH segmentations into intense and less intense WMH as per<sup><xref ref-type="bibr" rid="R44">44</xref></sup>, and considered an ‚Äòextended‚Äô WMH volume that included the WMH surrounding lacunes, thought to be reminiscences of old small subcortical infarcts (see <xref ref-type="fig" rid="F3">Figure 3C</xref>). It can be observed that the volume output from the scheme that jointly segmented the stroke lesions with the DEM of WMH change resulted strikingly similar to the one produced by this ‚Äòextended‚Äô WMH segmentation (see gray and yellow box plots in <xref ref-type="fig" rid="F3">Figures 3B and 3C</xref>, respectively), especially for patients in the highest quintile. Patients in this quintile exhibit a high burden of WMH surrounding lacunes and coalescing with previous strokes. Therefore, it is expected that not only AI schemes, but also experts would consider all hyperintensities as part of the white matter disease in absence of any other sequence or clinical information from this patient group. It can be also seen that the reference WMH change (i.e., blue box plot in the same figure) is mainly determined by the less intense WMH change (i.e., pale green box plot), therefore explaining the difficulty in obtaining accurate growth and shrinking spatial estimates and putting into question the accuracy in the spatial estimates of the ground truth segmentations given the degree of observer-dependent manual input they had.</p></sec><sec id="S25"><title>Spatial agreement evaluation</title><p id="P56">Spatial agreement evaluation was performed to see whether closer predicted future volumes of WMH to the reference future WMH volumes is followed by higher spatial agreements between predicted DEM and ground truth DEM or not. <xref ref-type="table" rid="T2">Table 2</xref> shows performances of all tested configurations using DSC (<xref ref-type="disp-formula" rid="FD12">Equation 12</xref>). The best and second best measurement values for each DEM label are written in bold and underlined respectively. Note that the ‚ÄòChanging‚Äô refers to shrinking and growing WMH combined together as one label, ‚ÄòAverage‚Äô is calculated by averaging DSC values of ‚ÄòShrinking‚Äô, ‚ÄòGrowing‚Äô, and ‚ÄòStable‚Äô, and ‚ÄòStroke Lesions‚Äô is only available when joint segmentation of WMH DEM and stroke lesions are performed.</p><p id="P57">From <xref ref-type="table" rid="T2">Table 2</xref>, we can see that joint segmentation of DEM and stroke lesions with volume loss (PUNet-wSL-vol) produced the best segmentation results based on DSC for ‚ÄòShrinking‚Äô (0.2290) and ‚ÄòAverage‚Äô (0.3598). Furthermore, we can see that joint segmentation of DEM and stroke lesions by PUNet-wSL (i.e., without volume loss) and PUNet-wSL-vol (i.e., with volume loss) produced either the best or second best DSC values for all categories of DEM, except for ‚ÄòGrowing‚Äô and ‚ÄòStable‚Äô WMH (achieved by the original models of PUNet and PUNet-vol). On the other hand, models with auxiliary input of probabilistic maps of WMH change, (i.e., Att-PUNet, Att-PUNet-vol, Att-PUNet-wSL, and Att-PUNet-wSL-vol) failed to improve the performance of the DEM segmentation while improved the performance of ‚ÄòStroke Lesions‚Äô segmentation. Furthermore, models trained using volume loss (i.e., PUNet-vol, Att-PUNet-vol, PUNet-wSL-vol, and Att-PUNet-wSL-vol) produced better DSC values on ‚ÄòAverage‚Äô, which indicates that the volume loss impacted positively in the task of estimating the DEM of WMH.</p><p id="P58">DSC is influenced by TP, FP, and FN counts between ground truth mask and predicted segmentation, but TP, FP, and FN counts are highly imbalance in the segmentation of brain lesions. To provide a better illustration of the relationship between DSC and corresponding TP, FP, and FN counts, we present the confusion matrices and a table compiling these values from the ‚ÄòShrinking‚Äô WMH and ‚ÄòGrowing‚Äô WMH labels obtained from PUNet-vol and PUNet-wSL-vol configurations (<xref ref-type="fig" rid="F5">Figure 5</xref> and <xref ref-type="table" rid="T3">Table 3</xref> respectively). <xref ref-type="fig" rid="F5">Figure 5</xref> contains the number of segmented voxels corresponding to each label (<italic>n</italic>) from all patients in the testing set, false negative rate (<italic>fnr</italic>), false positive rate (<italic>fpr</italic>), true positive rate (TPR), and positive predictive value (PPV). <xref ref-type="table" rid="T3">Table 3</xref> compiles values of DSC, PRE, REC, FN, and FP for the ‚ÄòShrinking‚Äô WMH and ‚ÄòGrowing‚Äô WMH labels from both PUNet-vol and PUNet-wSL-vol configurations. From both, <xref ref-type="fig" rid="F5">Figure 5</xref> and <xref ref-type="table" rid="T3">Table 3</xref>, we can see that PUNet-vol produced higher PRE value for ‚ÄòShrinking‚Äô WMH with lower FP counts than PUNet-wSL-vol. But PUNet-vol produced lower PRE value for ‚ÄòGrowing‚Äô WMH as it produced higher FP counts than PUNet-wSL-vol in this label/category.</p><p id="P59">Confusion matrices in <xref ref-type="fig" rid="F5">Figure 5</xref>, show a high level of uncertainty between ‚ÄòGrowing‚Äô WMH and ‚ÄòNormal‚Äô brain tissues as more than 50% of the ‚ÄòGrowing‚Äô WMH identified in the ground truth DEM were wrongly predicted as ‚ÄòNormal‚Äô tissues (i.e., under-segmentation of ‚ÄòGrowing‚Äô WMH which leads to higher <italic>fnr</italic> in the confusion matrix) by PUNet-vol and PUNet-wSL-vol configurations with <italic>fnr</italic> = 0.5339 and <italic>fnr</italic> = 0.5254 respectively. In extended experiments, all proposed configurations were observed producing the same level of under-segmentation for ‚ÄòGrowing‚Äô WMH. In general, areas of ‚ÄòGrowing‚Äô WMH are difficult to be differentiated from ‚ÄòNormal‚Äô brain tissues due to the high level of uncertainty between these two classes. Overall, for the model that jointly segmented the stroke lesions and the WMH, mean DSC values were slightly better in this sample.</p><p id="P60">Although the combined segmentation of WMH and stroke lesions is not the main focus of this study, it must be noted that the state-of-the-art joint segmentation method for WMH and stroke lesions (i.e., sub-acute and chronic as per in the present dataset)<sup><xref ref-type="bibr" rid="R51">51</xref></sup>, which used a UResNet configuration, reported a mean (SD) Dice equal to 0.4 (0.252) for stroke lesions segmentation, lower than any of our joint-segmentation schemes (see <xref ref-type="table" rid="T2">Table 2</xref>).</p></sec><sec id="S26"><title>Qualitative/visual evaluation of spatial agreement between ground truth and predicted DEMs</title><p id="P61"><xref ref-type="fig" rid="F6">Figures 6A and 6B</xref> show examples of the predicted DEM segmentation from PUNet-wSL-vol and PUNet-vol and their corresponding DEM ground truth forpatients with high and low DSC values on ‚ÄòAverage‚Äô respectively. PUNet-wSL-vol and PUNet-vol were chosen for qualitative/visual evaluation as they produced the best and second best DSC values on ‚ÄòAverage‚Äô (See <xref ref-type="table" rid="T2">Table 2</xref>). <xref ref-type="fig" rid="F6">Figure 6A</xref> shows that PUNet-wSL-vol, which jointly segments WMH DEM and stroke lesions, produced better segmentation results than PUNet-vol, which exhibits a high level of uncertainty in predicting shrinking and growing WMH. Confusion matrices in <xref ref-type="fig" rid="F5">Figure 5</xref> show that PUNet-wSL-vol lowered this uncertainty by producing lower rates of <italic>fnr</italic> (and their corresponding FN counts (<italic>n</italic>)) for shrinking and growing WMH) in most cases. <xref ref-type="fig" rid="F6">Figure 6B</xref> illustrates cases where low DSC values of predicted WMH DEM were caused mostly by two reasons: low WMH volume at V1 (patient and MSSB172) and brain MRI artefacts (patient MSSB211). Based on our observations, these two problems were relevant throughout the sample in our evaluations.</p></sec><sec id="S27"><title>Uncertainty quantification</title><p id="P62">As all configurations evaluated are based on the Probabilistic U-Net, uncertainty for each label in the DEM was quantified by predicting DEM for each subject multiple times. In this study 30 different DEM predictions were generated from 30 samples of <italic>z</italic><sub><italic>prior</italic></sub> from Prior Net for each input data/patient. From these 30 DEM predictions per patient data, uncertainty was calculated as the Cross Entropy (CE) between probability values from all DEM predictions and its average as written in <xref ref-type="disp-formula" rid="FD13">Equation 13</xref>.</p><p id="P63"><xref ref-type="fig" rid="F7">Figure 7</xref> shows the uncertainty maps for all DEM labels produced by the model that generated the best DSC ‚ÄòAverage‚Äô value, PUNet-wSL-vol, for the whole brain and inside the predicted DEM for a patient. From the uncertainty maps for the whole brain, we can see that the uncertainties for shrinking and growing WMH encompass larger brain areas than for stable WMH. This finding supports results from evaluating the spatial agreement between ground truth and the models‚Äô outputs, indicating lower accuracy in the predictions of changing WMH (i.e., shrinking and growing) compared to the predictions of stable WMH. The example shown in <xref ref-type="fig" rid="F7">Figure 7A</xref> has incorrect areas showing uncertainty in the ‚ÄòShrinking‚Äô label (e.g., in the frontal cortex and in the septum), owed mainly to hyperintense flow artefacts.</p><p id="P64">Interestingly, in the uncertainty maps, the uncertainty values inside DEM labels of shrinking and growing WMH are higher than those inside stable WMH, a consistent finding from this evaluation. This is in-line with a previous analysis<sup><xref ref-type="bibr" rid="R50">50</xref></sup> that showed WMH progression and disappearance being associated with the areas of ill-defined subtle or ‚Äúless intense‚Äù WMH, largely identified as indicative of pre- (and post-) lesional changes. As expected, and <xref ref-type="fig" rid="F7">Figure 7B</xref> shows, the uncertainty values inside the predicted DEMs and the DSC values produced by PUNet-wSL-vol are negatively correlated for each DEM label (i.e., shrinking, growing and stable WMH). However, only for stable WMH (r=0.75) higher DSC values of DEM labels can be predicted by having lower uncertainty values inside the predicted DEM and vice versa. Plots of the correspondence in shrinking and growing labels show a wide spread in DSC values especially among those with uncertainty values between 0.7 and 0.98, that would make any inference of the predictive power of one magnitude over the other inaccurate.</p></sec></sec><sec id="S28" sec-type="conclusions"><title>Conclusion</title><p id="P65">This study proposed deep learning models based on the Probabilistic U-Net<sup><xref ref-type="bibr" rid="R26">26</xref></sup> architecture trained incorporating stroke lesions information into the models and using volume loss as additional loss for improving the quality of predicted future volume of WMH and disease evolution map (DEM) of WMH. Probabilistic U-Net was chosen as the baseline method because a preliminary study showed that it performed better than the U-Net<sup><xref ref-type="bibr" rid="R25">25</xref></sup>.</p><p id="P66">We proposed three different approaches for incorporating stroke lesions information into Probabilistic U-Net models. These are <bold>(1)</bold> joint segmentation of DEM and stroke lesions, <bold>(2)</bold> use of probabilistic maps of WMH change in relation to stroke lesions‚Äô locations, and <bold>(3)</bold> combination of <bold>(1)</bold> and <bold>(2)</bold>. We proposed to incorporate stroke lesions information into deep learning models to predict WMH evolution because stroke is commonly associated with the evolution of WMH<sup><xref ref-type="bibr" rid="R3">3</xref></sup>. Based on the results from the various experiments, joint segmentation of DEM and stroke lesions (approach <bold>(1)</bold>) was the most effective approach to improve the quality of predicted DEM of WMH in all evaluations, while being also simpler and more straightforward than the other approaches evaluated in this study. The introduction of a volume loss as an additional loss to the scheme substantially improved the quality in predicting the DEM of WMH in terms of volume, correlation with clinical scores of WMH progression, and in terms of spatial agreement.</p><p id="P67">This study shows that 1) incorporating factors that have been commonly associated with WMH progression (i.e., stroke lesions information) is crucial to produce better prediction of DEM for WMH from brain MRI; 2) the best method for incorporating associated factors that can be extracted from the same data/image modality involves performing multi-task learning; and 3) in patients with vascular pathology, a multi-class segmentation of brain features resulting from symptomatic (i.e. stroke) and asymptomatic (i.e., WMH) vascular events generates better results consistent with clinical research. In this study, as stroke lesions appear on the same T2-FLAIR MRI sequence as WMH, we performed joint segmentation of DEM for WMH and stroke lesions. However, previous clinical studies have shown that there are other non-image risk factors and brain features that have been commonly associated with the progression and evolution of WMH, like age<sup><xref ref-type="bibr" rid="R8">8</xref></sup>, ventricular enlargement<sup><xref ref-type="bibr" rid="R52">52</xref>, <xref ref-type="bibr" rid="R53">53</xref></sup>, and brain atrophy<sup><xref ref-type="bibr" rid="R54">54</xref></sup>. Thus, more (image and non-image) factors could be incorporated in future studies to further improve the quality of predicted DEM of WMH, although the best way to incorporate non-image factors to the prediction model remains to be found.</p><p id="P68">This study also has limitations to overcome in future works. The dataset was small in size impeding a quantitative in-depth analysis of the models‚Äô performance in different patient subgroups, e.g., patients stratified by age and sex, patients grouped by stroke subtype, etc. Thus, subgroup analyses were carried out visually and volumetrically, not spatially. By using only data from patients presenting to a clinic with a mild-to-moderate stroke, the generalisability of the proposed approach can be questioned. Therefore, further evaluation in a wider and more heterogeneous sample will be needed. The use of DSC in the evaluation needed the binarisation of the probabilistic outputs from the models. Limitations in the use of DSC have been recently acknowledged<sup><xref ref-type="bibr" rid="R55">55</xref></sup>. However, it must be noted that ground truth segmentations are also binary, and observer-dependent. By using different quality control metrics in a comprehensive analysis we have overcome the limitations that the analysis of the spatial agreement using DSC poses. A probabilistic metric allowing spatial analyses of segmentation results is needed. Also, we used probabilistic maps of WMH change for strokes in the lentiform nucleus and centrum semiovale based on findings from a clinical study. However, the same clinical study specified that it was not possible to ascertain WMH evolution and distribution for patients with the stroke in other regions like thalami and midbrain or brain stem due to the limited sample of patients with infarcts in those regions. Incorporating findings for more powered studies would be necessary to conclude about the usefulness of incorporating attention maps to the AI schemes. Finally, various schemes for estimating uncertainty in segmentation/classification tasks have recently emerged<sup><xref ref-type="bibr" rid="R56">56</xref>, <xref ref-type="bibr" rid="R57">57</xref></sup>, which would be worth exploring in the future for estimating WMH evolution.</p></sec></body><back><ack id="S29"><title>Acknowledgements</title><p>Funds from JSPS (Kakenhi Grant-in-Aid for Research Activity Start-up, Project No. 20K23356) (MFR); RIKEN‚Äôs Special Postdoctoral Researchers (SPDR) program (MFR); Row Fogo Charitable Trust (Grant No. BRO-D.FID3668413) (MCVH); Wellcome Trust (patient recruitment, scanning, primary study Ref No. WT088134/Z/09/A); Fondation Leducq (Perivascular Spaces Transatlantic Network of Excellence); EU Horizon 2020 (SVDs@Target); and the MRC UK Dementia Research Institute at the University of Edinburgh (Wardlaw programme) are gratefully acknowledged. This research was also supported by the program for Brain Mapping by Integrated Neurotechnologies for Disease Studies (Brain/MINDS) from the Japan Agency for Medical Research and Development AMED (JP15dm0207001). Library access provided by the Faculty of Computer Science, Universitas Indonesia is also gratefully acknowledged.</p></ack><fn-group><title>Additional information</title><fn id="FN1"><label>1</label><p id="P69"><ext-link ext-link-type="uri" xlink:href="https://datashare.ed.ac.uk/handle/10283/3934">https://datashare.ed.ac.uk/handle/10283/3934</ext-link></p></fn><fn fn-type="con" id="FN2"><p id="P70"><bold>Author contributions statement</bold></p><p id="P71">M.F.R and M.V.H. conducted experiments (including conceptualization, methodology, software, experiments, and evaluations).</p><p id="P72">S.M. and J.W. performed data curation and clinical analysis. H.S. conducted methodology development and analysis.</p></fn><fn id="FN3"><p id="P73"><bold>Accession codes:</bold> <ext-link ext-link-type="uri" xlink:href="https://github.com/febrianrachmadi/probunet-gan-vie">https://github.com/febrianrachmadi/probunet-gan-vie</ext-link>;</p></fn><fn fn-type="conflict" id="FN4"><p id="P74"><bold>Competing interests:</bold> No conflict of interests.</p></fn><fn id="FN5" fn-type="conflict"><p id="P75">The corresponding author is responsible for submitting a competing interests statement on behalf of all authors of the paper. This statement must be included in the submitted article file.</p></fn></fn-group><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wardlaw</surname><given-names>JM</given-names></name><etal/></person-group><article-title>Neuroimaging standards for research into small vessel disease and its contribution to ageing and neurodegeneration</article-title><source>The Lancet Neurol</source><year>2013</year><volume>12</volume><fpage>822</fpage><lpage>38</lpage><pub-id pub-id-type="pmcid">PMC3714437</pub-id><pub-id pub-id-type="pmid">23867200</pub-id><pub-id pub-id-type="doi">10.1016/S1474-4422(13)70124-8</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prins</surname><given-names>ND</given-names></name><name><surname>Scheltens</surname><given-names>P</given-names></name></person-group><article-title>White matter hyperintensities, cognitive impairment and dementia: an update. Nat. reviews</article-title><source>Neurol</source><year>2015</year><volume>11</volume><fpage>157</fpage><lpage>65</lpage><pub-id pub-id-type="pmid">25686760</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wardlaw</surname><given-names>JM</given-names></name><etal/></person-group><article-title>White matter hyperintensity reduction and outcomes after minor stroke</article-title><source>Neurology</source><year>2017</year><volume>89</volume><fpage>1003</fpage><lpage>1010</lpage><pub-id pub-id-type="pmcid">PMC5589793</pub-id><pub-id pub-id-type="pmid">28794252</pub-id><pub-id pub-id-type="doi">10.1212/WNL.0000000000004328</pub-id></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hern√°ndez Vald√©s</surname><given-names>MdC</given-names></name><name><surname>Piper</surname><given-names>RJ</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Deary</surname><given-names>IJ</given-names></name><name><surname>Wardlaw</surname><given-names>JM</given-names></name></person-group><article-title>Towards the automatic computational assessment of enlarged perivascular spaces on brain magnetic resonance images: a systematic review</article-title><source>J Magn Reson Imaging</source><year>2013</year><volume>38</volume><fpage>774</fpage><lpage>785</lpage><pub-id pub-id-type="pmid">23441036</pub-id></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Hern√°ndez</surname><given-names>MCV</given-names></name><name><surname>Doubal</surname><given-names>F</given-names></name><name><surname>Chappell</surname><given-names>FM</given-names></name><name><surname>Wardlaw</surname><given-names>JM</given-names></name></person-group><article-title>How much do focal infarcts distort white matter lesions and global cerebral atrophy measures?</article-title><source>Cerebrovasc Dis</source><year>2012</year><volume>34</volume><fpage>336</fpage><lpage>342</lpage><pub-id pub-id-type="pmcid">PMC3566554</pub-id><pub-id pub-id-type="pmid">23154746</pub-id><pub-id pub-id-type="doi">10.1159/000343226</pub-id></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmidt</surname><given-names>R</given-names></name><name><surname>Enzinger</surname><given-names>C</given-names></name><name><surname>Ropele</surname><given-names>S</given-names></name><name><surname>Schmidt</surname><given-names>H</given-names></name><name><surname>Fazekas</surname><given-names>F</given-names></name></person-group><article-title>Progression of cerebral white matter lesions: 6-Year results of the Austrian Stroke Prevention Study</article-title><source>Lancet</source><year>2003</year><volume>361</volume><fpage>2046</fpage><lpage>2048</lpage><pub-id pub-id-type="pmid">12814718</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sachdev</surname><given-names>P</given-names></name><name><surname>Wen</surname><given-names>W</given-names></name><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Brodaty</surname><given-names>H</given-names></name></person-group><article-title>Progression of white matter hyperintensities in elderly individuals over 3 years</article-title><source>Neurology</source><year>2007</year><volume>68</volume><fpage>214</fpage><lpage>222</lpage><pub-id pub-id-type="pmid">17224576</pub-id></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Dijk</surname><given-names>EJ</given-names></name><etal/></person-group><article-title>Progression of cerebral small vessel disease in relation to risk factors and cognitive consequences: Rotterdam scan study</article-title><source>Stroke</source><year>2008</year><volume>39</volume><fpage>2712</fpage><lpage>2719</lpage><pub-id pub-id-type="pmid">18635849</pub-id></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moriya</surname><given-names>Y</given-names></name><name><surname>Kozaki</surname><given-names>K</given-names></name><name><surname>Nagai</surname><given-names>K</given-names></name><name><surname>Toba</surname><given-names>K</given-names></name></person-group><article-title>Attenuation of brain white matter hyperintensities after cerebral infarction</article-title><source>Am J Neuroradiol</source><year>2009</year><volume>30</volume><elocation-id>3174</elocation-id><pub-id pub-id-type="pmcid">PMC7051466</pub-id><pub-id pub-id-type="pmid">19112066</pub-id><pub-id pub-id-type="doi">10.3174/ajnr.A1340</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jochems</surname><given-names>AC</given-names></name><etal/></person-group><article-title>Longitudinal changes of white matter hyperintensities in sporadic small vessel disease: a systematic review and meta-analysis</article-title><source>Neurology</source><year>2022</year><volume>99</volume><fpage>e2454</fpage><lpage>e2463</lpage><pub-id pub-id-type="pmcid">PMC9728036</pub-id><pub-id pub-id-type="pmid">36123130</pub-id><pub-id pub-id-type="doi">10.1212/WNL.0000000000201205</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramirez</surname><given-names>J</given-names></name><name><surname>McNeely</surname><given-names>AA</given-names></name><name><surname>Berezuk</surname><given-names>C</given-names></name><name><surname>Gao</surname><given-names>F</given-names></name><name><surname>Black</surname><given-names>SE</given-names></name></person-group><article-title>Dynamic progression of white matter hyperintensities in Alzheimer‚Äôs disease and normal aging: Results from the Sunnybrook dementia study</article-title><source>Front Aging Neurosci</source><year>2016</year><volume>8</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="pmcid">PMC4805606</pub-id><pub-id pub-id-type="pmid">27047377</pub-id><pub-id pub-id-type="doi">10.3389/fnagi.2016.00062</pub-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chappell</surname><given-names>FM</given-names></name><etal/></person-group><article-title>Sample size considerations for trials using cerebral white matter hyperintensity progression as an intermediate outcome at 1 year after mild stroke: Results of a prospective cohort study</article-title><source>Trials</source><year>2017</year><volume>18</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="pmcid">PMC5320698</pub-id><pub-id pub-id-type="pmid">28222778</pub-id><pub-id pub-id-type="doi">10.1186/s13063-017-1825-7</pub-id></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>R</given-names></name><name><surname>Low</surname><given-names>A</given-names></name><name><surname>Markus</surname><given-names>HS</given-names></name></person-group><article-title>Rate of, and risk factors for, white matter hyperintensity growth: a systematic review and meta-analysis with implications for clinical trial design</article-title><source>J Neurol Neurosurg &amp; Psychiatry</source><year>2021</year><volume>92</volume><fpage>1271</fpage><lpage>1277</lpage><pub-id pub-id-type="pmid">34344790</pub-id></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cai</surname><given-names>M</given-names></name><etal/></person-group><article-title>Determinants and temporal dynamics of cerebral small vessel disease: 14-year follow-up</article-title><source>Stroke</source><year>2022</year><fpage>10</fpage><lpage>1161</lpage><pub-id pub-id-type="pmcid">PMC9389939</pub-id><pub-id pub-id-type="pmid">35506383</pub-id><pub-id pub-id-type="doi">10.1161/STROKEAHA.121.038099</pub-id></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Schmidt</surname><given-names>R</given-names></name><etal/></person-group><chapter-title>Risk factors and progression of small vessel disease-related cerebral abnormalities</chapter-title><source>Ageing and Dementia Current and Future Concepts</source><publisher-name>Springer</publisher-name><year>2002</year><fpage>47</fpage><lpage>52</lpage><pub-id pub-id-type="pmid">12456049</pub-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmidt</surname><given-names>H</given-names></name><etal/></person-group><article-title>Genetic variants of the NOTCH3 gene in the elderly and magnetic resonance imaging correlates of age-related cerebral small vessel disease</article-title><source>Brain</source><year>2011</year><volume>134</volume><fpage>3384</fpage><lpage>3397</lpage><pub-id pub-id-type="pmcid">PMC3212720</pub-id><pub-id pub-id-type="pmid">22006983</pub-id><pub-id pub-id-type="doi">10.1093/brain/awr252</pub-id></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Godin</surname><given-names>O</given-names></name><etal/></person-group><article-title>Apolipoprotein E genotype is related to progression of white matter lesion load</article-title><source>Stroke</source><year>2009</year><volume>40</volume><fpage>3186</fpage><lpage>3190</lpage><pub-id pub-id-type="pmid">19644067</pub-id></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luo</surname><given-names>X</given-names></name><etal/></person-group><article-title>Associations between APOE genotype and cerebral small-vessel disease: a longitudinal study</article-title><source>Oncotarget</source><year>2017</year><volume>8</volume><fpage>44477</fpage><lpage>44489</lpage><pub-id pub-id-type="pmcid">PMC5546495</pub-id><pub-id pub-id-type="pmid">28574812</pub-id><pub-id pub-id-type="doi">10.18632/oncotarget.17724</pub-id></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silbert</surname><given-names>LC</given-names></name><name><surname>Howieson</surname><given-names>DB</given-names></name><name><surname>Dodge</surname><given-names>H</given-names></name><name><surname>Kaye</surname><given-names>JA</given-names></name></person-group><article-title>Cognitive impairment risk: white matter hyperintensity progression matters</article-title><source>Neurology</source><year>2009</year><volume>73</volume><fpage>120</fpage><lpage>125</lpage><pub-id pub-id-type="pmcid">PMC2713187</pub-id><pub-id pub-id-type="pmid">19597134</pub-id><pub-id pub-id-type="doi">10.1212/WNL.0b013e3181ad53fd</pub-id></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hern√°ndez Vald√©s</surname><given-names>MdC</given-names></name><etal/></person-group><article-title>Post-stroke cognition at 1 and 3 years is influenced by the location of white matter hyperintensities in patients with lacunar stroke</article-title><source>Front Neurol</source><year>2021</year><volume>12</volume><pub-id pub-id-type="pmcid">PMC7956970</pub-id><pub-id pub-id-type="pmid">33732208</pub-id><pub-id pub-id-type="doi">10.3389/fneur.2021.634460</pub-id></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Botz</surname><given-names>J</given-names></name><name><surname>Lohner</surname><given-names>V</given-names></name><name><surname>Schirmer</surname><given-names>MD</given-names></name></person-group><article-title>Spatial patterns of white matter hyperintensities: a systematic review</article-title><source>Front Aging Neurosci</source><year>2023</year><volume>15</volume><elocation-id>1165324</elocation-id><pub-id pub-id-type="pmcid">PMC10214839</pub-id><pub-id pub-id-type="pmid">37251801</pub-id><pub-id pub-id-type="doi">10.3389/fnagi.2023.1165324</pub-id></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuijf</surname><given-names>HJ</given-names></name><etal/></person-group><article-title>Standardized assessment of automatic segmentation of white matter hyperintensities and results of the wmh segmentation challenge</article-title><source>IEEE transactions on medical imaging</source><year>2019</year><volume>38</volume><fpage>2556</fpage><lpage>2568</lpage><pub-id pub-id-type="pmcid">PMC7590957</pub-id><pub-id pub-id-type="pmid">30908194</pub-id><pub-id pub-id-type="doi">10.1109/TMI.2019.2905770</pub-id></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Rachmadi</surname><given-names>MF</given-names></name><name><surname>Vald√©s-Hern√°ndez</surname><given-names>MdC</given-names></name><name><surname>Makin</surname><given-names>S</given-names></name><name><surname>Wardlaw</surname><given-names>JM</given-names></name><name><surname>Komura</surname><given-names>T</given-names></name></person-group><source>Predicting the evolution of white matter hyperintensities in brain mri using generative adversarial networks and irregularity map</source><conf-name>International Conference on Medical Image Computing and Computer-Assisted Intervention</conf-name><publisher-name>Springer</publisher-name><year>2019</year><fpage>146</fpage><lpage>154</lpage></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rachmadi</surname><given-names>MF</given-names></name><name><surname>Vald√©s-Hern√°ndez</surname><given-names>MdC</given-names></name><name><surname>Makin</surname><given-names>S</given-names></name><name><surname>Wardlaw</surname><given-names>J</given-names></name><name><surname>Komura</surname><given-names>T</given-names></name></person-group><article-title>Automatic spatial estimation of white matter hyperintensities evolution in brain mri using disease evolution predictor deep neural networks</article-title><source>Med image analysis</source><year>2020</year><volume>63</volume><elocation-id>101712</elocation-id><pub-id pub-id-type="pmcid">PMC7294240</pub-id><pub-id pub-id-type="pmid">32428823</pub-id><pub-id pub-id-type="doi">10.1016/j.media.2020.101712</pub-id></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Rachmadi</surname><given-names>MF</given-names></name><etal/></person-group><source>Probabilistic deep learning with adversarial training and volume interval estimation-better ways to perform and evaluate predictive models for white matter hyperintensities evolution</source><conf-name>International Workshop on PRedictive Intelligence In MEdicine</conf-name><publisher-name>Springer</publisher-name><year>2021</year><fpage>168</fpage><lpage>180</lpage></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kohl</surname><given-names>S</given-names></name><etal/></person-group><chapter-title>A probabilistic u-net for segmentation of ambiguous images</chapter-title><person-group person-group-type="editor"><name><surname>Bengio</surname><given-names>S</given-names></name><etal/></person-group><source>Advances in Neural Information Processing Systems</source><publisher-name>Curran Associates, Inc</publisher-name><year>2018</year><volume>31</volume><comment>eds</comment></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shu</surname><given-names>Z</given-names></name><name><surname>Xu</surname><given-names>Y</given-names></name><name><surname>Shao</surname><given-names>Y</given-names></name><name><surname>Pang</surname><given-names>P</given-names></name><name><surname>Gong</surname><given-names>X</given-names></name></person-group><article-title>Radiomics from magnetic resonance imaging may be used to predict the progression of white matter hyperintensities and identify associated risk factors</article-title><source>Eur radiology</source><year>2020</year><volume>30</volume><fpage>3046</fpage><lpage>3058</lpage><pub-id pub-id-type="pmid">32086580</pub-id></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Souza</surname><given-names>FSH</given-names></name><name><surname>Hojo-Souza</surname><given-names>NS</given-names></name><name><surname>Santos</surname><given-names>Dos</given-names></name><name><surname>Da Silva</surname><given-names>CM</given-names></name><name><surname>Guidoni</surname><given-names>DL</given-names></name></person-group><article-title>Predicting the disease outcome in covid-19 positive patients through machine learning: a retrospective cohort study with brazilian data</article-title><source>Front Artif Intell</source><year>2021</year><fpage>4</fpage><pub-id pub-id-type="pmcid">PMC8427867</pub-id><pub-id pub-id-type="pmid">34514377</pub-id><pub-id pub-id-type="doi">10.3389/frai.2021.579931</pub-id></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pinto</surname><given-names>MF</given-names></name><etal/></person-group><article-title>Prediction of disease progression and outcomes in multiple sclerosis with machine learning</article-title><source>Sci reports</source><year>2020</year><volume>10</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="pmcid">PMC7713436</pub-id><pub-id pub-id-type="pmid">33273676</pub-id><pub-id pub-id-type="doi">10.1038/s41598-020-78212-6</pub-id></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chong</surname><given-names>S-L</given-names></name><name><surname>Liu</surname><given-names>N</given-names></name><name><surname>Barbier</surname><given-names>S</given-names></name><name><surname>Ong</surname><given-names>MEH</given-names></name></person-group><article-title>Predictive modeling in pediatric traumatic brain injury using machine learning</article-title><source>BMC medical research methodology</source><year>2015</year><volume>15</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="pmcid">PMC4374377</pub-id><pub-id pub-id-type="pmid">25886156</pub-id><pub-id pub-id-type="doi">10.1186/s12874-015-0015-0</pub-id></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pease</surname><given-names>M</given-names></name><etal/></person-group><article-title>Outcome prediction in patients with severe traumatic brain injury using deep learning from head ct scans</article-title><source>Radiology</source><year>2022</year><pub-id pub-id-type="pmcid">PMC9340242</pub-id><pub-id pub-id-type="pmid">35471108</pub-id><pub-id pub-id-type="doi">10.1148/radiol.212181</pub-id></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pellegrini</surname><given-names>E</given-names></name><etal/></person-group><article-title>Machine learning of neuroimaging for assisted diagnosis of cognitive impairment and dementia: a systematic review</article-title><source>Alzheimer‚Äôs &amp; Dementia: Diagn Assess &amp; Dis Monit</source><year>2018</year><volume>10</volume><fpage>519</fpage><lpage>535</lpage><pub-id pub-id-type="pmcid">PMC6197752</pub-id><pub-id pub-id-type="pmid">30364671</pub-id><pub-id pub-id-type="doi">10.1016/j.dadm.2018.07.004</pub-id></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>T</given-names></name><etal/></person-group><article-title>Predicting mci to ad conversation using integrated smri and rs-fmri: machine learning and graph theory approach</article-title><source>Front Aging Neurosci</source><year>2021</year><volume>429</volume><pub-id pub-id-type="pmcid">PMC8375594</pub-id><pub-id pub-id-type="pmid">34421570</pub-id><pub-id pub-id-type="doi">10.3389/fnagi.2021.688926</pub-id></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nakagawa</surname><given-names>T</given-names></name><etal/></person-group><article-title>Prediction of conversion to alzheimer‚Äôs disease using deep survival analysis of mri images</article-title><source>Brain communications</source><year>2020</year><volume>2</volume><elocation-id>fcaa057</elocation-id><pub-id pub-id-type="pmcid">PMC7425528</pub-id><pub-id pub-id-type="pmid">32954307</pub-id><pub-id pub-id-type="doi">10.1093/braincomms/fcaa057</pub-id></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nguyen</surname><given-names>M</given-names></name><etal/></person-group><article-title>Predicting alzheimer‚Äôs disease progression using deep recurrent neural networks</article-title><source>NeuroImage</source><year>2020</year><volume>222</volume><elocation-id>117203</elocation-id><pub-id pub-id-type="pmcid">PMC7797176</pub-id><pub-id pub-id-type="pmid">32763427</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117203</pub-id></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rafael-Palou</surname><given-names>X</given-names></name><etal/></person-group><article-title>Prediction of lung nodule progression with an uncertainty-aware hierarchical probabilistic network</article-title><source>Diagnostics</source><year>2022</year><volume>12</volume><elocation-id>2639</elocation-id><pub-id pub-id-type="pmcid">PMC9689366</pub-id><pub-id pub-id-type="pmid">36359482</pub-id><pub-id pub-id-type="doi">10.3390/diagnostics12112639</pub-id></element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Sauty</surname><given-names>B</given-names></name><name><surname>Durrleman</surname><given-names>S</given-names></name></person-group><source>Progression models for imaging data with longitudinal variational auto encoders</source><conf-name>International Conference on Medical Image Computing and Computer-Assisted Intervention</conf-name><publisher-name>Springer</publisher-name><year>2022</year><fpage>3</fpage><lpage>13</lpage></element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prins</surname><given-names>N</given-names></name><etal/></person-group><article-title>Measuring progression of cerebral white matter lesions on mri: visual rating and volumetrics</article-title><source>Neurology</source><year>2004</year><volume>62</volume><fpage>1533</fpage><lpage>1539</lpage><pub-id pub-id-type="pmid">15136677</pub-id></element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goodfellow</surname><given-names>I</given-names></name><etal/></person-group><article-title>Generative adversarial nets</article-title><source>Advances in neural information processing systems</source><year>2014</year><fpage>2672</fpage><lpage>2680</lpage></element-citation></ref><ref id="R40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oktay</surname><given-names>O</given-names></name><etal/></person-group><article-title>Attention u-net: Learning where to look for the pancreas</article-title><source>arXiv preprint</source><year>2018</year><elocation-id>arXiv:1804 03999</elocation-id></element-citation></ref><ref id="R41"><label>41</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>H√ºllermeier</surname><given-names>E</given-names></name><name><surname>Waegeman</surname><given-names>W</given-names></name></person-group><article-title>Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and methods</article-title><source>Mach Learn</source><year>2021</year><volume>110</volume><fpage>457</fpage><lpage>506</lpage><pub-id pub-id-type="doi">10.1007/s10994-021-05946-3</pub-id></element-citation></ref><ref id="R42"><label>42</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Ronneberger</surname><given-names>O</given-names></name><name><surname>Fischer</surname><given-names>P</given-names></name><name><surname>Brox</surname><given-names>T</given-names></name></person-group><source>U-net: Convolutional networks for biomedical image segmentation</source><conf-name>International Conference on Medical image computing and computer-assisted intervention</conf-name><publisher-name>Springer</publisher-name><year>2015</year><fpage>234</fpage><lpage>241</lpage></element-citation></ref><ref id="R43"><label>43</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hern√°ndez Vald√©s</surname><given-names>HdC</given-names></name><etal/></person-group><source>White matter hyperintensities evolution patterns 1 year post-lacunar stroke and their association with post-stroke cognition, 2009-2013</source><publisher-name>Univ Edinburgh Centre for Clin Brain Sci</publisher-name><year>2021</year><comment>[dataset]</comment></element-citation></ref><ref id="R44"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hern√°ndez Vald√©s</surname><given-names>HdC</given-names></name><etal/></person-group><article-title>Rationale, design and methodology of the image analysis protocol for studies of patients with cerebral small vessel disease and mild stroke</article-title><source>Brain behavior</source><year>2015</year><volume>5</volume><elocation-id>e00415</elocation-id><pub-id pub-id-type="pmcid">PMC4714639</pub-id><pub-id pub-id-type="pmid">26807340</pub-id><pub-id pub-id-type="doi">10.1002/brb3.415</pub-id></element-citation></ref><ref id="R45"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Bannister</surname><given-names>P</given-names></name><name><surname>Brady</surname><given-names>M</given-names></name><name><surname>Smith</surname><given-names>S</given-names></name></person-group><article-title>Improved optimization for the robust and accurate linear registration and motion correction of brain images</article-title><source>Neuroimage</source><year>2002</year><volume>17</volume><fpage>825</fpage><lpage>841</lpage><pub-id pub-id-type="pmid">12377157</pub-id></element-citation></ref><ref id="R46"><label>46</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clayden</surname><given-names>JD</given-names></name><etal/></person-group><article-title>Tractor: magnetic resonance imaging and tractography with r</article-title><source>J Stat Softw</source><year>2011</year><volume>44</volume><fpage>1</fpage><lpage>18</lpage></element-citation></ref><ref id="R47"><label>47</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hern√°ndez Vald√©s</surname><given-names>MdC</given-names></name></person-group><source>Human brain atlases across the lifespan ‚Äì anatomical segmentations, 1990-2016 [dataset]</source><publisher-name>Univ Edinburgh Centre for Clin Brain Sci</publisher-name><year>2021</year></element-citation></ref><ref id="R48"><label>48</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>T-Y</given-names></name><name><surname>Goyal</surname><given-names>P</given-names></name><name><surname>Girshick</surname><given-names>R</given-names></name><name><surname>He</surname><given-names>K</given-names></name><name><surname>Doll√°r</surname><given-names>P</given-names></name></person-group><source>Focal loss for dense object detection</source><conf-name>Proceedings of the IEEE international conference on computer vision</conf-name><year>2017</year><fpage>2980</fpage><lpage>2988</lpage></element-citation></ref><ref id="R49"><label>49</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dice</surname><given-names>LR</given-names></name></person-group><article-title>Measures of the amount of ecologic association between species</article-title><source>Ecology</source><year>1945</year><volume>26</volume><fpage>297</fpage><lpage>302</lpage></element-citation></ref><ref id="R50"><label>50</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hern√°ndez Vald√©s</surname><given-names>HdC</given-names></name><etal/></person-group><article-title>Metric to quantify white matter damage on brain magnetic resonance images</article-title><source>Neuroradiology</source><year>2017</year><volume>59</volume><fpage>951</fpage><lpage>962</lpage><pub-id pub-id-type="pmcid">PMC5596039</pub-id><pub-id pub-id-type="pmid">28815362</pub-id><pub-id pub-id-type="doi">10.1007/s00234-017-1892-1</pub-id></element-citation></ref><ref id="R51"><label>51</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guerrero</surname><given-names>R</given-names></name><etal/></person-group><article-title>White matter hyperintensity and stroke lesion segmentation and differentiation using convolutional neural networks</article-title><source>NeuroImage: Clin</source><year>2018</year><volume>17</volume><fpage>918</fpage><lpage>934</lpage><pub-id pub-id-type="pmcid">PMC5842732</pub-id><pub-id pub-id-type="pmid">29527496</pub-id><pub-id pub-id-type="doi">10.1016/j.nicl.2017.12.022</pub-id></element-citation></ref><ref id="R52"><label>52</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Breteler</surname><given-names>M</given-names></name><etal/></person-group><article-title>Cognitive correlates of ventricular enlargement and cerebral white matter lesions on magnetic resonance imaging. the rotterdam study</article-title><source>Stroke</source><year>1994</year><volume>25</volume><fpage>1109</fpage><lpage>1115</lpage><pub-id pub-id-type="pmid">8202966</pub-id></element-citation></ref><ref id="R53"><label>53</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jochems</surname><given-names>AC</given-names></name><etal/></person-group><article-title>Contribution of white matter hyperintensities to ventricular enlargement in older adults</article-title><source>NeuroImage: Clin</source><year>2022</year><volume>34</volume><elocation-id>103019</elocation-id><pub-id pub-id-type="pmcid">PMC9062739</pub-id><pub-id pub-id-type="pmid">35490587</pub-id><pub-id pub-id-type="doi">10.1016/j.nicl.2022.103019</pub-id></element-citation></ref><ref id="R54"><label>54</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wardlaw</surname><given-names>JM</given-names></name><name><surname>Hern√°ndez Vald√©s</surname><given-names>HdC</given-names></name><name><surname>Mu√±oz-Maniega</surname><given-names>S</given-names></name></person-group><article-title>What are white matter hyperintensities made of? relevance to vascular cognitive impairment</article-title><source>J Am Hear Assoc</source><year>2015</year><volume>4</volume><elocation-id>e001140</elocation-id><pub-id pub-id-type="pmcid">PMC4599520</pub-id><pub-id pub-id-type="pmid">26104658</pub-id><pub-id pub-id-type="doi">10.1161/JAHA.114.001140</pub-id></element-citation></ref><ref id="R55"><label>55</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maier-Hein</surname><given-names>L</given-names></name><etal/></person-group><article-title>Metrics reloaded: Pitfalls and recommendations for image analysis validation</article-title><source>arXiv preprint</source><year>2022</year><elocation-id>arXiv:2206 01653</elocation-id></element-citation></ref><ref id="R56"><label>56</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>J</given-names></name><etal/></person-group><article-title>Simple and principled uncertainty estimation with deterministic deep learning via distance awareness</article-title><source>Adv Neural Inf Process Syst</source><year>2020</year><volume>33</volume><fpage>7498</fpage><lpage>7512</lpage></element-citation></ref><ref id="R57"><label>57</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sensoy</surname><given-names>M</given-names></name><name><surname>Kaplan</surname><given-names>L</given-names></name><name><surname>Kandemir</surname><given-names>M</given-names></name></person-group><article-title>Evidential deep learning to quantify classification uncertainty</article-title><source>Adv neural information processing systems</source><year>2018</year><volume>31</volume></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><p><bold>A:</bold> Brain-extracted FLAIR axial slice of the baseline scan or V1. <bold>B:</bold> Visualisation of disease evolution map (DEM) of white matter hyperintesities (WMH). Red represents shrinking WMH, green represents growing WMH, blue represents stable WMH, and yellow represents stroke lesions. <bold>C:</bold> Volumetric progression of WMH (in <italic>ml</italic>) from V1 to V2 (1 year apart) for all subjects from our dataset. <bold>D:</bold> shows the distribution of volumetric progression of WMH (in <italic>ml</italic>) based on WMH volume at V1 for all subjects.</p></caption><graphic xlink:href="EMS158895-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><p><bold>A:</bold> Schematic representation of the Probabilistic U-Net<sup><xref ref-type="bibr" rid="R26">26</xref></sup> with adversarial training<sup><xref ref-type="bibr" rid="R39">39</xref></sup> used in this study, firstly introduced in a previous work<sup><xref ref-type="bibr" rid="R25">25</xref></sup>. <bold>B:</bold> Segmentation network of Probabilistic U-Net used in this study, which is based on the original U-Net extended into Attention U-Net only when probability maps of WMH change are used as auxiliary input. The output channel of <italic>C</italic> is either 5 or 4 depending on whether stroke lesions are jointly segmented or not, respectively. <bold>C:</bold> Schematic of additive attention gate (AG) used in this study, firstly introduced in<sup><xref ref-type="bibr" rid="R40">40</xref></sup>. Input features (<italic>x</italic><sub><italic>l</italic></sub>) are from the U-Net‚Äôs skip connection while gating signals (<italic>g</italic><sub><italic>l</italic></sub>) are from the gating signal encoder (GSE). Attention coefficients (<italic>Œ±</italic>) are learned in the training process and used to scale input features <italic>x</italic><sub><italic>l</italic></sub> to highlight important areas.</p></caption><graphic xlink:href="EMS158895-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><p><bold>A:</bold> Average progression of WMH volume (<italic>ml</italic>) from V1 to V2 (1 year) for Ground truth and all tested models/configurations. <bold>B:</bold> Volumetric WMH change in <italic>ml</italic> (vertical axes) for patients grouped by quintiles (horizontal axes) depending on their WMH volume at baseline.</p></caption><graphic xlink:href="EMS158895-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><p>Spearman correlations between the spatial growth (above) and shrinkage (below) from each scheme and Prins overall scores. GT: ground truth, PUNet: Probabilistic UNet, PUNvo: Probabilistic UNet adding a volume loss to the cost function (PUNet-vol), PUNSL: Probabilistic UNet that outputs stroke lesion (SL) and WMH masks, PUNSv Probabilistic UNet that outputs SL and WMH and uses volume loss added to the cost function, Prins: total (summed) clinical scores</p></caption><graphic xlink:href="EMS158895-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><p>Confusion matrices for all labels produced by PUNet-vol and PUNet-wSL-vol configurations from all subjects. Abbreviation <italic>n</italic> stands for number of segmented voxels which can be used to calculate false negative rate (<italic>fnr</italic>), false positive rate (<italic>fpr</italic>), true positive rate (TPR), and positive predictive value (PPV). Note that TPR and <italic>fnr</italic> are calculated horizontally for each row (true label of DEM). On the other hand, PPV and <italic>fpr</italic> are calculated vertically for each column (predicted label of DEM).</p></caption><graphic xlink:href="EMS158895-f005"/></fig><fig id="F6" position="float"><label>Figure 6</label><caption><p><bold>A:</bold> Examples of predicted DEM produced by PUNet-wSL-vol and PUNet-vol and their corresponding DEM ground truth from subjects with high DSC values on average. <bold>B:</bold> Examples of predicted DEM produced by PUNet-wSL-vol and PUNet-vol and their corresponding DEM ground truth from subjects with low DSC values on average. <bold>A and B:</bold> Red represents shrinking WMH, green represents growing WMH, blue represents stable WMH, and yellow represents stroke lesions. Obvious improvements are highlighted in white rectangles.</p></caption><graphic xlink:href="EMS158895-f006"/></fig><fig id="F7" position="float"><label>Figure 7</label><caption><p><bold>A:</bold> Uncertainty maps produced by PUNet-wSL-vol from subject MSSB212. <bold>B:</bold> Correlation between the average of uncertainty values inside the predicted DEM and DSC values of predicted DEM produced by PUNet-wSL-vol.</p></caption><graphic xlink:href="EMS158895-f007"/></fig><table-wrap id="T1" orientation="portrait" position="float"><label>Table 1</label><caption><title>Volume based evaluation for all models evaluated.</title><p>There are 98 patients with growing (GRW) and 54 with shrinking (SHR) volume of WMH. ‚ÄúCP‚Äù stands for ‚ÄúCorrect Prediction‚Äù, ‚ÄúCPinEVI‚Äù stands for ‚ÄúCorrect Prediction in Estimated Volume Interval‚Äù, and ‚Äú(CP+WP)inEVI‚Äù stands for ‚ÄúCorrect Prediction + Wrong Prediction but still in EVI‚Äù. Symbol ‚Üë indicates that higher values are better while symbol ‚Üí 0 indicates that values closer to 0 are better. The best and second best values for each evaluation measurements are written in bold and underlined respectively.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="middle" align="left" rowspan="2" style="border-top:solid 1px">Model‚Äôs Name</th><th valign="top" align="center" colspan="2" style="border-top: 1px solid;border-left: 1px solid">Prediction ‚Üë</th><th valign="top" align="center" colspan="3" style="border-top: 1px solid;border-left: 1px solid">Estimated Volume Interval (n=152) ‚Üë</th><th valign="top" align="center" rowspan="2" style="border-top: 1px solid;border-left: 1px solid">Volumetric Error (std) ‚Üí 0</th></tr><tr><th valign="top" align="center" style="border-left: 1px solid">GRW</th><th valign="top" align="center">SHR</th><th valign="top" align="center" style="border-left: 1px solid">CP</th><th valign="top" align="center">CPinEVI</th><th valign="top" align="center" style="border-bottom: 1px solid">(CP+WP)inEVI</th></tr></thead><tbody><tr><td valign="top" align="left" style="border-top: 1px solid">PUNet<sup><xref ref-type="bibr" rid="R25">25</xref></sup></td><td valign="top" align="center" style="border-top: 1px solid;border-left: 1px solid">78.57%</td><td valign="top" align="center" style="border-top: 1px solid">46.30%</td><td valign="top" align="center" style="border-top: 1px solid;border-left: 1px solid">67.11%</td><td valign="top" align="center" style="border-top: 1px solid">47.37%</td><td valign="top" align="center"><underline>61.18%</underline></td><td valign="top" align="center" style="border-top: 1px solid;border-left: 1px solid">-1.7739 (9.798)</td></tr><tr><td valign="top" align="left">PUNet-vol</td><td valign="top" align="center" style="border-left: 1px solid"><underline>83.67%</underline></td><td valign="top" align="center">51.85%</td><td valign="top" align="center" style="border-left: 1px solid">71.71%</td><td valign="top" align="center">46.71%</td><td valign="top" align="center" style="border-bottom: 1px solid">60.53%</td><td valign="top" align="center" style="border-left: 1px solid;border-bottom: 1px solid">-0.8342 (8.657)</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid">PUNet-wSL</td><td valign="top" align="center" style="border-top: 1px solid;border-left: 1px solid">75.51%</td><td valign="top" align="center" style="border-top: 1px solid">64.81%</td><td valign="top" align="center" style="border-top: 1px solid;border-left: 1px solid">71.71%</td><td valign="top" align="center" style="border-top: 1px solid">48.68%</td><td valign="top" align="center">59.21%</td><td valign="top" align="center" style="border-left: 1px solid"><underline>0.2269 (10.427)</underline></td></tr><tr><td valign="top" align="left">PUNet-wSL-vol</td><td valign="top" align="center" style="border-left: 1px solid">74.49%</td><td valign="top" align="center"><underline>74.07%</underline></td><td valign="top" align="center" style="border-left: 1px solid"><underline>74.34%</underline></td><td valign="top" align="center"><bold>53.29%</bold></td><td valign="top" align="center"><bold>62.50%</bold></td><td valign="top" align="center" style="border-left: 1px solid;border-bottom: 1px solid"><bold>-0.0092 (9.751)</bold></td></tr><tr><td valign="top" align="left" style="border-top: 1px solid">Att-PUNet</td><td valign="top" align="center" style="border-top: 1px solid;border-left: 1px solid">70.41%</td><td valign="top" align="center" style="border-top: 1px solid"><bold>79.63%</bold></td><td valign="top" align="center" style="border-top: 1px solid;border-left: 1px solid">73.68%</td><td valign="top" align="center" style="border-top: 1px solid">45.39%</td><td valign="top" align="center" style="border-top: 1px solid">55.26%</td><td valign="top" align="center" style="border-left: 1px solid">3.1823 (8.447)</td></tr><tr><td valign="top" align="left">Att-PUNet-vol</td><td valign="top" align="center" style="border-left: 1px solid">81.63%</td><td valign="top" align="center">55.56%</td><td valign="top" align="center" style="border-left: 1px solid">72.37%</td><td valign="top" align="center">43.42%</td><td valign="top" align="center">54.61%</td><td valign="top" align="center" style="border-left: 1px solid">-0.5546 (9.043)</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid">Att-PUNet-wSL</td><td valign="top" align="center" style="border-top: 1px solid;border-left: 1px solid"><bold>86.73%</bold></td><td valign="top" align="center" style="border-top: 1px solid">55.56%</td><td valign="top" align="center" style="border-top: 1px solid;border-left: 1px solid"><bold>75.66%</bold></td><td valign="top" align="center" style="border-top: 1px solid"><underline>51.97%</underline></td><td valign="top" align="center" style="border-top: 1px solid">59.87%</td><td valign="top" align="center" style="border-top: 1px solid;border-left: 1px solid">-0.5978 (10.901)</td></tr><tr><td valign="top" align="left" style="border-bottom: 1px solid">Att-PUNet-wSL-vol</td><td valign="top" align="center" style="border-left: 1px solid;border-bottom: 1px solid">81.63%</td><td valign="top" align="center" style="border-bottom: 1px solid">64.81%</td><td valign="top" align="center" style="border-left: 1px solid;border-bottom: 1px solid"><bold>75.66%</bold></td><td valign="top" align="center" style="border-bottom: 1px solid">43.42%</td><td valign="top" align="center" style="border-bottom: 1px solid">53.95%</td><td valign="top" align="center" style="border-left: 1px solid;border-bottom: 1px solid">0.2701 (9.050)</td></tr></tbody></table></table-wrap><table-wrap id="T2" orientation="portrait" position="float"><label>Table 2</label><caption><title>Dice similarity coefficient (DSC) for all model configurations.</title><p>Symbol ‚Üë indicates that higher values are better. The best and second best measurement values for each category of WMH are written in bold and underlined respectively.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="middle" align="left" rowspan="2" style="border-top: 1px solid">Model‚Äôs Name</th><th valign="top" align="center" colspan="7" style="border-top: 1px solid">Dice Similarity Coefficient (DSC) ‚Üë</th></tr><tr><th valign="top" align="center">Shrinking</th><th valign="top" align="center">Growing</th><th valign="top" align="center">Stable</th><th valign="top" align="center"/><th valign="top" align="center">Average</th><th valign="top" align="center">Changing</th><th valign="top" align="center">Stroke Lesions</th></tr></thead><tbody><tr><td valign="top" align="left" style="border-top: 1px solid">PUNet<sup><xref ref-type="bibr" rid="R25">25</xref></sup></td><td valign="top" align="center" style="border-top: 1px solid">0.2132</td><td valign="top" align="center" style="border-top: 1px solid">0.2137</td><td valign="top" align="center" style="border-top: 1px solid">0.6385</td><td valign="top" align="center" style="border-top: 1px solid"/><td valign="top" align="center" style="border-top: 1px solid">0.3551</td><td valign="top" align="center" style="border-top: 1px solid">0.3633</td><td valign="top" align="center" style="border-top: 1px solid">-</td></tr><tr><td valign="top" align="left">PUNet-vol</td><td valign="top" align="center">0.2107</td><td valign="top" align="center" style="border-top: 1px solid"><bold>0.2232</bold></td><td valign="top" align="center"><bold>0.6439</bold></td><td valign="top" align="center" style="border-bottom: 1px solid"/><td valign="top" align="center">0.3593</td><td valign="top" align="center">0.3642</td><td valign="top" align="center">-</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid">PUNet-wSL</td><td valign="top" align="center" style="border-top: 1px solid">0.2217</td><td valign="top" align="center" style="border-top: 1px solid">0.2130</td><td valign="top" align="center" style="border-top: 1px solid">0.6437</td><td valign="top" align="center"/><td valign="top" align="center" style="border-top: 1px solid">0.3595</td><td valign="top" align="center" style="border-top: 1px solid"><bold>0.3719</bold></td><td valign="top" align="center" style="border-top: 1px solid">0.4499</td></tr><tr><td valign="top" align="left">PUNet-wSL-vol</td><td valign="top" align="center" style="border-top: 1px solid"><bold>0.2290</bold></td><td valign="top" align="center">0.2112</td><td valign="top" align="center" style="border-top: 1px solid">0.6392</td><td valign="top" align="center" style="border-bottom: 1px solid"/><td valign="top" align="center" style="border-top: 1px solid"><bold>0.3598</bold></td><td valign="top" align="center">0.3681</td><td valign="top" align="center">0.4281</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid">Att-PUNet</td><td valign="top" align="center" style="border-top: 1px solid">0.2211</td><td valign="top" align="center" style="border-top: 1px solid">0.1796</td><td valign="top" align="center" style="border-top: 1px solid">0.6302</td><td valign="top" align="center"/><td valign="top" align="center" style="border-top: 1px solid">0.3437</td><td valign="top" align="center" style="border-top: 1px solid">0.3510</td><td valign="top" align="center" style="border-top: 1px solid">-</td></tr><tr><td valign="top" align="left">Att-PUNet-vol</td><td valign="top" align="center">0.2078</td><td valign="top" align="center">0.1981</td><td valign="top" align="center">0.6315</td><td valign="top" align="center"/><td valign="top" align="center">0.3458</td><td valign="top" align="center">0.3471</td><td valign="top" align="center">-</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid">Att-PUNet-wSL</td><td valign="top" align="center" style="border-top: 1px solid">0.1968</td><td valign="top" align="center" style="border-top: 1px solid">0.2045</td><td valign="top" align="center" style="border-top: 1px solid">0.6240</td><td valign="top" align="center" style="border-top: 1px solid"/><td valign="top" align="center" style="border-top: 1px solid">0.3417</td><td valign="top" align="center" style="border-top: 1px solid">0.3543</td><td valign="top" align="center" style="border-top: 1px solid">0.5338</td></tr><tr><td valign="top" align="left" style="border-bottom: 1px solid">Att-PUNet-wSL-vol</td><td valign="top" align="center" style="border-bottom: 1px solid">0.1960</td><td valign="top" align="center" style="border-bottom: 1px solid">0.2077</td><td valign="top" align="center" style="border-bottom: 1px solid">0.6322</td><td valign="top" align="center" style="border-bottom: 1px solid"/><td valign="top" align="center" style="border-bottom: 1px solid">0.3453</td><td valign="top" align="center" style="border-bottom: 1px solid">0.3536</td><td valign="top" align="center" style="border-top: 1px solid;border-bottom: 1px solid"><bold>0.5430</bold></td></tr></tbody></table></table-wrap><table-wrap id="T3" orientation="portrait" position="float"><label>Table 3</label><caption><title>Comparison of DSC, PRE, and REC values to FN and FP counts for PUNet-vol and PUNet-wSL-vol configurations.</title><p>Symbols ‚Üë and ‚Üì indicate that higher and lower values are better respectively.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top" align="left" style="border-top: 1px solid;"/><th valign="top" align="center" colspan="5" style="border-top: 1px solid;border-left: 1px solid">Shrinking WMH</th><th valign="top" align="center" colspan="5" style="border-top: 1px solid;border-left: 1px solid">Growing WMH</th></tr><tr><th valign="top" align="left"/><th valign="top" align="center" style="border-left: 1px solid">DSC ‚Üë</th><th valign="top" align="center">PRE ‚Üë</th><th valign="top" align="center">REC ‚Üë</th><th valign="top" align="center">FN ‚Üì</th><th valign="top" align="center">FP ‚Üì</th><th valign="top" align="center" style="border-left: 1px solid">DSC ‚Üë</th><th valign="top" align="center">PRE ‚Üë</th><th valign="top" align="center">REC ‚Üë</th><th valign="top" align="center">FN ‚Üì</th><th valign="top" align="center">FP ‚Üì</th></tr></thead><tbody><tr><td valign="top" align="left" style="border-top: 1px solid"><bold>PUNet-vol</bold></td><td valign="top" align="center" style="border-top: 1px solid;border-left: 1px solid">0.2107</td><td valign="top" align="center" style="border-top: 1px solid"><bold>0.2527</bold></td><td valign="top" align="center" style="border-top: 1px solid">0.2408</td><td valign="top" align="center" style="border-top: 1px solid">220,342</td><td valign="top" align="center" style="border-top: 1px solid"><bold>215,635</bold></td><td valign="top" align="center" style="border-top: 1px solid;border-left: 1px solid"><bold>0.2232</bold></td><td valign="top" align="center" style="border-top: 1px solid">0.2391</td><td valign="top" align="center" style="border-top: 1px solid"><bold>0.2569</bold></td><td valign="top" align="center" style="border-top: 1px solid"><bold>259,905</bold></td><td valign="top" align="center" style="border-top: 1px solid">279,753</td></tr><tr><td valign="top" align="left" style="border-bottom: 1px solid"><bold>PUNet-wSL-vol</bold></td><td valign="top" align="center" style="border-left: 1px solid;border-bottom: 1px solid"><bold>0.2290</bold></td><td valign="top" align="center" style="border-bottom: 1px solid">0.2295</td><td valign="top" align="center" style="border-bottom: 1px solid"><bold>0.3066</bold></td><td valign="top" align="center" style="border-bottom: 1px solid"><bold>211,424</bold></td><td valign="top" align="center" style="border-bottom: 1px solid">266,436</td><td valign="top" align="center" style="border-left: 1px solid;border-bottom: 1px solid">0.2112</td><td valign="top" align="center" style="border-bottom: 1px solid"><bold>0.2479</bold></td><td valign="top" align="center" style="border-bottom: 1px solid">0.2346</td><td valign="top" align="center" style="border-bottom: 1px solid">262,794</td><td valign="top" align="center" style="border-bottom: 1px solid"><bold>271,775</bold></td></tr></tbody></table></table-wrap></floats-group></article>