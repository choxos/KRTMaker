<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS156328</article-id><article-id pub-id-type="doi">10.1101/2022.10.27.514039</article-id><article-id pub-id-type="archive">PPR563719</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Representational similarity learning reveals a graded multi-dimensional semantic space in the human anterior temporal cortex</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-8287-3865</contrib-id><name><surname>Cox</surname><given-names>Christopher R.</given-names></name><email>chriscox@lsu.edu</email><xref ref-type="aff" rid="A1">1</xref><xref ref-type="corresp" rid="CR1">*</xref><xref ref-type="fn" rid="FN1">※</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-6304-755X</contrib-id><name><surname>Rogers</surname><given-names>Timothy T.</given-names></name><email>ttrogers@wisc.edu</email><xref ref-type="aff" rid="A2">2</xref><xref ref-type="corresp" rid="CR1">*</xref><xref ref-type="fn" rid="FN1">※</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-3777-685X</contrib-id><name><surname>Shimotake</surname><given-names>Akihiro</given-names></name><email>smtk@kuhp.kyoto-u.ac.jp</email><xref ref-type="aff" rid="A3">3</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><contrib contrib-type="author"><name><surname>Kikuchi</surname><given-names>Takayuki</given-names></name><xref ref-type="aff" rid="A4">4</xref></contrib><contrib contrib-type="author"><name><surname>Kunieda</surname><given-names>Takeharu</given-names></name><xref ref-type="aff" rid="A4">4</xref><xref ref-type="aff" rid="A5">5</xref></contrib><contrib contrib-type="author"><name><surname>Miyamoto</surname><given-names>Susumu</given-names></name><xref ref-type="aff" rid="A4">4</xref></contrib><contrib contrib-type="author"><name><surname>Takahashi</surname><given-names>Ryosuke</given-names></name><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-3985-9210</contrib-id><name><surname>Matsumoto</surname><given-names>Riki</given-names></name><email>matsumot@med.kobe-u.ac.jp</email><xref ref-type="aff" rid="A7">7</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><contrib contrib-type="author"><name><surname>Ikeda</surname><given-names>Akio</given-names></name><xref ref-type="aff" rid="A6">6</xref><xref ref-type="fn" rid="FN2">†</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-5907-2488</contrib-id><name><surname>Lambon Ralph</surname><given-names>Matthew A.</given-names></name><email>Matt.Lambon-Ralph@mrc-cbu.cam.ac.uk</email><xref ref-type="aff" rid="A8">8</xref><xref ref-type="corresp" rid="CR1">*</xref><xref ref-type="fn" rid="FN2">†</xref></contrib></contrib-group><aff id="A1"><label>1</label>Dept. of Psychology, Louisiana State University, Audubon Hall, Baton Rouge, LA 70803</aff><aff id="A2"><label>2</label>Dept. of Psychology, University of Wisconsin, Brogden Hall, Madison, WI 53706</aff><aff id="A3"><label>3</label>Dept. of Neurology. Kyoto University Graduate School of Medicine, Kawaharacho, Shogoin, Sakyo-ku, Kyoto, 606-8507, Japan</aff><aff id="A4"><label>4</label>Dept. of Neurosurgery, Kyoto University Graduate School of Medicine, Kyoto, Japan</aff><aff id="A5"><label>5</label>Dept. of Neurosurgery, Ehime University Graduate School of Medicine, Shizukawa Toon city, Ehime, 791-0295, Japan</aff><aff id="A6"><label>6</label>Dept. of Epilepsy, Movement Disorders and Physiology, Kyoto University Graduate School of Medicine, Kyoto, Japan</aff><aff id="A7"><label>7</label>Div. of Neurology, Kobe University Graduate School of Medicine, Kusunoki-cho, Chuo-ku, Kobe, 650-0017, Japan</aff><aff id="A8"><label>8</label>MRC Cognition and Brain Sciences Unit, 15 Chaucer Rd., Cambridge, UK, CB2-7EF</aff><author-notes><corresp id="CR1"><label>*</label>Corresponding author</corresp><fn id="FN1"><label>※</label><p id="P1">Co-first author</p></fn><fn id="FN2"><label>†</label><p id="P2">Co-senior author</p></fn></author-notes><pub-date pub-type="nihms-submitted"><day>29</day><month>10</month><year>2022</year></pub-date><pub-date pub-type="preprint"><day>27</day><month>10</month><year>2022</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nd/4.0/">CC BY-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P3">Neuro-cognitive models of semantic memory have proposed that the ventral anterior temporal lobes (vATLs) encode a graded, distributed, and multidimensional semantic space—yet neuroimaging studies seeking brain regions that encode semantic structure rarely identify these areas. In computer simulations we show that this discrepancy may arise from limitations of a commonly-used multivariate analysis, and introduce a new approach, <italic>representational similarity learning</italic> (RSL), that resolves these. We then use RSL to decode semantic structure from ECoG data collected from the vATL cortical surface while participants named line drawings of common items. The results reveal a graded, multi-dimensional semantic space encoded in neural activity across the vATL, which evolves over time and simultaneously expresses both broad and finer-grained semantic structure amongst animate and inanimate concepts. The work thus resolves the apparent discrepancy within the semantic cognition literature and suggests a new approach to discovering representational structure in neural data more generally.</p></abstract><kwd-group><kwd>Semantic memory</kwd><kwd>ECoG</kwd><kwd>temporal lobe</kwd><kwd>decoding</kwd><kwd>representational similarity analysis</kwd><kwd>RSA</kwd><kwd>network RSA</kwd></kwd-group></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P4">If you encounter a wolf when walking home through a dark wood, your mind readily accomplishes some remarkable feats: it anticipates the animal’s likely behavior, perhaps slinking closer toward you; it assigns the thing a name, which you might shout to alert others (“wolf!”); and it directs you to change your own plans, maybe running back down the path. These feats arise from the human ability to discern conceptual structure—to realize that the wolf, despite its resemblance to friendly dogs in town, is nevertheless a quite different sort of animal.</p><p id="P5">This ability to represent and exploit conceptual structure is central to human semantic cognition. Such structure is <italic>graded</italic> in that similarities vary along a continuum: wolves are highly similar to coyotes, partially similar to elk, and quite distinct from birch trees or canoes. It is also <italic>multidimensional</italic> in that concepts vary along myriad independent components: wolves and dogs are similar in their shapes, parts, movements, and phylogeny, but different in their behaviors, habitats, and diets. To capture these properties of knowledge, computational approaches to semantics often represent concepts with <italic>vector spaces:</italic> the meaning of a word or image is expressed as a point in an <italic>n</italic>-dimensional space (or equivalently as an <italic>n</italic>-dimensional vector) such that the proximity between points expresses the similarity in meaning between the denoted concepts. Cognitive science and machine-learning offer many techniques for estimating semantic vector spaces from natural language <sup><xref ref-type="bibr" rid="R1">1</xref></sup>, feature norms <sup><xref ref-type="bibr" rid="R2">2</xref></sup>, or similarity-judgments <sup><xref ref-type="bibr" rid="R3">3</xref></sup>, and these methods have provided a critical empirical foundation for studying human conceptual knowledge.</p><p id="P6">A central question for cognitive neuroscience concerns how semantic vector spaces are encoded in neural activity, but progress has been hampered by contradictory findings across different literatures. Convergent evidence from neuropsychology, clinical neurophysiology, transcranial magnetic stimulation, and computational modeling suggests that the anterior temporal lobes (ATLs) encode graded and multidimensional conceptual similarity structure <sup><xref ref-type="bibr" rid="R4">4</xref>–<xref ref-type="bibr" rid="R9">9</xref></sup>, but a direct empirical test of this hypothesis—multivariate decoding of functional neuroimaging data—has yielded decidedly mixed results. A few studies have found ATL areas that encode conceptual structure in neural activity <sup><xref ref-type="bibr" rid="R10">10</xref>–<xref ref-type="bibr" rid="R14">14</xref></sup>, but others have observed such structure only in posterior temporal areas <sup><xref ref-type="bibr" rid="R15">15</xref>–<xref ref-type="bibr" rid="R22">22</xref></sup>, or within a left-lateralized peri-sylvian network <sup><xref ref-type="bibr" rid="R12">12</xref>,<xref ref-type="bibr" rid="R23">23</xref>–<xref ref-type="bibr" rid="R25">25</xref></sup>, or even across the entire cortex <italic>except</italic> the ATL <sup><xref ref-type="bibr" rid="R26">26</xref></sup>.</p><p id="P7">This paper considers the possibility that the gap between imaging and other literatures arises because the most common analytic technique employed in these studies—representational similarity analysis (RSA)—is not actually well-suited to finding <italic><underline>graded multidimensional</underline></italic> structure. This may seem surprising, since RSA was developed specifically as a tool for finding cognitive similarity structure in imaging data <sup><xref ref-type="bibr" rid="R27">27</xref></sup>—yet the reliance of the approach on unsupervised correlation places non-trivial limits on the kinds of signal it can detect. Study 1 reports simulations assessing how these limitations will influence discovery of neuro-semantic representations, and introduces a new approach to neural decoding, <italic>representational similarity learning</italic> RSL; <sup><xref ref-type="bibr" rid="R28">28</xref></sup>, designed to address them. Study 2 considers how RSL can be applied to decoding of very large neural datasets by exploiting patterns of <italic>structured sparsity</italic> present in neural signals. We show how such patterns can inform model fitting in RSL, then use the approach to decode graded multidimensional semantic structure from electro-corticography (ECoG) recorded from the surface of human vATL. The results resolve the contradiction in the literature and suggest a new path for multivariate neural decoding more generally.</p></sec><sec id="S2" sec-type="results"><title>Results</title><sec id="S3"><title>Study 1: Simulation experiments</title><p id="P8">RSA aims to find sets of neural features—voxels, electrodes, or other measurements of neuro-physiological activity—whose responses to various cognitive events (e.g., the perception of a stimulus) jointly encode an independently-measured target structure. Typically, the target structure is a <italic>representational similarity matrix</italic> (RSM)<sup><xref ref-type="fn" rid="FN3">1</xref></sup> in which the rows and columns correspond to the different stimuli in an experiment and the entries indicate the cognitive/representational similarities between stimuli. For semantic representation, entries in the target RSM indicate similarity of meaning among pairs of concepts as estimated from behavioral or corpus data. To determine if a set of neural features (e.g., voxels, electrodes, EEG sources, etc.) encodes the target similarities, the experimenter estimates the pattern of neural activity evoked by each stimulus and computes the pairwise similarities between these to create a <italic>neural similarity matrix</italic> (NSM). Correlations between the RSM and NSM are computed separately for each participant, and brain regions where these are reliably greater than zero are interpreted as encoding the target structure.</p><p id="P9">This approach faces three challenges when used to find <italic>graded, multidimensional</italic> structure in neural codes. First, reliable correlations with a continuous-valued target RSM can arise even if the neural response is discrete or categorical (e.g., equally active for items in one semantic category and equally inactive for a different category). Thus, a positive result does not indicate that the neural response encodes <italic>graded</italic> structure even if such structure is present in the target RSM. Second, when computing the correlation, all neural features are equally weighted and no parameters are fit, so the approach may yield a null result even if the target structure <italic>is</italic> encoded by a weighted subset of the neural features under consideration. Thus, a negative result does not indicate that the neural features carry no target information. Third, correlation is inherently one-dimensional, so in itself cannot provide evidence of multidimensional structure in the neural response. Simulation 1 assessed how these characteristics of RSA will influence discovery of neuro-semantic representations by applying the approach to simulated neural data encoding different aspects of a target similarity matrix.</p><sec id="S4"><title>Simulation 1: Limitations of RSA</title><p id="P10">The target RSM was computed from semantic feature norms for 100 items, half animate and half inanimate, collected in prior work <sup><xref ref-type="bibr" rid="R29">29</xref></sup>. The feature vectors for each item were aggregated in a matrix with rows indicating words and columns indicating features and entries indicating whether the referent of the word possess that feature. Matrix columns were mean-centered and the RSM was computed as the cosine similarity for all pairs of row vectors.</p><p id="P11">To understand the latent structure of the RSM, we used singular value decomposition (SVD) to extract three components accounting for 90% of the variance in the full matrix. <xref ref-type="fig" rid="F1">Figure 1</xref> shows the coordinates for all 100 items on each latent dimension, color coded by semantic category (see SM). The decomposition reveals graded semantic structure along each dimension. The first separates animate from inanimate items but also individuates subcategories in each domain. The second strongly differentiates subcategories of animals but also weakly distinguishes inanimate subcategories. The third differentiates the inanimate items, though the resulting spread is less “clumpy” than within animate items as commonly found with such data <sup><xref ref-type="bibr" rid="R5">5</xref></sup>.</p><p id="P12">We investigated what results RSA would yield when applied to a neural signal known to encode some aspects of this underlying semantic structure. Specifically, we created five simulated neural datasets, each capturing a different aspect of semantic structure in the target RSM. For each dataset we simulated the responses of 24 hypothesized neural features (e.g., the BOLD response over 24 voxels in an ROI, or the mean evoked response at each of 24 electrodes) to the 100 stimuli. Half of the simulated neural features encoded true semantic information about the target items while half adopted random values sampled from a uniform distribution in the same range. The five datasets varied in which aspects of the target matrix they encoded, as illustrated in the schematic plots in <xref ref-type="fig" rid="F2">Figure 2A</xref>. In the <italic>binary condition</italic>, all signal-carrying neural features adopted one state (-1 or 1) for animate items and the opposite state for inanimate items. Thus, the code was both one-dimensional and discrete. In three <italic>one-D conditions</italic>, all signal-carrying neural features only encoded a single latent component of the target RSM—either the first, second, or third singular vector as shown in <xref ref-type="fig" rid="F1">Figure 1</xref>. Thus, each encoded <italic>graded</italic> similarity structure but only <italic>one</italic> dimension of variation. In the <italic>full structure condition</italic>, the signal-carrying units jointly encoded all three latent components of variation in the target RMS—thus the code was both graded and multidimensional.</p><p id="P13">To examine the results RSA would yield for each kind of neural signal, we distorted the simulated neural responses to each stimulus with measurement noise sampled from a uniform distribution centered on 0, then computed the correlation between the simulated NSM and target RSM. <xref ref-type="fig" rid="F2">Figure 2B</xref> shows the results across increasing measurement noise and averaged over 20 runs of the simulation. The binary code showed robust correlations across the full noise-spectrum, illustrating that RSA can yield a positive result even when the neural code is neither continuous nor multidimensional. Amongst the one-D codes, RSA showed a strong positive result if the neural response encoded the first singular vector of the target matrix, but much weaker results that decayed to zero with increasing noise when the neural response encoded other components. Thus, RSA can yield null results even when the neural features under consideration reliably encode target information orthogonal to the primary component of the RSM. A strong correlation was observed when the neural features encoded all three components of the target matrix and there was little noise in the signal, but this declined steeply with noise. In high noise conditions, RSA yielded a more reliable result when the simulated neural response encoded a binary domain distinction or just the first component of variation. For these scenarios, all signal-carrying features encode the same information, so noise “cancels out” across features and the signal remains robust. When the same number of features encode three orthogonal components, fewer resources are dedicated to each, and corruption from noise more seriously degrades the signal.</p><p id="P14">The simulation shows that, when decoding semantic similarity structure of the kind captured by feature norms, RSA can yield a positive result when the neural response is discrete and/or one-dimensional, and a null result when the neural response encodes underlying dimensions of the target matrix beyond the strongest. Thus RSA, as typically deployed, does not reliably indicate whether a set of neural signals encode the graded, multidimensional semantic structure existing in a target RSM.</p></sec><sec id="S5"><title>Simulation 2: Decoding with RSL</title><p id="P15">These issues led us to consider an alternative approach designed explicitly to decode graded, multidimensional similarity structure, which we call <italic>representational similarity learning</italic> RSL; <sup><xref ref-type="bibr" rid="R28">28</xref></sup>. Rather than using pairwise similarities in the RSM as the target values for decoding, RSL first decomposes the matrix into orthogonal latent components, effectively re-representing each stimulus item as a point in a low-dimensional semantic space as shown in <xref ref-type="fig" rid="F1">Figure 1</xref>. It then fits <italic>decoding models</italic> to predict the coordinates of each item along each dimension from their evoked neural responses.</p><p id="P16">Simulation 2 assessed whether this approach can reveal the graded and/or multidimensional structure obscured by RSA. Using the same dataset from Simulation 1, we fit regression models to predict coordinates of each stimulus along each of the three latent semantic dimensions shown in <xref ref-type="fig" rid="F1">Figure 1</xref>, then assessed model fit using 10-fold hold-out cross validation. Multidimensional structure in the neural code should be revealed by reliable prediction of coordinates along more the one latent dimension. To assess whether the neural code captures graded similarity, we evaluated models fit separately to animate- or inanimate items only. If the neural signal only categorically differentiates, for instance, animate from inanimate stimuli as observed, for instance, by <sup><xref ref-type="bibr" rid="R30">30</xref></sup>, then predicted and true values should correlate significantly when models are fit to all items, but should not correlate when fit to just the animate or just the inanimate items. Reliable intra- and inter-domain correlations thus indicate that the neural code captures a graded degree of similarity structure.</p><p id="P17"><xref ref-type="fig" rid="F3">Figure 3C</xref> shows the correlation between true and predicted coordinates for held-out items on each of the three target components (columns), for the five different neural coding scenarios (rows), and computed across all items (black lines), animate items (red), or inanimate items (green). The pattern of results reveals the information encoded in each simulated neural response. With the binary neural signal (top row), predicted and true coordinates correlated strongly for models fit to all items but not separately for animates vs inanimates. With continuous one-D signals, strong correlations were observed for models fit to all items and within each domain separately, but only for the dimension encoded by the neural response. When the neural signal encoded graded multidimensional structure, reliable correlations were observed on all three latent components, for models fit to all items and fit separately to each domain. Thus in simulation, the pattern of results uniquely revealed whether the neural signal encodes graded or discrete structure, and which semantic dimensions it captures.</p></sec></sec><sec id="S6"><title>Study 2: Decoding semantic structure from ECoG using RSL</title><p id="P18">The simulations show how RSL can test for graded and multidimensional structure where RSA results are ambiguous. Applying the approach to real brain imaging data, however, faces an immediate challenge: such technologies produce many more neural measurements than there are stimuli, so regression models predicting stimulus characteristics from neural data are ill-defined (i.e., there exist infinite solutions that can perfectly predict outcomes even from random input data). To find a unique fit without a-priori feature selection, the regression must be <italic>regularized</italic> to satisfy some additional constraint that will guarantee a single unique solution for model fitting. For instance, the weight optimization might jointly minimize prediction error and the size of the model coefficients, measured as the sum of their absolute values (the <italic>L1-norm</italic>). Since this sum can be minimized by placing zero coefficients on many predictors, this form of regularization promotes a sparse solution in which only a few predictors have non-zero coefficients in the final model e.g., <sup><xref ref-type="bibr" rid="R31">31</xref></sup>. Other regularizers (such as the L2 norm or the elastic net) enforce different constraints on model fitting, and thus lead to other solutions when applied to the same dataset <sup><xref ref-type="bibr" rid="R32">32</xref></sup>. The selection of a regularization function therefore amounts to a prior hypothesis stipulating how the neural signal is likely to be structured <sup><xref ref-type="bibr" rid="R33">33</xref></sup>.</p><sec id="S7"><title>Regularization with structured sparsity</title><p id="P19">RSL applied to real neural data adopts the <italic>group-ordered-weighted LASSO</italic> or grOWL loss <sup><xref ref-type="bibr" rid="R28">28</xref></sup>, a regularization function designed specifically in prior work to capture three theoretically-motivated assumptions about the structure of neural representations. First, it assumes the signal is <italic>sparse:</italic> of all measurements taken, only a relatively small proportion encode target information of interest, so the regularizer should place zero coefficients on many predictors (as with L1 regularization). Second, it assumes <italic>redundancy</italic> in the true signal: neural populations that encode variation along the same dimension will be correlated in their activity patterns over items. The regularizer should therefore spread similar coefficients across correlated signal-carrying populations (similar to L2 regularization). Third, it assumes that signal-carrying populations are unlikely to be “axis-aligned” with the target semantic space (i.e., where each semantic dimension aligns perfectly and uniquely with individual neural elements), but more likely encode multiple, varying “directions” within the space, such that the neural population carries information about the items’ coordinates within the multiple dimensional target space. We will refer to this as the <italic>spanning</italic> assumption, since the selected neural features span the target representational space but are unlikely to only encode distinct, individual dimensions. To enforce this assumption, the regularizer should prefer solutions where coefficients on a given neural feature are either all zero (the feature does not carry any information) or all non-zero (it predicts some variation along all target dimensions).</p><p id="P20">All three assumptions can be captured in a single loss function, as follows. Rather than fitting a separate regression model for each latent component of the target RSM, we instead predict all latent components (<xref ref-type="fig" rid="F3">Figure 3A</xref>) simultaneously by estimating the parameters of a <italic>decoding matrix β</italic> (<xref ref-type="fig" rid="F3">Figure 3C</xref>). Suppose the coordinates of <italic>n</italic> stimuli on <italic>r</italic> latent semantic dimensions are stored in matrix <italic><bold>Y</bold></italic><sub><italic>n</italic>×<italic>r</italic></sub> while the responses of <italic>m</italic> neural features to the stimuli are stored in matrix <italic><bold>X</bold></italic><sub><italic>n</italic>×<italic>m</italic></sub>. RSL models the entries in <italic><bold>Y</bold></italic> as the matrix product of the neural activations in <italic><bold>X</bold></italic> and the decoding matrix <italic><bold>β</bold></italic><sub><italic>m</italic>×<italic>r</italic></sub>: <italic><bold>Y</bold></italic> = <italic><bold>Xβ</bold></italic>. Each row of <italic><bold>β</bold></italic> corresponds to one neural feature (voxel, electrode, etc.), and each column encodes weights for each neural feature when predicting stimulus coordinates on the corresponding dimension of the target matrix <italic><bold>Y</bold></italic>. With this setup, the assumptions about neural signal just listed can be formalized as constraints on the structure of the decoding matrix <italic><bold>β</bold></italic> (<xref ref-type="fig" rid="F3">Figure 3D</xref>). To capture the sparsity and spanning assumptions, <italic><bold>β</bold></italic> is constrained to be <italic>row-sparse:</italic> most rows have all zero values (sparsity), and the rest have all non-zero values (spanning). To capture the redundancy assumption, highly correlated and signal-carrying neural features receive similar row-vectors in <italic><bold>β</bold></italic> (<xref ref-type="fig" rid="F3">Figure 3D</xref>). A formal description of the decoding model and grOWL regularizer, including a definition of the loss and explanation of how it encourages these properties in the decoding matrix, are provided in the <xref ref-type="supplementary-material" rid="SD1">Supplementary Materials</xref>. Further analysis and proofs were described by <sup><xref ref-type="bibr" rid="R28">28</xref></sup>. <xref ref-type="fig" rid="F3">Figure 3</xref> shows the full workflow decoding semantic structure from ECoG data.</p><p id="P21">With this overview we can consider how RSL can be applied to assess whether neural data encode a multidimensional and graded similarity space. Parameters in <italic><bold>β</bold></italic> are estimated for a batch of training data using regularized regression. The decoding model is then applied to predict the coordinates of held-out items along each dimension in the target representation space. If predicted and true coordinates for held-out items correlate reliably with more than one dimension, the neural signal must encode multidimensional structure. To assess whether the neural code captures graded similarity, we additionally fit and evaluate models separately for animate and inanimate items, as in the simulation. If the neural signal only categorically differentiates animate from inanimate stimuli as suggested by the RSA analysis in <sup><xref ref-type="bibr" rid="R30">30</xref></sup>, then predicted and true values should correlate significantly across all items, but not across just the animate or just the inanimate items. Observation of both inter- and intra-domain correlations thus indicates that the neural code captures a graded degree of similarity structure. Finally, to assess how well the decoder recovers the target semantic similarities, the predicted coordinates for held-out items can be used to estimate semantic distances between stimulus pairs. These estimates can then be correlated with true semantic distances, similar to standard RSA.</p></sec><sec id="S8"><title>ECoG experiment</title><p id="P22">We applied this approach to an ECoG dataset where prior work using RSA found little evidence for graded multidimensional structure <sup><xref ref-type="bibr" rid="R30">30</xref></sup>. While the authors did find a reliable correlation between a semantic RSM and the NSM in the anterior ventral temporal cortex, further analysis showed that the NSM correlated equally well with a binary matrix capturing only stimulus animacy (similar to the binary code in Simulation 1) and did not correlate at all with a matrix capturing within-domain semantic structure (similar to the 1D codes in Simulation 1). These results do not seem to be in keeping with the hypothesis that vATL activity encodes a graded, multi-dimensional semantic space; accordingly, we assessed whether such a space could be recovered from the same data using RSL.</p><p id="P23">The dataset contains voltages measured from grid electrodes implanted in the surface of left (8) or right (2) vATL in ten patients undergoing preparation for intractable epilepsy (9) or brain tumor (1) while they named line drawings depicting the 100 items described in Study 1. Each patient had between 6 and 32 electrodes (mean of 20) covering vATL. The dataset included, for each stimulus, voltages measured at each electrode over a 1s window from stimulus onset and downsampled to 100 Hz. Thus, for a participant with 20 electrodes, each stimulus was associated with a 2,000-element vector of voltages (20 electrodes x 100 time points). See <xref ref-type="sec" rid="S11">Methods</xref> for further detail about the patients, stimuli and experimental procedure.</p><p id="P24">All models were fit and evaluated using a nested 10-fold cross-validation procedure: an inner loop performed on 90% of the data was used to select model hyper-parameters; a single model was then fit using the best hyper-parameters and was evaluated on the remaining 10% of data. This procedure was run 10 times for 10 different final hold-out sets. In each fold, the fitted model was used to predict coordinates of the held-out items on the three latent semantic dimensions. The predictions were then aggregated across folds to create a single matrix of predicted coordinates for each item when it was held out from model fitting. Separate models were fit and evaluated independently for each participant, and we assessed whether the mean correlation between predicted and true coordinates was reliably positive across participants. Further model fitting and evaluation details appear in the Methods.</p><p id="P25">Our analyses closely followed the simulations: correlations between predicted and true coordinates on each dimension were computed for all 100 stimuli, just the 50 animate items, or just the 50 inanimate items. To determine whether the observed correlation was statistically reliable, we compared it to bootstrapped null distributions generated via permutation testing <sup><xref ref-type="bibr" rid="R34">34</xref></sup>; see <xref ref-type="sec" rid="S11">Methods</xref>, using a familywise error rate of 0.05. Finally, to understand the effects of regularization with structured sparsity (grOWL) vs. more standard techniques, we compared models fit with grOWL regularization to those fit with L1 (LASSO) regularization.</p><p id="P26"><xref ref-type="fig" rid="F4">Figure 4</xref>(top) shows results from decoding the full 1s time-window. Models fit with grOWL reliably decoded the first and second latent components of the semantic matrix, both when fit to all items and just to animate items. Thus, grOWL reveals graded, multidimensional semantic structure in ECoG signals recorded from ventral ATL. Regularization with the LASSO showed similar decoding of the first latent component but null results for the second and third, suggesting that additional constraints from grOWL aided in the discovery of semantic structure.</p><p id="P27">To see how this structure emerges in the ECoG signal over time, we conducted an “opening window” analysis in which the same procedure was applied to an increasingly wide aperture of data, beginning with just the first 50 ms post-stimulus, extending to 100 ms, then growing by 100 ms up to 1000 ms. At each window models were fit and evaluated as just described. The results showed reliable decoding of the first dimension by 200 ms, but only for models fit to all items, suggesting an early differentiation of animate from inanimate items. By 300 ms, models also reliably decoded component-1 variation when fit separately for just animate or just inanimate items. Decoding accuracy along component 1 continually improved with wider windows for models fit with all items or animates alone, but not for models fit only with inanimate items. Decoding along the second component was not observed until 400 ms (for animates only) or 500 ms (for all items). Decoding along the third (weakest) component of the target matrix was not observed at any time point. Models fit with LASSO again revealed reliable decoding of only the first latent dimension, and only for models fit to all data or just animates.</p><p id="P28">Finally, we considered how well the decoding model recovers true semantic similarities between stimuli by reconstructing the pairwise similarity matrix from the predicted coordinates of held-out items across all three dimensions, then correlating these decoded similarities with the best possible reconstruction (i.e., similarities expressed by the three singular vectors/values of the true RSM; results for the original full-rank matrix are similar and shown in SM). For comparison to the prior RSA analysis of the same dataset <sup><xref ref-type="bibr" rid="R30">30</xref></sup>, models were fit and evaluated on a 100 ms moving window, beginning at 0 ms from stimulus onset and advancing in 50 ms increments (see <xref ref-type="sec" rid="S11">Methods</xref>). At each window, predicted coordinates for all items were generated using the nested cross-validation procedure described earlier and concatenating the predictions for each hold-out set across folds. The predicted coordinates were used to compute predicted similarities between all stimulus pairs. Each row of the resulting matrix contains predicted similarities between an item and all other items. We then computed, for each row, the correlation between the predicted and true similarities, and averaged these correlations across (1) all rows, (2) just the animates or (3) just the inanimates. The full procedure was carried out independently for each participant at each time-window. Correlation coefficients in each condition (all items, animates, inanimates) were then averaged across participants at each time-window and compared to a bootstrapped permutation-based null distribution using a familywise error-rate of p &lt; 0.05.</p><p id="P29">The results are shown in <xref ref-type="fig" rid="F5">Figure 5</xref> (left). Filled circles indicate where predicted/true correlations are reliably non-zero relative to a bootstrapped permutation-based null distribution with a familywise error-rate of p &lt; 0.05. Reliable correlations were observed from 100 − 150 ms post-stimulus onward, whether computed across all items, within domain only, or between-domain only. <xref ref-type="fig" rid="F5">Figure 5</xref> (left) also shows the mean correlation (across participants) between RSM and NSM at each window reported in Y. Chen et al.’s <sup><xref ref-type="bibr" rid="R30">30</xref></sup> RSA analyses of the same data. While reliably positive correlations were observed from 200 ms onward, the correlation coefficient was about 1/10<sup>th</sup> the magnitude observed with RSL.</p><p id="P30">To assess whether RSL models capture structure for both animate and inanimate items, we computed the same three metrics separately for each domain. First considering just the animates, we computed the correlation between true and predicted similarities to all other items, other animate items (i.e., same domain), or inanimate items (i.e., other domain). The results in <xref ref-type="fig" rid="F5">Figure 5</xref> (middle) show reliable decoding in all three cases, albeit at only a few time-windows for similarities from animates to inanimates. Applying the same analysis to inanimates, we observed reliable decoding of similarities to all items, same-domain items, and other-domain items from about 200 ms post-stimulus. Note that the weakest reliable correlations are still about double the magnitude of those observed in the Y. Chen, et al. <sup><xref ref-type="bibr" rid="R30">30</xref></sup> study using RSA.</p></sec></sec></sec><sec id="S9" sec-type="discussion"><title>Discussion</title><p id="P31">We introduced this paper with a puzzle: neuropsychology, clinical neurophysiology, TMS and computational modelling all suggest that the vATLs encode a continuous multidimensional semantic space, but multivariate analysis of brain imaging data often leads to quite different conclusions. In simulation we showed that the puzzle might reflect more general limitations of RSA, which can produce positive results even if the underlying neural code is discrete and one-dimensional, or negative results even if the neural code does capture latent structure in the target matrix beyond the first component. RSL addresses these limitations by using regularized regression to predict coordinates of stimuli along the latent dimensions of the RSM. For application to large neural datasets, we illustrated how hypothesized patterns of structured sparsity in the neural signal can constrain model fit via grOWL regularization and applied this approach to discovery of semantic structure in an ECoG dataset where prior work using RSA found only a binary animacy code. In contrast, RSL uncovered a graded and multidimensional semantic space capturing similarities within and between animate and inanimate domains—reconciling the apparent discrepancy between neuroimaging and results yielded by other methodologies.</p><p id="P32">We note that decoding of intra-domain similarities was always more robust for animate compared to inanimate items. Considering each dimension separately, within-inanimate decoding was only reliable for one time window on the first latent dimension. When predicting pairwise distances, correlations with true similarities were always smallest for within-inanimate structure (i.e., the “other domain” correlations in the middle panel of <xref ref-type="fig" rid="F5">Figure 5</xref>, and “same domain” correlations in the rightmost panel). We attribute this to differences in the similarity structures of animate and inanimate concepts. Semantic subcategories of inanimate objects are only weakly differentiated, not just in the current dataset, but in norming studies more generally and in other approaches to characterizing semantic structure e.g., <sup><xref ref-type="bibr" rid="R35">35</xref>,<xref ref-type="bibr" rid="R36">36</xref>–<xref ref-type="bibr" rid="R38">38</xref></sup>. Indeed, this difference in statistical structure is precisely what leads, under some theories, to apparent category-specific patterns of semantic impairment <sup><xref ref-type="bibr" rid="R5">5</xref>,<xref ref-type="bibr" rid="R39">39</xref></sup> and functional activation <sup><xref ref-type="bibr" rid="R40">40</xref></sup>. The differences can be seen in <xref ref-type="fig" rid="F1">Figure 1</xref>, where animate items fall into somewhat well-differentiated subcategories in dimensions 1 and 2 while inanimates are uniformly distributed with no clear subclusters even along dimension 3. Indeed, pairwise similarities reconstructed from the first three singular vectors of the full semantic matrix are more accurate for animate than inanimate items (see <xref ref-type="supplementary-material" rid="SD1">SM3</xref>). Thus, the structure of the semantic matrix itself <italic>requires</italic> that decoding be worse within inanimates than within animates, precisely because inanimates are less well-structured. Yet despite this intrinsic disadvantage, within-inanimate similarities were still reliably decoded over many time-windows, illustrating that neural signal in vATL does express some intra-domain semantic structure even for inanimate stimuli. In summary, the results suggest the vATLs encode a multidimensional representation space that captures the conceptual similarities existing amongst a variety of different concepts including both animate and inanimate items <sup><xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R9">9</xref>,<xref ref-type="bibr" rid="R41">41</xref></sup>. Better decoding within animates simply reflects the fact that animate subcategories are better-differentiated, so that intra-domain similarities are better-approximated by a low-rank decomposition.</p><p id="P33">We further note that multidimensional structure was only discovered with grOWL regularization—that is, when the decoding model was constrained to be sparse overall, with correlated neural features receiving similar weights, and with weights on all dimensions encouraged to be all-zero or all-nonzero. The observation is important for two reasons. First, consistent with other recent work <sup><xref ref-type="bibr" rid="R32">32</xref></sup>, it shows that the form of model regularization matters critically to conclusions about information encoded in the neural signal. Simple regularization with the L1 norm was insufficient to reveal more than one dimension of structure in the neural code. Second, it suggests that different dimensions in the semantic matrix are <italic>not</italic> encoded separately by distinct neural populations at the resolution captured by ECoG. The pressure from grOWL to place either all-zero or all-nonzero coefficients on each neural feature produced reliable decoding of both the first and second latent dimensions of the semantic matrix—thus features that predict variation along the first dimension are also likely to carry information about the second dimension and vice versa. This observation is again consistent with the view that all signal-carrying neural populations jointly contribute to encoding a single semantic space (see also analysis of feature distributions across the cortical surface in SM).</p><p id="P34">Since we only analyzed electrodes situated in vATL, the current data do not shed light on structure encoded in other parts of cortex. The characteristics of RSA we have identified do, however, carry additional implications for interpretation of the broader literature. A recent review <sup><xref ref-type="bibr" rid="R33">33</xref></sup> identified 34 studies that have applied RSA to the discovery of semantic representations in the brain, with positive results observed across multiple cortical regions including posterior temporal cortex <sup><xref ref-type="bibr" rid="R19">19</xref></sup>, angular gyrus <sup><xref ref-type="bibr" rid="R12">12</xref>,<xref ref-type="bibr" rid="R42">42</xref></sup>, left perisylvian cortex <sup><xref ref-type="bibr" rid="R25">25</xref></sup>, and prefrontal cortex <sup><xref ref-type="bibr" rid="R22">22</xref></sup>. Simulation 1 suggests, however, that RSA will yield a positive result for any property correlated with the animate/inanimate distinction, including even discrete binary properties. Many features are confounded with animacy: inanimate items tend to be more familiar, less visually complex, more associated with action plans, less associated with motion, more likely to have lines and corners, less predictable from color or texture, etc. see <sup><xref ref-type="bibr" rid="R43">43</xref> for a review</sup>. Most RSA papers do not report the magnitude of correlation between RSM and NSM where results are significant, instead focusing on whether the estimated correlation coefficient is reliably non-zero across participants. As shown in <xref ref-type="fig" rid="F5">Figure 5</xref>, this can happen even when mean correlations are very small. Moreover, several studies use target RSMs with only a small number of rows/columns—sometimes as few as 5 e.g., <sup><xref ref-type="bibr" rid="R12">12</xref>,<xref ref-type="bibr" rid="R19">19</xref></sup>, meaning that correlations are computed across just 10 cells of the matrix (i.e., the lower triangle of a 5×5 RSM). Such small numbers increase the likelihood that a small-but-non-zero correlation is driven by some arbitrary property of the chosen stimuli or categories. Together these observations raise the possibility that the literature contains misleading positive results—brain areas whose responses encode unidimensional characteristics weakly confounded with animacy, rather than multi-dimensional semantic structure. Testing this possibility for various brain areas hypothesized to encode semantic structure will require analyses similar to the ones we have developed here.</p></sec><sec id="S10" sec-type="conclusions"><title>Conclusion</title><p id="P35">In cognitive science, semantic representations are often construed as vector spaces that encoded graded, multidimensional similarity structure amongst the concepts experienced in our verbal and nonverbal world. Through application of a new technique for mapping representational similarity in neural activity, we have shown that neural signals in vATL encode such a space. In so doing, we have identified some limitations of representational similarity analysis, a widespread technique commonly thought to reveal graded and multidimensional representational structure. The work resolves an important discrepancy between behavioral and neuroimaging results in prior work and suggests a new approach to discovering representational structure in neural data more generally.</p></sec><sec id="S11" sec-type="methods"><title>Methods</title><sec id="S12"><title>Patients and ECoG Acquisition</title><p id="P36">Ten patients with intractable partial epilepsy (nine) or brain tumor (one) participated in this study, including two for whom language was not left-lateralized as determined by the WADA language lateralization test. Chen, et al. <sup><xref ref-type="bibr" rid="R30">30</xref></sup> provide their background clinical information. Platinum subdural electrodes (83 per patient on average; range 56 − 107 electrodes) were implanted in the left (8 patients) or right (2 patients) hemisphere for presurgical evaluation with inter-electrode distance of 1 cm and recording diameter of 2.3 mm (ADTECH, WI). Between six and 32 (mean 20) electrodes covered the vATL in each patient. Data were sampled at 1000 Hz (eight patients) or 2000 Hz (two patients) with a band-pass filter of 0.016 − 300 (eight patients) or 0.016 − 600 Hz (two patients), though our analyses downsampled these to 100 Hz. All patients with epilepsy had seizure onset zones outside the anterior fusiform region, except one patient for whom it was not possible to localize the core seizure onset region. The study was approved by the ethics committee of the Kyoto University Graduate School of Medicine (No. C533). Participants provided written informed consent to participate in the study.</p></sec><sec id="S13"><title>Stimuli and Procedure</title><p id="P37">One hundred line drawings (50 animate and 50 inanimate items) were obtained from previous norming studies (Morrison et al., 1997; Snodgrass &amp; Vanderwart, 1980). See Chen, et al. <sup><xref ref-type="bibr" rid="R30">30</xref></sup> for a complete list. Animate and inanimate stimuli were matched on age of acquisition, visual complexity, familiarity, and word frequency, and had high name agreement. Each stimulus was presented on a computer screen for 5 seconds, one after another with no interstimulus interval, once during each of four sessions (four times in total). Each session proceeded in a different random order. Participants were instructed to name each item as quickly and accurately as possible. Participants were video and audio recorded during the experiment. Video was used to monitor eye fixations and general attention to the task. The mean response latency was 1190 ms.</p></sec><sec id="S14"><title>Semantic similarity structure and dimensionality reduction</title><p id="P38">Each of the 100 images used in the picture-naming task refer to concepts that have been included in prior semantic feature norming studies (Dilkina &amp; Lambon Ralph, 2013; McRae et al., 2005). From these we constructed binary semantic feature vectors indicating which features were judged to be true of each concept. The feature vectors for each concept were aggregated in a matrix with rows indicating concepts and columns indicating features and entries indicating whether the concept possess that feature. Matrix columns were mean-centered and the similarity between all row vectors was then estimated as the cosine of the angle between them: <inline-formula><mml:math id="M1"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo mathvariant="bold">,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msqrt><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:msqrt><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> The resulting symmetric cosine similarity matrix is the full-rank semantic similarity structure among concepts. The full-rank structure was then embedded into a 3-dimensional metric space by applying singular value decomposition to the corresponding cosine distance matrix 1 − <italic><bold>S</bold></italic>. The low-dimensional embedding, shown in <xref ref-type="fig" rid="F1">Figure 1</xref>, accounted for 90% of the variance in the full distance matrix.</p></sec><sec id="S15"><title>ECoG data preprocessing</title><p id="P39">Preprocessing was performed in MATLAB. Data were downsampled to 100 Hz by averaging measurements within 10 ms boxcars. A prior study applying pattern classification to these data found near identical results when analyzing raw voltages versus voltages referenced to the electrode beneath the galea aponeurotica or to the scalp electrode on the mastoid process contralateral to the side of electrode implantation (Rogers et al., 2021). For this reason, and because the location of the reference electrode varied across patients, we analyzed all voltages without referencing. For each stimulus we retained data for 1000 ms from stimulus onset. While the trial epoch may include the onset of articulation toward the end, the critical results cannot reflect such motor activity since all key phenomena are observed early in the epoch. Baseline correction was not performed. The mean voltage at each electrode for each stimulus was computed across the four repetitions. Voltages from different electrodes were concatenated into a row vector and arranged in a neural data matrix with each row containing the vector of voltages for one stimulus sampled from multiple electrodes over time. We rejected columns and then rows where the marginal mean was and more than five standard deviations from the average marginal mean to censor extreme outliers.</p></sec><sec id="S16"><title>Representational similarity learning (RSL) analysis</title><p id="P40">RSL decoding models regularized with either grOWL or the L1-norm were fit and analyzed in MATLAB v9.5 (2018b) <sup><xref ref-type="bibr" rid="R44">44</xref></sup> using the Whole-brain Imaging with Sparse Correlations (WISC) toolbox <sup><xref ref-type="bibr" rid="R45">45</xref></sup>, which implements the approach as a multitask variant of group ordered weighted L1-regularized regression grOWL; <sup><xref ref-type="bibr" rid="R28">28</xref>,<xref ref-type="bibr" rid="R46">46</xref></sup>. <xref ref-type="supplementary-material" rid="SD1">Supplementary Materials</xref> provide a formal description of the grOWL regularization and its application to neural decoding.</p><p id="P41">Fitting a decoding model regularized with grOWL requires specification of two hyper-parameters, <italic>λ</italic> and <italic>w</italic>, which govern the strength with which the decoding matrix is pressured to be row-sparse (2) with similar weights across correlated neural features (<italic>w</italic>). The choice of hyperparameters was determined by ten-fold nested cross-validation for each model fit. The 100 stimuli were randomly divided into ten subsets, each containing five animate and five inanimate items. On each of the ten outer-loop folds, one such set was held out (outer-loop holdout). The remaining nine sets were used to search for good hyperparameter values, using inner-loop cross validation.</p><p id="P42">On each inner-loop fold, one of the nine remaining sets was held out (inner-loop holdout), and a decoding model was fit to the remaining eight sets using a specified pair of hyper-parameter values. Prediction error (Frobenius norm of true versus predicted coordinates on latent dimensions) for the fitted model was evaluated on the inner-loop holdout set. This procedure was repeated once for each of the nine different inner-loop holdouts, all using the same specified hyperparameter values. We then used mean prediction error across the 9 inner-loop hold outs as the estimated performance of the decoder when fit using the specified hyperparameters. Many different hyperparameter values were evaluated in the inner loop, chosen using the Hyperband procedure <sup><xref ref-type="bibr" rid="R47">47</xref></sup>. The best-performing values were selected from these and a final inner-loop model was fit using those parameters and all nine data subsets. This final inner-loop model was used to predict coordinates on the latent semantic dimension for the outer-loop holdout set, completing one iteration of the outer-loop cross-validation. The whole procedure was done ten times, using each data subset once as the outer-loop holdout. Across folds, the procedure generated predicted coordinates for all 100 items when those items were completely held out of model fitting. These final predicted, held-out coordinates, computed separately for each time-window in each participant, were the primary data evaluated in the results.</p></sec><sec id="S17"><title>Statistical thresholding with permutation testing</title><p id="P43">The correlation metric we computed to assess model accuracy has many useful properties: it standardizes means and variances of the target and predicted vectors to focus on just their covariance. This is especially critical when evaluating animate and inanimate items separately. Because data are mean-centered, however, cross-validated correlation has a negative bias when evaluating held-out items <sup><xref ref-type="bibr" rid="R48">48</xref></sup>, so that a null hypothesis of zero with a t-distributed sampling distribution cannot be assumed. We therefore used permutation testing to generate a group-level null distribution following the prescription of <sup><xref ref-type="bibr" rid="R34">34</xref></sup> with 10,000 simulated values for each test (i.e., each window, for each subset of items, in all analyses).</p><p id="P44">For every patient, window, and experimental condition, we conducted the full analysis pipeline just described 100 times, randomly permuting the ordering of the rows in the target matrix each time. This yielded 100 correlation values for each patient, representing expected values from our workflow when no reliable relationship exists between neural data and target matrix (due to the permutation procedure). To estimate the group-level null distribution for each window and condition, we randomly sampled one permutation-based correlation value from the 100 associated with each patient and averaged these. This was repeated 10,000 times <sup><xref ref-type="bibr" rid="R34">34</xref></sup>. If <italic>m</italic> is the number of values in the permutation distribution and <italic>b</italic> is the number of values in the distribution larger than the true correlation value, then the one-tailed p-value can be computed <sup><xref ref-type="bibr" rid="R49">49</xref>,<xref ref-type="bibr" rid="R50">50</xref></sup> as: <disp-formula id="FD1"><mml:math id="M2"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>b</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p id="P45">To control the family-wise error rate, we applied the Westfall-Young procedure <sup><xref ref-type="bibr" rid="R51">51</xref>,<xref ref-type="bibr" rid="R52">52</xref></sup>, which involves taking the maximum value over family members for each of permutation and comparing all test statistics in the family to this single distribution of maximal values.</p></sec></sec><sec sec-type="supplementary-material" id="SkkkM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary Materials</label><media xlink:href="EMS156328-supplement-Supplementary_Materials.pdf" mimetype="application" mime-subtype="pdf" id="d94aAdFbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S18"><title>Acknowledgments</title><sec id="S19"><title>Funding</title><p>This work was partially supported by MRC Programme grant to MALR and TTR (MR/R023883/1) and an intramural award (MC_UU_00005/18), and by a European Research Council grant GAP: 502670428 - BRAIN2MIND_NEUROCOMP. RM reports grants from MEXT, KAKENHI 22H04777, 22H02945. AS reports grants from MEXT, KAKENHI 22K07537</p></sec></ack><sec sec-type="data-availability" id="S20"><title>Data and materials availability</title><p id="P46">All data are available via links in the main text or the <xref ref-type="supplementary-material" rid="SD1">Supplementary Information</xref>.</p></sec><fn-group><fn id="FN3"><label>1</label><p id="P47">Many studies employ the term <italic>representational dissimilarity matrix</italic> or RDM instead. Since the approach is called “representational similarity analysis,” and because similarity/dissimilarity are inversely related, we prefer <italic>representational similarity matrix</italic> or RSM.</p></fn><fn id="FN4" fn-type="con"><p id="P48"><bold>Author Contributions</bold></p><p id="P49">Cox conducted all analysis and drafted the manuscript. Rogers and Lambon Ralph contributed to all aspects of the study design, analysis, and manuscript preparation. Shimotake, Kikuchi, Kunieda, Miyamoto, Takahasi, Ikeda and Matsumoto were responsible for ECoG data collection and clinical assessment.</p></fn><fn id="FN5" fn-type="conflict"><p id="P50"><bold>Competing interests</bold></p><p id="P51">Authors declare no competing interests.</p></fn><fn id="FN6" fn-type="conflict"><p id="P52"><bold>Conflict of interest</bold></p><p id="P53">The Department of Epilepsy, Movement Disorders, and Physiology, Kyoto University Graduate School of Medicine conducts Industry-Academia Collaboration Courses, supported by Eisai Co., Ltd, Nihon Kohden Corporation, Otsuka Pharmaceutical Co., and UCB Japan Co., Ltd.</p></fn></fn-group><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pereira</surname><given-names>F</given-names></name><name><surname>Gershman</surname><given-names>S</given-names></name><name><surname>Ritter</surname><given-names>S</given-names></name><name><surname>Botvinick</surname><given-names>M</given-names></name></person-group><article-title>A comparative evaluation of off-the-shelf distributed semantic representations for modelling behavioural data</article-title><source>Cognitive Neuropsychology</source><year>2016</year><volume>33</volume><fpage>175</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1080/02643294.2016.1176907</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McRae</surname><given-names>K</given-names></name><name><surname>Cree</surname><given-names>GS</given-names></name><name><surname>Seidenberg</surname><given-names>MS</given-names></name><name><surname>McNorgan</surname><given-names>C</given-names></name></person-group><article-title>Semantic feature production norms for a large set of living and nonliving things</article-title><source>Behavior Research Methods</source><year>2005</year><volume>37</volume><fpage>547</fpage><lpage>559</lpage><pub-id pub-id-type="doi">10.3758/BF03192726</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hebart</surname><given-names>MN</given-names></name><name><surname>Zheng</surname><given-names>CY</given-names></name><name><surname>Pereira</surname><given-names>F</given-names></name><name><surname>Baker</surname><given-names>CI</given-names></name></person-group><article-title>Revealing the multidimensional mental representations of natural objects underlying human similarity judgements</article-title><source>Nature Human Behaviour</source><year>2020</year><volume>4</volume><fpage>1173</fpage><lpage>1185</lpage><pub-id pub-id-type="doi">10.1038/s41562-020-00951-3</pub-id></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rogers</surname><given-names>TT</given-names></name><etal/></person-group><article-title>Structure and Deterioration of Semantic Memory: A Neuropsychological and Computational Investigation</article-title><source>Psychological Review</source><year>2004</year><volume>111</volume><fpage>205</fpage><lpage>235</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.111.1.205</pub-id></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lambon Ralph</surname><given-names>MA</given-names></name><name><surname>Lowe</surname><given-names>C</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name></person-group><article-title>Neural basis of category-specific semantic deficits for living things: evidence from semantic dementia, HSVE and a neural network model</article-title><source>Brain</source><year>2007</year><volume>130</volume><fpage>1127</fpage><lpage>1137</lpage><pub-id pub-id-type="doi">10.1093/brain/awm025</pub-id></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Patterson</surname><given-names>K</given-names></name><name><surname>Nestor</surname><given-names>PJ</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name></person-group><article-title>Where do you know what you know? The representation of semantic knowledge in the human brain</article-title><source>Nature Reviews Neuroscience</source><year>2007</year><volume>8</volume><fpage>976</fpage><lpage>987</lpage><pub-id pub-id-type="doi">10.1038/nrn2277</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lambon Ralph</surname><given-names>MA</given-names></name></person-group><article-title>Neurocognitive insights on conceptual knowledge and its breakdown</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><year>2014</year><volume>369</volume><elocation-id>20120392</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2012.0392</pub-id></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shimotake</surname><given-names>A</given-names></name><etal/></person-group><article-title>Direct Exploration of the Role of the Ventral Anterior Temporal Lobe in Semantic Memory: Cortical Stimulation and Local Field Potential Evidence From Subdural Grid Electrodes</article-title><source>Cerebral Cortex</source><year>2015</year><volume>25</volume><fpage>3802</fpage><lpage>3817</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu262</pub-id></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lambon Ralph</surname><given-names>MA</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Patterson</surname><given-names>K</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name></person-group><article-title>The neural and computational bases of semantic cognition</article-title><source>Nature Reviews Neuroscience</source><year>2017</year><volume>18</volume><fpage>42</fpage><pub-id pub-id-type="doi">10.1038/nrn.2016.150</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peelen</surname><given-names>MV</given-names></name><name><surname>Caramazza</surname><given-names>A</given-names></name></person-group><article-title>Conceptual object representations in human anterior temporal cortex</article-title><source>Journal of Neuroscience</source><year>2012</year><volume>32</volume><fpage>15728</fpage><lpage>15736</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1953-12.2012</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bruffaerts</surname><given-names>R</given-names></name><etal/></person-group><article-title>Similarity of fMRI activity patterns in left perirhinal cortex reflects semantic similarity between words</article-title><source>Journal of Neuroscience</source><year>2013</year><volume>33</volume><fpage>18597</fpage><lpage>18607</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1548-13.2013</pub-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fairhall</surname><given-names>SL</given-names></name><name><surname>Caramazza</surname><given-names>A</given-names></name></person-group><article-title>Brain regions that represent amodal conceptual knowledge</article-title><source>Journal of Neuroscience</source><year>2013</year><volume>33</volume><fpage>10552</fpage><lpage>10558</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0051-13.2013</pub-id></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Devereux</surname><given-names>BJ</given-names></name><name><surname>Clarke</surname><given-names>A</given-names></name><name><surname>Tyler</surname><given-names>LK</given-names></name></person-group><article-title>Integrated deep visual and semantic attractor neural networks predict fMRI pattern-information along the ventral object processing pathway</article-title><source>Scientific Reports</source><year>2018</year><volume>8</volume><elocation-id>10636</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-018-28865-1</pub-id></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martin</surname><given-names>CB</given-names></name><name><surname>Douglas</surname><given-names>D</given-names></name><name><surname>Newsome</surname><given-names>RN</given-names></name><name><surname>Man</surname><given-names>LLY</given-names></name><name><surname>Barense</surname><given-names>MD</given-names></name></person-group><article-title>Integrative and distinctive coding of visual and conceptual object features in the ventral visual stream</article-title><source>eLife</source><year>2018</year><volume>7</volume><elocation-id>e31873</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.31873</pub-id></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chao</surname><given-names>LL</given-names></name><name><surname>Haxby</surname><given-names>JV</given-names></name><name><surname>Martin</surname><given-names>A</given-names></name></person-group><article-title>Attribute-based neural substrates in temporal cortex for perceiving and knowing about objects</article-title><source>Nature Neuroscience</source><year>1999</year><volume>2</volume><fpage>913</fpage><lpage>919</lpage><pub-id pub-id-type="doi">10.1038/13217</pub-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haxby</surname><given-names>JV</given-names></name><etal/></person-group><article-title>Distributed and overlapping representations of faces and objects in ventral temporal cortex</article-title><source>Science</source><year>2001</year><volume>293</volume><fpage>2425</fpage><lpage>2430</lpage><pub-id pub-id-type="doi">10.1126/science.1063736</pub-id></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martin</surname><given-names>A</given-names></name></person-group><article-title>The representation of object concepts in the brain</article-title><source>Annual Review of Psychology</source><year>2007</year><volume>58</volume><fpage>25</fpage><lpage>45</lpage><pub-id pub-id-type="doi">10.1146/annurev.psych.57.102904.190143</pub-id></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name><etal/></person-group><article-title>Matching categorical object representations in inferior temporal cortex of man and monkey</article-title><source>Neuron</source><year>2008</year><volume>60</volume><fpage>1126</fpage><lpage>1141</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.10.043</pub-id></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Connolly</surname><given-names>AC</given-names></name><etal/></person-group><article-title>The representation of biological classes in the human brain</article-title><source>Journal of Neuroscience</source><year>2012</year><volume>32</volume><fpage>2608</fpage><lpage>2618</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5547-11.2012</pub-id></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sha</surname><given-names>L</given-names></name><etal/></person-group><article-title>The animacy continuum in the human ventral vision pathway</article-title><source>Journal of Cognitive Neuroscience</source><year>2015</year><volume>27</volume><fpage>665</fpage><lpage>678</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00733</pub-id></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martin</surname><given-names>A</given-names></name></person-group><article-title>GRAPES--Grounding representations in action, perception, and emotion systems: How object properties and categories are represented in the brain</article-title><source>Psychonomic Bulletin &amp; Review</source><year>2016</year><volume>23</volume><fpage>979</fpage><lpage>990</lpage><pub-id pub-id-type="doi">10.3758/s13423-015-0842-3</pub-id></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carota</surname><given-names>F</given-names></name><name><surname>Kriegeskorte</surname><given-names>N</given-names></name><name><surname>Nili</surname><given-names>H</given-names></name><name><surname>Pulvermuller</surname><given-names>F</given-names></name></person-group><article-title>Representational Similarity Mapping of Distributional Semantics in Left Inferior Frontal, Middle Temporal, and Motor Cortex</article-title><source>Cerebral Cortex</source><year>2017</year><volume>27</volume><fpage>294</fpage><lpage>309</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhw379</pub-id></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Binder</surname><given-names>JR</given-names></name><name><surname>Desai</surname><given-names>RH</given-names></name><name><surname>Graves</surname><given-names>WW</given-names></name><name><surname>Conant</surname><given-names>LL</given-names></name></person-group><article-title>Where is the semantic system? A critical review and meta-analysis of 120 functional neuroimaging studies</article-title><source>Cerebral Cortex</source><year>2009</year><volume>19</volume><fpage>2767</fpage><lpage>2796</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhp055</pub-id></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Binder</surname><given-names>JR</given-names></name><name><surname>Desai</surname><given-names>RH</given-names></name></person-group><article-title>The neurobiology of semantic memory</article-title><source>Trends in Cognitive Sciences</source><year>2011</year><volume>15</volume><fpage>527</fpage><lpage>536</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2011.10.001</pub-id></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Devereux</surname><given-names>BJ</given-names></name><name><surname>Clarke</surname><given-names>A</given-names></name><name><surname>Marouchos</surname><given-names>A</given-names></name><name><surname>Tyler</surname><given-names>LK</given-names></name></person-group><article-title>Representational Similarity Analysis Reveals Commonalities and Differences in the Semantic Processing of Words and Objects</article-title><source>Journal of Neuroscience</source><year>2013</year><volume>33</volume><fpage>18906</fpage><lpage>18916</lpage><pub-id pub-id-type="doi">10.1523/jneurosci.3809-13.2013</pub-id></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huth</surname><given-names>AG</given-names></name><name><surname>de Heer</surname><given-names>WA</given-names></name><name><surname>Griffiths</surname><given-names>TL</given-names></name><name><surname>Theunissen</surname><given-names>FE</given-names></name><name><surname>Gallant</surname><given-names>JL</given-names></name></person-group><article-title>Natural speech reveals the semantic maps that tile human cerebral cortex</article-title><source>Nature</source><year>2016</year><volume>532</volume><fpage>453</fpage><lpage>458</lpage><pub-id pub-id-type="doi">10.1038/nature17637</pub-id></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name><name><surname>Mur</surname><given-names>M</given-names></name><name><surname>Bandettini</surname><given-names>PA</given-names></name></person-group><article-title>Representational similarity analysis - connecting the branches of systems neuroscience</article-title><source>Frontiers in Systems Neuroscience</source><year>2008</year><volume>2</volume><fpage>4</fpage><pub-id pub-id-type="doi">10.3389/neuro.06.004.2008</pub-id></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Oswal</surname><given-names>U</given-names></name><name><surname>Cox</surname><given-names>CR</given-names></name><name><surname>Lambon Ralph</surname><given-names>MA</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name><name><surname>Nowak</surname><given-names>RD</given-names></name></person-group><conf-name>ICML’16 Proceedings of the 33rd International Conference on International Conference on Machine Learning</conf-name><fpage>1041</fpage><lpage>1049</lpage></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dilkina</surname><given-names>K</given-names></name><name><surname>Lambon Ralph</surname><given-names>MA</given-names></name></person-group><article-title>Conceptual structure within and between modalities</article-title><source>Frontiers in Human Neuroscience</source><year>2013</year><volume>6</volume><fpage>333</fpage><pub-id pub-id-type="doi">10.3389/fnhum.2012.00333</pub-id></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>Y</given-names></name><etal/></person-group><article-title>The ‘when’ and ‘where’ of semantic coding in the anterior temporal lobe: Temporal representational similarity analysis of electrocorticogram data</article-title><source>Cortex</source><year>2016</year><volume>79</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2016.02.015</pub-id></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rogers</surname><given-names>TT</given-names></name><etal/></person-group><article-title>Evidence for a deep, distributed and dynamic code for animacy in human ventral anterior temporal cortex</article-title><source>eLife</source><year>2021</year><volume>10</volume><elocation-id>e66276</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.66276</pub-id></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cox</surname><given-names>CR</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name></person-group><article-title>Finding Distributed Needles in Neural Haystacks</article-title><source>Journal of Neuroscience</source><year>2021</year><volume>41</volume><fpage>1019</fpage><lpage>1032</lpage><pub-id pub-id-type="doi">10.1523/jneurosci.0904-20.2020</pub-id></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frisby</surname><given-names>S</given-names></name><name><surname>Halai</surname><given-names>AD</given-names></name><name><surname>Cox</surname><given-names>CR</given-names></name><name><surname>Lambon Ralph</surname><given-names>MA</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name></person-group><article-title>Decoding semantic representations in mind and brain</article-title><pub-id pub-id-type="doi">10.31234/osf.io/6kjtf</pub-id></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stelzer</surname><given-names>J</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Turner</surname><given-names>R</given-names></name></person-group><article-title>Statistical inference and multiple testing correction in classification-based multi-voxel pattern analysis (MVPA): random permutations and cluster size control</article-title><source>NeuroImage</source><year>2013</year><volume>65</volume><fpage>69</fpage><lpage>82</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.09.063</pub-id></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McRae</surname><given-names>K</given-names></name><name><surname>de Sa</surname><given-names>VR</given-names></name><name><surname>Seidenberg</surname><given-names>MS</given-names></name></person-group><article-title>On the nature and scope of featural representations of word meaning</article-title><source>Journal of Experimental Psychology: General</source><year>1997</year><volume>126</volume><fpage>99</fpage><lpage>130</lpage><pub-id pub-id-type="doi">10.1037/0096-3445.126.2.99</pub-id></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Devlin</surname><given-names>JT</given-names></name><name><surname>Gonnerman</surname><given-names>LM</given-names></name><name><surname>Andersen</surname><given-names>ES</given-names></name><name><surname>Seidenberg</surname><given-names>MS</given-names></name></person-group><article-title>Category-Specific Semantic Deficits in Focal and Widespread Brain Damage: A Computational Account</article-title><source>Journal of Cognitive Neuroscience</source><year>1998</year><volume>10</volume><fpage>77</fpage><lpage>94</lpage><pub-id pub-id-type="doi">10.1162/089892998563798</pub-id></element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tyler</surname><given-names>LK</given-names></name><name><surname>Moss</surname><given-names>HE</given-names></name><name><surname>Durrant-Peatfield</surname><given-names>MR</given-names></name><name><surname>Levy</surname><given-names>JP</given-names></name></person-group><article-title>Conceptual Structure and the Structure of Concepts: A Distributed Account of Category-Specific Deficits</article-title><source>Brain and Language</source><year>2000</year><volume>75</volume><fpage>195</fpage><lpage>231</lpage><pub-id pub-id-type="doi">10.1006/brln.2000.2353</pub-id></element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garrard</surname><given-names>P</given-names></name><name><surname>Lambon Ralph</surname><given-names>MA</given-names></name><name><surname>Hodges</surname><given-names>JR</given-names></name><name><surname>Patterson</surname><given-names>K</given-names></name></person-group><article-title>Prototypicality, distinctiveness, and intercorrelation: Analyses of the semantic attributes of living and nonliving concepts</article-title><source>Cognitive Neuropsychology</source><year>2001</year><volume>18</volume><fpage>125</fpage><lpage>174</lpage><pub-id pub-id-type="doi">10.1080/02643290125857</pub-id></element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Devlin</surname><given-names>JT</given-names></name><etal/></person-group><article-title>Is there an anatomical basis for category-specificity? Semantic memory studies in PET and fMRI</article-title><source>Neuropsychologia</source><year>2002</year><volume>40</volume><fpage>54</fpage><lpage>75</lpage><pub-id pub-id-type="doi">10.1016/S0028-3932(01)00066-5</pub-id></element-citation></ref><ref id="R40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rogers</surname><given-names>TT</given-names></name><etal/></person-group><article-title>Anterior temporal cortex and semantic memory: reconciling findings from neuropsychology and functional imaging</article-title><source>Cognitive, Affective, &amp; Behavioral Neuroscience</source><year>2006</year><volume>6</volume><fpage>201</fpage><lpage>213</lpage><pub-id pub-id-type="doi">10.3758/CABN.6.3.201</pub-id></element-citation></ref><ref id="R41"><label>41</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rogers</surname><given-names>TT</given-names></name><name><surname>McClelland</surname><given-names>JL</given-names></name></person-group><source>Semantic cognition: A parallel distributed processing approach</source><publisher-name>MIT press</publisher-name><year>2004</year></element-citation></ref><ref id="R42"><label>42</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fernandino</surname><given-names>L</given-names></name><name><surname>Tong</surname><given-names>J-Q</given-names></name><name><surname>Conant</surname><given-names>LL</given-names></name><name><surname>Humphries</surname><given-names>CJ</given-names></name><name><surname>Binder</surname><given-names>JR</given-names></name></person-group><article-title>Decoding the information structure underlying the neural representation of concepts</article-title><source>Proceedings of the National Academy of Sciences</source><year>2022</year><volume>119</volume><elocation-id>e2108091119</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2108091119</pub-id></element-citation></ref><ref id="R43"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>L</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name></person-group><article-title>Revisiting domain-general accounts of category specificity in mind and brain</article-title><source>WIREs Cognitive Science</source><year>2014</year><volume>5</volume><fpage>327</fpage><lpage>344</lpage><pub-id pub-id-type="doi">10.1002/wcs.1283</pub-id></element-citation></ref><ref id="R44"><label>44</label><element-citation publication-type="book"><source>Matlab v. 9.5 (R2018b)</source><publisher-name>The MathWorks</publisher-name><publisher-loc>Natick, MA</publisher-loc><year>2018</year></element-citation></ref><ref id="R45"><label>45</label><element-citation publication-type="book"><source>Whole-brain Imaging with Sparse Correlations</source><publisher-name>Github</publisher-name><year>2021</year><pub-id pub-id-type="doi">10.5281/zenodo.6975270</pub-id></element-citation></ref><ref id="R46"><label>46</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Figueiredo</surname><given-names>M</given-names></name><name><surname>Nowak</surname><given-names>R</given-names></name></person-group><article-title>Artificial Intelligence and Statistics</article-title><fpage>930</fpage><lpage>938</lpage></element-citation></ref><ref id="R47"><label>47</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>L</given-names></name><name><surname>Jamieson</surname><given-names>K</given-names></name><name><surname>DeSalvo</surname><given-names>G</given-names></name><name><surname>Rostamizadeh</surname><given-names>A</given-names></name><name><surname>Talwalkar</surname><given-names>A</given-names></name></person-group><article-title>Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization</article-title><source>Journal of Machine Learning Research</source><year>2018</year><volume>18</volume><fpage>1</fpage><lpage>52</lpage></element-citation></ref><ref id="R48"><label>48</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>Y</given-names></name><name><surname>Vales</surname><given-names>MI</given-names></name><name><surname>Wang</surname><given-names>A</given-names></name><name><surname>Zhang</surname><given-names>Z</given-names></name></person-group><article-title>Systematic bias of correlation coefficient may explain negative accuracy of genomic prediction</article-title><source>Briefings in Bioinformatics</source><year>2017</year><volume>18</volume><fpage>1093</fpage><lpage>1093</lpage><pub-id pub-id-type="doi">10.1093/bib/bbx133</pub-id></element-citation></ref><ref id="R49"><label>49</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Edgington</surname><given-names>ES</given-names></name></person-group><chapter-title>Randomization tests [electronic resource]</chapter-title><source>rev and expanded edn</source><publisher-name>M. Dekker</publisher-name><year>1995</year><edition>3rd</edition></element-citation></ref><ref id="R50"><label>50</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Phipson</surname><given-names>B</given-names></name><name><surname>Smyth</surname><given-names>GK</given-names></name></person-group><article-title>Permutation P-values Should Never Be Zero: Calculating Exact P-values When Permutations Are Randomly Drawn</article-title><source>Statistical Applications in Genetics and Molecular Biology</source><year>2010</year><volume>9</volume><pub-id pub-id-type="doi">10.2202/1544-6115.1585</pub-id></element-citation></ref><ref id="R51"><label>51</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alberton</surname><given-names>BAV</given-names></name><name><surname>Nichols</surname><given-names>TE</given-names></name><name><surname>Gamba</surname><given-names>HR</given-names></name><name><surname>Winkler</surname><given-names>AM</given-names></name></person-group><article-title>Multiple testing correction over contrasts for brain imaging</article-title><source>NeuroImage</source><year>2020</year><volume>216</volume><elocation-id>116760</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.116760</pub-id></element-citation></ref><ref id="R52"><label>52</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Westfall</surname><given-names>PH</given-names></name><name><surname>Young</surname><given-names>SS</given-names></name><name><surname>Wright</surname><given-names>SP</given-names></name></person-group><article-title>On Adjusting P-Values for Multiplicity</article-title><source>Biometrics</source><year>1993</year><volume>49</volume><fpage>941</fpage><lpage>945</lpage><pub-id pub-id-type="doi">10.2307/2532216</pub-id></element-citation></ref><ref id="R53"><label>53</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yuan</surname><given-names>M</given-names></name><name><surname>Lin</surname><given-names>Y</given-names></name></person-group><article-title>Model selection and estimation in regression with grouped variables</article-title><source>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</source><year>2006</year><volume>68</volume><fpage>49</fpage><lpage>67</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9868.2005.00532.x</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><p><bold>Coordinates of the 100 stimuli</bold> in the three-dimensional singular-value-decomposition of the of the semantic similarity matrix. Colors show category membership within each domain. Component 1 separates animate from inanimate items, but also separates animate sub-categories. Component 2 largely separates animate sub-categories, while component 3 largely separates inanimate sub-categories.</p></caption><graphic xlink:href="EMS156328-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Simulation results.</title><p>A. Each plot illustrates different ways that a neural response might encode some aspects of a target RSM, schematized in the rightmost plot (“All”). Vertical bars show the hypothesized responses of neural features to various animate and inanimate stimuli (red more active; blue less active; gray random) while the squares show the neural similarity matrices that would then result (red high similarity, blue low). All conditions encode some components of the full RSM and so should be detected by a multivariate method seeking semantic structure. B. Curves showing the expected results of standard RSA when used to decode real semantic structure from the Dilkina norms under different hypotheses about the neural code and increasing amounts of measurement noise. Dots show the mean correlation while ribbons show the 95% confidence interval. The approach can yield robust results when the neural signal is discrete and/or one-dimensional, even under substantial noise, and can yield weak or null results when the neural signal faithfully encodes weaker components of the RSM, even under low-noise conditions. C. Results of RSL applied to the same simulated data, showing the correlation between true and predicted coordinates for held-out items on each latent component of the target matrix (columns), for the five different simulation conditions (rows), and computed across all items (black lines), animate items (red), or inanimate items (green). RSL shows a positive result in each case, identifies which components of the matrix are present in the neural code, and reveals reliable within-domain decoding only when the neural code expresses continuous similarity structure.</p></caption><graphic xlink:href="EMS156328-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Representational similarity learning.</title><p>A. To generate the target structure for decoding, semantic feature vectors for each of <italic>n</italic> items are mean-centered and converted to a cosine similarity matrix <italic><bold>S</bold><sub>n×n</sub></italic> of approximate rank <italic>r</italic>. This is decomposed into matrix <italic><bold>U</bold></italic><sub><italic>n</italic>×<italic>r</italic></sub> containing <italic>r</italic> orthogonal singular vectors and diagonal matrix <italic><bold>D</bold><sub>r×r</sub></italic> containing singular values for each vector. The product <inline-formula><mml:math id="M3"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mi mathvariant="bold">U</mml:mi><mml:msqrt><mml:mi mathvariant="bold">D</mml:mi></mml:msqrt></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> is an <italic>nxr</italic> matrix whose columns contain <italic>r</italic> root-weighted singular vectors that are the target of the decoding model. Note that the product of this matrix with its transpose provides an estimate of the original matrix <italic><bold>S</bold></italic><sub><italic>n</italic>×<italic>n</italic></sub>. B. Neural responses in a picture-naming task are recorded for each stimulus as intra-cranial voltage potentials collected at 1000 Hz over electrodes implanted in vATL. Data are concatenated across electrodes to create a single <italic>m</italic>-dimensional “neural feature vector” for each stimulus, where <italic>m</italic> is the total number of electrodes times the size of the decoding window in milliseconds. All such vectors are compiled into a neural feature matrix <italic><bold>X</bold><sub>n×m</sub></italic> which contains the predictors for the decoding model. C. The target structure <inline-formula><mml:math id="M4"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mi>U</mml:mi><mml:msqrt><mml:mi>D</mml:mi></mml:msqrt></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> is then modeled as the product of the neural feature matrix <italic><bold>X</bold></italic> and a decoding matrix of regression coefficients <italic><bold>β</bold></italic> whose values are chosen via gradient descent to minimize prediction error plus the regularization penalty <italic>H</italic>(<italic><bold>β</bold></italic>) scaled by the weighting parameter <italic>α</italic>. D. Definition of the group-ordered-weighted LASSO (grOWL) regularization function and illustration of the structure it promotes in the decoding matrix.</p></caption><graphic xlink:href="EMS156328-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>ECoG decoding results.</title><p>Correlation between true and predicted coordinates along each latent dimension (columns) for models fit to all items (green), animate items only (orange), or inanimate items only (blue), and regularized with grOWL or LASSO. Bars show standard errors. Colored bars / filled circles indicate reliable decoding with Westfall-Young FWER &lt; .05 for all points in a panel. Top row: grOWL and LASSO model performance when trained on the full 1000-ms trial epoch. Middle row: grOWL model performance within opening windows. Bottom row: LASSO model performance within opening windows.</p></caption><graphic xlink:href="EMS156328-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><p>Correlation between predicted semantic similarities and the best-possible similarities reconstructed from the first three singular vectors/values of the true matrix. Considering all pairwise similarities (left panel black line), predictions from RSL show much stronger correlations with the true structure than observed in a previous study using searchlight RSA (left panel gray line; see <sup><xref ref-type="bibr" rid="R30">30</xref></sup>). Moreover, where the prior study found no evidence for within-domain semantic structure in these data, decoding models fit with RSL reliably predict semantic similarities both within (red lines) and between (green lines) conceptual domains, for both animate (middle panel) and inanimate (right panel) stimuli, from about 100 − 200 ms post-stimulus onward.</p></caption><graphic xlink:href="EMS156328-f005"/></fig></floats-group></article>