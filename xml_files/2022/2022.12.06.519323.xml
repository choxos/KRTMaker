<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS158246</article-id><article-id pub-id-type="doi">10.1101/2022.12.06.519323</article-id><article-id pub-id-type="archive">PPR580857</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Representations of tactile object location in the retrosplenial cortex</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Lande</surname><given-names>Andreas Sigstad</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Vervaeke</surname><given-names>Koen</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="corresp" rid="CR1">✉</xref></contrib></contrib-group><aff id="A1"><label>1</label>Department of Physiology; Institute of Basic Medical Sciences, University of Oslo, Norway</aff><author-notes><corresp id="CR1"><label>✉</label>Correspondence: <email>koenv@medisin.uio.no</email></corresp></author-notes><pub-date pub-type="nihms-submitted"><day>08</day><month>12</month><year>2022</year></pub-date><pub-date pub-type="preprint"><day>06</day><month>12</month><year>2022</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Little is known about how animals use tactile sensation to detect important objects and remember their location in a world-based coordinate system. Here, we hypothesized that retrosplenial cortex (RSC), a key network for contextual memory and spatial navigation, represents the location of objects based on tactile sensation. We studied mice that palpate objects with their whiskers while running on a treadmill in a tactile virtual reality in darkness. Using two-photon Ca<sup>2+</sup> imaging, we discovered a population of neurons in agranular RSC that signal the location of tactile objects. Tactile object location responses do not simply reflect the sensory stimulus. Instead, they are highly task- and context-dependent and often predict the upcoming object before it is within reach. In addition, most tactile object location neurons also maintain a memory trace of the object’s location. These data show that RSC encodes the location and arrangement of tactile objects in a spatial reference frame.</p></abstract><kwd-group><kwd>Retrosplenial cortex</kwd><kwd>tactile sensation</kwd><kwd>spatial navigation</kwd><kwd>whiskers</kwd><kwd>virtual reality</kwd><kwd>object location</kwd><kwd>contextual memory</kwd><kwd>place cells</kwd><kwd>spatial landmarks</kwd><kwd>two-photon microscopy</kwd></kwd-group></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">Humans and animals effortlessly remember the location of important objects in their surroundings. To locate objects, humans mostly rely on their visual sense1. In addition, tactile interaction with objects contributes to remembering their location (<xref ref-type="bibr" rid="R28">Gallace and Spence, 2014</xref>), and for nocturnal animals such as rodents, tactile exploration is essential. However, how the brain encodes the location of objects based on tactile input remains unknown.</p><p id="P3">Functional imaging experiments of sighted and blind human subjects, who explore and memorize spatial layouts using only tactile input from the fingers (<xref ref-type="bibr" rid="R84">Wolbers et al., 2011</xref>; <xref ref-type="bibr" rid="R60">Ottink et al., 2021</xref>), show prominent activity in two brain areas: the parahippocampal- and the retrosplenial cortex (RSC)(<xref ref-type="bibr" rid="R84">Wolbers et al., 2011</xref>). The latter area may be surprising because RSC is best known for encoding visual information. Indeed, because of its prominent anatomical connections with the visual system and hippocampus (<xref ref-type="bibr" rid="R77">Sugar et al., 2011</xref>; <xref ref-type="bibr" rid="R85">Wyss and Groen, 1992</xref>; <xref ref-type="bibr" rid="R34">Groen and Wyss, 1992</xref>), RSC plays a crucial role in contextual memory and navigation when visual landmarks are available (<xref ref-type="bibr" rid="R79">Vann et al., 2009</xref>; <xref ref-type="bibr" rid="R16">Claessen and Ham, 2017</xref>; <xref ref-type="bibr" rid="R45">Maguire, 2001</xref>; <xref ref-type="bibr" rid="R14">Chen et al., 1994</xref>; <xref ref-type="bibr" rid="R3">Alexander and Nitz, 2015</xref>; <xref ref-type="bibr" rid="R25">Fischer et al., 2020</xref>; <xref ref-type="bibr" rid="R46">Mao et al., 2017</xref>; <xref ref-type="bibr" rid="R80">Vedder et al., 2016</xref>; <xref ref-type="bibr" rid="R20">Czajkowski et al., 2014</xref>; <xref ref-type="bibr" rid="R19">Cowansage et al., 2014</xref>; <xref ref-type="bibr" rid="R6">Bar, 2004</xref>; <xref ref-type="bibr" rid="R69">Powell et al., 2020</xref>; <xref ref-type="bibr" rid="R47">Mao et al., 2018</xref>; <xref ref-type="bibr" rid="R70">Rice et al., 1986</xref>). The experiments in humans suggest that RSC also has access to tactile information and may form a sensory modality-independent representation of space (<xref ref-type="bibr" rid="R84">Wolbers et al., 2011</xref>). However, testing this idea requires using a non-human animal model, such as rodents, to enable cellular-resolution circuit analysis during well-controlled behaviors.</p><p id="P4">To explore tactile objects, rodents use their facial whiskers - specialized hairs extending from follicles packed with nerve endings (<xref ref-type="bibr" rid="R70">Rice et al., 1986</xref>; <xref ref-type="bibr" rid="R61">O’Connor et al., 2021</xref>). Decades of research have revealed how the whisker system encodes the location of objects in the rodents’ peri-personal space in a head-centred coordinate system (<xref ref-type="bibr" rid="R24">Diamond et al., 2008</xref>; <xref ref-type="bibr" rid="R64">Petersen, 2007</xref>; <xref ref-type="bibr" rid="R43">Knutsen and Ahissar, 2009</xref>; <xref ref-type="bibr" rid="R66">Pluta et al., 2017</xref>; <xref ref-type="bibr" rid="R62">Pammer et al., 2013</xref>; <xref ref-type="bibr" rid="R56">O’Connor et al., 2010</xref>; <xref ref-type="bibr" rid="R15">Cheung et al., 2020</xref>). However, animals also need to remember the location of tactile objects in an extended space, in a world-based coordinate system. To date, no studies have examined how or where in the brain this representation is generated. Tactile information is likely routed to the brain’s spatial network and integrated with the spatial code (<xref ref-type="bibr" rid="R31">Gener et al., 2013</xref>; <xref ref-type="bibr" rid="R72">Save et al., 1998</xref>; <xref ref-type="bibr" rid="R58">O’Keefe and Dostrovsky, 1971</xref>). In support of this, whisker-related neural activity is not restricted to somatosensory areas but can also be observed in spatially modulated brain areas (<xref ref-type="bibr" rid="R53">Mohan et al., 2019</xref>; <xref ref-type="bibr" rid="R59">Olcese et al., 2013</xref>; <xref ref-type="bibr" rid="R29">Gallero-Salas et al., 2021</xref>; <xref ref-type="bibr" rid="R54">Mohan et al., 2018b</xref>,<xref ref-type="bibr" rid="R52">a</xref>; <xref ref-type="bibr" rid="R7">Bellistri et al., 2013</xref>; <xref ref-type="bibr" rid="R63">Pereira et al., 2007</xref>; <xref ref-type="bibr" rid="R41">Itskov et al., 2011</xref>; <xref ref-type="bibr" rid="R48">Merre et al., 2018</xref>). However, previous investigations were largely restricted to measuring neural responses to whisker stimuli in immobile or anaesthetized mice. Therefore, it remains to be tested how tactile information is processed during spatial navigation, and which circuits encode the location of tactile objects.</p><p id="P5">Here, we designed a task whereby mice run on a treadmill through a whisker-based tactile virtual reality system (inspired by (<xref ref-type="bibr" rid="R75">Sofroniew et al., 2014</xref>; <xref ref-type="bibr" rid="R5">Ayaz et al., 2019</xref>)). We found that neurons in agranular RSC represent the spatial location where the whiskers contact an object. These tactile object location responses show several features compatible with the hypothesis that RSC constructs a map of tactile space. Tactile object location responses did not simply reflect the sensory stimulus. Instead, they were highly task- and visual context-dependent. Moreover, in well-trained mice, a subset of tactile object location neurons also predicts of the upcoming object, and most object locations cells maintain their spatial tuning when the object is omitted. These data indicate that RSC encodes the location of tactile objects in a world-based spatial reference frame.</p></sec><sec id="S2" sec-type="results"><title>Results</title><sec id="S3"><title>Responses to tactile objects during a spatial task in darkness</title><p id="P6">We trained head-fixed mice to run laps on a treadmill in darkness to find the location of a water reward. At two positions along the track, a motorised cue, controlled in a closed loop by running speed, brushed across the whiskers, simulating the sensation of running past an object (<xref ref-type="fig" rid="F1">Figure 1A</xref>, see <xref ref-type="sec" rid="S9">Methods</xref>). Our goal was to develop a spatial behavioural task whereby we could change the tactile stimuli flexibly in a lap-by-lap manner and determine the precise timing of contacts between the whiskers and the object (<xref ref-type="fig" rid="F1">Figure 1B</xref>. We performed these experiments in complete darkness to avoid visual responses to the moving object and therefore we tracked the animals’ behaviour using infrared light (940 nm) (<xref ref-type="bibr" rid="R18">Couto et al., 2019</xref>; <xref ref-type="bibr" rid="R55">Nikbakht and Diamond, 2021</xref>). Well-trained mice ran at a relatively constant speed, uninterrupted by the tactile stimulus, but slowed down to lick for water at the correct location, indicating they learned the rewarded position (<xref ref-type="fig" rid="F1">Figure 1C</xref>, <xref ref-type="supplementary-material" rid="SD1">Video S1</xref>, data from 8 mice, 10 sessions).</p><p id="P7">To measure neuronal activity in layer 2/3 of the agranular RSC (Brodmann area 30), contralateral to the stimulated whiskers, we performed two-photon Ca<sup>2+</sup> imaging using mice expressing the Ca<sup>2+</sup> indicator GCaMP6s in excitatory neurons (Thy1-GCaMP6s, 8 mice, 10 Fields of View, FOV) (<xref ref-type="bibr" rid="R21">Dana et al., 2014</xref>)(<xref ref-type="fig" rid="F1">Figure 1D</xref>, see <xref ref-type="sec" rid="S9">Methods</xref>). We deconvolved the fluorescence signals to infer spiking activity (<xref ref-type="bibr" rid="R33">Giovannucci et al., 2019</xref>). When we analyzed all neurons with stable firing fields in specific positions along the track, we observed two types of activity. Neurons with a single firing field that could be located anywhere along the track, which we refer to as position-tuned cells (<xref ref-type="bibr" rid="R46">Mao et al., 2017</xref>), and neurons with two firing fields tightly coupled to location of the tactile objects which we refer to as object location cells (34.9% position-tuned cells, 11.9% object location cells, out of 3120 neurons in total, <xref ref-type="fig" rid="F1">Figure 1E-G</xref>). The response amplitude did not differ much between these groups, but the tuning width of object location cells was slightly narrower compared to position-tuned cells (<xref ref-type="fig" rid="F1">Figure 1H</xref>). In mice trained without whiskers, the percentage of object location cells was greatly reduced and was similar to the percentage observed by chance in mice that had whiskers but were trained without tactile objects (<xref ref-type="fig" rid="F1">Figure 1I</xref>, “Whiskers”: 12.1 ± 2 %, 8 mice, 10 FOVs; “No whiskers” 2.9 ± 0.6 %, 3 mice, 6 FOVs; “No tactile object”; 2.7 ± 0.4 %, 2 mice, 3 FOVs; mean ± SEM and hereafter, see <xref ref-type="sec" rid="S9">Methods</xref>. We also considered whether whisker stimuli could evoke eye movements(<xref ref-type="bibr" rid="R86">Zahler et al., 2021</xref>) and whether these could trigger neuronal responses in RSC (<xref ref-type="bibr" rid="R73">Sikes et al., 1988</xref>)(<xref ref-type="supplementary-material" rid="SD1">Figure S1A-C</xref>, 3 mice, 3 FOVs). Tracking the pupils showed that tactile stimuli did not evoke any eye movements along the yaw or pitch rotation axis. However, we noticed that in some laps the mouse makes a minute eyeblink following a tactile stimulus (<xref ref-type="supplementary-material" rid="SD1">Figure S1D</xref>). We tested whether the activity of object location neurons was significantly correlated with these eyeblinks. However, this was the case for only 4.4 % of these cells showing that object location tuning does not depend on eye blinks (<xref ref-type="supplementary-material" rid="SD1">Figure S1E</xref>). Finally, when we visualized the spatial organization of object location neurons, we found that these were spatially intermingled with position-tuned neurons in a salt-and-pepper fashion suggesting that RSC may integrate object location and animal position signals (<xref ref-type="fig" rid="F1">Figure 1J</xref>). In summary, these data demonstrate that a population of neurons encoding the location of tactile objects co-exist with position-tuned cells in agranular RSC.</p></sec><sec id="S4"><title>Tactile object location representations are task specific</title><p id="P8">Neurons in hippocampus and association cortices such as RSC encode not only the location of the animal but also what the animal is doing. Such a conjunctive code can disambiguate sensory stimuli that happened in the same environment but when the animal was engaged in different behaviors (<xref ref-type="bibr" rid="R25">Fischer et al., 2020</xref>; <xref ref-type="bibr" rid="R65">Pho et al., 2019</xref>; <xref ref-type="bibr" rid="R26">Franco and Goard, 2021</xref>; <xref ref-type="bibr" rid="R42">Kentros et al., 2004</xref>; <xref ref-type="bibr" rid="R36">Harvey et al., 2012</xref>; <xref ref-type="bibr" rid="R49">Miller et al., 2019</xref>). To test whether object location neurons in RSC are task-specific, we measured how the same neurons respond to tactile stimuli under three different task conditions. First, mice started the session performing the tactile virtual reality task (“goal oriented”) (<xref ref-type="fig" rid="F2">Figure 2A</xref>). Next, we immobilized the mouse by clamping the running wheel and we provided playback tactile stimuli (“passive stimulus”, see <xref ref-type="sec" rid="S9">Methods</xref>). Finally, we unclamped the running wheel to let mice run freely, but without water rewards, and we provided tactile objects in random locations along the track (“unengaged”).</p><p id="P9">How neurons responded to tactile objects was greatly task-dependent (<xref ref-type="fig" rid="F2">Figure 2B</xref>). Of all object location neurons classified in the goal-oriented task (124 out of 1271 cells), only 16.1 2.4 % responded to passive stimuli, and 26.6 ± 5.4 % responded when the mouse was unengaged (<xref ref-type="fig" rid="F2">Figure 2B, C</xref>, 3 mice, 4 FOVs). Overall, the response amplitude was only slightly different between conditions. Yet, in the goal-oriented task, object responses were significantly larger than responses under the other two task conditions (<xref ref-type="fig" rid="F2">Figure 2D</xref>). Notably, the percentage of responsive neurons was similar under each task condition (<xref ref-type="fig" rid="F2">Figure 2E</xref>). In total, 20 % of all neurons responded to tactile objects in at least one condition, showing that a large fraction of RSC neurons can respond to tactile objects but only do so under specific task conditions.</p></sec><sec id="S5"><title>Responses to tactile objects are visual context dependent</title><p id="P10">RSC may encode an abstract representation of a tactile object within its environment rather than of the tactile object per se (<xref ref-type="bibr" rid="R6">Bar, 2004</xref>; <xref ref-type="bibr" rid="R88">Zhao et al., 2020</xref>; <xref ref-type="bibr" rid="R27">Fyhn et al., 2007</xref>). Because of RSC’s well-established role in processing visual information, we hypothesized that tactile responses in RSC may be modulated by visual context. To test this, we presented tactile objects in different levels of ambient luminance such that the mouse can both see and feel the object. A session was composed of three blocks of laps (<xref ref-type="fig" rid="F3">Figure 3A</xref>). The first block of laps occurred in darkness, followed by two blocks of laps in two different levels of ambient luminance.</p><p id="P11">Neuronal responses were highly visual-context dependent (<xref ref-type="fig" rid="F3">Figure 3B</xref>). Some neurons responded to tactile objects only in complete darkness, others responded only to congruent visuo-tactile objects, and a minority responded in both darkness and light. Overall, the number of object-responsive neurons almost doubled between dark and bright ambient light (<xref ref-type="fig" rid="F3">Figure 3C</xref>, 1510 neurons, 5 mice, 5 sessions), likely because many RSC neurons are sensitive to the visual features of the moving object. In contrast, the percentage of position-tuned cells did not increase significantly. When we analyzed the tuning properties of object location neurons and position-tuned neurons under different luminance conditions, we observed notable changes (<xref ref-type="fig" rid="F3">Figure 3D</xref>). Most classified cells lost their tuning in ambient light. However, in light, new object-responsive and position-tuned cells emerged. Moreover, object-responsive neurons and position-tuned neurons could switch identities. Overall, only 25.4 % of object location neurons classified in darkness maintained their tuning in light (<xref ref-type="fig" rid="F3">Figure 3E</xref>). Similarly, only 27.4 % of position-tuned neurons classified in darkness maintained their tuning in light. Assessing a Venn diagram of responses under different light conditions showed that neuronal responses to the moving object were highly visual context-dependent, with most neurons responding in bright ambient light (<xref ref-type="fig" rid="F3">Figure 3F</xref>). These data show that both tactile object location neurons and position-tuned neurons in RSC are highly sensitive to changes in visual context.</p></sec><sec id="S6"><title>RSC develops predictive responses to upcoming tactile objects</title><p id="P12">When we analyzed the onset time of tactile responses in darkness, we observed that a fraction of cells started to respond before the object was in reach of the whiskers (<xref ref-type="fig" rid="F4">Figure 4A</xref>, reproduced from <xref ref-type="fig" rid="F1">Figure 1F</xref>, and examples in <xref ref-type="fig" rid="F4">Figure 4B</xref>, 8 mice, 10 FOVs, 370 tactile cells out of 3120 cells). We determined the onset times of neuronal responses in relation to the time when the whiskers touch the object based on high-speed videography. We also verified that these early responses were not due to the sound of the motors moving the object (see <xref ref-type="sec" rid="S9">Methods</xref>). Predictive neuronal responses could start up to 50 cm before the whiskers touch the object (<xref ref-type="fig" rid="F4">Figure 4C</xref>). Converted to time, based on the running speed of the animal, these cells could anticipate the object by up to 1 second (<xref ref-type="fig" rid="F4">Figure 4C</xref>). Altogether, 17 % of all object location cells predicted the tactile object (<xref ref-type="fig" rid="F4">Figure 4D</xref>).</p></sec><sec id="S7"><title>Memory traces of tactile object location in RSC</title><p id="P13">Do tactile objects leave a memory trace in RSC? To test this, we randomly omitted the first tactile object in a subset of laps (<xref ref-type="fig" rid="F5">Figure 5A</xref>, 8 mice, 10 FOVs). After mice ran a minimum of 50 laps, we started omitting the first tactile object randomly in 50% of laps. For visualization purposes, we sorted the laps according to whether the tactile object was present or omitted (<xref ref-type="fig" rid="F5">Figure 5A</xref>). First, we verified whether omitting a tactile object would change the mouse’s running speed or its estimate of the reward location by analyzing the lick rate, but this was not the case (<xref ref-type="supplementary-material" rid="SD1">Figure S2A, B</xref>). We found examples of object location cells that lost tuning when the object was omitted (<xref ref-type="fig" rid="F5">Figure 5B</xref>, “non-trace” cell). However, most object location cells responded despite the lacking object (<xref ref-type="fig" rid="F5">Figure 5B</xref>, “trace” cell). When we categorized all object location cells into non-trace and trace cells, we noticed that many trace neurons were active before the tactile object (<xref ref-type="fig" rid="F5">Figure 5C</xref>, bottom traces), indicating that many of the trace cells were also predictive cells (see <xref ref-type="fig" rid="F4">Figure 4</xref>). Indeed, since predictive cells are active before the object, they are agnostic about whether the object will be present or not. Of the object location cells that were classified as predictive neurons, 81% were also classified as trace cells, while only 51% of non-predictive neurons were classified as trace cells (<xref ref-type="fig" rid="F5">Figure 5D</xref>). These data show that most tactile object location cells in RSC maintain a memory trace of where tactile events occurred.</p><p id="P14">Finally, we tested whether tactile objects influence how well the mouse’s position can be decoded based on the activity of position-tuned neurons. Using Bayesian decoding, we quantified the decoding error as a function of position along the track. This showed that the presence of tactile objects reduced the decoding error (<xref ref-type="fig" rid="F5">Figure 5E</xref>). Further analysis showed that, following contact with an object, there are more position-tuned cells (<xref ref-type="fig" rid="F5">Figure 5F, G</xref>) and the width of the tuning curve of position-tuned cells is significantly smaller (<xref ref-type="fig" rid="F5">Figure 5H</xref>). The combination of these two factors likely decreases the decoding error of spatial position. These data show that tactile events are not only encoded in the activity of object location cells, but also affect the activity of position-tuned neurons and improve the decoding of spatial position.</p></sec></sec><sec id="S8" sec-type="discussion"><title>Discussion</title><p id="P15">How do animals use tactile information to detect important objects and remember their location? Here, we asked whether tactile objects are represented in the brain’s spatial network and integrated with the spatial code. We found that neurons in RSC respond to whisker stimulation associated with tactile objects and show several features resembling the properties of a map of the tactile environment. Neuronal responses are highly task and context-dependent, and in well-trained mice, neuronal activity is predictive of upcoming tactile objects. Moreover, neuronal activity persists when tactile objects are removed, indicating that RSC maintains a memory trace of tactile object location.</p><p id="P16">We found that neurons in RSC encode tactile object location in a task-dependent (<xref ref-type="fig" rid="F2">Figure 2</xref>) and visual context-specific manner (<xref ref-type="fig" rid="F3">Figure 3</xref>). These findings support a framework wherein RSC encodes abstract representations of tactile objects within an environment rather than of tactile objects per se. Several theories propose that the binding of objects to locations occurs in the hippocampus (<xref ref-type="bibr" rid="R17">Connor and Knierim, 2017</xref>). However, evidence shows that this may already occur upstream of the hippocampus, in the peri- and postrhinal cortex and entorhinal cortices (reviewed in <xref ref-type="bibr" rid="R17">Connor and Knierim, 2017</xref>). There is also evidence that this may happen in the retrosplenial cortex, at least for visual objects (<xref ref-type="bibr" rid="R1">Aggleton and Nelson, 2020</xref>; <xref ref-type="bibr" rid="R76">Stacho and Manahan-Vaughan, 2022</xref>; <xref ref-type="bibr" rid="R50">Miller et al., 2014</xref>; <xref ref-type="bibr" rid="R51">Mitchell et al., 2018</xref>; <xref ref-type="bibr" rid="R44">Landeta et al., 2020</xref>; <xref ref-type="bibr" rid="R13">Carstensen et al., 2021</xref>). Comparing our results to previous investigations is difficult because these were performed in freely moving rodents that explore objects in an arena(<xref ref-type="bibr" rid="R81">Weible et al., 2012</xref>; <xref ref-type="bibr" rid="R23">Deshmukh and Knierim, 2013</xref>, <xref ref-type="bibr" rid="R22">2011</xref>; <xref ref-type="bibr" rid="R39">Høydal et al., 2019</xref>; <xref ref-type="bibr" rid="R78">Tsao et al., 2013</xref>; <xref ref-type="bibr" rid="R71">Rivard et al., 2004</xref>). There, the animal can inspect and interact with the object using both visual and somatosensory information, which likely includes a mixture of input from the whiskers, limbs, and paws. In such experiments, object-responsive cells may also encode aspects of behaviour related to object exploration and not necessarily object location. Therefore, isolating the contribution of individual sensory modalities requires well-controlled behavioural experiments. Following such an approach, a recent study used head-fixed mice and found that a fraction of hippocampal CA1 cells respond to visuotactile cues attached to a treadmill (<xref ref-type="bibr" rid="R30">Geiller et al., 2017</xref>).</p><p id="P17">These data differed substantially from our RSC data. Hippocampal CA1 responses to cues were not modulated by contextual changes and removing the cues did not cause a lasting memory trace of the cue location. They also found a subset of cells that were active up to 13 cm before the cues, but since experiments were performed in light, they could not exclude that the mouse sees the cues approaching before they are in reach. These findings could indicate key differences between the hippocampus and RSC. Alternatively, the differences may also depend on the task design, as they did not isolate contribution of different sensory modalities and manipulated the contextual cues differently. Therefore, future work should explore how different sensory cues are encoded in the different areas of the brain’s spatial network under standardized behavior conditions.</p><p id="P18">How do whisker signals reach RSC? There are several possibilities. First, RSC may receive indirect whisker input from the barrel cortex via the posterior parietal cortex (PPC), which forms dense connections with the anterior portion of RSC (<xref ref-type="bibr" rid="R53">Mohan et al., 2019</xref>; <xref ref-type="bibr" rid="R48">Merre et al., 2018</xref>; <xref ref-type="bibr" rid="R11">Bosman et al., 2011</xref>). Second, RSC may receive whisker signals via the same pathways as the hippocampus. Both RSC and the hippocampus receive entorhinal cortex input, although these projections are much sparser in RSC (<xref ref-type="bibr" rid="R77">Sugar et al., 2011</xref>; <xref ref-type="bibr" rid="R83">Witter et al., 2017</xref>). The entorhinal cortex may receive its tactile information from the barrel cortex via the perirhinal cortex, a key brain area for object recognition (<xref ref-type="bibr" rid="R17">Connor and Knierim, 2017</xref>; <xref ref-type="bibr" rid="R40">Ibarra-Casta<italic>ñ</italic>eda et al., 2022</xref>; <xref ref-type="bibr" rid="R4">Aronoff et al., 2010</xref>). A third possibility is that RSC receives whisker information from the vibrissal motor cortex (<xref ref-type="bibr" rid="R74">Smith and Alloway, 2010</xref>) via the claustrum (<xref ref-type="bibr" rid="R12">Brennan et al., 2021</xref>). And, finally, there is also an understudied pathway that conveys whisker signals via the spinal trigeminal nucleus to the laterodorsal nucleus of the thalamus (<xref ref-type="bibr" rid="R11">Bosman et al., 2011</xref>; <xref ref-type="bibr" rid="R8">Bezdudnaya and Keller, 2008</xref>), which in turn, projects to the superficial layers of the agranular RSC (<xref ref-type="bibr" rid="R34">Groen and Wyss, 1992</xref>). Of the pathways discussed here, the latter involves the fewest synaptic connections from the mechanoreceptors of the whiskers to RSC.</p><p id="P19">We found that most object location neurons form a memory trace (<xref ref-type="fig" rid="F5">Figure 5</xref>), and a fraction of these were predictive of upcoming tactile input, in some cases up to 50 cm before the tactile object (<xref ref-type="fig" rid="F4">Figure 4C</xref>). These features resemble some of the properties of recently discovered cells that encode a vectorial signal of the distance and direction between the animal and nearby objects or borders in the environment (<xref ref-type="bibr" rid="R9">Bicanski and Burgess, 2020</xref>; <xref ref-type="bibr" rid="R2">Alexander et al., 2020</xref>; <xref ref-type="bibr" rid="R82">Wijngaarden et al., 2020</xref>). Notably, both vectorial and non-vectoral cells that code for objects and borders can also maintain their response when the object or border is removed, leaving a memory trace of their location (<xref ref-type="bibr" rid="R81">Weible et al., 2012</xref>; <xref ref-type="bibr" rid="R22">Deshmukh and Knierim, 2011</xref>, <xref ref-type="bibr" rid="R23">2013</xref>; <xref ref-type="bibr" rid="R78">Tsao et al., 2013</xref>; <xref ref-type="bibr" rid="R57">O’Keefe, 1976</xref>; <xref ref-type="bibr" rid="R68">Poulter et al., 2021</xref>). However, because the angle between the animal and object location cannot be assessed when animals run on a linear track, it remains to be determined whether the predictive tactile neurons reported here are vector coding cells.</p><p id="P20">Interestingly, the neuronal responses that we separated into position-tuned and object location-tuned cells share many similarities. They both lack temporal precision (<xref ref-type="fig" rid="F1">Figure 1E</xref>), they have a similar amplitude and tuning width (<xref ref-type="fig" rid="F1">Figure 1H</xref>), are spatially intermingled (<xref ref-type="fig" rid="F1">Figure 1J</xref>), have a similar sensitivity to visual context (<xref ref-type="fig" rid="F3">Figure 3D, E</xref>) and can even switch identities (<xref ref-type="fig" rid="F3">Figure 3D</xref>). Therefore, these similarities may be based on a common plasticity mechanism. We propose that a prime candidate could be the behavioral time-scale plasticity rule (BTSP) that was recently discovered in CA1 pyramidal neurons (<xref ref-type="bibr" rid="R10">Bittner et al., 2017</xref>; <xref ref-type="bibr" rid="R88">Zhao et al., 2020</xref>). BTSP potentiates only those presynaptic inputs active in a second-long time window around a postsynaptic plateau potential. The essential difference between object location-and position tuned cells could be that they were induced by a plateau potential driven by tactile input and position input, respectively. Notably, using a similar task, we recently reported a preponderance of position-tuned long-range input to RSC from numerous sources (<xref ref-type="bibr" rid="R32">Gianatti et al., 2022</xref>). Thus, both tactile-driven and position-driven plateau potentials will lead to a potentiation of position-tuned input. This hypothesis could explain why trace object location cells respond in the absence of an object (<xref ref-type="fig" rid="F5">Figure 5C</xref>), and this could also explain why some cells start to respond up to one second before the tactile object is within reach (<xref ref-type="fig" rid="F4">Figure 4</xref>). Future experiments will have to verify these hypotheses by testing whether RSC neurons can produce plateau potentials and whether this results in object- or position-tuned responses. The head-fixed navigation task with tactile VR proposed here, should be ideally suited to test these ideas and to dissect how tactile objects are encoded and stored in the brain’s spatial network.</p></sec><sec id="S9" sec-type="methods" specific-use="web-only"><title>Methods</title><sec id="S10"><title>Resource availability</title><sec id="S11"><title>Lead contact</title><p id="P21">Further information and resource requests should be directed to and will be fulfilled by the lead contact Koen Vervaeke (<email>koenv@medisin.uio.no</email>).</p></sec><sec id="S12"><title>Materials availability</title><p id="P22">This study did not generate new unique reagents.</p></sec></sec><sec id="S13"><title>Experimental model and subject details</title><p id="P23">We used male and female Thy1-GCaMP6s mice (GP 4.3 line #024275 from JAX, (<xref ref-type="bibr" rid="R21">Dana et al., 2014</xref>)) between 3 – 8 months old at the time of surgery. We housed mice in groups with 2-4 littermates on a reversed 12-hour light/ 12-hour dark cycle, and we carried out experiments during their dark phase. Mice were kept in a humidity and temperature-controlled environment. Mice received water drop rewards throughout the task, and we kept them on a water restriction regime as described in (<xref ref-type="bibr" rid="R35">Guo et al., 2014</xref>). All procedures were approved by the Norwegian Food Safety Authority (project: FOTS 6590, 7480, 19129) and experiments were performed in accordance with the Norwegian Animal Welfare Act.</p></sec><sec id="S14"><title>Methods details</title><sec id="S15"><title>Surgery</title><p id="P24">Surgery was carried out under isoflurane anesthesia (3 % induction, 1 % maintenance) while maintaining body temperature at 37°C with a heating pad (Harvard Apparatus). We delivered a subcutaneous injection of 0.1 mL Marcaine (bupivacaine 0.25 % m/V in sterile water) at the scalp incision site and administered post-operative analgesia (Temgesic, 0.1 mg/kg) subcutaneously. Several weeks before experiments began, we implanted the head bar and cranial window. The center of the window was -2.2 mm AP from bregma. The window consisted of a circular outer window (3.5 mm diameter, #1.5 coverslip glass) affixed to a circular inner window (2.5 mm diameter, #2 coverslip glass) with optical adhesive (Norland Optical Adhesive; ThorLabs NOA61). We held the window in place by applying gentle pressure so that the outer window would fit into the thinned skull area and flush with the skull’s surface. We used heated agar (1 %; Sigma #A6877) to seal any open spaces between the skull and edges of the glass window, and we affixed the window to the skull with cyanoacrylate glue. A detailed protocol of the surgery can be found in (<xref ref-type="bibr" rid="R38">Holtmaat et al., 2009</xref>).</p></sec><sec id="S16"><title>Water restriction</title><p id="P25">Starting a minimum 1 week after surgery, we placed mice on water restriction (<xref ref-type="bibr" rid="R35">Guo et al., 2014</xref>). Mice received 1-1.5 ml of water per day while we monitored their body weight to ensure they maintained more than 80% of the initial body weight.</p></sec><sec id="S17"><title>Tactile VR setup</title><p id="P26">Mice were trained to find the location of a water reward on a 50 cm diameter Styrofoam wheel (circumference 157 cm). On the left side of the animal, we positioned a rotary servo motor (Zaber NM08AS-T4; controlled by Zaber X-MCB2 24V motor controller) and to the shaft we attached a 2 x 6 cm piece of cardboard. The distance of the motor was adjusted such that the cardboard brushed the outer one-third of the whiskers. The rotation speed of the rotary motor was controlled closed loop by the running speed of the mouse which was recorded using an optical rotary encoder attached to the running wheel axis. The coupling gain was adjusted so the cardboard brushed the whiskers at the same speed as the mouse’s running speed, simulation the sensation of running passed an object. The rotary motor was triggered to start moving at positions 45 cm and 105 cm along the track, relative to the location of the water reward. It takes about 5 cm of forward movement by the mouse before the motors rotate the object in reach of the whiskers. Therefore, the tactile object reached the whiskers at positions 50 cm and 110 cm. Once the mouse passed the tactile object, the motor was reset to its home position, out of reach of the whiskers, until the next tactile object.</p><p id="P27">The behavior was automated used custom routines in LabView (2018, National Instruments) to control all actuators, sensors, data acquisition, to record behavioral parameters, and to trigger the microscope to start and stop recording. All behavioral parameters were recorded at 5 kHz. The absolute position on the running wheel was based on the rotary encoder and additionally calibrated using an IR emitter-receiver pair (transceiver) facing the running wheel. A small black cue passing the transceiver then signaled each time a full lap passed. In addition to the motor-controlled tactile object, a strip of fine sandpaper (2 cm wide) was attached to the running wheel 17 cm before the reward location. The behavior setup was positioned under a custom-build two-photon microscope in a light-tight enclosure built from Thorlabs parts (25 mm optical rails, Thorlabs, XE25L48), blackout hardboard (Thorlabs, TB4) and blackout fabric (Thorlabs, BK5). It was key that no light could enter the enclosure and additionally, the room lights where the microscope was located were turned off.</p><sec id="S18"><title>Passive whisker stimulation</title><p id="P28">In a subset of experiments (<xref ref-type="fig" rid="F2">Figure 2</xref>), we passively stimulated the whiskers. The running wheel was clamped to immobilize the mouse and at random intervals the motor brushed the tactile object over the whiskers at a speed matching the running speed of the mouse in a normal session, typically 40-50 cm/s. After about 15 trials, the wheel was unlocked allowing the mouse to freely run again and the passive stimulation was again repeated during running for about 15 laps. The stimulations were separated by at least 5 seconds.</p></sec><sec id="S19"><title>Dark/ Light experiments</title><p id="P29">In experiments comparing responses in darkness and two different levels of ambient light, we used a Thorlabs white LED (MNWHL4) to illuminate the inside of the enclosure. The LED was positioned 0.5 meter behind the mouse and controlled by a Thorlabs LED driver (LEDD1B) which was modulated through a 5V input drive via LabView. The current applied to the LED was: no-light: 0 mA; dim light: 7.2 mA; bright light: 24 mA. The mice were trained on the task in darkness before the dark/light experiments were performed.</p></sec><sec id="S20"><title>Whisker imaging and pupil tracking</title><p id="P30">High speed imaging of the whiskers was done using a NORPIX imaging system with a Basler Aca2000-340kmNIR camera and Streampix-6 acquisition software at 200 Hz. To illuminate the whiskers, we used a 940 nm IR LED (Thor Labs M940L3). Whisker imaging was synchronized with two-photon imaging using the microscope frame clock to send TTLs to a small IR LED positioned in the whisker camera’s field of view (see <xref ref-type="supplementary-material" rid="SD1">Video S1</xref>). This TTL was set to 5 V during the first half of a microscope frame and 0 V for the second half. A custom MATLAB script then searched the whisker imaging frames, and every frame where the LED switched on was matched up with the corresponding two-photon imaging frame. In a subset of mice, we performed pupil tracking to look for correlations in pupil parameters such as diameter, and pupil movements in the yaw and pitch rotation axis (<xref ref-type="supplementary-material" rid="SD1">Figure S1</xref>). This was done using the same camera and software for whisker imaging, but at 50 Hz. Extraction of pupil parameters was done using custom code in MATLAB.</p></sec><sec id="S21"><title>Behavioral training</title><p id="P31">Mice were water restricted for 7-10 days before their first exposure to the training environment (<xref ref-type="bibr" rid="R35">Guo et al., 2014</xref>). To habituate the animals to being head-fixed and walk on the Styrofoam wheel, the mice were exposed gradually to the setup, typically only 3-5 minutes on the first and second day of training. As mice got more confident, the duration was increased to the point where they ran typically 300 meters during a 20-minute session. When mice were running comfortably for a minimum of 80 meters with a parabolic running profile (see <xref ref-type="fig" rid="F1">Figure 1C</xref>), the motor-controlled tactile objects were introduced. Thereafter, the mice were trained to run with the tactile objects present for at least a week before imaging experiments started.</p></sec><sec id="S22"><title>Two-photon imaging</title><p id="P32">Imaging was performed on a custom-built two-photon microscope designed to provide a large space under the objective, allowing the large Styrofoam running wheel of the VR setup (<xref ref-type="bibr" rid="R37">Hennestad et al., 2021</xref>). The microscope was built in collaboration with Independent Neuroscience Services (INSS). All imaging data was acquired at 31 fps (512 x 512 pixels) using the open-source acquisition software SciScan (written in LabVIEW). The excitation wavelength was 950 nm using a MaiTai DeepSee ePH DS laser (Spectra-Physics), where the average power measured under the objective (N16XLWD-PF, Nikon) was typically 60-110 mW. The field of view width varied between 500-600 <italic>μ</italic>m. Photons were detected using GaAsP photomultiplier tubes (PMT2101/M, Thorlabs). The primary dichroic mirror was a 700 nm LP (Chroma), and the photon detection path consisted of a 680 nm SP filter (Chroma), a 566 nm LP dichroic mirror (Chroma), and a 510/80 nm BP filter (Chroma). The field of view center for recordings was between -1.7 and -3.2 mm anterior-posterior, and 0.3 to 0.7 mm medial-lateral, relative to bregma. Imaging depth varied between 100-220 <italic>μ</italic>m below the cortical surface, corresponding to Layer 2/3 in the agranular RSC.</p></sec><sec id="S23"><title>Motion correction, image segmentation and signal extraction</title><p id="P33">Images were registered using a combination of custom and published code. Images were first de-stretched to correct for distortions resulting from the sinusoidal speed profile of the resonance scan mirror of the microscope. Next, both rigid and non-rigid motion correction was performed using custom written scripts utilizing NoRMCorre (<xref ref-type="bibr" rid="R67">Pnevmatikakis et al., 2016</xref>). Registered images were then loaded into a custom written MATLAB GUI to manually draw regions of interest (ROIs) around neuronal somas. When ROIs were overlapping the overlapping region was excluded. A doughnut-shaped ROI of surrounding neuropil was automatically created for each ROI, by dilating the ROI so that the doughnut area was four times larger than the soma ROI area. If this doughnut overlapped with another soma ROI, then that soma ROI was excluded from the doughnut.</p><p id="P34">The ROI fluorescence is computed as a fractional change dF/F according to <italic>f</italic>(<italic>t</italic>) = (<italic>F</italic> (<italic>t</italic>) − <italic>F</italic><sub>0</sub>)<italic>/F</italic><sub>0</sub>, with <italic>F</italic><sub>0</sub> being the baseline defined as the 20th percentile of the signal. This was calculated for both the soma and neuropil ROI. Then the neuropil dF/F was subtracted from the soma dF/F, and finally, a correction factor was added to ensure that the soma dF/F remained positive. The dF/F for each cell was then deconvolved using the CaImAn package (<xref ref-type="bibr" rid="R33">Giovannucci et al., 2019</xref>). The resulting deconvolved signals are given in arbitrary units (a.u.).</p></sec></sec></sec><sec id="S24"><title>Quantification and statistical analysis</title><p id="P35">Time series for dF/F, deconvolved dF/F and behavioral data were processed and analyzed using Matlab. The behavioral time series were first binned to match the two-photon microscope frame rate (31 Hz) by finding the behavioral data sample closest in time to the imaging frame.</p><sec id="S25"><title>Running speed analysis</title><p id="P36">The running speed was computed by calculating the change in distance between two samples. Using the wheel circumference (2·π·<italic>radius</italic> of 25 cm) and dividing it by the number of ticks in one full rotation of the optical encoder (2000 ticks), an estimated running speed was obtained. The running speed was then smoothed using a 0.1 second moving average to remove unwanted spikes. For each sample point, the absolute position on the wheel was found by computing the modulo of the number of ticks T(t) by max number of ticks for one round: <disp-formula id="FD1"><label>(1)</label><mml:math id="M1"><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mn>2000</mml:mn></mml:mrow><mml:mrow><mml:mn>2000</mml:mn></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo><mml:mo>∗</mml:mo><mml:mn>157.5</mml:mn><mml:mi>c</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:math></disp-formula></p><p id="P37">The position was then offset by the position of the first sample where the wheel position LED diode was triggered, which was set to be position 0 cm. The lap number at sample t was computed by the following: <disp-formula id="FD2"><label>(2)</label><mml:math id="M2"><mml:mrow><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2000</mml:mn></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P38">where T(t) is the tick count at sample t. Both position and lap time series were down sampled to match the imaging frames by computing the mean value at each frame. Finally, the position along the track was binned into 1.5 cm bins, creating 105 bins along the linear track.</p></sec><sec id="S26"><title>Tactile object movement detection</title><p id="P39">The movement of the motor-controlled tactile objects was detected for each lap either by using the whisker imaging data, or by recording the rotary motor speed signal. For all plots where a line is used to visualize the object position, and for analysis that required the object position, we used bin 32 and 72 (48 cm and 108 cm), which was found to be the last bin where no whisker-object interaction was observed.</p></sec><sec id="S27"><title>Average tuning curves</title><p id="P40">For each cell, we created an average tuning curve to quantify the response profile along the linear track. First, the linear track was divided into 1.5 cm bins, giving 105 bins. An occupancy count was created by counting the number of time bins the animal had been within each of the 105 bins. For each cell the deconvolved dF/F response at each bin was summed and later divided by the occupancy count in each bin, creating the final occupancy normalized averaged tuning curve.</p></sec><sec id="S28"><title>Classification of position-tuned cells</title><p id="P41">Classification was similar to (<xref ref-type="bibr" rid="R46">Mao et al., 2017</xref>). Position tuned cells were detected by finding significant peak responses in the averaged tuning curve. Peaks were detected using the MATLAB Signal Processing Toolbox function findpeaks(). Each peak that was detected had to be separated by a minimum distance of 40 cm to the surrounding peaks, have a minimum width of 2 cm and a maximum width of 120 cm. A maximum of 3 peaks could be detected by the algorithm. A “response threshold” was used to detect a peak, which was defined as 30% of the difference between the maximum and minimum of the average tuning curve. Because the linear track is circular, meaning position 0 cm is the same as position 157 cm, the first 45 cm of the position map was added to the end of the position map when detecting peaks to allow the full shape of the response peaks to be present. Finally, the neural response had to cross the response threshold within its tuning field in 1/3 of laps. To find the field width of position-tuned cells, we looked forward and backwards at each detected peak to find the positions where the response would fall below the “response threshold” and set the field width to be the number of bins around the peak where the cell showed continuous response above this threshold.</p></sec><sec id="S29"><title>Classification of object location cells</title><p id="P42">First, we detected cells that, based on their tuning curve, showed a significant response ± 15 cm from the tactile object position. For classification, the tuning curve was first smoothed using a Gaussian filter with sigma = 30 cm. A cell was then classified if it had a response peak at both positions where the tactile object was presented. The response peaks in the averaged tuning curve were found using the MATLAB Signal Processing Toolbox function findpeaks(), set to search a max number of 4 peaks. The peaks were limited to a max width of 75 cm, and a minimum distance between peaks of 30 cm. A peak was deemed significant if (1) it was greater than 25% of the difference between the max and min of the average tuning curve and (2) it was higher than the reliability criteria. The reliability criteria required that a response was present on a minimum of 20% of the laps for the most prominent of the two peaks, or a minimum of 10% of the laps for the least prominent of the two peaks.</p></sec><sec id="S30"><title>Classification of trace and non-trace object location cells</title><p id="P43">A trace cell showed a significant response at the position of the missing tactile object. To determine this, we first combined all laps where the tactile object was omitted and created an average tuning curve. The baseline activity of each tactile cell was computed by taking the 10 least active bins of the average tuning curve and calculating the mean and standard deviation of these bins. A tactile cell was classified as a trace tactile cell if (1) the maximum response at ± 15 cm from the tactile object crossed a threshold set as the baseline mean + (baseline standard deviation ∗ 3) and (2) this threshold was crossed in at least 20% of laps. Non-trace cells, trace cells and position tuned cells were mutually exclusive cell classes.</p></sec><sec id="S31"><title>Passive stimulus responding cells</title><p id="P44">For a given cell, dF/F responses were collected in a window of 4 seconds before and 4 seconds after the stimulation, for each trial. This was done for both immobile passive stimulation and for passive stimulation during running, resulting in two matrices of n trials by 8 seconds. We then classified responses for each matrix using shuffling by randomly shifting the response in each trial (using MATLABs function circshift()). An average response was computed for the original matrix and for the shuffled matrix. We created 1000 shuffled matrices and computed the average response of each. A response was deemed significant if the average response in a 650 ms window starting 350 ms after the stimulation was larger than the 95th percentile of the shuffled responses in the same time window.</p></sec><sec id="S32"><title>Predictive cells</title><p id="P45">The average tuning curve of all object location cells was used to find predictive cells. All cells that had their maximum response along the track before the first tactile object onset and all cells that had a maximum response up to 35 cm before the second tactile object was deemed to be predictive. To find the onset position of each predictive cell, we found the earliest position along the track that the cell showed an average response above the 95th percentile of the cells’ average tuning curve. To find the <italic>onset time</italic> of each predictive cell, we first found each time bin where the mouse entered the tactile object at the first object position and created a matrix containing the deconvolved dF/F signal in a time window of 1 second before. We then averaged this time aligned response and used it to find the time bin where the signal first crossed the 95th percentile of the averaged deconvolved dF/F signal.</p></sec><sec id="S33"><title>Light responsive cells</title><p id="P46">For experiments in light, cells were classified as object location cells as described above. The experiments had three levels of light; no light, dim light, and bright light. Cells were tested for being responsive in each visual context by using the laps for each of these light conditions.</p></sec><sec id="S34"><title>Analysis of changes in tuning across light contexts</title><p id="P47">Cells were classified as position-tuned or object location cells across the three light contexts as detailed above. To compute similarity across contexts, we computed the percentage of cells that stayed within their class across all three contexts.</p></sec><sec id="S35"><title>Population decoding</title><p id="P48">We used a Bayesian algorithm (<xref ref-type="bibr" rid="R87">Zhang et al., 1998</xref>) as a decoding model (<xref ref-type="bibr" rid="R46">Mao et al., 2017</xref>) to estimate the position of the animal based on the activity of all position-tuned cells. This was done to compare the spatial information in laps where the tactile object was present or omitted. Data from 10 session (8 mice) was included. Decoding was done only for periods where the running speed of the animal was above 1 cm/s, using the deconvolved dF/F traces, excluding all cells that had no deconvolved transients. Deconvolved signals were smoothed using a Gaussian filter with sigma = 5 cm. The time series were later binned (0.19 s) using non-overlapping time bins selected to minimize decoding error. The data was split into laps where the tactile object was present or omitted. Training data was generated using odd laps where the tactile object was present. Two sets of test data were used, even laps when the object was presented (control), or all laps when the object was not presented (omitted). Mean decoding error and SEM are reported by combining the individual laps across all included sessions. The decoding error was computed as the absolute difference between the actual and decoded position of the animal at each sample bin. The decoded position was selected from the maximum likelihood given the activity of all position-tuned cells within a time bin. The maximum likelihood was found by computing the probability of the animal’s position at each position given the population activity: <disp-formula id="FD3"><label>(3)</label><mml:math id="M3"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>F</mml:mi></mml:mrow><mml:mi>F</mml:mi></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>t</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mi>F</mml:mi><mml:mo>/</mml:mo><mml:mi>F</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>t</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mi>F</mml:mi><mml:mo>/</mml:mo><mml:mi>F</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>t</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p id="P49">Where <italic>position</italic> is the binned position at the given time bin, (<italic>dF/F</italic>)<sub><italic>ptcells</italic></sub> is the population activity of all position-tuned cells, and P is probability. P(<italic>position</italic>) was computed using the occupancy in each position bin. <disp-formula id="FD4"><label>(4)</label><mml:math id="M4"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mi>F</mml:mi><mml:mo>/</mml:mo><mml:mi>F</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>t</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>∏</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mi>F</mml:mi><mml:mo>/</mml:mo><mml:mi>F</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>t</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>∣</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>∏</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>τ</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>!</mml:mo></mml:mrow></mml:mfrac><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula></p><p id="P50">where <italic>τ</italic> is the time bin (0.19 s), <italic>f<sub>i</sub></italic>(<italic>position</italic>) is the computed position tuning curve for the i-th neurons, N is the total number of neurons; and <italic>n<sub>i</sub></italic> is the mean activity of the i-th neuron within that time bin. This gives: <disp-formula id="FD5"><label>(5)</label><mml:math id="M5"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mi>F</mml:mi><mml:mo>/</mml:mo><mml:mi>F</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>t</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>∏</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>∑</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula> where C serves as a normalization factor so that <italic>P</italic>(<italic>position</italic>|(<italic>dF/F</italic>)<sub><italic>ptcells</italic></sub>) sums to 1.</p></sec></sec><sec id="S36"><title>Analyzing position-tuned cells around tactile objects</title><p id="P51">To find position-tuned cells that were active around the tactile objects, we first quantified cells that were position-tuned using the first 50 laps where the tactile object was presented. For each of these cells we created an average tuning response and picked only cells with a single firing field along the track for further analysis. We subsequently selected cells that had their peak activity ±21 cm from either the first or the second tactile object. Field width of each position-tuned cells were found as described under “<italic>Classification of position tuned cells</italic>”.</p></sec><sec id="S37"><title>Eye movement analysis</title><p id="P52">The pupil was back-illuminated by the IR laser light used for two-photon imaging. First, a raster map was produced for each of the eye signals; the horizontal (yaw) eye movement, the vertical (pitch) eye movement, and pupil diameter. Because experiments were performed in the dark, the pupil was fully dilated. Therefore, reductions in eye diameter (<xref ref-type="supplementary-material" rid="SD1">Figure S1D, E</xref>) reflect eyeblinks rather than pupil contractions. To determine correlations between the eye blinks and neuronal activity, we resampled the 50 Hz pupil video to match the two-photon imaging capturing at 31 Hz. An eye blink event was defined as a drop in eye radius below a baseline value. The baseline was set to be the mean - 2 x the standard deviation of eye radius in a window of 30 cm before the tactile object was presented, up to the point of object presentation. To test which neurons were significantly correlated with eye squints, we performed Wilcoxon rank sum test on each recorded neuron. To do so, we found the max response of each neuron in a 15 cm window after the tactile object was presented, and split the data into two vectors, one containing the responses during eye blinks, and one containing the responses when there were no eye blinks. The rank sum test used alpha = 0.05 and a left tail.</p></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary Figures</label><media xlink:href="EMS158246-supplement-Supplementary_Figures.pdf" mimetype="application" mime-subtype="pdf" id="d43aAdEbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S38"><title>Acknowledgements</title><p>This work was funded by the European Research Council (ERC Starting Grant #639272) and the Research Council of Norway #274306. We thank Kristin Larsen Sand and Eivind Hennestad for technical assistance. We thank Bruno Pichler (Independent NeuroScience Services; INSS) for developing the custom two-photon microscope and providing technical assistance. Some schematics were created with Biorender.com. The cartoon in <xref ref-type="fig" rid="F1">Figure 1A</xref> is from scidraw.io. Finally, we thank the members of the Vervaeke lab and Matthijs Dorst, Maximiliano Nigro, Shankar Sachidhanandam, Jørgen Sugar, and Jianing Yu for providing critical comments that significantly improved a draft of the manuscript.</p></ack><sec id="S39" sec-type="data-availability"><title>Data and code availability</title><list list-type="bullet" id="L1"><list-item><p id="P53">Ca<sup>2+</sup> imaging and tracing data reported in this paper will be shared by the lead contact upon request.</p></list-item><list-item><p id="P54">All original code will be deposited on GitHub and is publicly available as of the date of publication. Any additional information required to reanalyze the data reported in this paper is available from the lead contact upon request.</p></list-item></list></sec><fn-group><fn id="FN1" fn-type="con"><p id="P55"><bold>Author contributions</bold></p><p id="P56">AL and KV designed the study. AL performed all experiments and analysis. AL and KV wrote the paper. All authors discussed the results.</p></fn></fn-group><ref-list><title>Bibliography</title><ref id="R1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aggleton</surname><given-names>JP</given-names></name><name><surname>Nelson</surname><given-names>AJ</given-names></name></person-group><article-title>Distributed interactive brain circuits for object-in-place memory: A place for time?</article-title><source>Brain and Neuroscience Advances</source><year>2020</year><pub-id pub-id-type="pmcid">PMC7479857</pub-id><pub-id pub-id-type="pmid">32954003</pub-id><pub-id pub-id-type="doi">10.1177/2398212820933471</pub-id></element-citation></ref><ref id="R2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alexander</surname><given-names>AS</given-names></name><name><surname>Carstensen</surname><given-names>LC</given-names></name><name><surname>Hinman</surname><given-names>JR</given-names></name><name><surname>Raudies</surname><given-names>F</given-names></name><name><surname>Chapman</surname><given-names>GW</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group><article-title>Egocentric boundary vector tuning of the retrosplenial cortex</article-title><source>Science Advances</source><year>2020</year><issue>8</issue><pub-id pub-id-type="pmcid">PMC7035004</pub-id><pub-id pub-id-type="pmid">32128423</pub-id><pub-id pub-id-type="doi">10.1126/sciadv.aaz2322</pub-id></element-citation></ref><ref id="R3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alexander</surname><given-names>AS</given-names></name><name><surname>Nitz</surname><given-names>DA</given-names></name></person-group><article-title>Retrosplenial cortex maps the conjunction of internal and external spaces</article-title><source>Nature Neuroscience</source><year>2015</year><volume>18</volume><issue>8</issue><fpage>1143</fpage><lpage>1151</lpage><pub-id pub-id-type="pmid">26147532</pub-id></element-citation></ref><ref id="R4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aronoff</surname><given-names>R</given-names></name><name><surname>Matyas</surname><given-names>F</given-names></name><name><surname>Mateo</surname><given-names>C</given-names></name><name><surname>Ciron</surname><given-names>C</given-names></name><name><surname>Schneider</surname><given-names>B</given-names></name><name><surname>Petersen</surname><given-names>CC</given-names></name></person-group><article-title>Long-range connectivity of mouse primary somatosensory barrel cortex</article-title><source>European Journal of Neuroscience</source><year>2010</year><volume>31</volume><issue>12</issue><fpage>2221</fpage><lpage>2233</lpage><pub-id pub-id-type="pmid">20550566</pub-id></element-citation></ref><ref id="R5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ayaz</surname><given-names>A</given-names></name><name><surname>Stäuble</surname><given-names>A</given-names></name><name><surname>Hamada</surname><given-names>M</given-names></name><name><surname>Wulf</surname><given-names>M-A</given-names></name><name><surname>Saleem</surname><given-names>AB</given-names></name><name><surname>Helmchen</surname><given-names>F</given-names></name></person-group><article-title>Layer-specific integration of locomotion and sensory information in mouse barrel cortex</article-title><source>Nature Communications</source><year>2019</year><volume>10</volume><issue>1</issue><elocation-id>2585</elocation-id><pub-id pub-id-type="pmcid">PMC6565743</pub-id><pub-id pub-id-type="pmid">31197148</pub-id><pub-id pub-id-type="doi">10.1038/s41467-019-10564-8</pub-id></element-citation></ref><ref id="R6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bar</surname><given-names>M</given-names></name></person-group><article-title>Visual objects in context</article-title><source>Nature reviews. Neuroscience</source><year>2004</year><volume>5</volume><issue>8</issue><fpage>617</fpage><lpage>629</lpage><pub-id pub-id-type="pmid">15263892</pub-id></element-citation></ref><ref id="R7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bellistri</surname><given-names>E</given-names></name><name><surname>Aguilar</surname><given-names>J</given-names></name><name><surname>Brotons-Mas</surname><given-names>JR</given-names></name><name><surname>Foffani</surname><given-names>G</given-names></name><name><surname>Prida</surname><given-names>LMdl</given-names></name></person-group><article-title>Basic properties of somatosensory-evoked responses in the dorsal hippocampus of the rat</article-title><source>The Journal of Physiology</source><year>2013</year><volume>591</volume><issue>10</issue><fpage>2667</fpage><lpage>2686</lpage><pub-id pub-id-type="pmcid">PMC3678049</pub-id><pub-id pub-id-type="pmid">23420661</pub-id><pub-id pub-id-type="doi">10.1113/jphysiol.2013.251892</pub-id></element-citation></ref><ref id="R8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bezdudnaya</surname><given-names>T</given-names></name><name><surname>Keller</surname><given-names>A</given-names></name></person-group><article-title>Laterodorsal nucleus of the thalamus: A processor of somatosensory inputs</article-title><source>Journal of Comparative Neurology</source><year>2008</year><volume>507</volume><issue>6</issue><fpage>1979</fpage><lpage>1989</lpage><pub-id pub-id-type="pmcid">PMC2800129</pub-id><pub-id pub-id-type="pmid">18273888</pub-id><pub-id pub-id-type="doi">10.1002/cne.21664</pub-id></element-citation></ref><ref id="R9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bicanski</surname><given-names>A</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><article-title>Neuronal vector coding in spatial cognition</article-title><source>Nature Reviews Neuroscience</source><year>2020</year><volume>21</volume><issue>9</issue><fpage>453</fpage><lpage>470</lpage><pub-id pub-id-type="pmid">32764728</pub-id></element-citation></ref><ref id="R10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bittner</surname><given-names>KC</given-names></name><name><surname>Milstein</surname><given-names>AD</given-names></name><name><surname>Grienberger</surname><given-names>C</given-names></name><name><surname>Romani</surname><given-names>S</given-names></name><name><surname>Magee</surname><given-names>JC</given-names></name></person-group><article-title>Behavioral time scale synaptic plasticity underlies CA1 place fields</article-title><source>Science</source><year>2017</year><volume>357</volume><issue>6355</issue><fpage>1033</fpage><lpage>1036</lpage><pub-id pub-id-type="pmcid">PMC7289271</pub-id><pub-id pub-id-type="pmid">28883072</pub-id><pub-id pub-id-type="doi">10.1126/science.aan3846</pub-id></element-citation></ref><ref id="R11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bosman</surname><given-names>LWJ</given-names></name><name><surname>Houweling</surname><given-names>AR</given-names></name><name><surname>Owens</surname><given-names>CB</given-names></name><name><surname>Tanke</surname><given-names>N</given-names></name><name><surname>Shevchouk</surname><given-names>OT</given-names></name><name><surname>Rahmati</surname><given-names>N</given-names></name><name><surname>Teunissen</surname><given-names>WHT</given-names></name><name><surname>Ju</surname><given-names>C</given-names></name><name><surname>Gong</surname><given-names>W</given-names></name><name><surname>Koekkoek</surname><given-names>SKE</given-names></name><name><surname>Zeeuw</surname><given-names>CID</given-names></name></person-group><article-title>Anatomical Pathways Involved in Generating and Sensing Rhythmic Whisker Movements</article-title><source>Frontiers in Integrative Neuroscience</source><year>2011</year><volume>5</volume><fpage>53</fpage><pub-id pub-id-type="pmcid">PMC3207327</pub-id><pub-id pub-id-type="pmid">22065951</pub-id><pub-id pub-id-type="doi">10.3389/fnint.2011.00053</pub-id></element-citation></ref><ref id="R12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brennan</surname><given-names>EK</given-names></name><name><surname>Jedrasiak-Cape</surname><given-names>I</given-names></name><name><surname>Kailasa</surname><given-names>S</given-names></name><name><surname>Rice</surname><given-names>SP</given-names></name><name><surname>Sudhakar</surname><given-names>SK</given-names></name><name><surname>Ahmed</surname><given-names>OJ</given-names></name></person-group><article-title>Thalamus and claustrum control parallel layer 1 circuits in retrosplenial cortex</article-title><source>eLife</source><year>2021</year><pub-id pub-id-type="pmcid">PMC8233040</pub-id><pub-id pub-id-type="pmid">34170817</pub-id><pub-id pub-id-type="doi">10.7554/eLife.62207</pub-id></element-citation></ref><ref id="R13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carstensen</surname><given-names>LC</given-names></name><name><surname>Alexander</surname><given-names>AS</given-names></name><name><surname>Chapman</surname><given-names>GW</given-names></name><name><surname>Lee</surname><given-names>AJ</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group><article-title>Neural responses in retrosplenial cortex associated with environmental alterations</article-title><source>iScience</source><year>2021</year><volume>24</volume><issue>11</issue><elocation-id>103377</elocation-id><pub-id pub-id-type="pmcid">PMC8605176</pub-id><pub-id pub-id-type="pmid">34825142</pub-id><pub-id pub-id-type="doi">10.1016/j.isci.2021.103377</pub-id></element-citation></ref><ref id="R14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>LL</given-names></name><name><surname>Lin</surname><given-names>LH</given-names></name><name><surname>Green</surname><given-names>EJ</given-names></name><name><surname>Barnes</surname><given-names>Ca</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><article-title>Head-direction cells in the rat posterior cortex. I. Anatomical distribution and behavioral modulation</article-title><source>Experimental Brain Research</source><year>1994</year><volume>101</volume><issue>1</issue><fpage>8</fpage><lpage>23</lpage><pub-id pub-id-type="pmid">7843305</pub-id></element-citation></ref><ref id="R15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheung</surname><given-names>JA</given-names></name><name><surname>Maire</surname><given-names>P</given-names></name><name><surname>Kim</surname><given-names>J</given-names></name><name><surname>Lee</surname><given-names>K</given-names></name><name><surname>Flynn</surname><given-names>G</given-names></name><name><surname>Hires</surname><given-names>SA</given-names></name></person-group><article-title>Independent representations of self-motion and object location in barrel cortex output</article-title><source>PLoS Biology</source><year>2020</year><issue>11</issue><pub-id pub-id-type="pmcid">PMC7665803</pub-id><pub-id pub-id-type="pmid">33141817</pub-id><pub-id pub-id-type="doi">10.1371/journal.pbio.3000882</pub-id></element-citation></ref><ref id="R16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Claessen</surname><given-names>MH</given-names></name><name><surname>Ham</surname><given-names>IJvd</given-names></name></person-group><article-title>Classification of navigation impairment: A systematic review of neuropsychological case studies</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><year>2017</year><volume>73</volume><fpage>81</fpage><lpage>97</lpage><pub-id pub-id-type="pmid">27993606</pub-id></element-citation></ref><ref id="R17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Connor</surname><given-names>CE</given-names></name><name><surname>Knierim</surname><given-names>JJ</given-names></name></person-group><article-title>Integration of objects and space in perception and memory</article-title><source>Nature neuroscience</source><year>2017</year><volume>20</volume><issue>11</issue><fpage>1493</fpage><lpage>1503</lpage><pub-id pub-id-type="pmcid">PMC5920781</pub-id><pub-id pub-id-type="pmid">29073645</pub-id><pub-id pub-id-type="doi">10.1038/nn.4657</pub-id></element-citation></ref><ref id="R18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Couto</surname><given-names>J</given-names></name><name><surname>Kandler</surname><given-names>S</given-names></name><name><surname>Mao</surname><given-names>D</given-names></name><name><surname>McNaughton</surname><given-names>B</given-names></name><name><surname>Arckens</surname><given-names>L</given-names></name><name><surname>Bonin</surname><given-names>V</given-names></name></person-group><article-title>Spatially segregated responses to visuo-tactile stimuli in mouse neocortex during active sensation</article-title><source>bioRxiv</source><year>2019</year></element-citation></ref><ref id="R19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cowansage</surname><given-names>KK</given-names></name><name><surname>Shuman</surname><given-names>T</given-names></name><name><surname>Dillingham</surname><given-names>BC</given-names></name><name><surname>Chang</surname><given-names>A</given-names></name><name><surname>Golshani</surname><given-names>P</given-names></name><name><surname>Mayford</surname><given-names>M</given-names></name></person-group><article-title>Direct reactivation of a coherent neocortical memory of context</article-title><source>Neuron</source><year>2014</year><volume>84</volume><issue>2</issue><fpage>432</fpage><lpage>441</lpage><pub-id pub-id-type="pmcid">PMC4372249</pub-id><pub-id pub-id-type="pmid">25308330</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2014.09.022</pub-id></element-citation></ref><ref id="R20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Czajkowski</surname><given-names>R</given-names></name><name><surname>Jayaprakash</surname><given-names>B</given-names></name><name><surname>Wiltgen</surname><given-names>B</given-names></name><name><surname>Rogerson</surname><given-names>T</given-names></name><name><surname>Guzman-Karlsson</surname><given-names>MC</given-names></name><name><surname>Barth</surname><given-names>AL</given-names></name><name><surname>Trachtenberg</surname><given-names>JT</given-names></name><name><surname>Silva</surname><given-names>AJ</given-names></name></person-group><article-title>Encoding and storage of spatial information in the retrosplenial cortex</article-title><source>Proceedings of the National Academy of Sciences</source><year>2014</year><volume>111</volume><issue>23</issue><fpage>8661</fpage><lpage>8666</lpage><pub-id pub-id-type="pmcid">PMC4060653</pub-id><pub-id pub-id-type="pmid">24912150</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1313222111</pub-id></element-citation></ref><ref id="R21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dana</surname><given-names>H</given-names></name><name><surname>Chen</surname><given-names>T-W</given-names></name><name><surname>Hu</surname><given-names>A</given-names></name><name><surname>Shields</surname><given-names>BC</given-names></name><name><surname>Guo</surname><given-names>C</given-names></name><name><surname>Looger</surname><given-names>LL</given-names></name><name><surname>Kim</surname><given-names>DS</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name></person-group><article-title>Thy1-GCaMP6 Transgenic Mice for Neuronal Population Imaging In Vivo</article-title><source>PLoS ONE</source><year>2014</year><volume>9</volume><issue>9</issue><elocation-id>e108697</elocation-id><pub-id pub-id-type="pmcid">PMC4177405</pub-id><pub-id pub-id-type="pmid">25250714</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0108697</pub-id></element-citation></ref><ref id="R22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deshmukh</surname><given-names>SS</given-names></name><name><surname>Knierim</surname><given-names>JJ</given-names></name></person-group><article-title>Representation of Non-Spatial and Spatial Information in the Lateral Entorhinal Cortex</article-title><source>Frontiers in Behavioral Neuroscience</source><year>2011</year><volume>5</volume><fpage>69</fpage><pub-id pub-id-type="pmcid">PMC3203372</pub-id><pub-id pub-id-type="pmid">22065409</pub-id><pub-id pub-id-type="doi">10.3389/fnbeh.2011.00069</pub-id></element-citation></ref><ref id="R23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deshmukh</surname><given-names>SS</given-names></name><name><surname>Knierim</surname><given-names>JJ</given-names></name></person-group><article-title>Influence of local objects on hippocampal representations: Landmark vectors and memory</article-title><source>Hippocampus</source><year>2013</year><volume>23</volume><issue>4</issue><fpage>253</fpage><lpage>267</lpage><pub-id pub-id-type="pmcid">PMC3869706</pub-id><pub-id pub-id-type="pmid">23447419</pub-id><pub-id pub-id-type="doi">10.1002/hipo.22101</pub-id></element-citation></ref><ref id="R24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diamond</surname><given-names>ME</given-names></name><name><surname>Heimendahl</surname><given-names>Mv</given-names></name><name><surname>Knutsen</surname><given-names>PM</given-names></name><name><surname>Kleinfeld</surname><given-names>D</given-names></name><name><surname>Ahissar</surname><given-names>E</given-names></name></person-group><article-title>‘Where’ and ‘what’ in the whisker sensorimotor system</article-title><source>Nature Reviews Neuroscience</source><year>2008</year><volume>9</volume><issue>8</issue><fpage>601</fpage><lpage>612</lpage><pub-id pub-id-type="pmid">18641667</pub-id></element-citation></ref><ref id="R25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischer</surname><given-names>LF</given-names></name><name><surname>Soto-Albors</surname><given-names>RM</given-names></name><name><surname>Buck</surname><given-names>F</given-names></name><name><surname>Harnett</surname><given-names>MT</given-names></name></person-group><article-title>Representation of visual landmarks in retrosplenial cortex</article-title><source>eLife</source><year>2020</year><volume>9</volume><elocation-id>e51458</elocation-id><pub-id pub-id-type="pmcid">PMC7064342</pub-id><pub-id pub-id-type="pmid">32154781</pub-id><pub-id pub-id-type="doi">10.7554/eLife.51458</pub-id></element-citation></ref><ref id="R26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Franco</surname><given-names>LM</given-names></name><name><surname>Goard</surname><given-names>MJ</given-names></name></person-group><article-title>A distributed circuit for associating environmental context with motor choice in retrosplenial cortex</article-title><source>Science Advances</source><year>2021</year><volume>7</volume><issue>35</issue><elocation-id>eabf9815</elocation-id><pub-id pub-id-type="pmcid">PMC8386923</pub-id><pub-id pub-id-type="pmid">34433557</pub-id><pub-id pub-id-type="doi">10.1126/sciadv.abf9815</pub-id></element-citation></ref><ref id="R27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fyhn</surname><given-names>M</given-names></name><name><surname>Hafting</surname><given-names>T</given-names></name><name><surname>Treves</surname><given-names>A</given-names></name><name><surname>Moser</surname><given-names>M-B</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><article-title>Hippocampal remapping and grid realignment in entorhinal cortex</article-title><source>Nature</source><year>2007</year><volume>446</volume><issue>7132</issue><fpage>190</fpage><lpage>194</lpage><pub-id pub-id-type="pmid">17322902</pub-id></element-citation></ref><ref id="R28"><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Gallace</surname><given-names>A</given-names></name><name><surname>Spence</surname><given-names>C</given-names></name></person-group><source>Chapter 5- A memory for touch</source><year>2014</year><fpage>111</fpage><lpage>146</lpage></element-citation></ref><ref id="R29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallero-Salas</surname><given-names>Y</given-names></name><name><surname>Han</surname><given-names>S</given-names></name><name><surname>Sych</surname><given-names>Y</given-names></name><name><surname>Voigt</surname><given-names>FF</given-names></name><name><surname>Laurenczy</surname><given-names>B</given-names></name><name><surname>Gilad</surname><given-names>A</given-names></name><name><surname>Helmchen</surname><given-names>F</given-names></name></person-group><article-title>Sensory and Behavioral Components of Neocortical Signal Flow in Discrimination Tasks with Short-Term Memory</article-title><source>Neuron</source><year>2021</year><volume>109</volume><issue>1</issue><fpage>135</fpage><lpage>148</lpage><elocation-id>e6</elocation-id><pub-id pub-id-type="pmid">33159842</pub-id></element-citation></ref><ref id="R30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geiller</surname><given-names>T</given-names></name><name><surname>Fattahi</surname><given-names>M</given-names></name><name><surname>Choi</surname><given-names>J-S</given-names></name><name><surname>Royer</surname><given-names>S</given-names></name></person-group><article-title>Place cells are more strongly tied to landmarks in deep than in superficial CA1</article-title><source>Nature Communications</source><year>2017</year><volume>8</volume><issue>1</issue><elocation-id>14531</elocation-id><pub-id pub-id-type="pmcid">PMC5321734</pub-id><pub-id pub-id-type="pmid">28218283</pub-id><pub-id pub-id-type="doi">10.1038/ncomms14531</pub-id></element-citation></ref><ref id="R31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gener</surname><given-names>T</given-names></name><name><surname>Perez-Mendez</surname><given-names>L</given-names></name><name><surname>Sanchez-Vives</surname><given-names>MV</given-names></name></person-group><article-title>Tactile modulation of hippocampal place fields</article-title><source>Hippocampus</source><year>2013</year><volume>23</volume><issue>12</issue><fpage>1453</fpage><lpage>1462</lpage><pub-id pub-id-type="pmid">23996430</pub-id></element-citation></ref><ref id="R32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gianatti</surname><given-names>M</given-names></name><name><surname>Garvert</surname><given-names>AC</given-names></name><name><surname>Vervaeke</surname><given-names>K</given-names></name></person-group><article-title>Diverse long-range projections convey position information to the retrosplenial cortex</article-title><source>bioRxiv</source><year>2022</year><elocation-id>2022.09.18.508427</elocation-id></element-citation></ref><ref id="R33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giovannucci</surname><given-names>A</given-names></name><name><surname>Friedrich</surname><given-names>J</given-names></name><name><surname>Gunn</surname><given-names>P</given-names></name><name><surname>Kalfon</surname><given-names>J</given-names></name><name><surname>Brown</surname><given-names>BL</given-names></name><name><surname>Koay</surname><given-names>SA</given-names></name><name><surname>Taxidis</surname><given-names>J</given-names></name><name><surname>Najafi</surname><given-names>F</given-names></name><name><surname>Gauthier</surname><given-names>JL</given-names></name><name><surname>Zhou</surname><given-names>P</given-names></name><name><surname>Khakh</surname><given-names>BS</given-names></name><etal/></person-group><article-title>CaImAn an open source tool for scalable calcium imaging data analysis</article-title><source>eLife</source><year>2019</year><volume>8</volume><elocation-id>e38173</elocation-id><pub-id pub-id-type="pmcid">PMC6342523</pub-id><pub-id pub-id-type="pmid">30652683</pub-id><pub-id pub-id-type="doi">10.7554/eLife.38173</pub-id></element-citation></ref><ref id="R34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Groen</surname><given-names>Tv</given-names></name><name><surname>Wyss</surname><given-names>JM</given-names></name></person-group><article-title>Connections of the retrosplenial dysgranular cortex in the rat</article-title><source>The Journal of comparative neurology</source><year>1992</year><volume>315</volume><issue>2</issue><fpage>200</fpage><lpage>216</lpage><pub-id pub-id-type="pmid">1545009</pub-id></element-citation></ref><ref id="R35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guo</surname><given-names>ZV</given-names></name><name><surname>Hires</surname><given-names>SA</given-names></name><name><surname>Li</surname><given-names>N</given-names></name><name><surname>O’Connor</surname><given-names>DH</given-names></name><name><surname>Komiyama</surname><given-names>T</given-names></name><name><surname>Ophir</surname><given-names>E</given-names></name><name><surname>Huber</surname><given-names>D</given-names></name><name><surname>Bonardi</surname><given-names>C</given-names></name><name><surname>Morandell</surname><given-names>K</given-names></name><name><surname>Gutnisky</surname><given-names>D</given-names></name><name><surname>Peron</surname><given-names>S</given-names></name><etal/></person-group><article-title>Procedures for Behavioral Experiments in Head-Fixed Mice</article-title><source>PLoS ONE</source><year>2014</year><volume>9</volume><issue>2</issue><elocation-id>e88678</elocation-id><pub-id pub-id-type="pmcid">PMC3919818</pub-id><pub-id pub-id-type="pmid">24520413</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0088678</pub-id></element-citation></ref><ref id="R36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harvey</surname><given-names>CD</given-names></name><name><surname>Coen</surname><given-names>P</given-names></name><name><surname>Tank</surname><given-names>DW</given-names></name></person-group><article-title>Choice-specific sequences in parietal cortex during a virtual-navigation decision task</article-title><source>Nature</source><year>2012</year><volume>484</volume><issue>7392</issue><fpage>62</fpage><lpage>68</lpage><pub-id pub-id-type="pmcid">PMC3321074</pub-id><pub-id pub-id-type="pmid">22419153</pub-id><pub-id pub-id-type="doi">10.1038/nature10918</pub-id></element-citation></ref><ref id="R37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hennestad</surname><given-names>E</given-names></name><name><surname>Witoelar</surname><given-names>A</given-names></name><name><surname>Chambers</surname><given-names>AR</given-names></name><name><surname>Vervaeke</surname><given-names>K</given-names></name></person-group><article-title>Mapping vestibular and visual contributions to angular head velocity tuning in the cortex</article-title><source>Cell Reports</source><year>2021</year><volume>37</volume><issue>12</issue><elocation-id>110134</elocation-id><pub-id pub-id-type="pmcid">PMC8721284</pub-id><pub-id pub-id-type="pmid">34936869</pub-id><pub-id pub-id-type="doi">10.1016/j.celrep.2021.110134</pub-id></element-citation></ref><ref id="R38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holtmaat</surname><given-names>A</given-names></name><name><surname>Bonhoeffer</surname><given-names>T</given-names></name><name><surname>Chow</surname><given-names>DK</given-names></name><name><surname>Chuckowree</surname><given-names>J</given-names></name><name><surname>Paola</surname><given-names>VD</given-names></name><name><surname>Hofer</surname><given-names>SB</given-names></name><name><surname>Hübener</surname><given-names>M</given-names></name><name><surname>Keck</surname><given-names>T</given-names></name><name><surname>Knott</surname><given-names>G</given-names></name><name><surname>Lee</surname><given-names>W-CA</given-names></name><name><surname>Mostany</surname><given-names>R</given-names></name><etal/></person-group><article-title>Long-term, high-resolution imaging in the mouse neocortex through a chronic cranial window</article-title><source>Nature Protocols</source><year>2009</year><volume>4</volume><issue>8</issue><fpage>1128</fpage><lpage>1144</lpage><pub-id pub-id-type="pmcid">PMC3072839</pub-id><pub-id pub-id-type="pmid">19617885</pub-id><pub-id pub-id-type="doi">10.1038/nprot.2009.89</pub-id></element-citation></ref><ref id="R39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Høydal</surname><given-names>ØA</given-names></name><name><surname>Skytøen</surname><given-names>ER</given-names></name><name><surname>Andersson</surname><given-names>SO</given-names></name><name><surname>Moser</surname><given-names>M-B</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><article-title>Object-vector coding in the medial entorhinal cortex</article-title><source>Nature</source><year>2019</year><volume>568</volume><issue>7752</issue><fpage>400</fpage><lpage>404</lpage><pub-id pub-id-type="pmid">30944479</pub-id></element-citation></ref><ref id="R40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ibarra-Castañeda</surname><given-names>N</given-names></name><name><surname>Moy-Lopez</surname><given-names>NA</given-names></name><name><surname>González-Pérez</surname><given-names>O</given-names></name></person-group><article-title>Tactile information from the vibrissal system modulates hippocampal functioning</article-title><source>Current Research in Neurobiology</source><year>2022</year><volume>3</volume><elocation-id>100034</elocation-id><pub-id pub-id-type="pmcid">PMC9140216</pub-id><pub-id pub-id-type="pmid">35647562</pub-id><pub-id pub-id-type="doi">10.1016/j.crneur.2022.100034</pub-id></element-citation></ref><ref id="R41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Itskov</surname><given-names>PM</given-names></name><name><surname>Vinnik</surname><given-names>E</given-names></name><name><surname>Diamond</surname><given-names>ME</given-names></name></person-group><article-title>Hippocampal Representation of Touch-Guided Behavior in Rats: Persistent and Independent Traces of Stimulus and Reward Location</article-title><source>PLoS ONE</source><year>2011</year><volume>6</volume><issue>1</issue><elocation-id>e16462</elocation-id><pub-id pub-id-type="pmcid">PMC3030589</pub-id><pub-id pub-id-type="pmid">21305039</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0016462</pub-id></element-citation></ref><ref id="R42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kentros</surname><given-names>CG</given-names></name><name><surname>Agnihotri</surname><given-names>NT</given-names></name><name><surname>Streater</surname><given-names>S</given-names></name><name><surname>Hawkins</surname><given-names>RD</given-names></name><name><surname>Kandel</surname><given-names>ER</given-names></name></person-group><article-title>Increased attention to spatial context increases both place field stability and spatial memory</article-title><source>Neuron</source><year>2004</year><volume>42</volume><issue>2</issue><fpage>283</fpage><lpage>295</lpage><pub-id pub-id-type="pmid">15091343</pub-id></element-citation></ref><ref id="R43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knutsen</surname><given-names>PM</given-names></name><name><surname>Ahissar</surname><given-names>E</given-names></name></person-group><article-title>Orthogonal coding of object location</article-title><source>Trends in Neurosciences</source><year>2009</year><volume>32</volume><issue>2</issue><fpage>101</fpage><lpage>109</lpage><pub-id pub-id-type="pmid">19070909</pub-id></element-citation></ref><ref id="R44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Landeta</surname><given-names>ABd</given-names></name><name><surname>Pereyra</surname><given-names>M</given-names></name><name><surname>Medina</surname><given-names>JH</given-names></name><name><surname>Katche</surname><given-names>C</given-names></name></person-group><article-title>Anterior retrosplenial cortex is required for long-term object recognition memory</article-title><source>Scientific Reports</source><year>2020</year><volume>10</volume><issue>1</issue><elocation-id>4002</elocation-id><pub-id pub-id-type="pmcid">PMC7062718</pub-id><pub-id pub-id-type="pmid">32152383</pub-id><pub-id pub-id-type="doi">10.1038/s41598-020-60937-z</pub-id></element-citation></ref><ref id="R45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maguire</surname><given-names>E</given-names></name></person-group><article-title>The retrosplenial contribution to human navigation: A review of lesion and neuroimaging findings</article-title><source>Scandinavian Journal of Psychology</source><year>2001</year><volume>42</volume><issue>3</issue><fpage>225</fpage><lpage>238</lpage><pub-id pub-id-type="pmid">11501737</pub-id></element-citation></ref><ref id="R46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mao</surname><given-names>D</given-names></name><name><surname>Kandler</surname><given-names>S</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>Bonin</surname><given-names>V</given-names></name></person-group><article-title>Sparse orthogonal population representation of spatial context in the retrosplenial cortex</article-title><source>Nature communications</source><year>2017</year><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="pmcid">PMC5557927</pub-id><pub-id pub-id-type="pmid">28811461</pub-id><pub-id pub-id-type="doi">10.1038/s41467-017-00180-9</pub-id></element-citation></ref><ref id="R47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mao</surname><given-names>D</given-names></name><name><surname>Neumann</surname><given-names>AR</given-names></name><name><surname>Sun</surname><given-names>J</given-names></name><name><surname>Bonin</surname><given-names>V</given-names></name><name><surname>Mohajerani</surname><given-names>MH</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><article-title>Hippocampus-dependent emergence of spatial sequence coding in retrosplenial cortex</article-title><source>Proceedings of the National Academy of Sciences</source><year>2018</year><volume>115</volume><issue>31</issue><fpage>8015</fpage><lpage>8018</lpage><pub-id pub-id-type="pmcid">PMC6077725</pub-id><pub-id pub-id-type="pmid">30012620</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1803224115</pub-id></element-citation></ref><ref id="R48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merre</surname><given-names>PL</given-names></name><name><surname>Esmaeili</surname><given-names>V</given-names></name><name><surname>Charrière</surname><given-names>E</given-names></name><name><surname>Galan</surname><given-names>K</given-names></name><name><surname>Salin</surname><given-names>P-A</given-names></name><name><surname>Petersen</surname><given-names>CC</given-names></name><name><surname>Crochet</surname><given-names>S</given-names></name></person-group><article-title>Reward-Based Learning Drives Rapid Sensory Signals in Medial Prefrontal Cortex and Dorsal Hippocampus Necessary for Goal-Directed Behavior</article-title><source>Neuron</source><year>2018</year><volume>97</volume><issue>1</issue><fpage>83</fpage><lpage>91</lpage><elocation-id>e5</elocation-id><pub-id pub-id-type="pmcid">PMC5766832</pub-id><pub-id pub-id-type="pmid">29249287</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2017.11.031</pub-id></element-citation></ref><ref id="R49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>AM</given-names></name><name><surname>Mau</surname><given-names>W</given-names></name><name><surname>Smith</surname><given-names>DM</given-names></name></person-group><article-title>Retrosplenial Cortical Representations of Space and Future Goal Locations Develop with Learning</article-title><source>Current Biology</source><year>2019</year><volume>29</volume><issue>12</issue><fpage>2083</fpage><lpage>2090</lpage><elocation-id>e4</elocation-id><pub-id pub-id-type="pmcid">PMC6637961</pub-id><pub-id pub-id-type="pmid">31178316</pub-id><pub-id pub-id-type="doi">10.1016/j.cub.2019.05.034</pub-id></element-citation></ref><ref id="R50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>AMP</given-names></name><name><surname>Vedder</surname><given-names>LC</given-names></name><name><surname>Law</surname><given-names>LM</given-names></name><name><surname>Smith</surname><given-names>DM</given-names></name></person-group><article-title>Cues, context, and long-term memory: the role of the retrosplenial cortex in spatial cognition</article-title><source>Frontiers in human neuroscience</source><year>2014</year><volume>8</volume><fpage>586</fpage><pub-id pub-id-type="pmcid">PMC4122222</pub-id><pub-id pub-id-type="pmid">25140141</pub-id><pub-id pub-id-type="doi">10.3389/fnhum.2014.00586</pub-id></element-citation></ref><ref id="R51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mitchell</surname><given-names>AS</given-names></name><name><surname>Czajkowski</surname><given-names>R</given-names></name><name><surname>Zhang</surname><given-names>N</given-names></name><name><surname>Jeffery</surname><given-names>K</given-names></name><name><surname>Nelson</surname><given-names>AJD</given-names></name></person-group><article-title>Retrosplenial cortex and its role in spatial cognition</article-title><source>Brain and Neuroscience Advances</source><year>2018</year><volume>2</volume><issue>3</issue><elocation-id>239821281875709</elocation-id><pub-id pub-id-type="pmcid">PMC6095108</pub-id><pub-id pub-id-type="pmid">30221204</pub-id><pub-id pub-id-type="doi">10.1177/2398212818757098</pub-id></element-citation></ref><ref id="R52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mohan</surname><given-names>H</given-names></name><name><surname>Gallero-Salas</surname><given-names>Y</given-names></name><name><surname>Carta</surname><given-names>S</given-names></name><name><surname>Sacramento</surname><given-names>J</given-names></name><name><surname>Laurenczy</surname><given-names>B</given-names></name><name><surname>Sumanovski</surname><given-names>LT</given-names></name><name><surname>Kock</surname><given-names>CPJd</given-names></name><name><surname>Helmchen</surname><given-names>F</given-names></name><name><surname>Sachidhanandam</surname><given-names>S</given-names></name></person-group><article-title>Sensory representation of an auditory cued tactile stimulus in the posterior parietal cortex of the mouse</article-title><source>Scientific Reports</source><year>2018a</year><volume>8</volume><issue>1</issue><elocation-id>7739</elocation-id><pub-id pub-id-type="pmcid">PMC5958066</pub-id><pub-id pub-id-type="pmid">29773806</pub-id><pub-id pub-id-type="doi">10.1038/s41598-018-25891-x</pub-id></element-citation></ref><ref id="R53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mohan</surname><given-names>H</given-names></name><name><surname>Haan</surname><given-names>Rd</given-names></name><name><surname>Broersen</surname><given-names>R</given-names></name><name><surname>Pieneman</surname><given-names>AW</given-names></name><name><surname>Helmchen</surname><given-names>F</given-names></name><name><surname>Staiger</surname><given-names>JF</given-names></name><name><surname>Mansvelder</surname><given-names>HD</given-names></name><name><surname>Kock</surname><given-names>CPJd</given-names></name></person-group><article-title>Functional Architecture and Encoding of Tactile Sensorimotor Behavior in Rat Posterior Parietal Cortex</article-title><source>The Journal of Neuroscience</source><year>2019</year><volume>39</volume><issue>37</issue><fpage>7332</fpage><lpage>7343</lpage><pub-id pub-id-type="pmcid">PMC6759035</pub-id><pub-id pub-id-type="pmid">31332000</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0693-19.2019</pub-id></element-citation></ref><ref id="R54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mohan</surname><given-names>H</given-names></name><name><surname>Haan</surname><given-names>Rd</given-names></name><name><surname>Mansvelder</surname><given-names>HD</given-names></name><name><surname>Kock</surname><given-names>CPd</given-names></name></person-group><article-title>The posterior parietal cortex as integrative hub for whisker sensorimotor information</article-title><source>Neuroscience</source><year>2018b</year><volume>368</volume><fpage>240</fpage><lpage>245</lpage><pub-id pub-id-type="pmid">28642168</pub-id></element-citation></ref><ref id="R55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nikbakht</surname><given-names>N</given-names></name><name><surname>Diamond</surname><given-names>ME</given-names></name></person-group><article-title>Conserved visual capacity of rats under red light</article-title><source>eLife</source><year>2021</year><volume>10</volume><elocation-id>e66429</elocation-id><pub-id pub-id-type="pmcid">PMC8360654</pub-id><pub-id pub-id-type="pmid">34282724</pub-id><pub-id pub-id-type="doi">10.7554/eLife.66429</pub-id></element-citation></ref><ref id="R56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Connor</surname><given-names>DH</given-names></name><name><surname>Clack</surname><given-names>NG</given-names></name><name><surname>Huber</surname><given-names>D</given-names></name><name><surname>Komiyama</surname><given-names>T</given-names></name><name><surname>Myers</surname><given-names>EW</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name></person-group><article-title>Vibrissa-based object localization in head-fixed mice</article-title><source>The Journal of neuroscience : the official journal of the Society for Neuroscience</source><year>2010</year><volume>30</volume><issue>5</issue><fpage>1947</fpage><lpage>1967</lpage><pub-id pub-id-type="pmcid">PMC6634009</pub-id><pub-id pub-id-type="pmid">20130203</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3762-09.2010</pub-id></element-citation></ref><ref id="R57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Keefe</surname><given-names>J</given-names></name></person-group><article-title>Place units in the hippocampus of the freely moving rat</article-title><source>Experimental Neurology</source><year>1976</year><volume>51</volume><issue>1</issue><fpage>78</fpage><lpage>109</lpage><pub-id pub-id-type="pmid">1261644</pub-id></element-citation></ref><ref id="R58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Dostrovsky</surname><given-names>J</given-names></name></person-group><article-title>The hippocampus as a spatial map. Preliminary evidence from unit activity in the freely-moving rat</article-title><source>Brain Research</source><year>1971</year><volume>34</volume><issue>1</issue><fpage>171</fpage><lpage>175</lpage><pub-id pub-id-type="pmid">5124915</pub-id></element-citation></ref><ref id="R59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olcese</surname><given-names>U</given-names></name><name><surname>Iurilli</surname><given-names>G</given-names></name><name><surname>Medini</surname><given-names>P</given-names></name></person-group><article-title>Cellular and Synaptic Architecture of Multisensory Integration in the Mouse Neocortex</article-title><source>Neuron</source><year>2013</year><volume>79</volume><issue>3</issue><fpage>579</fpage><lpage>593</lpage><pub-id pub-id-type="pmid">23850594</pub-id></element-citation></ref><ref id="R60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ottink</surname><given-names>L</given-names></name><name><surname>Hoogendonk</surname><given-names>M</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name><name><surname>Geest</surname><given-names>TMVd</given-names></name><name><surname>Wezel</surname><given-names>RJAV</given-names></name></person-group><article-title>Cognitive map formation through haptic and visual exploration of tactile city-like maps</article-title><source>Scientific Reports</source><year>2021</year><volume>11</volume><issue>1</issue><elocation-id>15254</elocation-id><pub-id pub-id-type="pmcid">PMC8316501</pub-id><pub-id pub-id-type="pmid">34315940</pub-id><pub-id pub-id-type="doi">10.1038/s41598-021-94778-1</pub-id></element-citation></ref><ref id="R61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Connor</surname><given-names>DH</given-names></name><name><surname>Krubitzer</surname><given-names>LE</given-names></name><name><surname>Sliman</surname><given-names>JB</given-names></name></person-group><article-title>Of mice and monkeys: Somatosensory processing in two prominent animal models</article-title><source>Progress in Neurobiology</source><year>2021</year><volume>201</volume><elocation-id>102008</elocation-id><pub-id pub-id-type="pmcid">PMC8096687</pub-id><pub-id pub-id-type="pmid">33587956</pub-id><pub-id pub-id-type="doi">10.1016/j.pneurobio.2021.102008</pub-id></element-citation></ref><ref id="R62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pammer</surname><given-names>L</given-names></name><name><surname>O’Connor</surname><given-names>DH</given-names></name><name><surname>Hires</surname><given-names>SA</given-names></name><name><surname>Clack</surname><given-names>NG</given-names></name><name><surname>Huber</surname><given-names>D</given-names></name><name><surname>Myers</surname><given-names>EW</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name></person-group><article-title>The Mechanical Variables Underlying Object Localization along the Axis of the Whisker</article-title><source>Journal of Neuroscience</source><year>2013</year><volume>33</volume><issue>16</issue><fpage>6726</fpage><lpage>6741</lpage><pub-id pub-id-type="pmcid">PMC3733083</pub-id><pub-id pub-id-type="pmid">23595731</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4316-12.2013</pub-id></element-citation></ref><ref id="R63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pereira</surname><given-names>A</given-names></name><name><surname>Ribeiro</surname><given-names>S</given-names></name><name><surname>Wiest</surname><given-names>M</given-names></name><name><surname>Moore</surname><given-names>LC</given-names></name><name><surname>Pantoja</surname><given-names>J</given-names></name><name><surname>Lin</surname><given-names>S-C</given-names></name><name><surname>Nicolelis</surname><given-names>MAL</given-names></name></person-group><article-title>Processing of tactile information by the hippocampus</article-title><source>Proceedings of the National Academy of Sciences</source><year>2007</year><volume>104</volume><issue>46</issue><fpage>18286</fpage><lpage>18291</lpage><pub-id pub-id-type="pmcid">PMC2084335</pub-id><pub-id pub-id-type="pmid">17989221</pub-id><pub-id pub-id-type="doi">10.1073/pnas.0708611104</pub-id></element-citation></ref><ref id="R64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petersen</surname><given-names>CCH</given-names></name></person-group><article-title>The Functional Organization of the Barrel Cortex</article-title><source>Neuron</source><year>2007</year><volume>56</volume><issue>2</issue><fpage>339</fpage><lpage>355</lpage><pub-id pub-id-type="pmid">17964250</pub-id></element-citation></ref><ref id="R65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pho</surname><given-names>GN</given-names></name><name><surname>Goard</surname><given-names>MJ</given-names></name><name><surname>Woodson</surname><given-names>J</given-names></name><name><surname>Crawford</surname><given-names>B</given-names></name><name><surname>Sur</surname><given-names>M</given-names></name></person-group><article-title>Task-dependent representations of stimulus and choice in mouse parietal cortex</article-title><source>Nature communications</source><year>2019</year><volume>9</volume><issue>1</issue><elocation-id>2596</elocation-id><pub-id pub-id-type="pmcid">PMC6030204</pub-id><pub-id pub-id-type="pmid">29968709</pub-id><pub-id pub-id-type="doi">10.1038/s41467-018-05012-y</pub-id></element-citation></ref><ref id="R66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pluta</surname><given-names>SR</given-names></name><name><surname>Lyall</surname><given-names>EH</given-names></name><name><surname>Telian</surname><given-names>GI</given-names></name><name><surname>Ryapolova-Webb</surname><given-names>E</given-names></name><name><surname>Adesnik</surname><given-names>H</given-names></name></person-group><article-title>Surround Integration Organizes a Spatial Map during Active Sensation</article-title><source>Neuron</source><year>2017</year><fpage>1</fpage><lpage>20</lpage><pub-id pub-id-type="pmcid">PMC5512457</pub-id><pub-id pub-id-type="pmid">28504117</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2017.04.026</pub-id></element-citation></ref><ref id="R67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pnevmatikakis</surname><given-names>Ea</given-names></name><name><surname>Soudry</surname><given-names>D</given-names></name><name><surname>Gao</surname><given-names>Y</given-names></name><name><surname>Machado</surname><given-names>TA</given-names></name><name><surname>Merel</surname><given-names>J</given-names></name><name><surname>Pfau</surname><given-names>D</given-names></name><name><surname>Reardon</surname><given-names>T</given-names></name><name><surname>Mu</surname><given-names>Y</given-names></name><name><surname>Lacefield</surname><given-names>C</given-names></name><name><surname>Yang</surname><given-names>W</given-names></name><name><surname>Ahrens</surname><given-names>M</given-names></name><etal/></person-group><article-title>Simultaneous Denoising, Deconvolution, and Demixing of Calcium Imaging Data</article-title><source>Neuron</source><year>2016</year><volume>89</volume><issue>2</issue><fpage>285</fpage><lpage>299</lpage><pub-id pub-id-type="pmcid">PMC4881387</pub-id><pub-id pub-id-type="pmid">26774160</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.037</pub-id></element-citation></ref><ref id="R68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poulter</surname><given-names>S</given-names></name><name><surname>Lee</surname><given-names>SA</given-names></name><name><surname>Dachtler</surname><given-names>J</given-names></name><name><surname>Wills</surname><given-names>TJ</given-names></name><name><surname>Lever</surname><given-names>C</given-names></name></person-group><article-title>Vector Trace cells in the Subiculum of the Hippocampal formation</article-title><source>Nature neuroscience</source><year>2021</year><volume>24</volume><issue>2</issue><fpage>266</fpage><lpage>275</lpage><pub-id pub-id-type="pmcid">PMC7116739</pub-id><pub-id pub-id-type="pmid">33349710</pub-id><pub-id pub-id-type="doi">10.1038/s41593-020-00761-w</pub-id></element-citation></ref><ref id="R69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Powell</surname><given-names>A</given-names></name><name><surname>Connelly</surname><given-names>WM</given-names></name><name><surname>Vasalauskaite</surname><given-names>A</given-names></name><name><surname>Nelson</surname><given-names>AJD</given-names></name><name><surname>Vann</surname><given-names>SD</given-names></name><name><surname>Aggleton</surname><given-names>JP</given-names></name><name><surname>Sengpiel</surname><given-names>F</given-names></name><name><surname>Ranson</surname><given-names>A</given-names></name></person-group><article-title>Stable Encoding of Visual Cues in the Mouse Retrosplenial Cortex</article-title><source>Cerebral Cortex (New York, NY)</source><year>2020</year><volume>30</volume><issue>8</issue><fpage>4424</fpage><lpage>4437</lpage><pub-id pub-id-type="pmcid">PMC7438634</pub-id><pub-id pub-id-type="pmid">32147692</pub-id><pub-id pub-id-type="doi">10.1093/cercor/bhaa030</pub-id></element-citation></ref><ref id="R70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rice</surname><given-names>FL</given-names></name><name><surname>Mance</surname><given-names>A</given-names></name><name><surname>Munger</surname><given-names>BL</given-names></name></person-group><article-title>A comparative light microscopic analysis of the sensory innervation of the mystacial pad. I. Innervation of vibrissal follicle-sinus complexes</article-title><source>Journal of Comparative Neurology</source><year>1986</year><volume>252</volume><issue>2</issue><fpage>154</fpage><lpage>174</lpage><pub-id pub-id-type="pmid">3782505</pub-id></element-citation></ref><ref id="R71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rivard</surname><given-names>B</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Lenck-Santini</surname><given-names>P-P</given-names></name><name><surname>Poucet</surname><given-names>B</given-names></name><name><surname>Muller</surname><given-names>RU</given-names></name></person-group><article-title>Representation of Objects in Space by Two Classes of Hippocampal Pyramidal Cells</article-title><source>The Journal of General Physiology</source><year>2004</year><volume>124</volume><issue>1</issue><fpage>9</fpage><lpage>25</lpage><pub-id pub-id-type="pmcid">PMC2229600</pub-id><pub-id pub-id-type="pmid">15197223</pub-id><pub-id pub-id-type="doi">10.1085/jgp.200409015</pub-id></element-citation></ref><ref id="R72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Save</surname><given-names>E</given-names></name><name><surname>Cressant</surname><given-names>A</given-names></name><name><surname>Thinus-Blanc</surname><given-names>C</given-names></name><name><surname>Poucet</surname><given-names>B</given-names></name></person-group><article-title>Spatial Firing of Hippocampal Place Cells in Blind Rats</article-title><source>The Journal of Neuroscience</source><year>1998</year><volume>18</volume><issue>5</issue><fpage>1818</fpage><lpage>1826</lpage><pub-id pub-id-type="pmcid">PMC6792629</pub-id><pub-id pub-id-type="pmid">9465006</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.18-05-01818.1998</pub-id></element-citation></ref><ref id="R73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sikes</surname><given-names>RW</given-names></name><name><surname>Vogt</surname><given-names>BA</given-names></name><name><surname>Swadlow</surname><given-names>HA</given-names></name></person-group><article-title>Neuronal responses in rabbit cingulate cortex linked to quick-phase eye movements during nystagmus</article-title><source>Journal of neurophysiology</source><year>1988</year><volume>59</volume><issue>3</issue><fpage>922</fpage><lpage>936</lpage><pub-id pub-id-type="pmid">3367203</pub-id></element-citation></ref><ref id="R74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>JB</given-names></name><name><surname>Alloway</surname><given-names>KD</given-names></name></person-group><article-title>Functional Specificity of Claustrum Connections in the Rat: Interhemispheric Communication between Specific Parts of Motor Cortex</article-title><source>Journal of Neuroscience</source><year>2010</year><volume>30</volume><issue>50</issue><fpage>16832</fpage><lpage>16844</lpage><pub-id pub-id-type="pmcid">PMC3010244</pub-id><pub-id pub-id-type="pmid">21159954</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4438-10.2010</pub-id></element-citation></ref><ref id="R75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sofroniew</surname><given-names>NJ</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name><name><surname>Lee</surname><given-names>AK</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name></person-group><article-title>Natural Whisker-Guided Behavior by Head-Fixed Mice in Tactile Virtual Reality</article-title><source>The Journal of Neuroscience</source><year>2014</year><volume>34</volume><issue>29</issue><fpage>9537</fpage><lpage>9550</lpage><pub-id pub-id-type="pmcid">PMC4099538</pub-id><pub-id pub-id-type="pmid">25031397</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0712-14.2014</pub-id></element-citation></ref><ref id="R76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stacho</surname><given-names>M</given-names></name><name><surname>Manahan-Vaughan</surname><given-names>D</given-names></name></person-group><article-title>Mechanistic flexibility of the retrosplenial cortex enables its contribution to spatial cognition</article-title><source>Trends in Neurosciences</source><year>2022</year><volume>45</volume><issue>4</issue><fpage>284</fpage><lpage>296</lpage><pub-id pub-id-type="pmid">35183378</pub-id></element-citation></ref><ref id="R77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sugar</surname><given-names>J</given-names></name><name><surname>Witter</surname><given-names>MP</given-names></name><name><surname>Strien</surname><given-names>NMv</given-names></name><name><surname>Cappaert</surname><given-names>NLM</given-names></name></person-group><article-title>The retrosplenial cortex: intrinsic connectivity and connections with the (para)hippocampal region in the rat. An interactive connectome</article-title><source>Frontiers in Neuroinformatics</source><year>2011</year><volume>5</volume><fpage>7</fpage><pub-id pub-id-type="pmcid">PMC3147162</pub-id><pub-id pub-id-type="pmid">21847380</pub-id><pub-id pub-id-type="doi">10.3389/fninf.2011.00007</pub-id></element-citation></ref><ref id="R78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsao</surname><given-names>A</given-names></name><name><surname>Moser</surname><given-names>M-B</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><article-title>Traces of experience in the lateral entorhinal cortex</article-title><source>Current biology</source><year>2013</year><volume>23</volume><issue>5</issue><fpage>399</fpage><lpage>405</lpage><pub-id pub-id-type="pmid">23434282</pub-id></element-citation></ref><ref id="R79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vann</surname><given-names>SD</given-names></name><name><surname>Aggleton</surname><given-names>JP</given-names></name><name><surname>Maguire</surname><given-names>EA</given-names></name></person-group><article-title>What does the retrosplenial cortex do?</article-title><source>Nature reviews. Neuroscience</source><year>2009</year><volume>10</volume><issue>11</issue><fpage>792</fpage><lpage>802</lpage><pub-id pub-id-type="pmid">19812579</pub-id></element-citation></ref><ref id="R80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vedder</surname><given-names>LC</given-names></name><name><surname>Miller</surname><given-names>AMP</given-names></name><name><surname>Harrison</surname><given-names>MB</given-names></name><name><surname>Smith</surname><given-names>DM</given-names></name></person-group><article-title>Retrosplenial Cortical Neurons Encode Navigational Cues, Trajectories and Reward Locations During Goal Directed Navigation</article-title><source>Cerebral Cortex</source><year>2016</year><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="pmcid">PMC6059095</pub-id><pub-id pub-id-type="pmid">27473323</pub-id><pub-id pub-id-type="doi">10.1093/cercor/bhw192</pub-id></element-citation></ref><ref id="R81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weible</surname><given-names>AP</given-names></name><name><surname>Rowland</surname><given-names>DC</given-names></name><name><surname>Monaghan</surname><given-names>CK</given-names></name><name><surname>Wolfgang</surname><given-names>NT</given-names></name><name><surname>Kentros</surname><given-names>CG</given-names></name></person-group><article-title>Neural Correlates of Long-Term Object Memory in the Mouse Anterior Cingulate Cortex</article-title><source>Journal of Neuroscience</source><year>2012</year><volume>32</volume><issue>16</issue><fpage>5598</fpage><lpage>5608</lpage><pub-id pub-id-type="pmcid">PMC6703503</pub-id><pub-id pub-id-type="pmid">22514321</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5265-11.2012</pub-id></element-citation></ref><ref id="R82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wijngaarden</surname><given-names>JBv</given-names></name><name><surname>Babl</surname><given-names>SS</given-names></name><name><surname>Ito</surname><given-names>HT</given-names></name></person-group><article-title>Entorhinal-retrosplenial circuits for allocentric-egocentric transformation of boundary coding</article-title><source>eLife</source><year>2020</year><volume>9</volume><elocation-id>e59816</elocation-id><pub-id pub-id-type="pmcid">PMC7609058</pub-id><pub-id pub-id-type="pmid">33138915</pub-id><pub-id pub-id-type="doi">10.7554/eLife.59816</pub-id></element-citation></ref><ref id="R83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Witter</surname><given-names>MP</given-names></name><name><surname>Doan</surname><given-names>TP</given-names></name><name><surname>Jacobsen</surname><given-names>B</given-names></name><name><surname>Nilssen</surname><given-names>ES</given-names></name><name><surname>Ohara</surname><given-names>S</given-names></name></person-group><article-title>Architecture of the Entorhinal Cortex A Review of Entorhinal Anatomy in Rodents with Some Comparative Notes</article-title><source>Frontiers in systems neuroscience</source><year>2017</year><volume>11</volume><fpage>46</fpage><pub-id pub-id-type="pmcid">PMC5488372</pub-id><pub-id pub-id-type="pmid">28701931</pub-id><pub-id pub-id-type="doi">10.3389/fnsys.2017.00046</pub-id></element-citation></ref><ref id="R84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolbers</surname><given-names>T</given-names></name><name><surname>Klatzky</surname><given-names>R</given-names></name><name><surname>Loomis</surname><given-names>J</given-names></name><name><surname>Wutte</surname><given-names>M</given-names></name><name><surname>Giudice</surname><given-names>N</given-names></name></person-group><article-title>Modality-Independent Coding of Spatial Layout in the Human Brain</article-title><source>Current Biology</source><year>2011</year><volume>21</volume><issue>11</issue><fpage>984</fpage><lpage>989</lpage><pub-id pub-id-type="pmcid">PMC3119034</pub-id><pub-id pub-id-type="pmid">21620708</pub-id><pub-id pub-id-type="doi">10.1016/j.cub.2011.04.038</pub-id></element-citation></ref><ref id="R85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wyss</surname><given-names>JM</given-names></name><name><surname>Groen</surname><given-names>Tv</given-names></name></person-group><article-title>Connections between the retrosplenial cortex and the hippocampal formation in the rat: a review</article-title><source>Hippocampus</source><year>1992</year><volume>2</volume><issue>1</issue><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="pmid">1308170</pub-id></element-citation></ref><ref id="R86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zahler</surname><given-names>SH</given-names></name><name><surname>Taylor</surname><given-names>DE</given-names></name><name><surname>Wong</surname><given-names>JY</given-names></name><name><surname>Adams</surname><given-names>JM</given-names></name><name><surname>Feinberg</surname><given-names>EH</given-names></name></person-group><article-title>Superior colliculus drives stimulus-evoked directionally biased saccades and attempted head movements in head-fixed mice</article-title><source>eLife</source><year>2021</year><volume>10</volume><elocation-id>e73081</elocation-id><pub-id pub-id-type="pmcid">PMC8747496</pub-id><pub-id pub-id-type="pmid">34970968</pub-id><pub-id pub-id-type="doi">10.7554/eLife.73081</pub-id></element-citation></ref><ref id="R87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>K</given-names></name><name><surname>Ginzburg</surname><given-names>I</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><article-title>Interpreting neuronal population activity by reconstruction: unified framework with application to hippocampal place cells</article-title><source>Journal of neurophysiology</source><year>1998</year><volume>79</volume><issue>2</issue><fpage>1017</fpage><lpage>1044</lpage><pub-id pub-id-type="pmid">9463459</pub-id></element-citation></ref><ref id="R88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>X</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Spruston</surname><given-names>N</given-names></name><name><surname>Magee</surname><given-names>JC</given-names></name></person-group><article-title>Membrane potential dynamics underlying context-dependent sensory responses in the hippocampus</article-title><source>Nature Neuroscience</source><year>2020</year><volume>23</volume><issue>7</issue><fpage>881</fpage><lpage>891</lpage><pub-id pub-id-type="pmid">32451487</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>Responses to tactile objects during a spatial task in darkness.</title><p>(<bold>A</bold>) Head-fixed mouse running laps in darkness to find the location of a water reward in a tactile virtual reality. T1 and T2 are the locations along the track where a tactile cue, controlled in a closed loop by running speed, brushes across the whiskers, simulating the sensation of running past an object. S is a 1 cm long sandpaper strip on the running wheel just before the reward location. (<bold>B</bold>) Whisker imaging using infrared (940 nm) illumination. The first frame is a cartoon outlining the mouse’s head and whiskers (black), waterspout (blue), and tactile object (red). (<bold>C</bold>) (Top) Mean ± SD running speed. (Bottom) Lick probability (8 mice, 10 sessions). (<bold>D</bold>) (Top) Confocal fluorescence image of coronal brain slice and microscope objective above agranular RSC (Thy1-GCaMP6s / GP 4.3 mice). (Bottom) Two-photon fluorescence image showing a typical field of view (FOV) of layer 2/3 neurons in agranular RSC (124 <italic>μ</italic>m deep). (Right) Example fluorescence traces (fractional change of fluorescence, dF/F) during four laps, and bottom traces showing the mouse’s position and running speed. Orange traces show deconvolved dF/F. (<bold>E</bold>) Examples of four position-tuned (left column) and four object location-tuned cells (right column). Deconvolved activity for 30 consecutive laps. Red lines indicate the movement onset of the tactile object. (<bold>F</bold>) Average response of all position-tuned cells and object location-tuned cells, sorted according to the position of peak response. White lines indicate the movement onset of the tactile object (8 mice, 10 FOVs). (<bold>G</bold>) Percentage of cell types (8 mice, 10 FOVs, 3120 cells in total, 1088 position-tuned cells, 370 object location cells). (<bold>H</bold>) (Left) Distribution of the maximum amplitude (dF/F) for all position-tuned cells (black) and object location cells (red). Right: Distribution of tuning curve width (8 mice, 10 FOVs, 1088 position-tuned cells, 370 object location cells). Kolmogorov-Smirnoff test for max dF/F: p = 4 x 10-4, and for tuning curve width: p = 2.7 x 10-19. (<bold>I</bold>) Percentage of object location cells (mean ± SEM) in: (1) Control mice exposed to the tactile object (“whiskers”, 8 mice, 10 FOVs, 370 out of 3120 cells), (2) in mice exposed to tactile objects but trained without contralateral whiskers (“no whiskers”, 3 mice, 6 FOVs, 40 cells out of 1448 cells), and (3) in mice with intact whiskers but without tactile objects (“no tactile object”, 2 mice, 3 FOVs, 20 out of 734 cells). (<bold>J</bold>) Spatial organization of cells in a typical FOV. Only position-tuned (black) and object location cells (red) are shown (184 position-tuned cells and 70 object location cells).</p></caption><graphic xlink:href="EMS158246-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Responses to tactile objects are task specific.</title><p>(<bold>A</bold>)(Left) Cartoons showing the three different task conditions. (Top) “Goal oriented”: Mice ran laps to find water rewards while encountering tactile objects along the path. (Middle) “Passive stimulation”: The running wheel was clamped to immobilize the mouse and playback tactile stimuli were provided at random time intervals separated by at least 5 seconds. (Bottom) “Unengaged”: Mice were free to run but there were no rewards, and tactile stimuli occurred at random time intervals. (<bold>B</bold>) Example cells illustrating the diversity of responses (mean ± SEM). Left example cell responded only in the goal-oriented task. The other two example cells responded under multiple task conditions. (<bold>C</bold>) Percentage of cells classified as object location cells under the goal-oriented condition that were also responsive to tactile stimuli under the other task conditions (3 mice, 4 FOVs, 1271 cell recorded in total, “goal-oriented”, 100 %; “passive stimulation”, 16.1 ± 2.4 %; “unengaged”, 26.6 ± 5.4 %). (<bold>D</bold>) Touch response amplitude under each task condition (mean ± SEM, Mann Whitney-U test, “ns” p-value = 0.48; <italic>**</italic> p-value = 0.02; <italic>* * *</italic> p-value = 7.7 ·10<sup>−4</sup>). (<bold>E</bold>) Venn diagram showing the percentage of object-responsive cells under different task conditions.</p></caption><graphic xlink:href="EMS158246-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Responses to tactile objects are visual context dependent.</title><p>(<bold>A</bold>) Mice performed the spatial task while the visual context changed by adjusting the ambient luminance every ~ 50 laps during a session. First, mice ran in complete darkness (“no light”), then under dim ambient light conditions (“dim light”), and finally under bright light conditions (“bright light”). (<bold>B</bold>) Example cells (deconvolved dF/F). Cell #1 only responds in the dark, Cell #2 only when light is present, and Cell #3 responds under all three conditions. (<bold>C</bold>) Percentage of object-responsive cells (left) and position-tuned cells (middle) in each visual context (1510 cells from 5 mice, 5 FOVs; object-responsive cells: “no light” 8.0 ± 1.4 %; “dim light” 16.1 ± 1.0 %; “bright light” 19.1 ± 3.9 %; Position-tuned cells: “no light” 21.4 ± 6.0 %; “dim light” 23.2 ± 3.5 %; “bright light” 27.0 ± 2.4 %). Right: Relative change of classified cells across visual contexts normalized to the task in darkness. (<bold>D</bold>) Single neuron classification across visual contexts (red, object-responsive cell; black, position-tuned cell). Only cells classified in at least one context were included. (<bold>E</bold>) Percentage of object location- and position-tuned cells that keep their tuning identity across all visual contexts (Object location cells 25.4 %; Position-tuned cells 27.4 %). (<bold>F</bold>) Venn diagram of the number of object-responsive cells in each visual context.</p></caption><graphic xlink:href="EMS158246-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>RSC develops predictive responses to upcoming tactile objects.</title><p>(<bold>A</bold>) Average response of all object location cells, sorted according to the position of peak response (reproduced from <xref ref-type="fig" rid="F1">Figure 1F</xref>). White lines indicate the movement onset of the tactile object. Red boxes indicate cells classified as predictive cells (8 mice, 10 FOVs, 370 object location cells out of 3120 cells). (<bold>B</bold>) Example predictive cells. (Top) Neuronal responses during 50 laps (deconvolved dF/F). Black trace shows the average response. Red lines indicate tactile object movement onset. (Middle) Median running speed. Blue lines indicate the 25th and 75th percentile. (Bottom) Normalized deconvolved dF/F aligned to tactile object onset time. (<bold>C</bold>) Distribution of the response onset of predictive cells aligned to tactile object movement onset, shown on a spatial axis (left) and time axis (right). (<bold>D</bold>) Percentage of predictive- and non-predictive cells among object location neurons.</p></caption><graphic xlink:href="EMS158246-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>Memory traces of tactile object location in RSC.</title><p>(<bold>A</bold>) (Left) Half-way a behavior session, the first tactile object was randomly omitted in 50 % of laps. (Right) For visualization, we sorted the laps according to whether the tactile object was present or not. (<bold>B</bold>) Two example object location cells. The non-trace cell example stopped responding when the tactile object was omitted. The trace cell example continued to respond in the absence of the tactile object. Red lines indicate the earliest possible contact time of the whiskers with the object. (<bold>C</bold>) Average response of all trace and non-trace cells, sorted by the position of peak response. The same cells are shown with the first object present (left) or omitted (right). White lines indicate earliest possible contact time of the whiskers with the object. Black line at the bottom shows the average across all cells (8 mice, 10 FOVs, 370 object location cells out of 3120 recorded cells). (<bold>D</bold>) (Top) Percentage of trace and non-trace cells. (Middle) Percentage of trace cells among predictive cells. (Bottom) Percentage of trace cells among non-predictive cells. (<bold>E</bold>) Mean ± SEM decoding error of position using only position-tuned neurons, with the tactile objects present in both locations (control, black), or when the first tactile object is omitted (blue). (<bold>F</bold>) Average response of all position-tuned cells with the peak of their place field at ± 20 cm from either of the two tactile objects. Average responses were sorted by the position of the peak response. (<bold>G</bold>) Percentage of position-tuned cells that were found in the 20 cm window before and after the tactile object. (<bold>H</bold>) Tuning curve width (mean ± SEM) of position-tuned cells in the 20 cm window before or after the tactile object (<italic>* * *</italic> p-value = 12 x 10<sup>−6</sup>, Mann Whitney-U test).</p></caption><graphic xlink:href="EMS158246-f005"/></fig></floats-group></article>