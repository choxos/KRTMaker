<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS157026</article-id><article-id pub-id-type="doi">10.1101/2022.11.09.515902</article-id><article-id pub-id-type="archive">PPR570084</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Cortico-ocular coupling in the service of episodic memory formation</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Popov</surname><given-names>Tzvetan</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Staudigl</surname><given-names>Tobias</given-names></name><xref ref-type="aff" rid="A2">2</xref></contrib></contrib-group><aff id="A1"><label>1</label>Methods of Plasticity Research, Department of Psychology, University of Zurich,Zurich, Switzerland</aff><aff id="A2"><label>2</label>Department of Psychology, Ludwig-Maximilians-Universität München, Munich, Germany</aff><author-notes><corresp id="CR1">Corresponding author: Tzvetan Popov <email>tzvetan.popov@uzh.ch</email>, Corresponding address: Methods of Plasticity Research Laboratory, Department of Psychology, University of Zurich, Binzmühlestrasse 14, CH-8050, Zurich, Switzerland</corresp></author-notes><pub-date pub-type="nihms-submitted"><day>14</day><month>11</month><year>2022</year></pub-date><pub-date pub-type="preprint"><day>10</day><month>11</month><year>2022</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Encoding of visual information is a necessary requirement for most types of episodic memories. In search for a neural signature of memory formation, amplitude modulation of neural activity has been repeatedly shown to correlate with and suggested to be functionally involved in successful memory encoding. We here report a complementary view on why and how brain activity relates to memory, indicating a functional role of cortico-ocular interactions for episodic memory formation. Recording simultaneous magnetoencephalography and eye tracking in 35 human participants, we demonstrate that gaze variability and amplitude modulations of alpha/beta oscillations (10-20 Hz) in visual cortex covary and predict subsequent memory performance between and within participants. Amplitude variation during pre-stimulus baseline was associated with gaze direction variability, echoing the co-variation observed during scene encoding. We conclude that encoding of visual information engages unison coupling between oculomotor and visual areas in the service of memory formation.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">Encoding of visual material is a prerequisite for most of our episodic memories and typically begins with the exploration of the environment. Relying heavily on vision, humans tend to explore the environment by eye movements. These typically include, but are not limited to, micro- and macro saccades as well as fixations jointly contributing to the overall gaze pattern<sup><xref ref-type="bibr" rid="R1">1</xref></sup>. Evidence suggests a strong association between gaze patterns and episodic memory formation<sup><xref ref-type="bibr" rid="R2">2</xref>–<xref ref-type="bibr" rid="R7">7</xref></sup>. Visual scenes that were explored with more eye movements are more likely to be remembered than scenes explored with less eye movements<sup><xref ref-type="bibr" rid="R8">8</xref></sup>.These associations between memory encoding and gaze are complemented by studies showing that gaze pattern reinstatement during retrieval supports successful recollection<sup><xref ref-type="bibr" rid="R9">9</xref>–<xref ref-type="bibr" rid="R12">12</xref></sup>. Similarly, gaze patterns are reinstated during visual imagery <sup><xref ref-type="bibr" rid="R12">12</xref>–<xref ref-type="bibr" rid="R15">15</xref></sup> even without the guidance of retinal input, i.e. during full darkness<sup><xref ref-type="bibr" rid="R16">16</xref></sup>.</p><p id="P3">Electro- and magnetoencephalographic studies confirm a robust power modulation of alpha/beta oscillatory activity (appr. range 10-20Hz) during the encoding of items that is predictive of later memory performance: alpha/beta power during later remembered items is reduced as compared to later forgotten items, an observation termed “subsequent memory effect” (SME<sup><xref ref-type="bibr" rid="R17">17</xref></sup>). Alpha/beta SMEs have been replicated consistently<sup><xref ref-type="bibr" rid="R18">18</xref>–<xref ref-type="bibr" rid="R23">23</xref></sup>, with remarkable specificity of alpha/beta power decreases during successful memory encoding<sup><xref ref-type="bibr" rid="R24">24</xref>–<xref ref-type="bibr" rid="R30">30</xref></sup>. This is of particular relevance as these alpha/beta effects have been interpreted as the mechanism by which the cortex tracks and organizes representations of the stimulus input to be fed forward to downstream memory circuits. According to these ideas, alpha/beta activity is functionally involved in successful episodic memory formation<sup><xref ref-type="bibr" rid="R24">24</xref>,<xref ref-type="bibr" rid="R31">31</xref>,<xref ref-type="bibr" rid="R32">32</xref></sup>.</p><p id="P4">Complementing such cognitive interpretations, a recent account of alpha/beta activity argues for a view closer to the biological implementation of the association between alpha/beta power modulations and oculomotor action<sup><xref ref-type="bibr" rid="R33">33</xref></sup>. Building on recent evidence demonstrating this close relationship in a variety of tasks<sup><xref ref-type="bibr" rid="R34">34</xref>–<xref ref-type="bibr" rid="R36">36</xref></sup>, the account postulates a fundamental and domain-general functional organization linking visual cortical signals to oculomotor action. The topographic modulation of alpha power (i.e. power reduction) was associated with consistent eye movements towards the contralateral visual hemifield<sup><xref ref-type="bibr" rid="R36">36</xref>–<xref ref-type="bibr" rid="R38">38</xref></sup>. We here set out to test the link between eye movements and alpha/beta activity in the context of episodic memory formation.</p><p id="P5">We hypothesize that alpha/beta power modulations link to episodic memory formation through consistent biases in gaze patterns. Thirty-five participants performed a memory task while simultaneously tracking eye movements and monitoring brain activity using magnetoencephalography (MEG). Gaze bias analyses revealed a robust gaze-related SME confirming that higher levels of visual exploration are associated with better memory performance. Crucially, high subjective confidence in correctly memorizing an item was predictive of gaze-related and alpha/beta SME. Moreover, splitting trials according to high versus low gaze bias revealed the typical alpha/beta SME over posterior sensors. During the baseline interval prior to scene encoding, spontaneous fluctuations of alpha/beta power reliably predicted the gaze direction variability, akin to the one observed during scene encoding. Exploratory analyses of the covariation between gaze direction and alpha/beta power confirmed a consistent relationship present throughout the entire recording and evident between and within participants.</p></sec><sec id="S2" sec-type="results"><title>Results</title><sec id="S3"><title>Memory performance evident in both gaze variability and power modulation of visual cortex activity</title><p id="P6">During the study phase, participants viewed visual scenes presented for 4 seconds. For each trial and participant, the simultaneously recorded eye tracking data were extracted and converted into 2D density heat maps with the x-axis representing the horizontal, y-axis vertical visual eccentricity. The density of gaze direction locations is color coded. Subsequently, a statistical contrast using non-parametric testing with clusters was performed<sup><xref ref-type="bibr" rid="R39">39</xref></sup>. This analysis revealed a robust gaze-related SME (<xref ref-type="fig" rid="F1">Figure 1A</xref>, cluster-permutation test, p &lt; 0.025; corrected for multiple comparisons across time and frequencies), indicating that, during the study phase, items that will be later remembered are characterized by a strong gaze bias away from fixation and towards various locations of the viewed scene. Quantification of the different eye movement types such as saccades and fixations using the EEG-EYE toolbox<sup><xref ref-type="bibr" rid="R40">40</xref>,<xref ref-type="bibr" rid="R41">41</xref></sup> yielded similar results (<xref ref-type="supplementary-material" rid="SD1">supplemental Figure S1</xref>). For later remembered items, participants made more fixations (M/STD = 2044/544) and saccades (M/STD = 2070/545), as compared to later forgotten items (fixations: M/STD= 691/350; saccades: M/STD = 703/364). A significant condition difference was confirmed for both, fixations (t<sub>34</sub> = 9.7, CI[1068 1637], p = 2.6977e-11, Cohen’s d = 1.64) and saccades (t<sub>34</sub> = 9.7, CI[1079 1653], p = 2.7457e-11, Cohen’s d = 1.63). In the test phase, participants correctly recognized 72.83 % (+/- 2.51 SEM) of the scenes on average, yielding a d-prime of 2.24 (+/- 0.09 SEM).</p><p id="P7">Applying a standard (i.e. in accordance with previous work in the field) subsequent memory analyses on the MEG data confirmed the well documented alpha/beta SME (<xref ref-type="fig" rid="F1">Figure 1B</xref>). Encoding of later remembered material was associated with a stronger alpha/beta decrease over occipital sensors (cluster-permutation test, p &lt; 0.025; corrected for multiple comparisons across time and frequencies). The co-variation of stronger scene exploration (i.e., stronger gaze biases away from fixation for later remembered items) and modulation of visual alpha/beta power (i.e., stronger decrease for later remembered items) was informative for the participant’s memory confidence. Items reported with high confidence in being correctly memorized displayed stronger gaze biases (exploration) during encoding (<xref ref-type="fig" rid="F1">Figure 1 C</xref> left, cluster-permutation test, p &lt; 0.025) and alpha/beta SMEs (<xref ref-type="fig" rid="F1">Figure 1 D</xref>, clusterpermutation test, p &lt; 0.025), as compared to items with lower confidence (<xref ref-type="fig" rid="F1">Figure 1C</xref> right). A potential alternative interpretation of the apparent relationship between eye movements and the modulation of visual alpha/beta power might be the subjective saliency of the stimulus material. Salience is hard to quantify objectively and strongly depends on subjective experience. Hence, some stimulus material could trigger both, variability in eye movements and alpha/beta power modulations. It could allow the conjecture that the apparent correlation between the two is driven by external stimulus factors. In order to test this alternative, we set out to explore a potential relationship between gaze variability and power modulation of ongoing alpha/beta activity using the data of the pre-stimulus (e.g. baseline) intervals during the study phase, where only a fixation cross instead of a visual scene was displayed. Participants were required and were successful in maintenance of central fixation, ranging within ±5° of horizontal and vertical visual angle (see <xref ref-type="supplementary-material" rid="SD1">Figure S2</xref>). We reasoned that, within participants, one could split the trials into high and low alpha/beta power (e.g. based on median split) during the pre-stimulus baseline interval. Subsequently, one could evaluate the distribution of gaze density around the required fixation. If the above conjecture is true, there should be no difference in the gaze variability between high and low alpha/beta power conditions, since the stimuli in the baseline period (that is, the fixation cross) did not vary in saliency. Conversely, differences in gaze bias would further confirm a co-varying relationship between the direction of gaze and modulation of visual alpha/beta power, independent of the task context and stimulus properties. The results of this analysis are illustrated in <xref ref-type="fig" rid="F1">Figure 1 E and F</xref>. Within participants, trials with less alpha/beta power were also associated with a gaze pattern that deviated more from fixation (<xref ref-type="fig" rid="F1">Figure 1 E</xref>). Conversely, high alpha/beta power during baseline was associated with reduction of the degrees of freedom in eye movements, resulting in less variability of gaze around the targeted (fixation) direction. This result echoes the observations made during stimulus presentation (e.g. <xref ref-type="fig" rid="F1">Figure 1 A,B</xref>), both in terms of the direction of the relationship (i.e. alpha/beta power decrease relates to higher gaze variability) and scalp topography (<xref ref-type="fig" rid="F1">Figure 1F</xref>).</p></sec><sec id="S4"><title>Gaze variability predicts both modulation of visual cortical activity and memory performance</title><p id="P8">Next we asked to what extend the inverse direction of high vs. low gaze variability will predict alpha/beta SMEs. Within participants we median split the trials during encoding into high and low gaze variability within the visual display area of high variability identified in <xref ref-type="fig" rid="F1">Figure 1A</xref> (i.e. positive cluster). Trivially, the group difference in gaze variability is significant per design (<xref ref-type="fig" rid="F2">Figure 2A</xref>). Importantly however this should not necessary hold for cortical alpha/beta power and/or memory performance. We observed that trials dominated with high gaze variability were also associated with stronger modulation of alpha/beta power over occipital sensors, akin to the alpha/beta SME topography observed in <xref ref-type="fig" rid="F1">Figure 1B</xref> (cluster-permutation test, p &lt; 0.02). Moreover, high gaze variability during encoding was associated with an increase in the number of later remembered items as compared to low gaze variability (<xref ref-type="fig" rid="F2">Figure 2C</xref>, left). The opposite relationship was observed for forgotten items (<xref ref-type="fig" rid="F2">Figure 2C</xref>, right). An alternative illustration of the same result is depicted in <xref ref-type="fig" rid="F2">Figure 2D</xref>. The effect size of the memory contrast (# items remembered vs. forgotten) was dependent upon the gaze exploration during encoding: high gaze variability is linked to better memory performance as compared to low gaze variability (<xref ref-type="fig" rid="F2">Figure 2D</xref>).</p></sec><sec id="S5"><title>Gaze variability and visual cortical activity are continuously coupled</title><p id="P9">Given the results described above, we next asked whether a co-fluctuation of gaze bias and alpha/beta power would be restricted to the memory task or could be a more general pattern. Specifically, we asked whether alpha/beta power and gaze bias would be correlated over the whole period of the experiment. The results of this analysis are summarized in <xref ref-type="fig" rid="F3">Figure 3</xref>.</p><p id="P10">First, we computed the time-frequency representation of power (TFR) for the entire recording per participant (M/SEM = 60.59/±2.01 min) and accounted for the presence of aperiodic activity <sup><xref ref-type="bibr" rid="R43">43</xref></sup>. For illustrative purposes, <xref ref-type="fig" rid="F3">Figure 3A</xref> illustrates the first 6 minutes in the recording of a representative participant. The TFR depicts the spontaneous power modulation of alpha (predominantly in 10-14 Hz) activity over occipital sensors. In addition, we extracted the fixation density for the horizontal direction averaged across the vertical direction. This fixation density signal can be visualized as a function of time with the horizontal viewing direction now illustrated on the y-axis (<xref ref-type="fig" rid="F3">Figure 3B</xref>). In both panels (<xref ref-type="fig" rid="F3">Figure 3 A and B</xref>), the power of the signals is range corrected (<italic>[x – min]/[max-min]</italic>) to vary between 0 and 1. The time series of alpha/beta power and fixation density can be extracted and overlaid (<xref ref-type="fig" rid="F3">Figure 3C</xref>) conveying a (descriptive) similarity between the variation in alpha/beta power and the variation in fixation maintenance. Using this approach, we computed Spearman’s rho correlations between both timeseries for the entire recording session in each participant. In addition, surrogate data was generated by circularly shifting both time series (1000 times) and computing the corresponding correlation. This analysis yielded two distributions of correlations that can be parametrically compared (<xref ref-type="fig" rid="F3">Figure 3D</xref>). For each participant we derived two correlation coefficients. These correlations obtained from the original data were significantly different from the one generated by the surrogate data (t<sub>(34)</sub>= 6.8, CI[0.12 0.22], p &lt; 7.4e-08, Cohen’s d= 1.1541). This effect was confirmed on the individual participant level, with 33 out of 35 participants showing a significant difference (<xref ref-type="supplementary-material" rid="SD1">Figure S3</xref>). Finally, we computed the coherence between the two timeseries to infer the frequency of any phase relationship in the covarion of gaze and occipital alpha/beta power. Both time courses were segmented into trials of 200 seconds length, and the coherence across trials between gaze and alpha/beta power time series was computed. We observed a consistent coherence at app. 0.18Hz (<xref ref-type="fig" rid="F3">Figure 3E</xref>, cluster permutation test, p &lt; 0.025, t &gt; 10, Cohen’s d &gt; 1.5) as compared to surrogate data generated after 1000 permutations of the trials. As illustrated in <xref ref-type="fig" rid="F3">Figure 3E</xref>, the permutation procedure effectively eliminated the temporal correspondence between alpha/beta power and gaze density time courses, reflected in a flatter coherence spectrum.</p></sec></sec><sec id="S6" sec-type="discussion"><title>Discussion</title><p id="P11">Previous research has shown that gaze patterns as well as amplitude modulation of neural activity in posterior cortex during encoding of visual scenes strongly predicts memory performance. However, gaze patterns and amplitude modulation have thus far been studied in isolation. Our findings indicate that we might be looking at two sides of the same coin: gaze patterns and amplitude modulations covary and jointly predict memory performance. We simultaneously recorded MEG and eye movements in a free viewing memory paradigm. To relate alpha/beta MEG activity as well gaze variability to successful encoding, we contrasted later remembered versus later forgotten study phase items. In line with many previous studies <sup><xref ref-type="bibr" rid="R18">18</xref>–<xref ref-type="bibr" rid="R30">30</xref></sup>, we find an alpha/beta SME, with greater decreases in 10-20 Hz power for later remembered as compared to later forgotten items. Importantly, we here demonstrate that gaze covaries with this well-established effect. During the presentation of later remembered items, gaze was directed away from the center to a greater extent than during later forgotten items. This gaze bias indicates that more extensive visual exploration correlates with a higher probability to remember the item, a finding in line with previous studies showing that the amount of saccades on complex visual stimuli predicts whether or not the stimulus will be remembered<sup><xref ref-type="bibr" rid="R8">8</xref></sup>. Just like the alpha/beta SME, the gaze-related SME also correlated with the reported confidence judgement. Items that were later remembered with high confidence displayed stronger gaze biases and stronger alpha/beta desynchronization than those items remembered with lower confidence. Moreover, we find that splitting the encoding EEG data between high vs. low gaze variability trials closely emulates the traditional alpha/beta SME, both in frequency and topography. Trials with high gaze bias display significantly stronger alpha/beta power decreases than trials with lower gaze bias. Contrasting subsequent memory performance based on gaze bias confirmed that higher gaze bias was predictive of successful memory performance. These results indicate that gaze variability and alpha/beta activity go hand in hand in service of memory formation, a notion in line with a previous study linking saccades and the phase of alpha/beta activity successful remembering<sup><xref ref-type="bibr" rid="R44">44</xref></sup>.</p><p id="P12">Generalizing the covariation of gaze and alpha/beta activity beyond memory encoding, we show that gaze covaries with spontaneous fluctuations of alpha/beta during the pre-stimulus baseline. Again, greater variation in gaze was correlated with larger decreases in alpha/beta power. Moving even further away from specific, task-related activity, we show that alpha/beta activity and gaze covary over the course of the whole experiment. Including an hour of simultaneous eye tracking and MEG recordings per participant, we show substantial covariation of alpha power and gaze that is task-independent. Taken together, these observations support the idea of a fundamental and domain-general link between visual alpha/beta activity and oculomotor action.</p><p id="P13">The present results are in line with recent studies indicating a strong link between eye movements and alpha/beta activity. Biases in gaze direction are associated with a topographically consistent decrease of alpha/beta power, independent of the stimulus modality (e.g. vision, audition)<sup><xref ref-type="bibr" rid="R35">35</xref></sup>, independent of retinal input and present during full darkness<sup><xref ref-type="bibr" rid="R33">33</xref></sup>. Similar associations between gaze bias and alpha/beta power modulation have recently been reported in the context of working memory<sup><xref ref-type="bibr" rid="R36">36</xref>,<xref ref-type="bibr" rid="R45">45</xref></sup>. Together with the here reported results, these studies make a strong case that the association between gaze and alpha/beta activity reflects a fundamental functional organization linking visual cortical signals to oculomotor action.</p><p id="P14">The present findings are also in line with previous studies showing a functionally relevant coordination of eye movements and brain activity. Eye movements affect the neural activity in- and outside visual areas<sup><xref ref-type="bibr" rid="R44">44</xref>,<xref ref-type="bibr" rid="R46">46</xref>–<xref ref-type="bibr" rid="R53">53</xref></sup>, as well as in brain areas crucial for episodic memory formation: neural activity in the primate hippocampus is sensitive to eye movements<sup><xref ref-type="bibr" rid="R54">54</xref>–<xref ref-type="bibr" rid="R58">58</xref></sup>. In particular, the phase of hippocampal low-frequency activity has been shown to be aligned to saccadic eye movements<sup><xref ref-type="bibr" rid="R59">59</xref>,<xref ref-type="bibr" rid="R60">60</xref></sup>, and the amount of alignment was found to be functionally relevant<sup><xref ref-type="bibr" rid="R61">61</xref>,<xref ref-type="bibr" rid="R62">62</xref></sup>. Such phase alignment could be a general motif in the nervous system to facilitate the organization of neural ensembles<sup><xref ref-type="bibr" rid="R63">63</xref></sup>. The exact temporal coordination of neural activity and eye movements could be brought about by efference copies<sup><xref ref-type="bibr" rid="R64">64</xref></sup>. These copies of motor commands branch off corticofugal projections and could, in principle, be distributed across many brain areas. If they are capable of inducing phase alignment, efference copies could trigger the alignment of neural activity across a broad range of areas and, thereby, facilitate neural processing and communication<sup><xref ref-type="bibr" rid="R65">65</xref>–<xref ref-type="bibr" rid="R67">67</xref></sup>.</p><p id="P15">We here demonstrate a link between eye movements and alpha/beta activity during the free viewing of visual scenes in the study phase of a memory paradigm. Alpha/beta SMEs during memory encoding are indeed a common finding, yet to what extent the present linkage between alpha/beta SME and gaze variability generalize across stimulus material such as faces and words<sup><xref ref-type="bibr" rid="R68">68</xref></sup> vs. visual scenes requires further examination. Moreover, one could argue that the present findings are limited to free viewing encoding conditions, as the majority of the studies investigating SMEs ask their research participants to maintain fixation. Hence, the observation of alpha/beta variation with gaze variability might be somewhat coincidental. We hypothesize that the present findings will generalize to such conditions as well. This prediction is based on the present observation that the alpha/beta-gaze relationship was, albeit weaker, also evident when the eyes do not move feely (e.g. maintain fixation during the baseline period, <xref ref-type="fig" rid="F1">Figure 1E,F</xref>). As fixation is not a stationary event but a process involving the control of miniature eye movements such as micro saccades<sup><xref ref-type="bibr" rid="R69">69</xref></sup>, a testable prediction is that independent of task instructions (fixation, free view), alpha/beta SME modulation should be also associated with gaze-related SME. An empirical question that can be examined in future studies.</p><p id="P16">In conclusion, we demonstrate that alpha/beta activity (10-20 Hz) in visual cortex and eye movements covary and jointly predict subsequent memory. Going beyond memory-related brain activity, we show that this covariation is task-independent and preserved over the course of hours. The present results thus support a complementary view on the role of alpha/beta activity, emphasizing its fundamental interrelation with oculomotor behavior.</p></sec><sec id="S7" sec-type="materials | methods"><title>Materials and Methods</title><p id="P17">Part of the present dataset has been previously analyzed and documented elsewhere<sup><xref ref-type="bibr" rid="R44">44</xref></sup>.</p><sec id="S8"><title>Ethic statement</title><p id="P18">Study enrollment followed the approval of the local ethics committee- commission for human related research CMO-2014/288 region Arnhem/Nijmegen, the Netherlands. Prior to participation all volunteers were given written informed consent in accordance with the Declaration of Helsinki.</p></sec><sec id="S9" sec-type="subjects"><title>Participants</title><p id="P19">A total of 48 participants were recruited. Thirty-five were included in the present study. Thirteen participants were excluded due to: not completing the study (N=7), excessive artifacts (N=3) and technical difficulties during acquisition (N=3). The included participants sample (24 female, age range 18-30, mean age 23.1y) reported no history of neurological and/or psychiatric diagnosis and had normal or corrected to normal vision.</p></sec><sec id="S10"><title>Task design and procedure</title><p id="P20">Visual scenes were presented to the participants projected onto a back-projection screen position in front of the participants inside a magnetically shielding room (MSR). The back-projection screen had the size of 39 × 46 cm corresponding to a visual angle of vertical 27° × 32° horizontal dva (degrees of visual angle). Three sets of visual scenes (100 scenes each) were used. Two sets were displayed during the study (encoding) and the test phase. The scenes in the third set served as lures and were presented exclusively during the test phase. Set assignment to study and test phase was counterbalanced across participants. A training session preceded the actual memory task to ensure participants familiarity with the task procedures. Nine additional scenes not used in the main experiment were shown during the training session. All participants were made aware about the memory test prior to data acquisition.</p><p id="P21">During the study phase, visual scenes (indoor and outdoor images) were displayed for 4 sec with the constrained that no more than 4 scenes from the same category could appear consecutively. Participants were instructed to to report via button press whether or not the current scene displayed was an indoor or outdoor image. The response was given during the display of a fixation cross with a variable duration between 1-2 sec presented after each scene. During scene viewing, participants were not required to maintain fixation but were allowed to freely explore the scenes.</p><p id="P22">A short distracter session was required after each study phase. This session consisted of solving simple mathematical problems (appr. 1 min), a simple saccade task during which participants had to saccade to various locations on the screen (5 min), eyes open and eyes closed data acquisition (appr. 1 min each). The purpose of this distracter session was to prevent participants from covert rehearsing.</p><p id="P23">The test phase followed thereafter. The three sets of images (200 old items from the study phase intermixed with 100 new items) were randomly presented for viewing duration of 4 sec. The randomization had the constrained that no more than 4 images of the same type (old/new) could be shown consecutively. Following each image presentation, a 6-point response scale was displayed. Participants were required to indicate whether the just presented image was “old” or “new” with the scale ranging from “very sure old”(1) to “very sure new”(6). The 6-point scale remained on the visual display until the participants response was given followed by a fixation cross of variable duration ranging between 0.75-1.25 sec.</p></sec><sec id="S11"><title>Data acquisition</title><p id="P24">Whole head magnetoencephalography (MEG) was acquired with a 275-axial gradiometer system (VSM MedTech/CTF MEG, Coquitlam, Canada) within the MSR. During data acquisition, the sampling frequency was set to 1200 Hz using a low-pass antialiasing filter at a cutoff frequency of 300 Hz. Ocular artifacts were monitored by horizontal and vertical electrooculogram using Ag/AgCl electrodes and a bipolar montage. Head movements were tracked continuously using 3 coils placed in the vicinity of the nasion and the left and right ear canals<sup><xref ref-type="bibr" rid="R70">70</xref></sup>. An Eyelink 1000 (SR Research) system was used to monitor horizontal and vertical eye movements of the left eye. Prior to data acquisition, eye tracker calibration was performed which involved the collection of gaze fixation samples from pre-defined positions (9 dots on a 3×3 grid) on the visual display. Raw eye tracking data was mapped to these pre-defined screen coordinates followed by a validation procedure to ensure sufficient correspondence between the position of the current gaze fixations and the one obtained during the preceding calibration. The calibration was accepted if the difference was &lt; 1° dva.</p></sec><sec id="S12"><title>Data preprocessing and analysis</title><sec id="S13"><title>MEG data</title><p id="P25">Offline data analyses was performed with the open source software for neuroelectric- and neuromagnetic data analysis (FieldTrip<sup><xref ref-type="bibr" rid="R71">71</xref></sup>). The continuous data was segmented around the events of interest (scene onsets) into epochs of 8 sec (3 sec baseline prior to event onset). Following a finite impulse response band-pass filter (1-40Hz) the epochs were re-segmented to exclude potential filter artifacts resulting in time range of -2.5 to 4.5 sec around the event onset. Oculo-muscular and cardiac artifacts were identified and removed from further analysis by means of independent component analysis (ICA). These procedures were applied to all data epochs extracted during the study (encoding) and test (retrieval) phase. Subsequently, for each epoch, time-frequency estimates of power were computed using a sliding window of 0.5 sec and a Hanning taper resulting in a frequency resolution of appr. 2Hz. The window slid every 50 ms within the range of -2 to 4 sec around the event onset. Power estimates were averaged across epochs for each condition separately, e.g. encoding (remembered/forgotten), retrieval (remembered/forgotten). Baseline correction using the time window of -1 to -.25 (encoding) and -.75 to -.25 (retrieval) was applied transforming the raw power estimates into dB change from pre-stimulus baseline. The number of trials used in the present analysis were N<sub>remembered</sub> = 145.15/30 (M/STD) and N<sub>forgotten</sub> = 54.77/30 (M/STD).</p><p id="P26">We followed a similar approach to split the epochs into high versus low pre-stimulus alpha power during scene encoding. Specifically, a Fast Fourier transform was applied to the data prior to stimulus onset (-1 to 0 sec), including all occipital sensors (see <xref ref-type="supplementary-material" rid="SD1">Figure S4</xref>). A Hanning taper was used, resulting in appr. 1 Hz frequency resolution. The mean power within the alpha/beta frequency range (10-20Hz) was extracted and averaged over all occipital sensors. Subsequently, trials with high and low alpha power were separated by means of median split. Using this subset of high and low alpha power trials, the power estimates were re-grouped and averaged over trials. Finally, the difference between the condition’s alpha power low minus alpha power high was computed.</p></sec><sec id="S14"><title>Gaze data</title><p id="P27">The raw eye tracking data was converted form voltage to pixel coordinates following the procedures described here <ext-link ext-link-type="uri" xlink:href="https://www.fieldtriptoolbox.org/getting_started/eyelink/#what-are-the-units-of-the-eye-tracker-data">https://www.fieldtriptoolbox.org/getting_started/eyelink/#what-are-the-units-of-the-eye-tracker-data</ext-link>. Gaze density was expressed as the 2D heat map according to the procedures described here (<ext-link ext-link-type="uri" xlink:href="https://stackoverflow.com/questions/46996206/matlab-creating-a-heatmap-to-visualize-density-of-2d-point-data">https://stackoverflow.com/questions/46996206/matlab-creating-a-heatmap-to-visualize-density-of-2d-point-data</ext-link>). Briefly, the scatter plot of all <italic>x</italic> and <italic>y</italic> positions was converted into an image array (using <italic>imagesc.m</italic> in MATLAB) after a 2-D convolution <italic>(conv2.m)</italic> with a Gaussian filter matrix <italic>G.</italic> For the given range of <italic>x</italic> and <italic>y</italic> coordinates denoted as <italic>xG</italic> and <italic>yG</italic> and width parameter sigma (in the present case set to 2.5), <italic>G</italic> = exp[-xG<sup>2</sup>/(2*sigma<sup>2</sup>) – yG<sup>2</sup>/(2*sigma<sup>2</sup>)]. After 2D conversion the eye tracking data was converted to a structure that can be read by FieldTrip akin to the one for time-frequency data. Subsequently, all approaches available for statistical treatment of time-frequency data could be applied to the gaze density data.</p></sec><sec id="S15"><title>Relationships between MEG and gaze data</title><p id="P28">In order to examine the relationship between the continuous MEG recording and the gaze variation as presented in <xref ref-type="fig" rid="F2">Figure 2</xref> the following procedures were utilized. First, the continuous data form occipital sensors was segmented into trials of 2 sec length. Following Fourier analysis as described above, the 1/f aperiodic component was removed from each trial using the <italic>specparam</italic> routines<sup><xref ref-type="bibr" rid="R72">72</xref></sup> allowing the parametrization and visualization of periodic components (e.g. alpha activity) in the continuous data. Subsequently, these trials were concatenated yielding a time-frequency representation of power (e.g. <xref ref-type="fig" rid="F2">Figure 2A</xref>). Next, for each trial, the corresponding gaze data was computed as described above, averaged along the vertical direction and concatenated, yielding a time by horizontal position spectrogram with color coded density of horizontal gaze direction (e.g. <xref ref-type="fig" rid="F2">Figure 2B</xref>). For each participant, the time course of occipital alpha power was extracted by averaging the spectral estimates across the dominant frequency band width (e.g. 10-14Hz) across all occipital sensors. The reason for taking 10-14Hz rather than alpha/beta activity is that in spontaneous recordings the dominant rhythm is alpha, whereas alpha/beta decreases are scored as function of baseline or some contrast that in this case we do not have. Instead we took the spontaneous signal exhibiting strongest power mostly in the 10-14Hz range. Similarly, the time course of gaze density averaged around fixation at 0 dva (± .5 horizontal dva) was extracted. These time courses were correlated using a bootstrapping resampling procedure with 1000 iterations yielding a distribution of correlations between the two time courses (e.g. <xref ref-type="fig" rid="F2">Figure 2D</xref>). Surrogate data was generated by circularly shifting the time series 1000 times, where at each iteration, the length of the time shift was randomly chosen ranging between 1s and the total duration of the recording. This procedure resulted in a surrogate distribution of correlations (e.g. <xref ref-type="fig" rid="F2">Figure 2D</xref>), against which the distribution of correlations obtained from the original data was compared. All correlation coefficients were transformed into z-scores (e.g. <italic>z = log((1+r) / (1- r))/2</italic>) prior to further statistical evaluation. Finally, the coherence between the MEG and gaze time series was computed. Given a sampling frequency of 0.5 Hz determined by the length of the trials used to derived these time courses (see above), the MEG and gaze data was first re-segmented into epochs of 200s length. A multi-taper approach<sup><xref ref-type="bibr" rid="R73">73</xref></sup> was used to estimate power and cross-spectral density for each trial padded with zeros at the begin and the end of each trial (500 sec in total). Three tapers were used covering the frequency range from 0 to Nyquist frequency (0.25Hz). The phase in the cross-spectra represents the phase difference between the oscillatory signals of the MEG and gaze time series, with consistent phase difference resulting in larger coherence values. Surrogate data was generated by permuting the trial order of the MEG and gaze data with respect to each other and computing coherence. This approach was repeated 1000 times and the resulting coherence values were averaged resulting in the surrogate coherence result presented in <xref ref-type="fig" rid="F2">Figure 2E</xref>.</p></sec><sec id="S16"><title>Statistics</title><p id="P29">Statistical control followed the cluster-based permutation framework <sup><xref ref-type="bibr" rid="R39">39</xref></sup>. This approach utilizes clustering across sensors, time points, and frequency (wherever appropriate). Multiple comparisons problem was addressed by using 1000 permutations and a two-tailed alpha threshold of 0.05 (p &lt; 0.025). Correlations were evaluated by utilizing Spearman’s correlation coefficient Rho.</p></sec></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplemental material</label><media xlink:href="EMS157026-supplement-Supplemental_material.pdf" mimetype="application" mime-subtype="pdf" id="d83aAdEbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S17"><title>Acknowledgements</title><p>The study was performed at the Donders Institute for Brain, Cognition and Behaviour. The authors would like to thank Ole Jensen and Christian F. Doeller for their involvement in conceptualizing the study. The authors would also like to thank all the participants volunteering in the experiment.</p><sec id="S18"><title>Funding</title><p>This work was supported by the European Union’s Horizon 2020 research and innovation program (grant number 661373) and the European Research Council (ERC-StG 802681) awarded to TS and the Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung (SNF) Grant 105314_207580 awarded to TP.</p></sec></ack><fn-group><fn id="FN1" fn-type="conflict"><p id="P30"><bold>Competing Interests statement</bold></p><p id="P31">The authors report no competing interests.</p></fn></fn-group><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Otero-Millan</surname><given-names>J</given-names></name><name><surname>Troncoso</surname><given-names>XG</given-names></name><name><surname>Macknik</surname><given-names>SL</given-names></name><name><surname>Serrano-Pedraza</surname><given-names>I</given-names></name><name><surname>Martinez-Conde</surname><given-names>S</given-names></name></person-group><article-title>Saccades and microsaccades during visual fixation, exploration, and search: foundations for a common saccadic generator</article-title><source>J Vis</source><year>2008</year><volume>8</volume><issue>21</issue><fpage>21</fpage><lpage>18</lpage><pub-id pub-id-type="doi">10.1167/8.14.21</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Damiano</surname><given-names>C</given-names></name><name><surname>Walther</surname><given-names>DB</given-names></name></person-group><article-title>Distinct roles of eye movements during memory encoding and retrieval</article-title><source>Cognition</source><year>2019</year><volume>184</volume><fpage>119</fpage><lpage>129</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2018.12.014</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fehlmann</surname><given-names>B</given-names></name><etal/></person-group><article-title>Visual Exploration at Higher Fixation Frequency Increases Subsequent Memory Recall</article-title><source>Cerebral cortex communications</source><year>2020</year><volume>1</volume><elocation-id>tgaa032</elocation-id><pub-id pub-id-type="doi">10.1093/texcom/tgaa032</pub-id></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Molitor</surname><given-names>RJ</given-names></name><name><surname>Ko</surname><given-names>PC</given-names></name><name><surname>Hussey</surname><given-names>EP</given-names></name><name><surname>Ally</surname><given-names>BA</given-names></name></person-group><article-title>Memory-related eye movements challenge behavioral measures of pattern completion and pattern separation</article-title><source>Hippocampus</source><year>2014</year><volume>24</volume><fpage>666</fpage><lpage>672</lpage><pub-id pub-id-type="doi">10.1002/hipo.22256</pub-id></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olsen</surname><given-names>RK</given-names></name><etal/></person-group><article-title>The relationship between eye movements and subsequent recognition: Evidence from individual differences and amnesia</article-title><source>Cortex; a journal devoted to the study of the nervous system and behavior</source><year>2016</year><volume>85</volume><fpage>182</fpage><lpage>193</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2016.10.007</pub-id></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kragel</surname><given-names>JE</given-names></name><name><surname>Voss</surname><given-names>JL</given-names></name></person-group><article-title>Looking for the neural basis of memory</article-title><source>Trends in cognitive sciences</source><year>2022</year><volume>26</volume><fpage>53</fpage><lpage>65</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2021.10.010</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Broers</surname><given-names>N</given-names></name><name><surname>Bainbridge</surname><given-names>WA</given-names></name><name><surname>Michel</surname><given-names>R</given-names></name><name><surname>Balestrieri</surname><given-names>E</given-names></name><name><surname>Busch</surname><given-names>NA</given-names></name></person-group><article-title>The extent and specificity of visual exploration determines the formation of recollected memories in complex scenes</article-title><source>J Vis</source><year>2022</year><volume>22</volume><issue>9</issue><pub-id pub-id-type="doi">10.1167/jov.22.11.9</pub-id></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Voss</surname><given-names>JL</given-names></name><name><surname>Bridge</surname><given-names>DJ</given-names></name><name><surname>Cohen</surname><given-names>NJ</given-names></name><name><surname>Walker</surname><given-names>JA</given-names></name></person-group><article-title>A Closer Look at the Hippocampus and Memory</article-title><source>Trends in cognitive sciences</source><year>2017</year><volume>21</volume><fpage>577</fpage><lpage>588</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2017.05.008</pub-id></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johansson</surname><given-names>R</given-names></name><name><surname>Nystrom</surname><given-names>M</given-names></name><name><surname>Dewhurst</surname><given-names>R</given-names></name><name><surname>Johansson</surname><given-names>M</given-names></name></person-group><article-title>Eye-movement replay supports episodic remembering</article-title><source>Proc BiolSci</source><year>2022</year><volume>289</volume><elocation-id>20220964</elocation-id><pub-id pub-id-type="doi">10.1098/rspb.2022.0964</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wynn</surname><given-names>JS</given-names></name><name><surname>Ryan</surname><given-names>JD</given-names></name><name><surname>Buchsbaum</surname><given-names>BR</given-names></name></person-group><article-title>Eye movements support behavioral pattern completion</article-title><source>Proc Natl Acad Sci U S A</source><year>2020</year><volume>117</volume><fpage>6246</fpage><lpage>6254</lpage><pub-id pub-id-type="doi">10.1073/pnas.1917586117</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wynn</surname><given-names>JS</given-names></name><name><surname>Shen</surname><given-names>K</given-names></name><name><surname>Ryan</surname><given-names>JD</given-names></name></person-group><article-title>Eye Movements Actively Reinstate Spatiotemporal Mnemonic Content</article-title><source>Vision (Basel)</source><year>2019</year><volume>3</volume><pub-id pub-id-type="doi">10.3390/vision3020021</pub-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brandt</surname><given-names>SA</given-names></name><name><surname>Stark</surname><given-names>LW</given-names></name></person-group><article-title>Spontaneous eye movements during visual imagery reflect the content of the visual scene</article-title><source>Journal of cognitive neuroscience</source><year>1997</year><volume>9</volume><fpage>27</fpage><lpage>38</lpage><pub-id pub-id-type="doi">10.1162/jocn.1997.9.1.27</pub-id></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bochynska</surname><given-names>A</given-names></name><name><surname>Laeng</surname><given-names>B</given-names></name></person-group><article-title>Tracking down the path of memory: eye scanpaths facilitate retrieval of visuospatial information</article-title><source>Cogn Process</source><year>2015</year><volume>16</volume><issue>Suppl 1</issue><fpage>159</fpage><lpage>163</lpage><pub-id pub-id-type="doi">10.1007/s10339-015-0690-0</pub-id></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laeng</surname><given-names>B</given-names></name><name><surname>Teodorescu</surname><given-names>D-S</given-names></name></person-group><article-title>Eye scanpaths during visual imagery reenact those of perception of the same visual scene</article-title><source>Cognitive science</source><year>2002</year><volume>26</volume><fpage>207</fpage><lpage>231</lpage><pub-id pub-id-type="doi">10.1207/s15516709cog2602_3</pub-id></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gbadamosi</surname><given-names>J</given-names></name><name><surname>Zangemeister</surname><given-names>WH</given-names></name></person-group><article-title>Visual imagery in hemianopic patients</article-title><source>Journal of cognitive neuroscience</source><year>2001</year><volume>13</volume><fpage>855</fpage><lpage>866</lpage><pub-id pub-id-type="doi">10.1162/089892901753165782</pub-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johansson</surname><given-names>R</given-names></name><name><surname>Holsanova</surname><given-names>J</given-names></name><name><surname>Holmqvist</surname><given-names>K</given-names></name></person-group><article-title>Pictures and spoken descriptions elicit similar eye movements during mental imagery, both in light and in complete darkness</article-title><source>Cognitive science</source><year>2006</year><volume>30</volume><fpage>1053</fpage><lpage>1079</lpage><pub-id pub-id-type="doi">10.1207/s15516709cog0000_86</pub-id></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paller</surname><given-names>KA</given-names></name><name><surname>Wagner</surname><given-names>AD</given-names></name></person-group><article-title>Observing the transformation of experience into memory</article-title><source>Trends in cognitive sciences</source><year>2002</year><volume>6</volume><fpage>93</fpage><lpage>102</lpage><pub-id pub-id-type="doi">10.1016/s1364-6613(00)01845-3</pub-id></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vogelsang</surname><given-names>DA</given-names></name><name><surname>Gruber</surname><given-names>M</given-names></name><name><surname>Bergström</surname><given-names>ZM</given-names></name><name><surname>Ranganath</surname><given-names>C</given-names></name><name><surname>Simons</surname><given-names>JS</given-names></name></person-group><article-title>Alpha Oscillations during Incidental Encoding Predict Subsequent Memory for New “Foil “ Information</article-title><source>Journal of cognitive neuroscience</source><year>2018</year><volume>30</volume><fpage>667</fpage><lpage>679</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01234</pub-id></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fellner</surname><given-names>MC</given-names></name><name><surname>Bäuml</surname><given-names>KH</given-names></name><name><surname>Hanslmayr</surname><given-names>S</given-names></name></person-group><article-title>Brain oscillatory subsequent memory effects differ in power and long-range synchronization between semantic and survival processing</article-title><source>NeuroImage</source><year>2013</year><volume>79</volume><fpage>361</fpage><lpage>370</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.04.121</pub-id></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khader</surname><given-names>PH</given-names></name><name><surname>Jost</surname><given-names>K</given-names></name><name><surname>Ranganath</surname><given-names>C</given-names></name><name><surname>Rosler</surname><given-names>F</given-names></name></person-group><article-title>Theta and alpha oscillations during working-memory maintenance predict successful long-term memory encoding</article-title><source>Neurosci Lett</source><year>2010</year><volume>468</volume><fpage>339</fpage><lpage>343</lpage><pub-id pub-id-type="doi">10.1016/j.neulet.2009.11.028</pub-id></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanslmayr</surname><given-names>S</given-names></name><name><surname>Spitzer</surname><given-names>B</given-names></name><name><surname>Bäuml</surname><given-names>K-H</given-names></name></person-group><article-title>Brain Oscillations Dissociate between Semantic and Nonsemantic Encoding of Episodic Memories</article-title><source>Cerebral Cortex</source><year>2008</year><volume>19</volume><fpage>1631</fpage><lpage>1640</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhn197</pub-id></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klimesch</surname><given-names>W</given-names></name><etal/></person-group><article-title>Event-related desynchronization (ERD) and the Dm effect: does alpha desynchronization during encoding predict later recall performance?</article-title><source>Int J Psychophysiol</source><year>1996</year><volume>24</volume><fpage>47</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.1016/s0167-8760(96)00054-2</pub-id></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sederberg</surname><given-names>PB</given-names></name><name><surname>Kahana</surname><given-names>MJ</given-names></name><name><surname>Howard</surname><given-names>MW</given-names></name><name><surname>Donner</surname><given-names>EJ</given-names></name><name><surname>Madsen</surname><given-names>JR</given-names></name></person-group><article-title>Theta and gamma oscillations during encoding predict subsequent recall</article-title><source>J Neurosci</source><year>2003</year><volume>23</volume><fpage>10809</fpage><lpage>10814</lpage></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanslmayr</surname><given-names>S</given-names></name><name><surname>Staudigl</surname><given-names>T</given-names></name><name><surname>Fellner</surname><given-names>MC</given-names></name></person-group><article-title>Oscillatory power decreases and long-term memory: the information via desynchronization hypothesis</article-title><source>Front Hum Neurosci</source><year>2012</year><volume>6</volume><fpage>74</fpage><pub-id pub-id-type="doi">10.3389/fnhum.2012.00074</pub-id></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Griffiths</surname><given-names>BJ</given-names></name><etal/></person-group><article-title>Alpha/beta power decreases track the fidelity of stimulus-specific information</article-title><source>Elife</source><year>2019</year><volume>8</volume><pub-id pub-id-type="doi">10.7554/eLife.49562</pub-id></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Griffiths</surname><given-names>BJ</given-names></name><name><surname>Martín-Buro</surname><given-names>MC</given-names></name><name><surname>Staresina</surname><given-names>BP</given-names></name><name><surname>Hanslmayr</surname><given-names>S</given-names></name></person-group><article-title>Disentangling neocortical alpha/beta and hippocampal theta/gamma oscillations in human episodic memory formation</article-title><source>NeuroImage</source><year>2021</year><volume>242</volume><elocation-id>118454</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2021.118454</pub-id></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Strunk</surname><given-names>J</given-names></name><name><surname>Duarte</surname><given-names>A</given-names></name></person-group><article-title>Prestimulus and poststimulus oscillatory activity predicts successful episodic encoding for both young and older adults</article-title><source>Neurobiology of aging</source><year>2019</year><volume>77</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.1016/j.neurobiolaging.2019.01.005</pub-id></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sander</surname><given-names>MC</given-names></name><name><surname>Fandakova</surname><given-names>Y</given-names></name><name><surname>Grandy</surname><given-names>TH</given-names></name><name><surname>Shing</surname><given-names>YL</given-names></name><name><surname>Werkle-Bergner</surname><given-names>M</given-names></name></person-group><article-title>Oscillatory Mechanisms of Successful Memory Formation in Younger and Older Adults Are Related to Structural Integrity</article-title><source>Cerebral Cortex</source><year>2020</year><volume>30</volume><fpage>3744</fpage><lpage>3758</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhz339</pub-id></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Griffiths</surname><given-names>BJ</given-names></name><name><surname>Martín-Buro</surname><given-names>MC</given-names></name><name><surname>Staresina</surname><given-names>BP</given-names></name><name><surname>Hanslmayr</surname><given-names>S</given-names></name><name><surname>Staudigl</surname><given-names>T</given-names></name></person-group><article-title>Alpha/beta power decreases during episodic memory formation predict the magnitude of alpha/beta power decreases during subsequent retrieval</article-title><source>Neuropsychologia</source><year>2021</year><volume>153</volume><elocation-id>107755</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2021.107755</pub-id></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanslmayr</surname><given-names>S</given-names></name><name><surname>Staudigl</surname><given-names>T</given-names></name></person-group><article-title>How brain oscillations form memories--a processing based perspective on oscillatory subsequent memory effects</article-title><source>NeuroImage</source><year>2014</year><volume>85</volume><issue>Pt 2</issue><fpage>648</fpage><lpage>655</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.05.121</pub-id></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parish</surname><given-names>G</given-names></name><name><surname>Hanslmayr</surname><given-names>S</given-names></name><name><surname>Bowman</surname><given-names>H</given-names></name></person-group><article-title>The Sync/deSync Model: How a Synchronized Hippocampus and a Desynchronized Neocortex Code Memories</article-title><source>The Journal of Neuroscience</source><year>2018</year><volume>38</volume><fpage>3428</fpage><lpage>3440</lpage><pub-id pub-id-type="doi">10.1523/jneurosci.2561-17.2018</pub-id></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanslmayr</surname><given-names>S</given-names></name><name><surname>Staresina</surname><given-names>BP</given-names></name><name><surname>Bowman</surname><given-names>H</given-names></name></person-group><article-title>Oscillations and Episodic Memory: Addressing the Synchronization/Desynchronization Conundrum</article-title><source>Trends in neurosciences</source><year>2016</year><volume>39</volume><fpage>16</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2015.11.004</pub-id></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Popov</surname><given-names>T</given-names></name><name><surname>Miller</surname><given-names>GA</given-names></name><name><surname>Rockstroh</surname><given-names>B</given-names></name><name><surname>Jensen</surname><given-names>O</given-names></name><name><surname>Langer</surname><given-names>N</given-names></name></person-group><article-title>Alpha oscillations link action to cognition: An oculomotor account of the brain’s dominant rhythm</article-title><source>bioRxiv</source><year>2021</year><elocation-id>2021.2009.2024.461634</elocation-id><pub-id pub-id-type="doi">10.1101/2021.09.24.461634</pub-id></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Staudigl</surname><given-names>T</given-names></name><name><surname>Hartl</surname><given-names>E</given-names></name><name><surname>Noachtar</surname><given-names>S</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name><name><surname>Jensen</surname><given-names>O</given-names></name></person-group><article-title>Saccades are phase-locked to alpha oscillations in the occipital and medial temporal lobe during successful memory encoding</article-title><source>PLoS biology</source><year>2017</year><volume>15</volume><elocation-id>e2003404</elocation-id></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Popov</surname><given-names>T</given-names></name><name><surname>Langer</surname><given-names>N</given-names></name><name><surname>Gips</surname><given-names>B</given-names></name><name><surname>Weisz</surname><given-names>N</given-names></name><name><surname>Jensen</surname><given-names>O</given-names></name></person-group><article-title>Sound-location specific alpha power modulation in the visual cortex in absence of visual input</article-title><source>bioRxiv</source><year>2021</year><elocation-id>2021.2003.2015.435371</elocation-id><pub-id pub-id-type="doi">10.1101/2021.03.15.435371</pub-id></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Printzlau</surname><given-names>FAB</given-names></name><name><surname>Myers</surname><given-names>NE</given-names></name><name><surname>Manohar</surname><given-names>SG</given-names></name><name><surname>Stokes</surname><given-names>MG</given-names></name></person-group><article-title>Neural Reinstatement Tracks Spread of Attention between Object Features in Working Memory</article-title><source>Journal of cognitive neuroscience</source><year>2022</year><fpage>1</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01879</pub-id></element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Popov</surname><given-names>T</given-names></name><name><surname>Gips</surname><given-names>B</given-names></name><name><surname>Weisz</surname><given-names>N</given-names></name><name><surname>Jensen</surname><given-names>O</given-names></name></person-group><article-title>Brain areas associated with visual spatial attention display topographic organization during auditory spatial attention</article-title><source>Cerebral cortex (New York, NY : 1991)</source><year>2022</year><pub-id pub-id-type="doi">10.1093/cercor/bhac285</pub-id></element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>B</given-names></name><name><surname>Nobre</surname><given-names>AC</given-names></name>van<name><surname>Ede</surname><given-names>F</given-names></name></person-group><article-title>Microsaccades transiently lateralise EEG alpha activity</article-title><source>bioRxiv</source><year>2022</year><elocation-id>2022.2009.2002.506318</elocation-id><pub-id pub-id-type="doi">10.1101/2022.09.02.506318</pub-id></element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maris</surname><given-names>E</given-names></name><name><surname>Oostenveld</surname><given-names>R</given-names></name></person-group><article-title>Nonparametric statistical testing of EEG-and MEG-data</article-title><source>J Neurosci Methods</source><year>2007</year><volume>164</volume><fpage>177</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2007.03.024</pub-id></element-citation></ref><ref id="R40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dimigen</surname><given-names>O</given-names></name><name><surname>Sommer</surname><given-names>W</given-names></name><name><surname>Hohlfeld</surname><given-names>A</given-names></name><name><surname>Jacobs</surname><given-names>AM</given-names></name><name><surname>Kliegl</surname><given-names>R</given-names></name></person-group><article-title>Coregistration of eye movements and EEG in natural reading: analyses and review</article-title><source>J Exp Psychol Gen</source><year>2011</year><volume>140</volume><fpage>552</fpage><lpage>572</lpage><pub-id pub-id-type="doi">10.1037/a0023885</pub-id></element-citation></ref><ref id="R41"><label>41</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engbert</surname><given-names>R</given-names></name><name><surname>Mergenthaler</surname><given-names>K</given-names></name></person-group><article-title>Microsaccades are triggered by low retinal image slip</article-title><source>Proc Natl Acad Sci U S A</source><year>2006</year><volume>103</volume><fpage>7192</fpage><lpage>7197</lpage><pub-id pub-id-type="doi">10.1073/pnas.0509557103</pub-id></element-citation></ref><ref id="R42"><label>42</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allen</surname><given-names>M</given-names></name><name><surname>Poggiali</surname><given-names>D</given-names></name><name><surname>Whitaker</surname><given-names>K</given-names></name><name><surname>Marshall</surname><given-names>TR</given-names></name><name><surname>Kievit</surname><given-names>RA</given-names></name></person-group><article-title>Raincloud plots: a multi-platform tool for robust data visualization</article-title><source>Wellcome Open Res</source><year>2019</year><volume>4</volume><fpage>63</fpage><pub-id pub-id-type="doi">10.12688/wellcomeopenres.15191.1</pub-id></element-citation></ref><ref id="R43"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Donoghue</surname><given-names>T</given-names></name><etal/></person-group><article-title>Parameterizing neural power spectra into periodic and aperiodic components</article-title><source>Nature Neuroscience</source><year>2020</year><volume>23</volume><fpage>1655</fpage><lpage>1665</lpage><pub-id pub-id-type="doi">10.1038/s41593-020-00744-x</pub-id></element-citation></ref><ref id="R44"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Staudigl</surname><given-names>T</given-names></name><name><surname>Hartl</surname><given-names>E</given-names></name><name><surname>Noachtar</surname><given-names>S</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name><name><surname>Jensen</surname><given-names>O</given-names></name></person-group><article-title>Saccades are phase-locked to alpha oscillations in the occipital and medial temporal lobe during successful memory encoding</article-title><source>PLoS Biol</source><year>2017</year><volume>15</volume><elocation-id>e2003404</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.2003404</pub-id></element-citation></ref><ref id="R45"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>B</given-names></name><name><surname>Nobre</surname><given-names>AC</given-names></name><name><surname>van Ede</surname><given-names>F</given-names></name></person-group><article-title>Functional but not obligatory link between microsaccades and neural modulation by covert spatial attention</article-title><source>Nature Communications</source><year>2022</year><volume>13</volume><elocation-id>3503</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-022-31217-3</pub-id></element-citation></ref><ref id="R46"><label>46</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brunet</surname><given-names>N</given-names></name><etal/></person-group><article-title>Visual cortical gamma-band activity during free viewing of natural images</article-title><source>Cerebral cortex (New York, NY : 1991)</source><year>2015</year><volume>25</volume><fpage>918</fpage><lpage>926</lpage><pub-id pub-id-type="doi">10.1093/cercor/bht280</pub-id></element-citation></ref><ref id="R47"><label>47</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McFarland</surname><given-names>JM</given-names></name><name><surname>Bondy</surname><given-names>AG</given-names></name><name><surname>Saunders</surname><given-names>RC</given-names></name><name><surname>Cumming</surname><given-names>BG</given-names></name><name><surname>Butts</surname><given-names>DA</given-names></name></person-group><article-title>Saccadic modulation of stimulus processing in primary visual cortex</article-title><source>Nature Communications</source><year>2015</year><volume>6</volume><elocation-id>8110</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms9110</pub-id></element-citation></ref><ref id="R48"><label>48</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ito</surname><given-names>J</given-names></name><name><surname>Maldonado</surname><given-names>P</given-names></name><name><surname>Singer</surname><given-names>W</given-names></name><name><surname>Grün</surname><given-names>S</given-names></name></person-group><article-title>Saccade-related modulations of neuronal excitability support synchrony of visually elicited spikes</article-title><source>Cerebral cortex (New York, NY : 1991)</source><year>2011</year><volume>21</volume><fpage>2482</fpage><lpage>2497</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhr020</pub-id></element-citation></ref><ref id="R49"><label>49</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rajkai</surname><given-names>C</given-names></name><etal/></person-group><article-title>Transient cortical excitation at the onset of visual fixation</article-title><source>Cerebral cortex (New York, NY : 1991)</source><year>2008</year><volume>18</volume><fpage>200</fpage><lpage>209</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhm046</pub-id></element-citation></ref><ref id="R50"><label>50</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barczak</surname><given-names>A</given-names></name><etal/></person-group><article-title>Dynamic Modulation of Cortical Excitability during Visual Active Sensing</article-title><source>Cell reports</source><year>2019</year><volume>27</volume><fpage>3447</fpage><lpage>3459</lpage><elocation-id>e3443</elocation-id><pub-id pub-id-type="doi">10.1016/j.celrep.2019.05.072</pub-id></element-citation></ref><ref id="R51"><label>51</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leszczynski</surname><given-names>M</given-names></name><etal/></person-group><article-title>Neural activity in the human anterior thalamus during natural vision</article-title><source>Scientific Reports</source><year>2021</year><volume>11</volume><elocation-id>17480</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-021-96588-x</pub-id></element-citation></ref><ref id="R52"><label>52</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hamamé</surname><given-names>CM</given-names></name><etal/></person-group><article-title>Functional selectivity in the human occipitotemporal cortex during natural vision: evidence from combined intracranial EEG and eye-tracking</article-title><source>NeuroImage</source><year>2014</year><volume>95</volume><fpage>276</fpage><lpage>286</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.03.025</pub-id></element-citation></ref><ref id="R53"><label>53</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Purpura</surname><given-names>KP</given-names></name><name><surname>Kalik</surname><given-names>SF</given-names></name><name><surname>Schiff</surname><given-names>ND</given-names></name></person-group><article-title>Analysis of perisaccadic field potentials in the occipitotemporal pathway during active vision</article-title><source>Journal of neurophysiology</source><year>2003</year><volume>90</volume><fpage>3455</fpage><lpage>3478</lpage><pub-id pub-id-type="doi">10.1152/jn.00011.2003</pub-id></element-citation></ref><ref id="R54"><label>54</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andrillon</surname><given-names>T</given-names></name><name><surname>Nir</surname><given-names>Y</given-names></name><name><surname>Cirelli</surname><given-names>C</given-names></name><name><surname>Tononi</surname><given-names>G</given-names></name><name><surname>Fried</surname><given-names>I</given-names></name></person-group><article-title>Single-neuron activity and eye movements during human REM sleep and awake vision</article-title><source>Nature Communications</source><year>2015</year><volume>6</volume><elocation-id>7884</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms8884</pub-id></element-citation></ref><ref id="R55"><label>55</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mao</surname><given-names>D</given-names></name><etal/></person-group><article-title>Spatial modulation of hippocampal activity in freely moving macaques</article-title><source>Neuron</source><year>2021</year><volume>109</volume><fpage>3521</fpage><lpage>3534</lpage><elocation-id>e3526</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuron.2021.09.032</pub-id></element-citation></ref><ref id="R56"><label>56</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Katz</surname><given-names>CN</given-names></name><etal/></person-group><article-title>A corollary discharge mediates saccade-related inhibition of single units in mnemonic structures of the human brain</article-title><source>Curr Biol</source><year>2022</year><volume>32</volume><fpage>3082</fpage><lpage>3094</lpage><elocation-id>e3084</elocation-id><pub-id pub-id-type="doi">10.1016/j.cub.2022.06.015</pub-id></element-citation></ref><ref id="R57"><label>57</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wagner</surname><given-names>IC</given-names></name><name><surname>Jensen</surname><given-names>O</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name><name><surname>Staudigl</surname><given-names>T</given-names></name></person-group><article-title>Saccades are coordinated with directed circuit dynamics and stable but distinct hippocampal patterns that promote memory formation</article-title><source>bioRxiv</source><year>2022</year><elocation-id>2022.2008.2018.504386</elocation-id><pub-id pub-id-type="doi">10.1101/2022.08.18.504386</pub-id></element-citation></ref><ref id="R58"><label>58</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>ZX</given-names></name><name><surname>Shen</surname><given-names>K</given-names></name><name><surname>Olsen</surname><given-names>RK</given-names></name><name><surname>Ryan</surname><given-names>JD</given-names></name></person-group><article-title>Visual Sampling Predicts Hippocampal Activity</article-title><source>J Neurosci</source><year>2017</year><volume>37</volume><fpage>599</fpage><lpage>609</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2610-16.2016</pub-id></element-citation></ref><ref id="R59"><label>59</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoffman</surname><given-names>KL</given-names></name><etal/></person-group><article-title>Saccades during visual exploration align hippocampal 3-8 Hz rhythms in human and non-human primates</article-title><source>Frontiers in systems neuroscience</source><year>2013</year><volume>7</volume><fpage>43</fpage><pub-id pub-id-type="doi">10.3389/fnsys.2013.00043</pub-id></element-citation></ref><ref id="R60"><label>60</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doucet</surname><given-names>G</given-names></name><name><surname>Gulli</surname><given-names>RA</given-names></name><name><surname>Corrigan</surname><given-names>BW</given-names></name><name><surname>Duong</surname><given-names>LR</given-names></name><name><surname>Martinez-Trujillo</surname><given-names>JC</given-names></name></person-group><article-title>Modulation of local field potentials and neuronal activity in primate hippocampus during saccades</article-title><source>Hippocampus</source><year>2020</year><volume>30</volume><fpage>192</fpage><lpage>209</lpage><pub-id pub-id-type="doi">10.1002/hipo.23140</pub-id></element-citation></ref><ref id="R61"><label>61</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jutras</surname><given-names>MJ</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name><name><surname>Buffalo</surname><given-names>EA</given-names></name></person-group><article-title>Oscillatory activity in the monkey hippocampus during visual exploration and memory formation</article-title><source>Proc Natl Acad Sci U S A</source><year>2013</year><volume>110</volume><fpage>13144</fpage><lpage>13149</lpage><pub-id pub-id-type="doi">10.1073/pnas.1302351110</pub-id></element-citation></ref><ref id="R62"><label>62</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Staudigl</surname><given-names>T</given-names></name><name><surname>Minxha</surname><given-names>J</given-names></name><name><surname>Mamelak</surname><given-names>AN</given-names></name><name><surname>Gothard</surname><given-names>KM</given-names></name><name><surname>Rutishauser</surname><given-names>U</given-names></name></person-group><article-title>Saccade-related neural communication in the human medial temporal lobe is modulated by the social relevance of stimuli</article-title><source>Science advances</source><year>2022</year><volume>8</volume><elocation-id>eabl6037</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.abl6037</pub-id></element-citation></ref><ref id="R63"><label>63</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Voloh</surname><given-names>B</given-names></name><name><surname>Womelsdorf</surname><given-names>T</given-names></name></person-group><article-title>A Role of Phase-Resetting in Coordinating Large Scale Neural Networks During Attention and Goal-Directed Behavior</article-title><source>Frontiers in systems neuroscience</source><year>2016</year><volume>10</volume><fpage>18</fpage><pub-id pub-id-type="doi">10.3389/fnsys.2016.00018</pub-id></element-citation></ref><ref id="R64"><label>64</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sommer</surname><given-names>MA</given-names></name><name><surname>Wurtz</surname><given-names>RH</given-names></name></person-group><article-title>A pathway in primate brain for internal monitoring of movements</article-title><source>Cerebral cortex (New York, NY)</source><year>2002</year><volume>296</volume><fpage>1480</fpage><lpage>1482</lpage><pub-id pub-id-type="doi">10.1126/science.1069590</pub-id></element-citation></ref><ref id="R65"><label>65</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><article-title>Neural syntax: cell assemblies, synapsembles, and readers</article-title><source>Neuron</source><year>2010</year><volume>68</volume><fpage>362</fpage><lpage>385</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.09.023</pub-id></element-citation></ref><ref id="R66"><label>66</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fries</surname><given-names>P</given-names></name></person-group><article-title>Rhythms for Cognition: Communication through Coherence</article-title><source>Neuron</source><year>2015</year><volume>88</volume><fpage>220</fpage><lpage>235</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.034</pub-id></element-citation></ref><ref id="R67"><label>67</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneider</surname><given-names>M</given-names></name><etal/></person-group><article-title>A mechanism for inter-areal coherence through communication based on connectivity and oscillatory power</article-title><source>Neuron</source><year>2021</year><volume>109</volume><fpage>4050</fpage><lpage>4067</lpage><elocation-id>e4012</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuron.2021.09.037</pub-id></element-citation></ref><ref id="R68"><label>68</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fellner</surname><given-names>MC</given-names></name><etal/></person-group><article-title>Spectral fingerprints or spectral tilt? Evidence for distinct oscillatory signatures of memory formation</article-title><source>PLoS Biol</source><year>2019</year><volume>17</volume><elocation-id>e3000403</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.3000403</pub-id></element-citation></ref><ref id="R69"><label>69</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martinez-Conde</surname><given-names>S</given-names></name><name><surname>Otero-Millan</surname><given-names>J</given-names></name><name><surname>Macknik</surname><given-names>SL</given-names></name></person-group><article-title>The impact of microsaccades on vision: towards a unified theory of saccadic function</article-title><source>Nature reviews Neuroscience</source><year>2013</year><volume>14</volume><fpage>83</fpage><lpage>96</lpage><pub-id pub-id-type="doi">10.1038/nrn3405</pub-id></element-citation></ref><ref id="R70"><label>70</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stolk</surname><given-names>A</given-names></name><name><surname>Todorovic</surname><given-names>A</given-names></name><name><surname>Schoffelen</surname><given-names>JM</given-names></name><name><surname>Oostenveld</surname><given-names>R</given-names></name></person-group><article-title>Online and offline tools for head movement compensation in MEG</article-title><source>NeuroImage</source><year>2013</year><volume>68</volume><fpage>39</fpage><lpage>48</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.11.047</pub-id></element-citation></ref><ref id="R71"><label>71</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oostenveld</surname><given-names>R</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name><name><surname>Maris</surname><given-names>E</given-names></name><name><surname>Schoffelen</surname><given-names>JM</given-names></name></person-group><article-title>FieldTrip: Open source software for advanced analysis of MEG, EEG, and invasive electrophysiological data</article-title><source>Comput Intell Neurosci</source><year>2011</year><volume>2011</volume><elocation-id>156869</elocation-id><pub-id pub-id-type="doi">10.1155/2011/156869</pub-id></element-citation></ref><ref id="R72"><label>72</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Donoghue</surname><given-names>T</given-names></name><etal/></person-group><article-title>Parameterizing neural power spectra into periodic and aperiodic components</article-title><source>Nat Neurosci</source><year>2020</year><volume>23</volume><fpage>1655</fpage><lpage>1665</lpage><pub-id pub-id-type="doi">10.1038/s41593-020-00744-x</pub-id></element-citation></ref><ref id="R73"><label>73</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mitra</surname><given-names>PP</given-names></name><name><surname>Pesaran</surname><given-names>B</given-names></name></person-group><article-title>Analysis of Dynamic Brain Imaging Data</article-title><source>Biophysical Journal</source><year>1999</year><volume>76</volume><fpage>691</fpage><lpage>708</lpage><pub-id pub-id-type="doi">10.1016/S0006-3495(99)77236-X</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>Coinciding subsequent memory effects (SME) reflected in gaze biases and modulation of visual alpha/beta power</title><p><bold>A-</bold> Gaze density contrast between later remembered vs. later forgotten items. The 2D density maps were calculated per trial and latency between 0- 4sec following scene presentation during the study phase. Red color indicates increased biased towards the respective visual screen locations for later remembered items and blue color decreased gaze density or gaze direction away from the respective location. Color code is expressed in units of effect size Cohen’s d obtained after cluster-permutation test (p&lt; 0.025). <bold>B-</bold> Scalp topography and time-frequency representation of power (TFR) of the contrast between later remembered vs. later forgotten items during the study phase. Color code indicates effect size Cohen’s d obtained after cluster-permutation approach at p &lt; 0.025. The black outline in the TFR highlights the cluster supporting the rejection of the null hypothesis of no effect between later remembered and later forgotten items. <bold>C-</bold> Similar to A but split according to the particpants confidence as of how certain their response is for an item being “old ” or “new ”. Gaze bias for high confidence trials (left) versus gaze bias for low confidence trials (right). <bold>D-</bold> 2×2 Interaction SME (remembered, forgotten) x Confidence (high, low) illustrating the scalp topography and the TFR expressed in units of effect size Cohen’s d (cluster-permutation test, p &lt; 0.025). <bold>E-</bold> Contrast in gaze density between trials dominated by low alpha/beta power minus high alpha/beta power during the prestimulus baseline (-1 to 0 sec) in the study phase. Color code is expressed in units of effect size Cohen’s d obtained after cluster-permutation test (p&lt; 0.025). Red color indicates increased bias towards the respective visual screen locations for trials dominated by low alpha/power power as compared to high alpha/beta power. <bold>F-</bold> Scalp topography of the relative alpha/betapower change between the same trials as in (E) dominated by low vs. high alpha/betapower. Color code denotes the relative change in %. Statistical contrast is inapproriate in this case as it will be highly signficant per construction. This is however not the case for the evaluation of the gaze biases illustrated in E. The power spectrum of the difference averaged across occipital sensors is provided with shading denoting SEM.</p></caption><graphic xlink:href="EMS157026-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Gaze variability affects cortical alpha/beta power modulation and the effect size of memory performance.</title><p><bold>A-</bold> Gaze density contrast between trials dominated by high vs. low gaze variability (median split within participants). The 2D density maps were calculated per trial and latency between 0- 4sec following scene presentation during the study phase. Red color indicates increased biased towards the respective visual screen locations for later remembered items and blue color decreased gaze density or gaze direction away from the respective location. Color code is expressed in units of effect size Cohen’s d obtained after cluster-permutation test (p&lt; 0.025). <bold>B-</bold> Scalp topography and power spectrum contrast between high vs. low gaze variability trials during the study phase. Color code indicates effect size Cohen’s d obtained after cluster-permutation approach at p &lt; 0.025. The black asterisks in the topography and the shaded areas in the powerspecturm highlight the clusters supporting the rejection of the null hypothesis of no effect between trials dominated by high vs. low gaze variability during encoding. <bold>C-</bold> Rain cloud plots<sup><xref ref-type="bibr" rid="R42">42</xref></sup> illustrating the distribution of remembered (left) and forgotten (right) itmes split by gaze variability (high vs. low) during encoding. <bold>D-</bold> The distribution of high (left) and low (right) gaze variability split by memory performance (remembered vs. forgotten).</p></caption><graphic xlink:href="EMS157026-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Time course of the covariation of occipital alpha power and gaze direction maintenance.</title><p><bold>A-</bold> Single subject example of TFR averaged over occipital sensors, corrected for the presense of the aperiodic 1/F component. X-axis denotes time in minutes and y-axis frequency in Hz. The first 6 minutes of the recording are shown for illustrative purposes. Color code denotes the range corrected power (x – min)/(max-min) varying between 0 and 1. <bold>B-</bold> Gaze density in the horizontal dimension around the fixation location and vertical range of ±3 dva expressed as function of time (x-axis). The middle position of the y-axis denots the fixation location, up rightward gaze bias and down denotes leftward gaze bias. Color code illustrates the range corrected gaze density varying between 0 and 1. <bold>C-</bold> Time course of alpha power (10-14Hz, red color) and gaze density at the fixation location (blue color) overlaid on top of each other. The x-axis is identical to A and B. <bold>D-</bold> Normalized probability histogramms (sum of y-axis equals 1) of the Spearman’s rho correlation coefficient between the time courses of alpha power and gaze density at fixation, converted in z-values. Red color denotes the distribution of all correlations across all participants estimated on the original time series. Blue color denotes the distribution of correlations estimated on circularly shifted time series after 1000 permutations. A significant difference was confirmed t(34)= 6.8, CI[0.12 0.22], p &lt; 7.4e-08 and estimated effect size of Cohen’s d= 1.1541. <bold>E-</bold> Coherence spectra between the alpha power and gaze density timeseries. Frequency is depicted on the x-axis and coherence magnitude on the y-axis. Red color denotes the original time series and the blue color the surrogate data generated after permuting the trial correspondense between alpha power and gaze densitiy data and computing the coherence (1000-fold permutation) and averaging over folds. Shading illsustrates standard error.</p></caption><graphic xlink:href="EMS157026-f003"/></fig></floats-group></article>