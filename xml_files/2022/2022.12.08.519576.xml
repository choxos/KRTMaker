<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS158367</article-id><article-id pub-id-type="doi">10.1101/2022.12.08.519576</article-id><article-id pub-id-type="archive">PPR581954</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>At Which Low Amplitude Modulated Frequency Do Infants Best Entrain? A Frequency Tagging Study</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-4076-0322</contrib-id><name><surname>Ives</surname><given-names>James</given-names></name></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-8688-6935</contrib-id><name><surname>Labendzki</surname><given-names>Pierre</given-names></name></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-6487-6886</contrib-id><name><surname>Perapoch Amadó</surname><given-names>Marta</given-names></name></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-9723-9664</contrib-id><name><surname>Greenwood</surname><given-names>Emily</given-names></name></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-0354-0216</contrib-id><name><surname>Viswanathan</surname><given-names>Narain</given-names></name></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-5724-591X</contrib-id><name><surname>Northrop</surname><given-names>Tom</given-names></name></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-7421-3493</contrib-id><name><surname>Wass</surname><given-names>Sam</given-names></name></contrib><aff id="A1">UEL Baby Development Lab, University of East London, Water Lane, London, E15 4LZ, UK</aff></contrib-group><author-notes><corresp id="CR1">Correspondence concerning this article should be addressed to James Ives, University of East London, Water Lane, London, E15 4LZ. <email>u2067263@uel.ac.uk</email>
</corresp></author-notes><pub-date pub-type="nihms-submitted"><day>10</day><month>12</month><year>2022</year></pub-date><pub-date pub-type="preprint"><day>08</day><month>12</month><year>2022</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Previous infant entrainment research has shown neural entrainment to a wide range of stimuli and amplitude modulated frequencies. However, it is unknown if infants neurally entrain more strongly to some frequencies more than others, and to which low amplitude modulated frequency infants show the strongest entrainment. The current study seeks to address this by testing the neural entrainment of N=23 4–6-month-old infants and N=22 control group adult caregivers while they listened to a range of sinusoidally amplitude modulated beep stimuli at rest (no sound), 2, 4, 6, 8, 10 and 12 Hz. Analysis examined differences across power and phase, regions of interest predetermined by previous literature and by segmented time windows. Results showed that the strongest entrainment was at 2Hz for both adult and infant participants; that there was no significant difference in power and phase, entrainment was occipital temporal and slightly left fronto-central in adults and right fronto-central and left occipito-temporal in infants, leading to some regions of interest used in previous studies being significant in infants and all regions of interest being significant in adults. Segmenting by time window did not show any significant increase or decrease in entrainment over time, but longer time windows showed a stronger entrainment response. In conclusion, it is important to choose appropriate stimulation frequencies when investigating entrainment between stimulation frequencies or across ages; whole head recording is recommended to see the full extent of activation; there is no preference on power vs phase analyses; and longer recordings show stronger effects.</p></abstract><kwd-group><kwd>Entrainment</kwd><kwd>Frequency Tagging</kwd><kwd>Infant EEG</kwd><kwd>Low amplitude modulated frequencies</kwd></kwd-group></article-meta></front><body><sec id="S1"><label>1</label><title>At Which Low Amplitude Modulated Frequency Do Infants Best Entrain? A Frequency Tagging Study</title><p id="P2">Neural activity in mammalian brains during rest and excitation has been shown to take on an oscillatory structure. Oscillations take on the role of pacemaker networks and resonators, each responding to particular firing frequencies (<xref ref-type="bibr" rid="R148">Llinás, 1988</xref>). <xref ref-type="bibr" rid="R148">Llinás (1988)</xref> describes how these oscillatory networks help specify connectivity during development, help with motor coordination, timing and help with global states, e.g., sleep-wake or attentional state. <xref ref-type="bibr" rid="R28">Buzsáki and Draguhn (2004)</xref> demonstrated in the human brain that across five orders of magnitude cortical networks oscillate to help promote processing of incoming sensory information. These neural oscillations help bias input selection, promote long-term consolidation of information and help with time perception.</p><p id="P3">Person-person and person-environment neural entrainment have been well studied in the adult literature (e.g., <xref ref-type="bibr" rid="R28">Buzsáki and Draguhn, 2004</xref>; <xref ref-type="bibr" rid="R86">Glass, 2001</xref>; <xref ref-type="bibr" rid="R107">Hoehl, Fairhurst &amp; Schirmer, 2021</xref>; <xref ref-type="bibr" rid="R239">Thut, Schyns &amp; Gross, 2011</xref>) and to some extent infant literature (<xref ref-type="bibr" rid="R254">Wass et al., 2020</xref>; <xref ref-type="bibr" rid="R252">Wass, Perapoch Amadó &amp; Ives, 2022</xref>). Neural entrainment is measured as matching periods of oscillatory activity, measured either concurrently or simultaneously across a dyad, as a result of a shared stimulus or social interaction, producing a bidirectional influence between the dyad (<xref ref-type="bibr" rid="R254">Wass et al., 2020</xref>).</p><p id="P4">Entrainment studies in adults have suggested that entrainment helps attention selection (<xref ref-type="bibr" rid="R23">Besle et al., 2011</xref>; <xref ref-type="bibr" rid="R138">Lakatos et al., 2008</xref>; <xref ref-type="bibr" rid="R239">Thut, Schyns &amp; Gross, 2011</xref>; <xref ref-type="bibr" rid="R250">Ward, 2003</xref>), memory encoding (<xref ref-type="bibr" rid="R250">Ward, 2003</xref>), memory recall (<xref ref-type="bibr" rid="R106">Hickey et al., 2020</xref>), sensory selection (<xref ref-type="bibr" rid="R217">Schroeder &amp; Lakatos, 2009</xref>), auditory perception (<xref ref-type="bibr" rid="R125">Kayser et al., 2015</xref>; <xref ref-type="bibr" rid="R203">Rimmele et al., 2018</xref>), music processing (<xref ref-type="bibr" rid="R63">Doelling &amp; Poeppel, 2015</xref>), speech processing (<xref ref-type="bibr" rid="R60">Ding et al., 2015</xref>; <xref ref-type="bibr" rid="R85">Giraud &amp; Poeppel, 2012</xref>; <xref ref-type="bibr" rid="R110">Hyafil et al., 2015</xref>), interperson conversational features including speech pitch, intensity voice quality and speaking rate (<xref ref-type="bibr" rid="R146">Levitab &amp; Hirschberg, 2011</xref>) audio-visual processing (<xref ref-type="bibr" rid="R218">Schroeder et al., 2008</xref>), synchrony during face-to-face communications (<xref ref-type="bibr" rid="R116">Jiang et al., 2012</xref>), visual-olfactory processing (<xref ref-type="bibr" rid="R199">Rekow et al., 2022</xref>), prediction of future actions (<xref ref-type="bibr" rid="R124">Kayhan et al., 2022</xref>), coordination of movement and auditory rhythm (<xref ref-type="bibr" rid="R243">Varlet, Williams &amp; Keller, 2018</xref>) and event timing (<xref ref-type="bibr" rid="R128">Kösem, Gramfort &amp; van Wassenhove, 2014</xref>) (for further review see <xref ref-type="bibr" rid="R119">Kabdebon et al. (2022)</xref>.</p><p id="P5">Many behaviours are thought to evoke neural entrainment including conversations (<xref ref-type="bibr" rid="R186">Pérez, Carreiras &amp; Duñabeitia, 2017</xref>) that feature both infant directed and adult directed speech (<xref ref-type="bibr" rid="R120">Kalashnikova et al., 2018</xref>), singing (<xref ref-type="bibr" rid="R256">Weinstein et al., 2016</xref>) listening to audiobooks (<xref ref-type="bibr" rid="R129">Koskinen &amp; Seppä, 2014</xref>), watching movies (<xref ref-type="bibr" rid="R140">Lankinen et al., 2014</xref>) and watching cartoons (<xref ref-type="bibr" rid="R114">Jessen et al., 2019</xref>). Entrainment is also thought to be coupled across many physiological markers, including mother-infant synchronisation of heart rhythms (<xref ref-type="bibr" rid="R73">Feldman, 2007</xref>), neural tracking of pain (<xref ref-type="bibr" rid="R94">Guo et al., 2020</xref>), thermal-cardiac entrainment (<xref ref-type="bibr" rid="R154">Mannix et al., 1997</xref>), infant-adult synchronisation of pupil dilations (<xref ref-type="bibr" rid="R72">Fawcett et al., 2017</xref>) and synchronisation of respiration to rocking (<xref ref-type="bibr" rid="R213">Sammon &amp; Darnell, 1994</xref>).</p><p id="P6">For further review of entrainment in early social interaction, and oscillatory entrainment to early social and physical environments please see <xref ref-type="bibr" rid="R254">Wass et al., (2020)</xref> and <xref ref-type="bibr" rid="R252">Wass, Perapoch Amadó and Ives (2022)</xref>.</p><sec id="S2"><label>1.1</label><title>Developmental Auditory Capabilities</title><p id="P7">The ongoing auditory scene from our surrounding environment is a constant barrage of overlapping spectral and temporal information that arrives at our ears as a single stream, but which humans separate into distinct sources during auditory processing in the brain. <xref ref-type="bibr" rid="R169">Näätänen et al., (2001)</xref> describe how adults use “sensory intelligence” to untangle this information to produce an auditory scene in the auditory cortex. Young infants, including newborns (<xref ref-type="bibr" rid="R159">McAdams, 1997</xref>; <xref ref-type="bibr" rid="R259">Winkler et al., 2003</xref>) and 7–15-week-olds (<xref ref-type="bibr" rid="R56">Demany, 1982</xref>), have been shown to separate concurrent audio streams of information, suggesting that some elements of how complex auditory sounds are processed seem likely to be present at birth. After grouping and organising the auditory input, humans have then been shown to track and apply hierarchies to the information. For example, this is commonly seen in the cortical tracking of speech structures in adults (Ding et al., 2016) and infants (<xref ref-type="bibr" rid="R35">Choi et al., 2020</xref>; <xref ref-type="bibr" rid="R142">Leong &amp; Goswami, 2015</xref>). This is also seen across sensory modalities spanning very low frequencies (˂ 1Hz), including across minutes, hours and days (for a review see <xref ref-type="bibr" rid="R252">Wass, Perapoch Amadó &amp; Ives, 2022</xref>).</p><p id="P8">Infants, even newborns, have been shown to be born with a range of complex auditory processing capabilities that allow them to segregate sounds and organise their auditory world. For example, infants can detect changes in pitch (Alho, 1989), prefer their native maternal language (<xref ref-type="bibr" rid="R165">Moon, Cooper &amp; Fifer, 1993</xref>), and recognise and prefer their mother’s voice (<xref ref-type="bibr" rid="R53">De Casper &amp; Fifer, 1980</xref>). Machine learning has been shown to reliably classify the neural response of 8-week-olds to both rhythmic and non-rhythmic speech (<xref ref-type="bibr" rid="R84">Gibbon et al., 2021</xref>). Using this segregated information, newborns have been shown to model acoustic regularity by learning to group repeating tones out of random patterns (<xref ref-type="bibr" rid="R228">Stefanics et al., 2007</xref>), and model acoustic regularity and show a neural response to violations in expected auditory sequences (<xref ref-type="bibr" rid="R30">Carral et al., 2005</xref>).</p><p id="P9">At a more granular level, infants have been shown to employ statistical learning as patterns to perceive acoustically relevant information. <xref ref-type="bibr" rid="R212">Saffran et al., (1999)</xref> demonstrated the first evidence of infant statistical learning of tone sequences in both infants and adults. Further studies have demonstrated that infants under the age of 12 months can use statistical learning to pick out words in regular computerised speech (<xref ref-type="bibr" rid="R35">Choi et al., 2020</xref>; <xref ref-type="bibr" rid="R80">Fló et al., 2022</xref>; <xref ref-type="bibr" rid="R118">Kabdebon et al., 2015</xref>), while cortical tracking studies have demonstrated that infants track sung speech (<xref ref-type="bibr" rid="R14">Attaheri et al., 2022</xref>), cartoons (<xref ref-type="bibr" rid="R114">Jessen et al., 2019</xref>) and infant directed and adult directed speech (<xref ref-type="bibr" rid="R120">Kalashnikova et al., 2018</xref>).</p></sec><sec id="S3"><label>1.2</label><title>Infant vs Adult Neural Entrainment Capabilities</title><p id="P10">Auditory steady state responses (ASSRs) are cortical responses to fast isochronously repeating stimuli, which are often used to test hearing capabilities in newborns and young infants. ASSRs are a valuable technique as they can be administered to adults and infants whether they are awake or asleep (e.g., Cohen et al., 1991; <xref ref-type="bibr" rid="R112">Jerger et al., 1986</xref>; <xref ref-type="bibr" rid="R249">Wang et al., 2022</xref>). Using ASSRs, infants have been shown to cortically track simple stimuli from a very early age (e.g., <xref ref-type="bibr" rid="R150">Lorenzini et al., 2022</xref>). <xref ref-type="bibr" rid="R48">Daneshvarfard et al., (2019)</xref> demonstrated that preterm infants even at an average gestational age of 31.48 weeks exhibited a classic ASSR. While <xref ref-type="bibr" rid="R174">Niepel et al., (2020)</xref> showed using foetal MEG that infants as young as 30 weeks gestational age exhibit ASSRs <italic>in utero</italic>, suggesting that even with limited capacity to interact with the outside environment foetal brains can track and entrain to rhythmic stimuli. However, while there is evidence that infants can entrain to auditory stimuli as a method of parsing auditory information in a more efficient manner, there is clear evidence that adult and infant auditory processing is not the same, and entrainment studies using adults cannot be used as a proxy for infant auditory entrainment (for a review of dissimilarities between adult and infant auditory processing please see Saffran, Werker &amp; Werner, 2006).</p><p id="P11">One expected contributor, especially during early infancy, is the maturation occurring in infant auditory cortices and neural networks (e.g., <xref ref-type="bibr" rid="R1">Adibpour et al., 2020</xref>). This, in turn, impacts infant’s ability to neurally synchronise with their environment and the people around them (<xref ref-type="bibr" rid="R220">Shafer, Yu &amp; Wagner, 2015</xref>; <xref ref-type="bibr" rid="R241">Uhlhaas et al., 2010</xref>). As an example, the original ASSR study in adults by <xref ref-type="bibr" rid="R82">Galambos et al., (1981)</xref> used as a technique to test auditory pathways, showed a distinctive response at 40Hz and was quickly taken up globally (<xref ref-type="bibr" rid="R134">Kuwada et al., 1986</xref>; <xref ref-type="bibr" rid="R194">Rees et al., 1986</xref>; Rickards and Clark, 1984; D. Stapells et al., 1984). However, there is not such a strong response in infants at higher frequencies including at 40Hz (<xref ref-type="bibr" rid="R158">Maurizi et al., 1990</xref>; Picton, 2003). Instead, this response grows as children mature into adults (<xref ref-type="bibr" rid="R206">Rojas et al., 2006</xref>) due to the protracted maturation of the auditory cortex (e.g. <xref ref-type="bibr" rid="R1">Adibpour, 2020</xref>), where the 40Hz ASSR has been reported to be centred in response to clicks, noise bursts (<xref ref-type="bibr" rid="R97">Hari, Hämäläinen, &amp; Joutsiniemi, S., 1989</xref>) and sinusoidal tones (<xref ref-type="bibr" rid="R104">Herdman et al., 2002</xref>).</p><p id="P12">Infants have been shown to entrain at a range of lower amplitude modulation frequencies (see <xref ref-type="sec" rid="S3">section 1.4</xref>) and have been shown to mentally construct meter in scenarios where there is an ambiguous meter (<xref ref-type="bibr" rid="R37">Cirelli et al., 2016</xref>). The ability to entrain to these low frequency rhythms may be a direct result of low amplitude modulated stimuli targeted at infants from adult caregivers, which has been shown to consistently change to match an infant’s abilities across many languages (<xref ref-type="bibr" rid="R170">Narayan &amp; McDermott, 2016</xref>).</p></sec><sec id="S4"><label>1.3</label><title>Why are slow amplitude modulated rhythms important?</title><p id="P13">Sounds include two key oscillatory components, a carrier frequency, which is often referred to as pitch, and an amplitude modulated frequency, often referred to as the rate, tempo or rhythm of a repeating sound. Carrier frequencies must be above 20Hz to fall into the audible range of humans, this overlaps with the amplitude modulated frequencies which start at rates below 0.1Hz and can reach into the hundreds of Hz. The point at which amplitude modulated frequencies become carrier frequencies is the point at which peaks, and troughs of the oscillations are no longer individually discernible from neighbouring oscillations.</p><p id="P14">Slow amplitude modulated rhythms are prevalent in natural sounds, which may carry critical information (<xref ref-type="bibr" rid="R223">Singh et al., 2003</xref>). They are a key component of human social interactions such as speech and have consistently been shown to encode temporal cues that help people forward predict social information during social interactions (<xref ref-type="bibr" rid="R3">Ahissar et al., 2001</xref>; Alaerts et al., 2008; <xref ref-type="bibr" rid="R6">Aiken &amp; Picton, 2008</xref>; <xref ref-type="bibr" rid="R22">Bertoncini et al., 2011</xref>; <xref ref-type="bibr" rid="R102">Henry, Herrmann and Grahn, 2017</xref>; <xref ref-type="bibr" rid="R248">Wang et al., 2011</xref>). <xref ref-type="bibr" rid="R91">Greenberg et al., (2003)</xref> demonstrated that properties of speech under 5Hz generally represent a lower branch of modulated speech, used for heavily stressed syllables, while speech properties with higher frequencies between 6-20Hz generally reflect unstressed syllables. <xref ref-type="bibr" rid="R90">Goswami and Leong, (2013)</xref> investigated the characteristics of speech and suggested that the stress, syllable and part of the phoneme presentation rate were under 20Hz.</p><p id="P15">Similarly, when phase locking value (PLV) of neural signal to white noise between 4-128Hz was calculated by <xref ref-type="bibr" rid="R147">Liegeois-Chauval et al., (2004)</xref> the auditory cortices were shown to have the strongest response to the lowest amplitude modulated frequencies between 4-16Hz, matching the range crucial for speech intelligibility.</p><p id="P16">While in the process of decoding the complex stimuli around an infant that help infants to develop the skilled task of contingent social interactions, it seems especially important that infants are able to neurally entrain to a range of low amplitude modulated signals. This is important in speech, as shown above, but also in the effect of a wider range low amplitude and ultra-low amplitude (˂ 1Hz) modulated oscillators including respiratory, arousal, sleep-wake and hormone cycles (<xref ref-type="bibr" rid="R74">Feldman, 2006</xref>; <xref ref-type="bibr" rid="R73">Feldman, 2007</xref>) on infant-caregiver synchrony. In the words of <xref ref-type="bibr" rid="R74">Feldman (2006)</xref> “the organization of physiological oscillators appears to lay the foundation for the infant’s capacity to partake in a temporally matched social dialogue”.</p></sec><sec id="S5"><label>1.4</label><title>Research of Stimuli Frequency</title><p id="P17">Given the importance of low amplitude modulated auditory frequencies to infant development, it is important to ask to which frequencies do infants best entrain? While there have been some infant-adult or infant studies, the question of entrainment to auditory stimuli has received much more attention in the adult literature.</p><p id="P18">Many MEG and EEG studies have examined these questions from the perspective of hearing acuity or auditory perception: <xref ref-type="bibr" rid="R151">Luo et al., (2006)</xref> investigated phase vs power neural tracking between 0.3-8Hz; <xref ref-type="bibr" rid="R179">Nozaradan, Peretz and Mouraux, (2012)</xref>, studied neural entrainment to beat and meter in musical rhythms between 0.426-5Hz; <xref ref-type="bibr" rid="R194">Rees, Green and Kay, (1986)</xref> looked at the effects of modulation depth on ASSR responses between 0.4-400Hz; Wang et al., (2012) studied sensitivity to spectral bandwidth in speech processing between 1.5-31.5Hz; <xref ref-type="bibr" rid="R190">Picton et al., (1987)</xref> examined the effects of amplitude modulation vs frequency modulation in the context of modulation depth between 2-12.7Hz; Peelle, Gross and David, (2013) examined neural responses to speech amplitude envelope between 4-7Hz; <xref ref-type="bibr" rid="R164">Millman et al., (2010)</xref> investigated the spatiotemporal structure of the auditory steady state response (ASSR) at 4, 8 and 12 Hz; <xref ref-type="bibr" rid="R102">Henry, Herrmann and Grahn (2017)</xref> examined responses to tone duration, onset/offset duration and input patterns between 5-40Hz; <xref ref-type="bibr" rid="R208">Roß, Borgmann and Draganova, (2000)</xref> investigated magnitude of neural response between 10-98Hz; <xref ref-type="bibr" rid="R134">Kuwada, Batra and Maher, (1986)</xref> looked at the impact of steady state responses on normally hearing vs hearing-impaired participants between 25-350Hz, with the largest steady state responses found between 25-50Hz.</p><p id="P19">There have been a few studies that have examined adults and infants including: <xref ref-type="bibr" rid="R227">Stapells et al., (1988)</xref> who tested 3 week to 28-month-old infants with a variety of steady state responses between 9-59Hz in 5Hz steps and showed no consistent neural peak. <xref ref-type="bibr" rid="R145">Levi, Folsom and Dobie, (1993)</xref> presented adults and 1 month old infants with stimuli amplitude modulated between 10-80Hz. Adults showed an increased magnitude of response at 40Hz which then dropped for later frequencies, while infants showed an increased linear response between 10-80Hz. <xref ref-type="bibr" rid="R9">Aoyagi et al., (1994)</xref> studied auditory sweeps of frequencies rapidly presented between 20-200Hz in 20Hz steps to gauge hearing acuity as a function of age in participants between 4 months to 15 years and a cohort of adults showing that the optimal steady state response was detected at 80Hz for young infants (2-4 years old). <xref ref-type="bibr" rid="R204">Riquelme et al., (2006)</xref> tested 149 newborns with a range of stimuli including carrier frequencies of 500, 1KHz, 2KHz and 4KHz that were amplitude modulated between 25-98Hz to test for the presence and magnitude of steady state responses. <xref ref-type="bibr" rid="R204">Riquelme et al., (2006)</xref> also tested the impact of intensity of these stimuli on the infants with stimuli volumes between 20-70dB. They demonstrated that there were steady state responses between 41-88Hz across all carrier frequencies. <xref ref-type="bibr" rid="R188">Pethe et al., (2004</xref>; see also <xref ref-type="bibr" rid="R215">Savio et al., 2004</xref>) investigated the impact of age on two frequencies, 40 and 80Hz, with infants between 2 months and 14 years old. <xref ref-type="bibr" rid="R188">Pethe et al., (2004)</xref> found that the optimal steady state response changed from 80Hz to 40Hz for children aged 13 and above, matching adult responses. Finally, <xref ref-type="bibr" rid="R202">Rickards et al., (1994)</xref> investigated the impact of modulation depth on 337 sleeping newborns between 60-100Hz, finding steady state responses at all frequencies tested to varying degrees.</p><p id="P20">The above research demonstrates that there have been investigations into the impact of stimuli frequency both in adult and infant studies. However, there are two issues with the above studies in relation to the current question. First, the majority of these studies, especially the infant studies, tested frequencies much higher than the low amplitude modulation rate important in speech and speech perception. Second, most of these studies have investigated a range of frequencies for the primary purpose of hearing acuity tests, which use a small number of cycles for each stimulation frequency. While there may be evidence of entrainment at these frequencies it is difficult to measure the extent to which these are the result of endogenous oscillators entraining to the stimuli or exogenously generated stimulus responses (<xref ref-type="bibr" rid="R95">Haegens &amp; Golumbic, 2018</xref>; <xref ref-type="bibr" rid="R252">Wass, Perapoch Amado &amp; Ives, 2021</xref>). It is expected that there will be a stimulus response to any stimuli in the environment that has a high enough intensity or salience, but this does not show the neural tracking of these stimuli after initial habituation, i.e. after the reduction of high magnitude exogenous stimulus responses, driven by a high level of attention to a new stimulus.</p></sec><sec id="S6"><label>1.5</label><title>Measuring Infant Neural Entrainment with Frequency Tagging</title><sec id="S7"><label>1.5.1</label><title>Frequency Tagging</title><p id="P21">There are multiple ways to investigate the characteristics of infant neural entrainment, one popular method is frequency tagging. Fundamentally, frequency tagging assumes that the neural response to a rhythmic stimulus will be at the same frequency as the stimulation frequency. This allows researchers to “tag” a particular response in a specific brain region. The enticing aspect of frequency tagging is that the stimulus characteristics can be manipulated to test perceptual capabilities (e.g. complex rhythm detection, <xref ref-type="bibr" rid="R179">Nozaradan et al., 2017</xref>), test high and low order comprehension (e.g. hierarchy of linguistic components in speech, <xref ref-type="bibr" rid="R149">Lo et al., 2022</xref>) and can be completed with multiple stimulus types in parallel (e.g. social vs non-social stimuli, <xref ref-type="bibr" rid="R244">Vettori et al., 2020</xref>). Frequency tagging requires minimal effort from participants, and in the case of auditory frequency tagging can be completed while participants sleep, as sleep has been shown to dull but not remove steady state responses (e.g. Cohen et al., 1991; <xref ref-type="bibr" rid="R112">Jerger et al., 1986</xref>; <xref ref-type="bibr" rid="R249">Wang et al., 2022</xref>).</p></sec><sec id="S8"><label>1.5.2</label><title>Stimulus Characteristics</title><p id="P22">Stimulus characteristics have been explored in previous literature. <xref ref-type="bibr" rid="R266">Zhou et al., (2016)</xref> have investigated the interpretation of expected responses to single stimuli vs repeated periodic stimuli, single stimulus duration and effects of fast onset/offset stimuli vs sinusoidal amplitude modulated stimuli, as well as expected harmonic responses using stimuli with varying characteristics. While <xref ref-type="bibr" rid="R119">Kabdebon et al., 2022</xref> have suggested considerations for the stimulation rate in frequency tagging studies, e.g. the stimulation frequency should bear in mind the cognitive response time of the region of interest being targeted; frequencies relating to dominant neural frequencies (6-9Hz in infants, 9-12Hz in adults) should be avoided if possible due to the higher resting power at these frequencies; and that there should be at least 4-8 frequency bins between stimulation frequencies if multiple stimuli are being tested. However, while previous research has suggested frequencies to avoid to stop the response clashing with dominant neural frequencies, to the best of our knowledge, there have been no studies that advise on which frequencies show the strongest entrainment.</p></sec><sec id="S9"><label>1.5.3</label><title>Analysis method</title><p id="P23">A tagged response can be seen both in the power and phase domains (for a review see <xref ref-type="bibr" rid="R119">Kabdebon et al., 2022</xref>). However, it is not clear from this review, which method of analysis should be preferred, whether both are needed or if the methods could be used interchangeably. <xref ref-type="bibr" rid="R268">Zoefel, ten Oever and Sack, (2018)</xref> describe one issue with using a Fourier transform to measure neural frequency tagged response. Neural mechanisms such as phase resetting of neural signals to better entrain to an ongoing stimulus violate the stationarity of the signal, so when compared to a sinusoid, e.g. during a fast Fourier transform, the power of the signal will be lowered. This may also represent an issue for phase analyses if the phase resetting produces phase angles that are opposed to one another (e.g. 180 degrees apart), as this may make the amplitude of the phase measure cancel itself out, e.g. during a biopolar or tripolar phase angle response.</p><p id="P24">One potential solution to this is to use entropy of phase angle. Entropy measures the variance in responses rather than a cumulative phase angle and so responses with bipolar or tripolar opposites would not be cancelled out. Entropy of phase angle has been used previously by <xref ref-type="bibr" rid="R175">Notbohm, Kurths and Herrmann, (2016)</xref> when measuring the impact of stimulus intensity on neural entrainment.</p></sec></sec><sec id="S10"><label>1.6</label><title>Auditory Frequency Tagging Regions of interest</title><p id="P25">Previous studies have focused on particular regions of interest when conducting auditory frequency tagging. Many of these relate to auditory centres of the brain, especially when the objective of the study is to use auditory frequency tagging as a measure of auditory perception. These include Cz only (e.g. <xref ref-type="bibr" rid="R9">Aoyagi et al., 1994</xref>; Cohen, Rickards and Clark, 1991; <xref ref-type="bibr" rid="R112">Jerger et al., 1986</xref>; <xref ref-type="bibr" rid="R166">Mühler, Rahne and Verheya, 2013</xref>; <xref ref-type="bibr" rid="R188">Pethe et al., 2004</xref>; <xref ref-type="bibr" rid="R227">Stappels et al., 1988</xref>); Forehead/FPz only (e.g. <xref ref-type="bibr" rid="R7">Alaerts et al., 2009</xref>; <xref ref-type="bibr" rid="R145">Levi, Folsom and Dobie, 1993</xref>; <xref ref-type="bibr" rid="R158">Maurizi et al., 1990</xref>; <xref ref-type="bibr" rid="R202">Rickards et al., 1994</xref>; <xref ref-type="bibr" rid="R204">Riquelme et al., 2006</xref>; <xref ref-type="bibr" rid="R215">Savio et al., 2001</xref>); vertex area (e.g. <xref ref-type="bibr" rid="R35">Choi et al., 2020</xref>; <xref ref-type="bibr" rid="R206">Rojas et al., 2006</xref>); surrounding the zenith line from anterior to posterior (e.g. <xref ref-type="bibr" rid="R48">Daneshvarfard et al., 2019</xref>; Ramos- Escobar et al., 2021); and whole head recordings (e.g. <xref ref-type="bibr" rid="R14">Attaheri et al., 2022</xref>, <xref ref-type="bibr" rid="R35">Choi et al., 2020</xref>, <xref ref-type="bibr" rid="R37">Cirelli et al., 2016</xref>; <xref ref-type="bibr" rid="R104">Herdman et al., 2002</xref>; <xref ref-type="bibr" rid="R118">Kabdebon et al., 2015</xref>).</p><p id="P26">Choosing a region of interest is often part of a hypothesis driven approach. Investigating commonly known regions of activity (e.g. electrodes corresponding to A1, Wernicke’s area, Broca’s area or the perisylvian region), using previous research highlighting topographic activity or reducing unnecessary topographic artefact are seen as methods to reduce fishing for spurious results. However, there is also the possibility to miss potentially interesting regional activation when investigating a topic where there is limited knowledge, especially as there are developmental changes in the topographic activity due to broader developmental change.</p></sec><sec id="S11"><label>1.7</label><title>Current Study Aims</title><p id="P27">The current study aims to fill the gap in this research area by testing infants and adults with a range of low amplitude modulated frequencies to investigate their neural entrainment responses and determine if there is a preference for any particular frequency. It is expected that there will be an increased response at the dominant frequencies for infants (6-9Hz) and adults (9-12Hz), which will be seen in both power and phase analyses. This is thought to be true because these dominant frequencies can be flexible to help track oscillations in the environment (for a review see <xref ref-type="bibr" rid="R268">Zoefel, ten Oever and Sack, 2018</xref>), but increasing the spectral distance between two oscillators increases the intensity of the stimuli to bring two oscillators in alignment, which is the fundamental concept of the Arnold’s tongue (<xref ref-type="bibr" rid="R175">Notbohm, Kurths, Herrmann, 2016</xref>; <xref ref-type="bibr" rid="R268">Zoefel, ten Oever &amp; Sack, 2018</xref>).</p><p id="P28">We anticipate that there will be differences in the power and phase response; responses over the time course of the stimulation; and with regional differences across the scalp. Using the frequency that shows the strongest response for each participant group, the current study will therefore investigate differences in power vs phase, temporal and spatial responses. We realise that this investigation will not be generalisable to all studies due to the broad range of stimulus types, infant participant ages and experimental settings. This means that we cannot provide authoritative guidance on the best approach to all research scenarios. However, we expect to learn lessons that will be valuable to the infant development, neural entrainment and frequency tagging communities when planning similar studies.</p></sec></sec><sec id="S12" sec-type="methods"><label>2</label><title>Method</title><sec id="S13" sec-type="subjects"><label>2.1</label><title>Participants</title><p id="P29">26 adult-infant dyad participants were recruited as part of a wider longitudinal project. Of these, 7 infant datasets were rejected due to poor data quality, 6 adult datasets were rejected due to technical fault or poor data quality. The study included 7 conditions: no sound (rest), 2Hz, 4Hz, 6Hz, 8Hz, 10Hz and 12Hz. After preprocessing of EEG data, infants contributed 6, 8, 11, 10, 12, 9 and 9 participants to these passive audio conditions respectively, while adults contributed: 6, 7, 10, 12, 18, 6 and 10 participants to the same conditions, a table detailing which participants completed which conditions has been placed in the supplementary materials. Conditions were presented in a random order, testing was stopped if the child fussed or woke up, contributing to the uneven sample sizes. Participant information has been included in the <xref ref-type="supplementary-material" rid="SD1">supplementary materials</xref>.</p><p id="P30">Mean adult participant age was 35.53 years (standard error, 0.698), mean infant age 5.39 months (range 4.46-6.36 months, standard error 0.099). All adult participants were female, infant participants included 16 male, 10 female. Infants had an average gestational age of 40.51 weeks.</p><p id="P31">The University of East London ethics committee approved the study. All adult participants provided informed consent for both themselves and their children according to the Declaration of Helsinki. All participants were offered a £10 shopping voucher as a monetary reward for their time. Travel and food expenses were also covered for those that requested them.</p><p id="P32">The current experiment was part of a longitudinal research project, which tests infant-caregiver dyads at 5-, 10-, 15- and 36-month timepoints. As part of the testing protocol a lab session is run split into three sessions. The data for this study was one of the sessions, the order of which varied depending on when the infants slept during the day.</p></sec><sec id="S14"><label>2.2</label><title>Stimuli</title><p id="P33">Audio stimuli were generated in MATLAB 2021b, consisting of pure sinusoidal tones using a carrier frequency of 1000Hz and sinusoidal amplitude modulation at either 2, 4, 6, 8, 10 or 12Hz saved with a sampling frequency of 48KHz. Audio stimuli had a minimum amplitude of -1 and a maximum amplitude of 1, which was then controlled to the target volume of 65dB using on speaker controls and a sonometer. Each audio file was created with 240 seconds of continuous audio.</p></sec><sec id="S15" sec-type="methods"><label>2.3</label><title>Procedure</title><p id="P34">Data collection was conducted when an infant fell asleep during a lab testing session. The experimental environment changed depending on how the infant was comfortable sleeping. Infants slept in their mothers’ arms, in a moses basket, on a sofa, baby sling/carrier or in their pram. The room was kept quiet and in the majority of cases the lights were dimmed to help the child sleep. No auditory sleep aids were permitted.</p><p id="P35">Creative SBS 250 speakers were placed close to the participants and calibrated to 65dB at the participants’ ear using a RS PRO RS-95 sonometer, chosen to be at the average volume of standard speech (e.g. Olsen, 1998).</p><p id="P36">Adult participants were also instructed to listen to the passive audio task and were permitted to sleep. Participants were asked not to do any rhythmic motions including: chewing, talking, fidgeting, waving, bouncing etc, and asked not to eat or use any electronic devices. Participants were told that if they wanted to stop for any reason or if the infant woke up then the procedure would be stopped.</p></sec><sec id="S16"><label>2.4</label><title>EEG Data Acquisition</title><p id="P37">EEG signals were obtained using a dual BioSemi (Amsterdam, NL) ActiveTwo system configured for 64 channel recording from both participants simultaneously. Participants wore size appropriate 64 channel Electro-Cap International (Ohio, US) caps with a 10-20 electrode montage. Common Mode Sense and Driven Right Leg electrodes between Pz and POz were used as the active reference. EEG signals were recorded at 512Hz with no online filtering using ActiView data acquisition software (version 7.07; BioSemi). Signa Gel conductive electrode gel from Parker Laboratories BV (Almelo, NL) was used to bridge the connection between the electrodes and the participant’s scalp.</p></sec><sec id="S17"><label>2.5</label><title>EEG Artifact Rejection and Preprocessing</title><p id="P38">A modified version of <xref ref-type="bibr" rid="R155">Marriott-Haresign et al.’s, (2021)</xref> automated EEG artifact rejection and pre-processing pipeline was implemented. First the data were high pass filtered at 1Hz using the EEGLAB (<xref ref-type="bibr" rid="R55">Delorme &amp; Makeig, 2004</xref>) function <italic>pop_eegfiltnew.m</italic> (<xref ref-type="bibr" rid="R258">Widmann, 2008</xref>; default settings, filter order 3380). Second, line noise was removed using a notch filter with <italic>pop_cleanline.m</italic> (<xref ref-type="bibr" rid="R167">Mullen, 2012</xref>). Third, a low pass filter was applied at 25Hz with the same settings as the highpass filter. Fourth, the data were referenced to a robust average, calculated by first temporarily removing noisy channels using <italic>clean_channels.m</italic> (<xref ref-type="bibr" rid="R130">Kothe, 2014</xref>; default settings) and averaging the remaining channels. Fifth, after averaging all channels using the robust average, channels that were subsequently still noisy were rejected using <italic>clean_lines.m</italic> with a correlation threshold of 0.7 and a noise threshold of 4. Subsequently, all channels that were not rejected were put through <italic>eBridge.m</italic> (<xref ref-type="bibr" rid="R8">Alschuler et al., 2014</xref>; default settings) to identify bridged electrodes. All electrodes that were identified as noisy or bridged were interpolated using the spherical method of <italic>eeg_interp.m</italic> (<xref ref-type="bibr" rid="R54">Delorme, 2006</xref>). Sixth, using a sliding 1 second window without overlap, epochs were rejected and zeroed out if 70% of the channels exceeded -3.5 to 5 standard deviations of a robust estimate of channel EEG power. This was completed using <italic>clean_windows.m</italic> (<xref ref-type="bibr" rid="R131">Kothe, 2010</xref>). <xref ref-type="supplementary-material" rid="SD1">Supplementary materials</xref> show that there was no violation of stationarity using this method and no bias towards any frequency.</p><p id="P39">EEG data were rejected based if more than 25% channels interpolated (42.5% of infant conditions and 25.5% of adult conditions removed); more than 25% continuous sections removed (14.9% vs 12.8% conditions removed for infant vs adult participants).</p></sec><sec id="S18"><label>2.6</label><title>Data Analysis Plan</title><p id="P40">The first analysis investigated whether different low amplitude modulation frequencies cause different strengths of neural entrainment in infant and adult participants. This was completed by comparing the amplitude of the signal to noise ratio value at the target frequency bin across conditions using an ANOVAN. The subsequent analyses will only use the low amplitude modulated frequency which shows the strongest entrainment response.</p><p id="P41">The second analysis tested the sensitivity of power, phase and variance analyses using fast Fourier transform (FFT), phase locking value (PLV) and entropy of phase locking value (entropy) respectively. These will be completed on the participant samples and on individual participants.</p><p id="P42">The third analysis examined whether there is an increase or decrease in entrainment response over time. The four-minute condition was segmented into 2-minute, 1 minute and 30 second epochs. Power and phase analyses were completed to show trends of entrainment over time.</p><p id="P43">Finally, the fourth analysis studied entrainment responses using predetermined regions of interest from previous literature vs whole head neural responses.</p><sec id="S19"><label>2.6.1</label><title>Analysis 1 – Between Low Amplitude Modulated Frequencies</title><p id="P44">Our first research question was to investigate whether different low amplitude modulation frequencies cause different strengths of neural entrainment in infant and adult participants. To address this, first for each participant x electrode x condition timeseries, a check was run to ensure that each timeseries was the same length. Any timeseries that was shorter than the required 122880 samples (512Hz x 240 seconds) were zero padded. A check was conducted to determine whether the zero padding would have an impact on the spectral composition, see supplementary materials. An FFT was calculated using a modified <italic>myFFT.m</italic> (Schoof, 2017) MATLAB script.</p><p id="P45">PLV (<xref ref-type="bibr" rid="R135">Lachaux et al., 1999</xref>) was calculated for each of the participant x electrode timeseries against frequencies of interest 2Hz above and below the condition’s target frequency in 0.01Hz steps. For example, for the 8Hz condition, a 6-10Hz window was selected giving 401 frequency bins. For the 2Hz condition, frequencies of interest were 1-4Hz in 0.01Hz steps due to the high pass filter completed during preprocessing stage. Any timeseries that was shorter than the required 122880 samples were zero padded in the same way as the FFT analysis. For each participant x electrode timeseries, a perfect sinusoid signal for each frequency bin within the frequencies of interest range was created with the same temporal length. A phase angle timeseries was calculated for the EEG timeseries and each of the frequencies of interest by taking the Hilbert transform of the data and calculating the phase angle. The difference between the neural phase angle timeseries and the frequencies of interest timeseries were taken, multiplied by the imaginary operator i to give a complex number and the exponential was determined for each value. PLV was calculated as the average exponential value in the timeseries. One PLV value is calculated for each frequency of interest.</p><p id="P46">After power (FFT) and phase (PLV) analyses were completed on the cleaned data sets in MATLAB 2021b (see Supplementary Materials for scripts used) the resulting data were then passed through a signal to noise ratio (SNR) script to standardise the data across conditions by removing the 1/f component of the neural data for each electrode x participant (e.g. <xref ref-type="bibr" rid="R245">Vettori et al., 2019</xref>).</p><p id="P47">SNR scores were calculated using a moving window of 25 frequency bins for each dataset between the first and last frequency of interest, for each participant x condition spectral series, in 0.01Hz steps. Of the 24 bins either side of the central frequency, the two closest frequency bins, and two bins within the remaining range with the maximum absolute difference from the target were removed and the average of the remaining 20 bins was taken from the central frequency bin.</p><p id="P48">For each condition x electrode x participant, the amplitude of the SNR score at the stimulation frequency was taken. An N-ways ANOVA (ANOVAN), <italic>anovan.m,</italic> was completed to test the significance of the SNR amplitude across stimulation frequency conditions (rest, 2Hz, 4Hz, 6Hz, 8Hz, 10Hz and 12Hz). An ANOVAN was chosen due to the uneven participant numbers per condition. Multiple comparisons, using <italic>multcompare.m,</italic> were completed when an ANOVAN showed significant differences.</p></sec><sec id="S20"><label>2.6.2</label><title>Analysis 2 – Sensitivity of power, phase and variance analyses</title><p id="P49">Our second research question tested the sensitivity of power, phase and variance analyses using FFT, PLV and entropy of phase locking value respectively. To investigate this, using only the stimulation frequency found to show strongest entrainment in analysis 1, FFT and PLV were calculated for each participant x electrode timeseries in the same way as in analysis 1.</p><p id="P50">Additionally, normalised entropy (<xref ref-type="bibr" rid="R221">Shannon, 1948</xref>; <xref ref-type="bibr" rid="R235">Tass et al., 1998</xref>) of PLV was calculated for each participant x electrode timeseries. Each timeseries was compared against frequencies of interest 1-4Hz in 0.01Hz steps. A phase angle timeseries for neural data and each sinusoidal signal for the frequencies of interest, along with the phase angle difference between the EEG timeseries and each of the frequencies of interest were created in the same way as in the PLV analysis. The entropy value was calculated over 80 bins (<xref ref-type="bibr" rid="R175">Notbohm, Kurths and Herrmann, 2016</xref>) using the below formula (<xref ref-type="bibr" rid="R92">Gross et al, 2021</xref>; <xref ref-type="bibr" rid="R175">Notbohm, Kurths, Herrmann, 2016</xref>), where H is the entropy and Pi is the probability of a given phase. <disp-formula id="FD1"><mml:math id="M1"><mml:mrow><mml:mi>H</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mi>∑</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mspace width="0.2em"/><mml:mi>b</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mspace width="0.2em"/><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mspace width="0.2em"/><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p id="P51">The probability of a given phase was calculated using <italic>hist.m</italic> to calculate the count and centre of each bin. The bin width was then determined as the difference between bin centres with <italic>diff.m</italic> and the maximum minus the minimum value. The counts per bin above 0 were collated and the probability of a value in each bin was calculated as the number of above zero values in the bin divided by the total number of values.</p><p id="P52">The resulting data were then passed through the same SNR script as in analysis 1. For the group wide analyses the data was averaged over electrodes and participants to give one FFT, PLV and entropy dataset. For individual participant analyses, the data were averaged over the electrodes only to give one data set for each of the analysis types per participant.</p><p id="P53">Next a permutation analysis was completed on each dataset. The SNR value at 2Hz was recorded as the test value. Bootstrapping with replacement was completed to create 10,000 surrogate datasets per participant and analysis type using <italic>bootstrp.m</italic> (<xref ref-type="bibr" rid="R68">Efron &amp; Tibshirani, 1993</xref>). For each surrogate dataset the original test value was ranked against all surrogate values to give a test value rank. The 10,000 test value ranks generated with the surrogate datasets were then averaged to give an overall rank. The overall rank was considered significant if it fell in the top 5% of ranks.</p></sec><sec id="S21"><label>2.6.3</label><title>Analysis 3 – Entrainment over time analyses</title><p id="P54">Our third analysis examined whether there is an increase or decrease in entrainment response over time. To test this, using only the stimulation condition with the strongest entrainment, to see if there was an increase or decrease in entrainment over time, preprocessed data were segmented into 1 x 4 minute window, 2 x 2 minute windows, 4 x 1 minute windows or 8 x 30 second windows.</p><p id="P55">FFT and PLV were calculated for each participant x electrode x time window timeseries in the same way as in analysis 1. Subsequently SNR values were calculated in the same way as analysis 1. SNR spectral series were averaged over participant and electrode to give one dataset for infants and adults, for both power and phase analysis, and for each time window. Then, permutation analysis was conducted in the same way as in analysis 2. This generated ranked permutation results in power and phase analyses for each time window and each participant group.</p></sec><sec id="S22"><label>2.6.4</label><title>Analysis 4 – Entrainment over space analyses</title><p id="P56">Our final analysis studied entrainment responses using five predetermined regions of interest from previous literature vs whole head neural responses. These five regions of interest were selected prior to the results being known. Electrodes referring to Cz; Fz-FCz-Fz; the central zenith line from anterior to posterior of the head (FPz, AFz, Fz, FCz, Cz, CPz, Pz, POz, Oz), the zenith line plus two lines of electrodes either side (referred to as expanded zenith line; Fp1, FPz, FP2, AF3, AFz, AF4, F1, Fz, F2, FC1, FCz, FC2, C1, Cz, C2, CP1, CPz, CP2, P1, Pz, P2, PO3, POz, PO4, O1, Oz, O2), and a square of 9 electrodes surrounding and including Cz (referred to as the vertex area; FC1, FCz, FC2, C1, Cz, C2, Cp1, CPz, CP2) were chosen as the potential regions of interest.</p><p id="P57">For each of these regions of interest, FFT and PLV were calculated for each participant x electrode for the full 4-minute timeseries in the same way as in analysis 1. Subsequently SNR values were calculated in the same way as analysis 1. SNR spectral series were averaged over participant and electrode cluster to give one dataset for infants and adults, for both power and phase analysis, for each region of interest. Then permutation analysis was conducted in the same way as in analysis 2. This generated ranked permutation results in power and phase analyses for each region of interest and each participant group.</p><p id="P58">Along with these analyses, topographic reporting of the whole head of electrodes was also completed and is shown in the results section to compare the ground truth regions of activation vs the clusters analysed.</p></sec></sec></sec><sec id="S23" sec-type="results"><label>3</label><title>Results</title><sec id="S24"><label>3.1</label><title>Analysis 1 – Between Stimulation Frequencies</title><p id="P59">A comparison of the entrainment to the low amplitude modulated frequency conditions rest (no sound), 2, 4, 6, 8, 10 and 12Hz was completed in both the power and phase domains using FFT and PLV.</p><sec id="S25"><label>3.1.1</label><title>Power analysis</title><p id="P60">An ANOVAN comparing different SNR values of FFT results for rest (no sound) and stimulation frequencies (2, 4, 6, 8, 10 and 12Hz) for both infant (<xref ref-type="fig" rid="F3">figure 3a</xref>) and adult (<xref ref-type="fig" rid="F3">figure 3b</xref>) participants showed there was a significant difference between conditions in the power domain both for infants (F(6,63) = [40.996], p ˂ 0.001) and adults (F(6,63) = [138.617], p ˂ 0.001). There were no significant differences between electrodes (p ˃ 0.05).</p><p id="P61">Multiple comparisons were completed using the <italic>multcompare.m</italic> Matlab library, which showed that the 2Hz stimuli had the strongest response, being significantly higher than all other conditions for both infants and adults. Three other statistical differences were shown for infant participants (see <xref ref-type="table" rid="T1">table 1</xref>) between 10Hz and 6/8Hz and between 6Hz and rest. For adult participants, as well as differences between 2Hz and other frequency conditions, 4 and 10Hz conditions were also significantly different than rest, 6, 8 and 12Hz conditions. Statistical differences for adult participants are shown in <xref ref-type="table" rid="T1">table 1</xref>.</p></sec><sec id="S26"><label>3.1.2</label><title>Phase analysis</title><p id="P62">An ANOVAN comparing different SNR values of PLV results between stimulation frequencies for both infant (<xref ref-type="fig" rid="F4">figure 4a</xref>) and adult (<xref ref-type="fig" rid="F4">figure 4b</xref>) participants both show significant differences (infant, F(6, 63) = [35.903], p ˂ 0.001; adult, F(6,63) = [131.33], p ˂ 0.001). There were no significant differences between electrodes (p ˃ 0.05).</p><p id="P63">Multiple comparisons were completed using the <italic>multcompare.m</italic> Matlab library, which showed that the 2Hz stimuli had the strongest response for both adults and infants, being significantly different from all other conditions. Three other statistically significant results were found, shown in <xref ref-type="table" rid="T2">table 2</xref>. For adult participants multiple other statistical differences were found, which are shown in <xref ref-type="table" rid="T2">table 2</xref>.</p></sec></sec><sec id="S27"><label>3.2</label><title>Analysis 2 – Sensitivity of power, phase and variance analyses</title><p id="P64">Having identified that the strongest entrainment between conditions was observed at 2Hz, we went on to investigate the sensitivity of power, phase and variance analyses using FFT, PLV and entropy at both the group and individual level.</p><sec id="S28"><label>3.2.1</label><title>Comparison of FFT, PLV and entropy at a group level</title><p id="P65">A bootstrapping analysis of the SNR scores derived from FFT, PLV and entropy analyses was conducted. <xref ref-type="fig" rid="F5">Figure 5</xref> shows the spectral series for adults and infants for each analysis type. <xref ref-type="table" rid="T3">Table 3</xref> shows the SNR values for each participant and analysis condition. All conditions were highly significant (p ˂ 0.01) except for infant entropy (p ˃ 0.05).</p><p id="P66">To investigate if there was a difference between infant and adult participant populations, a Welch’s t-test was completed between infants and adult SNR scores at the 2Hz stimulation frequency for each analysis type to test for differences between the participant groups. This was not significantly different for any of the groups (p ˃ 0.05). An ANOVA comparing the mean ranks achieved for each participant’s bootstrapped values between each analysis type was completed to investigate if the results were significantly different between analysis types. This was not significant for either infants or adults (p ˃ 0.05).</p></sec><sec id="S29"><label>3.2.2</label><title>Comparison of FFT, PLV and entropy at an individual level</title><p id="P67">To investigate individual differences in frequency tagging responses and examine if the significant findings at the group level were driven by a small number of individuals or were seen across the group, analyses on a participant-by-participant basis were conducted. The analysis was the same as at the group level (<xref ref-type="sec" rid="S28">section 3.2.1</xref>) but used datasets that had not been averaged over participants. <xref ref-type="table" rid="T4">Table 4</xref> shows the per participant data and significance. Data quality metrics per participant are shown in <xref ref-type="supplementary-material" rid="SD1">Supplementary Materials</xref>.</p><p id="P68">There were more adult participants that were found to have a significant frequency tagging response at 2Hz (FFT, 86%; PLV 71%; entropy 57%) compared to infant participants (FFT, 25%; PLV 50%, entropy 13%). There were also more highly significant results for adult participants across analyses (52%) compared to infant results (17%).</p></sec></sec><sec id="S30"><label>3.3</label><title>Analysis 3 – Entrainment over time analyses</title><p id="P69">The 2Hz stimulation condition was the only condition used, as this had shown the strongest entrainment response (see analysis 1). To investigate if there is a progression or reduction in entrainment as measured by different analyses, a comparison of four-time lengths was made for power (FFT) and phase (PLV) analyses. Conditions contained 4-minute recordings which were split into either: 1 x 4-minute windows, 2 x 2-minute windows, 4 x 1-minute windows or 8 x 30-second windows. A bootstrapping analysis was used to compare the test value derived from the 2Hz frequency bin for each of the temporal epochs in the same way as in analysis 2. <xref ref-type="table" rid="T5">Table 5</xref> shows the SNR score at the 2Hz stimulation frequency across segments for each participant group, analysis type and time segments.</p></sec><sec id="S31"><label>3.4</label><title>Analysis 4 – Entrainment over space analyses</title><p id="P70">To test the spatial location of the frequency tagging response in both infants and adults, and to test the validity of regions of interest selected in previous research. A bootstrapping permutation analysis was conducted that was the same as in analysis 2 and applied to each region of interest (electrode locations are listed in <xref ref-type="sec" rid="S22">section 2.6.4</xref>). Table 6 shows which areas of interest showed significance, with all areas being significant for both FFT and PLV for adults. In infant data Fz-FCz-Cz, zenith line and expanded zenith line were significant in the FFT data (p ˂ 0.01, p ˂ 0.05, p ˂ 0.05) and Fz-FCz-Cz, expanded zenith line and vertex area were significant in the PLV data (all p ˂ 0.05).</p><p id="P71">To compare these regions to the significant clusters seen across the whole head, topoplots of SNR scores for FFT and PLV analyses for participant groups are shown in <xref ref-type="fig" rid="F6">figure 6 (a-d)</xref>, and significance values are mapped with the topoplots in <xref ref-type="fig" rid="F6">figure 6 (e-h)</xref>.</p></sec></sec><sec id="S32" sec-type="discussion"><label>4</label><title>Discussion</title><sec id="S33"><label>4.1</label><title>Overview</title><p id="P72">In this study we examined how a range of low amplitude modulated frequencies impact the level of neural entrainment recorded with young (4–6-month-old) infants and their adult caregivers. We also investigated the sensitivity of analysis methods and spatiotemporal characteristics of infant and adult entrainment to the stimulation frequency that showed the strongest neural entrainment. To the best of our knowledge, no previous research has demonstrated a direct comparison of these important low amplitude modulated frequencies under the same conditions.</p><p id="P73">One issue when comparing across frequencies is the 1/f nature of neural data makes it difficult to compare absolute values in response to different stimulation frequencies (e.g. <xref ref-type="bibr" rid="R31">Cellier et al., 2021</xref>). Another issue is that the range of values expected for each analysis is different (e.g. <xref ref-type="bibr" rid="R92">Gross et al., 2021</xref>). To combat this, all results were subjected to a signal to noise ratio calculation to remove the average of the surrounding data and normalise the results. Below when referring to different frequency or analysis conditions these are all in fact the signal to noise ratio versions of these data so that they can be compared.</p></sec><sec id="S34"><label>4.2</label><title>Between Low Amplitude Modulated Frequencies</title><p id="P74">The results comparing low amplitude modulated frequency conditions found that both adult and infant participants showed the strongest response in both the power and phase domains to the 2Hz stimuli when compared to all other conditions. While many stimulation frequencies have been used in a range of auditory frequency tagging studies (see <xref ref-type="sec" rid="S7">section 1.4</xref>), to our knowledge this is the first study to directly compare this range of low amplitude modulated stimulation frequencies as a measure of infant and adult neural entrainment and shows that not all low amplitude modulated stimulation frequencies are responded to equally.</p><p id="P75">This contradicts our hypothesis that there would be an increased response to neural frequencies related to the resting states of the infant (6-9Hz) and adult (9-12Hz) brains. This was thought to be the case due to the increased power at these frequencies and previous research by <xref ref-type="bibr" rid="R175">Notbohm, Kurths and Sack, (2016)</xref> which demonstrated that increasing spectral distance between a neural oscillator and stimulus frequency requires an increase in the stimulus intensity to bring the two oscillators into alignment. While there was some increase in the neural entrainment response seen at these dominant frequencies to the stimulation frequency, this was dwarfed by the response to the 2Hz condition.</p><p id="P76">Aside from the 2Hz condition vs other stimulation frequencies there were some significant differences seen, which often did reflect the difference between frequencies that were at the participants’ dominant frequency vs others. In the power domain, for adult participants there were significant differences found with an increased response at 4 and 10Hz vs rest, 6, 8 and 12Hz frequencies. Whereas, in the infant group there were significant differences found with an increased response shown at 6 and 8Hz vs 10Hz, as well as 4Hz vs rest. In the phase domain, for adult participants, there was a significantly increased response from the 4 and 10Hz conditions when compared to rest, 6 and 12Hz conditions as well as an elevated response in 10Hz compared to 8Hz, and 8Hz compared to 6Hz conditions. For infant participants, there were significantly increased neural responses to the 4 and 8Hz conditions vs 12 Hz, as well as 8Hz vs rest.</p><p id="P77">This reinforces previous work (e.g., <xref ref-type="bibr" rid="R119">Kabdebon et al., 2022</xref>) that has suggested it is best to avoid stimulation frequencies that correspond to these dominant neural frequencies without an appropriate control. This could be an issue when comparing between groups of different ages that are above and below the ages of ˜7 years old. As noted in the paper by <xref ref-type="bibr" rid="R31">Cellier et al., (2021)</xref> the resting dominant frequencies of children changes at ˜7 years old from a dominant theta band of ˜7Hz to a dominant alpha band of ˜10Hz. These findings also present an issue for studies that choose to present frequency tagged stimuli at multiple frequencies which include dominant neural frequencies, without having an appropriate control. Researchers may not be able to differentiate how much of the result in this range is due to the frequency tagging condition and how much is due to an underlying endogenous oscillatory activity.</p><p id="P78">It is interesting that both infants and adults responded more strongly to the lowest amplitude modulated stimulation that was presented, which raises further questions. While 2Hz was the stimulation frequency that showed the strongest response in this study, it is not clear from these results whether this is because 2Hz condition truly shows the strongest response of all possible low amplitude modulated frequencies, or whether this shows the strongest response because this study didn’t investigate the 0.1-4Hz frequency range in enough detail. Future studies should investigate the neural response to stimuli between 0.1 and 4Hz to further our understanding.</p><p id="P79">The researchers of the current study considered confounding explanations for the strength of neural response at 2Hz. Perhaps the result at 2Hz represents the resting heart rhythm of the infants and adults, who have an average heart rhythm of 2.15Hz and 1.2Hz respectively (<xref ref-type="bibr" rid="R181">Ostchega et al., 2011</xref>). Similarly, it could be questioned whether the results are due to the 1/f distribution of the neural signal. However, for both of these theories, this would also have been seen in the resting data collected.</p><p id="P80">Another possibility is that the result could be attributed to the language heard by participants, English has many elements that follow a 2Hz structure including a 2Hz “stress” rate (<xref ref-type="bibr" rid="R90">Goswami and Leong, 2013</xref>; Leong, 2014), and infant directed speech also shows similar prosodic stress components at 2Hz (<xref ref-type="bibr" rid="R142">Leong and Goswami, 2015</xref>). While not all participants were native English speakers, all certainly had proficient English enough to live in the UK and it is to be expected that the infants will have been heavily exposed to English in their environments. Further studies are required in cultures that do not share this property with the English language.</p></sec><sec id="S35"><label>4.3</label><title>Sensitivity of power, phase and variance analyses</title><p id="P81">On a group level, investigation of FFT, PLV and entropy analyses as a method of detecting frequency tagging responses showed that FFT and PLV demonstrated a significant frequency tagged neural response at the target stimulation frequency of 2Hz. This is consistent with previous studies (see <xref ref-type="sec" rid="S9">section 1.5.3</xref>). Entropy showed the same result for adult participants only, suggesting that the variance in PLV as measured in the entropy measure was not a strong predictor of frequency tagged results. This contrasts with previous studies looking at entropy of PLV as a method to detect neural frequency tagged response (Notbohm, Kurths and Sack, 2018). This may be because previous studies have focused on entropy as a measure of frequency tagging in adults rather than young infants. There were no significant differences found between infant and adult results at the 2Hz stimulation frequency for FFT or PLV analyses, but there was a significant difference found between infant and adult entropy values, which was to be expected.</p><p id="P82">On a participant-by-participant level, the results showed that not all participants had a significant frequency tagging response at 2Hz and that a significant result using one analysis did not always translate to a significant result across all analysis types. Adult participants had more individual participants that showed a frequency tagging response than infants. This likely caused the non-significant but lower response at 2Hz from infants as seen in <xref ref-type="fig" rid="F5">figure 5</xref>. Individual participant details relating to age, infant gestation and gender are shown in supplementary materials. Infant participants that showed a neural response were not of one age group, gender or having had a particularly long or short gestation period. Data quality metrics are also shown in the supplementary materials. Analyses suggested that data quality was not a significant driver of whether significant entrainment was observed.</p></sec><sec id="S36"><label>4.4</label><title>Entrainment over time analyses</title><p id="P83">To investigate whether there is an increase or decrease in entrainment as measured by the frequency tagging response, data were segmented into 4, 2 or 1 minute or 30 second chunks and bootstrapping analyses were conducted on each segment for each participant group. For infant FFT analysis, data remained significant throughout the 4- and 2-minute segments and for the first three of the 1-minute segments. Data were also significant for the 1<sup>st</sup> and 4<sup>th</sup> of the 30 second chunks. For infant PLV analysis, data were significant for all the 4-, 2- and 1-minute segments and the 1<sup>st</sup> and 6<sup>th</sup> 30 second segments. Infants showed no clear pattern of significant segments. Adult results showed all the 4-, 2- and 1-minute segments for both FFT and PLV analyses were significant as well as the 5-7<sup>th</sup> and 4-7<sup>th</sup> segments in FFT and PLV analyses respectively. There was no clear pattern showing a change of significance results between the timeseries.</p><p id="P84">As the data for these segments is the same but divided into smaller and smaller pieces, it could be suggested that taking the spectral series from a smaller timeseries decreases the response seen to the stimulation frequency, which in turn reduces the likelihood of seeing a statistically significant result. This is evidenced by smaller segments of highly significant epochs not being subsequently significant, for example when comparing the first two 1 minute segments of adult FFT results (p ˂ 0.05 and p ˂ 0.01) to the first four 30 second segments (all p ˃ 0.05). This suggests that the length of the stimulation is important to seeing a statistically significant result.</p></sec><sec id="S37"><label>4.5</label><title>Spatial analyses</title><p id="P85">Previous studies have used specific regions of interest to investigate frequency tagging. These areas are often chosen to satisfy hypothesis driven research, but in many cases are also centred around auditory regions of the brain. Five ROIs were found in previous literature (see <xref ref-type="sec" rid="S10">section 1.6</xref>), these were each tested to show if they would demonstrate a frequency tagging response. The ground truth frequency tagging response was also shown in topoplots. In adult data all five of the regions of interest showed significant results, while infant data showed significant results in the: Fz-FCz-Cz electrodes (FFT and PLV); zenith line region (FFT only); expanded zenith line (FFT and PLV) and in the vertex region (PLV only).</p><p id="P86">Further data showed that there were significant clusters in adult data in a slightly left lateralised fronto-central region and in a tempero-occipital cluster spread across both hemispheres. In infant data a right lateralised fronto-central-parietal cluster was shown along with a left lateralised occipital-temporal cluster. This may suggest that while there is some overlap between the predefined clusters that previous studies have used, there are other areas that are of interest outside the usual regions of interest. The lateralisation seen in infant data and the slight lateralisation on the opposite side of the adult data is also interesting as it may represent a developmental change in response to these stimuli. While no developmental conclusions can be drawn from the current results it is worth further study to see if there is a gradual or sudden shift in significant regional clusters over time.</p></sec></sec><sec id="S38" sec-type="conclusions"><title>Conclusion</title><p id="P87">Careful choice of low amplitude modulated stimulation frequency should be an important consideration when designing a frequency tagging experiment. Based on current findings choosing a 2Hz low amplitude modulated frequency offers a comparable stimulation frequency between young infant and adult participants. Other stimulus and analysis choices are also worth considering, including having sufficient stimulus length and conducting whole head recordings where possible. There were no significant differences between power and phase analyses.</p></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary Material</label><media xlink:href="EMS158367-supplement-Supplementary_Material.pdf" mimetype="application" mime-subtype="pdf" id="d30aAdFbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S39"><title>Acknowledgements</title><p>This project was funded by the European Research Council (ERC Horizon 2020; award number 853251). The authors thank Dr Sofie Vettori and Dr Victoria Leong for their helpful comments during the initial stages of this article.</p></ack><sec id="S40" sec-type="data-availability"><title>Data and Code Availability</title><p id="P88">MATLAB code, stimuli files, raw EEG files and EEG events used are freely available <ext-link ext-link-type="uri" xlink:href="https://e1.pcloud.link/publink/show?code=kZlkQYZ2Jjab25UEGu8WcGTTXqvMXG5dVmV">here</ext-link>. Participant details are available upon request from the corresponding author due to the potentially sensitive nature.</p></sec><fn-group><fn id="FN1" fn-type="con"><p id="P89"><bold>Author Contribution Statement</bold></p><p id="P90">Ives, J., conceptualisation, data collection and curation, formal analysis, methodology, writing – original draft; Labendzki, P., data collection and curation, formal analysis, writing – review &amp; editing; Perapoch Amadó, M., data collection and curation, writing – review &amp; editing; Greenwood, E., data collection and curation, participant recruitment, writing – review &amp; editing; Viswanathan, N., data collection and curation, writing – review &amp; editing; Northrop, T., data collection and curation, participant recruitment, writing – review &amp; editing; Wass, S., conceptualisation, funding acquisition, methodology, project administration, supervision, writing – review &amp; editing.</p></fn><fn id="FN2"><p id="P91"><bold>Ethics Statement</bold></p><p id="P92">The University of East London ethics committee approved the study (application ID: ETH2021-0076). All adult participants provided informed consent for both themselves and their children according to the Declaration of Helsinki. All participants were offered a £10 shopping voucher as a monetary reward for their time. Travel and food expenses were also covered for those that requested them.</p></fn><fn id="FN3" fn-type="conflict"><p id="P93"><bold>Disclosure of competing interests</bold></p><p id="P94">The authors confirm that there are no competing or conflicting interests.</p></fn></fn-group><ref-list><ref id="R1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adibpour</surname><given-names>P</given-names></name><name><surname>Lebenberg</surname><given-names>J</given-names></name><name><surname>Kabdebon</surname><given-names>C</given-names></name><name><surname>Dehaene-Lambertz</surname><given-names>G</given-names></name><name><surname>Dubois</surname><given-names>J</given-names></name></person-group><article-title>Anatomo-functional correlates of auditory development in infancy</article-title><source>Developmental Cognitive Neuroscience</source><year>2020</year><volume>42</volume><elocation-id>100752</elocation-id><pub-id pub-id-type="doi">10.1016/j.dcn.2019.100752</pub-id></element-citation></ref><ref id="R2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adibpour</surname><given-names>P</given-names></name><name><surname>Lebenberg</surname><given-names>J</given-names></name><name><surname>Kabdebon</surname><given-names>C</given-names></name><name><surname>Dehaene-lambertz</surname><given-names>G</given-names></name><name><surname>Dubois</surname><given-names>J</given-names></name></person-group><article-title>Developmental Cognitive Neuroscience Anatomo-functional correlates of auditory development in infancy</article-title><source>Developmental Cognitive Neuroscience</source><year>2020</year><volume>42</volume><elocation-id>100752</elocation-id><pub-id pub-id-type="doi">10.1016/j.dcn.2019.100752</pub-id></element-citation></ref><ref id="R3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahissar</surname><given-names>E</given-names></name><name><surname>Nagarajan</surname><given-names>S</given-names></name><name><surname>Ahissar</surname><given-names>M</given-names></name><name><surname>Protopapas</surname><given-names>A</given-names></name><name><surname>Mahncke</surname><given-names>H</given-names></name><name><surname>Merzenich</surname><given-names>M</given-names></name></person-group><article-title>Speech comprehension is correlated with temporal response patterns recorded from auditory cortex</article-title><source>PNAS</source><year>2001</year><volume>98</volume><issue>23</issue><fpage>13367</fpage><lpage>13372</lpage></element-citation></ref><ref id="R4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahlo</surname><given-names>K</given-names></name><name><surname>Sainio</surname><given-names>K</given-names></name><name><surname>Sajaniemi</surname><given-names>N</given-names></name><name><surname>Reinikainen</surname><given-names>K</given-names></name><name><surname>Näätänen</surname><given-names>R</given-names></name></person-group><article-title>Event-related brain potential of human newborns to pitch change of an acoustic stimulus</article-title><source>Electroencephalography and Clinical Neurophysiology</source><year>1990</year><volume>1</volume><issue>77</issue><fpage>151</fpage><lpage>155</lpage></element-citation></ref><ref id="R5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahtola</surname><given-names>E</given-names></name><name><surname>Stjerna</surname><given-names>S</given-names></name><name><surname>Tokariev</surname><given-names>A</given-names></name><name><surname>Vanhatalo</surname><given-names>S</given-names></name></person-group><article-title>Use of complex visual stimuli allows controlled recruitment of cortical networks in infants</article-title><source>Clinical Neurophysiology</source><year>2020</year><volume>131</volume><issue>8</issue><fpage>2032</fpage><lpage>2040</lpage><pub-id pub-id-type="doi">10.1016/j.clinph.2020.03.034</pub-id></element-citation></ref><ref id="R6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aiken</surname><given-names>SJ</given-names></name><name><surname>Picton</surname><given-names>TW</given-names></name></person-group><article-title>Human Cortical Responses to the Speech Envelope</article-title><source>Ear &amp; Hearing</source><year>2008</year><volume>29</volume><issue>2</issue><fpage>139</fpage><lpage>157</lpage></element-citation></ref><ref id="R7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alaerts</surname><given-names>J</given-names></name><name><surname>Heleen</surname><given-names>L</given-names></name><name><surname>Hofmann</surname><given-names>M</given-names></name><name><surname>Wouters</surname><given-names>J</given-names></name></person-group><article-title>Cortical auditory steady-state responses to low modulation rates</article-title><source>Internation Journal of Audiology</source><year>2009</year><volume>48</volume><fpage>582</fpage><lpage>593</lpage><pub-id pub-id-type="doi">10.1080/14992020902894558</pub-id></element-citation></ref><ref id="R8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alschuler</surname><given-names>DM</given-names></name><name><surname>Tenke</surname><given-names>CE</given-names></name><name><surname>Bruder</surname><given-names>GE</given-names></name><name><surname>Kayser</surname><given-names>J</given-names></name></person-group><article-title>Identifying electrode bridging from electrical distance distributions: A survey of publicly-available EEG data using a new method</article-title><source>Clinical Neurophysiology</source><year>2014</year><volume>125</volume><issue>3</issue><fpage>484</fpage><lpage>490</lpage><pub-id pub-id-type="doi">10.1016/j.clinph.2013.08.024</pub-id></element-citation></ref><ref id="R9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aoyagi</surname><given-names>M</given-names></name><name><surname>Kiren</surname><given-names>T</given-names></name><name><surname>Furuse</surname><given-names>H</given-names></name><name><surname>Fuse</surname><given-names>T</given-names></name><name><surname>Suzuki</surname><given-names>Y</given-names></name><name><surname>Yokota</surname><given-names>M</given-names></name><name><surname>Koike</surname><given-names>Y</given-names></name></person-group><article-title>Effects of Aging on Amplitude-modulation Following Response Effects of Aging on Amplitude-modulation Following Response</article-title><source>Acta Oto-Laryngologica</source><year>1994</year><volume>511</volume><fpage>15</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.3109/00016489409128295</pub-id></element-citation></ref><ref id="R10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arnal</surname><given-names>LH</given-names></name><name><surname>Doelling</surname><given-names>KB</given-names></name><name><surname>Poeppel</surname><given-names>D</given-names></name></person-group><article-title>Delta – Beta Coupled Oscillations Underlie Temporal Prediction Accuracy</article-title><year>2015</year><month>September</month><fpage>3077</fpage><lpage>3085</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu103</pub-id></element-citation></ref><ref id="R11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arnal</surname><given-names>LH</given-names></name><name><surname>Giraud</surname><given-names>A</given-names></name></person-group><article-title>Cortical oscillations and sensory predictions</article-title><source>Trends in Cognitive Sciences</source><year>2012</year><volume>16</volume><issue>7</issue><fpage>390</fpage><lpage>398</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2012.05.003</pub-id></element-citation></ref><ref id="R12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aston-Jones</surname><given-names>G</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><article-title>An integrative theory of locus coeruleus-norepinephrine function: Adaptive gain and optimal performance</article-title><source>Annual Review of Neuroscience</source><year>2005</year><volume>28</volume><fpage>403</fpage><lpage>450</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.28.061604.135709</pub-id></element-citation></ref><ref id="R13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Attaheri</surname><given-names>A</given-names></name><name><surname>Choisdealbha</surname><given-names>ÁN</given-names></name><name><surname>Di Liberto</surname><given-names>GM</given-names></name><name><surname>Rocha</surname><given-names>S</given-names></name><name><surname>Brusini</surname><given-names>P</given-names></name><name><surname>Mead</surname><given-names>N</given-names></name><name><surname>Olawole-Scott</surname><given-names>H</given-names></name><name><surname>Boutris</surname><given-names>P</given-names></name><name><surname>Gibbon</surname><given-names>S</given-names></name><name><surname>Williams</surname><given-names>I</given-names></name><name><surname>Grey</surname><given-names>C</given-names></name><etal/></person-group><article-title>Delta- and theta-band cortical tracking and phase-amplitude coupling to sung speech by infants</article-title><source>BioRxiv</source><year>2021</year><elocation-id>2020.10.12.329326</elocation-id><comment><ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2020.10.12.329326v4.abstract">https://www.biorxiv.org/content/10.1101/2020.10.12.329326v4.abstract</ext-link></comment></element-citation></ref><ref id="R14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Attaheri</surname><given-names>A</given-names></name><name><surname>Ní Choisdealbha</surname><given-names>Á</given-names></name><name><surname>Di Liberto</surname><given-names>GM</given-names></name><name><surname>Rocha</surname><given-names>S</given-names></name><name><surname>Brusini</surname><given-names>P</given-names></name><name><surname>Mead</surname><given-names>N</given-names></name><name><surname>Olawole-scott</surname><given-names>H</given-names></name><name><surname>Boutris</surname><given-names>P</given-names></name><name><surname>Gibbon</surname><given-names>S</given-names></name><name><surname>Williams</surname><given-names>I</given-names></name><name><surname>Grey</surname><given-names>C</given-names></name><etal/></person-group><article-title>Delta- and theta-band cortical tracking and phase-amplitude coupling to sung speech by infants</article-title><source>NeuroImage</source><year>2022</year><month>March</month><volume>247</volume><elocation-id>118698</elocation-id><comment>(March 2021)</comment><pub-id pub-id-type="doi">10.1016/j.neuroimage.2021.118698</pub-id></element-citation></ref><ref id="R15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Babiloni</surname><given-names>F</given-names></name><name><surname>Astolfi</surname><given-names>L</given-names></name></person-group><article-title>Neuroscience and Biobehavioral Reviews Social neuroscience and hyperscanning techniques: Past, present and future</article-title><source>Neuroscience and Biobehavioral Reviews</source><year>2014</year><volume>44</volume><fpage>76</fpage><lpage>93</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2012.07.006</pub-id></element-citation></ref><ref id="R16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Backer</surname><given-names>KC</given-names></name><name><surname>Kessler</surname><given-names>AS</given-names></name><name><surname>Lawyer</surname><given-names>LA</given-names></name><name><surname>Corina</surname><given-names>DP</given-names></name><name><surname>Miller</surname><given-names>LM</given-names></name></person-group><article-title>A novel EEG paradigm to simultaneously and rapidly assess the functioning of auditory and visual pathways</article-title><source>Journal of Neurophysiology</source><year>2019</year><volume>122</volume><issue>4</issue><fpage>1312</fpage><lpage>1329</lpage><pub-id pub-id-type="doi">10.1152/jn.00868.2018</pub-id></element-citation></ref><ref id="R17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Backer</surname><given-names>KristinaC</given-names></name><name><surname>Kessler</surname><given-names>AS</given-names></name></person-group><article-title>A Novel EEG Paradigm to Simultaneously and Rapidly Assess the Functioning of Auditory and Visual Pathways</article-title><year>2019</year><volume>530</volume></element-citation></ref><ref id="R18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barnet</surname><given-names>Ann</given-names></name><name><surname>Ohlrich</surname><given-names>Elizabeth</given-names></name><name><surname>Weiss</surname><given-names>Ira</given-names></name><name><surname>Shanks</surname><given-names>B</given-names></name></person-group><article-title>Auditory Evoked Potentials During Sleep in Normal Children From Ten Days to Three Years of Age</article-title><source>Electroencephalography and Clinical Neurophysiology</source><year>1975</year><volume>39</volume><fpage>29</fpage><lpage>41</lpage></element-citation></ref><ref id="R19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bednar</surname><given-names>A</given-names></name><name><surname>Lalor</surname><given-names>EC</given-names></name></person-group><article-title>Where is the cocktail party? Decoding locations of attended and unattended moving sound sources using EEG</article-title><source>NeuroImage</source><year>2020</year><month>August</month><volume>205</volume><elocation-id>116283</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.116283</pub-id></element-citation></ref><ref id="R20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Begum Ali</surname><given-names>J</given-names></name><name><surname>Charman</surname><given-names>T</given-names></name><name><surname>Johnson</surname><given-names>MH</given-names></name><name><surname>Jones</surname><given-names>EJH</given-names></name><name><surname>Agyapong</surname><given-names>M</given-names></name><name><surname>Bazelmans</surname><given-names>T</given-names></name><name><surname>Dafner</surname><given-names>L</given-names></name><name><surname>Ersoy</surname><given-names>M</given-names></name><name><surname>Gliga</surname><given-names>T</given-names></name><name><surname>Goodwin</surname><given-names>A</given-names></name><name><surname>Haartsen</surname><given-names>R</given-names></name><etal/></person-group><article-title>Early Motor Differences in Infants at Elevated Likelihood of Autism Spectrum Disorder and/or Attention Deficit Hyperactivity Disorder</article-title><source>Journal of Autism and Developmental Disorders</source><year>2020</year><volume>50</volume><issue>12</issue><fpage>4367</fpage><lpage>4384</lpage><pub-id pub-id-type="doi">10.1007/s10803-020-04489-1</pub-id></element-citation></ref><ref id="R21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bernstein-Ratner</surname><given-names>N</given-names></name></person-group><article-title>Dissociations between Vowel Durations and Formant Frequency Characteristics</article-title><source>Journal of Speech, Language, and Hearing Research</source><year>1985</year><volume>28</volume><issue>2</issue><fpage>255</fpage><lpage>264</lpage><pub-id pub-id-type="doi">10.1044/jshr.2802.255</pub-id></element-citation></ref><ref id="R22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bertoncini</surname><given-names>J</given-names></name><name><surname>Nazzi</surname><given-names>T</given-names></name><name><surname>Cabrera</surname><given-names>L</given-names></name><name><surname>Lorenzi</surname><given-names>C</given-names></name></person-group><article-title>Six-month-old infants discriminate voicing on the basis of temporal envelope cues (L)</article-title><source>The Journal of the Acoustical Society of America</source><year>2011</year><volume>129</volume><issue>5</issue><fpage>2761</fpage><lpage>2764</lpage><pub-id pub-id-type="doi">10.1121/1.3571424</pub-id></element-citation></ref><ref id="R23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Besle</surname><given-names>J</given-names></name><name><surname>Schevon</surname><given-names>CA</given-names></name><name><surname>Mehta</surname><given-names>AD</given-names></name><name><surname>Lakatos</surname><given-names>P</given-names></name><name><surname>Goodman</surname><given-names>RR</given-names></name><name><surname>Mckhann</surname><given-names>GM</given-names></name><name><surname>Emerson</surname><given-names>RG</given-names></name><name><surname>Schroeder</surname><given-names>CE</given-names></name></person-group><article-title>Tuning of the Human Neocortex to the Temporal Dynamics of Attended Events</article-title><source>The Journal of Neuroscience</source><year>2011</year><volume>31</volume><issue>9</issue><fpage>3176</fpage><lpage>3185</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4518-10.2011</pub-id></element-citation></ref><ref id="R24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boyer</surname><given-names>TW</given-names></name><name><surname>Harding</surname><given-names>SM</given-names></name><name><surname>Bertenthal</surname><given-names>BI</given-names></name></person-group><article-title>The temporal dynamics of infants’ joint attention: Effects of others’ gaze cues and manual actions</article-title><source>Cognition</source><year>2020</year><month>December</month><volume>197</volume><pub-id pub-id-type="doi">10.1016/j.cognition.2019.104151</pub-id></element-citation></ref><ref id="R25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burgess</surname><given-names>A</given-names></name></person-group><article-title>On the interpretation of synchronization in EEG hyperscanning studies: a cautionary note</article-title><source>Frontiers in Human Neuroscience</source><year>2013</year><volume>7</volume><month>December</month><fpage>1</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.3389/fnhum.2013.00881</pub-id></element-citation></ref><ref id="R26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burgess</surname><given-names>AP</given-names></name></person-group><article-title>Towards a Unified Understanding of Event-Related Changes in the EEG: The Firefly Model of Synchronization through Cross-Frequency Phase Modulation</article-title><source>PLoS ONE</source><year>2012</year><volume>7</volume><issue>9</issue><pub-id pub-id-type="doi">10.1371/journal.pone.0045630</pub-id></element-citation></ref><ref id="R27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burnham</surname><given-names>D</given-names></name><name><surname>Dodd</surname><given-names>B</given-names></name></person-group><article-title>Auditory-visual speech integration by prelinguistic infants: Perception of an emergent consonant in the McGurk effect</article-title><source>Developmental Psychobiology</source><year>2004</year><volume>45</volume><issue>4</issue><fpage>204</fpage><lpage>220</lpage><pub-id pub-id-type="doi">10.1002/dev.20032</pub-id></element-citation></ref><ref id="R28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buzsáki</surname><given-names>G</given-names></name><name><surname>Draguhn</surname><given-names>A</given-names></name></person-group><article-title>Neuronal Oscillations in Cortical Networks</article-title><source>Science</source><year>2004</year><month>June</month><volume>304</volume><fpage>1926</fpage><lpage>1929</lpage><comment><ext-link ext-link-type="uri" xlink:href="http://science.sciencemag.org/">http://science.sciencemag.org/</ext-link></comment></element-citation></ref><ref id="R29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cabrera</surname><given-names>L</given-names></name><name><surname>Calcus</surname><given-names>A</given-names></name><name><surname>Labendzki</surname><given-names>P</given-names></name><name><surname>Lorenzini</surname><given-names>I</given-names></name></person-group><article-title>Amplitude Modulation Following Response in Normal-Hearing Adults: Is There a Link With the Ability to Perceive Speech in Noise?</article-title><year>2021</year><volume>2021</volume></element-citation></ref><ref id="R30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carral</surname><given-names>V</given-names></name><name><surname>Huotilainen</surname><given-names>M</given-names></name><name><surname>Ruusuvirta</surname><given-names>T</given-names></name><name><surname>Fellman</surname><given-names>V</given-names></name><name><surname>Näätänen</surname><given-names>R</given-names></name><name><surname>Escera</surname><given-names>C</given-names></name></person-group><article-title>A kind of auditory ‘ primitive intelligence ’ already present at birth</article-title><source>European Journal of Neuroscience</source><year>2005</year><month>March</month><volume>21</volume><fpage>3201</fpage><lpage>3204</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.2005.04144.x</pub-id></element-citation></ref><ref id="R31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cellier</surname><given-names>D</given-names></name><name><surname>Riddle</surname><given-names>J</given-names></name><name><surname>Petersen</surname><given-names>I</given-names></name><name><surname>Hwang</surname><given-names>K</given-names></name></person-group><article-title>Developmental Cognitive Neuroscience The development of theta and alpha neural oscillations from ages 3 to 24 years</article-title><source>Developmental Cognitive Neuroscience</source><year>2021</year><volume>50</volume><elocation-id>100969</elocation-id><pub-id pub-id-type="doi">10.1016/j.dcn.2021.100969</pub-id></element-citation></ref><ref id="R32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Centre</surname><given-names>D</given-names></name><name><surname>Neuroscience</surname><given-names>M</given-names></name><name><surname>Duprez</surname><given-names>J</given-names></name></person-group><article-title>Synchronization between keyboard typing and neural oscillations</article-title><year>2020</year><fpage>1</fpage><lpage>33</lpage></element-citation></ref><ref id="R33"><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Chave</surname><given-names>J</given-names></name><name><surname>Herault</surname><given-names>B</given-names></name><etal/></person-group><source>Fo r R ev iew On ly Fo r R iew On ly</source><year>1976</year><fpage>6</fpage><lpage>82</lpage></element-citation></ref><ref id="R34"><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Chemero</surname><given-names>A</given-names></name></person-group><source>Radical embodied cognitive science</source><year>2009</year><comment>[References]. In (2009)</comment></element-citation></ref><ref id="R35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Choi</surname><given-names>D</given-names></name><name><surname>Batterink</surname><given-names>LJ</given-names></name><name><surname>Black</surname><given-names>AK</given-names></name><name><surname>Paller</surname><given-names>KA</given-names></name><name><surname>Werker</surname><given-names>JF</given-names></name></person-group><article-title>Preverbal Infants Discover Statistical Word Patterns at Similar Rates as Adults: Evidence From Neural Entrainment</article-title><source>Association for Psychological Science</source><year>2020</year><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1177/0956797620933237</pub-id></element-citation></ref><ref id="R36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Choisdealbha</surname><given-names>ÁN</given-names></name><name><surname>Attaheri</surname><given-names>A</given-names></name><name><surname>Rocha</surname><given-names>S</given-names></name><name><surname>Mead</surname><given-names>N</given-names></name><name><surname>Brusini</surname><given-names>P</given-names></name><name><surname>Gibbon</surname><given-names>S</given-names></name><name><surname>Boutris</surname><given-names>P</given-names></name><name><surname>Grey</surname><given-names>C</given-names></name><name><surname>Flanagan</surname><given-names>S</given-names></name><name><surname>Goswami</surname><given-names>U</given-names></name></person-group><article-title>Cortical Oscillations in Pre-verbal Infants Track Rhythmic Speech and Non-speech Stimuli</article-title><year>2022</year></element-citation></ref><ref id="R37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cirelli</surname><given-names>LK</given-names></name><name><surname>Spinelli</surname><given-names>C</given-names></name><name><surname>Nozaradan</surname><given-names>S</given-names></name><name><surname>Trainor</surname><given-names>LJ</given-names></name></person-group><article-title>Measuring Neural Entrainment to Beat and Meter in Infants: Effects of Music Background</article-title><source>Frontiers in Neuroscience</source><year>2016</year><month>May</month><volume>10</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.3389/fnins.2016.00229</pub-id></element-citation></ref><ref id="R38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clerkin</surname><given-names>EM</given-names></name><name><surname>Hart</surname><given-names>E</given-names></name><name><surname>Rehg</surname><given-names>JM</given-names></name><name><surname>Yu</surname><given-names>C</given-names></name><name><surname>Smith</surname><given-names>LB</given-names></name><name><surname>Smith</surname><given-names>LB</given-names></name></person-group><article-title>Real-world visual statistics and infants ’ first-learned object names</article-title><year>2017</year></element-citation></ref><ref id="R39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>LT</given-names></name><name><surname>Rickards</surname><given-names>FW</given-names></name><name><surname>Clark</surname><given-names>GM</given-names></name></person-group><article-title>A comparison of steady-state evoked potentials to modulated tones in awake and sleeping humans</article-title><source>Journal of the Acoustical Society of America</source><year>2014</year><volume>90</volume><issue>5</issue><fpage>2467</fpage><lpage>2479</lpage></element-citation></ref><ref id="R40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohn</surname><given-names>JF</given-names></name><name><surname>Tronick</surname><given-names>EZ</given-names></name></person-group><article-title>Mother-Infant Face-to-Face Interaction: Influence is Bidirectional and Unrelated to Periodic Cycles in Either Partner’s Behavior</article-title><source>Developmental Psychology</source><year>1988</year><volume>24</volume><issue>3</issue><fpage>386</fpage><lpage>392</lpage><pub-id pub-id-type="doi">10.1037/0012-1649.24.3.386</pub-id></element-citation></ref><ref id="R41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Colombo</surname><given-names>J</given-names></name><name><surname>Cheatham</surname><given-names>CL</given-names></name></person-group><article-title>The emergence and basis of endogenous attention in infancy and early childhood</article-title><source>Advances in Child Development and Behavior</source><year>2006</year><volume>34</volume><pub-id pub-id-type="doi">10.1016/S0065-2407(06)80010-8</pub-id></element-citation></ref><ref id="R42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cooper</surname><given-names>RP</given-names></name><name><surname>Aslin</surname><given-names>RN</given-names></name></person-group><article-title>Developmental Differences in Infant Attention to the Spectral Properties of Infant-directed Speech</article-title><source>Child Development</source><year>1994</year><volume>65</volume><issue>6</issue><fpage>1663</fpage><lpage>1677</lpage><pub-id pub-id-type="doi">10.1111/j.1467-8624.1994.tb00841.x</pub-id></element-citation></ref><ref id="R43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cooper</surname><given-names>RP</given-names></name><name><surname>Aslin</surname><given-names>RN</given-names></name></person-group><article-title>Preference for Infant-directed Speech in the First Month after Birth</article-title><source>Child Development</source><year>1990</year><volume>61</volume><issue>5</issue><fpage>1584</fpage><lpage>1595</lpage><pub-id pub-id-type="doi">10.1111/j.1467-8624.1990.tb02885.x</pub-id></element-citation></ref><ref id="R44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crosse</surname><given-names>MJ</given-names></name><name><surname>Butler</surname><given-names>JS</given-names></name><name><surname>Lalor</surname><given-names>EC</given-names></name></person-group><article-title>Congruent visual speech enhances cortical entrainment to continuous auditory speech in noise-free conditions</article-title><source>Journal of Neuroscience</source><year>2015</year><volume>35</volume><issue>42</issue><fpage>14195</fpage><lpage>14204</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1829-15.2015</pub-id></element-citation></ref><ref id="R45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crosse</surname><given-names>MJ</given-names></name><name><surname>Di Liberto</surname><given-names>GM</given-names></name><name><surname>Bednar</surname><given-names>A</given-names></name><name><surname>Lalor</surname><given-names>EC</given-names></name></person-group><article-title>The multivariate temporal response function (mTRF) toolbox: A MATLAB toolbox for relating neural signals to continuous stimuli</article-title><source>Frontiers in Human Neuroscience</source><year>2016</year><month>NOV</month><volume>10</volume><fpage>1</fpage><lpage>14</lpage><comment>2016</comment><pub-id pub-id-type="doi">10.3389/fnhum.2016.00604</pub-id></element-citation></ref><ref id="R46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Csibra</surname><given-names>G</given-names></name><name><surname>Davis</surname><given-names>G</given-names></name><name><surname>Spratling</surname><given-names>MW</given-names></name><name><surname>Johnson</surname><given-names>MH</given-names></name></person-group><article-title>Gamma Oscillations and Object Processing in the Infant Brain</article-title><year>2000</year><month>November</month><volume>290</volume><fpage>5</fpage><lpage>8</lpage></element-citation></ref><ref id="R47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cuevas</surname><given-names>K</given-names></name><name><surname>Cannon</surname><given-names>EN</given-names></name><name><surname>Yoo</surname><given-names>K</given-names></name><name><surname>Fox</surname><given-names>NA</given-names></name></person-group><article-title>The infant EEG mu rhythm: Methodological considerations and best practices</article-title><source>Developmental Review</source><year>2014</year><volume>34</volume><issue>1</issue><fpage>26</fpage><lpage>43</lpage><pub-id pub-id-type="doi">10.1016/j.dr.2013.12.001</pub-id></element-citation></ref><ref id="R48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daneshvarfard</surname><given-names>F</given-names></name><name><surname>Moghaddam</surname><given-names>HA</given-names></name><name><surname>Dehaene-lambertz</surname><given-names>G</given-names></name></person-group><article-title>Neurodevelopment and asymmetry of auditory-related responses to repetitive syllabic stimuli in preterm neonates based on frequency-domain analysis</article-title><source>Scientific Reports</source><year>2019</year><month>October</month><volume>9</volume><elocation-id>10654</elocation-id><comment>2018</comment><pub-id pub-id-type="doi">10.1038/s41598-019-47064-0</pub-id></element-citation></ref><ref id="R49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daume</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>P</given-names></name><name><surname>Maye</surname><given-names>A</given-names></name><name><surname>Zhang</surname><given-names>D</given-names></name><name><surname>Engel</surname><given-names>AK</given-names></name></person-group><article-title>Non-rhythmic temporal prediction involves phase resets of low-frequency delta oscillations</article-title><source>NeuroImage</source><year>2021</year><month>September</month><volume>224</volume><elocation-id>117376</elocation-id><comment>(September 2020)</comment><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117376</pub-id></element-citation></ref><ref id="R50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>David</surname><given-names>O</given-names></name><name><surname>Harrison</surname><given-names>L</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><article-title>Modelling event-related responses in the brain</article-title><source>NeuroImage</source><year>2005</year><volume>25</volume><issue>3</issue><fpage>756</fpage><lpage>770</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2004.12.030</pub-id></element-citation></ref><ref id="R51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>David</surname><given-names>O</given-names></name><name><surname>Kilner</surname><given-names>JM</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><article-title>Mechanisms of evoked and induced responses in MEG/EEG</article-title><source>NeuroImage</source><year>2006</year><volume>31</volume><issue>4</issue><fpage>1580</fpage><lpage>1591</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.02.034</pub-id></element-citation></ref><ref id="R52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Debener</surname><given-names>S</given-names></name><name><surname>Minow</surname><given-names>F</given-names></name><name><surname>Emkes</surname><given-names>R</given-names></name><name><surname>Gandras</surname><given-names>K</given-names></name><name><surname>Vos</surname><given-names>MDE</given-names></name></person-group><article-title>How about taking a low-cost, small, and wireless EEG for a walk?</article-title><year>2012</year><fpage>1</fpage><lpage>5</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.2012.01471.x</pub-id></element-citation></ref><ref id="R53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Decasper</surname><given-names>AJ</given-names></name><name><surname>Fifer</surname><given-names>WP</given-names></name></person-group><article-title>Of human bonding: Newborns prefer their mothers’ voices</article-title><source>Science</source><year>1980</year><volume>208</volume><issue>4448</issue><fpage>1174</fpage><lpage>1176</lpage><pub-id pub-id-type="doi">10.1126/science.7375928</pub-id></element-citation></ref><ref id="R54"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Delorme</surname><given-names>A</given-names></name></person-group><source>eeg_interp EEGLAB function</source><publisher-name>The Mathworks, Inc</publisher-name><year>2006</year></element-citation></ref><ref id="R55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delorme</surname><given-names>A</given-names></name><name><surname>Makeig</surname><given-names>S</given-names></name></person-group><article-title>EEGLAB: An open source toolbox for analysis of single-trial EEG dynamics including independent component analysis</article-title><source>Journal of Neuroscience Methods</source><year>2004</year><volume>134</volume><issue>1</issue><fpage>9</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2003.10.009</pub-id></element-citation></ref><ref id="R56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Demany</surname><given-names>L</given-names></name></person-group><article-title>Auditory stream segregation in infancy</article-title><source>Infant Behavior and Development</source><year>1982</year><volume>5</volume><issue>2–4</issue><fpage>261</fpage><lpage>276</lpage><pub-id pub-id-type="doi">10.1016/S0163-6383(82)80036-2</pub-id></element-citation></ref><ref id="R57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Demos</surname><given-names>AP</given-names></name><name><surname>Chaffin</surname><given-names>R</given-names></name><name><surname>Marsh</surname><given-names>KL</given-names></name></person-group><article-title>Spontaneous Vs Intentional Entrainment To a Musical Beat</article-title><year>2007</year><month>January</month><fpage>1</fpage><lpage>4</lpage></element-citation></ref><ref id="R58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dikker</surname><given-names>S</given-names></name><name><surname>Wan</surname><given-names>L</given-names></name><name><surname>Davidesco</surname><given-names>I</given-names></name><name><surname>Van Bavel</surname><given-names>JJ</given-names></name><name><surname>Ding</surname><given-names>M</given-names></name><name><surname>Poeppel</surname><given-names>D</given-names></name><name><surname>Dikker</surname><given-names>S</given-names></name><name><surname>Wan</surname><given-names>L</given-names></name><name><surname>Davidesco</surname><given-names>I</given-names></name><name><surname>Kaggen</surname><given-names>L</given-names></name><name><surname>Oostrik</surname><given-names>M</given-names></name><etal/></person-group><article-title>Brain-to-Brain Synchrony Tracks Real-World Report Brain-to-Brain Synchrony Tracks Real-World Dynamic Group Interactions in the Classroom</article-title><source>Current Biology</source><year>2017</year><fpage>1</fpage><lpage>6</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.04.002</pub-id></element-citation></ref><ref id="R59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname><given-names>J</given-names></name><name><surname>Sperling</surname><given-names>G</given-names></name><name><surname>Srinivasan</surname><given-names>R</given-names></name></person-group><article-title>Attentional modulation of SSVEP power depends on the network tagged by the flicker frequency</article-title><source>Cerebral Cortex</source><year>2006</year><volume>16</volume><issue>7</issue><fpage>1016</fpage><lpage>1029</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhj044</pub-id></element-citation></ref><ref id="R60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname><given-names>N</given-names></name><name><surname>Melloni</surname><given-names>L</given-names></name><name><surname>Zhang</surname><given-names>H</given-names></name><name><surname>Tian</surname><given-names>X</given-names></name><name><surname>Poeppel</surname><given-names>D</given-names></name></person-group><article-title>Cortical tracking of hierarchical linguistic structures in connected speech</article-title><source>Nature Neuroscience</source><year>2015</year><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1038/nn.4186</pub-id></element-citation></ref><ref id="R61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname><given-names>N</given-names></name><name><surname>Simon</surname><given-names>JZ</given-names></name></person-group><article-title>Neural coding of continuous speech in auditory cortex during monaural and dichotic listening</article-title><source>Journal of Neurophysiology</source><year>2012</year><volume>107</volume><issue>1</issue><fpage>78</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1152/jn.00297.2011</pub-id></element-citation></ref><ref id="R62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname><given-names>N</given-names></name><name><surname>Simon</surname><given-names>JZ</given-names></name></person-group><article-title>Power and phase properties of oscillatory neural responses in the presence of background activity</article-title><source>Journal of Computational Neuroscience</source><year>2013</year><volume>34</volume><issue>2</issue><fpage>337</fpage><lpage>343</lpage><pub-id pub-id-type="doi">10.1007/s10827-012-0424-6</pub-id></element-citation></ref><ref id="R63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doelling</surname><given-names>K</given-names></name><name><surname>Poeppel</surname><given-names>D</given-names></name></person-group><article-title>Cortical entrainment to music and its modulation by expertise</article-title><source>PNAS</source><year>2015</year><fpage>6233</fpage><lpage>6242</lpage></element-citation></ref><ref id="R64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doelling</surname><given-names>KB</given-names></name><name><surname>Florencia Assaneo</surname><given-names>M</given-names></name><name><surname>Bevilacqua</surname><given-names>D</given-names></name><name><surname>Pesaran</surname><given-names>B</given-names></name><name><surname>Poeppel</surname><given-names>D</given-names></name></person-group><article-title>An oscillator model better predicts cortical entrainment to music</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><year>2019</year><volume>116</volume><issue>20</issue><fpage>10113</fpage><lpage>10121</lpage><pub-id pub-id-type="doi">10.1073/pnas.1816414116</pub-id></element-citation></ref><ref id="R65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doelling</surname><given-names>KB</given-names></name><name><surname>Florencia Assaneo</surname><given-names>M</given-names></name><name><surname>Bevilacqua</surname><given-names>D</given-names></name><name><surname>Pesaran</surname><given-names>B</given-names></name><name><surname>Poeppel</surname><given-names>D</given-names></name></person-group><article-title>An oscillator model better predicts cortical entrainment to music</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><year>2019</year><volume>116</volume><issue>20</issue><fpage>10113</fpage><lpage>10121</lpage><pub-id pub-id-type="doi">10.1073/pnas.1816414116</pub-id></element-citation></ref><ref id="R66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doelling</surname><given-names>KB</given-names></name><name><surname>Arnal</surname><given-names>LH</given-names></name><name><surname>Ghitza</surname><given-names>O</given-names></name><name><surname>Poeppel</surname><given-names>D</given-names></name></person-group><article-title>Acoustic landmarks drive delta – theta oscillations to enable speech comprehension by facilitating perceptual parsing</article-title><source>NeuroImage</source><year>2014</year><volume>85</volume><fpage>761</fpage><lpage>768</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.06.035</pub-id></element-citation></ref><ref id="R67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drullman</surname><given-names>R</given-names></name><name><surname>Festen</surname><given-names>JM</given-names></name><name><surname>Plomp</surname><given-names>R</given-names></name></person-group><article-title>Effect of reducing slow temporal modulations on speech reception</article-title><source>Journal of the Acoustical Society of America</source><year>1994</year><volume>95</volume><issue>5</issue><fpage>2670</fpage><lpage>2680</lpage><pub-id pub-id-type="doi">10.1121/1.409836</pub-id></element-citation></ref><ref id="R68"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Efron</surname><given-names>B</given-names></name><name><surname>Tibshirani</surname><given-names>R</given-names></name></person-group><source>Bootstrp.m MATLAB function</source><publisher-name>The Mathworks, Inc</publisher-name><year>1993</year></element-citation></ref><ref id="R69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eisermann</surname><given-names>M</given-names></name><name><surname>Kaminska</surname><given-names>A</given-names></name><name><surname>Moutard</surname><given-names>ML</given-names></name><name><surname>Soufflet</surname><given-names>C</given-names></name><name><surname>Plouin</surname><given-names>P</given-names></name></person-group><article-title>Normal EEG in childhood: From neonates to adolescents</article-title><source>Neurophysiologie Clinique</source><year>2013</year><volume>43</volume><issue>1</issue><fpage>35</fpage><lpage>65</lpage><pub-id pub-id-type="doi">10.1016/j.neucli.2012.09.091</pub-id></element-citation></ref><ref id="R70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fairhurst</surname><given-names>MT</given-names></name><name><surname>Dumas</surname><given-names>G</given-names></name></person-group><article-title>Reciprocity and alignment: quantifying coupling in dynamic interactions</article-title><year>2019</year><pub-id pub-id-type="doi">10.31234/osf.io/nmg4x</pub-id></element-citation></ref><ref id="R71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Falk</surname><given-names>S</given-names></name><name><surname>Kello</surname><given-names>CT</given-names></name></person-group><article-title>Hierarchical organization in the temporal structure of infant-direct speech and song</article-title><source>Cognition</source><year>2017</year><volume>163</volume><fpage>80</fpage><lpage>86</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2017.02.017</pub-id></element-citation></ref><ref id="R72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fawcett</surname><given-names>C</given-names></name><name><surname>Arslan</surname><given-names>M</given-names></name><name><surname>Falck-Ytter</surname><given-names>T</given-names></name><name><surname>Roeyers</surname><given-names>H</given-names></name><name><surname>Gredebäck</surname><given-names>G</given-names></name></person-group><article-title>Human eyes with dilated pupils induce pupillary contagion in infants</article-title><source>Scientific Reports</source><year>2017</year><volume>7</volume><issue>1</issue><fpage>2</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1038/s41598-017-08223-3</pub-id></element-citation></ref><ref id="R73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feldman</surname><given-names>R</given-names></name></person-group><article-title>Parent-infant synchrony and the construction of shared timing; physiological precursors, developmental outcomes, and risk conditions</article-title><source>Journal of Child Psychology and Psychiatry2</source><year>2007</year><volume>48</volume><issue>3/4</issue><fpage>329</fpage><lpage>354</lpage></element-citation></ref><ref id="R74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feldman</surname><given-names>R</given-names></name></person-group><article-title>From biological rhythms to social rhythms: Physiological precursors of mother-infant synchrony</article-title><source>Developmental Psychology</source><year>2006</year><volume>42</volume><issue>1</issue><fpage>175</fpage><lpage>188</lpage><pub-id pub-id-type="doi">10.1037/0012-1649.42.1.175</pub-id></element-citation></ref><ref id="R75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feldman</surname><given-names>R</given-names></name></person-group><article-title>Parent-infant synchrony: Biological foundations and developmental outcomes</article-title><source>Current Directions in Psychological Science</source><year>2007</year><volume>16</volume><issue>6</issue><fpage>340</fpage><lpage>345</lpage><pub-id pub-id-type="doi">10.1111/j.1467-8721.2007.00532.x</pub-id></element-citation></ref><ref id="R76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feldman</surname><given-names>R</given-names></name><name><surname>Magori-Cohen</surname><given-names>R</given-names></name><name><surname>Galili</surname><given-names>G</given-names></name><name><surname>Singer</surname><given-names>M</given-names></name><name><surname>Louzoun</surname><given-names>Y</given-names></name></person-group><article-title>Mother and infant coordinate heart rhythms through episodes of interaction synchrony</article-title><source>Infant Behavior and Development</source><year>2011</year><volume>34</volume><issue>4</issue><fpage>569</fpage><lpage>577</lpage><pub-id pub-id-type="doi">10.1016/j.infbeh.2011.06.008</pub-id></element-citation></ref><ref id="R77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fernald</surname><given-names>A</given-names></name><name><surname>Mazzie</surname><given-names>C</given-names></name></person-group><article-title>Prosody and focus in speech to infants and adults.: EBSCOhost</article-title><source>American Psychological Association, Inc</source><year>1991</year><volume>27</volume><issue>2</issue><fpage>209</fpage><lpage>221</lpage><comment><ext-link ext-link-type="uri" xlink:href="http://web.b.ebscohost.com.revproxy.brown.edu/ehost/pdfviewer/pdfviewer?sid=a7d41e1d-1263-4ba9-9b94-bbaf722e1f4e%40sessionmgr110&amp;vid=1&amp;hid=107">http://web.b.ebscohost.com.revproxy.brown.edu/ehost/pdfviewer/pdfviewer?sid=a7d41e1d-1263-4ba9-9b94-bbaf722e1f4e%40sessionmgr110&amp;vid=1&amp;hid=107</ext-link></comment></element-citation></ref><ref id="R78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fernald</surname><given-names>A</given-names></name><name><surname>Simon</surname><given-names>T</given-names></name></person-group><article-title>Expanded intonation contours in mothers’ speech to newborns</article-title><source>Developmental Psychology</source><year>1984</year><volume>20</volume><issue>1</issue><fpage>104</fpage><lpage>113</lpage><pub-id pub-id-type="doi">10.1037/0012-1649.20.1.104</pub-id></element-citation></ref><ref id="R79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feven-Parsons</surname><given-names>IM</given-names></name><name><surname>Goslin</surname><given-names>J</given-names></name></person-group><article-title>Electrophysiological study of action-affordance priming between object names</article-title><source>Brain and Language</source><year>2018</year><month>June</month><volume>184</volume><fpage>20</fpage><lpage>31</lpage><pub-id pub-id-type="doi">10.1016/j.bandl.2018.06.002</pub-id></element-citation></ref><ref id="R80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fló</surname><given-names>A</given-names></name><name><surname>Benjamin</surname><given-names>L</given-names></name><name><surname>Palu</surname><given-names>M</given-names></name><name><surname>Dehaene-Lambertz</surname><given-names>G</given-names></name></person-group><article-title>Sleeping neonates track transitional probabilities in speech but only retain the first syllable of words</article-title><source>Scientific Reports</source><year>2022</year><volume>12</volume><issue>1</issue><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1038/s41598-022-08411-w</pub-id></element-citation></ref><ref id="R81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fuglsang</surname><given-names>SA</given-names></name><name><surname>Dau</surname><given-names>T</given-names></name><name><surname>Hjortkjær</surname><given-names>J</given-names></name></person-group><source>NeuroImage</source><year>2017</year><comment>Author ’ s Accepted Manuscript</comment><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.04.026</pub-id></element-citation></ref><ref id="R82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Galambos</surname><given-names>R</given-names></name><name><surname>Makeig</surname><given-names>S</given-names></name><name><surname>Talmachoff</surname><given-names>PJ</given-names></name></person-group><article-title>A 40-Hz auditory potential recorded from the human scalp</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><year>1981</year><volume>78</volume><issue>4 II</issue><fpage>2643</fpage><lpage>2647</lpage><pub-id pub-id-type="doi">10.1073/pnas.78.4.2643</pub-id></element-citation></ref><ref id="R83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ghinst</surname><given-names>M</given-names></name><name><surname>Vander Bourguignon</surname><given-names>M</given-names></name><name><surname>Niesen</surname><given-names>M</given-names></name><name><surname>Wens</surname><given-names>V</given-names></name><name><surname>Hassid</surname><given-names>S</given-names></name><name><surname>Choufani</surname><given-names>G</given-names></name><name><surname>Jousmäki</surname><given-names>V</given-names></name><name><surname>Hari</surname><given-names>R</given-names></name><name><surname>Goldman</surname><given-names>S</given-names></name><name><surname>De Tiège</surname><given-names>X</given-names></name></person-group><article-title>Cortical tracking of speech-in-noise develops from childhood to adulthood</article-title><source>Journal of Neuroscience</source><year>2019</year><volume>39</volume><issue>15</issue><fpage>2938</fpage><lpage>2950</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1732-18.2019</pub-id></element-citation></ref><ref id="R84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gibbon</surname><given-names>S</given-names></name><name><surname>Attaheri</surname><given-names>A</given-names></name><name><surname>Ní Choisdealbha</surname><given-names>Á</given-names></name><name><surname>Rocha</surname><given-names>S</given-names></name><name><surname>Brusini</surname><given-names>P</given-names></name><name><surname>Mead</surname><given-names>N</given-names></name><name><surname>Boutris</surname><given-names>P</given-names></name><name><surname>Olawole-Scott</surname><given-names>H</given-names></name><name><surname>Ahmed</surname><given-names>H</given-names></name><name><surname>Flanagan</surname><given-names>S</given-names></name><name><surname>Mandke</surname><given-names>K</given-names></name><etal/></person-group><article-title>Machine learning accurately classifies neural responses to rhythmic speech vs. non-speech from 8-week-old infant EEG</article-title><source>Brain and Language</source><year>2021</year><volume>220</volume><fpage>0</fpage><lpage>6</lpage><comment>(July 2020)</comment><pub-id pub-id-type="doi">10.1016/j.bandl.2021.104968</pub-id></element-citation></ref><ref id="R85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giraud</surname><given-names>AL</given-names></name><name><surname>Poeppel</surname><given-names>D</given-names></name></person-group><article-title>Cortical oscillations and speech processing: Emerging computational principles and operations</article-title><source>Nature Neuroscience</source><year>2012</year><volume>15</volume><issue>4</issue><fpage>511</fpage><lpage>517</lpage><pub-id pub-id-type="doi">10.1038/nn.3063</pub-id></element-citation></ref><ref id="R86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glass</surname><given-names>L</given-names></name></person-group><article-title>Synchronization and rhythmic processes in physiology</article-title><source>Nature</source><year>2001</year><month>March</month><volume>410</volume><fpage>277</fpage><lpage>284</lpage></element-citation></ref><ref id="R87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gliga</surname><given-names>T</given-names></name><name><surname>Farroni</surname><given-names>T</given-names></name><name><surname>Cascio</surname><given-names>CJ</given-names></name></person-group><article-title>Social touch: A new vista for developmental cognitive neuroscience?</article-title><source>Developmental Cognitive Neuroscience</source><year>2019</year><volume>35</volume><fpage>1</fpage><lpage>4</lpage><pub-id pub-id-type="doi">10.1016/j.dcn.2018.05.006</pub-id></element-citation></ref><ref id="R88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Golumbic</surname><given-names>EMZ</given-names></name><name><surname>Ding</surname><given-names>N</given-names></name><name><surname>Bickel</surname><given-names>S</given-names></name><name><surname>Lakatos</surname><given-names>P</given-names></name><name><surname>Schevon</surname><given-names>CA</given-names></name><name><surname>Mckhann</surname><given-names>GM</given-names></name><name><surname>Goodman</surname><given-names>RR</given-names></name><name><surname>Emerson</surname><given-names>R</given-names></name><name><surname>Mehta</surname><given-names>AD</given-names></name><name><surname>Simon</surname><given-names>JZ</given-names></name><name><surname>Poeppel</surname><given-names>D</given-names></name></person-group><article-title>Article Mechanisms Underlying Selective Neuronal Tracking of Attended Speech at a ‘“ Cocktail Party”’</article-title><source>Neuron</source><year>2012</year><volume>77</volume><issue>5</issue><fpage>980</fpage><lpage>991</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.12.037</pub-id></element-citation></ref><ref id="R89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gomez-Ramirez</surname><given-names>M</given-names></name><name><surname>Kelly</surname><given-names>SP</given-names></name><name><surname>Molholm</surname><given-names>S</given-names></name><name><surname>Sehatpour</surname><given-names>P</given-names></name><name><surname>Schwartz</surname><given-names>TH</given-names></name><name><surname>Foxe</surname><given-names>JJ</given-names></name></person-group><article-title>Oscillatory sensory selection mechanisms during intersensory attention to rhythmic auditory and visual inputs: A human electrocorticographic investigation</article-title><source>Journal of Neuroscience</source><year>2011</year><volume>31</volume><issue>50</issue><fpage>18556</fpage><lpage>18567</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2164-11.2011</pub-id></element-citation></ref><ref id="R90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goswami</surname><given-names>U</given-names></name><name><surname>Leong</surname><given-names>V</given-names></name></person-group><article-title>Speech rhythm and temporal structure: Converging perspectives?</article-title><source>Laboratory Phonology</source><year>2013</year><volume>4</volume><issue>1</issue><fpage>67</fpage><lpage>92</lpage><pub-id pub-id-type="doi">10.1515/lp-2013-0004</pub-id></element-citation></ref><ref id="R91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greenberg</surname><given-names>S</given-names></name><name><surname>Carvey</surname><given-names>H</given-names></name><name><surname>Hitchcock</surname><given-names>L</given-names></name><name><surname>Chang</surname><given-names>S</given-names></name></person-group><article-title>Temporal properties of spontaneous speech - A syllable-centric perspective</article-title><source>Journal of Phonetics</source><year>2003</year><volume>31</volume><issue>3–4</issue><fpage>465</fpage><lpage>485</lpage><pub-id pub-id-type="doi">10.1016/j.wocn.2003.09.005</pub-id></element-citation></ref><ref id="R92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gross</surname><given-names>J</given-names></name><name><surname>Kluger</surname><given-names>DS</given-names></name><name><surname>Abbasi</surname><given-names>O</given-names></name><name><surname>Chalas</surname><given-names>N</given-names></name><name><surname>Steingräber</surname><given-names>N</given-names></name><name><surname>Daube</surname><given-names>C</given-names></name><name><surname>Schoffelen</surname><given-names>JM</given-names></name></person-group><article-title>Comparison of undirected frequency-domain connectivity measures for cerebro-peripheral analysis</article-title><source>NeuroImage</source><year>2021</year><month>Septembe</month><volume>245</volume><elocation-id>118660</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2021.118660</pub-id></element-citation></ref><ref id="R93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gross</surname><given-names>J</given-names></name><name><surname>Kluger</surname><given-names>DS</given-names></name><name><surname>Abbasi</surname><given-names>O</given-names></name><name><surname>Chalas</surname><given-names>N</given-names></name><name><surname>Steingräber</surname><given-names>N</given-names></name><name><surname>Daube</surname><given-names>C</given-names></name><name><surname>Schoffelen</surname><given-names>JM</given-names></name></person-group><article-title>Comparison of undirected frequency-domain connectivity measures for cerebro-peripheral analysis</article-title><source>NeuroImage</source><year>2021</year><month>September</month><volume>245</volume><elocation-id>118660</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2021.118660</pub-id></element-citation></ref><ref id="R94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guo</surname><given-names>Y</given-names></name><name><surname>Bufacchi</surname><given-names>RJ</given-names></name><name><surname>Novembre</surname><given-names>G</given-names></name><name><surname>Kilintari</surname><given-names>M</given-names></name><name><surname>Moayedi</surname><given-names>M</given-names></name><name><surname>Hu</surname><given-names>L</given-names></name><name><surname>Iannetti</surname><given-names>GD</given-names></name></person-group><article-title>Ultralow-frequency neural entrainment to pain</article-title><source>PLoS Biology</source><year>2020</year><volume>18</volume><issue>4</issue><fpage>1</fpage><lpage>27</lpage><pub-id pub-id-type="doi">10.1371/journal.pbio.3000491</pub-id></element-citation></ref><ref id="R95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haegens</surname><given-names>S</given-names></name><name><surname>Zion Golumbic</surname><given-names>E</given-names></name></person-group><article-title>Rhythmic facilitation of sensory processing: A critical review</article-title><source>Neuroscience and Biobehavioral Reviews</source><year>2018</year><volume>86</volume><fpage>150</fpage><lpage>165</lpage><comment>(July 2017)</comment><pub-id pub-id-type="doi">10.1016/j.neubiorev.2017.12.002</pub-id></element-citation></ref><ref id="R96"><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Hamilton</surname><given-names>A</given-names></name></person-group><source>Hype, hyperscanning and embodied social neuroscience</source><comment>(n.d.)</comment></element-citation></ref><ref id="R97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hari</surname><given-names>R</given-names></name><name><surname>Hämäläinen</surname><given-names>M</given-names></name><name><surname>Joutsiniemi</surname><given-names>SL</given-names></name></person-group><article-title>Neuromagnetic steady-state responses to auditory stimuli</article-title><source>Journal of the Acoustical Society of America</source><year>1989</year><volume>86</volume><issue>3</issue><fpage>1033</fpage><lpage>1039</lpage><pub-id pub-id-type="doi">10.1121/1.398093</pub-id></element-citation></ref><ref id="R98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><article-title>Nonsense correlations in neuroscience</article-title><source>BioRxiv</source><year>2020</year><elocation-id>2020.11.29.402719</elocation-id><pub-id pub-id-type="doi">10.1101/2020.11.29.402719</pub-id></element-citation></ref><ref id="R99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Frith</surname><given-names>CD</given-names></name></person-group><article-title>Mirroring and beyond: Coupled dynamics as a generalized framework for modelling social interactions</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><year>2016</year><volume>371</volume><issue>1693</issue><pub-id pub-id-type="doi">10.1098/rstb.2015.0366</pub-id></element-citation></ref><ref id="R100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haufe</surname><given-names>S</given-names></name><name><surname>Meinecke</surname><given-names>F</given-names></name><name><surname>Görgen</surname><given-names>K</given-names></name><name><surname>Dähne</surname><given-names>S</given-names></name><name><surname>Haynes</surname><given-names>JD</given-names></name><name><surname>Blankertz</surname><given-names>B</given-names></name><name><surname>Bießmann</surname><given-names>F</given-names></name></person-group><article-title>On the interpretation of weight vectors of linear models in multivariate neuroimaging</article-title><source>NeuroImage</source><year>2014</year><volume>87</volume><fpage>96</fpage><lpage>110</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.10.067</pub-id></element-citation></ref><ref id="R101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>W</given-names></name><name><surname>Donoghue</surname><given-names>T</given-names></name><name><surname>Sowman</surname><given-names>PF</given-names></name><name><surname>Seymour</surname><given-names>RA</given-names></name><name><surname>Brock</surname><given-names>J</given-names></name><name><surname>Crain</surname><given-names>S</given-names></name><name><surname>Voytek</surname><given-names>B</given-names></name><name><surname>Hillebrand</surname><given-names>A</given-names></name></person-group><article-title>Co-increasing neuronal noise and beta power in the developing brain</article-title><source>BioRxiv</source><year>2019</year><month>December</month><pub-id pub-id-type="doi">10.1101/839258</pub-id></element-citation></ref><ref id="R102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henry</surname><given-names>MJ</given-names></name><name><surname>Herrmann</surname><given-names>B</given-names></name><name><surname>Grahn</surname><given-names>JA</given-names></name></person-group><article-title>What can we learn about beat perception by comparing brain signals and stimulus envelopes?</article-title><source>PLoS ONE</source><year>2017</year><volume>12</volume><issue>2</issue><fpage>1</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.1371/journal.pone.0172454</pub-id></element-citation></ref><ref id="R103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henry</surname><given-names>MJ</given-names></name><name><surname>Obleser</surname><given-names>J</given-names></name></person-group><article-title>Frequency modulation entrains slow neural oscillations and optimizes human listening behavior</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><year>2012</year><volume>109</volume><issue>49</issue><fpage>20095</fpage><lpage>20100</lpage><pub-id pub-id-type="doi">10.1073/pnas.1213390109</pub-id></element-citation></ref><ref id="R104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herdman</surname><given-names>AT</given-names></name><name><surname>Lins</surname><given-names>O</given-names></name><name><surname>Van Roon</surname><given-names>P</given-names></name><name><surname>Stapells</surname><given-names>DR</given-names></name><name><surname>Scherg</surname><given-names>M</given-names></name><name><surname>Picton</surname><given-names>TW</given-names></name></person-group><article-title>Intracerebral sources of human auditory steady-state responses</article-title><source>Brain Topography</source><year>2002</year><volume>15</volume><issue>2</issue><fpage>69</fpage><lpage>86</lpage><pub-id pub-id-type="doi">10.1023/A:1021470822922</pub-id></element-citation></ref><ref id="R105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hessels</surname><given-names>RS</given-names></name></person-group><article-title>How does gaze to faces support face-to-face interaction? A review and perspective</article-title><source>Psychonomic Bulletin and Review</source><year>2020</year><volume>27</volume><issue>5</issue><fpage>856</fpage><lpage>881</lpage><pub-id pub-id-type="doi">10.3758/s13423-020-01715-w</pub-id></element-citation></ref><ref id="R106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hickey</surname><given-names>P</given-names></name><name><surname>Merseal</surname><given-names>H</given-names></name><name><surname>Patel</surname><given-names>AD</given-names></name><name><surname>Race</surname><given-names>E</given-names></name></person-group><article-title>Memory in time: Neural tracking of low-frequency rhythm dynamically modulates memory formation</article-title><source>NeuroImage</source><year>2020</year><month>February</month><volume>213</volume><elocation-id>116693</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.116693</pub-id></element-citation></ref><ref id="R107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoehl</surname><given-names>S</given-names></name><name><surname>Fairhurst</surname><given-names>M</given-names></name><name><surname>Schirmer</surname><given-names>A</given-names></name></person-group><article-title>Interactional synchrony: Signals, mechanisms and benefits</article-title><source>Social Cognitive and Affective Neuroscience</source><year>2021</year><volume>16</volume><issue>1–2</issue><fpage>5</fpage><lpage>18</lpage><pub-id pub-id-type="doi">10.1093/scan/nsaa024</pub-id></element-citation></ref><ref id="R108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoehl</surname><given-names>S</given-names></name><name><surname>Fairhurst</surname><given-names>M</given-names></name><name><surname>Schirmer</surname><given-names>A</given-names></name></person-group><article-title>Interactional synchrony: signals, mechanisms and benefits</article-title><source>Social Cognitive and Affective Neuroscience</source><year>2020</year><pub-id pub-id-type="doi">10.1093/scan/nsaa024</pub-id></element-citation></ref><ref id="R109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holler</surname><given-names>J</given-names></name><name><surname>Kendrick</surname><given-names>KH</given-names></name><name><surname>Casillas</surname><given-names>M</given-names></name><name><surname>Levinson</surname><given-names>SC</given-names></name></person-group><article-title>Editorial: Turn-Taking in Human Communicative Interaction</article-title><source>Frontiers in Psychology</source><year>2015</year><month>DEC</month><volume>6</volume><pub-id pub-id-type="doi">10.3389/fpsyg.2015.01919</pub-id></element-citation></ref><ref id="R110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hyafil</surname><given-names>A</given-names></name><name><surname>Fontolan</surname><given-names>L</given-names></name><name><surname>Kabdebon</surname><given-names>C</given-names></name><name><surname>Gutkin</surname><given-names>B</given-names></name><name><surname>Giraud</surname><given-names>AL</given-names></name></person-group><article-title>Speech encoding by coupled cortical theta and gamma oscillations</article-title><source>ELife</source><year>2015</year><month>MAY</month><volume>4</volume><fpage>1</fpage><lpage>45</lpage><pub-id pub-id-type="doi">10.7554/eLife.06213</pub-id></element-citation></ref><ref id="R111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jaffe</surname><given-names>J</given-names></name><name><surname>Beebe</surname><given-names>B</given-names></name><name><surname>Feldstein</surname><given-names>S</given-names></name><name><surname>Crown</surname><given-names>CL</given-names></name><name><surname>Jasnow</surname><given-names>MD</given-names></name></person-group><article-title>Rhythms of dialogue in infancy: coordinated timing in development</article-title><source>Monographs of the Society for Research in Child Development</source><year>2001</year><volume>66</volume><issue>2</issue><fpage>1</fpage><lpage>132</lpage><pub-id pub-id-type="pmid">11428150</pub-id></element-citation></ref><ref id="R112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jerger</surname><given-names>J</given-names></name><name><surname>Chmiel</surname><given-names>R</given-names></name><name><surname>Frost</surname><given-names>JD</given-names></name><name><surname>Coker</surname><given-names>N</given-names></name></person-group><article-title>Effect of sleep on the auditory steady state evoked potential</article-title><source>Ear and Hearing</source><year>1986</year><volume>7</volume><issue>4</issue><fpage>240</fpage><lpage>245</lpage><pub-id pub-id-type="doi">10.1097/00003446-198608000-00004</pub-id></element-citation></ref><ref id="R113"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jervis</surname><given-names>BW</given-names></name><name><surname>Nichols</surname><given-names>MJ</given-names></name><name><surname>Johnson</surname><given-names>TE</given-names></name><name><surname>Allen</surname><given-names>E</given-names></name><name><surname>Hudson</surname><given-names>NR</given-names></name></person-group><article-title>A Fundamental Investigation of the Composition of Auditory Evoked Potentials</article-title><source>IEEE Transactions on Biomedical Engineering, BME</source><year>1983</year><volume>30</volume><issue>1</issue><fpage>43</fpage><lpage>50</lpage><pub-id pub-id-type="doi">10.1109/TBME.1983.325165</pub-id></element-citation></ref><ref id="R114"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jessen</surname><given-names>S</given-names></name><name><surname>Fiedler</surname><given-names>L</given-names></name><name><surname>Münte</surname><given-names>TF</given-names></name><name><surname>Obleser</surname><given-names>J</given-names></name></person-group><article-title>Quantifying the individual auditory and visual brain response in 7-month-old infants watching a brief cartoon movie</article-title><source>NeuroImage</source><year>2019</year><month>April</month><volume>202</volume><elocation-id>116060</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.116060</pub-id></element-citation></ref><ref id="R115"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jessen</surname><given-names>S</given-names></name><name><surname>Fiedler</surname><given-names>L</given-names></name><name><surname>Münte</surname><given-names>TF</given-names></name><name><surname>Obleser</surname><given-names>J</given-names></name></person-group><article-title>Quantifying the individual auditory and visual brain response in 7-month-old infants watching a brief cartoon movie</article-title><source>NeuroImage</source><year>2019</year><month>July</month><volume>202</volume><elocation-id>116060</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.116060</pub-id></element-citation></ref><ref id="R116"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>J</given-names></name><name><surname>Dai</surname><given-names>B</given-names></name><name><surname>Peng</surname><given-names>D</given-names></name><name><surname>Zhu</surname><given-names>C</given-names></name><name><surname>Liu</surname><given-names>L</given-names></name><name><surname>Lu</surname><given-names>C</given-names></name></person-group><article-title>Neural Synchronization during Face-to-Face Communication</article-title><source>The Journal of Neuroscience</source><year>2012</year><volume>32</volume><issue>45</issue><fpage>16064</fpage><lpage>16069</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2926-12.2012</pub-id></element-citation></ref><ref id="R117"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>EJH</given-names></name><name><surname>Venema</surname><given-names>K</given-names></name><name><surname>Lowy</surname><given-names>R</given-names></name><name><surname>Earl</surname><given-names>RK</given-names></name><name><surname>Webb</surname><given-names>SJ</given-names></name></person-group><article-title>Developmental changes in infant brain activity during naturalistic social experiences</article-title><source>Developmental Psychobiology</source><year>2015</year><volume>57</volume><issue>7</issue><fpage>842</fpage><lpage>853</lpage><pub-id pub-id-type="doi">10.1002/dev.21336</pub-id></element-citation></ref><ref id="R118"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kabdebon</surname><given-names>C</given-names></name><name><surname>Pena</surname><given-names>M</given-names></name><name><surname>Buiatti</surname><given-names>M</given-names></name><name><surname>Dehaene-lambertz</surname><given-names>G</given-names></name></person-group><article-title>Brain &amp; Language Electrophysiological evidence of statistical learning of long-distance dependencies in 8-month-old preterm and full-term infants</article-title><source>Brain and Language</source><year>2015</year><volume>148</volume><fpage>25</fpage><lpage>36</lpage><pub-id pub-id-type="doi">10.1016/j.bandl.2015.03.005</pub-id></element-citation></ref><ref id="R119"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kabdebon</surname><given-names>C</given-names></name><name><surname>Fló</surname><given-names>A</given-names></name><name><surname>Heering</surname><given-names>ADe</given-names></name><name><surname>Aslin</surname><given-names>R</given-names></name></person-group><article-title>The power of rhythms: how steady-state evoked responses reveal early neurocognitive development</article-title><source>NeuroImage</source><year>2022</year><volume>254</volume><elocation-id>119150</elocation-id><comment>(August 2021)</comment><pub-id pub-id-type="doi">10.1016/j.neuroimage.2022.119150</pub-id></element-citation></ref><ref id="R120"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kalashnikova</surname><given-names>M</given-names></name><name><surname>Peter</surname><given-names>V</given-names></name><name><surname>Di Liberto</surname><given-names>GM</given-names></name><name><surname>Lalor</surname><given-names>EC</given-names></name><name><surname>Burnham</surname><given-names>D</given-names></name></person-group><article-title>Infant-directed speech facilitates seven-month-old infants’ cortical tracking of speech</article-title><source>Scientific Reports</source><year>2018</year><volume>8</volume><issue>1</issue><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1038/s41598-018-32150-6</pub-id></element-citation></ref><ref id="R121"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kalashnikova</surname><given-names>M</given-names></name><name><surname>Peter</surname><given-names>V</given-names></name><name><surname>Di Liberto</surname><given-names>GM</given-names></name><name><surname>Lalor</surname><given-names>EC</given-names></name></person-group><article-title>Infant-directed speech facilitates seven-month-old infants ’ cortical tracking of speech</article-title><source>Scientific Reports</source><year>2018</year><month>April</month><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1038/s41598-018-32150-6</pub-id></element-citation></ref><ref id="R122"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kandylaki</surname><given-names>KD</given-names></name><name><surname>Kotz</surname><given-names>SA</given-names></name></person-group><article-title>Distinct cortical rhythms in speech and language processing and some more: a commentary on</article-title><source>Language, Cognition and Neuroscience</source><year>2020</year><volume>0</volume><issue>0</issue><fpage>1</fpage><lpage>5</lpage><pub-id pub-id-type="doi">10.1080/23273798.2020.1757729</pub-id></element-citation></ref><ref id="R123"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kawasaki</surname><given-names>M</given-names></name><name><surname>Yamada</surname><given-names>Y</given-names></name><name><surname>Ushiku</surname><given-names>Y</given-names></name><name><surname>Miyauchi</surname><given-names>E</given-names></name><name><surname>Yamaguchi</surname><given-names>Y</given-names></name></person-group><article-title>Inter-brain synchronization during coordination of speech rhythm in human-to-human social interaction</article-title><year>2013</year><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1038/srep01692</pub-id></element-citation></ref><ref id="R124"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kayhan</surname><given-names>E</given-names></name><name><surname>Nguyen</surname><given-names>T</given-names></name><name><surname>Matthes</surname><given-names>D</given-names></name><name><surname>Langeloh</surname><given-names>M</given-names></name><name><surname>Michel</surname><given-names>C</given-names></name><name><surname>Jiang</surname><given-names>J</given-names></name></person-group><article-title>Interpersonal neural synchrony when predicting others ’ actions during a game of rock - paper - scissors</article-title><source>Scientific Reports</source><year>2022</year><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1038/s41598-022-16956-z</pub-id></element-citation></ref><ref id="R125"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kayser</surname><given-names>C</given-names></name><name><surname>Wilson</surname><given-names>C</given-names></name><name><surname>Safaai</surname><given-names>H</given-names></name><name><surname>Sakata</surname><given-names>S</given-names></name><name><surname>Panzeri</surname><given-names>S</given-names></name></person-group><article-title>Rhythmic auditory cortex activity at multiple timescales shapes stimulus–response gain and background firing</article-title><source>Journal of Neuroscience</source><year>2015</year><volume>35</volume><issue>20</issue><fpage>7750</fpage><lpage>7762</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0268-15.2015</pub-id></element-citation></ref><ref id="R126"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kimbrough Oller</surname><given-names>D</given-names></name></person-group><source>The Emergence of the Speech Capability</source><edition>1st ed</edition><publisher-name>Taylor &amp; Francis</publisher-name><year>2000</year></element-citation></ref><ref id="R127"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kingsbury</surname><given-names>L</given-names></name><name><surname>Huang</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Gu</surname><given-names>K</given-names></name><name><surname>Golshani</surname><given-names>P</given-names></name><name><surname>Wu</surname><given-names>YE</given-names></name><name><surname>Hong</surname><given-names>W</given-names></name></person-group><article-title>Correlated Neural Activity and Encoding of Behavior across Brains of Socially Interacting Animals</article-title><source>Cell</source><year>2019</year><volume>178</volume><issue>2</issue><fpage>429</fpage><lpage>446</lpage><elocation-id>e16</elocation-id><pub-id pub-id-type="doi">10.1016/j.cell.2019.05.022</pub-id></element-citation></ref><ref id="R128"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kösem</surname><given-names>A</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Van Wassenhove</surname><given-names>V</given-names></name></person-group><article-title>Encoding of event timing in the phase of neural oscillations</article-title><source>NeuroImage</source><year>2014</year><volume>92</volume><fpage>274</fpage><lpage>284</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.02.010</pub-id></element-citation></ref><ref id="R129"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koskinen</surname><given-names>M</given-names></name><name><surname>Seppä</surname><given-names>M</given-names></name></person-group><article-title>Uncovering cortical MEG responses to listened audiobook stories</article-title><source>NeuroImage</source><year>2014</year><volume>100</volume><fpage>263</fpage><lpage>270</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.06.018</pub-id></element-citation></ref><ref id="R130"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kothe</surname><given-names>C</given-names></name></person-group><source>Clean_channels EEGLAb plugin</source><publisher-name>The Mathworks, Inc</publisher-name><year>2014</year></element-citation></ref><ref id="R131"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kothe</surname><given-names>C</given-names></name></person-group><source>clean_windows EEGLAB plugin</source><publisher-name>The Mathworks, Inc</publisher-name><year>2010</year></element-citation></ref><ref id="R132"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kozulin</surname><given-names>P</given-names></name><name><surname>Almarza</surname><given-names>G</given-names></name><name><surname>Gobius</surname><given-names>I</given-names></name><name><surname>Richards</surname><given-names>LJ</given-names></name></person-group><article-title>Prenatal and Postnatal Determinants of Development</article-title><source>Neuromethods</source><year>2016</year><volume>109</volume><fpage>3</fpage><lpage>20</lpage><pub-id pub-id-type="doi">10.1007/978-1-4939-3014-2</pub-id></element-citation></ref><ref id="R133"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kushnerenko</surname><given-names>E</given-names></name><name><surname>Eponiene</surname><given-names>R</given-names></name><name><surname>Balan</surname><given-names>P</given-names></name><name><surname>Fellman</surname><given-names>V</given-names></name><name><surname>Huotilainen</surname><given-names>M</given-names></name><name><surname>Näätänen</surname><given-names>R</given-names></name></person-group><article-title>Maturation of the auditory event-related potentials during the first year of life</article-title><source>NeuroReport</source><year>2002</year><volume>13</volume><issue>1</issue><fpage>47</fpage><lpage>51</lpage><pub-id pub-id-type="doi">10.1097/00001756-200201210-00014</pub-id></element-citation></ref><ref id="R134"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuwada</surname><given-names>S</given-names></name><name><surname>Batra</surname><given-names>R</given-names></name><name><surname>Maher</surname><given-names>VL</given-names></name></person-group><article-title>Scalp potentials of normal and hearing-impaired subjects in response to sinusoidally amplitude-modulated tones</article-title><source>Hearing Research</source><year>1986</year><volume>21</volume><issue>2</issue><fpage>179</fpage><lpage>192</lpage><pub-id pub-id-type="doi">10.1016/0378-5955(86)90038-9</pub-id></element-citation></ref><ref id="R135"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lachaux</surname><given-names>JP</given-names></name><name><surname>Rodriguez</surname><given-names>E</given-names></name><name><surname>Martinerie</surname><given-names>J</given-names></name><name><surname>Varela</surname><given-names>FJ</given-names></name></person-group><article-title>Measuring phase synchrony in brain signals</article-title><source>Human Brain Mapping</source><year>1999</year><volume>8</volume><issue>4</issue><fpage>194</fpage><lpage>208</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1097-0193(1999)8:4˂194::AID-HBM4˃3.0.CO;2-C</pub-id></element-citation></ref><ref id="R136"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lachaux</surname><given-names>J-P</given-names></name><name><surname>Rodriguez</surname><given-names>E</given-names></name><name><surname>Martinerie</surname><given-names>J</given-names></name><name><surname>Varela</surname><given-names>FJ</given-names></name></person-group><article-title>Measureing Phase Synchrony in Brain Signals</article-title><source>Human Brain Mapping</source><year>1978</year><volume>8</volume><fpage>194</fpage><lpage>208</lpage><pub-id pub-id-type="doi">10.1017/S0007680500048066</pub-id></element-citation></ref><ref id="R137"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lakatos</surname><given-names>P</given-names></name><name><surname>Gross</surname><given-names>J</given-names></name><name><surname>Thut</surname><given-names>G</given-names></name></person-group><article-title>A New Unifying Account of the Roles of Neuronal Entrainment</article-title><source>Current Biology</source><year>2019</year><volume>29</volume><issue>18</issue><fpage>R890</fpage><lpage>R905</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2019.07.075</pub-id></element-citation></ref><ref id="R138"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lakatos</surname><given-names>P</given-names></name><name><surname>Karmos</surname><given-names>G</given-names></name><name><surname>Mehta</surname><given-names>AD</given-names></name><name><surname>Ulbert</surname><given-names>I</given-names></name><name><surname>Schroeder</surname><given-names>CE</given-names></name></person-group><article-title>Entrainment of neuronal oscillations as a mechanism of attentional selection</article-title><source>Science</source><year>2008</year><volume>320</volume><issue>5872</issue><fpage>110</fpage><lpage>113</lpage><pub-id pub-id-type="doi">10.1126/science.1154735</pub-id></element-citation></ref><ref id="R139"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lakatos</surname><given-names>P</given-names></name><name><surname>Musacchia</surname><given-names>G</given-names></name><name><surname>O’Connel</surname><given-names>MN</given-names></name><name><surname>Falchier</surname><given-names>AY</given-names></name><name><surname>Javitt</surname><given-names>DC</given-names></name><name><surname>Schroeder</surname><given-names>CE</given-names></name></person-group><article-title>The Spectrotemporal Filter Mechanism of Auditory Selective Attention</article-title><source>Neuron</source><year>2013</year><volume>77</volume><issue>4</issue><fpage>750</fpage><lpage>761</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.11.034</pub-id></element-citation></ref><ref id="R140"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lankinen</surname><given-names>K</given-names></name><name><surname>Saari</surname><given-names>J</given-names></name><name><surname>Hari</surname><given-names>R</given-names></name><name><surname>Koskinen</surname><given-names>M</given-names></name></person-group><article-title>Intersubject consistency of cortical MEG signals during movie viewing</article-title><source>NeuroImage</source><year>2014</year><volume>92</volume><fpage>217</fpage><lpage>224</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.02.004</pub-id></element-citation></ref><ref id="R141"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leong</surname><given-names>V</given-names></name><name><surname>Byrne</surname><given-names>E</given-names></name><name><surname>Clackson</surname><given-names>K</given-names></name><name><surname>Georgieva</surname><given-names>S</given-names></name><name><surname>Lam</surname><given-names>S</given-names></name><name><surname>Wass</surname><given-names>S</given-names></name></person-group><article-title>Speaker gaze increases information coupling between infant and adult brains</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><year>2017</year><volume>114</volume><issue>50</issue><fpage>13290</fpage><lpage>13295</lpage><pub-id pub-id-type="doi">10.1073/pnas.1702493114</pub-id></element-citation></ref><ref id="R142"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leong</surname><given-names>V</given-names></name><name><surname>Goswami</surname><given-names>U</given-names></name></person-group><article-title>Acoustic-emergent phonology in the amplitude envelope of child-directed speech</article-title><source>PLoS ONE</source><year>2015</year><volume>10</volume><issue>12</issue><fpage>1</fpage><lpage>37</lpage><pub-id pub-id-type="doi">10.1371/journal.pone.0144411</pub-id></element-citation></ref><ref id="R143"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leong</surname><given-names>V</given-names></name><name><surname>Noreika</surname><given-names>V</given-names></name><name><surname>Clackson</surname><given-names>K</given-names></name><name><surname>Georgieva</surname><given-names>S</given-names></name><name><surname>Brightman</surname><given-names>L</given-names></name><name><surname>Nutbrown</surname><given-names>R</given-names></name><name><surname>Fujita</surname><given-names>S</given-names></name><name><surname>Neale</surname><given-names>D</given-names></name><name><surname>Wass</surname><given-names>S</given-names></name></person-group><article-title>Mother-infant interpersonal neural connectivity predicts infants’ social learning</article-title><year>2019</year><pub-id pub-id-type="doi">10.31234/osf.io/gueaq</pub-id></element-citation></ref><ref id="R144"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leong</surname><given-names>V</given-names></name><name><surname>Stone</surname><given-names>MA</given-names></name><name><surname>Turner</surname><given-names>RE</given-names></name><name><surname>Goswami</surname><given-names>U</given-names></name></person-group><article-title>A role for amplitude modulation phase relationships in speech rhythm perception</article-title><source>The Journal of the Acoustical Society of America</source><year>2014</year><volume>136</volume><issue>1</issue><fpage>366</fpage><lpage>381</lpage><pub-id pub-id-type="doi">10.1121/1.4883366</pub-id></element-citation></ref><ref id="R145"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levi</surname><given-names>EC</given-names></name><name><surname>Folsom</surname><given-names>RC</given-names></name><name><surname>Dobie</surname><given-names>RA</given-names></name></person-group><article-title>Amplitude-modulation following response (AMFR): Effects of modulation rate, carrier frequency, age, and state</article-title><source>Hearing Research</source><year>1993</year><volume>68</volume><issue>1</issue><fpage>42</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.1016/0378-5955(93)90063-7</pub-id></element-citation></ref><ref id="R146"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Levitan</surname><given-names>R</given-names></name><name><surname>Hirschberg</surname><given-names>J</given-names></name></person-group><article-title>Measuring acoustic-prosodic entrainment with respect to multiple levels and dimensions</article-title><conf-name>Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH</conf-name><year>2011</year><fpage>3081</fpage><lpage>3084</lpage><pub-id pub-id-type="doi">10.21437/interspeech.2011-771</pub-id></element-citation></ref><ref id="R147"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liégeois-Chauvel</surname><given-names>C</given-names></name><name><surname>Lorenzi</surname><given-names>C</given-names></name><name><surname>Trébuchon</surname><given-names>A</given-names></name><name><surname>Régis</surname><given-names>J</given-names></name><name><surname>Chauvel</surname><given-names>P</given-names></name></person-group><article-title>Temporal envelope processing in the human left and right auditory cortices</article-title><source>Cerebral Cortex</source><year>2004</year><volume>14</volume><issue>7</issue><fpage>731</fpage><lpage>740</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhh033</pub-id></element-citation></ref><ref id="R148"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Llinas</surname><given-names>RR</given-names></name></person-group><article-title>Intrinsic Electrophysiological Properties Central Nervous System Function</article-title><source>Science</source><year>1988</year><volume>242</volume><fpage>1654</fpage><lpage>1664</lpage></element-citation></ref><ref id="R149"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lo</surname><given-names>C-W</given-names></name><name><surname>Tung</surname><given-names>T-Y</given-names></name><name><surname>Ke</surname><given-names>AH</given-names></name><name><surname>Brennan</surname><given-names>JR</given-names></name></person-group><article-title>Hierarchy, Not Lexical Regularity, Modulates Low-Frequency Neural Synchrony During Language Comprehension</article-title><source>Neurobiology of Language</source><year>2022</year><volume>3</volume><issue>4</issue><fpage>538</fpage><lpage>555</lpage><pub-id pub-id-type="doi">10.1162/nol_a_00077</pub-id></element-citation></ref><ref id="R150"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lorenzini</surname><given-names>I</given-names></name><name><surname>Labendzki</surname><given-names>P</given-names></name><name><surname>Hababou</surname><given-names>M</given-names></name><name><surname>Basire</surname><given-names>C</given-names></name></person-group><article-title>Human neural processing of auditory temporal modulations during the first year of life</article-title><source>PsyArXiv, (Preprint)</source><year>2022</year><fpage>1</fpage><lpage>21</lpage></element-citation></ref><ref id="R151"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luo</surname><given-names>H</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Poeppel</surname><given-names>D</given-names></name><name><surname>Simon</surname><given-names>JZ</given-names></name></person-group><article-title>Concurrent encoding of frequency and amplitude modulation in human auditory cortex: MEG evidence</article-title><source>Journal of Neurophysiology</source><year>2006</year><volume>96</volume><issue>5</issue><fpage>2712</fpage><lpage>2723</lpage><pub-id pub-id-type="doi">10.1152/jn.01256.2005</pub-id></element-citation></ref><ref id="R152"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maitha</surname><given-names>C</given-names></name><name><surname>Goode</surname><given-names>JC</given-names></name><name><surname>Maulucci</surname><given-names>DP</given-names></name><name><surname>Lasassmeh</surname><given-names>SMS</given-names></name><name><surname>Yu</surname><given-names>C</given-names></name><name><surname>Smith</surname><given-names>LB</given-names></name><name><surname>Borjon</surname><given-names>JI</given-names></name></person-group><article-title>An open-source, wireless vest for measuring autonomic function in infants</article-title><year>2020</year></element-citation></ref><ref id="R153"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Makeig</surname><given-names>S</given-names></name><name><surname>Westerfield</surname><given-names>M</given-names></name><name><surname>Jung</surname><given-names>TP</given-names></name><name><surname>Enghoff</surname><given-names>S</given-names></name><name><surname>Townsend</surname><given-names>J</given-names></name><name><surname>Courchesne</surname><given-names>E</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><article-title>Dynamic brain sources of visual evoked responses</article-title><source>Science</source><year>2002</year><volume>295</volume><issue>5555</issue><fpage>690</fpage><lpage>694</lpage><pub-id pub-id-type="doi">10.1126/science.1066168</pub-id></element-citation></ref><ref id="R154"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mannix</surname><given-names>P</given-names></name><name><surname>Inwald</surname><given-names>D</given-names></name><name><surname>hathorn</surname><given-names>M</given-names></name><name><surname>Coseloe</surname><given-names>K</given-names></name></person-group><article-title>Tehrman Entrainment of Heart Rate in the Preterm Infant</article-title><source>Pediatric Research</source><year>1997</year><volume>42</volume><fpage>282</fpage><lpage>286</lpage></element-citation></ref><ref id="R155"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marriott Haresign</surname><given-names>I</given-names></name><name><surname>Phillips</surname><given-names>E</given-names></name><name><surname>Whitehorn</surname><given-names>M</given-names></name><name><surname>Noreika</surname><given-names>V</given-names></name><name><surname>Jones</surname><given-names>EJH</given-names></name><name><surname>Leong</surname><given-names>V</given-names></name><name><surname>Wass</surname><given-names>SV</given-names></name></person-group><article-title>Automatic classification of ICA components from infant EEG using MARA</article-title><source>Developmental Cognitive Neuroscience</source><year>2021</year><month>September</month><volume>52</volume><elocation-id>101024</elocation-id><pub-id pub-id-type="doi">10.1016/j.dcn.2021.101024</pub-id></element-citation></ref><ref id="R156"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marshall</surname><given-names>PJ</given-names></name><name><surname>Bar-Haim</surname><given-names>Y</given-names></name><name><surname>Fox</surname><given-names>NA</given-names></name></person-group><article-title>Development of the EEG from 5 months to 4 years of age</article-title><source>Clinical Neurophysiology</source><year>2002</year><volume>113</volume><issue>8</issue><fpage>1199</fpage><lpage>1208</lpage><pub-id pub-id-type="doi">10.1016/S1388-2457(02)00163-3</pub-id></element-citation></ref><ref id="R157"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Masataka</surname><given-names>N</given-names></name></person-group><article-title>Preference for infant-directed singing in 2-day-old hearing infants of deaf parents</article-title><source>Developmental Psychology</source><year>1999</year><volume>35</volume><issue>4</issue><fpage>1001</fpage><lpage>1005</lpage><pub-id pub-id-type="doi">10.1037/0012-1649.35.4.1001</pub-id></element-citation></ref><ref id="R158"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maurizi</surname><given-names>M</given-names></name><name><surname>Almadori</surname><given-names>G</given-names></name><name><surname>Paludetti</surname><given-names>G</given-names></name><name><surname>Ottavani</surname><given-names>F</given-names></name><name><surname>Rosignoli</surname><given-names>M</given-names></name><name><surname>Luciano</surname><given-names>R</given-names></name></person-group><article-title>40-Hz Steady-State Responses in Newborns and in Children</article-title><source>Audiology</source><year>1990</year><volume>29</volume><fpage>322</fpage><lpage>328</lpage></element-citation></ref><ref id="R159"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McAdams</surname><given-names>S</given-names></name><name><surname>Bertoncini</surname><given-names>J</given-names></name></person-group><article-title>Organization and discrimination of repeating sound sequences by newborn infants</article-title><source>The Journal of the Acoustical Society of America</source><year>1997</year><volume>102</volume><issue>5</issue><fpage>2945</fpage><lpage>2953</lpage><pub-id pub-id-type="doi">10.1121/1.420349</pub-id></element-citation></ref><ref id="R160"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McCulloch</surname><given-names>DL</given-names></name><name><surname>Orbach</surname><given-names>H</given-names></name><name><surname>Skarf</surname><given-names>B</given-names></name></person-group><article-title>Maturation of the pattern-reversal VEP in human infants: A theoretical framework</article-title><source>Vision Research</source><year>1999</year><volume>39</volume><issue>22</issue><fpage>3673</fpage><lpage>3680</lpage><pub-id pub-id-type="doi">10.1016/S0042-6989(99)00091-7</pub-id></element-citation></ref><ref id="R161"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname><given-names>L</given-names></name><name><surname>Sun</surname><given-names>Y</given-names></name><name><surname>Martin</surname><given-names>AE</given-names></name></person-group><article-title>Synchronous, but not entrained: exogenous and endogenous cortical rhythms of speech and language processing</article-title><year>2019</year><volume>3798</volume><pub-id pub-id-type="doi">10.1080/23273798.2019.1693050</pub-id></element-citation></ref><ref id="R162"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname><given-names>L</given-names></name><name><surname>Sun</surname><given-names>Y</given-names></name><name><surname>Martin</surname><given-names>AE</given-names></name><name><surname>Meyer</surname><given-names>L</given-names></name><name><surname>Sun</surname><given-names>Y</given-names></name><name><surname>Entraining</surname><given-names>AEM</given-names></name></person-group><article-title>Entraining ” to speech, generating languageâ€¯?</article-title><source>Language, Cognition and Neuroscience</source><year>2020</year><volume>0</volume><issue>0</issue><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1080/23273798.2020.1827155</pub-id></element-citation></ref><ref id="R163"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Michel</surname><given-names>CM</given-names></name><name><surname>He</surname><given-names>B</given-names></name></person-group><chapter-title>EEG source localization</chapter-title><source>Handbook of Clinical Neurology</source><edition>1st ed</edition><publisher-name>Elsevier B.V</publisher-name><year>2019</year><volume>160</volume><pub-id pub-id-type="doi">10.1016/B978-0-444-64032-1.00006-0</pub-id></element-citation></ref><ref id="R164"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Millman</surname><given-names>RE</given-names></name><name><surname>Prendergast</surname><given-names>G</given-names></name><name><surname>Kitterick</surname><given-names>PT</given-names></name><name><surname>Woods</surname><given-names>WP</given-names></name><name><surname>Green</surname><given-names>GGR</given-names></name></person-group><article-title>Spatiotemporal reconstruction of the auditory steady-state response to frequency modulation using magnetoencephalography</article-title><source>NeuroImage</source><year>2010</year><volume>49</volume><issue>1</issue><fpage>745</fpage><lpage>758</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.08.029</pub-id></element-citation></ref><ref id="R165"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moon</surname><given-names>C</given-names></name><name><surname>Cooper</surname><given-names>RP</given-names></name><name><surname>Fifer</surname><given-names>WP</given-names></name></person-group><article-title>Two-day-olds prefer their native language</article-title><source>Infant Behavior and Development</source><year>1993</year><volume>16</volume><issue>4</issue><fpage>495</fpage><lpage>500</lpage><pub-id pub-id-type="doi">10.1016/0163-6383(93)80007-U</pub-id></element-citation></ref><ref id="R166"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mühler</surname><given-names>R</given-names></name><name><surname>Rahne</surname><given-names>T</given-names></name><name><surname>Verhey</surname><given-names>JL</given-names></name></person-group><article-title>Auditory brainstem responses to broad-band chirps: Amplitude growth functions in sedated and anaesthetised infants</article-title><source>International Journal of Pediatric Otorhinolaryngology</source><year>2013</year><volume>77</volume><issue>1</issue><fpage>49</fpage><lpage>53</lpage><pub-id pub-id-type="doi">10.1016/j.ijporl.2012.09.028</pub-id></element-citation></ref><ref id="R167"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Mullen</surname><given-names>T</given-names></name></person-group><source>CleanLine EEGLAB plugin</source><publisher-name>The Mathworks, Inc</publisher-name><year>2012</year></element-citation></ref><ref id="R168"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murray</surname><given-names>L</given-names></name><name><surname>Trevarthen</surname><given-names>C</given-names></name></person-group><article-title>The infant’s role in mother-infant communications</article-title><source>Journal of Child Language</source><year>1986</year><volume>13</volume><issue>1</issue><fpage>15</fpage><lpage>29</lpage><pub-id pub-id-type="doi">10.1017/S0305000900000271</pub-id></element-citation></ref><ref id="R169"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Näätänen</surname><given-names>R</given-names></name><name><surname>Tervaniemi</surname><given-names>M</given-names></name><name><surname>Sussman</surname><given-names>E</given-names></name><name><surname>Paavilainen</surname><given-names>P</given-names></name><name><surname>Winkler</surname><given-names>I</given-names></name></person-group><article-title>‘Primitive intelligence’ in the auditory.pdf</article-title><source>Trends in Neurosciences</source><year>2001</year><volume>24</volume><issue>5</issue><fpage>283</fpage><lpage>288</lpage></element-citation></ref><ref id="R170"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Narayan</surname><given-names>CR</given-names></name><name><surname>McDermott</surname><given-names>LC</given-names></name></person-group><article-title>Speech rate and pitch characteristics of infant-directed speech: Longitudinal and cross-linguistic observations</article-title><source>The Journal of the Acoustical Society of America</source><year>2016</year><volume>139</volume><issue>3</issue><fpage>1272</fpage><lpage>1281</lpage><pub-id pub-id-type="doi">10.1121/1.4944634</pub-id></element-citation></ref><ref id="R171"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Neale</surname><given-names>D</given-names></name><name><surname>Georgieva</surname><given-names>S</given-names></name><name><surname>Wass</surname><given-names>S</given-names></name><name><surname>Leong</surname><given-names>V</given-names></name></person-group><article-title>Towards a neuroscientific understanding of play: A neuropsychological coding framework for analysing infant-adult play patterns</article-title><year>2017</year><month>October</month><pub-id pub-id-type="doi">10.1101/202648</pub-id></element-citation></ref><ref id="R172"><element-citation publication-type="journal"><person-group person-group-type="author"><collab>Neuroscience, C</collab><name><surname>Cirelli</surname><given-names>Laura K</given-names></name></person-group><article-title>Effects of maternal singing style on mother–infant arousal and behavior</article-title><year>2019</year><fpage>1</fpage><lpage>27</lpage></element-citation></ref><ref id="R173"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niedźwiecka</surname><given-names>A</given-names></name><name><surname>Ramotowska</surname><given-names>S</given-names></name><name><surname>Tomalski</surname><given-names>P</given-names></name></person-group><article-title>Mutual Gaze During Early Mother–Infant Interactions Promotes Attention Control Development</article-title><source>Child Development</source><year>2018</year><volume>89</volume><issue>6</issue><fpage>2230</fpage><lpage>2244</lpage><pub-id pub-id-type="doi">10.1111/cdev.12830</pub-id></element-citation></ref><ref id="R174"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niepel</surname><given-names>D</given-names></name><name><surname>Krishna</surname><given-names>B</given-names></name><name><surname>Siegel</surname><given-names>ER</given-names></name><name><surname>Draganova</surname><given-names>R</given-names></name><name><surname>Preissl</surname><given-names>H</given-names></name><name><surname>Govindan</surname><given-names>RB</given-names></name><name><surname>Eswaran</surname><given-names>H</given-names></name></person-group><article-title>A pilot study: Auditory steady-state responses (ASSR) can be measured in human fetuses using fetal magnetoencephalography (fMEG)</article-title><source>PLoS ONE</source><year>2020</year><month>July</month><day>7</day><volume>15</volume><fpage>1</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.1371/journal.pone.0235310</pub-id></element-citation></ref><ref id="R175"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Notbohm</surname><given-names>A</given-names></name><name><surname>Kurths</surname><given-names>J</given-names></name><name><surname>Herrmann</surname><given-names>CS</given-names></name></person-group><article-title>Modification of brain oscillations via rhythmic light stimulation provides evidence for entrainment but not for superposition of event-related responses</article-title><source>Frontiers in Human Neuroscience</source><year>2016</year><month>FEB</month><volume>10</volume><comment>2016</comment><pub-id pub-id-type="doi">10.3389/fnhum.2016.00010</pub-id></element-citation></ref><ref id="R176"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Novak</surname><given-names>GP</given-names></name><name><surname>Kurtzberg</surname><given-names>D</given-names></name><name><surname>Kreuzer</surname><given-names>JA</given-names></name><name><surname>Vaughan</surname><given-names>HG</given-names></name></person-group><article-title>Cortical responses to speech sounds and their formants in normal infants: maturational sequence and spatiotemporal analysis</article-title><source>Electroencephalography and Clinical Neurophysiology</source><year>1989</year><volume>73</volume><issue>4</issue><fpage>295</fpage><lpage>305</lpage><pub-id pub-id-type="doi">10.1016/0013-4694(89)90108-9</pub-id></element-citation></ref><ref id="R177"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nozaradan</surname><given-names>S</given-names></name><name><surname>Keller</surname><given-names>PE</given-names></name><name><surname>Rossion</surname><given-names>B</given-names></name><name><surname>Mouraux</surname><given-names>A</given-names></name></person-group><article-title>EEG Frequency-Tagging and Input–Output Comparison in Rhythm Perception</article-title><source>Brain Topography</source><year>2018</year><volume>31</volume><issue>2</issue><fpage>153</fpage><lpage>160</lpage><pub-id pub-id-type="doi">10.1007/s10548-017-0605-8</pub-id></element-citation></ref><ref id="R178"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nozaradan</surname><given-names>S</given-names></name><name><surname>Peretz</surname><given-names>I</given-names></name><name><surname>Missal</surname><given-names>M</given-names></name><name><surname>Mouraux</surname><given-names>A</given-names></name></person-group><article-title>Tagging the neuronal entrainment to beat and meter</article-title><source>Journal of Neuroscience</source><year>2011</year><volume>31</volume><issue>28</issue><fpage>10234</fpage><lpage>10240</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0411-11.2011</pub-id></element-citation></ref><ref id="R179"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nozaradan</surname><given-names>S</given-names></name><name><surname>Peretz</surname><given-names>I</given-names></name><name><surname>Mouraux</surname><given-names>A</given-names></name></person-group><article-title>Selective neuronal entrainment to the beat and meter embedded in a musical rhythm</article-title><source>Journal of Neuroscience</source><year>2012</year><volume>32</volume><issue>49</issue><fpage>17572</fpage><lpage>17581</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3203-12.2012</pub-id></element-citation></ref><ref id="R180"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olsen</surname><given-names>WO</given-names></name></person-group><article-title>Average Speech Levels and Spectra in Various Speaking/Listening Conditions: A Summary of the Pearson, Bennett &amp; Fidell (1977) Report</article-title><source>American Journal of Audiology</source><year>1977</year><volume>7</volume></element-citation></ref><ref id="R181"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ostchega</surname><given-names>Y</given-names></name><name><surname>Porter</surname><given-names>K</given-names></name><name><surname>Hughes</surname><given-names>J</given-names></name><name><surname>Dillon</surname><given-names>C</given-names></name><name><surname>Nwankwo</surname><given-names>T</given-names></name></person-group><article-title>Resting Pulse Rate Reference Data for Children, Adolescents, and Adults: United States, 1999-2008</article-title><year>2011</year><fpage>1</fpage><lpage>16</lpage></element-citation></ref><ref id="R182"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>H</given-names></name><name><surname>Ince</surname><given-names>RAA</given-names></name><name><surname>Schyns</surname><given-names>PG</given-names></name><name><surname>Thut</surname><given-names>G</given-names></name><name><surname>Park</surname><given-names>H</given-names></name><name><surname>Ince</surname><given-names>RAA</given-names></name><name><surname>Schyns</surname><given-names>PG</given-names></name><name><surname>Thut</surname><given-names>G</given-names></name><name><surname>Gross</surname><given-names>J</given-names></name></person-group><article-title>Frontal Top-Down Signals Increase Coupling of Auditory Low-Frequency Oscillations to Continuous Speech in Human Listeners Report Frontal Top-Down Signals Increase Coupling of Auditory Low-Frequency Oscillations to Continuous Speech in Human Listeners</article-title><source>Current Biology</source><year>2015</year><volume>25</volume><issue>12</issue><fpage>1649</fpage><lpage>1653</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2015.04.049</pub-id></element-citation></ref><ref id="R183"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paulus</surname><given-names>M</given-names></name><name><surname>Hunnius</surname><given-names>S</given-names></name><name><surname>Bekkering</surname><given-names>H</given-names></name></person-group><article-title>Neurocognitive mechanisms underlying social learning in infancy: infants ’ neural processing of the effects of others ’ actions</article-title><year>2013</year><fpage>774</fpage><lpage>779</lpage><pub-id pub-id-type="doi">10.1093/scan/nss065</pub-id></element-citation></ref><ref id="R184"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peelle</surname><given-names>JE</given-names></name><name><surname>Gross</surname><given-names>J</given-names></name><name><surname>Davis</surname><given-names>MH</given-names></name></person-group><article-title>Phase-locked responses to speech in human auditory cortex are enhanced during comprehension</article-title><source>Cerebral Cortex</source><year>2013</year><volume>23</volume><issue>6</issue><fpage>1378</fpage><lpage>1387</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhs118</pub-id></element-citation></ref><ref id="R185"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peelle</surname><given-names>JE</given-names></name><name><surname>Gross</surname><given-names>J</given-names></name><name><surname>Davis</surname><given-names>MH</given-names></name></person-group><article-title>Phase-Locked Responses to Speech in Human Auditory Cortex are Enhanced During Comprehension</article-title><year>2013</year><month>June</month><fpage>1378</fpage><lpage>1387</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhs118</pub-id></element-citation></ref><ref id="R186"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pérez</surname><given-names>A</given-names></name><name><surname>Carreiras</surname><given-names>M</given-names></name><name><surname>Duñabeitia</surname><given-names>JA</given-names></name></person-group><article-title>Brain-To-brain entrainment: EEG interbrain synchronization while speaking and listening</article-title><source>Scientific Reports</source><year>2017</year><volume>7</volume><issue>1</issue><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.1038/s41598-017-04464-4</pub-id></element-citation></ref><ref id="R187"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perone</surname><given-names>S</given-names></name><name><surname>Gartstein</surname><given-names>MA</given-names></name></person-group><article-title>Relations between dynamics of parent-infant interactions and baseline EEG functional connectivity</article-title><source>Infant Behavior and Development</source><year>2019</year><month>March</month><volume>57</volume><elocation-id>101344</elocation-id><pub-id pub-id-type="doi">10.1016/j.infbeh.2019.101344</pub-id></element-citation></ref><ref id="R188"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pethe</surname><given-names>J</given-names></name><name><surname>Mühler</surname><given-names>R</given-names></name><name><surname>Siewert</surname><given-names>K</given-names></name><name><surname>Von Specht</surname><given-names>H</given-names></name></person-group><article-title>Near-threshold recordings of amplitude modulation following responses (AMFR) in children of different ages</article-title><source>International Journal of Audiology</source><year>2004</year><volume>43</volume><issue>6</issue><fpage>339</fpage><lpage>345</lpage><pub-id pub-id-type="doi">10.1080/14992020400050043</pub-id></element-citation></ref><ref id="R189"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Picton</surname><given-names>T</given-names></name><name><surname>Sasha John</surname><given-names>M</given-names></name><name><surname>Dimitrijevic</surname><given-names>A</given-names></name><name><surname>Purcell</surname><given-names>D</given-names></name></person-group><article-title>Human auditory steady-state responses</article-title><source>International Journal of Audiology</source><year>2003</year><volume>42</volume><fpage>177</fpage><lpage>219</lpage></element-citation></ref><ref id="R190"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Picton</surname><given-names>TW</given-names></name><name><surname>Skinner</surname><given-names>CR</given-names></name><name><surname>Champagne</surname><given-names>SC</given-names></name><name><surname>Kellett</surname><given-names>AJC</given-names></name></person-group><article-title>Potentials evoked by the sinusoidal modulation of the amplitude or frequency of a tone</article-title><source>Journal of Acousitic Society of America</source><year>1987</year><volume>82</volume><issue>1</issue><fpage>165</fpage><lpage>178</lpage></element-citation></ref><ref id="R191"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poulin-Dubois</surname><given-names>Diane</given-names></name><name><surname>Brosseau-Liard</surname><given-names>P</given-names></name></person-group><article-title>The Developmental Origins of Selective Social Learning</article-title><source>Physiology &amp; Behavior</source><year>2017</year><volume>176</volume><issue>3</issue><fpage>139</fpage><lpage>148</lpage><pub-id pub-id-type="doi">10.1177/0963721415613962.The</pub-id></element-citation></ref><ref id="R192"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Povel</surname><given-names>D</given-names></name><name><surname>Essens</surname><given-names>P</given-names></name></person-group><article-title>Perception of Temporal Patterns</article-title><source>Music Perception</source><year>1985</year><volume>2</volume><issue>4</issue><fpage>411</fpage><lpage>440</lpage></element-citation></ref><ref id="R193"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Power</surname><given-names>AJ</given-names></name><name><surname>Mead</surname><given-names>N</given-names></name><name><surname>Barnes</surname><given-names>L</given-names></name><name><surname>Goswami</surname><given-names>U</given-names></name></person-group><article-title>Neural Entrainment to Rhythmically Presented Auditory, Visual, and Audio-Visual Speech in Children</article-title><source>Frontiers in Psychology</source><year>2012</year><month>July</month><volume>3</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.3389/fpsyg.2012.00216</pub-id></element-citation></ref><ref id="R194"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rees</surname><given-names>A</given-names></name><name><surname>Green</surname><given-names>GGR</given-names></name><name><surname>Kay</surname><given-names>RH</given-names></name></person-group><article-title>Steady-state evoked responses to sinusoidally amplitude-modulated sounds recorded in man</article-title><source>Hearing Research</source><year>1986</year><volume>23</volume><issue>2</issue><fpage>123</fpage><lpage>133</lpage><pub-id pub-id-type="doi">10.1016/0378-5955(86)90009-2</pub-id></element-citation></ref><ref id="R195"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Regan</surname><given-names>D</given-names></name></person-group><article-title>Human brain electrophysiology: Evoked potentials and evoked magnetic fields in science and medicine</article-title><year>1989</year></element-citation></ref><ref id="R196"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reid</surname><given-names>VM</given-names></name></person-group><article-title>The directed attention model of infant social cognition</article-title><year>2007</year><month>May</month><comment>2014</comment><pub-id pub-id-type="doi">10.1080/17405620601005648</pub-id></element-citation></ref><ref id="R197"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reid</surname><given-names>VM</given-names></name><name><surname>Striano</surname><given-names>T</given-names></name><name><surname>Iacoboni</surname><given-names>M</given-names></name></person-group><article-title>Developmental Cognitive Neuroscience Neural correlates of dyadic interaction during infancy</article-title><source>Accident Analysis and Prevention</source><year>2011</year><volume>1</volume><issue>2</issue><fpage>124</fpage><lpage>130</lpage><pub-id pub-id-type="doi">10.1016/j.dcn.2011.01.001</pub-id></element-citation></ref><ref id="R198"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reindl</surname><given-names>V</given-names></name><name><surname>Gerloff</surname><given-names>C</given-names></name><name><surname>Scharke</surname><given-names>W</given-names></name><name><surname>Konrad</surname><given-names>K</given-names></name></person-group><source>NeuroImage</source><year>2018</year><comment>SC</comment><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.05.060</pub-id></element-citation></ref><ref id="R199"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rekow</surname><given-names>D</given-names></name><name><surname>Baudouin</surname><given-names>JY</given-names></name><name><surname>Durand</surname><given-names>K</given-names></name><name><surname>Leleu</surname><given-names>A</given-names></name></person-group><article-title>Smell what you hardly see: Odors assist visual categorization in the human brain</article-title><source>NeuroImage</source><year>2022</year><month>January</month><volume>255</volume><elocation-id>119181</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2022.119181</pub-id></element-citation></ref><ref id="R200"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Repp</surname><given-names>BH</given-names></name></person-group><source>Rate Limits of Sensorimotor Synchronization</source><year>2006</year><volume>2</volume><issue>2</issue><fpage>163</fpage><lpage>181</lpage></element-citation></ref><ref id="R201"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Retter</surname><given-names>TL</given-names></name><name><surname>Rossion</surname><given-names>B</given-names></name><name><surname>Schiltz</surname><given-names>C</given-names></name></person-group><article-title>Harmonic amplitude summation for frequency-tagging analysis</article-title><source>Journal of Cognitive Neuroscience</source><year>2021</year><volume>33</volume><issue>11</issue><fpage>2372</fpage><lpage>2393</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01763</pub-id></element-citation></ref><ref id="R202"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rickards</surname><given-names>FW</given-names></name><name><surname>Tan</surname><given-names>LE</given-names></name><name><surname>Cohen</surname><given-names>LT</given-names></name><name><surname>Wilson</surname><given-names>OJ</given-names></name><name><surname>Drew</surname><given-names>JH</given-names></name><name><surname>Clark</surname><given-names>GM</given-names></name></person-group><article-title>Auditory steady-state evoked potentials in newborns</article-title><source>British Journal of Audiology1</source><year>1994</year><volume>28</volume><fpage>327</fpage><lpage>337</lpage></element-citation></ref><ref id="R203"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rimmele</surname><given-names>JM</given-names></name><name><surname>Morillon</surname><given-names>B</given-names></name><name><surname>Poeppel</surname><given-names>D</given-names></name><name><surname>Arnal</surname><given-names>LH</given-names></name></person-group><article-title>Proactive Sensing of Periodic and Aperiodic Auditory Patterns</article-title><source>Trends in Cognitive Sciences</source><publisher-name>Elsevier Ltd</publisher-name><year>2018</year><volume>22</volume><issue>10</issue><fpage>870</fpage><lpage>882</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2018.08.003</pub-id></element-citation></ref><ref id="R204"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Riquelme</surname><given-names>R</given-names></name><name><surname>Kuwada</surname><given-names>S</given-names></name><name><surname>Filipovic</surname><given-names>B</given-names></name><name><surname>Hartung</surname><given-names>K</given-names></name><name><surname>Leonard</surname><given-names>G</given-names></name></person-group><article-title>Optimizing the stimuli to evoke the amplitude modulation following response (AMFR) in neonates</article-title><source>Ear and Hearing</source><year>2006</year><volume>27</volume><issue>2</issue><fpage>104</fpage><lpage>119</lpage><pub-id pub-id-type="doi">10.1097/01.aud.0000201857.99240.24</pub-id></element-citation></ref><ref id="R205"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robertson</surname><given-names>SS</given-names></name><name><surname>Watamura</surname><given-names>SE</given-names></name><name><surname>Wilbourn</surname><given-names>MP</given-names></name></person-group><article-title>Attentional dynamics of infant visual foraging</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><year>2012</year><volume>109</volume><issue>28</issue><fpage>11460</fpage><lpage>11464</lpage><pub-id pub-id-type="doi">10.1073/pnas.1203482109</pub-id></element-citation></ref><ref id="R206"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rojas</surname><given-names>DC</given-names></name><name><surname>Maharajh</surname><given-names>K</given-names></name><name><surname>Teale</surname><given-names>PD</given-names></name><name><surname>Kleman</surname><given-names>MR</given-names></name><name><surname>Benkers</surname><given-names>TL</given-names></name><name><surname>Carlson</surname><given-names>JP</given-names></name><name><surname>Reite</surname><given-names>ML</given-names></name></person-group><article-title>Development of the 40 Hz steady state auditory evoked magnetic field from ages 5 to 52</article-title><source>Clinical Neurophysiology</source><year>2006</year><volume>117</volume><issue>1</issue><fpage>110</fpage><lpage>117</lpage><pub-id pub-id-type="doi">10.1016/j.clinph.2005.08.032</pub-id></element-citation></ref><ref id="R207"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosen</surname><given-names>S</given-names></name></person-group><article-title>Temporal information in speech: acoustic, auditory and linguistic aspects</article-title><source>Philosophical transactions of the Royal Society of London. Series B, Biological sciences</source><year>1992</year><volume>336</volume><issue>1278</issue><fpage>367</fpage><lpage>373</lpage><pub-id pub-id-type="doi">10.1098/rstb.1992.0070</pub-id></element-citation></ref><ref id="R208"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roß</surname><given-names>B</given-names></name><name><surname>Borgmann</surname><given-names>C</given-names></name><name><surname>Draganova</surname><given-names>R</given-names></name><name><surname>Roberts</surname><given-names>LE</given-names></name><name><surname>Pantev</surname><given-names>C</given-names></name></person-group><article-title>A high-precision magnetoencephalographic study of human auditory steady-state responses to amplitude-modulated tones</article-title><source>The Journal of the Acoustical Society of America</source><year>2000</year><volume>108</volume><issue>2</issue><fpage>679</fpage><lpage>691</lpage><pub-id pub-id-type="doi">10.1121/1.429600</pub-id></element-citation></ref><ref id="R209"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saby</surname><given-names>JN</given-names></name><name><surname>Marshall</surname><given-names>PJ</given-names></name></person-group><article-title>Developmental Neuropsychology The Utility of EEG Band Power Analysis in the Study of Infancy and Early Childhood The Utility of EEG Band Power Analysis in the Study of Infancy and Early Childhood</article-title><year>2012</year><month>December</month><fpage>37</fpage><lpage>41</lpage><pub-id pub-id-type="doi">10.1080/87565641.2011.614663</pub-id></element-citation></ref><ref id="R210"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saffran</surname><given-names>JR</given-names></name><name><surname>Kirkham</surname><given-names>NZ</given-names></name></person-group><article-title>Infant Statistical Learning</article-title><source>Annual Review of Psychology</source><year>2018</year><volume>69</volume><fpage>181</fpage><lpage>203</lpage><pub-id pub-id-type="doi">10.1146/annurev-psych-122216-011805</pub-id></element-citation></ref><ref id="R211"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Saffran</surname><given-names>JR</given-names></name><name><surname>Werker</surname><given-names>JF</given-names></name><name><surname>Werner</surname><given-names>LA</given-names></name></person-group><chapter-title>The Infant’s Auditory World: Hearing, Speech, and the Beginnings of Language</chapter-title><source>Handbook of Child Psychology</source><year>2007</year><fpage>58</fpage><lpage>108</lpage><pub-id pub-id-type="doi">10.1002/9780470147658.chpsy0202</pub-id></element-citation></ref><ref id="R212"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saffran</surname><given-names>JR</given-names></name><name><surname>Johnson</surname><given-names>EK</given-names></name><name><surname>Aslin</surname><given-names>RN</given-names></name><name><surname>Newport</surname><given-names>EL</given-names></name></person-group><article-title>Statistical learning of tone sequences by human infants and adults</article-title><source>Cognition</source><year>1999</year><volume>70</volume><issue>1</issue><fpage>27</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.1016/S0010-0277(98)00075-4</pub-id></element-citation></ref><ref id="R213"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sammon</surname><given-names>MP</given-names></name><name><surname>Darnall</surname><given-names>RA</given-names></name></person-group><article-title>Entrainment of respiration to rocking in premature infants: Coherence analysis</article-title><source>Journal of Applied Physiology</source><year>1994</year><volume>77</volume><issue>3</issue><fpage>1548</fpage><lpage>1554</lpage><pub-id pub-id-type="doi">10.1152/jappl.1994.77.3.1548</pub-id></element-citation></ref><ref id="R214"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sauseng</surname><given-names>P</given-names></name><name><surname>Klimesch</surname><given-names>W</given-names></name><name><surname>Gruber</surname><given-names>WR</given-names></name><name><surname>Hanslmayr</surname><given-names>S</given-names></name><name><surname>Freunberger</surname><given-names>R</given-names></name><name><surname>Doppelmayr</surname><given-names>M</given-names></name></person-group><article-title>Are event-related potential components generated by phase resetting of brain oscillations? A critical discussion</article-title><source>Neuroscience</source><year>2007</year><volume>146</volume><issue>4</issue><fpage>1435</fpage><lpage>1444</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2007.03.014</pub-id></element-citation></ref><ref id="R215"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Savio</surname><given-names>G</given-names></name><name><surname>Cárdenas</surname><given-names>J</given-names></name><name><surname>Pérez Abalo</surname><given-names>MC</given-names></name><name><surname>González</surname><given-names>A</given-names></name><name><surname>Valdés</surname><given-names>J</given-names></name></person-group><article-title>The low and high frequency auditory steady state responses mature at different rates</article-title><source>Audiology and Neuro-Otology</source><year>2001</year><volume>6</volume><issue>5</issue><fpage>279</fpage><lpage>287</lpage><pub-id pub-id-type="doi">10.1159/000046133</pub-id></element-citation></ref><ref id="R216"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schaworonkow</surname><given-names>N</given-names></name><name><surname>Voytek</surname><given-names>B</given-names></name></person-group><article-title>Longitudinal changes in aperiodic and periodic activity in electrophysiological recordings in the first seven months of life</article-title><source>Developmental Cognitive Neuroscience</source><year>2021</year><volume>47</volume><elocation-id>100895</elocation-id><pub-id pub-id-type="doi">10.1016/j.dcn.2020.100895</pub-id></element-citation></ref><ref id="R217"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schroeder</surname><given-names>CE</given-names></name><name><surname>Lakatos</surname><given-names>P</given-names></name></person-group><article-title>Low-frequency neuronal oscillations as instruments of sensory selection</article-title><source>Trends in Neurosciences</source><year>2009</year><volume>32</volume><issue>1</issue><fpage>9</fpage><lpage>18</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2008.09.012</pub-id></element-citation></ref><ref id="R218"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schroeder</surname><given-names>CE</given-names></name><name><surname>Lakatos</surname><given-names>P</given-names></name><name><surname>Kajikawa</surname><given-names>Y</given-names></name><name><surname>Partan</surname><given-names>S</given-names></name><name><surname>Puce</surname><given-names>A</given-names></name></person-group><article-title>Neuronal oscillations and visual amplification of speech</article-title><source>Trends in Cognitive Sciences</source><year>2008</year><volume>12</volume><issue>3</issue><fpage>106</fpage><lpage>113</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2008.01.002</pub-id></element-citation></ref><ref id="R219"><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Service</surname><given-names>B</given-names></name><name><surname>Disclosure</surname><given-names>T</given-names></name><name><surname>Service</surname><given-names>B</given-names></name><name><surname>Act</surname><given-names>O</given-names></name><name><surname>Certificate</surname><given-names>EDBS</given-names></name><name><surname>Dbs</surname><given-names>E</given-names></name><name><surname>Certificate</surname><given-names>DBS</given-names></name><name><surname>Certificate</surname><given-names>DBS</given-names></name><name><surname>Ambassador</surname><given-names>UELS</given-names></name><name><surname>If</surname><given-names>M</given-names></name><name><surname>London</surname><given-names>E</given-names></name></person-group><source>Disclosure and Barring Service (DBS) Checks – Frequently asked questions</source><year>2019</year><month>February</month></element-citation></ref><ref id="R220"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shafer</surname><given-names>VL</given-names></name><name><surname>Yu</surname><given-names>YH</given-names></name><name><surname>Wagner</surname><given-names>M</given-names></name></person-group><article-title>Maturation of cortical auditory evoked potentials (CAEPs) to speech recorded from frontocentral and temporal sites: Three months to eight years of age</article-title><source>International Journal of Psychophysiology</source><year>2015</year><volume>95</volume><issue>2</issue><fpage>77</fpage><lpage>93</lpage><pub-id pub-id-type="doi">10.1016/j.ijpsycho.2014.08.1390</pub-id></element-citation></ref><ref id="R221"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shannon</surname><given-names>C</given-names></name></person-group><article-title>A Mathematical Theory of Communication</article-title><source>The Bell System Technical Journal</source><year>1948</year><volume>196</volume><issue>4</issue><fpage>519</fpage><lpage>520</lpage><pub-id pub-id-type="doi">10.1016/s0016-0032(23)90506-5</pub-id></element-citation></ref><ref id="R222"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheean</surname></name><etal/></person-group><article-title>基因的改变NIH Public Access</article-title><source>Bone</source><year>2013</year><volume>23</volume><issue>1</issue><fpage>1</fpage><lpage>7</lpage><comment>2008</comment><pub-id pub-id-type="doi">10.1038/jid.2014.371</pub-id></element-citation></ref><ref id="R223"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Singh</surname><given-names>NC</given-names></name><name><surname>Theunissen</surname><given-names>FE</given-names></name></person-group><article-title>Modulation spectra of natural sounds and ethological theories of auditory processing</article-title><source>The Journal of the Acoustical Society of America</source><year>2003</year><volume>114</volume><issue>6</issue><fpage>3394</fpage><lpage>3411</lpage><pub-id pub-id-type="doi">10.1121/1.1624067</pub-id></element-citation></ref><ref id="R224"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>LB</given-names></name><name><surname>Thelen</surname><given-names>E</given-names></name></person-group><article-title>Development as a dynamic system</article-title><source>Trends in Cognitive Sciences</source><year>2003</year><volume>7</volume><issue>8</issue><fpage>343</fpage><lpage>348</lpage><pub-id pub-id-type="doi">10.1016/S1364-6613(03)00156-6</pub-id></element-citation></ref><ref id="R225"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>LB</given-names></name><name><surname>Jayaraman</surname><given-names>S</given-names></name><name><surname>Clerkin</surname><given-names>E</given-names></name><name><surname>Yu</surname><given-names>C</given-names></name></person-group><article-title>The Developing Infant Creates a Curriculum for Statistical Learning</article-title><source>Trends in Cognitive Sciences</source><year>2018</year><volume>22</volume><issue>4</issue><fpage>325</fpage><lpage>336</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2018.02.004</pub-id></element-citation></ref><ref id="R226"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>NA</given-names></name><name><surname>Trainor</surname><given-names>LJ</given-names></name></person-group><article-title>Infant-directed speech is modulated by infant feedback</article-title><source>Infancy</source><year>2008</year><volume>13</volume><issue>4</issue><fpage>410</fpage><lpage>420</lpage><pub-id pub-id-type="doi">10.1080/15250000802188719</pub-id></element-citation></ref><ref id="R227"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stapells</surname><given-names>DR</given-names></name><name><surname>Galambos</surname><given-names>R</given-names></name><name><surname>Costello</surname><given-names>JA</given-names></name><name><surname>Makeig</surname><given-names>S</given-names></name></person-group><article-title>Inconsistency of auditory middle latency and steady-state responses in infants 1 David R. Stapells, Robert Galambos Jamie A. Costello and Scott Makeig</article-title><source>Electroencephalography and Clinical Neurophysiology</source><year>1988</year><volume>71</volume><fpage>289</fpage><lpage>295</lpage></element-citation></ref><ref id="R228"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stefanics</surname><given-names>G</given-names></name><name><surname>Haden</surname><given-names>G</given-names></name><name><surname>Huotilainen</surname><given-names>M</given-names></name><name><surname>Balazs</surname><given-names>L</given-names></name><name><surname>Sziller</surname><given-names>I</given-names></name><name><surname>Beke</surname><given-names>A</given-names></name><name><surname>Fellman</surname><given-names>V</given-names></name><name><surname>Winkler</surname><given-names>I</given-names></name></person-group><article-title>Auditory temporal grouping in newborn infants</article-title><source>Psychophysiology</source><year>2007</year><volume>44</volume><fpage>697</fpage><lpage>702</lpage></element-citation></ref><ref id="R229"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stenberg</surname><given-names>G</given-names></name></person-group><article-title>Do 12-month-old infants trust a competent adult?</article-title><source>Infancy</source><year>2013</year><volume>18</volume><issue>5</issue><fpage>873</fpage><lpage>904</lpage><pub-id pub-id-type="doi">10.1111/infa.12011</pub-id></element-citation></ref><ref id="R230"><element-citation publication-type="other"><collab>Study A E E G</collab><source>brain sciences Dynamic Causal Modelling of the Reduced Habituation to Painful Stimuli in Migraine</source><year>2020</year></element-citation></ref><ref id="R231"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suanda</surname><given-names>SH</given-names></name><name><surname>Smith</surname><given-names>LB</given-names></name><name><surname>Yu</surname><given-names>C</given-names></name></person-group><article-title>The Multisensory Nature of Verbal Discourse in Parent – Toddler Interactions The Multisensory Nature of Verbal Discourse in Parent – Toddler</article-title><source>Developmental Neuropsychology</source><year>2017</year><volume>41</volume><issue>5–8</issue><fpage>324</fpage><lpage>341</lpage><pub-id pub-id-type="doi">10.1080/87565641.2016.1256403</pub-id></element-citation></ref><ref id="R232"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tallon-Baudry</surname><given-names>C</given-names></name><name><surname>Bertrand</surname><given-names>O</given-names></name><name><surname>Delpuech</surname><given-names>C</given-names></name><name><surname>Pernier</surname><given-names>J</given-names></name></person-group><article-title>Stimulus specificity of phase-locked and non-phase-locked 40 Hz visual responses in human</article-title><source>Journal of Neuroscience</source><year>1996</year><volume>16</volume><issue>13</issue><fpage>4240</fpage><lpage>4249</lpage><pub-id pub-id-type="doi">10.1523/jneurosci.16-13-04240.1996</pub-id></element-citation></ref><ref id="R233"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Tamis-LeMonda</surname><given-names>C</given-names></name></person-group><source>Child Psychology: A Handbook of Contemporary Issues</source><edition>2nd ed</edition><person-group person-group-type="editor"><name><surname>Balter</surname><given-names>C</given-names></name><name><surname>Tamis-LeMOnda</surname><given-names>L</given-names></name></person-group><publisher-name>Psychology Press, Taylor &amp; Francis Group</publisher-name><year>2006</year></element-citation></ref><ref id="R234"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tang</surname><given-names>J-S-Y</given-names></name><name><surname>Maidment</surname><given-names>J-A</given-names></name></person-group><article-title>Prosodic Aspects of Child-Directed Speech in Cantonese</article-title><source>Speech, Hearing and Language</source><year>1996</year><volume>9</volume><issue>1989</issue><fpage>257</fpage><lpage>276</lpage></element-citation></ref><ref id="R235"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tass</surname><given-names>P</given-names></name><name><surname>Rosenblum</surname><given-names>MG</given-names></name><name><surname>Weule</surname><given-names>J</given-names></name><name><surname>Kurths</surname><given-names>J</given-names></name><name><surname>Pikovsky</surname><given-names>A</given-names></name><name><surname>Volkmann</surname><given-names>J</given-names></name><name><surname>Schnitzler</surname><given-names>A</given-names></name><name><surname>Freund</surname><given-names>H</given-names></name></person-group><article-title>Detection of n:m Phase Locking from Noisy Data: Application to Magnetoencephalography</article-title><source>Physical Review Letters</source><year>1998</year><volume>81</volume><issue>15</issue><fpage>3291</fpage><lpage>3294</lpage><comment><ext-link ext-link-type="uri" xlink:href="https://www.google.com/search?client=firefox-b-d&amp;q=papers3%3A%2F%2Fpublication%2Fuuid%2FEE6C3B36-05D2-46A0-A8D0-6E09C3C2BF78">papers3://publication/uuid/EE6C3B36-05D2-46A0-A8D0-6E09C3C2BF78</ext-link></comment></element-citation></ref><ref id="R236"><element-citation publication-type="other"><collab>Technische Universtität München, L-M-U M</collab><source>e-conversion - Proposal for a Cluster of Excellence</source><year>2018</year><comment>#x6E08;無No Title No Title</comment></element-citation></ref><ref id="R237"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ten Oever</surname><given-names>S</given-names></name><name><surname>Schroeder</surname><given-names>CE</given-names></name><name><surname>Poeppel</surname><given-names>D</given-names></name><name><surname>Van Atteveldt</surname><given-names>N</given-names></name><name><surname>Mehta</surname><given-names>AD</given-names></name><name><surname>Mégevand</surname><given-names>P</given-names></name><name><surname>Groppe</surname><given-names>DM</given-names></name><name><surname>Zion-Golumbic</surname><given-names>E</given-names></name></person-group><article-title>Low-frequency cortical oscillations entrain to subthreshold rhythmic auditory stimuli</article-title><source>Journal of Neuroscience</source><year>2017</year><volume>37</volume><issue>19</issue><fpage>4903</fpage><lpage>4912</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3658-16.2017</pub-id></element-citation></ref><ref id="R238"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thiessen</surname><given-names>ED</given-names></name><name><surname>Hill</surname><given-names>EA</given-names></name><name><surname>Saffran</surname><given-names>JR</given-names></name></person-group><article-title>Infant-directed speech facilitates word segmentation</article-title><source>Infancy</source><year>2005</year><volume>7</volume><issue>1</issue><fpage>53</fpage><lpage>71</lpage><pub-id pub-id-type="doi">10.1207/s15327078in0701_5</pub-id></element-citation></ref><ref id="R239"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thut</surname><given-names>G</given-names></name><name><surname>Schyns</surname><given-names>PG</given-names></name><name><surname>Gross</surname><given-names>J</given-names></name></person-group><article-title>Entrainment of perceptually relevant brain oscillations by non-invasive rhythmic stimulation of the human brain</article-title><source>Frontiers in Psychology</source><year>2011</year><month>JUL</month><volume>2</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.3389/fpsyg.2011.00170</pub-id></element-citation></ref><ref id="R240"><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Tierney</surname><given-names>A</given-names></name><name><surname>Kraus</surname><given-names>N</given-names></name></person-group><source>nc or re ct ed Pr oo f nc or re ed Pr oo f</source><comment>(n.d.)</comment><pub-id pub-id-type="doi">10.1162/jocn</pub-id></element-citation></ref><ref id="R241"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uhlhaas</surname><given-names>PJ</given-names></name><name><surname>Roux</surname><given-names>F</given-names></name><name><surname>Rodriguez</surname><given-names>E</given-names></name><name><surname>Rotarska-Jagiela</surname><given-names>A</given-names></name><name><surname>Singer</surname><given-names>W</given-names></name></person-group><article-title>Neural synchrony and the development of cortical networks</article-title><source>Trends in Cognitive Sciences</source><year>2010</year><volume>14</volume><issue>2</issue><fpage>72</fpage><lpage>80</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2009.12.002</pub-id></element-citation></ref><ref id="R242"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vanrullen</surname><given-names>R</given-names></name></person-group><article-title>Perceptual Cycles</article-title><source>Trends in Cognitive Sciences</source><year>2016</year><volume>20</volume><issue>10</issue><fpage>723</fpage><lpage>735</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2016.07.006</pub-id></element-citation></ref><ref id="R243"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Varlet</surname><given-names>M</given-names></name><name><surname>Williams</surname><given-names>R</given-names></name><name><surname>Keller</surname><given-names>PE</given-names></name></person-group><article-title>Effects of pitch and tempo of auditory rhythms on spontaneous movement entrainment and stabilisation</article-title><source>Psychological Research</source><year>2020</year><volume>84</volume><issue>3</issue><fpage>568</fpage><lpage>584</lpage><pub-id pub-id-type="doi">10.1007/s00426-018-1074-8</pub-id></element-citation></ref><ref id="R244"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vettori</surname><given-names>S</given-names></name><name><surname>Dzhelyova</surname><given-names>M</given-names></name><name><surname>Van der Donck</surname><given-names>S</given-names></name><name><surname>Jacques</surname><given-names>C</given-names></name><name><surname>Steyaert</surname><given-names>J</given-names></name><name><surname>Rossion</surname><given-names>B</given-names></name><name><surname>Boets</surname><given-names>B</given-names></name></person-group><article-title>Frequency-Tagging Electroencephalography of Superimposed Social and Non-Social Visual Stimulation Streams Reveals Reduced Saliency of Faces in Autism Spectrum Disorder</article-title><source>Frontiers in Psychiatry</source><year>2020</year><month>April</month><volume>11</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.3389/fpsyt.2020.00332</pub-id></element-citation></ref><ref id="R245"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vettori</surname><given-names>S</given-names></name><name><surname>Dzhelyova</surname><given-names>M</given-names></name><name><surname>Van der Donck</surname><given-names>S</given-names></name><name><surname>Jacques</surname><given-names>C</given-names></name><name><surname>Steyaert</surname><given-names>J</given-names></name><name><surname>Rossion</surname><given-names>B</given-names></name><name><surname>Boets</surname><given-names>B</given-names></name></person-group><article-title>Reduced neural sensitivity to rapid individual face discrimination in autism spectrum disorder</article-title><source>NeuroImage: Clinical</source><year>2018</year><month>&gt;November</month><volume>21</volume><elocation-id>101613</elocation-id><comment>2019</comment><pub-id pub-id-type="doi">10.1016/j.nicl.2018.101613</pub-id></element-citation></ref><ref id="R246"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Von Stein</surname><given-names>A</given-names></name><name><surname>Chiang</surname><given-names>C</given-names></name><name><surname>König</surname><given-names>P</given-names></name></person-group><article-title>Top-down processing mediated by interareal synchronization</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><year>2000</year><volume>97</volume><issue>26</issue><fpage>14748</fpage><lpage>14753</lpage><pub-id pub-id-type="doi">10.1073/pnas.97.26.14748</pub-id></element-citation></ref><ref id="R247"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wallaert</surname><given-names>N</given-names></name><name><surname>Moore</surname><given-names>BCJ</given-names></name><name><surname>Lorenzi</surname><given-names>C</given-names></name></person-group><article-title>Comparing the effects of age on amplitude modulation and frequency modulation detection</article-title><source>The Journal of the Acoustical Society of America</source><year>2016</year><volume>139</volume><issue>6</issue><fpage>3088</fpage><lpage>3096</lpage><pub-id pub-id-type="doi">10.1121/1.4953019</pub-id></element-citation></ref><ref id="R248"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Ding</surname><given-names>N</given-names></name><name><surname>Ahmar</surname><given-names>N</given-names></name><name><surname>Xiang</surname><given-names>J</given-names></name><name><surname>Poeppel</surname><given-names>D</given-names></name><name><surname>Simon</surname><given-names>J</given-names></name></person-group><article-title>Sensitivity to temporal modulation rate and spectral bandwidth in the human auditory system: MEG evidence</article-title><source>Journal of Neurophysiology</source><year>2011</year><volume>107</volume><fpage>2033</fpage><lpage>2041</lpage></element-citation></ref><ref id="R249"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Lu</surname><given-names>L</given-names></name><name><surname>Zou</surname><given-names>G</given-names></name><name><surname>Zheng</surname><given-names>L</given-names></name><name><surname>Qin</surname><given-names>L</given-names></name><name><surname>Zou</surname><given-names>Q</given-names></name><name><surname>Gao</surname><given-names>JH</given-names></name></person-group><article-title>Disrupted neural tracking of sound localization during non-rapid eye movement sleep</article-title><source>NeuroImage</source><year>2022</year><month>January</month><volume>260</volume><elocation-id>119490</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2022.119490</pub-id></element-citation></ref><ref id="R250"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ward</surname><given-names>LM</given-names></name></person-group><article-title>Synchronous neural oscillations and cognitive processes</article-title><source>Trends in Cognitive Sciences</source><year>2003</year><volume>7</volume><issue>12</issue><fpage>553</fpage><lpage>559</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2003.10.012</pub-id></element-citation></ref><ref id="R251"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Warreyn</surname><given-names>P</given-names></name><name><surname>Ruysschaert</surname><given-names>L</given-names></name><name><surname>Wiersema</surname><given-names>JR</given-names></name><name><surname>Handl</surname><given-names>A</given-names></name><name><surname>Pattyn</surname><given-names>G</given-names></name><name><surname>Roeyers</surname><given-names>H</given-names></name></person-group><article-title>Infants ’ mu suppression during the observation of real and mimicked goal-directed actions</article-title><year>2013</year><volume>2</volume><fpage>173</fpage><lpage>185</lpage><pub-id pub-id-type="doi">10.1111/desc.12014</pub-id></element-citation></ref><ref id="R252"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wass</surname><given-names>SV</given-names></name><name><surname>Perapoch Amadó</surname><given-names>M</given-names></name><name><surname>Ives</surname><given-names>J</given-names></name></person-group><article-title>Oscillatory entrainment to our early social or physical environment and the emergence of volitional control</article-title><source>Developmental Cognitive Neuroscience</source><year>2021</year><month>November</month><volume>54</volume><comment>2022</comment><pub-id pub-id-type="doi">10.1016/j.dcn.2022.101102</pub-id></element-citation></ref><ref id="R253"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wass</surname><given-names>SV</given-names></name><name><surname>Clackson</surname><given-names>K</given-names></name><name><surname>Georgieva</surname><given-names>SD</given-names></name><name><surname>Brightman</surname><given-names>L</given-names></name><name><surname>Nutbrown</surname><given-names>R</given-names></name><name><surname>Leong</surname><given-names>V</given-names></name></person-group><article-title>Infants’ visual sustained attention is higher during joint play than solo play: is this due to increased endogenous attention control or exogenous stimulus capture?</article-title><source>Developmental Science</source><year>2018</year><volume>21</volume><issue>6</issue><pub-id pub-id-type="doi">10.1111/desc.12667</pub-id></element-citation></ref><ref id="R254"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wass</surname><given-names>SV</given-names></name><name><surname>Whitehorn</surname><given-names>M</given-names></name><name><surname>Marriott Haresign</surname><given-names>I</given-names></name><name><surname>Phillips</surname><given-names>E</given-names></name><name><surname>Leong</surname><given-names>V</given-names></name></person-group><article-title>Interpersonal Neural Entrainment during Early Social Interaction</article-title><source>Trends in Cognitive Sciences</source><year>2020</year><volume>24</volume><issue>4</issue><fpage>329</fpage><lpage>342</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2020.01.006</pub-id></element-citation></ref><ref id="R255"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wass</surname><given-names>SV</given-names></name><name><surname>Smith</surname><given-names>CG</given-names></name><name><surname>Clackson</surname><given-names>K</given-names></name><name><surname>Gibb</surname><given-names>C</given-names></name><name><surname>Eitzenberger</surname><given-names>J</given-names></name><name><surname>Mirza</surname><given-names>FU</given-names></name></person-group><article-title>Parents Mimic and Influence Their Infant’s Autonomic State through Dynamic Affective State Matching</article-title><source>Current Biology</source><year>2019</year><volume>29</volume><issue>14</issue><fpage>2415</fpage><lpage>2422</lpage><elocation-id>e4</elocation-id><pub-id pub-id-type="doi">10.1016/j.cub.2019.06.016</pub-id></element-citation></ref><ref id="R256"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weinstein</surname><given-names>D</given-names></name><name><surname>Launay</surname><given-names>J</given-names></name><name><surname>Pearce</surname><given-names>E</given-names></name><name><surname>Dunbar</surname><given-names>RIM</given-names></name><name><surname>Stewart</surname><given-names>L</given-names></name></person-group><article-title>Singing and social bonding: Changes in connectivity and pain threshold as a function of group size</article-title><source>Evolution and Human Behavior</source><year>2016</year><volume>37</volume><issue>2</issue><fpage>152</fpage><lpage>158</lpage><pub-id pub-id-type="doi">10.1016/j.evolhumbehav.2015.10.002</pub-id></element-citation></ref><ref id="R257"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wen</surname><given-names>X</given-names></name><name><surname>Mo</surname><given-names>J</given-names></name><name><surname>Ding</surname><given-names>M</given-names></name></person-group><article-title>Exploring resting-state functional connectivity with total interdependence</article-title><source>NeuroImage</source><year>2012</year><volume>60</volume><issue>2</issue><fpage>1587</fpage><lpage>1595</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.01.079</pub-id></element-citation></ref><ref id="R258"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Widmann</surname><given-names>A</given-names></name></person-group><source>Pop_eegfiltnew EEGLAB plugin</source><publisher-name>The Mathworks, Inc</publisher-name><year>2008</year></element-citation></ref><ref id="R259"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winkler</surname><given-names>I</given-names></name><name><surname>Kushnerenko</surname><given-names>E</given-names></name><name><surname>Hovárth</surname><given-names>J</given-names></name><name><surname>Čeponienė</surname><given-names>R</given-names></name><name><surname>Fellman</surname><given-names>V</given-names></name><name><surname>Huotilainen</surname><given-names>M</given-names></name><name><surname>Näätänen</surname><given-names>RSS</given-names></name></person-group><article-title>Newborn infants can organize the auditory world</article-title><source>PNAS</source><year>2003</year><volume>100</volume><issue>20</issue><fpage>11812</fpage><lpage>11815</lpage></element-citation></ref><ref id="R260"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winkler</surname><given-names>I</given-names></name><name><surname>Háden</surname><given-names>GP</given-names></name><name><surname>Ladinig</surname><given-names>O</given-names></name><name><surname>Sziller</surname><given-names>I</given-names></name><name><surname>Honing</surname><given-names>H</given-names></name></person-group><article-title>Newborn infants detect the beat in music</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><year>2009</year><volume>106</volume><issue>7</issue><fpage>2468</fpage><lpage>2471</lpage><pub-id pub-id-type="doi">10.1073/pnas.0809035106</pub-id></element-citation></ref><ref id="R261"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wunderlich</surname><given-names>JL</given-names></name><name><surname>Cone-Wesson</surname><given-names>BK</given-names></name></person-group><article-title>Maturation of CAEP in infants and children: A review</article-title><source>Hearing Research</source><year>2006</year><volume>212</volume><issue>1–2</issue><fpage>212</fpage><lpage>223</lpage><pub-id pub-id-type="doi">10.1016/j.heares.2005.11.008</pub-id></element-citation></ref><ref id="R262"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xie</surname><given-names>W</given-names></name><name><surname>Mallin</surname><given-names>BM</given-names></name><name><surname>Richards</surname><given-names>JE</given-names></name></person-group><article-title>Development of infant sustained attention and its relation to EEG oscillations: an EEG and cortical source analysis study</article-title><source>Developmental Science</source><year>2018</year><volume>21</volume><issue>3</issue><pub-id pub-id-type="doi">10.1111/desc.12562</pub-id></element-citation></ref><ref id="R263"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xie</surname><given-names>W</given-names></name><name><surname>Richards</surname><given-names>JE</given-names></name></person-group><article-title>The Relation between Infant Covert Orienting, Sustained Attention and Brain Activity</article-title><source>Brain Topography</source><year>2017</year><volume>30</volume><issue>2</issue><fpage>198</fpage><lpage>219</lpage><pub-id pub-id-type="doi">10.1007/s10548-016-0505-3</pub-id></element-citation></ref><ref id="R264"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>C</given-names></name><name><surname>Smith</surname><given-names>LB</given-names></name></person-group><article-title>Multiple Sensory-Motor Pathways Lead to Coordinated Visual Attention</article-title><year>2017</year><volume>41</volume><fpage>5</fpage><lpage>31</lpage><pub-id pub-id-type="doi">10.1111/cogs.12366</pub-id></element-citation></ref><ref id="R265"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>C</given-names></name><name><surname>Smith</surname><given-names>LB</given-names></name></person-group><article-title>Joint attention without gaze following: Human infants and their parents coordinate visual attention to objects through eye-hand coordination</article-title><source>PLoS ONE</source><year>2013</year><volume>8</volume><issue>11</issue><pub-id pub-id-type="doi">10.1371/journal.pone.0079659</pub-id></element-citation></ref><ref id="R266"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>H</given-names></name><name><surname>Melloni</surname><given-names>L</given-names></name><name><surname>Poeppel</surname><given-names>D</given-names></name><name><surname>Ding</surname><given-names>N</given-names></name></person-group><article-title>Interpretations of frequency domain analyses of neural entrainment: Periodicity, fundamental frequency, and harmonics</article-title><source>Frontiers in Human Neuroscience</source><year>2016</year><month>June</month><volume>10</volume><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.3389/fnhum.2016.00274</pub-id></element-citation></ref><ref id="R267"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zoefel</surname><given-names>B</given-names></name><name><surname>Heil</surname><given-names>P</given-names></name></person-group><article-title>Detection of near-threshold sounds is independent of eeg phase in common frequency bands</article-title><source>Frontiers in Psychology</source><year>2013</year><month>MAY</month><volume>4</volume><fpage>1</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.3389/fpsyg.2013.00262</pub-id></element-citation></ref><ref id="R268"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zoefel</surname><given-names>B</given-names></name><name><surname>ten Oever</surname><given-names>S</given-names></name><name><surname>Sack</surname><given-names>AT</given-names></name></person-group><article-title>The involvement of endogenous neural oscillations in the processing of rhythmic input: More than a regular repetition of evoked neural responses</article-title><source>Frontiers in Neuroscience</source><year>2018</year><month>MAR</month><volume>12</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.3389/fnins.2018.00095</pub-id></element-citation></ref><ref id="R269"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zoefel</surname><given-names>B</given-names></name><name><surname>Vanrullen</surname><given-names>R</given-names></name></person-group><article-title>The Role of High-Level Processes for Oscillatory Phase Entrainment to Speech Sound</article-title><year>2015</year><month>December</month><volume>9</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.3389/fnhum.2015.00651</pub-id></element-citation></ref></ref-list></back><floats-group><boxed-text id="BX1" position="float" orientation="portrait"><caption><title>Highlights</title></caption><list list-type="simple" id="L1"><list-item><label>-</label><p>2Hz amplitude modulation stimulation showed the strongest neural entrainment</p></list-item><list-item><label>-</label><p>We discuss power vs phase analyses of infant and adult frequency tagging responses</p></list-item><list-item><label>-</label><p>We illustrate topographic differences in adult and infant neural responses</p></list-item></list></boxed-text><fig id="F1" position="float"><label>Figure 1</label><caption><p>Examples of infant data that shows bipolar (a) and tripolar (b) phase responses to 8Hz stimuli. The large poles work to reduce the PLV value to a small response despite there being phase angles shown on the polar plots that are clearly preferred.</p></caption><graphic xlink:href="EMS158367-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><p>64 channel EEG cap using 10-20 montage, with highlighted areas relating to each region of interest chosen. Purple, Cz only; blue, Fz-FCz-Cz; orange, vertex area; green, zenith line; red, expanded zenith line.</p></caption><graphic xlink:href="EMS158367-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><p>Multiple comparisons using multcompare.m between rest, 2, 4, 6, 8, 10 and 12Hz target frequency conditions, completed with an ANOVAN for infant (left) and adult (right) participants comparing SNR of FFT results.</p></caption><graphic xlink:href="EMS158367-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><p>Multiple comparisons using multcompare.m between rest, 2, 4, 6, 8, 10 and 12Hz target frequency conditions, completed with an ANOVAN for infant (left) and adult (right) participants comparing SNR of PLV results.</p></caption><graphic xlink:href="EMS158367-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><p>SNR scores for each of the analysis types, from 1-4Hz with a frequency resolution of 0.01Hz and a 2Hz stimulation frequency. Adults showed a strong response compared to other frequencies in all analysis types. Infants showed a response for FFT and PLV analyses that was weaker than adults and showed no response at the stimulation frequency for the entropy of PLV analysis.</p></caption><graphic xlink:href="EMS158367-f005"/></fig><fig id="F6" position="float"><label>Figure 6</label><caption><p>Topoplots showing the signal to noise ratio value at 2Hz (a-d) and areas of significance (e-h) p ˃ 0.05 shown in red, p ˂ 0.05 to p ˂ 0.001 shown in various shades of blue as shown by the colour bar. Topoplots show a standard 64 channel 10-20 montage. Adult data shown on the left (a, c, e, g), infant data shown on the right (b, d, f, h), FFT data shown in plots a, b, e and f while PLV data is shown in plots c, d, g and h.</p></caption><graphic xlink:href="EMS158367-f006"/><graphic xlink:href="EMS158367-f007"/></fig><table-wrap id="T1" orientation="portrait" position="float"><label>Table 1</label><caption><title>Differences of means between conditions for infant and adult SNR of FFT, dark blue and ‡ denotes p ˂ 0.001, medium blue and † denotes p ˂ 0.01 and light blue and * denotes p ˂ 0.05</title></caption><table frame="box" rules="all"><thead><tr><th valign="top" align="center">Participant Group</th><th valign="top" align="center"/><th valign="top" align="center">Rest</th><th valign="top" align="center">2Hz</th><th valign="top" align="center">4Hz</th><th valign="top" align="center">6Hz</th><th valign="top" align="center">8Hz</th><th valign="top" align="center">10Hz</th><th valign="top" align="center">12Hz</th></tr></thead><tbody><tr><td valign="middle" align="center" rowspan="7"><bold>Infant</bold></td><td valign="middle" align="center"><bold>Rest</bold></td><td valign="middle" align="center">NaN</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.414‡</td><td valign="middle" align="center">-0.03</td><td valign="middle" align="center" style="background-color:#D9E2F3">-0.103*</td><td valign="middle" align="center">-0.096</td><td valign="middle" align="center">0.015</td><td valign="middle" align="center">-0.019</td></tr><tr><td valign="middle" align="center"><bold>2Hz</bold></td><td valign="middle" align="center" style="background-color:#2E75B5">0.414‡</td><td valign="middle" align="center">NaN</td><td valign="middle" align="center" style="background-color:#2E75B5">0.384‡</td><td valign="middle" align="center" style="background-color:#2E75B5">0.311‡</td><td valign="middle" align="center" style="background-color:#2E75B5">0.318‡</td><td valign="middle" align="center" style="background-color:#2E75B5">0.428‡</td><td valign="middle" align="center" style="background-color:#2E75B5">0.395‡</td></tr><tr><td valign="middle" align="center"><bold>4Hz</bold></td><td valign="middle" align="center">0.03</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.384‡</td><td valign="middle" align="center">NaN</td><td valign="middle" align="center">-0.073</td><td valign="middle" align="center">-0.067</td><td valign="middle" align="center">0.044</td><td valign="middle" align="center">0.011</td></tr><tr><td valign="middle" align="center"><bold>6Hz</bold></td><td valign="middle" align="center" style="background-color:#D9E2F3">0.103*</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.311‡</td><td valign="middle" align="center">0.073</td><td valign="middle" align="center">NaN</td><td valign="middle" align="center">0.007</td><td valign="middle" align="center" style="background-color:#8EAADB">0.117†</td><td valign="middle" align="center">0.084</td></tr><tr><td valign="middle" align="center"><bold>8Hz</bold></td><td valign="middle" align="center">0.096</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.318‡</td><td valign="middle" align="center">0.067</td><td valign="middle" align="center">-0.007</td><td valign="middle" align="center">NaN</td><td valign="middle" align="center" style="background-color:#8EAADB">0.111†</td><td valign="middle" align="center">0.077</td></tr><tr><td valign="middle" align="center"><bold>10Hz</bold></td><td valign="middle" align="center">-0.015</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.428‡</td><td valign="middle" align="center">-0.044</td><td valign="middle" align="center" style="background-color:#8EAADB">-0.117†</td><td valign="middle" align="center" style="background-color:#8EAADB">-0.111†</td><td valign="middle" align="center">NaN</td><td valign="middle" align="center">-0.033</td></tr><tr style="border-bottom: solid thick"><td valign="middle" align="center"><bold>12Hz</bold></td><td valign="middle" align="center">0.019</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.395‡</td><td valign="middle" align="center">-0.011</td><td valign="middle" align="center">-0.084</td><td valign="middle" align="center">-0.077</td><td valign="middle" align="center">0.033</td><td valign="middle" align="center">NaN</td></tr><tr><td valign="middle" align="center" rowspan="7"><bold>Adult</bold></td><td valign="middle" align="center"><bold>Rest</bold></td><td valign="middle" align="center">NaN</td><td valign="middle" align="center" style="background-color:#2E75B5">0.767‡</td><td valign="middle" align="center" style="background-color:#2E75B5">0.162‡</td><td valign="middle" align="center">-0.035</td><td valign="middle" align="center">0.017</td><td valign="middle" align="center" style="background-color:#2E75B5">0.166‡</td><td valign="middle" align="center">-0.014</td></tr><tr><td valign="middle" align="center"><bold>2Hz</bold></td><td valign="middle" align="center" style="background-color:#2E75B5">-0.767‡</td><td valign="middle" align="center">NaN</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.605‡</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.802‡</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.75‡</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.601‡</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.782‡</td></tr><tr><td valign="middle" align="center"><bold>4Hz</bold></td><td valign="middle" align="center" style="background-color:#2E75B5">-0.162‡</td><td valign="middle" align="center" style="background-color:#2E75B5">0.605‡</td><td valign="middle" align="center">NaN</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.197‡</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.145‡</td><td valign="middle" align="center">0.004</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.176‡</td></tr><tr><td valign="middle" align="center"><bold>6Hz</bold></td><td valign="middle" align="center">0.035</td><td valign="middle" align="center" style="background-color:#2E75B5">0.802‡</td><td valign="middle" align="center" style="background-color:#2E75B5">0.197‡</td><td valign="middle" align="center">NaN</td><td valign="middle" align="center">0.052</td><td valign="middle" align="center" style="background-color:#2E75B5">0.201‡</td><td valign="middle" align="center">0.021</td></tr><tr><td valign="middle" align="center"><bold>8Hz</bold></td><td valign="middle" align="center">-0.017</td><td valign="middle" align="center" style="background-color:#2E75B5">0.75‡</td><td valign="middle" align="center" style="background-color:#2E75B5">0.145‡</td><td valign="middle" align="center">-0.052</td><td valign="middle" align="center">NaN</td><td valign="middle" align="center" style="background-color:#2E75B5">0.149‡</td><td valign="middle" align="center">-0.031</td></tr><tr><td valign="middle" align="center"><bold>10Hz</bold></td><td valign="middle" align="center" style="background-color:#2E75B5">-0.166‡</td><td valign="middle" align="center" style="background-color:#2E75B5">0.601‡</td><td valign="middle" align="center">-0.004</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.201‡</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.149‡</td><td valign="middle" align="center">NaN</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.181‡</td></tr><tr><td valign="middle" align="center"><bold>12Hz</bold></td><td valign="middle" align="center">0.014</td><td valign="middle" align="center" style="background-color:#2E75B5">0.782‡</td><td valign="middle" align="center" style="background-color:#2E75B5">0.176‡</td><td valign="middle" align="center">-0.021</td><td valign="middle" align="center">0.031</td><td valign="middle" align="center" style="background-color:#2E75B5">0.181‡</td><td valign="middle" align="center">NaN</td></tr></tbody></table></table-wrap><table-wrap id="T2" orientation="portrait" position="float"><label>Table 2</label><caption><title>Differences of means between the rest, 2, 4, 6, 8, 0 and 12Hz conditions for infant SNR of PLV dark blue and ‡ denotes p ˂ 0.001, medium blue and † denotes p ˂ 0.01 and light blue and * denotes p ˂ 0.05.</title></caption><table frame="box" rules="all"><thead><tr><th valign="top" align="center">Participant Group</th><th valign="top" align="center"/><th valign="top" align="center">Rest</th><th valign="top" align="center">2Hz</th><th valign="top" align="center">4Hz</th><th valign="top" align="center">6Hz</th><th valign="top" align="center">8Hz</th><th valign="top" align="center">10Hz</th><th valign="top" align="center">12Hz</th></tr></thead><tbody><tr><td valign="middle" align="center" rowspan="7"><bold>Infant</bold></td><td valign="middle" align="center"><bold>Rest</bold></td><td valign="middle" align="center">NaN</td><td valign="middle" align="center" style="background-color:#2E75B5">0.397‡</td><td valign="middle" align="center">0.089</td><td valign="middle" align="center">0.052</td><td valign="middle" align="center" style="background-color:#8EAADB">0.107†</td><td valign="middle" align="center">0.027</td><td valign="middle" align="center">-0.01</td></tr><tr><td valign="middle" align="center"><bold>2Hz</bold></td><td valign="middle" align="center" style="background-color:#2E75B5">-0.397‡</td><td valign="middle" align="center">NaN</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.308‡</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.345‡</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.291‡</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.37‡</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.408‡</td></tr><tr><td valign="middle" align="center"><bold>4Hz</bold></td><td valign="middle" align="center">-0.089</td><td valign="middle" align="center" style="background-color:#2E75B5">0.308‡</td><td valign="middle" align="center">NaN</td><td valign="middle" align="center">-0.037</td><td valign="middle" align="center">0.017</td><td valign="middle" align="center">-0.062</td><td valign="middle" align="center" style="background-color:#D9E2F3">-0.099*</td></tr><tr><td valign="middle" align="center"><bold>6Hz</bold></td><td valign="middle" align="center">-0.052</td><td valign="middle" align="center" style="background-color:#2E75B5">0.345‡</td><td valign="middle" align="center">0.037</td><td valign="middle" align="center">NaN</td><td valign="middle" align="center">0.054</td><td valign="middle" align="center">-0.025</td><td valign="middle" align="center">-0.063</td></tr><tr><td valign="middle" align="center"><bold>8Hz</bold></td><td valign="middle" align="center" style="background-color:#8EAADB">-0.107†</td><td valign="middle" align="center" style="background-color:#2E75B5">0.291‡</td><td valign="middle" align="center">-0.017</td><td valign="middle" align="center">-0.054</td><td valign="middle" align="center">NaN</td><td valign="middle" align="center">-0.079</td><td valign="middle" align="center" style="background-color:#8EAADB">-0.117†</td></tr><tr><td valign="middle" align="center"><bold>10Hz</bold></td><td valign="middle" align="center">-0.027</td><td valign="middle" align="center" style="background-color:#2E75B5">0.37‡</td><td valign="middle" align="center">0.062</td><td valign="middle" align="center">0.025</td><td valign="middle" align="center">0.079</td><td valign="middle" align="center">NaN</td><td valign="middle" align="center">-0.037</td></tr><tr><td valign="middle" align="center"><bold>12Hz</bold></td><td valign="middle" align="center">0.01</td><td valign="middle" align="center" style="background-color:#2E75B5">0.408‡</td><td valign="middle" align="center" style="background-color:#D9E2F3">0.099*</td><td valign="middle" align="center">0.063</td><td valign="middle" align="center" style="background-color:#2E75B5">0.117‡</td><td valign="middle" align="center">0.037</td><td valign="middle" align="center">NaN</td></tr><tr style="border-top: solid thick"><td valign="middle" align="center" rowspan="7"><bold>Adult</bold></td><td valign="middle" align="center">Rest</td><td valign="middle" align="center">NaN</td><td valign="middle" align="center" style="background-color:#2E75B5">0.768‡</td><td valign="middle" align="center" style="background-color:#D9E2F3">0.113*</td><td valign="middle" align="center">-0.04</td><td valign="middle" align="center">0.043</td><td valign="middle" align="center" style="background-color:#2E75B5">0.215‡</td><td valign="middle" align="center">-0.006</td></tr><tr><td valign="middle" align="center">2Hz</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.768‡</td><td valign="middle" align="center">NaN</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.655‡</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.808‡</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.725‡</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.553‡</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.774‡</td></tr><tr><td valign="middle" align="center">4Hz</td><td valign="middle" align="center" style="background-color:#D9E2F3">-0.113*</td><td valign="middle" align="center" style="background-color:#2E75B5">0.655‡</td><td valign="middle" align="center">NaN</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.152‡</td><td valign="middle" align="center">-0.07</td><td valign="middle" align="center">0.102</td><td valign="middle" align="center" style="background-color:#8EAADB">-0.119†</td></tr><tr><td valign="middle" align="center">6Hz</td><td valign="middle" align="center">0.04</td><td valign="middle" align="center" style="background-color:#2E75B5">0.808‡</td><td valign="middle" align="center" style="background-color:#2E75B5">0.152‡</td><td valign="middle" align="center">NaN</td><td valign="middle" align="center" style="background-color:#D9E2F3">0.082*</td><td valign="middle" align="center" style="background-color:#2E75B5">0.255‡</td><td valign="middle" align="center">0.033</td></tr><tr><td valign="middle" align="center">8Hz</td><td valign="middle" align="center">-0.043</td><td valign="middle" align="center" style="background-color:#2E75B5">0.725‡</td><td valign="middle" align="center">0.07</td><td valign="middle" align="center" style="background-color:#D9E2F3">-0.082*</td><td valign="middle" align="center">NaN</td><td valign="middle" align="center" style="background-color:#2E75B5">0.172‡</td><td valign="middle" align="center">-0.049</td></tr><tr><td valign="middle" align="center">10Hz</td><td valign="middle" align="center">-0.215</td><td valign="middle" align="center" style="background-color:#2E75B5">0.553‡</td><td valign="middle" align="center">-0.102</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.255‡</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.172‡</td><td valign="middle" align="center">NaN</td><td valign="middle" align="center" style="background-color:#2E75B5">-0.221‡</td></tr><tr><td valign="middle" align="center">12Hz</td><td valign="middle" align="center">0.006</td><td valign="middle" align="center" style="background-color:#2E75B5">0.774‡</td><td valign="middle" align="center" style="background-color:#8EAADB">0.119†</td><td valign="middle" align="center">-0.033</td><td valign="middle" align="center">0.049</td><td valign="middle" align="center" style="background-color:#2E75B5">0.221‡</td><td valign="middle" align="center">NaN</td></tr></tbody></table></table-wrap><table-wrap id="T3" orientation="portrait" position="float"><label>Table 3</label><caption><title>Mean SNR values at the stimulation frequency of 2Hz for infant and adult participant groups for each analysis type (FFT, PLV, entropy of PLV). dark blue and † denotes p ˂ 0.01.</title></caption><table frame="box" rules="all"><thead><tr><th valign="top" align="center"/><th valign="top" align="center">Infant</th><th valign="top" align="center">Adult</th></tr></thead><tbody><tr><td valign="top" align="center"><bold>FFT</bold></td><td valign="top" align="center" style="background-color:#2E75B5">1.369†</td><td valign="top" align="center" style="background-color:#2E75B5">1.749†</td></tr><tr><td valign="top" align="center"><bold>PLV</bold></td><td valign="top" align="center" style="background-color:#2E75B5">1.358†</td><td valign="top" align="center" style="background-color:#2E75B5">1.741†</td></tr><tr><td valign="top" align="center"><bold>Entropy</bold></td><td valign="top" align="center">1</td><td valign="top" align="center" style="background-color:#2E75B5">1.00011†</td></tr></tbody></table></table-wrap><table-wrap id="T4" orientation="portrait" position="float"><label>Table 4</label><caption><title>Mean SNR values per participant (both infant or adult) for each analysis type (FFT, PLV, entropy of PLV), black shading indicates datasets that were not present due to technical error or poor data quality, medium blue and † denotes p ˂ 0.01 and light blue and * denotes p ˂ 0.05</title></caption><table frame="box" rules="all"><thead><tr><th valign="middle" align="center"/><th valign="middle" align="center" colspan="3">Infant</th><th valign="middle" align="center" colspan="3">Adult</th></tr><tr><th valign="middle" align="center"/><th valign="middle" align="center">FFT</th><th valign="middle" align="center">PLV</th><th valign="middle" align="center">Entropy</th><th valign="middle" align="center">FFT</th><th valign="middle" align="center">PLV</th><th valign="middle" align="center">Entropy</th></tr></thead><tbody><tr><td valign="middle" align="center"><bold>1042</bold></td><td valign="middle" align="center">1.196</td><td valign="middle" align="center">1.286</td><td valign="middle" align="center">1</td><td valign="middle" align="center" style="background-color:#D9E2F3">2.267*</td><td valign="middle" align="center" style="background-color:#8EAADB">2.299†</td><td valign="middle" align="center" style="background-color:#8EAADB">1.0001†</td></tr><tr><td valign="middle" align="center"><bold>1051</bold></td><td valign="middle" align="center">1.529</td><td valign="middle" align="center" style="background-color:#8EAADB">1.834†</td><td valign="middle" align="center">0.99994</td><td valign="middle" align="center" style="background-color:#D9E2F3">1.305*</td><td valign="middle" align="center">1.122</td><td valign="middle" align="center">1.0001</td></tr><tr><td valign="middle" align="center"><bold>1052</bold></td><td valign="middle" align="center">1.323</td><td valign="middle" align="center" style="background-color:#D9E2F3">1.508*</td><td valign="middle" align="center">1.0001</td><td valign="middle" align="center" style="background-color:#000000" colspan="3"/></tr><tr><td valign="middle" align="center"><bold>1053</bold></td><td valign="middle" align="center">0.932</td><td valign="middle" align="center">0.788</td><td valign="middle" align="center">0.99989</td><td valign="middle" align="center" style="background-color:#D9E2F3">1.671*</td><td valign="middle" align="center" style="background-color:#8EAADB">1.592†</td><td valign="middle" align="center">1.0001*</td></tr><tr><td valign="middle" align="center"><bold>1055</bold></td><td valign="middle" align="center" style="background-color:#000000" colspan="3" rowspan="3"/><td valign="middle" align="center" style="background-color:#8EAADB">1.847†</td><td valign="middle" align="center" style="background-color:#8EAADB">1.806†</td><td valign="middle" align="center">1.0001</td></tr><tr><td valign="middle" align="center"><bold>1059</bold></td><td valign="middle" align="center">1.301</td><td valign="middle" align="center">1.22</td><td valign="middle" align="center">1</td></tr><tr><td valign="middle" align="center"><bold>1061</bold></td><td valign="middle" align="center" style="background-color:#8EAADB">1.804†</td><td valign="middle" align="center" style="background-color:#8EAADB">1.648†</td><td valign="middle" align="center" style="background-color:#8EAADB">1.0002†</td></tr><tr><td valign="middle" align="center"><bold>1062</bold></td><td valign="middle" align="center">1.271</td><td valign="middle" align="center">0.999</td><td valign="middle" align="center">0.99993</td><td valign="middle" align="center" style="background-color:#000000" colspan="3"/></tr><tr><td valign="middle" align="center"><bold>1068</bold></td><td valign="middle" align="center" style="background-color:#000000" colspan="3"/><td valign="middle" align="center" style="background-color:#8EAADB">2.006†</td><td valign="middle" align="center" style="background-color:#8EAADB">2.503†</td><td valign="middle" align="center" style="background-color:#8EAADB">1.0002†</td></tr><tr><td valign="middle" align="center"><bold>1079</bold></td><td valign="middle" align="center" style="background-color:#8EAADB">2.058†</td><td valign="middle" align="center" style="background-color:#8EAADB">1.89†</td><td valign="middle" align="center" style="background-color:#D9E2F3">1.0002*</td><td valign="middle" align="center" style="background-color:#000000" colspan="3" rowspan="3"/></tr><tr><td valign="middle" align="center"><bold>1082</bold></td><td valign="middle" align="center">1.096</td><td valign="middle" align="center">1.011</td><td valign="middle" align="center">0.99993</td></tr><tr><td valign="middle" align="center"><bold>1084</bold></td><td valign="middle" align="center" style="background-color:#D9E2F3">1.548*</td><td valign="middle" align="center" style="background-color:#8EAADB">1.545†</td><td valign="middle" align="center">1.0001</td></tr></tbody></table></table-wrap><table-wrap id="T5" orientation="portrait" position="float"><label>Table 5</label><caption><title>Averaged SNR value at the 2Hz stimulation frequency split by participant group, analysis and time window. † denotes p ˂ 0.01 and * denotes p ˂ 0.05.</title></caption><table frame="box" rules="all"><thead><tr><th valign="middle" align="center">Participant group</th><th valign="middle" align="center">Analysis</th><th valign="middle" align="center">Time window</th><th valign="middle" align="center" colspan="8">Test values</th></tr></thead><tbody><tr><td valign="middle" align="center" rowspan="8"><bold>Infant</bold></td><td valign="middle" align="center" rowspan="4"><bold>FFT</bold></td><td valign="middle" align="center"><bold>4 minutes</bold></td><td valign="middle" align="center" style="background-color:#8EAADB" colspan="8">1.369†</td></tr><tr><td valign="middle" align="center"><bold>2 minutes</bold></td><td valign="middle" align="center" style="background-color:#D9E2F3" colspan="4">1.213*</td><td valign="middle" align="center" style="background-color:#8EAADB" colspan="4">1.265†</td></tr><tr><td valign="middle" align="center"><bold>1 minute</bold></td><td valign="middle" align="center" style="background-color:#D9E2F3" colspan="2">1.214*</td><td valign="middle" align="center" style="background-color:#D9E2F3" colspan="2">1.180*</td><td valign="middle" align="center" style="background-color:#D9E2F3" colspan="2">1.184*</td><td valign="middle" align="center" colspan="2">1.034</td></tr><tr><td valign="middle" align="center"><bold>30 seconds</bold></td><td valign="middle" align="center" style="background-color:#D9E2F3">1.164*</td><td valign="middle" align="center">0.988</td><td valign="middle" align="center">1.052</td><td valign="middle" align="center" style="background-color:#D9E2F3">1.194*</td><td valign="middle" align="center">1.050</td><td valign="middle" align="center">1.116</td><td valign="middle" align="center">1.089</td><td valign="middle" align="center">1.016</td></tr><tr style="border-top: solid thick"><td valign="middle" align="center" rowspan="4"><bold>PLV</bold></td><td valign="middle" align="center"><bold>4 minutes</bold></td><td valign="middle" align="center" style="background-color:#8EAADB" colspan="8">1.358†</td></tr><tr><td valign="middle" align="center"><bold>2 minutes</bold></td><td valign="middle" align="center" style="background-color:#D9E2F3" colspan="4">1.251*</td><td valign="middle" align="center" style="background-color:#8EAADB" colspan="4">1.197†</td></tr><tr><td valign="middle" align="center"><bold>1 minute</bold></td><td valign="middle" align="center" style="background-color:#8EAADB" colspan="2">1.218†</td><td valign="middle" align="center" style="background-color:#D9E2F3" colspan="2">1.168*</td><td valign="middle" align="center" style="background-color:#D9E2F3" colspan="2">1.156*</td><td valign="middle" align="center" style="background-color:#D9E2F3" colspan="2">1.033*</td></tr><tr style="border-bottom: solid thick"><td valign="middle" align="center"><bold>30 seconds</bold></td><td valign="middle" align="center" style="background-color:#D9E2F3">1.161*</td><td valign="middle" align="center">0.998</td><td valign="middle" align="center">1.048</td><td valign="middle" align="center">1.138</td><td valign="middle" align="center">1.059</td><td valign="middle" align="center" style="background-color:#D9E2F3">1.143*</td><td valign="middle" align="center">1.055</td><td valign="middle" align="center">0.993</td></tr><tr><td valign="middle" align="center" rowspan="8"><bold>Adult</bold></td><td valign="middle" align="center" rowspan="4"><bold>FFT</bold></td><td valign="middle" align="center"><bold>4 minutes</bold></td><td valign="middle" align="center" style="background-color:#8EAADB" colspan="8">1.743†</td></tr><tr><td valign="middle" align="center"><bold>2 minutes</bold></td><td valign="middle" align="center" style="background-color:#8EAADB" colspan="4">1.358†</td><td valign="middle" align="center" style="background-color:#8EAADB" colspan="4">1.421†</td></tr><tr><td valign="middle" align="center"><bold>1 minute</bold></td><td valign="middle" align="center" colspan="2" style="background-color:#D9E2F3; border-top: hidden">1.208*</td><td valign="middle" align="center" colspan="2" style="background-color:#8EAADB; border-top: hidden">1.276†</td><td valign="middle" align="center" colspan="2" style="background-color:#8EAADB; border-top: hidden">1.388†</td><td valign="middle" align="center" colspan="2" style="background-color:#D9E2F3; border-top: hidden">1.216*</td></tr><tr style="border-bottom: solid thick"><td valign="middle" align="center"><bold>30 seconds</bold></td><td valign="middle" align="center">1.038</td><td valign="middle" align="center">1.072</td><td valign="middle" align="center">0.994</td><td valign="middle" align="center">1.243</td><td valign="middle" align="center" style="background-color:#8EAADB; border-top: hidden">1.410†</td><td valign="middle" align="center" style="background-color:#D9E2F3; border-top: hidden">1.168*</td><td valign="middle" align="center" style="background-color:#D9E2F3; border-top: hidden">1.194*</td><td valign="middle" align="center">1.108</td></tr><tr><td valign="middle" align="center" rowspan="4"><bold>PLV</bold></td><td valign="middle" align="center"><bold>4 minutes</bold></td><td valign="middle" align="center" style="background-color:#8EAADB; border-bottom: solid thin" colspan="8">1.742†</td></tr><tr><td valign="middle" align="center"><bold>2 minutes</bold></td><td valign="middle" align="center" colspan="4" style="background-color:#8EAADB; border-top: hidden">1.381†</td><td valign="middle" align="center" colspan="4" style="background-color:#8EAADB; border-top: hidden">1.469†</td></tr><tr><td valign="middle" align="center"><bold>1 minute</bold></td><td valign="middle" align="center" colspan="2" style="background-color:#8EAADB; border-top: hidden">1.219†</td><td valign="middle" align="center" colspan="2" style="background-color:#8EAADB; border-top: hidden">1.266†</td><td valign="middle" align="center" colspan="2" style="background-color:#8EAADB; border-top: hidden">1.389†</td><td valign="middle" align="center" colspan="2" style="background-color:#D9E2F3; border-top: hidden">1.195*</td></tr><tr><td valign="middle" align="center"><bold>30 seconds</bold></td><td valign="middle" align="center">1.020</td><td valign="middle" align="center">1.075</td><td valign="middle" align="center">1.006</td><td valign="middle" align="center" style="background-color:#8EAADB">1.198†</td><td valign="middle" align="center" style="background-color:#8EAADB">1.211†</td><td valign="middle" align="center" style="background-color:#D9E2F3">1.205*</td><td valign="middle" align="center" style="background-color:#D9E2F3">1.147*</td><td valign="middle" align="center">1.112</td></tr></tbody></table></table-wrap><table-wrap id="T6" position="float" orientation="portrait"><label>Table 6</label><caption><title>Showing averaged SNR values at 2Hz for each region of interest per analysis and participant type. medium blue and † denotes p &lt; 0.01 and light blue and * denotes p &lt; 0.05.</title></caption><table frame="box" rules="all"><thead><tr><th align="center" valign="top"/><th align="center" valign="top" colspan="2">SNR of FFT</th><th align="center" valign="top" colspan="2">SNR of PLV</th></tr><tr><th align="center" valign="top"/><th align="center" valign="top">Infant</th><th align="center" valign="top">Adult</th><th align="center" valign="top">Infant</th><th align="center" valign="top">Adult</th></tr></thead><tbody><tr><td align="center" valign="top"><bold>All electrodes</bold>
</td><td align="center" valign="top" style="background-color:#8EAADB">1.369†</td><td align="center" valign="top" style="background-color:#8EAADB">1.749†</td><td align="center" valign="top" style="background-color:#8EAADB">1.358†</td><td align="center" valign="top" style="background-color:#8EAADB">1.741†</td></tr><tr><td align="center" valign="top"><bold>Cz only</bold></td><td align="center" valign="top">1.285</td><td align="center" valign="top" style="background-color:#8EAADB">1.671†</td><td align="center" valign="top">1.251</td><td align="center" valign="top" style="background-color:#8EAADB">1.781†</td></tr><tr><td align="center" valign="top"><bold>Fz-FCz-Cz</bold>
</td><td align="center" valign="top" style="background-color:#8EAADB">1.374†</td><td align="center" valign="top" style="background-color:#8EAADB">2.113†</td><td align="center" valign="top" style="background-color:#D9E2F3">1.365*</td><td align="center" valign="top" style="background-color:#8EAADB">2.115†</td></tr><tr><td align="center" valign="top"><bold>Zenith line</bold>
</td><td align="center" valign="top" style="background-color:#D9E2F3">1.246*</td><td align="center" valign="top" style="background-color:#8EAADB">1.815†</td><td align="center" valign="top">1.174</td><td align="center" valign="top" style="background-color:#8EAADB">1.721†</td></tr><tr><td align="center" valign="top"><bold>Expanded zenith line</bold>
</td><td align="center" valign="top" style="background-color:#D9E2F3">1.234*</td><td align="center" valign="top" style="background-color:#8EAADB">1.817†</td><td align="center" valign="top" style="background-color:#D9E2F3">1.215*</td><td align="center" valign="top" style="background-color:#8EAADB">1.797†</td></tr><tr><td align="center" valign="top"><bold>Vertex area</bold>
</td><td align="center" valign="top">1.232</td><td align="center" valign="top" style="background-color:#8EAADB">1.789†</td><td align="center" valign="top" style="background-color:#D9E2F3">1.220*</td><td align="center" valign="top" style="background-color:#8EAADB">1.818†</td></tr></tbody></table></table-wrap></floats-group></article>