<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS158899</article-id><article-id pub-id-type="doi">10.1101/2022.12.14.520410</article-id><article-id pub-id-type="archive">PPR585437</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Perceptual awareness is gradual in temporal and dichotomous in frontoparietal cortices</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Solanas</surname><given-names>Marta Poyo</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Zhan</surname><given-names>Minye</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="fn" rid="FN1">†</xref></contrib><contrib contrib-type="author"><name><surname>Gelder</surname><given-names>Beatrice de</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib></contrib-group><aff id="A1"><label>1</label>Department of Cognitive Neuroscience, Faculty of Psychology and Neuroscience, Maastricht University, Maastricht, The Netherlands</aff><aff id="A2"><label>2</label>Department of Computer Science, University College London, London, UK</aff><aff id="A3"><label>†</label>Now at Cognitive Neuroimaging Unit, CEA DRF/I2BM, INSERM, Université Paris-Sud, Université Paris-Saclay, NeuroSpin Center, France</aff><author-notes><corresp id="CR1">
<label>*</label>Address correspondence to Beatrice de Gelder, Department of Cognitive Neuroscience, Brain and Emotion Laboratory, Faculty of Psychology and Neuroscience, Maastricht University, Oxfordlaan 55, 6229 EV Maastricht, The Netherlands. Tel. +31 433881437. <email>b.degelder@maastrichtuniversity.nl</email></corresp></author-notes><pub-date pub-type="nihms-submitted"><day>23</day><month>12</month><year>2022</year></pub-date><pub-date pub-type="preprint"><day>15</day><month>12</month><year>2022</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Two major issues in consciousness research concern the measuring methods that determine perceptual unawareness and whether consciousness is a gradual or an ‘all-or-nothing’ phenomenon. This 7T fMRI study addresses both questions using a continuous flash suppression paradigm with an emotional recognition task (fear vs neutral bodies) in combination with the perceptual awareness scale. Behaviorally, recognition sensitivity increased linearly with increased stimuli awareness and was at chance level during perceptual unawareness. Threat expressions triggered a slower heart rate than neutral ones during ‘almost clear’ experience of the stimulus, indicating freezing behavior. The activity in occipital, temporal, parietal and frontal regions as well as in amygdala increased with increased stimulus awareness while the activity in early visual areas showed the opposite pattern. The relationship between temporal area activity and perceptual awareness was better characterized by a gradual model while the activity in fronto-parietal areas by a dichotomous model, suggesting different roles in conscious processing. Interestingly, no evidence of non-conscious processing was found in amygdala as well as no significant effect of emotion, in disagreement with the functions long ascribed to this subcortical structure.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">Substantial evidence has been gathered in the last decades about the role of consciousness in visual perception. Yet, the assessment of subjective perceptual awareness remains a major theoretical and methodological issue in consciousness studies. For example, previous studies have often measured participants’ perceptual experience with verbal reports after the experiment, which may not be a reliable method for measuring subjective experience during a task (<xref ref-type="bibr" rid="R83">Pessoa, Japee, Sturman, &amp; Ungerleider, 2006</xref>; <xref ref-type="bibr" rid="R119">Tsuchiya &amp; Adolphs, 2007</xref>). Other studies have adopted more rigorous approaches through trial-by-trial assessments or by adopting an objective threshold (e.g., specific stimuli contrast after psychophysical testing), but these attempts are still susceptible to methodological biases when not formally addressed. This is the case of using percent correct values to evaluate chance performance, as one might conclude that participants are unaware of the stimuli when in fact they may still be able to reliably detect them (<xref ref-type="bibr" rid="R27">Green &amp; Swets, 1966</xref>; <xref ref-type="bibr" rid="R63">Macmillan &amp; Creelman, 2004</xref>). Many authors have therefore proposed the use of signal detection theory (SDT) measures (<xref ref-type="bibr" rid="R27">Green &amp; Swets, 1966</xref>; <xref ref-type="bibr" rid="R118">Tanner &amp; Swets, 1954</xref>) to evaluate subjective perceptual awareness independently of participants’ response bias (<xref ref-type="bibr" rid="R27">Green &amp; Swets, 1966</xref>; <xref ref-type="bibr" rid="R63">Macmillan &amp; Creelman, 2004</xref>). As a consequence of the efforts made to account for these issues, many studies now report no evidence of perceptual processing without accompanying awareness in healthy participants (<xref ref-type="bibr" rid="R31">Hedger, Adams, &amp; Garner, 2015</xref>; <xref ref-type="bibr" rid="R32">Hedger, Gray, Garner, &amp; Adams, 2016</xref>; <xref ref-type="bibr" rid="R36">Hoffmann, Lipka, Mothes-Lasch, Miltner, &amp; Straube, 2012</xref>; <xref ref-type="bibr" rid="R37">Hoffmann, Mothes□Lasch, Miltner, &amp; Straube, 2015</xref>; <xref ref-type="bibr" rid="R65">Mayer, Merckelbach, de Jong, &amp; Leeuw, 1999</xref>; <xref ref-type="bibr" rid="R82">Pessoa, 2005</xref>; <xref ref-type="bibr" rid="R82">Pessoa, Japee, &amp; Ungerleider, 2005</xref>; <xref ref-type="bibr" rid="R113">Straube, Dietrich, Mothes□Lasch, Mentzel, &amp; Miltner, 2010</xref>).</p><p id="P3">Another source of controversy relates to the task employed to assess perceptual awareness. Early studies often used a dichotomous measure (i.e., yes/no, seen/unseen responses), which is now considered an inadequate approach for characterizing conscious perception. The reason is that such measure may not capture intermediate states of experience and thus may not correctly differentiate genuine forms of blindsight from residual conscious vision (<xref ref-type="bibr" rid="R66">Mazzi, Bagattini, &amp; Savazzi, 2016</xref>). This view has led to the development of finer measures of perceptual awareness, such as the perceptual awareness scale (PAS), with four different response alternatives: ‘no experience’, ‘brief glimpse’, ‘almost clear experience’ and ‘clear experience’ (<xref ref-type="bibr" rid="R93">Ramsøy &amp; Overgaard, 2004</xref>). Recent studies using PAS have reported chance performance during perceptual unawareness in objective forced-choice discrimination tasks, as well as intermediate states of perceptual awareness between unseen and completely seen reports (<xref ref-type="bibr" rid="R34">Hesselmann, Darcy, Rothkirch, &amp; Sterzer, 2018</xref>; <xref ref-type="bibr" rid="R51">Lähteenmäki, Hyönä, Koivisto, &amp; Nummenmaa, 2015</xref>; <xref ref-type="bibr" rid="R52">Lamy, Alon, Carmel, &amp; Shalev, 2015</xref>; <xref ref-type="bibr" rid="R53">Lamy, Carmel, &amp; Peremen, 2017</xref>; <xref ref-type="bibr" rid="R59">Lohse &amp; Overgaard, 2019</xref>; <xref ref-type="bibr" rid="R81">Peremen &amp; Lamy, 2014</xref>; <xref ref-type="bibr" rid="R93">Ramsøy &amp; Overgaard, 2004</xref>; Tagliabue, <xref ref-type="bibr" rid="R66">Mazzi, Bagattini, &amp; Savazzi, 2016</xref>). These findings have therefore instigated debates about non-conscious processing but also sparked theoretical discussions about whether perceptual awareness is a graded or an ‘all-or-none’ phenomenon. Despite all the research efforts trying to solve this controversy, a consensus has not yet been achieved as both views are supported by strong empirical evidence (for a review see <xref ref-type="bibr" rid="R136">Windey &amp; Cleeremans, 2015</xref>).</p><p id="P4">In the long standing debate about perception without awareness as well as in dichotomous vs. gradual discussions on consciousness, emotional stimuli have not occupied a major place. Indeed, in the dominant theories about consciousness, such as global workspace theories, higher order theories, integrated information theory or re-entry and predictive processing theories, the debates mainly concern cognitive processes (<xref ref-type="bibr" rid="R103">Seth &amp; Bayne, 2022</xref>). It is therefore an open question whether those major theories and debates on consciousness are applicable to affective stimuli. In this regard, fearful stimuli are considered a particularly strong candidate for non-conscious processing (<xref ref-type="bibr" rid="R11">de Gelder, Morris, &amp; Dolan, 2005</xref>; <xref ref-type="bibr" rid="R68">Morris, de Gelder, Weiskrantz, &amp; Dolan, 2001</xref>; <xref ref-type="bibr" rid="R127">Vieira, Wen, Oliver, &amp; Mitchell, 2017</xref>; <xref ref-type="bibr" rid="R132">Whalen et al., 1998</xref>) and appear to gain privileged access to awareness in comparison to other emotions (<xref ref-type="bibr" rid="R26">Gray, Adams, Hedger, Newton, &amp; Garner, 2013</xref>; <xref ref-type="bibr" rid="R55">Lee, Lim, Lee, &amp; Choi, 2009</xref>; <xref ref-type="bibr" rid="R73">Oliver, Mao, &amp; Mitchell, 2015</xref>; <xref ref-type="bibr" rid="R18">Stein, Seymour, Hebart, &amp; Sterzer, 2014</xref>; <xref ref-type="bibr" rid="R121">Tsuchiya, Moradi, Felsen, Yamazaki, &amp; Adolphs, 2009</xref>; <xref ref-type="bibr" rid="R141">Yang, Zald, &amp; Blake, 2007</xref>). Yet, most research on perceptual awareness and affective perception has used facial expressions. Available research on affective non-conscious processing has revealed differences between facial and bodily expressions even if they presumably represent the same emotion. For example, <xref ref-type="bibr" rid="R145">Zhan and colleagues (2015)</xref> found that angry bodies had shorter suppression times in comparison to other bodily emotions, while angry facial expressions had the longest suppression times (<xref ref-type="bibr" rid="R145">Zhan, Hortensius, &amp; de Gelder, 2015</xref>). These findings evidence the importance of extending investigations to other sources of affective information.</p><p id="P5">With regards to brain processes, a subcortical pathway involving the superior colliculus, pulvinar and amygdala has been suggested to be crucial in the non-conscious processing of emotional expressions (<xref ref-type="bibr" rid="R116">Tamietto &amp; de Gelder, 2010</xref>). Amygdala is known to have a key role in affective processing (<xref ref-type="bibr" rid="R14">Davis &amp; Whalen, 2001</xref>), while pulvinar has been involved in visual attention, saliency detection, spatial processing and top-down anticipation of visual information (<xref ref-type="bibr" rid="R98">Saalmann &amp; Kastner, 2011</xref>). In healthy participants, previous masking (<xref ref-type="bibr" rid="R69">Morris, Öhman, &amp; Dolan, 1998</xref>; <xref ref-type="bibr" rid="R132">Whalen et al., 1998</xref>) and binocular rivalry studies (<xref ref-type="bibr" rid="R78">Pasley, Mayes, &amp; Schultz, 2004</xref>; <xref ref-type="bibr" rid="R135">Williams, Morris, McGlone, Abbott, &amp; Mattingley, 2004</xref>) have reported amygdala responses to stimuli in conditions of unawareness. Yet again, evidence of amygdala involvement in non-conscious processing of affective information mainly comes from face studies using dichotomous measures. Emotional bodies have also shown to activate amygdala (<xref ref-type="bibr" rid="R29">Hadjikhani &amp; de Gelder, 2003</xref>; <xref ref-type="bibr" rid="R49">Kret, Pichon, Grèzes, &amp; de Gelder, 2011</xref>; <xref ref-type="bibr" rid="R107">Sinke, Sorger, Goebel, &amp; de Gelder, 2010</xref>; <xref ref-type="bibr" rid="R124">van de Riet, Grèzes, &amp; de Gelder, 2009</xref>), but their processing outside conscious awareness has yielded mixed results for this subcortical structure (<xref ref-type="bibr" rid="R11">de Gelder &amp; Hadjikhani, 2006</xref>; <xref ref-type="bibr" rid="R115">Tamietto et al., 2015</xref>; <xref ref-type="bibr" rid="R125">Van den Stock et al., 2011</xref>; <xref ref-type="bibr" rid="R18">Van den Stock et al., 2014</xref>; <xref ref-type="bibr" rid="R143">Zhan, Goebel, &amp; de Gelder, 2018</xref>). With regards to cortical areas, previous work has suggested a crucial role of the frontal, parietal and temporal cortex in perceptual stimulus awareness (<xref ref-type="bibr" rid="R48">Kreiman, Fried, &amp; Koch, 2002</xref>; <xref ref-type="bibr" rid="R56">Leopold &amp; Logothetis, 1996</xref>; <xref ref-type="bibr" rid="R58">Logothetis &amp; Schall, 1989</xref>; <xref ref-type="bibr" rid="R77">Panagiotaropoulos, Deco, Kapoor, &amp; Logothetis, 2012</xref>; <xref ref-type="bibr" rid="R104">Sheinberg &amp; Logothetis, 1997</xref>). However, evidence for the involvement of these areas in the non-conscious processing of affective stimuli is still limited.</p><p id="P6">It is therefore an open question whether affective signals, especially body expressions, are processed under conditions of perceptual unawareness and whether the perception of body expressions presents a gradual or a dichotomous relationship to perceptual awareness. Here, we used the CFS paradigm and ultrahigh field 7T (f)MRI scanning to investigate the processing of threat stimuli (fearful vs. neutral body expressions) in healthy participants. Body expressions were randomly presented either to the left or right visual field of participants’ non-dominant eye, while a colorful dynamic noise mask was shown to the dominant eye (<xref ref-type="fig" rid="F1">Figure 1</xref>). Participants performed a two-alternative forced-choice task (fear/neutral) followed by the rating of their visual stimulus experience with the perceptual awareness scale (<xref ref-type="bibr" rid="R93">Ramsøy &amp; Overgaard, 2004</xref>). Our experiment has several improvements over previous studies. First, we used the CFS paradigm (<xref ref-type="bibr" rid="R120">Tsuchiya &amp; Koch, 2005</xref>) to render stimuli invisible. This method has been increasingly used since it creates a stronger suppression and more stable non-conscious perception in comparison to previous methods, such as masking (<xref ref-type="bibr" rid="R140">Yang, Brascamp, Kang, &amp; Blake, 2014</xref>). Second, we measured perceptual awareness on a trial-by-trial basis and by using the perceptual awareness scale. This allowed us to differentiate genuine forms of perception without awareness from conditions of partial perceptual awareness and also allowed us to assess whether perceptual awareness is a gradual or a dichotomous phenomenon. Importantly, subjective perceptual awareness reports were also formally and objectively assessed with signal detection theory measures (<xref ref-type="bibr" rid="R27">Green &amp; Swets, 1966</xref>) and by comparing task performance to chance level. In addition, with ultra-high field magnetic resonance imaging we were able to obtain higher spatial resolution and specificity but also a higher contrast-to-noise ratio (<xref ref-type="bibr" rid="R123">Uğurbil, 2014</xref>). Finally, the use of body expressions provided a novel take on the processing of social information beyond facial expressions.</p></sec><sec id="S2" sec-type="results"><title>Results</title><sec id="S3"><title>Behavioral results</title><sec id="S4"><title>Sensitivity</title><p id="P7">The analysis of recognition sensitivity showed a significant main effect of Perceptual Awareness (F (3, 41.76) = 37.13, p &lt; .001), indicating a significantly higher sensitivity during ‘brief glimpse’ (PAS2, M = 0.38, SE = 0.08), ‘almost clear’ (PAS3, M = 1.32, SE = 0.13) and ‘clear’ (PAS4, M = 1.36, SE = 0.18) experience conditions than during ‘no experience’ (PAS1, M = -0.03, SE = 0.03). Sensitivity was also significantly lower during ‘brief glimpse’ than for ‘clear’ and ‘almost clear’ experience (see <xref ref-type="fig" rid="F2">Figure 2A</xref>). Sensitivity values differed from the chance level in PAS2 to PAS4 (p &lt; .001), but not in PAS1 (p = .352). Further analyses indicated that the relationship between perceptual sensitivity and perceptual awareness was significantly better described by a gradual model (M = 1.05, SE = 1.61) than by a dichotomous one (M = 6.61, SE = 1.13; t(16) = -3.69, p = .002).</p></sec><sec id="S5"><title>Criterion bias</title><p id="P8">The criterion bias analysis showed a significant main effect of Perceptual Awareness (F(3, 23.17) = 26.01, p &lt; .001) with more conservative emotional categorizations for ‘clear’ (M = 0.93, SE = 0.05) and ‘almost clear’ (M = 0.88, SE = 0.05) experiences than ‘no experience’ (M = 0.31, SE = 0.05) or ‘brief glimpse’ (M = 0.46, SE = 0.05) (see <xref ref-type="fig" rid="F2">Figure 2B</xref>). Criterion bias values did not differ significantly between ‘clear’ and ‘almost clear’ experiences as well as between ‘no experience’ and ‘brief glimpse’. Criterion bias scores were different from zero at all levels of the perceptual awareness scale (p &lt; .001).</p></sec><sec id="S6"><title>Reaction times</title><p id="P9">The analysis of RTs of the emotional categorization task (four levels: hit, miss, false alarm and correct rejection) did not show differences between different response types (F(3, 27.62) = 0.78, p = .513) (see <xref ref-type="supplementary-material" rid="SD1">Table S1</xref> in <xref ref-type="supplementary-material" rid="SD1">Supplementary Information</xref>). The analysis of the RTs of the perceptual awareness ratings (four levels: PAS 1-4) showed a main effect of Perceptual Awareness (F (3, 21.77) = 5.29, p = .007), indicating significant faster responses for ‘no experience’ (M = 0.48, SE = 0.04) than for ‘brief glimpse’ (M = 0.56, SE = 0.04) and marginally faster than for ‘clear’ ratings (M = 0.58, SE = 0.04) (see <xref ref-type="supplementary-material" rid="SD1">Table S1</xref> in <xref ref-type="supplementary-material" rid="SD1">Supplementary Information</xref>). For an overview of the proportion of responses by Signal Detection Theory measure and Perceptual Awareness Scale rating, see <xref ref-type="supplementary-material" rid="SD1">Table S2 in Supplementary Information</xref>.</p></sec></sec><sec id="S7"><title>Brain results</title><sec id="S8"><title>Regions sensitive to perceptual awareness</title><p id="P10">A group ANOVA with within-subjects factor Perceptual Awareness (i.e., PAS1-4) was performed to localize the areas sensitive to different degrees of perceptual awareness. ROIs showing a main effect of perceptual awareness were found bilaterally in the lateral occipito-temporal cortex (LOTC), fusiform gyrus, inferior temporal gyrus (ITG) as well as in right amygdala and left precuneus, occipital cortex, intraparietal sulcus (IPS), inferior frontal cortex (IFC), superior temporal gyrus (STG) and posterior superior temporal sulcus (pSTS) (see <xref ref-type="fig" rid="F3">Figure 3</xref>; see <xref ref-type="supplementary-material" rid="SD1">Supplementary Table S3</xref> for more details on ROI location, size and statistical values).</p></sec><sec id="S9"><title>Effect of emotion and perceptual awareness on PAS-sensitive ROI activity</title><p id="P11">To further understand their involvement in perceptual awareness, the beta values of these ROIs were then analyzed with a linear mixed-model analysis with within-subject factors Emotion (two levels: Neutral &amp; fear) and Perceptual Awareness (four levels: PAS1-4). All the ROIs showed a significant main effect of PAS but no significant main effect of Emotion or interaction effect (<xref ref-type="table" rid="T1">Table 1</xref>; see <xref ref-type="supplementary-material" rid="SD1">Supplementary Table S4</xref> for further statistical details; see <xref ref-type="fig" rid="F4">Figure 4</xref> for ROI activity visualization). Subsequently, different pairwise comparisons were performed to understand differences in activity levels between non-conscious and conscious perception (PAS1 vs PAS4; PAS1 vs PAS3), between non-conscious and threshold vision (PAS1 vs PAS2), between threshold and clearer degrees of conscious perception (PAS2 vs PAS4; PAS2 vs PAS3) and to assess whether there was a difference between levels of conscious perceptual awareness (PAS3 vs PSA4) in the different ROIs.</p><p id="P12">Significantly higher activity for PAS4 than PAS1 was observed in all ROIs with the exception of the left superior occipital gyrus (SOG), left STG and two areas in the left fourth occipital gyrus (see <xref ref-type="table" rid="T1">Table 1</xref>). Overall, similar results were observed for the PAS3 and PAS1 comparison. The ROIs in the left fourth occipital gyrus, left STG and SOG showed the opposite pattern, with higher activity for PAS1 than PAS3 and PAS4 (<xref ref-type="fig" rid="F4">Figure 4</xref>), although only significantly for the former two ROIs (<xref ref-type="table" rid="T1">Table 1</xref>). Significantly higher activity for PAS4 in comparison to PAS2 was found in bilateral LOTC and ITG, right amygdala and left pSTS, although not surviving multiple comparisons correction. Pairwise comparisons revealed that the activity for PAS3 and PAS4 conditions was not significantly different in any of the defined ROIs. Most of the ROIs showed a significantly different activity level between PAS2 and PAS1 conditions, except the bilateral ITG, left IPS and the left LOTC.</p><p id="P13">Overall, most of the defined ROIs showed an activity level significantly different from zero across the eight Emotion*Perceptual Awareness conditions (<xref ref-type="table" rid="T1">Table 1</xref>; see <xref ref-type="supplementary-material" rid="SD1">Supplementary Table S5</xref> for further statistical details; see <xref ref-type="fig" rid="F4">Figure 4</xref> for ROI activity visualization). An exception was found in the right amygdala and bilateral ITG, where the activity level was not significantly different from zero at PAS1 for both emotions, and at PAS2 for fear. In addition, the activity in the left precuneus did not differ from zero at PAS1 for fearful body expressions. The activity in the left STG did not differ from zero at any of the Emotion*Perceptual Awareness conditions.</p><p id="P14">To further investigate whether perceptual awareness is a gradual or a dichotomous phenomenon, two linear mixed models corresponding to each phenomenon were fit to the data. The activity pattern in the right LOTC was significantly better described by a gradual model, regardless of the emotion of the stimuli (<xref ref-type="table" rid="T1">Table 1</xref>; see <xref ref-type="supplementary-material" rid="SD1">Supplementary Table S6</xref> for further statistical details; see <xref ref-type="supplementary-material" rid="SD1">Supplementary Table S7</xref> for results on model slope and intercept comparisons). The responses in the left medial IPS and IFC were significantly best described by a dichotomous model, also with no differences across emotions. Yet, emotion specificity was found in some areas. The activity pattern in the SOG was different for the neutral and fearful body expressions across all PAS levels (i.e., significant interaction effect). For neutral bodies, SOG activity was significantly best described by a gradual model while in the case of fearful bodies, the activity was better represented by a dichotomous model, although it did not reach significance in the latter case. The responses of the left anterior IPS also showed an Emotion*Perceptual Awareness interaction effect, with the activity elicited by neutral bodies better described by a dichotomous model while a gradual model better described the activity elicited by fearful body expressions. However, pairwise comparisons were not significant in both cases. The rest of the ROIs did not show a significant preference for either of the models.</p></sec><sec id="S10"><title>Effect of emotion and perceptual awareness in anatomically defined amygdala and pulvinar</title><p id="P15">The analysis of amygdala betas yielded a significant main effect of Perceptual Awareness (F(3, 14.39) = 8.60, p = .002), showing that amygdala activity was significantly lower during ‘no experience’ (M = 0.08, SE = 0.09) than during ‘brief glimpse’ (M = 0.31, SE = 0.06), ‘almost clear’ (M = 0.40, SE = 0.07) and ‘clear experience’ (M = 0.58, SE = 0.13) (see <xref ref-type="fig" rid="F4">Figure 4</xref>). This analysis also yielded a significant main effect of Emotion (F(1, 13.23) = 6.67, p = .023), indicating a higher amygdala activity for neutral (M = 0.38, SE = 0.07) than fearful body expressions (M = 0.30, SE = 0.07). One-sample t-tests revealed that amygdala activity differed from baseline at PAS2 to PAS4 (p &lt; .001) but not at PAS1 (i.e., ‘no experience’), for both emotions. Amygdala activity did not show a significant preference for either the gradual or the dichotomous model.</p><p id="P16">The analysis of the activity in pulvinar did not show significant main effects for Emotion or Perceptual Awareness nor a significant Emotion*Perceptual Awareness interaction (see <xref ref-type="fig" rid="F4">Figure 4</xref>). However, pulvinar responses were significantly different from zero in all PAS levels for both emotions (p &lt; .005). As for the amygdala, pulvinar did not show a significant preference for either the gradual or the dichotomous model.</p></sec></sec><sec id="S11"><title>Heart rate</title><p id="P17">The analysis of heart rate responses yielded a marginal significant effect of Perceptual Awareness (F(3, 106.30) = 2.68, p = .051) and a significant Emotion*Perceptual Awareness interaction (F(3, 106.03) = 2.75, p = .047), indicating that at PAS3, heart rate in response to fearful bodies (M = -3.59, SE = 0.62) was slower than to neutral bodies (M = -1.91, SE = 0.63). For fearful expressions, heart rate was marginally significantly higher during ‘no experience’ (M = -1.54, SE = 0.63) and ‘clear’ experience (M = -1.50, SE = 0.63) than during ‘almost clear’ experience (M = - 3.59, SE = 0.62) (see <xref ref-type="fig" rid="F5">Figure 5</xref>).</p></sec></sec><sec id="S12" sec-type="discussion"><title>Discussion</title><p id="P18">This ultra-high field fMRI study investigated the perception of threat stimuli (fearful vs. neutral body expressions) in healthy participants using the continuous flash suppression paradigm in combination with the perceptual awareness scale. Behaviorally, we found a gradual relationship between recognition sensitivity and perceptual awareness and no evidence of perceptual discrimination without perceptual awareness. Heart rate was slower for fearful than neutral bodies during almost clear stimulus perception, in line with freezing behavior. At the brain level, the activity in occipital, temporal, parietal and frontal regions as well as in amygdala increased with increased stimulus awareness, while the activity in early visual areas showed the opposite pattern.</p><p id="P19">The relationship between temporal cortex activity and perceptual awareness was better characterized by a gradual model while the activity in fronto-parietal areas by a dichotomous model, suggesting different roles in conscious processing. Interestingly, no evidence of non-conscious body expression processing was found in the amygdala as well as no increased activation for threat stimuli, in contrast to some findings in the literature (<xref ref-type="bibr" rid="R3">Adolphs, Tranel, Damasio, &amp; Damasio, 1995</xref>; <xref ref-type="bibr" rid="R116">Tamietto &amp; de Gelder, 2010</xref>).</p><sec id="S13"><title>Behavioral evidence for the gradual account but not for non-conscious processing</title><p id="P20">The behavioral results revealed a continuum of intermediate states of perceptual awareness (<xref ref-type="fig" rid="F2">Figure 2C</xref>) as well as a linear increase in recognition sensitivity with increased perceptual awareness (<xref ref-type="fig" rid="F2">Figure 2A</xref>). In line with our findings, support for the gradual view has been reported for the perception of low-level features such as color or shape (<xref ref-type="bibr" rid="R51">Lähteenmäki et al., 2015</xref>; <xref ref-type="bibr" rid="R74">Overgaard, Rote, Mouridsen, &amp; Ramsøy, 2006</xref>; <xref ref-type="bibr" rid="R75">Overgaard &amp; Sandberg, 2012</xref>; <xref ref-type="bibr" rid="R93">Ramsøy &amp; Overgaard, 2004</xref>; <xref ref-type="bibr" rid="R99">Sandberg &amp; Overgaard, 2015</xref>; <xref ref-type="bibr" rid="R100">Sandberg, Timmermans, Overgaard, &amp; Cleeremans, 2010</xref>; <xref ref-type="bibr" rid="R133">Wierzchoń, Paulewicz, Asanowicz, Timmermans, &amp; Cleeremans, 2014</xref>; <xref ref-type="bibr" rid="R137">Windey, Vermeiren, Atas, &amp; Cleeremans, 2014</xref>), but also for high-level object and semantic (e.g., emotion) perception (<xref ref-type="bibr" rid="R51">Lähteenmäki et al., 2015</xref>; <xref ref-type="bibr" rid="R59">Lohse &amp; Overgaard, 2019</xref>; <xref ref-type="bibr" rid="R90">Poyo Solanas, Zhan, &amp; de Gelder, 2022</xref>). Moreover, our behavioral results replicated our earlier study using identical fearful and neutral body stimuli as well as angry body expressions (<xref ref-type="bibr" rid="R90">Poyo Solanas et al., 2022</xref>).</p><p id="P21">In contrast with previous work reporting non-conscious processing of emotional information in healthy participants (e.g., <xref ref-type="bibr" rid="R44">Khalid &amp; Ansorge, 2017</xref>; <xref ref-type="bibr" rid="R127">Vieira et al., 2017</xref>; <xref ref-type="bibr" rid="R130">Watanabe &amp; Haruno, 2015</xref>), we found no behavioral evidence for body expression discrimination during perceptual unawareness (<xref ref-type="fig" rid="F2">Figure 2A</xref>). One possible reason for these divergent results may be that most studies reporting non-conscious affective processing used facial expressions (<xref ref-type="bibr" rid="R116">Tamietto &amp; de Gelder, 2010</xref>). In this regard, there is evidence suggesting that emotional faces and bodies may be processed differently during CFS (<xref ref-type="bibr" rid="R145">Zhan et al., 2015</xref>). Another possible reason for this discrepancy may be due to methodological differences regarding the assessment of perceptual awareness. Earlier studies mostly relied on dichotomous measures, which may not be adequate for correctly differentiating true perceptual unawareness from partial/degraded states of perceptual awareness (e.g., ‘brief glimpse’ in PAS) (<xref ref-type="bibr" rid="R66">Mazzi et al., 2016</xref>). In agreement with our findings, growing evidence fails to find evidence for emotion processing outside conscious awareness when using finer scales of perceptual awareness in combination with objective force-choice discrimination tasks to assess task performance (<xref ref-type="bibr" rid="R34">Hesselmann et al., 2018</xref>; <xref ref-type="bibr" rid="R51">Lähteenmäki et al., 2015</xref>; <xref ref-type="bibr" rid="R52">Lamy et al., 2015</xref>; <xref ref-type="bibr" rid="R53">Lamy et al., 2017</xref>; <xref ref-type="bibr" rid="R59">Lohse &amp; Overgaard, 2019</xref>; <xref ref-type="bibr" rid="R81">Peremen &amp; Lamy, 2014</xref>; <xref ref-type="bibr" rid="R90">Poyo Solanas et al., 2022</xref>; <xref ref-type="bibr" rid="R93">Ramsøy &amp; Overgaard, 2004</xref>; <xref ref-type="bibr" rid="R114">Tagliabue et al., 2016</xref>) as well as when controlling for other methodological confounds (<xref ref-type="bibr" rid="R31">Hedger et al., 2015</xref>; <xref ref-type="bibr" rid="R85">Peters et al., 2017</xref>; <xref ref-type="bibr" rid="R86">Peters &amp; Lau, 2015</xref>; <xref ref-type="bibr" rid="R92">Rajananda, Zhu, &amp; Peters, 2020</xref>).</p></sec><sec id="S14"><title>Different brain areas involved in gradual and ‘all-or none’ perceptual awareness</title><p id="P22">Several areas spanning early visual as well as temporal, parietal and frontal regions were influenced by perceptual awareness. Among the areas found bilaterally, there was the LOTC (overlapping with the extrastriate body area (EBA), the fusiform gyrus (overlapping with the fusiform body area (FBA), and the inferior temporal cortex, all high-level visual object areas known to be involved in object recognition (<xref ref-type="bibr" rid="R20">Downing, Jiang, Shuman, &amp; Kanwisher, 2001</xref>; <xref ref-type="bibr" rid="R79">Peelen &amp; Downing, 2005</xref>) (<xref ref-type="fig" rid="F3">Figure 3</xref>). The activity in these areas increased with increased stimulus sensitivity, supporting the notion that degrees of perceptual (object) awareness correspond to degrees of stimulus recognition. Fusiform activity modulations have previously been reported in response to participants’ confidence in recognizing an object (<xref ref-type="bibr" rid="R6">Bar et al., 2001</xref>) as well as in response to stimulus visibility (<xref ref-type="bibr" rid="R83">Pessoa et al., 2006</xref>). In a study using an object naming task, recognition performance correlated with the activity of object areas in the occipito-temporal and fusiform cortex when stimuli exposure duration was varied from 20 to 500 milliseconds (<xref ref-type="bibr" rid="R28">Grill-Spector, Kushnir, Hendler, &amp; Malach, 2000</xref>). Another study using body postures and a CFS paradigm found higher activation in ventral body-sensitive areas during visible conditions, although this study did not assess perceptual awareness on a trial-by-trail basis (<xref ref-type="bibr" rid="R143">Zhan et al., 2018</xref>). Taken together, these studies and the current findings clearly demonstrate a correlation between the level of perceptual awareness and the magnitude of activation of high-level visual areas, including body-selective ones. This picture is different from the proposal by <xref ref-type="bibr" rid="R136">Windey and Cleeremans (2015)</xref> that high-level visual perception is dichotomous while low-level visual processing is graded (<xref ref-type="bibr" rid="R136">Windey &amp; Cleeremans, 2015</xref>). However, the recent study by <xref ref-type="bibr" rid="R89">Poyo Solanas and colleagues (2020)</xref> showed that a region in the lateral occipito-temporal cortex overlapping with the one of the current study encodes the degree of limb contraction. The gradual pattern found in this area may therefore reflect the encoding of this postural midlevel body feature (<xref ref-type="bibr" rid="R17">de Gelder &amp; Poyo Solanas, 2021</xref>; <xref ref-type="bibr" rid="R89">Poyo Solanas et al., 2020</xref>) instead of a high-level body representation.</p><p id="P23">Furthermore, the current results show an effect of perceptual awareness along the intraparietal sulcus. This region is part of the dorsal attention network and responds to stimulus salience, direction of attention and saccades (<xref ref-type="bibr" rid="R13">Corbetta &amp; Shulman, 2011</xref>), all of which may have played a role in our experiment. It is worth noting that our stimuli were presented at either the left or right of the fixation cross (<xref ref-type="fig" rid="F1">Figure 1</xref>). Although participants were specifically instructed to always fixate at the cross and to refrain to do any eye movements when perceiving something in the noise, we cannot exclude that stimulus visibility may have led to saccades (<xref ref-type="bibr" rid="R97">Rothkirch, Stein, Sekutowicz, &amp; Sterzer, 2012</xref>). However, in our previous pupillometry study using a similar experimental design, participants maintained central fixation in 95% of the trials (<xref ref-type="bibr" rid="R90">Poyo Solanas et al., 2022</xref>), which makes eye movements an unlikely explanation for the perceptual awareness modulations found in IPS. In addition, previous studies have shown increased activity in IPS for visible tools (<xref ref-type="bibr" rid="R35">Hesselmann, Hebart, &amp; Malach, 2011</xref>) and inverted bodies (<xref ref-type="bibr" rid="R143">Zhan et al., 2018</xref>) in comparison to their unseen counterparts. Transcranial magnetic stimulation (TMS) over IPS has also shown to cause perceptual vanishing of visual stimuli (<xref ref-type="bibr" rid="R9">Brascamp, Sterzer, Blake, &amp; Knapen, 2018</xref>; <xref ref-type="bibr" rid="R42">Kanai, Muggleton, &amp; Walsh, 2008</xref>), suggesting that this area may mediate perception of stimuli entering consciousness.</p><p id="P24">In line with previous work, our results also suggest an important role of the inferior frontal cortex in perceptual awareness (<xref ref-type="fig" rid="F3">Figure 3</xref>). For example, neuroimaging studies investigating bistable perception have reported increases in prefrontal activity to perceptual changes regardless of stimulus-driven transitions or of the stimuli or paradigm employed (<xref ref-type="bibr" rid="R9">Brascamp et al., 2018</xref>; <xref ref-type="bibr" rid="R60">Lumer, Friston, &amp; Rees, 1998</xref>; <xref ref-type="bibr" rid="R110">Sterzer &amp; Kleinschmidt, 2007</xref>; <xref ref-type="bibr" rid="R142">Zaretskaya, Thielscher, Logothetis, &amp; Bartels, 2010</xref>). Moreover, atypical perceptual transitions during bistable perception have been observed in patients with prefrontal cortex lesions (<xref ref-type="bibr" rid="R67">Meenan &amp; Miller, 1994</xref>; <xref ref-type="bibr" rid="R95">Ricci &amp; Blundo, 1990</xref>; <xref ref-type="bibr" rid="R138">Windmann, Wehrmann, Calabrese, &amp; Güntürkün, 2006</xref>). However, it has been claimed that the activity in the prefrontal cortex may reflect participants’ reports instead of actual changes in conscious perception (<xref ref-type="bibr" rid="R46">Koch, Massimini, Boly, &amp; Tononi, 2016</xref>; <xref ref-type="bibr" rid="R122">Tsuchiya, Wilke, Frässle, &amp; Lamme, 2015</xref>), which would impact the interpretability of the current results. Indeed, neuroimaging (<xref ref-type="bibr" rid="R61">Lumer &amp; Rees, 1999</xref>) as well as intracranial electrophysiological (<xref ref-type="bibr" rid="R71">Noy et al., 2015</xref>) studies involving no-report paradigms found no involvement of the dorsolateral prefrontal cortex in perceptual awareness. Yet, activation was still observed in the IFC, the area of the prefrontal cortex observed in the current study. Importantly, a causal role of the IFC in conscious experience has been recently demonstrated in a study combining neuroimaging methods with TMS showing that this area facilitates changes in conscious experience by continually monitoring conscious representations and comparing them to available sensory data (<xref ref-type="bibr" rid="R131">Weilnhammer et al., 2021</xref>).</p><p id="P25">Taken together, the current findings build upon previous work suggesting that the frontoparietal and temporal cortex constitute a cortico-cortical network involved in perceptual stimulus awareness (<xref ref-type="bibr" rid="R48">Kreiman et al., 2002</xref>; <xref ref-type="bibr" rid="R56">Leopold &amp; Logothetis, 1996</xref>; <xref ref-type="bibr" rid="R58">Logothetis &amp; Schall, 1989</xref>; <xref ref-type="bibr" rid="R77">Panagiotaropoulos et al., 2012</xref>; <xref ref-type="bibr" rid="R104">Sheinberg &amp; Logothetis, 1997</xref>). On one side, the gradual relationship observed between perceptual awareness and temporal cortex activity (<xref ref-type="table" rid="T1">Table 1</xref>) suggests that this area may encode subjective stimuli perception rather than merely physical stimuli properties (body stimuli were always presented and in the same manner). On the other side, the dichotomous activity pattern observed in anterior and medial parts of the IPS as well as in IFC suggests that these areas may be crucial in mediating stimuli entering into consciousness (<xref ref-type="bibr" rid="R9">Brascamp et al., 2018</xref>; <xref ref-type="bibr" rid="R42">Kanai et al., 2008</xref>; <xref ref-type="bibr" rid="R131">Weilnhammer et al., 2021</xref>). This was observed as a significantly lower activity level during ‘no experience’ (when no perceptual switches occurred) than in the rest of perceptual awareness levels (when perceptual switches occurred) as well as a non-significant activity difference between the PAS levels in which perceptual switches occurred (i.e., PAS2-4) (see <xref ref-type="table" rid="T1">Table 1</xref>). The increase in fronto-parietal activity with increased perceptual awareness was seen together with a decrease in the activity of early visual areas (<xref ref-type="fig" rid="F4">Figure 4</xref>). This could reflect the increased inhibition of neural populations representing the dominant stimulus (flickering colorful mask) as the body stimulus gradually became subjectively more visible (<xref ref-type="bibr" rid="R24">Gail, Brinksmeyer, &amp; Eckhorn, 2004</xref>; <xref ref-type="bibr" rid="R43">Keliris, Logothetis, &amp; Tolias, 2010</xref>; <xref ref-type="bibr" rid="R56">Leopold &amp; Logothetis, 1996</xref>; <xref ref-type="bibr" rid="R64">Maier, Logothetis, &amp; Leopold, 2007</xref>; <xref ref-type="bibr" rid="R134">Wilke, Logothetis, &amp; Leopold, 2006</xref>), suggesting that early visual areas may be sufficient to determine the content of perception in situations in which perceptual conflict has not escalated (i.e., PAS1) (<xref ref-type="bibr" rid="R139">Xu et al., 2016</xref>). This is in line with previous work suggesting that fronto-parietal areas may detect perceptual conflict via bottom-up mechanisms when the competing stimulus representations are perceptually different (<xref ref-type="bibr" rid="R129">Wang, Arteaga, &amp; He, 2013</xref>) leaving sensory areas in charge of resolving perceptual conflict when that is not the case (<xref ref-type="bibr" rid="R139">Xu et al., 2016</xref>).</p></sec><sec id="S15"><title>Amygdala and perceptual awareness</title><p id="P26">In the current study, no evidence of body expression processing outside awareness was found in the amygdala, as its activity was significantly lower than intermediate and clear levels of awareness and was also not significantly different from baseline at PAS1. These findings are therefore in disagreement with previous masking (<xref ref-type="bibr" rid="R69">Morris et al., 1998</xref>; <xref ref-type="bibr" rid="R132">Whalen et al., 1998</xref>) and binocular rivalry studies (<xref ref-type="bibr" rid="R78">Pasley et al., 2004</xref>; <xref ref-type="bibr" rid="R135">Williams et al., 2004</xref>) reporting amygdala responses to non-consciously perceived emotional stimuli. Several factors may explain the difference between those studies and the current results.</p><p id="P27">One explanation may be that these studies often failed to formally evaluate participant’s perception. For example, earlier backward masking studies often determined target discrimination based on subject debriefing after the experiment (<xref ref-type="bibr" rid="R94">Rauch et al., 2000</xref>; <xref ref-type="bibr" rid="R105">Sheline et al., 2001</xref>; <xref ref-type="bibr" rid="R132">Whalen et al., 1998</xref>). In line with this explanation, <xref ref-type="bibr" rid="R83">Pessoa and colleagues (2006)</xref> found, after assessing participant’s behavioral performance on a trial-by-trial basis and with SDT measures, differential amygdala activation between fearful and neutral face stimuli only when consciously perceiving the stimuli but not under perceptual unawareness (<xref ref-type="bibr" rid="R83">Pessoa et al., 2006</xref>). Similar results have been obtained for other types of threatening stimuli (<xref ref-type="bibr" rid="R36">Hoffmann et al., 2012</xref>; <xref ref-type="bibr" rid="R37">Hoffmann et al., 2015</xref>). Another possible explanation mentioned earlier could be that previous studies did not account for the different degrees of perceptual awareness, and therefore amygdala activation during reported unawareness could have been confounded with residual awareness.</p><p id="P28">A complementary explanation relates to the functional heterogeneity of the amygdala (<xref ref-type="bibr" rid="R41">Janak &amp; Tye, 2015</xref>; <xref ref-type="bibr" rid="R50">Kyriazi, Headley, &amp; Pare, 2018</xref>; <xref ref-type="bibr" rid="R54">LeDoux, 2007</xref>; <xref ref-type="bibr" rid="R70">Murray, 2007</xref>; <xref ref-type="bibr" rid="R87">Phelps &amp; LeDoux, 2005</xref>). In a binocular rivalry study, <xref ref-type="bibr" rid="R57">Lerner and colleagues (2012)</xref> found an interesting dissociation in the responses of the different amygdala subregions. While the ventral part of amygdala showed higher responses to unseen fearful faces, dorsal amygdala was more consistently activated by consciously perceived fearful faces (<xref ref-type="bibr" rid="R57">Lerner et al., 2012</xref>). Similar results have been shown in the masking study by <xref ref-type="bibr" rid="R23">Etkin and colleagues (2004)</xref> . In the current study, amygdala definition was not performed at the sub cluster level, which may partly explain the results.</p><p id="P29">Furthermore, although amygdala activation has been repeatedly reported for facial expressions, both consciously and non-consciously, evidence for its involvement in body expressions processing is not as consistent, with some studies reporting its involvement (<xref ref-type="bibr" rid="R29">Hadjikhani &amp; de Gelder, 2003</xref>; <xref ref-type="bibr" rid="R49">Kret et al., 2011</xref>; <xref ref-type="bibr" rid="R89">Poyo Solanas et al., 2020</xref>; <xref ref-type="bibr" rid="R107">Sinke et al., 2010</xref>; <xref ref-type="bibr" rid="R124">van de Riet et al., 2009</xref>) while others failed to show it (<xref ref-type="bibr" rid="R102">Seinfeld et al., 2021</xref>; <xref ref-type="bibr" rid="R143">Zhan et al., 2018</xref>; <xref ref-type="bibr" rid="R144">Zhan, Goebel, &amp; de Gelder, 2021</xref>). Recent proposals have suggested that amygdala’s involvement in emotional processing might be more related to facial properties than to emotion per se. In line with this, two behavioral CFS studies reported that the shorter suppression times observed for fearful faces could be explained by low-level facial features (e.g., the contrast), especially those in the eye region (<xref ref-type="bibr" rid="R26">Gray et al., 2013</xref>; <xref ref-type="bibr" rid="R141">Yang et al., 2007</xref>). Taken together, the fact that in the current study no amygdala involvement was found during non-conscious processing could relate to the different object category used here.</p><p id="P30">As mentioned above, amygdala activity increased as the subjective perception of the body stimuli became clearer. The correlation between the magnitude of amygdala activation and the degree of target visibility has previously been reported in the masking study by <xref ref-type="bibr" rid="R83">Pessoa and colleagues (2006)</xref> . The fact that stimuli visibility seems to modulate amygdala responses challenges the commonly held view that emotional processing in amygdala is automatic and independent of attention (<xref ref-type="bibr" rid="R19">Dolan &amp; Vuilleumier, 2003</xref>; <xref ref-type="bibr" rid="R72">Öhman, 2002</xref>). In this regard, the current lack of brain evidence of processing without subjective awareness could be then explained by the fact that body stimuli were presented outside the center of attention (i.e., right or left to the fixation cross). This explanation, however, may not apply in affective blindsight (<xref ref-type="bibr" rid="R68">Morris et al., 2001</xref>) or unilateral neglect patients (<xref ref-type="bibr" rid="R128">Vuilleumier et al., 2002</xref>). Another explanation already proposed by <xref ref-type="bibr" rid="R83">Pessoa and colleagues (2006)</xref> is that the activity of amygdala may itself determine stimulus visibility instead of stimulus awareness being the modulating factor of amygdala’s activity. According to <xref ref-type="bibr" rid="R83">Pessoa and colleagues (2006)</xref>, this interpretation does not contradict findings in blindsight patients, who may be able to perceive emotional stimuli due to increased amygdala sensitivity to this type of stimuli (<xref ref-type="bibr" rid="R83">Pessoa et al., 2006</xref>).</p></sec><sec id="S16"><title>Pulvinar and perceptual awareness</title><p id="P31">Although the activity of pulvinar was significantly different from zero in all PAS levels for both emotions, no evidence of emotion or perceptual awareness modulations were found in this area. This contradicts the findings by <xref ref-type="bibr" rid="R76">Padmala et al. (2010)</xref> showing a correlation between pulvinar responses and stimulus detection, especially for affectively conditioned stimuli (<xref ref-type="bibr" rid="R76">Padmala, Lim, &amp; Pessoa, 2010</xref>). Previous research in human and non-human primates has shown that this area is constituted by retinotopic maps of the contralateral visual fields. The fact that the presentation of the target stimuli was performed to either the right or left visual field may have ‘diluted’ any possible perceptual awareness or affective modulations. Another explanation could be that in the current experiment we did not differentiate between false alarms and hit trials. In a face detection task study, <xref ref-type="bibr" rid="R47">Koizumi and colleagues (2019)</xref> reported higher pulvinar activity for false alarm trials than hit trials independent of emotion (fearful or happy faces) (<xref ref-type="bibr" rid="R47">Koizumi et al., 2019</xref>). Also, in that study no significant differences between fearful and happy hit trials were reported. Taken together, those results point to a general role of pulvinar in signaling false percepts, which was not taken into account in the current study.</p></sec><sec id="S17"><title>Affective processing and perceptual awareness</title><p id="P32">As mentioned earlier, participants’ ability to discriminate fearful from neutral bodies increased linearly with increased perceptual awareness. Moreover, sensitivity values differed from chance performance at all PAS levels except for ‘no experience’. While these results indicate that emotional discrimination may not be observed during perceptual unawareness in neurologically intact participants (<xref ref-type="bibr" rid="R92">Rajananda et al., 2020</xref>), it is crucial to note that our results, like any others, are narrowly linked to the methods used to create (un)awareness. CFS is among the best methods to control for visual awareness, yet we do not fully understand how it interferers with the normal processing flow of feedforward and feedback projections in the visual system, including cortical as well as subcortical information streams.</p><p id="P33">At the physiological level, fearful bodies triggered a slower heart rate compared to neutral ones for ‘almost clear’ stimulus experience (<xref ref-type="fig" rid="F5">Figure 5</xref>). This is in line with freezing behavior, characterized by a deceleration of heart rate when confronted with a threat (<xref ref-type="bibr" rid="R96">Roelofs, 2017</xref>). Heart rate modulations have shown to depend on several factors, such as the ambiguity of the threat. During the almost clear experience of the stimulus, stimulus visibility may have been enough to recognize a body (or parts of it) but not sufficient to be completely certain of the emotional expression. This perceptual ambiguity may explain why freezing behavior was most pronounced for fearful body expressions when participants reported an ‘almost clear’ experience of the stimulus.</p><p id="P34">At the brain level, the activity in the areas showing an effect of perceptual awareness was not influenced by emotion. Previous studies showing emotion influences in fronto-parietal areas used facial expressions (<xref ref-type="bibr" rid="R132">Whalen et al., 1998</xref>), reported an area location that did not correspond to the ones in the current study (IFC, IPS) (<xref ref-type="bibr" rid="R5">Amting, Greening, &amp; Mitchell, 2010</xref>; <xref ref-type="bibr" rid="R128">Vuilleumier et al., 2002</xref>) or included large parts of the fronto-parietal cortices (<xref ref-type="bibr" rid="R45">Kiss &amp; Eimer, 2008</xref>), which may explain the current results. Future studies using other emotional stimuli than facial expressions are needed to investigate whether the resolution of perceptual transitions in fronto-parietal cortices occurs independently of the emotional content. Furthermore, no emotional modulation was found in high-level visual cortices in the current study. The involvement of EBA and FG in body expression perception is still inconclusive (<xref ref-type="bibr" rid="R124">van de Riet et al., 2009</xref>), with some studies supporting their role (<xref ref-type="bibr" rid="R29">Hadjikhani &amp; de Gelder, 2003</xref>; <xref ref-type="bibr" rid="R49">Kret et al., 2011</xref>; <xref ref-type="bibr" rid="R88">Pichon, de Gelder, &amp; Grèzes, 2009</xref>) while others ascribe it to attention and arousal confounding factors (<xref ref-type="bibr" rid="R21">Downing &amp; Peelen, 2011</xref>).</p><p id="P35">In the case of the amygdala, higher activity was found for neutral body expressions than fearful ones, in disagreement with previous literature linking this region with the processing of threatening signals (<xref ref-type="bibr" rid="R1">Adolphs, 1999</xref>). Although participants were able to correctly distinguish neutral bodies from fearful ones when reporting higher stimulus visibility (during almost clear and clear trials), it could be that the action represented by the neutral body posture (opening door) was more ambiguous than the fearful expression, which may explain the results. This interpretation agrees with previous studies suggesting this area as key in the signaling and resolution of ambiguity (<xref ref-type="bibr" rid="R2">Adolphs, 2002</xref>; <xref ref-type="bibr" rid="R18">de Gelder et al., 2014</xref>; <xref ref-type="bibr" rid="R38">Hortensius et al., 2017</xref>; <xref ref-type="bibr" rid="R91">Poyo Solanas et al., 2018</xref>; <xref ref-type="bibr" rid="R132">Whalen et al., 1998</xref>).</p></sec></sec><sec id="S18" sec-type="conclusions"><title>Conclusions</title><p id="P36">The current study provides behavioral, physiological and neuroscientific evidence of the processing of threatening body expressions at 7T using a finer measure of perceptual awareness in combination with signal detection theory measures. The use of the PAS scale revealed intermediate states of perceptual awareness and allowed to differentiate non-conscious processes from partial awareness states. In particular, this study shows a gradual relationship between recognition sensitivity and perceptual awareness as well as no evidence of perceptual discrimination during perceptual unawareness. In addition, it shows that there are both gradual and dichotomous relationships between perceptual awareness and brain activity, possibly reflecting the stimuli or feature processing stage or the different function of each area.</p></sec><sec id="S19" sec-type="materials | methods"><title>Materials and Methods</title><sec id="S20" sec-type="subjects"><title>Participants</title><p id="P37">Fifty-one healthy volunteers were recruited in this study. However, only seventeen healthy volunteers (mean age = 20.69 years; age range = 19-29 years; 11 female; all right-handed) met the required criteria (see <italic>Experimental design and procedure</italic> section) and participated in the fMRI experiment. Participants had normal or corrected-to-normal vision and a medical history without any psychiatric or neurological disorders. The experiment was approved by the Ethical Committee at Maastricht University and was performed in accordance with the Declaration of Helsinki. Participants provided informed written consent before the start of the experiment and received vouchers or credit points after their participation. In addition, participants remained unaware of the aim of the study until the completion of the experiment and were unfamiliar to the CFS paradigm.</p></sec><sec id="S21"><title>Experimental design and procedure</title><p id="P38">Each participant took part in two scan sessions performed on separate days and in randomized order. In one of the sessions, six functional runs of the main CFS experiment were acquired as well as the anatomical data of the participant (~2h 15min). In the other session, resting state data, the data of a body-area localizer and a population receptive field localizer for motion-sensitive early- and mid-level visual cortex were acquired (~1.5h) see <xref ref-type="supplementary-material" rid="SD1">Supplementary Information</xref> for more information on this session). Before the participation in the scanning sessions, participants underwent a short behavioral experiment (~30min) on a separate day to ensure their eligibility for the CFS experiment. Participants showing unstable merging of the stimuli and/or strong suppression were excluded from taking part in the fMRI sessions. The behavioral session also served to determine eye-dominance under CFS (see <xref ref-type="supplementary-material" rid="SD1">Supplementary Information</xref> for more information on the behavioral session).</p><p id="P39">In the main CFS experiment, the participants’ non-dominant eye was presented with a static body posture while a colorful Mondrian mask flickering at 10 Hz was presented to the dominant eye. Dichotomous presentation was accomplished using a cardboard panel and a pair of prism glasses. The cardboard was placed between the mirror attached to the head coil and the screen, dividing it into two halves and ensuring that each eye only perceived half of the screen.</p><p id="P40">The prism glasses (diopter = 6) bent the light in a way that the ipsilateral image was shifted back to the center of each eye (as described in <xref ref-type="bibr" rid="R101">Schurger, 2009</xref>). Both the body stimuli and the colorful mask were displayed on a grey background (RGB value = 128, 128, 128) within a black rectangular frame (frame thickness=10 pixels, frame size 318x352 pixels, 5.08°x5.62° visual angle) that had a fixation cross at its center, respectively, which facilitated the merging of the two images (see <xref ref-type="fig" rid="F1">Figure 1</xref>).</p><p id="P41">The body stimuli were selected from a large validated stimulus set of still whole-body images (<xref ref-type="bibr" rid="R10">Stienen &amp; de Gelder, 2011</xref>) and consisted of eight actor identities (half females) that portrayed either a fearful or a neutral (opening door) body expression (318x182 pixels, 5.08°x2.91° visual angle), with the facial information removed. The body postures were presented either to the right or left side of the fixation cross in a randomized order. The colorful Mondrian mask consisted of 600 unique patterns flashing randomly at 10Hz, which were comprised of overlapping small rectangles covering the entire rectangular frame (see <xref ref-type="fig" rid="F1">Figure 1</xref>).</p><p id="P42">Once the participant reported stable perception of a single rectangle, the experimental run started with a twelve-second fixation period. A change in the fixation cross color from black to white indicated the start of each trial and remained white for the whole trial duration. Each trial started with a one-second white fixation period, followed by a two-second CFS presentation consisting of a gradual increase of the body stimulus contrast over one second, followed by the ramp down of the contrast back to 0% within 0.5s, and a 0.5s blank period. The gradual increase of the stimulus contrast was performed to decrease the likelihood of the body stimulus escaping suppression. The contrast of the colorful Mondrian mask was constant throughout the two-second CFS presentation within each trial. However, both the contrast of the body stimuli and the Mondrian mask were determined for each trial using a staircase procedure with 10 steps (body stimuli: 5%, 14%, 23%, 32%, 41%, 50%, 50%, 50%, 50%, 50%; noise: 100%, 100%, 100%, 100%, 100%, 82%, 64%, 46%, 28%, 10%) that depended on the participant’s visual experience of the body stimulus in the previous trial. If participants reported not seeing anything in the colorful noise, the maximum contrast of the body stimuli increased one step while the contrast of the mask decreased, also by one step. Each run started at step 5 (i.e., 41% contrast for body stimulus and 100% for the noise). This staircase procedure was intended to balance the number of trials per perceptual awareness condition.</p><p id="P43">The two-second CFS period was followed by a jittered fixation period (4-6-8s) after which participants were required to make two responses. The first response required participants to categorize the body stimulus in a two-alternative forced-choice manner (fearful vs. neutral) by pressing one of two buttons. The assignment of the two buttons was randomized. Subsequently, participants had to indicate their visual experience of the stimulus according to the perceptual awareness scale by pressing one out of four buttons: ‘no experience’ (PAS1), ‘brief glimpse’ (PAS2), ‘almost clear experience’ (PAS3) and ‘clear experience’ (PAS4). The button assignment was kept constant for this task to facilitate a quick response. Both responses were required even when participants reported not seeing anything in the noise. In those cases, participants were instructed to guess the emotional expression of the stimulus. Both answers had to be given within a 1.5-second window each, and always with the right hand. Participants were informed about the short response window during the preceding behavioral session, where two practice runs were administered (see <xref ref-type="supplementary-material" rid="SD1">Supplementary Information</xref>). In addition, participants were instructed to keep as still as possible throughout the experiment, to always fixate on the cross and not to blink within the two-second CFS period. Each response period was followed by a jittered inter-trial-interval (4-6-8s), resulting in an average trial duration of 18s and an average run duration of 10min approximately. Each run was comprised of 32 trials, 16 per emotional condition, with two repetitions for each of the eight body stimulus identities. Therefore, a total of 192 trials were obtained, 96 for each emotional category. One participant only performed four runs due to delays in the scanning. Two participants performed seven runs instead of six. One run of three participants and two runs of another were discarded due to excessive motion.</p><p id="P44">The experiment was presented in MATLAB R2012a (MathWorks, Natick, MA, USA) using Psychotoolbox 3.0.11 (<xref ref-type="bibr" rid="R8">Brainard &amp; Vision, 1997</xref>; <xref ref-type="bibr" rid="R80">Pelli &amp; Vision, 1997</xref>). The stimuli were back-projected on a translucent screen situated at the end of the scanner bore, behind participants’ heads (Panasonic PT-EZ570; Newark, NJ, USA; screen size = 30 x 18 cm, screen resolution = 1920 x 1200 pixels, refresh rate = 60 Hz, visual angle = 17.23° x 10.38°). Participants viewed the screen through a tilted mirror attached to the head coil. The distance between the mirror and the screen was ~99 cm. Participant responses were recorded using an MR-compatible button box (Current Designs, 30 8-button response device, HHSC-2 × 4-C; Philadelphia, USA).</p></sec><sec id="S22"><title>Behavioral data analysis</title><p id="P45">Behavioral data were analyzed with SPSS (version 22.0; IBM Corp., Armonk, N.Y., USA) and custom code in MATLAB R2020a (MathWorks, Natick, MA, USA). First, trials without a response for one or both tasks were excluded from further analyses. Trials in which reaction times deviated more than 3.5 times the standard deviation from the mean (within run and subject) were also removed. In total, 136 out of 3239 trials (4.2%) were excluded from further analyses.</p><p id="P46">Participants’ responses in the two-alternative forced-choice task were counted as hits (H), misses (M), correct rejections (CR) and false alarms (FA) according to Signal Detection Theory (<xref ref-type="bibr" rid="R27">Green &amp; Swets, 1966</xref>; <xref ref-type="bibr" rid="R118">Tanner &amp; Swets, 1954</xref>). Hits refer to trials in which fearful bodies were correctly categorized, while misses to those trials in which participants incorrectly categorized fearful bodies as neutral. Correct rejections indicate trials where neutral bodies were correctly categorized whereas false alarms to the trials where neutral stimuli were incorrectly categorized as fearful ones (<xref ref-type="bibr" rid="R10">Candidi, Stienen, Aglioti, &amp; de Gelder, 2011</xref>; <xref ref-type="bibr" rid="R108">Snodgrass &amp; Corwin, 1988</xref>; <xref ref-type="bibr" rid="R117">Tamietto, Geminiani, Genero, &amp; de Gelder, 2007</xref>).</p><p id="P47">To further understand participants’ responses, the perceptual sensitivity (d’) and the response criterion or bias (c) were calculated for each PAS level. Sensitivity is commonly calculated by subtracting the z-transformed false alarm rates from the z-transformed hits (<xref ref-type="disp-formula" rid="FD3">Equation 3</xref>), and therefore reflects the distance between the target (fearful body) and noise (neutral body) distribution means, in standard deviation units. Here, a modified form of hit (H’) and false alarm (FA’) rates was used to account for ceiling effects, as proposed by Snodgrass &amp; Corwin (1988) (<xref ref-type="disp-formula" rid="FD1">Equation 1</xref> &amp; <xref ref-type="disp-formula" rid="FD2">2</xref>). Higher sensitivity values indicate higher discriminability of fearful bodies from neutral ones. A value of zero indicates inability to distinguish fearful body expressions from neutral ones. Independent from sensitivity, criterion bias was calculated by multiplying the sum of the z-transformed hit and false alarm by 0.5 (<xref ref-type="disp-formula" rid="FD4">Equation 4</xref>) (<xref ref-type="bibr" rid="R62">Macmillan, 1993</xref>; <xref ref-type="bibr" rid="R108">Snodgrass &amp; Corwin, 1988</xref>; <xref ref-type="bibr" rid="R117">Tamietto et al., 2007</xref>). It reflects the distance between the neutral point (where responses are not biased towards fearful bodies nor neutral ones) and the response criterion, in standard deviation units. Negative response criterion values indicate a bias in reporting the presence of a fearful body over a neutral one (liberal criterion), while positive values show the opposite response pattern (conservative criterion). <disp-formula id="FD1"><label>(1)</label><mml:math id="M1"><mml:mtext>H</mml:mtext><mml:mo>′</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mtext>H</mml:mtext><mml:mo>+</mml:mo><mml:mn>0.5</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mtext>H</mml:mtext><mml:mo>+</mml:mo><mml:mtext>M</mml:mtext><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula> <disp-formula id="FD2"><label>(2)</label><mml:math id="M2"><mml:mtext>FA</mml:mtext><mml:mo>′</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mtext>FA</mml:mtext><mml:mo>+</mml:mo><mml:mn>0.5</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mtext>FA</mml:mtext><mml:mo>+</mml:mo><mml:mtext>CR</mml:mtext><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula> <disp-formula id="FD3"><label>(3)</label><mml:math id="M3"><mml:mtext>d</mml:mtext><mml:mo>′</mml:mo><mml:mtext>=z</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mtext>H</mml:mtext><mml:mo>′</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mtext>-z</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mtext>F</mml:mtext><mml:mo>′</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula> <disp-formula id="FD4"><label>(4)</label><mml:math id="M4"><mml:mtext>c</mml:mtext><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>0.5</mml:mn><mml:mo>∗</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtext>z</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mtext>H</mml:mtext><mml:mo>′</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mtext>z</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mtext>FA</mml:mtext></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P48">Average sensitivity and criterion bias values were calculated for each perceptual awareness rating and participant. Subsequently, sensitivity and criterion bias values were analyzed, respectively, using a linear mixed model procedure with the within-subject factor Perceptual Awareness (four levels: PAS1, PAS2, PAS3 and PAS4) and the Toeplitz covariance matrix for repeated measures based on Akaike information criterion (AIC) values (<xref ref-type="bibr" rid="R4">Akaike, 1974</xref>). The weighted least squares method was used to account for violations of homoscedasticity in the analysis of sensitivity values. Sensitivity and criterion bias values were also compared to chance level (i.e., against zero) using a one sample t-test per perceptual awareness level.</p><p id="P49">Next, to investigate whether perceptual awareness is a gradual or a dichotomous phenomenon, we fitted two linear mixed models to the sensitivity data with different predictor definitions. In the gradual model, the predictors modelled a linear relationship between sensitivity and the PAS levels. In the dichotomous model, the predictor for the PAS1 level was set to zero while the rest of the PAS levels were set to 1, describing an ‘all-or-none’ relationship between recognition sensitivity and perceptual awareness. These two models were performed independently for each participant. To select the model that best represented the recognition sensitivity pattern across PAS levels at the group level, the values corresponding to the Bayesian information criterion (BIC) (<xref ref-type="bibr" rid="R112">Stone, 1979</xref>) resulting from each model fitting were analyzed with a paired-sample t-test (gradual vs. dichotomous). The model with the significantly lower BIC value (which indicates better fit) was selected as the final model.</p><p id="P50">Lastly, the reaction times (RTs) of the emotional recognition task were analyzed using a linear mixed model with SDT (four levels: H, M, FA, CR) as the within-subject factor. The RTs of the perceptual awareness task were also analyzed with a linear mixed model with Perceptual Awareness (four levels: PAS1, PAS2, PAS3 and PAS4) as the within-subject factor. Both models used the Toeplitz covariance matrix for repeated measures.</p></sec><sec id="S23"><title>(f)MRI data acquisition</title><p id="P51">(f)MRI data were acquired with a 1-transmitter/32-receiver head coil (NovaMedical Inc.; Wilmington, MA, USA) in a 7 Tesla Magnetom whole-body scanner (Siemens Medical Systems, Erlangen, Germany) located at the Maastricht Brain Imaging Centre (MBIC), the Netherlands. Functional images were obtained using a 2D gradient echo (GE) echo-planar imaging (EPI) sequence (voxel size = 1.2 mm isotropic, no gap, repetition time (TR)□=□2000 ms, echo time (TE)□=□21 ms, flip angle (FA)□=□75°, in-plane field of view (FoV) = 172.8 x 172.8 mm<sup>2</sup>, matrix size□=□144 x□144, number of slices per volume 70, multiband acceleration factor□=□2, iPAT=3, phase encoding direction = anterior to posterior, bandwidth=1488 Hz/Px, echo spacing=0.78 ms, number of volumes = 300 (main experimental runs), 440 (body-areas localizer), 315 (pRF mapping), 330 (resting state)). The slice positioning of the functional images was performed in a way to include the occipital, parietal and frontal lobes as well as the amygdala, thus ensuring a good coverage of important areas in body perception. However, limited coverage was obtained for the superior part of the motor cortex, anterior temporal lobe and orbito-frontal cortex. For distortion correction of the functional images, a short run (5 volumes) was acquired before each experimental run with the same parameters specified above but with opposite phase encoding direction (posterior-to-anterior). Anatomical images were acquired for each participant using a MP2RAGE sequence (voxel size = 0.65 mm isotropic, FoV = 207 x 207 mm<sup>2</sup>, matrix size □=□ 320 □ × □ 320, T1-weighted: TR□=□5000 ms, TE□=□2.51 ms, Inversion Time (IT) 1 = 900ms, IT2 = 2750 ms, FA1□=□5°, FA2 = 3°, iPAT = 2, bandwidth=250 Hz/Px, echo spacing = 7 ms). Dielectric pads covering the occipital and temporal lobes were used for all participants.</p></sec><sec id="S24"><title>(f)MRI data preprocessing</title><p id="P52">The pre-processing and analysis of the (f)MRI data were performed in BrainVoyager (v22.0; Brain Innovation B.V.) as well as with custom codes in MATLAB (vR2020a; The MathWorks Inc.; Natick, MA, USA). First, functional images underwent top-up distortion correction with the COPE (Correction based on Opposite Phase Encoding) plugin (v1.1.1) in BrainVoyager (<xref ref-type="bibr" rid="R33">Heinrich, Papież, Schnabel, &amp; Handels, 2014</xref>) based on the voxel displacement between the first volume of the functional run and that of the distortion correction run. Subsequently, slice scan time correction was applied to the functional runs using sinc interpolation. Functional images then underwent 3D rigid motion correction with respect to the first volume of each functional run (trilinear/sinc interpolation). Linear trend removal and high-pass temporal filtering were employed to exclude low-frequency drifts using a general linear model (GLM) Fourier basis set with 2 cycles per time course. In order to reduce the B1 bias field, the anatomical data were background-noise corrected by dividing the UNI image by the T1w image and then masking the resulting ratio image by the INV2 image. In addition, the structural data were corrected for intensity inhomogeneities and upsampled to 0.6 mm isotropic resolution (sinc interpolation, framing cube = 384) to best match the resolution of the functional data. After these steps, each pre-processed functional run was aligned to the first run of the main experiment and normalized to Talairach space. The resulting co-registered images were then spatially smoothed with a Gaussian kernel of a full-width half-maximum of 3mm. A group-averaged anatomical image was created by averaging the Talairach-normalized anatomical data across participants. All analyses were performed in volume space.</p><p id="P53">To facilitate the visualization of group results, a cortex-based alignment (CBA) procedure was carried out. First, the T1-weighted anatomical data of each participant were downsampled to 0.7mm isotropic (for better software results) and subsequently underwent a DNN-based segmentation procedure in BrainVoyager (strides value slow: 32x32x32). This approach classified each anatomical voxel into eight possible tissue types, including white matter, grey matter, cerebrospinal fluid, blood vessels, ventricles, subcortical structures, sagittal sinus and background. With this information, all the individual anatomical UNI datasets were then segmented at the grey–white matter boundary, upsampled to 0.6mm isotropic and normalized to Talairach space. After this step, manual corrections were performed when necessary, on a slice-by-slice basis. The cortical surfaces were then reconstructed, inflated, smoothed, and mapped onto a high-resolution standard sphere, separately for each hemisphere (vertices = 163842). A dynamic group averaging approach based on individual curvature information was used to align participants’ reconstructed cortical surfaces. After alignment, an averaged folded cortical mesh (<italic>n</italic>□=□17) was created for each hemisphere.</p></sec><sec id="S25"><title>Physiological data acquisition, preprocessing and noise correction of fMRI data</title><p id="P54">Cardiac and respiratory measures were acquired using an oximeter (50Hz) and a pneumatic compression belt (50Hz) to control for physiological fluctuation effects on the BOLD response (<xref ref-type="bibr" rid="R7">Birn, Smith, Jones, &amp; Bandettini, 2008</xref>; <xref ref-type="bibr" rid="R12">Chang, Cunningham, &amp; Glover, 2009</xref>; <xref ref-type="bibr" rid="R25">Glover, Li, &amp; Ress, 2000</xref>; <xref ref-type="bibr" rid="R106">Shmueli et al., 2007</xref>). Low-frequency drifts were removed from the raw cardiac (bandpass, 0.5-8Hz) and respiratory (lowpass, 2Hz) data and signal peaks were identified (<xref ref-type="bibr" rid="R22">Elgendi, Norton, Brearley, Abbott, &amp; Schuurmans, 2013</xref>). Physiological noise correction was performed using a modification of the conventional Retrospective Image Correction (RETROICOR) procedure (<xref ref-type="bibr" rid="R25">Glover et al., 2000</xref>; <xref ref-type="bibr" rid="R30">Harvey et al., 2008</xref>; <xref ref-type="bibr" rid="R3">Hu, Le, Parrish, &amp; Erhard, 1995</xref>; <xref ref-type="bibr" rid="R40">Hutton et al., 2011</xref>). In the current procedure, a cardiac and a respiratory phase were assigned to each functional image using third-order cardiac and fourth-order respiratory harmonics. The respiratory phase not only considered the respiratory timing but also the depth of the breathing (<xref ref-type="bibr" rid="R25">Glover et al., 2000</xref>). In addition, a cardiorespiratory interaction (first order) term was defined (<xref ref-type="bibr" rid="R30">Harvey et al., 2008</xref>). A total of 20 regressors were created, including 6 cardiac phase regressors, 8 respiratory phase regressors, 4 cardiorespiratory interaction regressors, as well as a filtered heart rate and respiratory rate regressor.</p></sec><sec id="S26"><title>(f)MRI data analysis</title><sec id="S27"><title>Definition of regions of interest sensitive to perceptual awareness</title><p id="P55">A whole-brain fixed-effects GLM was performed for each subject, individually, with the 3mm-smoothed percent-signal normalized functional data. The GLM included as predictors of interest four predictors corresponding to the perceptual awareness levels (i.e., PAS1-4), a parametric predictor of the mask contrast, a predictor for ‘no response’ trials and a predictor for each of the two response windows. These predictors were convolved with a two-gamma hemodynamic response function. In addition, six motion predictors and 20 physiological predictors (see previous section) were included in the design matrix as nuisance predictors. For each subject, a beta map for each perceptual awareness condition was obtained and entered into a group repeated-measures ANOVA in BrainVoyager. One subject was excluded from this analysis due to a missing condition (PAS4). The resulting t-map showing the main effect of PAS at the group level was corrected for multiple comparisons using a cluster-threshold procedure based on Monte-Carlo simulations (initial p-value = .001, alpha level = .05). This map was then used to define regions of interest (ROI) in each subject for subsequent analyses.</p></sec><sec id="S28"><title>Anatomical definition of amygdala and pulvinar</title><p id="P56">In addition to the PAS-sensitive defined ROIs, the pulvinar and the amygdala were defined in each subject using the Chakravarty Atlas (<xref ref-type="bibr" rid="R11">Chakravarty, Bertrand, Hodge, Sadikot, &amp; Collins, 2006</xref>) given their involvement in non-conscious processing (<xref ref-type="bibr" rid="R116">Tamietto &amp; de Gelder, 2010</xref>). The definition of pulvinar covered all different subnuclei of both the left and right hemisphere. Amygdala definition also covered all subnuclei of both the left and right hemisphere and was manually modified according to individual anatomy when necessary.</p></sec><sec id="S29"><title>Analysis of the defined ROI data</title><p id="P57">A fixed-effects GLM similar to the one described above was performed for each subject with the 3mm-smoothed functional data. However, the predictors corresponding to the perceptual awareness levels were now separated according to the emotional category of the stimulus (i.e., N1, N2, N3, N4, F1, F2, F3, F4; N = neutral; F = fear). For each subject, the beta values corresponding to these eight main conditions were extracted from each ROI (functionally and anatomically defined) and entered into a linear mixed model analysis in SPSS. This analysis was performed for each ROI separately and included two within-subject factors: Emotion (two levels: neutral, fear) and Perceptual Awareness (four levels: PAS1, PAS2, PAS3, PAS4). All analyses used the unstructured covariance matrix for repeated measures. Multiple comparisons were corrected within each ROI with the Sidak-method and across ROIs with the Benjamini-Hochberg false discovery rate (BHFDR) method. To examine whether ROI activity was consistently above or below baseline, a one-sample <italic>t</italic>-test against 0 was performed for each of the eight experimental conditions within each ROI (FDR correction at <italic>q</italic> &lt; .05).</p><p id="P58">As with the sensitivity data, we conducted further analyses to investigate whether brain activity showed a gradual or a dichotomous relationship to perceptual awareness. This resulted in the fitting of four linear mixed models (two Models: Gradual and Dichotomous; two Emotions: Neutral and Fear) into the data of each ROI and subject, respectively. The resulting BIC values from each model fitting were entered into a repeated measures ANOVA with within-subjects factor Model (two levels: gradual and dichotomous) and Emotion (two levels: neutral and fear). In the cases where there was a significant effect of Model but not a significant Model*Emotion interaction, a paired t-test was performed between the coefficient estimates of the neutral and fearful models to assess how different the model slopes and intercepts were across emotions. In the cases where there was a significant Model*Emotion interaction, a different model was selected for each emotion. When no significant effect of Emotion and Model were found, as well as no significant interaction, two model fittings were performed (Gradual and Dichotomous) after averaging the ROI data across emotions. Subsequently, a paired-sample t-test was performed with the resulting BIC values from each model fitting. The BHFDR method was used to correct for multiple comparisons across ROIs and the Sidak-method to correct them within each ROI.</p></sec></sec><sec id="S30"><title>Cardiac data analysis</title><p id="P59">For each trial, the systolic peaks corresponding to the two-second CFS period were identified. Peaks beyond a biologically feasible range were rejected (i.e., beats per minute &lt; 35 or &gt; 180) as well as outliers that were 2.5 standard deviations from the mean. Subsequently, the mean heart rate (beeps per minute) was obtained by averaging the time differences between consecutive peaks. These average estimates were baseline-corrected with respect to the mean heart rate corresponding to the one second preceding each CFS period. The resulting values were entered into a linear mixed model procedure with within-subject factors Emotion (two levels: anger and fear) and Perceptual Awareness (four levels: PAS1, PAS2, PAS3 and PAS4). The compound symmetry covariance matrix for repeated measures was used. Two outliers (single data points within the whole sample) were removed based on their standardized residuals resulting a model with significantly better fit.</p></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary</label><media xlink:href="EMS158899-supplement-Supplementary.pdf" mimetype="application" mime-subtype="pdf" id="d82aAdFbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S31"><title>Acknowledgements</title><p>This work was supported by the European Research Council (ERC) FP7-IDEAS-ERC (Grant agreement number 295673; Emobodies), by the ERC Synergy grant (Grant agreement 856495; Relevance), by the Future and Emerging Technologies (FET) Proactive Program H2020-EU.1.2.2 (Grant agreement 824160; EnTimeMent) and by the Industrial Leadership Program H2020-EU.1.2.2 (Grant agreement 825079; MindSpaces). We would like to thank J. Eck for the help regarding the physiological noise correction of fMRI data, to M. J. Vaessen for the help during the piloting of this study and to V. Smekal for comments on an earlier draft of the introduction section.</p></ack><fn-group><fn id="FN1" fn-type="conflict"><p id="P60"><bold>Competing interests</bold></p><p id="P61">The authors declare no competing interests.</p></fn><fn id="FN2" fn-type="con"><p id="P62"><bold>Author contributions</bold></p><p id="P63">Conceptualization: M.P.S., M.Z. and B.d.G.; Methodology and Software: M.P.S. and M.Z.; Investigation &amp; Formal Analysis: M.P.S.; Writing – original draft: M.P.S.; Writing – review &amp; editing: M.P.S., M.Z. and B.d.G; Visualization: M.P.S.; Funding Acquisition: B.d.G.</p></fn></fn-group><ref-list><ref id="R1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adolphs</surname><given-names>R</given-names></name></person-group><article-title>Social cognition and the human brain</article-title><source>Trends in cognitive sciences</source><year>1999</year><volume>3</volume><issue>12</issue><fpage>469</fpage><lpage>479</lpage><pub-id pub-id-type="pmid">10562726</pub-id></element-citation></ref><ref id="R2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adolphs</surname><given-names>R</given-names></name></person-group><article-title>Neural systems for recognizing emotion</article-title><source>Current opinion in neurobiology</source><year>2002</year><volume>12</volume><issue>2</issue><fpage>169</fpage><lpage>177</lpage><pub-id pub-id-type="pmid">12015233</pub-id></element-citation></ref><ref id="R3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adolphs</surname><given-names>R</given-names></name><name><surname>Tranel</surname><given-names>D</given-names></name><name><surname>Damasio</surname><given-names>H</given-names></name><name><surname>Damasio</surname><given-names>AR</given-names></name></person-group><article-title>Fear and the human amygdala</article-title><source>Journal of Neuroscience</source><year>1995</year><volume>15</volume><issue>9</issue><fpage>5879</fpage><lpage>5891</lpage><pub-id pub-id-type="pmcid">PMC6577662</pub-id><pub-id pub-id-type="pmid">7666173</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.15-09-05879.1995</pub-id></element-citation></ref><ref id="R4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akaike</surname><given-names>H</given-names></name></person-group><article-title>A new look at the statistical model identification</article-title><source>IEEE transactions on automatic control</source><year>1974</year><volume>19</volume><issue>6</issue><fpage>716</fpage><lpage>723</lpage><pub-id pub-id-type="doi">10.1109/TAC.1974.1100705</pub-id></element-citation></ref><ref id="R5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amting</surname><given-names>JM</given-names></name><name><surname>Greening</surname><given-names>SG</given-names></name><name><surname>Mitchell</surname><given-names>DG</given-names></name></person-group><article-title>Multiple mechanisms of consciousness: the neural correlates of emotional awareness</article-title><source>Journal of neuroscience</source><year>2010</year><volume>30</volume><issue>30</issue><fpage>10039</fpage><lpage>10047</lpage><pub-id pub-id-type="pmcid">PMC6633384</pub-id><pub-id pub-id-type="pmid">20668188</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.6434-09.2010</pub-id></element-citation></ref><ref id="R6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bar</surname><given-names>M</given-names></name><name><surname>Tootell</surname><given-names>RB</given-names></name><name><surname>Schacter</surname><given-names>DL</given-names></name><name><surname>Greve</surname><given-names>DN</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Mendola</surname><given-names>JD</given-names></name><etal/><name><surname>Dale</surname><given-names>AM</given-names></name></person-group><article-title>Cortical mechanisms specific to explicit visual object recognition</article-title><source>Neuron</source><year>2001</year><volume>29</volume><issue>2</issue><fpage>529</fpage><lpage>535</lpage><pub-id pub-id-type="pmid">11239441</pub-id></element-citation></ref><ref id="R7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Birn</surname><given-names>RM</given-names></name><name><surname>Smith</surname><given-names>MA</given-names></name><name><surname>Jones</surname><given-names>TB</given-names></name><name><surname>Bandettini</surname><given-names>PA</given-names></name></person-group><article-title>The respiration response function: the temporal dynamics of fMRI signal fluctuations related to changes in respiration</article-title><source>Neuroimage</source><year>2008</year><volume>40</volume><issue>2</issue><fpage>644</fpage><lpage>654</lpage><pub-id pub-id-type="pmcid">PMC2533266</pub-id><pub-id pub-id-type="pmid">18234517</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.11.059</pub-id></element-citation></ref><ref id="R8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname><given-names>DH</given-names></name><name><surname>Vision</surname><given-names>S</given-names></name></person-group><article-title>The psychophysics toolbox</article-title><source>Spatial vision</source><year>1997</year><volume>10</volume><issue>4</issue><fpage>433</fpage><lpage>436</lpage><pub-id pub-id-type="pmid">9176952</pub-id></element-citation></ref><ref id="R9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brascamp</surname><given-names>J</given-names></name><name><surname>Sterzer</surname><given-names>P</given-names></name><name><surname>Blake</surname><given-names>R</given-names></name><name><surname>Knapen</surname><given-names>T</given-names></name></person-group><article-title>Multistable perception and the role of the frontoparietal cortex in perceptual inference</article-title><source>Annu Rev Psychol</source><year>2018</year><volume>69</volume><fpage>77</fpage><lpage>103</lpage><pub-id pub-id-type="pmid">28854000</pub-id></element-citation></ref><ref id="R10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Candidi</surname><given-names>M</given-names></name><name><surname>Stienen</surname><given-names>BM</given-names></name><name><surname>Aglioti</surname><given-names>SM</given-names></name><name><surname>de Gelder</surname><given-names>B</given-names></name></person-group><article-title>Event-related repetitive transcranial magnetic stimulation of posterior superior temporal sulcus improves the detection of threatening postural changes in human bodies</article-title><source>Journal of neuroscience</source><year>2011</year><volume>31</volume><issue>48</issue><fpage>17547</fpage><lpage>17554</lpage><pub-id pub-id-type="pmcid">PMC6623811</pub-id><pub-id pub-id-type="pmid">22131416</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0697-11.2011</pub-id></element-citation></ref><ref id="R11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chakravarty</surname><given-names>MM</given-names></name><name><surname>Bertrand</surname><given-names>G</given-names></name><name><surname>Hodge</surname><given-names>CP</given-names></name><name><surname>Sadikot</surname><given-names>AF</given-names></name><name><surname>Collins</surname><given-names>DL</given-names></name></person-group><article-title>The creation of a brain atlas for image guided neurosurgery using serial histological data</article-title><source>Neuroimage</source><year>2006</year><volume>30</volume><issue>2</issue><fpage>359</fpage><lpage>376</lpage><pub-id pub-id-type="pmid">16406816</pub-id></element-citation></ref><ref id="R12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>C</given-names></name><name><surname>Cunningham</surname><given-names>JP</given-names></name><name><surname>Glover</surname><given-names>GH</given-names></name></person-group><article-title>Influence of heart rate on the BOLD signal: the cardiac response function</article-title><source>Neuroimage</source><year>2009</year><volume>44</volume><issue>3</issue><fpage>857</fpage><lpage>869</lpage><pub-id pub-id-type="pmcid">PMC2677820</pub-id><pub-id pub-id-type="pmid">18951982</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2008.09.029</pub-id></element-citation></ref><ref id="R13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Corbetta</surname><given-names>M</given-names></name><name><surname>Shulman</surname><given-names>GL</given-names></name></person-group><article-title>Spatial neglect and attention networks</article-title><source>Annual review of neuroscience</source><year>2011</year><volume>34</volume><fpage>569</fpage><pub-id pub-id-type="pmcid">PMC3790661</pub-id><pub-id pub-id-type="pmid">21692662</pub-id><pub-id pub-id-type="doi">10.1146/annurev-neuro-061010-113731</pub-id></element-citation></ref><ref id="R14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>M</given-names></name><name><surname>Whalen</surname><given-names>PJ</given-names></name></person-group><article-title>The amygdala: vigilance and emotion</article-title><source>Molecular psychiatry</source><year>2001</year><volume>6</volume><issue>1</issue><fpage>13</fpage><lpage>34</lpage><pub-id pub-id-type="pmid">11244481</pub-id></element-citation></ref><ref id="R15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Gelder</surname><given-names>B</given-names></name><name><surname>Hadjikhani</surname><given-names>N</given-names></name></person-group><article-title>Non-conscious recognition of emotional body language</article-title><source>Neuroreport</source><year>2006</year><volume>17</volume><issue>6</issue><fpage>583</fpage><lpage>586</lpage><pub-id pub-id-type="pmid">16603916</pub-id></element-citation></ref><ref id="R16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Gelder</surname><given-names>B</given-names></name><name><surname>Morris</surname><given-names>JS</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>Unconscious fear influences emotional awareness of faces and voices</article-title><source>Proceedings of the National Academy of Sciences</source><year>2005</year><volume>102</volume><issue>51</issue><fpage>18682</fpage><lpage>18687</lpage><pub-id pub-id-type="pmcid">PMC1317960</pub-id><pub-id pub-id-type="pmid">16352717</pub-id><pub-id pub-id-type="doi">10.1073/pnas.0509179102</pub-id></element-citation></ref><ref id="R17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Gelder</surname><given-names>B</given-names></name><name><surname>Poyo Solanas</surname><given-names>M</given-names></name></person-group><article-title>A computational neuroethology perspective on body and expression perception</article-title><source>Trends in cognitive sciences</source><year>2021</year><volume>25</volume><issue>9</issue><fpage>744</fpage><lpage>756</lpage><pub-id pub-id-type="pmid">34147363</pub-id></element-citation></ref><ref id="R18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Gelder</surname><given-names>B</given-names></name><name><surname>Terburg</surname><given-names>D</given-names></name><name><surname>Morgan</surname><given-names>B</given-names></name><name><surname>Hortensius</surname><given-names>R</given-names></name><name><surname>Stein</surname><given-names>DJ</given-names></name><name><surname>van Honk</surname><given-names>J</given-names></name></person-group><article-title>The role of human basolateral amygdala in ambiguous social threat perception</article-title><source>Cortex</source><year>2014</year><volume>52</volume><fpage>28</fpage><lpage>34</lpage><pub-id pub-id-type="pmid">24607266</pub-id></element-citation></ref><ref id="R19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Vuilleumier</surname><given-names>P</given-names></name></person-group><article-title>Amygdala automaticity in emotional processing</article-title><source>Annals of the New York Academy of Sciences</source><year>2003</year><volume>985</volume><issue>1</issue><fpage>348</fpage><lpage>355</lpage><pub-id pub-id-type="pmid">12724170</pub-id></element-citation></ref><ref id="R20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Downing</surname><given-names>PE</given-names></name><name><surname>Jiang</surname><given-names>Y</given-names></name><name><surname>Shuman</surname><given-names>M</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name></person-group><article-title>A cortical area selective for visual processing of the human body</article-title><source>Science</source><year>2001</year><volume>293</volume><issue>5539</issue><fpage>2470</fpage><lpage>2473</lpage><pub-id pub-id-type="pmid">11577239</pub-id></element-citation></ref><ref id="R21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Downing</surname><given-names>PE</given-names></name><name><surname>Peelen</surname><given-names>MV</given-names></name></person-group><article-title>The role of occipitotemporal body-selective regions in person perception</article-title><source>Cognitive neuroscience</source><year>2011</year><volume>2</volume><issue>3-4</issue><fpage>186</fpage><lpage>203</lpage><pub-id pub-id-type="pmid">24168534</pub-id></element-citation></ref><ref id="R22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elgendi</surname><given-names>M</given-names></name><name><surname>Norton</surname><given-names>I</given-names></name><name><surname>Brearley</surname><given-names>M</given-names></name><name><surname>Abbott</surname><given-names>D</given-names></name><name><surname>Schuurmans</surname><given-names>D</given-names></name></person-group><article-title>Systolic peak detection in acceleration photoplethysmograms measured from emergency responders in tropical conditions</article-title><source>PloS one</source><year>2013</year><volume>8</volume><issue>10</issue><elocation-id>e76585</elocation-id><pub-id pub-id-type="pmcid">PMC3805543</pub-id><pub-id pub-id-type="pmid">24167546</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0076585</pub-id></element-citation></ref><ref id="R23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Etkin</surname><given-names>A</given-names></name><name><surname>Klemenhagen</surname><given-names>KC</given-names></name><name><surname>Dudman</surname><given-names>JT</given-names></name><name><surname>Rogan</surname><given-names>MT</given-names></name><name><surname>Hen</surname><given-names>R</given-names></name><name><surname>Kandel</surname><given-names>ER</given-names></name><name><surname>Hirsch</surname><given-names>J</given-names></name></person-group><article-title>Individual differences in trait anxiety predict the response of the basolateral amygdala to unconsciously processed fearful faces</article-title><source>Neuron</source><year>2004</year><volume>44</volume><issue>6</issue><fpage>1043</fpage><lpage>1055</lpage><pub-id pub-id-type="pmid">15603746</pub-id></element-citation></ref><ref id="R24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gail</surname><given-names>A</given-names></name><name><surname>Brinksmeyer</surname><given-names>HJ</given-names></name><name><surname>Eckhorn</surname><given-names>R</given-names></name></person-group><article-title>Perception-related modulations of local field potential power and coherence in primary visual cortex of awake monkey during binocular rivalry</article-title><source>Cerebral cortex</source><year>2004</year><volume>14</volume><issue>3</issue><fpage>300</fpage><lpage>313</lpage><pub-id pub-id-type="pmid">14754869</pub-id></element-citation></ref><ref id="R25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glover</surname><given-names>GH</given-names></name><name><surname>Li</surname><given-names>TQ</given-names></name><name><surname>Ress</surname><given-names>D</given-names></name></person-group><article-title>Image-based method for retrospective correction of physiological motion effects in fMRI: RETROICOR</article-title><source>Magnetic Resonance in Medicine: An Official Journal of the International Society for Magnetic Resonance in Medicine</source><year>2000</year><volume>44</volume><issue>1</issue><fpage>162</fpage><lpage>167</lpage><pub-id pub-id-type="pmid">10893535</pub-id></element-citation></ref><ref id="R26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gray</surname><given-names>KL</given-names></name><name><surname>Adams</surname><given-names>WJ</given-names></name><name><surname>Hedger</surname><given-names>N</given-names></name><name><surname>Newton</surname><given-names>KE</given-names></name><name><surname>Garner</surname><given-names>M</given-names></name></person-group><article-title>Faces and awareness: low-level, not emotional factors determine perceptual dominance</article-title><source>Emotion</source><year>2013</year><volume>13</volume><issue>3</issue><fpage>537</fpage><pub-id pub-id-type="pmid">23398580</pub-id></element-citation></ref><ref id="R27"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Green</surname><given-names>DM</given-names></name><name><surname>Swets</surname><given-names>JA</given-names></name></person-group><chapter-title>Signal detection theory and psychophysics</chapter-title><source>Signal detection theory and psychophysics</source><publisher-loc>New York</publisher-loc><publisher-name>Wiley New York</publisher-name><year>1966</year></element-citation></ref><ref id="R28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grill-Spector</surname><given-names>K</given-names></name><name><surname>Kushnir</surname><given-names>T</given-names></name><name><surname>Hendler</surname><given-names>T</given-names></name><name><surname>Malach</surname><given-names>R</given-names></name></person-group><article-title>The dynamics of object-selective activation correlate with recognition performance in humans</article-title><source>Nature neuroscience</source><year>2000</year><volume>3</volume><issue>8</issue><fpage>837</fpage><lpage>843</lpage><pub-id pub-id-type="pmid">10903579</pub-id></element-citation></ref><ref id="R29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hadjikhani</surname><given-names>N</given-names></name><name><surname>de Gelder</surname><given-names>B</given-names></name></person-group><article-title>Seeing fearful body expressions activates the fusiform cortex and amygdala</article-title><source>Current biology</source><year>2003</year><volume>13</volume><issue>24</issue><fpage>2201</fpage><lpage>2205</lpage><pub-id pub-id-type="pmid">14680638</pub-id></element-citation></ref><ref id="R30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harvey</surname><given-names>AK</given-names></name><name><surname>Pattinson</surname><given-names>KT</given-names></name><name><surname>Brooks</surname><given-names>JC</given-names></name><name><surname>Mayhew</surname><given-names>SD</given-names></name><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Wise</surname><given-names>RG</given-names></name></person-group><article-title>Brainstem functional magnetic resonance imaging: disentangling signal from physiological noise</article-title><source>Journal of Magnetic Resonance Imaging: An Official Journal of the International Society for Magnetic Resonance in Medicine</source><year>2008</year><volume>28</volume><issue>6</issue><fpage>1337</fpage><lpage>1344</lpage><pub-id pub-id-type="pmid">19025940</pub-id></element-citation></ref><ref id="R31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hedger</surname><given-names>N</given-names></name><name><surname>Adams</surname><given-names>WJ</given-names></name><name><surname>Garner</surname><given-names>M</given-names></name></person-group><article-title>Autonomic arousal and attentional orienting to visual threat are predicted by awareness</article-title><source>Journal of Experimental Psychology: Human perception and performance</source><year>2015</year><volume>41</volume><issue>3</issue><fpage>798</fpage><lpage>806</lpage><pub-id pub-id-type="pmid">25867508</pub-id></element-citation></ref><ref id="R32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hedger</surname><given-names>N</given-names></name><name><surname>Gray</surname><given-names>KL</given-names></name><name><surname>Garner</surname><given-names>M</given-names></name><name><surname>Adams</surname><given-names>WJ</given-names></name></person-group><article-title>Are visual threats prioritized without awareness? A critical review and meta-analysis involving 3 behavioral paradigms and 2696 observers</article-title><source>Psychological bulletin</source><year>2016</year><volume>142</volume><issue>9</issue><fpage>934</fpage><lpage>968</lpage><pub-id pub-id-type="pmid">27123863</pub-id></element-citation></ref><ref id="R33"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Heinrich</surname><given-names>MP</given-names></name><name><surname>Papież</surname><given-names>BW</given-names></name><name><surname>Schnabel</surname><given-names>JA</given-names></name><name><surname>Handels</surname><given-names>H</given-names></name></person-group><source>Non-parametric discrete registration with convex optimisation</source><conf-name>Paper presented at the International Workshop on Biomedical Image Registration</conf-name><year>2014</year></element-citation></ref><ref id="R34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hesselmann</surname><given-names>G</given-names></name><name><surname>Darcy</surname><given-names>N</given-names></name><name><surname>Rothkirch</surname><given-names>M</given-names></name><name><surname>Sterzer</surname><given-names>P</given-names></name></person-group><article-title>Investigating masked priming along the “vision-for-perception” and “vision-for-action” dimensions of unconscious processing</article-title><source>Journal of Experimental Psychology: General</source><year>2018</year><volume>147</volume><issue>11</issue><fpage>1641</fpage><lpage>1659</lpage><pub-id pub-id-type="pmid">30010373</pub-id></element-citation></ref><ref id="R35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hesselmann</surname><given-names>G</given-names></name><name><surname>Hebart</surname><given-names>M</given-names></name><name><surname>Malach</surname><given-names>R</given-names></name></person-group><article-title>Differential BOLD activity associated with subjective and objective reports during “blindsight” in normal observers</article-title><source>Journal of neuroscience</source><year>2011</year><volume>31</volume><issue>36</issue><fpage>12936</fpage><lpage>12944</lpage><pub-id pub-id-type="pmcid">PMC6623391</pub-id><pub-id pub-id-type="pmid">21900572</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1556-11.2011</pub-id></element-citation></ref><ref id="R36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoffmann</surname><given-names>M</given-names></name><name><surname>Lipka</surname><given-names>J</given-names></name><name><surname>Mothes-Lasch</surname><given-names>M</given-names></name><name><surname>Miltner</surname><given-names>WH</given-names></name><name><surname>Straube</surname><given-names>T</given-names></name></person-group><article-title>Awareness modulates responses of the amygdala and the visual cortex to highly arousing visual threat</article-title><source>Neuroimage</source><year>2012</year><volume>62</volume><issue>3</issue><fpage>1439</fpage><lpage>1444</lpage><pub-id pub-id-type="pmid">22659485</pub-id></element-citation></ref><ref id="R37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoffmann</surname><given-names>M</given-names></name><name><surname>Mothes-Lasch</surname><given-names>M</given-names></name><name><surname>Miltner</surname><given-names>WH</given-names></name><name><surname>Straube</surname><given-names>T</given-names></name></person-group><article-title>Brain activation to briefly presented emotional words: effects of stimulus awareness</article-title><source>Human Brain Mapping</source><year>2015</year><volume>36</volume><issue>2</issue><fpage>655</fpage><lpage>665</lpage><pub-id pub-id-type="pmcid">PMC6869641</pub-id><pub-id pub-id-type="pmid">25324170</pub-id><pub-id pub-id-type="doi">10.1002/hbm.22654</pub-id></element-citation></ref><ref id="R38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hortensius</surname><given-names>R</given-names></name><name><surname>Terburg</surname><given-names>D</given-names></name><name><surname>Morgan</surname><given-names>B</given-names></name><name><surname>Stein</surname><given-names>DJ</given-names></name><name><surname>van Honk</surname><given-names>J</given-names></name><name><surname>de Gelder</surname><given-names>B</given-names></name></person-group><article-title>The basolateral amygdalae and frontotemporal network functions for threat perception</article-title><source>eneuro</source><year>2017</year><volume>4</volume><issue>1</issue><pub-id pub-id-type="pmcid">PMC5368167</pub-id><pub-id pub-id-type="pmid">28374005</pub-id><pub-id pub-id-type="doi">10.1523/ENEURO.0314-16.2016</pub-id></element-citation></ref><ref id="R39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hu</surname><given-names>X</given-names></name><name><surname>Le</surname><given-names>TH</given-names></name><name><surname>Parrish</surname><given-names>T</given-names></name><name><surname>Erhard</surname><given-names>P</given-names></name></person-group><article-title>Retrospective estimation and correction of physiological fluctuation in functional MRI</article-title><source>Magnetic resonance in medicine</source><year>1995</year><volume>34</volume><issue>2</issue><fpage>201</fpage><lpage>212</lpage><pub-id pub-id-type="pmid">7476079</pub-id></element-citation></ref><ref id="R40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hutton</surname><given-names>C</given-names></name><name><surname>Josephs</surname><given-names>O</given-names></name><name><surname>Stadler</surname><given-names>J</given-names></name><name><surname>Featherstone</surname><given-names>E</given-names></name><name><surname>Reid</surname><given-names>A</given-names></name><name><surname>Speck</surname><given-names>O</given-names></name><etal/><name><surname>Weiskopf</surname><given-names>N</given-names></name></person-group><article-title>The impact of physiological noise correction on fMRI at 7 T</article-title><source>Neuroimage</source><year>2011</year><volume>57</volume><issue>1</issue><fpage>101</fpage><lpage>112</lpage><pub-id pub-id-type="pmcid">PMC3115139</pub-id><pub-id pub-id-type="pmid">21515386</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.04.018</pub-id></element-citation></ref><ref id="R41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Janak</surname><given-names>PH</given-names></name><name><surname>Tye</surname><given-names>KM</given-names></name></person-group><article-title>From circuits to behaviour in the amygdala</article-title><source>Nature</source><year>2015</year><volume>517</volume><issue>7534</issue><fpage>284</fpage><lpage>292</lpage><pub-id pub-id-type="pmcid">PMC4565157</pub-id><pub-id pub-id-type="pmid">25592533</pub-id><pub-id pub-id-type="doi">10.1038/nature14188</pub-id></element-citation></ref><ref id="R42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kanai</surname><given-names>R</given-names></name><name><surname>Muggleton</surname><given-names>NG</given-names></name><name><surname>Walsh</surname><given-names>V</given-names></name></person-group><article-title>TMS over the intraparietal sulcus induces perceptual fading</article-title><source>Journal of Neurophysiology</source><year>2008</year><volume>100</volume><issue>6</issue><fpage>3343</fpage><lpage>3350</lpage><pub-id pub-id-type="pmid">18922944</pub-id></element-citation></ref><ref id="R43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keliris</surname><given-names>GA</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name></person-group><article-title>The role of the primary visual cortex in perceptual suppression of salient visual stimuli</article-title><source>Journal of neuroscience</source><year>2010</year><volume>30</volume><issue>37</issue><fpage>12353</fpage><lpage>12365</lpage><pub-id pub-id-type="pmcid">PMC2962415</pub-id><pub-id pub-id-type="pmid">20844131</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0677-10.2010</pub-id></element-citation></ref><ref id="R44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khalid</surname><given-names>S</given-names></name><name><surname>Ansorge</surname><given-names>U</given-names></name></person-group><article-title>Subliminal face emotion processing: a comparison of fearful and disgusted faces</article-title><source>Frontiers in psychology</source><year>2017</year><volume>8</volume><fpage>1028</fpage><pub-id pub-id-type="pmcid">PMC5478734</pub-id><pub-id pub-id-type="pmid">28680413</pub-id><pub-id pub-id-type="doi">10.3389/fpsyg.2017.01028</pub-id></element-citation></ref><ref id="R45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiss</surname><given-names>M</given-names></name><name><surname>Eimer</surname><given-names>M</given-names></name></person-group><article-title>ERPs reveal subliminal processing of fearful faces</article-title><source>Psychophysiology</source><year>2008</year><volume>45</volume><issue>2</issue><fpage>318</fpage><lpage>326</lpage><pub-id pub-id-type="pmcid">PMC2375009</pub-id><pub-id pub-id-type="pmid">17995905</pub-id><pub-id pub-id-type="doi">10.1111/j.1469-8986.2007.00634.x</pub-id></element-citation></ref><ref id="R46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Massimini</surname><given-names>M</given-names></name><name><surname>Boly</surname><given-names>M</given-names></name><name><surname>Tononi</surname><given-names>G</given-names></name></person-group><article-title>Neural correlates of consciousness: progress and problems</article-title><source>Nature Reviews Neuroscience</source><year>2016</year><volume>17</volume><issue>5</issue><fpage>307</fpage><lpage>321</lpage><pub-id pub-id-type="pmid">27094080</pub-id></element-citation></ref><ref id="R47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koizumi</surname><given-names>A</given-names></name><name><surname>Zhan</surname><given-names>M</given-names></name><name><surname>Ban</surname><given-names>H</given-names></name><name><surname>Kida</surname><given-names>I</given-names></name><name><surname>De Martino</surname><given-names>F</given-names></name><name><surname>Vaessen</surname><given-names>MJ</given-names></name><etal/><name><surname>Amano</surname><given-names>K</given-names></name></person-group><article-title>Threat anticipation in pulvinar and in superficial layers of primary visual cortex (V1). Evidence from layer-specific ultra-high field 7T fMRI</article-title><source>eneuro</source><year>2019</year><volume>6</volume><issue>6</issue><pub-id pub-id-type="pmcid">PMC6901684</pub-id><pub-id pub-id-type="pmid">31694815</pub-id><pub-id pub-id-type="doi">10.1523/ENEURO.0429-19.2019</pub-id></element-citation></ref><ref id="R48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kreiman</surname><given-names>G</given-names></name><name><surname>Fried</surname><given-names>I</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name></person-group><article-title>Single-neuron correlates of subjective vision in the human medial temporal lobe</article-title><source>Proceedings of the National Academy of Sciences</source><year>2002</year><volume>99</volume><issue>12</issue><fpage>8378</fpage><lpage>8383</lpage><pub-id pub-id-type="pmcid">PMC123075</pub-id><pub-id pub-id-type="pmid">12034865</pub-id><pub-id pub-id-type="doi">10.1073/pnas.072194099</pub-id></element-citation></ref><ref id="R49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kret</surname><given-names>ME</given-names></name><name><surname>Pichon</surname><given-names>S</given-names></name><name><surname>Grèzes</surname><given-names>J</given-names></name><name><surname>de Gelder</surname><given-names>B</given-names></name></person-group><article-title>Similarities and differences in perceiving threat from dynamic faces and bodies. An fMRI study</article-title><source>Neuroimage</source><year>2011</year><volume>54</volume><issue>2</issue><fpage>1755</fpage><lpage>1762</lpage><pub-id pub-id-type="pmid">20723605</pub-id></element-citation></ref><ref id="R50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kyriazi</surname><given-names>P</given-names></name><name><surname>Headley</surname><given-names>DB</given-names></name><name><surname>Pare</surname><given-names>D</given-names></name></person-group><article-title>Multi-dimensional coding by basolateral amygdala neurons</article-title><source>Neuron</source><year>2018</year><volume>99</volume><issue>6</issue><fpage>1315</fpage><lpage>1328</lpage><elocation-id>e1315</elocation-id><pub-id pub-id-type="pmcid">PMC6342465</pub-id><pub-id pub-id-type="pmid">30146300</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2018.07.036</pub-id></element-citation></ref><ref id="R51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lähteenmäki</surname><given-names>M</given-names></name><name><surname>Hyönä</surname><given-names>J</given-names></name><name><surname>Koivisto</surname><given-names>M</given-names></name><name><surname>Nummenmaa</surname><given-names>L</given-names></name></person-group><article-title>Affective processing requires awareness</article-title><source>Journal of Experimental Psychology: General</source><year>2015</year><volume>144</volume><issue>2</issue><fpage>339</fpage><lpage>365</lpage><pub-id pub-id-type="pmid">25559654</pub-id></element-citation></ref><ref id="R52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lamy</surname><given-names>D</given-names></name><name><surname>Alon</surname><given-names>L</given-names></name><name><surname>Carmel</surname><given-names>T</given-names></name><name><surname>Shalev</surname><given-names>N</given-names></name></person-group><article-title>The role of conscious perception in attentional capture and object-file updating</article-title><source>Psychological science</source><year>2015</year><volume>26</volume><issue>1</issue><fpage>48</fpage><lpage>57</lpage><pub-id pub-id-type="pmid">25413876</pub-id></element-citation></ref><ref id="R53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lamy</surname><given-names>D</given-names></name><name><surname>Carmel</surname><given-names>T</given-names></name><name><surname>Peremen</surname><given-names>Z</given-names></name></person-group><article-title>Prior conscious experience enhances conscious perception but does not affect response priming</article-title><source>Cognition</source><year>2017</year><volume>160</volume><fpage>62</fpage><lpage>81</lpage><pub-id pub-id-type="pmid">28056385</pub-id></element-citation></ref><ref id="R54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LeDoux</surname><given-names>J</given-names></name></person-group><article-title>The amygdala</article-title><source>Current biology</source><year>2007</year><volume>17</volume><issue>20</issue><fpage>R868</fpage><lpage>R874</lpage><pub-id pub-id-type="pmid">17956742</pub-id></element-citation></ref><ref id="R55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>T-H</given-names></name><name><surname>Lim</surname><given-names>S-L</given-names></name><name><surname>Lee</surname><given-names>K-Y</given-names></name><name><surname>Choi</surname><given-names>J-S</given-names></name></person-group><article-title>Facilitation of visual processing by masked presentation of a conditioned facial stimulus</article-title><source>Neuroreport</source><year>2009</year><volume>20</volume><issue>8</issue><fpage>750</fpage><lpage>754</lpage><pub-id pub-id-type="pmid">19398934</pub-id></element-citation></ref><ref id="R56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leopold</surname><given-names>DA</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name></person-group><article-title>Activity changes in early visual cortex reflect monkeys’ percepts during binocular rivalry</article-title><source>Nature</source><year>1996</year><volume>379</volume><issue>6565</issue><fpage>549</fpage><lpage>553</lpage><pub-id pub-id-type="pmid">8596635</pub-id></element-citation></ref><ref id="R57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lerner</surname><given-names>Y</given-names></name><name><surname>Singer</surname><given-names>N</given-names></name><name><surname>Gonen</surname><given-names>T</given-names></name><name><surname>Weintraub</surname><given-names>Y</given-names></name><name><surname>Cohen</surname><given-names>O</given-names></name><name><surname>Rubin</surname><given-names>N</given-names></name><etal/><name><surname>Hendler</surname><given-names>T</given-names></name></person-group><article-title>Feeling without seeing? Engagement of ventral, but not dorsal, amygdala during unaware exposure to emotional faces</article-title><source>Journal of cognitive neuroscience</source><year>2012</year><volume>24</volume><issue>3</issue><fpage>531</fpage><lpage>542</lpage><pub-id pub-id-type="pmid">22098264</pub-id></element-citation></ref><ref id="R58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Logothetis</surname><given-names>NK</given-names></name><name><surname>Schall</surname><given-names>JD</given-names></name></person-group><article-title>Neuronal correlates of subjective visual perception</article-title><source>Science</source><year>1989</year><volume>245</volume><issue>4919</issue><fpage>761</fpage><lpage>763</lpage><pub-id pub-id-type="pmid">2772635</pub-id></element-citation></ref><ref id="R59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lohse</surname><given-names>M</given-names></name><name><surname>Overgaard</surname><given-names>M</given-names></name></person-group><article-title>Emotional priming depends on the degree of conscious experience</article-title><source>Neuropsychologia</source><year>2019</year><volume>128</volume><fpage>96</fpage><lpage>102</lpage><pub-id pub-id-type="pmcid">PMC6562235</pub-id><pub-id pub-id-type="pmid">29129593</pub-id><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2017.10.028</pub-id></element-citation></ref><ref id="R60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lumer</surname><given-names>ED</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Rees</surname><given-names>G</given-names></name></person-group><article-title>Neural correlates of perceptual rivalry in the human brain</article-title><source>Science</source><year>1998</year><volume>280</volume><issue>5371</issue><fpage>1930</fpage><lpage>1934</lpage><pub-id pub-id-type="pmid">9632390</pub-id></element-citation></ref><ref id="R61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lumer</surname><given-names>ED</given-names></name><name><surname>Rees</surname><given-names>G</given-names></name></person-group><article-title>Covariation of activity in visual and prefrontal cortex associated with subjective visual perception</article-title><source>Proceedings of the National Academy of Sciences</source><year>1999</year><volume>96</volume><issue>4</issue><fpage>1669</fpage><lpage>1673</lpage><pub-id pub-id-type="pmcid">PMC15554</pub-id><pub-id pub-id-type="pmid">9990082</pub-id><pub-id pub-id-type="doi">10.1073/pnas.96.4.1669</pub-id></element-citation></ref><ref id="R62"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Macmillan</surname><given-names>NA</given-names></name></person-group><chapter-title>Signal detection theory as data analysis method and psychological decision model</chapter-title><person-group person-group-type="editor"><name><surname>Lewis</surname><given-names>GKC</given-names></name></person-group><source>A handbook for data analysis in the behavioral sciences: Methodological issues</source><publisher-name>Lawrence Erlbaum Associates</publisher-name><year>1993</year><fpage>21</fpage><lpage>57</lpage></element-citation></ref><ref id="R63"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Macmillan</surname><given-names>NA</given-names></name><name><surname>Creelman</surname><given-names>CD</given-names></name></person-group><source>Detection theory: A user’s guide</source><publisher-name>Psychology press</publisher-name><publisher-loc>New York</publisher-loc><year>2004</year></element-citation></ref><ref id="R64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maier</surname><given-names>A</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name><name><surname>Leopold</surname><given-names>DA</given-names></name></person-group><article-title>Context-dependent perceptual modulation of single neurons in primate visual cortex</article-title><source>Proceedings of the National Academy of Sciences</source><year>2007</year><volume>104</volume><issue>13</issue><fpage>5620</fpage><lpage>5625</lpage><pub-id pub-id-type="pmcid">PMC1828131</pub-id><pub-id pub-id-type="pmid">17369363</pub-id><pub-id pub-id-type="doi">10.1073/pnas.0608489104</pub-id></element-citation></ref><ref id="R65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mayer</surname><given-names>B</given-names></name><name><surname>Merckelbach</surname><given-names>H</given-names></name><name><surname>de Jong</surname><given-names>PJ</given-names></name><name><surname>Leeuw</surname><given-names>I</given-names></name></person-group><article-title>Skin conductance responses of spider phobics to backwardly masked phobic cues</article-title><source>Journal of Psychophysiology</source><year>1999</year><volume>13</volume><issue>3</issue><fpage>152</fpage><lpage>159</lpage><pub-id pub-id-type="doi">10.1027/0269-8803.13.3.152</pub-id></element-citation></ref><ref id="R66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mazzi</surname><given-names>C</given-names></name><name><surname>Bagattini</surname><given-names>C</given-names></name><name><surname>Savazzi</surname><given-names>S</given-names></name></person-group><article-title>Blind-sight vs. degraded-sight: different measures tell a different story</article-title><source>Frontiers in psychology</source><year>2016</year><volume>7</volume><fpage>901</fpage><pub-id pub-id-type="pmcid">PMC4909743</pub-id><pub-id pub-id-type="pmid">27378993</pub-id><pub-id pub-id-type="doi">10.3389/fpsyg.2016.00901</pub-id></element-citation></ref><ref id="R67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meenan</surname><given-names>J</given-names></name><name><surname>Miller</surname><given-names>LA</given-names></name></person-group><article-title>Perceptual flexibility after frontal or temporal lobectomy</article-title><source>Neuropsychologia</source><year>1994</year><volume>32</volume><issue>9</issue><fpage>1145</fpage><lpage>1149</lpage><pub-id pub-id-type="pmid">7991080</pub-id></element-citation></ref><ref id="R68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morris</surname><given-names>JS</given-names></name><name><surname>de Gelder</surname><given-names>B</given-names></name><name><surname>Weiskrantz</surname><given-names>L</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>Differential extrageniculostriate and amygdala responses to presentation of emotional faces in a cortically blind field</article-title><source>Brain</source><year>2001</year><volume>124</volume><issue>6</issue><fpage>1241</fpage><lpage>1252</lpage><pub-id pub-id-type="pmid">11353739</pub-id></element-citation></ref><ref id="R69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morris</surname><given-names>JS</given-names></name><name><surname>Öhman</surname><given-names>A</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>Conscious and unconscious emotional learning in the human amygdala</article-title><source>Nature</source><year>1998</year><volume>393</volume><issue>6684</issue><fpage>467</fpage><lpage>470</lpage><pub-id pub-id-type="pmid">9624001</pub-id></element-citation></ref><ref id="R70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murray</surname><given-names>EA</given-names></name></person-group><article-title>The amygdala, reward and emotion</article-title><source>Trends in cognitive sciences</source><year>2007</year><volume>11</volume><issue>11</issue><fpage>489</fpage><lpage>497</lpage><pub-id pub-id-type="pmid">17988930</pub-id></element-citation></ref><ref id="R71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Noy</surname><given-names>N</given-names></name><name><surname>Bickel</surname><given-names>S</given-names></name><name><surname>Zion-Golumbic</surname><given-names>E</given-names></name><name><surname>Harel</surname><given-names>M</given-names></name><name><surname>Golan</surname><given-names>T</given-names></name><name><surname>Davidesco</surname><given-names>I</given-names></name><etal/><name><surname>Schroeder</surname><given-names>C</given-names></name></person-group><article-title>Ignition’s glow: Ultra-fast spread of global cortical activity accompanying local “ignitions” in visual cortex during conscious visual perception</article-title><source>Consciousness and cognition</source><year>2015</year><volume>35</volume><fpage>206</fpage><lpage>224</lpage><pub-id pub-id-type="pmid">25824626</pub-id></element-citation></ref><ref id="R72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Öhman</surname><given-names>A</given-names></name></person-group><article-title>Automaticity and the amygdala: Nonconscious responses to emotional faces</article-title><source>Current directions in psychological science</source><year>2002</year><volume>11</volume><issue>2</issue><fpage>62</fpage><lpage>66</lpage><pub-id pub-id-type="doi">10.1111/1467-8721.00169</pub-id></element-citation></ref><ref id="R73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oliver</surname><given-names>LD</given-names></name><name><surname>Mao</surname><given-names>A</given-names></name><name><surname>Mitchell</surname><given-names>DG</given-names></name></person-group><article-title>“Blindsight” and subjective awareness of fearful faces: Inversion reverses the deficits in fear perception associated with core psychopathic traits</article-title><source>Cognition and emotion</source><year>2015</year><volume>29</volume><issue>7</issue><fpage>1256</fpage><lpage>1277</lpage><pub-id pub-id-type="pmid">25379973</pub-id></element-citation></ref><ref id="R74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Overgaard</surname><given-names>M</given-names></name><name><surname>Rote</surname><given-names>J</given-names></name><name><surname>Mouridsen</surname><given-names>K</given-names></name><name><surname>Ramsøy</surname><given-names>TZ</given-names></name></person-group><article-title>Is conscious perception gradual or dichotomous? A comparison of report methodologies during a visual task</article-title><source>Consciousness and cognition</source><year>2006</year><volume>15</volume><issue>4</issue><fpage>700</fpage><lpage>708</lpage><pub-id pub-id-type="pmid">16725347</pub-id></element-citation></ref><ref id="R75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Overgaard</surname><given-names>M</given-names></name><name><surname>Sandberg</surname><given-names>K</given-names></name></person-group><article-title>Kinds of access: different methods for report reveal different kinds of metacognitive access</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><year>2012</year><volume>367</volume><issue>1594</issue><fpage>1287</fpage><lpage>1296</lpage><pub-id pub-id-type="pmcid">PMC3318768</pub-id><pub-id pub-id-type="pmid">22492747</pub-id><pub-id pub-id-type="doi">10.1098/rstb.2011.0425</pub-id></element-citation></ref><ref id="R76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Padmala</surname><given-names>S</given-names></name><name><surname>Lim</surname><given-names>S-L</given-names></name><name><surname>Pessoa</surname><given-names>L</given-names></name></person-group><article-title>Pulvinar and affective significance: responses track moment-to-moment stimulus visibility</article-title><source>Frontiers in human neuroscience</source><year>2010</year><volume>4</volume><fpage>64</fpage><pub-id pub-id-type="pmcid">PMC2953413</pub-id><pub-id pub-id-type="pmid">20948583</pub-id><pub-id pub-id-type="doi">10.3389/fnhum.2010.00064</pub-id></element-citation></ref><ref id="R77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Panagiotaropoulos</surname><given-names>TI</given-names></name><name><surname>Deco</surname><given-names>G</given-names></name><name><surname>Kapoor</surname><given-names>V</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name></person-group><article-title>Neuronal discharges and gamma oscillations explicitly reflect visual consciousness in the lateral prefrontal cortex</article-title><source>Neuron</source><year>2012</year><volume>74</volume><issue>5</issue><fpage>924</fpage><lpage>935</lpage><pub-id pub-id-type="pmid">22681695</pub-id></element-citation></ref><ref id="R78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pasley</surname><given-names>BN</given-names></name><name><surname>Mayes</surname><given-names>LC</given-names></name><name><surname>Schultz</surname><given-names>RT</given-names></name></person-group><article-title>Subcortical discrimination of unperceived objects during binocular rivalry</article-title><source>Neuron</source><year>2004</year><volume>42</volume><issue>1</issue><fpage>163</fpage><lpage>172</lpage><pub-id pub-id-type="pmid">15066273</pub-id></element-citation></ref><ref id="R79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peelen</surname><given-names>MV</given-names></name><name><surname>Downing</surname><given-names>PE</given-names></name></person-group><article-title>Selectivity for the human body in the fusiform gyrus</article-title><source>Journal of Neurophysiology</source><year>2005</year><volume>93</volume><issue>1</issue><fpage>603</fpage><lpage>608</lpage><pub-id pub-id-type="pmid">15295012</pub-id></element-citation></ref><ref id="R80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pelli</surname><given-names>DG</given-names></name><name><surname>Vision</surname><given-names>S</given-names></name></person-group><article-title>The VideoToolbox software for visual psychophysics: Transforming numbers into movies</article-title><source>Spatial vision</source><year>1997</year><volume>10</volume><fpage>437</fpage><lpage>442</lpage><pub-id pub-id-type="pmid">9176953</pub-id></element-citation></ref><ref id="R81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peremen</surname><given-names>Z</given-names></name><name><surname>Lamy</surname><given-names>D</given-names></name></person-group><article-title>Do conscious perception and unconscious processing rely on independent mechanisms? A meta-contrast study</article-title><source>Consciousness and cognition</source><year>2014</year><volume>24</volume><fpage>22</fpage><lpage>32</lpage><pub-id pub-id-type="pmid">24398259</pub-id></element-citation></ref><ref id="R82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pessoa</surname><given-names>L</given-names></name></person-group><article-title>To what extent are emotional visual stimuli processed without attention and awareness?</article-title><source>Current opinion in neurobiology</source><year>2005</year><volume>15</volume><issue>2</issue><fpage>188</fpage><lpage>196</lpage><pub-id pub-id-type="pmid">15831401</pub-id></element-citation></ref><ref id="R83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pessoa</surname><given-names>L</given-names></name><name><surname>Japee</surname><given-names>S</given-names></name><name><surname>Sturman</surname><given-names>D</given-names></name><name><surname>Ungerleider</surname><given-names>LG</given-names></name></person-group><article-title>Target visibility and visual awareness modulate amygdala responses to fearful faces</article-title><source>Cerebral cortex</source><year>2006</year><volume>16</volume><issue>3</issue><fpage>366</fpage><lpage>375</lpage><pub-id pub-id-type="pmid">15930371</pub-id></element-citation></ref><ref id="R84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pessoa</surname><given-names>L</given-names></name><name><surname>Japee</surname><given-names>S</given-names></name><name><surname>Ungerleider</surname><given-names>LG</given-names></name></person-group><article-title>Visual awareness and the detection of fearful faces</article-title><source>Emotion</source><year>2005</year><volume>5</volume><issue>2</issue><fpage>243</fpage><lpage>247</lpage><pub-id pub-id-type="pmid">15982091</pub-id></element-citation></ref><ref id="R85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peters</surname><given-names>MA</given-names></name><name><surname>Fesi</surname><given-names>J</given-names></name><name><surname>Amendi</surname><given-names>N</given-names></name><name><surname>Knotts</surname><given-names>JD</given-names></name><name><surname>Lau</surname><given-names>H</given-names></name><name><surname>Ro</surname><given-names>T</given-names></name></person-group><article-title>Transcranial magnetic stimulation to visual cortex induces suboptimal introspection</article-title><source>Cortex</source><year>2017</year><volume>93</volume><fpage>119</fpage><lpage>132</lpage><pub-id pub-id-type="pmcid">PMC5541901</pub-id><pub-id pub-id-type="pmid">28646672</pub-id><pub-id pub-id-type="doi">10.1016/j.cortex.2017.05.017</pub-id></element-citation></ref><ref id="R86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peters</surname><given-names>MA</given-names></name><name><surname>Lau</surname><given-names>H</given-names></name></person-group><article-title>Human observers have optimal introspective access to perceptual processes even for visually masked stimuli</article-title><source>Elife</source><year>2015</year><volume>4</volume><elocation-id>e09651</elocation-id><pub-id pub-id-type="pmcid">PMC4749556</pub-id><pub-id pub-id-type="pmid">26433023</pub-id><pub-id pub-id-type="doi">10.7554/eLife.09651</pub-id></element-citation></ref><ref id="R87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Phelps</surname><given-names>EA</given-names></name><name><surname>LeDoux</surname><given-names>JE</given-names></name></person-group><article-title>Contributions of the amygdala to emotion processing: from animal models to human behavior</article-title><source>Neuron</source><year>2005</year><volume>48</volume><issue>2</issue><fpage>175</fpage><lpage>187</lpage><pub-id pub-id-type="pmid">16242399</pub-id></element-citation></ref><ref id="R88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pichon</surname><given-names>S</given-names></name><name><surname>de Gelder</surname><given-names>B</given-names></name><name><surname>Grèzes</surname><given-names>J</given-names></name></person-group><article-title>Two different faces of threat. Comparing the neural systems for recognizing fear and anger in dynamic body expressions</article-title><source>Neuroimage</source><year>2009</year><volume>47</volume><issue>4</issue><fpage>1873</fpage><lpage>1883</lpage><pub-id pub-id-type="pmid">19371787</pub-id></element-citation></ref><ref id="R89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poyo Solanas</surname><given-names>M</given-names></name><name><surname>Vaessen</surname><given-names>M</given-names></name><name><surname>de Gelder</surname><given-names>B</given-names></name></person-group><article-title>Computation-based feature representation of body expressions in the human brain</article-title><source>Cerebral cortex</source><year>2020</year><volume>30</volume><issue>12</issue><fpage>6376</fpage><lpage>6390</lpage><pub-id pub-id-type="pmid">32770200</pub-id></element-citation></ref><ref id="R90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poyo Solanas</surname><given-names>M</given-names></name><name><surname>Zhan</surname><given-names>M</given-names></name><name><surname>de Gelder</surname><given-names>B</given-names></name></person-group><article-title>Gradual relation between perceptual awareness, recognition and pupillary responses to social threat</article-title><source>bioRxiv</source><year>2022</year><elocation-id>2022.2009.2020.508721</elocation-id><pub-id pub-id-type="doi">10.1101/2022.09.20.508721</pub-id></element-citation></ref><ref id="R91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poyo Solanas</surname><given-names>M</given-names></name><name><surname>Zhan</surname><given-names>M</given-names></name><name><surname>Vaessen</surname><given-names>M</given-names></name><name><surname>Hortensius</surname><given-names>R</given-names></name><name><surname>Engelen</surname><given-names>T</given-names></name><name><surname>de Gelder</surname><given-names>B</given-names></name></person-group><article-title>Looking at the face and seeing the whole body. Neural basis of combined face and body expressions</article-title><source>Social cognitive and affective neuroscience</source><year>2018</year><volume>13</volume><issue>1</issue><fpage>135</fpage><lpage>144</lpage><pub-id pub-id-type="pmcid">PMC5793719</pub-id><pub-id pub-id-type="pmid">29092076</pub-id><pub-id pub-id-type="doi">10.1093/scan/nsx130</pub-id></element-citation></ref><ref id="R92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rajananda</surname><given-names>S</given-names></name><name><surname>Zhu</surname><given-names>J</given-names></name><name><surname>Peters</surname><given-names>MA</given-names></name></person-group><article-title>Normal observers show no evidence for blindsight in facial emotion perception</article-title><source>Neuroscience of Consciousness</source><year>2020</year><volume>2020</volume><issue>1</issue><elocation-id>niaa023</elocation-id><pub-id pub-id-type="pmcid">PMC7734439</pub-id><pub-id pub-id-type="pmid">33343928</pub-id><pub-id pub-id-type="doi">10.1093/nc/niaa023</pub-id></element-citation></ref><ref id="R93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramsøy</surname><given-names>TZ</given-names></name><name><surname>Overgaard</surname><given-names>M</given-names></name></person-group><article-title>Introspection and subliminal perception</article-title><source>Phenomenology and the cognitive sciences</source><year>2004</year><volume>3</volume><issue>1</issue><fpage>1</fpage><lpage>23</lpage><pub-id pub-id-type="doi">10.1023/B:PHEN.0000041900.30172.e8</pub-id></element-citation></ref><ref id="R94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rauch</surname><given-names>SL</given-names></name><name><surname>Whalen</surname><given-names>PJ</given-names></name><name><surname>Shin</surname><given-names>LM</given-names></name><name><surname>McInerney</surname><given-names>SC</given-names></name><name><surname>Macklin</surname><given-names>ML</given-names></name><name><surname>Lasko</surname><given-names>NB</given-names></name><etal/><name><surname>Pitman</surname><given-names>RK</given-names></name></person-group><article-title>Exaggerated amygdala response to masked facial stimuli in posttraumatic stress disorder: a functional MRI study</article-title><source>Biological psychiatry</source><year>2000</year><volume>47</volume><issue>9</issue><fpage>769</fpage><lpage>776</lpage><pub-id pub-id-type="pmid">10812035</pub-id></element-citation></ref><ref id="R95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ricci</surname><given-names>C</given-names></name><name><surname>Blundo</surname><given-names>C</given-names></name></person-group><article-title>Perception of ambiguous figures after focal brain lesions</article-title><source>Neuropsychologia</source><year>1990</year><volume>28</volume><issue>11</issue><fpage>1163</fpage><lpage>1173</lpage><pub-id pub-id-type="pmid">2290491</pub-id></element-citation></ref><ref id="R96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roelofs</surname><given-names>K</given-names></name></person-group><article-title>Freeze for action: neurobiological mechanisms in animal and human freezing</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><year>2017</year><volume>372</volume><issue>1718</issue><elocation-id>20160206</elocation-id><pub-id pub-id-type="pmcid">PMC5332864</pub-id><pub-id pub-id-type="pmid">28242739</pub-id><pub-id pub-id-type="doi">10.1098/rstb.2016.0206</pub-id></element-citation></ref><ref id="R97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rothkirch</surname><given-names>M</given-names></name><name><surname>Stein</surname><given-names>T</given-names></name><name><surname>Sekutowicz</surname><given-names>M</given-names></name><name><surname>Sterzer</surname><given-names>P</given-names></name></person-group><article-title>A direct oculomotor correlate of unconscious visual processing</article-title><source>Current biology</source><year>2012</year><volume>22</volume><issue>13</issue><fpage>R514</fpage><lpage>R515</lpage><pub-id pub-id-type="pmid">22789995</pub-id></element-citation></ref><ref id="R98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saalmann</surname><given-names>YB</given-names></name><name><surname>Kastner</surname><given-names>S</given-names></name></person-group><article-title>Cognitive and perceptual functions of the visual thalamus</article-title><source>Neuron</source><year>2011</year><volume>71</volume><issue>2</issue><fpage>209</fpage><lpage>223</lpage><pub-id pub-id-type="pmcid">PMC3148184</pub-id><pub-id pub-id-type="pmid">21791281</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2011.06.027</pub-id></element-citation></ref><ref id="R99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sandberg</surname><given-names>K</given-names></name><name><surname>Overgaard</surname><given-names>M</given-names></name></person-group><article-title>Using the perceptual awareness scale (PAS)</article-title><source>Behavioral methods in consciousness research</source><year>2015</year><fpage>181</fpage><lpage>196</lpage><pub-id pub-id-type="doi">10.1093/acprof:oso/9780199688890.003.0011</pub-id></element-citation></ref><ref id="R100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sandberg</surname><given-names>K</given-names></name><name><surname>Timmermans</surname><given-names>B</given-names></name><name><surname>Overgaard</surname><given-names>M</given-names></name><name><surname>Cleeremans</surname><given-names>A</given-names></name></person-group><article-title>Measuring consciousness: is one measure better than the other?</article-title><source>Consciousness and cognition</source><year>2010</year><volume>19</volume><issue>4</issue><fpage>1069</fpage><lpage>1078</lpage><pub-id pub-id-type="pmid">20133167</pub-id></element-citation></ref><ref id="R101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schurger</surname><given-names>A</given-names></name></person-group><article-title>A very inexpensive MRI-compatible method for dichoptic visual stimulation</article-title><source>Journal of neuroscience methods</source><year>2009</year><volume>177</volume><issue>1</issue><fpage>199</fpage><lpage>202</lpage><pub-id pub-id-type="pmid">18973774</pub-id></element-citation></ref><ref id="R102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seinfeld</surname><given-names>S</given-names></name><name><surname>Zhan</surname><given-names>M</given-names></name><name><surname>Poyo-Solanas</surname><given-names>M</given-names></name><name><surname>Barsuola</surname><given-names>G</given-names></name><name><surname>Vaessen</surname><given-names>M</given-names></name><name><surname>Slater</surname><given-names>M</given-names></name><etal/><name><surname>de Gelder</surname><given-names>B</given-names></name></person-group><article-title>Being the victim of virtual abuse changes default mode network responses to emotional expressions</article-title><source>Cortex</source><year>2021</year><volume>135</volume><fpage>268</fpage><lpage>284</lpage><pub-id pub-id-type="pmid">33418321</pub-id></element-citation></ref><ref id="R103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seth</surname><given-names>AK</given-names></name><name><surname>Bayne</surname><given-names>T</given-names></name></person-group><article-title>Theories of consciousness</article-title><source>Nature Reviews Neuroscience</source><year>2022</year><fpage>1</fpage><lpage>14</lpage><pub-id pub-id-type="pmid">35505255</pub-id></element-citation></ref><ref id="R104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheinberg</surname><given-names>DL</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name></person-group><article-title>The role of temporal cortical areas in perceptual organization</article-title><source>Proceedings of the National Academy of Sciences</source><year>1997</year><volume>94</volume><issue>7</issue><fpage>3408</fpage><lpage>3413</lpage><pub-id pub-id-type="pmcid">PMC20383</pub-id><pub-id pub-id-type="pmid">9096407</pub-id><pub-id pub-id-type="doi">10.1073/pnas.94.7.3408</pub-id></element-citation></ref><ref id="R105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheline</surname><given-names>YI</given-names></name><name><surname>Barch</surname><given-names>DM</given-names></name><name><surname>Donnelly</surname><given-names>JM</given-names></name><name><surname>Ollinger</surname><given-names>JM</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Mintun</surname><given-names>MA</given-names></name></person-group><article-title>Increased amygdala response to masked emotional faces in depressed subjects resolves with antidepressant treatment: an fMRI study</article-title><source>Biological psychiatry</source><year>2001</year><volume>50</volume><issue>9</issue><fpage>651</fpage><lpage>658</lpage><pub-id pub-id-type="pmid">11704071</pub-id></element-citation></ref><ref id="R106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shmueli</surname><given-names>K</given-names></name><name><surname>van Gelderen</surname><given-names>P</given-names></name><name><surname>de Zwart</surname><given-names>JA</given-names></name><name><surname>Horovitz</surname><given-names>SG</given-names></name><name><surname>Fukunaga</surname><given-names>M</given-names></name><name><surname>Jansma</surname><given-names>JM</given-names></name><name><surname>Duyn</surname><given-names>JH</given-names></name></person-group><article-title>Low-frequency fluctuations in the cardiac rate as a source of variance in the resting-state fMRI BOLD signal</article-title><source>Neuroimage</source><year>2007</year><volume>38</volume><issue>2</issue><fpage>306</fpage><lpage>320</lpage><pub-id pub-id-type="pmcid">PMC2128785</pub-id><pub-id pub-id-type="pmid">17869543</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.07.037</pub-id></element-citation></ref><ref id="R107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sinke</surname><given-names>CB</given-names></name><name><surname>Sorger</surname><given-names>B</given-names></name><name><surname>Goebel</surname><given-names>R</given-names></name><name><surname>de Gelder</surname><given-names>B</given-names></name></person-group><article-title>Tease or threat? Judging social interactions from bodily expressions</article-title><source>Neuroimage</source><year>2010</year><volume>49</volume><issue>2</issue><fpage>1717</fpage><lpage>1727</lpage><pub-id pub-id-type="pmid">19804836</pub-id></element-citation></ref><ref id="R108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Snodgrass</surname><given-names>JG</given-names></name><name><surname>Corwin</surname><given-names>J</given-names></name></person-group><article-title>Pragmatics of measuring recognition memory:applications to dementia and amnesia</article-title><source>Journal of Experimental Psychology: General</source><year>1988</year><volume>117</volume><issue>1</issue><fpage>34</fpage><lpage>50</lpage><pub-id pub-id-type="pmid">2966230</pub-id></element-citation></ref><ref id="R109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stein</surname><given-names>T</given-names></name><name><surname>Seymour</surname><given-names>K</given-names></name><name><surname>Hebart</surname><given-names>MN</given-names></name><name><surname>Sterzer</surname><given-names>P</given-names></name></person-group><article-title>Rapid fear detection relies on high spatial frequencies</article-title><source>Psychological science</source><year>2014</year><volume>25</volume><issue>2</issue><fpage>566</fpage><lpage>574</lpage><pub-id pub-id-type="pmid">24379157</pub-id></element-citation></ref><ref id="R110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sterzer</surname><given-names>P</given-names></name><name><surname>Kleinschmidt</surname><given-names>A</given-names></name></person-group><article-title>A neural basis for inference in perceptual ambiguity</article-title><source>Proceedings of the National Academy of Sciences</source><year>2007</year><volume>104</volume><issue>1</issue><fpage>323</fpage><lpage>328</lpage><pub-id pub-id-type="pmcid">PMC1765459</pub-id><pub-id pub-id-type="pmid">17190824</pub-id><pub-id pub-id-type="doi">10.1073/pnas.0609006104</pub-id></element-citation></ref><ref id="R111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stienen</surname><given-names>B</given-names></name><name><surname>de Gelder</surname><given-names>B</given-names></name></person-group><article-title>Fear detection and visual awareness in perceiving bodily expressions</article-title><source>Emotion</source><year>2011</year><volume>11</volume><issue>5</issue><fpage>1182</fpage><lpage>1189</lpage><pub-id pub-id-type="pmid">21707146</pub-id></element-citation></ref><ref id="R112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stone</surname><given-names>M</given-names></name></person-group><article-title>Comments on model selection criteria of Akaike and Schwarz</article-title><source>Journal of the Royal Statistical Society</source><series>Series B (Methodological)</series><year>1979</year><fpage>276</fpage><lpage>278</lpage><pub-id pub-id-type="doi">10.1111/j.2517-6161.1979.tb01084.x</pub-id></element-citation></ref><ref id="R113"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Straube</surname><given-names>T</given-names></name><name><surname>Dietrich</surname><given-names>C</given-names></name><name><surname>Mothes-Lasch</surname><given-names>M</given-names></name><name><surname>Mentzel</surname><given-names>HJ</given-names></name><name><surname>Miltner</surname><given-names>WH</given-names></name></person-group><article-title>The volatility of the amygdala response to masked fearful eyes</article-title><source>Human Brain Mapping</source><year>2010</year><volume>31</volume><issue>10</issue><fpage>1601</fpage><lpage>1608</lpage><pub-id pub-id-type="pmcid">PMC6870838</pub-id><pub-id pub-id-type="pmid">20162600</pub-id><pub-id pub-id-type="doi">10.1002/hbm.20960</pub-id></element-citation></ref><ref id="R114"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tagliabue</surname><given-names>CF</given-names></name><name><surname>Mazzi</surname><given-names>C</given-names></name><name><surname>Bagattini</surname><given-names>C</given-names></name><name><surname>Savazzi</surname><given-names>S</given-names></name></person-group><article-title>Early local activity in temporal areas reflects graded content of visual perception</article-title><source>Frontiers in psychology</source><year>2016</year><volume>7</volume><fpage>572</fpage><pub-id pub-id-type="pmcid">PMC4842950</pub-id><pub-id pub-id-type="pmid">27199809</pub-id><pub-id pub-id-type="doi">10.3389/fpsyg.2016.00572</pub-id></element-citation></ref><ref id="R115"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tamietto</surname><given-names>M</given-names></name><name><surname>Cauda</surname><given-names>F</given-names></name><name><surname>Celeghin</surname><given-names>A</given-names></name><name><surname>Diano</surname><given-names>M</given-names></name><name><surname>Costa</surname><given-names>T</given-names></name><name><surname>Cossa</surname><given-names>FM</given-names></name><etal/><name><surname>de Gelder</surname><given-names>B</given-names></name></person-group><article-title>Once you feel it, you see it: insula and sensory-motor contribution to visual awareness for fearful bodies in parietal neglect</article-title><source>Cortex</source><year>2015</year><volume>62</volume><fpage>56</fpage><lpage>72</lpage><pub-id pub-id-type="pmid">25465122</pub-id></element-citation></ref><ref id="R116"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tamietto</surname><given-names>M</given-names></name><name><surname>de Gelder</surname><given-names>B</given-names></name></person-group><article-title>Neural bases of the non-conscious perception of emotional signals</article-title><source>Nature Reviews Neuroscience</source><year>2010</year><volume>11</volume><issue>10</issue><fpage>697</fpage><lpage>709</lpage><pub-id pub-id-type="pmid">20811475</pub-id></element-citation></ref><ref id="R117"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tamietto</surname><given-names>M</given-names></name><name><surname>Geminiani</surname><given-names>G</given-names></name><name><surname>Genero</surname><given-names>R</given-names></name><name><surname>de Gelder</surname><given-names>B</given-names></name></person-group><article-title>Seeing fearful body language overcomes attentional deficits in patients with neglect</article-title><source>Journal of cognitive neuroscience</source><year>2007</year><volume>19</volume><issue>3</issue><fpage>445</fpage><lpage>454</lpage><pub-id pub-id-type="pmid">17335393</pub-id></element-citation></ref><ref id="R118"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tanner</surname><given-names>WP</given-names></name><name><surname>Swets</surname><given-names>JA</given-names></name></person-group><article-title>A decision-making theory of visual detection</article-title><source>Psychological review</source><year>1954</year><volume>61</volume><issue>6</issue><fpage>401</fpage><lpage>409</lpage><pub-id pub-id-type="pmid">13215690</pub-id></element-citation></ref><ref id="R119"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsuchiya</surname><given-names>N</given-names></name><name><surname>Adolphs</surname><given-names>R</given-names></name></person-group><article-title>Emotion and consciousness</article-title><source>Trends in cognitive sciences</source><year>2007</year><volume>11</volume><issue>4</issue><fpage>158</fpage><lpage>167</lpage><pub-id pub-id-type="pmid">17324608</pub-id></element-citation></ref><ref id="R120"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsuchiya</surname><given-names>N</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name></person-group><article-title>Continuous flash suppression reduces negative afterimages</article-title><source>Nature neuroscience</source><year>2005</year><volume>8</volume><issue>8</issue><fpage>1096</fpage><lpage>1101</lpage><pub-id pub-id-type="pmid">15995700</pub-id></element-citation></ref><ref id="R121"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsuchiya</surname><given-names>N</given-names></name><name><surname>Moradi</surname><given-names>F</given-names></name><name><surname>Felsen</surname><given-names>C</given-names></name><name><surname>Yamazaki</surname><given-names>M</given-names></name><name><surname>Adolphs</surname><given-names>R</given-names></name></person-group><article-title>Intact rapid detection of fearful faces in the absence of the amygdala</article-title><source>Nature neuroscience</source><year>2009</year><volume>12</volume><issue>10</issue><fpage>1224</fpage><lpage>1225</lpage><pub-id pub-id-type="pmcid">PMC2756300</pub-id><pub-id pub-id-type="pmid">19718036</pub-id><pub-id pub-id-type="doi">10.1038/nn.2380</pub-id></element-citation></ref><ref id="R122"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsuchiya</surname><given-names>N</given-names></name><name><surname>Wilke</surname><given-names>M</given-names></name><name><surname>Frässle</surname><given-names>S</given-names></name><name><surname>Lamme</surname><given-names>VA</given-names></name></person-group><article-title>No-report paradigms: extracting the true neural correlates of consciousness</article-title><source>Trends in cognitive sciences</source><year>2015</year><volume>19</volume><issue>12</issue><fpage>757</fpage><lpage>770</lpage><pub-id pub-id-type="pmid">26585549</pub-id></element-citation></ref><ref id="R123"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uğurbil</surname><given-names>K</given-names></name></person-group><article-title>Magnetic resonance imaging at ultrahigh fields</article-title><source>IEEE transactions on biomedical engineering</source><year>2014</year><volume>61</volume><issue>5</issue><fpage>1364</fpage><lpage>1379</lpage><pub-id pub-id-type="pmcid">PMC4135536</pub-id><pub-id pub-id-type="pmid">24686229</pub-id><pub-id pub-id-type="doi">10.1109/TBME.2014.2313619</pub-id></element-citation></ref><ref id="R124"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van de Riet</surname><given-names>WA</given-names></name><name><surname>Grèzes</surname><given-names>J</given-names></name><name><surname>de Gelder</surname><given-names>B</given-names></name></person-group><article-title>Specific and common brain regions involved in the perception of faces and bodies and the representation of their emotional expressions</article-title><source>Social neuroscience</source><year>2009</year><volume>4</volume><issue>2</issue><fpage>101</fpage><lpage>120</lpage><pub-id pub-id-type="pmid">19255912</pub-id></element-citation></ref><ref id="R125"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van den Stock</surname><given-names>J</given-names></name><name><surname>Tamietto</surname><given-names>M</given-names></name><name><surname>Sorger</surname><given-names>B</given-names></name><name><surname>Pichon</surname><given-names>S</given-names></name><name><surname>Grézes</surname><given-names>J</given-names></name><name><surname>de Gelder</surname><given-names>B</given-names></name></person-group><article-title>Cortico-subcortical visual, somatosensory, and motor activations for perceiving dynamic whole-body emotional expressions with and without striate cortex (V1)</article-title><source>Proceedings of the National Academy of Sciences</source><year>2011</year><volume>108</volume><issue>39</issue><fpage>16188</fpage><lpage>16193</lpage><pub-id pub-id-type="pmcid">PMC3182696</pub-id><pub-id pub-id-type="pmid">21911384</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1107214108</pub-id></element-citation></ref><ref id="R126"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van den Stock</surname><given-names>J</given-names></name><name><surname>Tamietto</surname><given-names>M</given-names></name><name><surname>Zhan</surname><given-names>M</given-names></name><name><surname>Heinecke</surname><given-names>A</given-names></name><name><surname>Hervais-Adelman</surname><given-names>A</given-names></name><name><surname>Legrand</surname><given-names>LB</given-names></name><etal/><name><surname>de Gelder</surname><given-names>B</given-names></name></person-group><article-title>Neural correlates of body and face perception following bilateral destruction of the primary visual cortices</article-title><source>Frontiers in behavioral neuroscience</source><year>2014</year><volume>8</volume><fpage>30</fpage><pub-id pub-id-type="pmcid">PMC3923138</pub-id><pub-id pub-id-type="pmid">24592218</pub-id><pub-id pub-id-type="doi">10.3389/fnbeh.2014.00030</pub-id></element-citation></ref><ref id="R127"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vieira</surname><given-names>JB</given-names></name><name><surname>Wen</surname><given-names>S</given-names></name><name><surname>Oliver</surname><given-names>LD</given-names></name><name><surname>Mitchell</surname><given-names>DG</given-names></name></person-group><article-title>Enhanced conscious processing and blindsight-like detection of fear-conditioned stimuli under continuous flash suppression</article-title><source>Experimental brain research</source><year>2017</year><volume>235</volume><issue>11</issue><fpage>3333</fpage><lpage>3344</lpage><pub-id pub-id-type="pmid">28815269</pub-id></element-citation></ref><ref id="R128"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vuilleumier</surname><given-names>P</given-names></name><name><surname>Armony</surname><given-names>J</given-names></name><name><surname>Clarke</surname><given-names>K</given-names></name><name><surname>Husain</surname><given-names>M</given-names></name><name><surname>Driver</surname><given-names>J</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>Neural response to emotional faces with and without awareness: event-related fMRI in a parietal patient with visual extinction and spatial neglect</article-title><source>Neuropsychologia</source><year>2002</year><volume>40</volume><issue>12</issue><fpage>2156</fpage><lpage>2166</lpage><pub-id pub-id-type="pmid">12208011</pub-id></element-citation></ref><ref id="R129"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>M</given-names></name><name><surname>Arteaga</surname><given-names>D</given-names></name><name><surname>He</surname><given-names>BJ</given-names></name></person-group><article-title>Brain mechanisms for simple perception and bistable perception</article-title><source>Proceedings of the National Academy of Sciences</source><year>2013</year><volume>110</volume><issue>35</issue><fpage>E3350</fpage><lpage>E3359</lpage><pub-id pub-id-type="pmcid">PMC3761598</pub-id><pub-id pub-id-type="pmid">23942129</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1221945110</pub-id></element-citation></ref><ref id="R130"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watanabe</surname><given-names>N</given-names></name><name><surname>Haruno</surname><given-names>M</given-names></name></person-group><article-title>Effects of subconscious and conscious emotions on human cue-reward association learning</article-title><source>Scientific reports</source><year>2015</year><volume>5</volume><issue>1</issue><fpage>1</fpage><lpage>6</lpage><pub-id pub-id-type="pmcid">PMC4329552</pub-id><pub-id pub-id-type="pmid">25684237</pub-id><pub-id pub-id-type="doi">10.1038/srep08478</pub-id></element-citation></ref><ref id="R131"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weilnhammer</surname><given-names>V</given-names></name><name><surname>Fritsch</surname><given-names>M</given-names></name><name><surname>Chikermane</surname><given-names>M</given-names></name><name><surname>Eckert</surname><given-names>A-L</given-names></name><name><surname>Kanthak</surname><given-names>K</given-names></name><name><surname>Stuke</surname><given-names>H</given-names></name><etal/><name><surname>Sterzer</surname><given-names>P</given-names></name></person-group><article-title>An active role of inferior frontal cortex in conscious experience</article-title><source>Current biology</source><year>2021</year><volume>31</volume><issue>13</issue><fpage>2868</fpage><lpage>2880</lpage><elocation-id>e2868</elocation-id><pub-id pub-id-type="pmid">33989530</pub-id></element-citation></ref><ref id="R132"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whalen</surname><given-names>PJ</given-names></name><name><surname>Rauch</surname><given-names>SL</given-names></name><name><surname>Etcoff</surname><given-names>NL</given-names></name><name><surname>McInerney</surname><given-names>SC</given-names></name><name><surname>Lee</surname><given-names>MB</given-names></name><name><surname>Jenike</surname><given-names>MA</given-names></name></person-group><article-title>Masked presentations of emotional facial expressions modulate amygdala activity without explicit knowledge</article-title><source>Journal of Neuroscience</source><year>1998</year><volume>18</volume><issue>1</issue><fpage>411</fpage><lpage>418</lpage><pub-id pub-id-type="pmcid">PMC6793390</pub-id><pub-id pub-id-type="pmid">9412517</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.18-01-00411.1998</pub-id></element-citation></ref><ref id="R133"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wierzchoń</surname><given-names>M</given-names></name><name><surname>Paulewicz</surname><given-names>B</given-names></name><name><surname>Asanowicz</surname><given-names>D</given-names></name><name><surname>Timmermans</surname><given-names>B</given-names></name><name><surname>Cleeremans</surname><given-names>A</given-names></name></person-group><article-title>Different subjective awareness measures demonstrate the influence of visual identification on perceptual awareness ratings</article-title><source>Consciousness and cognition</source><year>2014</year><volume>27</volume><fpage>109</fpage><lpage>120</lpage><pub-id pub-id-type="pmid">24842312</pub-id></element-citation></ref><ref id="R134"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilke</surname><given-names>M</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name><name><surname>Leopold</surname><given-names>DA</given-names></name></person-group><article-title>Local field potential reflects perceptual suppression in monkey visual cortex</article-title><source>Proceedings of the National Academy of Sciences</source><year>2006</year><volume>103</volume><issue>46</issue><fpage>17507</fpage><lpage>17512</lpage><pub-id pub-id-type="pmcid">PMC1859959</pub-id><pub-id pub-id-type="pmid">17088545</pub-id><pub-id pub-id-type="doi">10.1073/pnas.0604673103</pub-id></element-citation></ref><ref id="R135"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Williams</surname><given-names>MA</given-names></name><name><surname>Morris</surname><given-names>AP</given-names></name><name><surname>McGlone</surname><given-names>F</given-names></name><name><surname>Abbott</surname><given-names>DF</given-names></name><name><surname>Mattingley</surname><given-names>JB</given-names></name></person-group><article-title>Amygdala responses to fearful and happy facial expressions under conditions of binocular suppression</article-title><source>Journal of neuroscience</source><year>2004</year><volume>24</volume><issue>12</issue><fpage>2898</fpage><lpage>2904</lpage><pub-id pub-id-type="pmcid">PMC6729857</pub-id><pub-id pub-id-type="pmid">15044528</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4977-03.2004</pub-id></element-citation></ref><ref id="R136"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Windey</surname><given-names>B</given-names></name><name><surname>Cleeremans</surname><given-names>A</given-names></name></person-group><article-title>Consciousness as a graded and an all-or-none phenomenon: A conceptual analysis</article-title><source>Consciousness and cognition</source><year>2015</year><volume>35</volume><fpage>185</fpage><lpage>191</lpage><pub-id pub-id-type="pmid">25804704</pub-id></element-citation></ref><ref id="R137"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Windey</surname><given-names>B</given-names></name><name><surname>Vermeiren</surname><given-names>A</given-names></name><name><surname>Atas</surname><given-names>A</given-names></name><name><surname>Cleeremans</surname><given-names>A</given-names></name></person-group><article-title>The graded and dichotomous nature of visual awareness</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><year>2014</year><volume>369</volume><issue>1641</issue><elocation-id>20130282</elocation-id><pub-id pub-id-type="pmcid">PMC3965170</pub-id><pub-id pub-id-type="pmid">24639587</pub-id><pub-id pub-id-type="doi">10.1098/rstb.2013.0282</pub-id></element-citation></ref><ref id="R138"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Windmann</surname><given-names>S</given-names></name><name><surname>Wehrmann</surname><given-names>M</given-names></name><name><surname>Calabrese</surname><given-names>P</given-names></name><name><surname>Güntürkün</surname><given-names>O</given-names></name></person-group><article-title>Role of the prefrontal cortex in attentional control over bistable vision</article-title><source>Journal of cognitive neuroscience</source><year>2006</year><volume>18</volume><issue>3</issue><fpage>456</fpage><lpage>471</lpage><pub-id pub-id-type="pmid">16513009</pub-id></element-citation></ref><ref id="R139"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>H</given-names></name><name><surname>Han</surname><given-names>C</given-names></name><name><surname>Chen</surname><given-names>M</given-names></name><name><surname>Li</surname><given-names>P</given-names></name><name><surname>Zhu</surname><given-names>S</given-names></name><name><surname>Fang</surname><given-names>Y</given-names></name><etal/><name><surname>Lu</surname><given-names>HD</given-names></name></person-group><article-title>Rivalry-like neural activity in primary visual cortex in anesthetized monkeys</article-title><source>Journal of neuroscience</source><year>2016</year><volume>36</volume><issue>11</issue><fpage>3231</fpage><lpage>3242</lpage><pub-id pub-id-type="pmcid">PMC6705522</pub-id><pub-id pub-id-type="pmid">26985033</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3660-15.2016</pub-id></element-citation></ref><ref id="R140"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>E</given-names></name><name><surname>Brascamp</surname><given-names>J</given-names></name><name><surname>Kang</surname><given-names>M-S</given-names></name><name><surname>Blake</surname><given-names>R</given-names></name></person-group><article-title>On the use of continuous flash suppression for the study of visual processing outside of awareness</article-title><source>Frontiers in psychology</source><year>2014</year><volume>5</volume><fpage>724</fpage><pub-id pub-id-type="pmcid">PMC4093749</pub-id><pub-id pub-id-type="pmid">25071685</pub-id><pub-id pub-id-type="doi">10.3389/fpsyg.2014.00724</pub-id></element-citation></ref><ref id="R141"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>E</given-names></name><name><surname>Zald</surname><given-names>DH</given-names></name><name><surname>Blake</surname><given-names>R</given-names></name></person-group><article-title>Fearful expressions gain preferential access to awareness during continuous flash suppression</article-title><source>Emotion</source><year>2007</year><volume>7</volume><issue>4</issue><fpage>882</fpage><pub-id pub-id-type="pmcid">PMC4038625</pub-id><pub-id pub-id-type="pmid">18039058</pub-id><pub-id pub-id-type="doi">10.1037/1528-3542.7.4.882</pub-id></element-citation></ref><ref id="R142"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zaretskaya</surname><given-names>N</given-names></name><name><surname>Thielscher</surname><given-names>A</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name><name><surname>Bartels</surname><given-names>A</given-names></name></person-group><article-title>Disrupting parietal function prolongs dominance durations in binocular rivalry</article-title><source>Current biology</source><year>2010</year><volume>20</volume><issue>23</issue><fpage>2106</fpage><lpage>2111</lpage><pub-id pub-id-type="pmid">21093263</pub-id></element-citation></ref><ref id="R143"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhan</surname><given-names>M</given-names></name><name><surname>Goebel</surname><given-names>R</given-names></name><name><surname>de Gelder</surname><given-names>B</given-names></name></person-group><article-title>Ventral and dorsal pathways relate differently to visual awareness of body postures under continuous flash suppression</article-title><source>eneuro</source><year>2018</year><volume>5</volume><issue>1</issue><pub-id pub-id-type="pmcid">PMC5810040</pub-id><pub-id pub-id-type="pmid">29445766</pub-id><pub-id pub-id-type="doi">10.1523/ENEURO.0285-17.2017</pub-id></element-citation></ref><ref id="R144"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhan</surname><given-names>M</given-names></name><name><surname>Goebel</surname><given-names>R</given-names></name><name><surname>de Gelder</surname><given-names>B</given-names></name></person-group><article-title>Subjective understanding of actions and emotions involves the interplay of the semantic and action observation networks in the brain</article-title><source>bioRxiv</source><year>2021</year><pub-id pub-id-type="doi">10.1101/2021.04.15.439961</pub-id></element-citation></ref><ref id="R145"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhan</surname><given-names>M</given-names></name><name><surname>Hortensius</surname><given-names>R</given-names></name><name><surname>de Gelder</surname><given-names>B</given-names></name></person-group><article-title>The body as a tool for anger awareness—differential effects of angry facial and bodily expressions on suppression from awareness</article-title><source>PloS one</source><year>2015</year><volume>10</volume><issue>10</issue><elocation-id>e0139768</elocation-id><pub-id pub-id-type="pmcid">PMC4607361</pub-id><pub-id pub-id-type="pmid">26469878</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0139768</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>Schematic view of a trial presentation sequence in the main experiment.</title><p>After a 1s-fixation period, a 2s-CFS period started with the gradual ramping up of the body stimulus contrast from 0% to full contrast over 1s, followed by the contrast reduction to 0% within 0.5s and a 0.5s blank period (see content within frame). The contrast of the dynamic colorful mask was constant throughout the 2s. However, both the body stimuli and the mask contrasts were determined for each trial using a staircase procedure with 10 steps (body stimuli: 5%, 14%, 23%, 32%, 41%, 50%, 50%, 50%, 50%, 50%; noise: 100%, 100%, 100%, 100%, 100%, 82%, 64%, 46%, 28%, 10%) that depended on the participant’s visual experience of the stimulus in the previous trial. After a jittered fixation period (4-6-8s), participants were required to make two active responses, each within a 1.5s window: a two-alternative forced-choice task (fear vs. neutral) and the rating of their visual experience of the stimulus according to the Perceptual Awareness Scale (PAS). The inter-trial-interval (ITI) was jittered (4-6-8s) and the average trial duration was 18s.</p></caption><graphic xlink:href="EMS158899-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Overview of behavioral results.</title><p><bold>A)</bold> Estimated marginal means of sensitivity values separated by PAS levels. Shadowed area indicates standard error from the mean; <bold>B)</bold> Estimated marginal means of criterion bias values separated by PAS levels. Shadowed area indicates standard error from the mean; <bold>C)</bold> Average proportion of responses separated by PAS and SDT measures (i.e., Hit, Miss, False alarm, Correct rejection) (see <xref ref-type="supplementary-material" rid="SD1">Supplementary Table S2</xref> for average values and standard errors). <italic>Hit</italic>: correctly categorized fearful stimuli; <italic>Miss:</italic> fearful stimuli categorized as neutral; <italic>False alarms</italic>: neutral stimuli categorized as fearful; <italic>Correct rejection</italic>: correctly categorized neutral stimuli. <bold><italic>Notes</italic></bold>: Black asterisks denote significant differences between PAS levels. Rhombi denote significant difference from zero. */♦: p &lt; .05; **/♦♦: p &lt; .01; ***/♦♦♦: p &lt; .001. <bold><italic>Abbreviations</italic></bold>: PAS: perceptual awareness scale: PAS1: ‘no experience’, PAS2: ‘brief glimpse’, PAS3: ‘almost clear experience’, PAS4: ‘clear experience’.</p></caption><graphic xlink:href="EMS158899-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Areas showing a main effect of perceptual awareness at the group level.</title><p>These ROIs resulted from the repeated measures ANOVA (N = 16) with within-subject factor Perceptual Awareness (four levels: PAS1-4) (cluster size corrected with Monte-Carlo simulation, alpha level = 0.05, initial p = 0.001, numbers of iterations = 5000). <italic>Abbreviations</italic>: <bold>FG</bold>: fusiform gyrus; <bold>IFC</bold>: inferior frontal cortex <bold>IPS</bold>: intraparietal sulcus; <bold>ITG</bold>: inferior temporal gyrus; <bold>LOTC</bold>: lateral occipito-temporal cortex; <bold>OG</bold>: occipital gyrus; <bold>preCS</bold>: precentral sulcus; <bold>pSTS</bold>: posterior superior temporal sulcus; <bold>STG</bold>: superior temporal gyrus.</p></caption><graphic xlink:href="EMS158899-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Brain responses across Perceptual Awareness levels separately for each stimuli type.</title><p>Brain responses represent %-BOLD signal changes of the ROIs showing a main effect of PAS as well as the anatomically defined amygdala and pulvinar. Shadowed area indicates standard error from the mean. <italic>Abbreviations</italic>: <bold>aIPS</bold>: anterior intraparietal sulcus; <bold>def</bold>.: definition; <bold>FG</bold>: fusiform gyrus; <bold>Fourth OG</bold>: fourth occipital gyrus; <bold>IFC</bold>: inferior frontal cortex; <bold>ITG</bold>: inferior temporal gyrus; <bold>LOTC</bold>: lateral occipito-temporal cortex; <bold>mIPS</bold>: medial intraparietal sulcus; <bold>PAS</bold>: perceptual awareness scale; <bold>pIPS</bold>: posterior intraparietal sulcus; <bold>preCS</bold>: precentral sulcus; <bold>pSTS</bold>: posterior superior temporal sulcus; <bold>SOG</bold>: superior occipital gyrus; <bold>STG</bold>: superior temporal gyrus. <bold>[l]</bold>: left hemisphere; <bold>[r]</bold>: right hemisphere.</p></caption><graphic xlink:href="EMS158899-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>Heart rate across perceptual awareness levels and emotional stimuli categories.</title><p>Heart rate (beats per minute) was baseline-corrected and averaged over the 2s-CFS period. Shadowed area indicates standard error from the mean. <italic>Abbreviations</italic>:*: p &lt; .05; <bold>HR</bold>: heart rate; <bold>PAS</bold>: perceptual awareness scale.</p></caption><graphic xlink:href="EMS158899-f005"/></fig><table-wrap id="T1" position="float" orientation="portrait"><label>Table 1</label><caption><title>Results of the linear mixed model analysis with within-subject factors Emotion and PAS and the model fitting, separately for each ROI.</title></caption><table frame="hsides" rules="groups"><thead><tr style="border-bottom: 1px solid"><th align="center" valign="middle"> </th><th align="center" valign="middle" colspan="7">PAS main effect and pairwise comparisons (Emotion<sup><xref ref-type="table-fn" rid="TFN1">*</xref></sup>Perceptual Awareness)</th><th align="center" valign="middle" rowspan="2">Activity not different from baseline</th><th align="center" valign="middle" rowspan="2">Best model</th></tr><tr><th align="center" valign="middle"> </th><th align="center" valign="middle">PAS effect</th><th align="center" valign="middle">PAS4 &gt; PAS1</th><th align="center" valign="middle">PAS4 &gt; PAS2</th><th align="center" valign="middle">PAS4 &gt; PAS3</th><th align="center" valign="middle">PAS3 &gt; PAS2</th><th align="center" valign="middle">PAS3 &gt; PAS1</th><th align="center" valign="middle">PAS2 &gt; PAS1</th></tr></thead><tbody><tr><td align="left" valign="middle"><bold>ITG [r]</bold></td><td align="left" valign="middle">F(3,12.57) = 16.11; pcorr &lt; .001</td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN3">***</xref></sup></td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN1">*</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN1">*</xref></sup></td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN2">**</xref></sup></td><td align="center" valign="middle"/><td align="left" valign="middle">N1,F1,F2</td><td align="center" valign="middle"/></tr><tr><td align="left" valign="middle"><bold>LOTC [r]</bold></td><td align="left" valign="middle">F(3,13.71) = 21.01; pcorr &lt; .001</td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN3">***</xref></sup></td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN1">*</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN2">**</xref></sup></td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN3">***</xref></sup></td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN1">*</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle">Gradual<sup><xref ref-type="table-fn" rid="TFN2">**</xref></sup></td></tr><tr><td align="left" valign="middle"><bold>FG [r]</bold></td><td align="left" valign="middle">F(3,14.91) = 13.88; pcorr &lt; .001</td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN2">**</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN1">*</xref></sup></td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN3">***</xref></sup></td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN1">*</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle"/></tr><tr><td align="left" valign="middle"><bold>AMYG [r]</bold></td><td align="left" valign="middle">F(3,16.01) = 8.51; pcorr = .002</td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN2">**</xref></sup></td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN4">†</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN1">*</xref></sup></td><td align="left" valign="middle">N1,F1,F2</td><td align="center" valign="middle"/></tr><tr><td align="left" valign="middle"><bold>Precuneus [l]</bold></td><td align="left" valign="middle">F(3,16.03) = 13.05; pcorr &lt; .001</td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN2">**</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN3">***</xref></sup></td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN4">†</xref></sup></td><td align="left" valign="middle">F1</td><td align="center" valign="middle"/></tr><tr><td align="left" valign="middle"><bold>Fourth OG [l]</bold></td><td align="left" valign="middle">F(3,14.20) = 6.13; pcorr = .007</td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN2">**</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN1">*</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle"/></tr><tr><td align="left" valign="middle"><bold>SOG [l]</bold></td><td align="left" valign="middle">F(3,12.80) = 11.25; pcorr = .001</td><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN2">**</xref></sup></td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN1">*</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle">N-gradual<sup><xref ref-type="table-fn" rid="TFN2">**</xref></sup> F-dichot.</td></tr><tr><td align="left" valign="middle"><bold>Fourth OG [l]</bold></td><td align="left" valign="middle">F(3,15.02) = 23.00; pcorr &lt; .001</td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN3">***</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN3">***</xref></sup></td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN2">**</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle"/></tr><tr><td align="left" valign="middle"><bold>aIPS [l]</bold></td><td align="left" valign="middle">F(3,15.67) = 15.13; pcorr &lt; .001</td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN3">***</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN2">**</xref></sup></td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN1">*</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle">N-dichot. F-gradual</td></tr><tr><td align="left" valign="middle"><bold>mIPS [l]</bold></td><td align="left" valign="middle">F(3,16.11) = 12.01; pcorr &lt; .001</td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN3">***</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN2">**</xref></sup></td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN1">*</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle">Dichot.<sup><xref ref-type="table-fn" rid="TFN1">*</xref></sup></td></tr><tr><td align="left" valign="middle"><bold>pIPS [l]</bold></td><td align="left" valign="middle">F(3,13.14) = 5.71; pcorr = .010</td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN1">*</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN1">*</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"/></tr><tr><td align="left" valign="middle"><bold>pSTS [l]</bold></td><td align="left" valign="middle">F(3,15.99) = 7.77; pcorr = .002</td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN2">**</xref></sup></td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN4">†</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN1">*</xref></sup></td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN1">*</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle"/></tr><tr><td align="left" valign="middle"><bold>LOTC</bold>[l]</td><td align="left" valign="middle">F(3,14.54) = 13.48; pcorr &lt; .001</td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN3">***</xref></sup></td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN1">*</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN1">*</xref></sup></td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN2">**</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"/></tr><tr><td align="left" valign="middle"><bold>IFC [l]</bold></td><td align="left" valign="middle">F(3,16.02) = 19.50; pcorr &lt; .001</td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN3">***</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN2">**</xref></sup></td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN1">*</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle">Dichot.<sup><xref ref-type="table-fn" rid="TFN1">*</xref></sup></td></tr><tr><td align="left" valign="middle"><bold>FG [l]</bold></td><td align="left" valign="middle">F(3,14.13) = 15.10; pcorr &lt; .001</td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN3">***</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN4">†</xref></sup></td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN3">***</xref></sup></td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN1">*</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle"/></tr><tr><td align="left" valign="middle"><bold>ITG [l]</bold></td><td align="left" valign="middle">F(3,13.40) = 9.65; pcorr = .002</td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN2">**</xref></sup></td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN4">†</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN1">*</xref></sup></td><td align="center" valign="middle"/><td align="left" valign="middle">N1,F1,F2</td><td align="center" valign="middle"/></tr><tr><td align="left" valign="middle"><bold>STG [l]</bold></td><td align="left" valign="middle">F(3,7.83) = 11.03; pcorr = .004</td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN1">*</xref></sup></td><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"/><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN2">**</xref></sup></td><td align="center" valign="middle"><sup><xref ref-type="table-fn" rid="TFN1">*</xref></sup></td><td align="left" valign="middle">All</td><td align="center" valign="middle"/></tr></tbody></table><table-wrap-foot><fn id="TFN1"><label>*</label><p id="P64">p<sub>corrected</sub> &lt; .05;</p></fn><fn id="TFN2"><label>**</label><p id="P65">p<sub>corrected</sub> &lt; .01;</p></fn><fn id="TFN3"><label>***</label><p id="P66">p<sub>corrected</sub> &lt; .001;</p></fn><fn id="TFN4"><label>†</label><p id="P67">p<sub>uncorrected</sub> &lt; .05;</p></fn><fn id="TFN5"><p id="P68"><italic>Abbreviations</italic>: <bold>aIPS</bold>: anterior intraparietal sulcus; <bold>AMYG</bold>: amygdala; <bold>Dichot</bold>.: dichotomous model; <bold>F</bold>: fear; <bold>FG</bold>: fusiform gyrus; <bold>IFC</bold>: inferior frontal cortex; <bold>ITG</bold>: inferior temporal gyrus; <bold>LOTC</bold>: lateral occipito-temporal cortex; <bold>mIPS</bold>: medial intraparietal sulcus; <bold>N</bold>: neutral; <bold>OG</bold>: occipital gyrus; <bold>PAS</bold>: perceptual awareness scale; <bold>pIPS</bold>: posterior intraparietal sulcus; <bold>pSTS</bold>: posterior superior temporal sulcus; <bold>SOG</bold>: superior occipital gyrus; <bold>STG</bold>: superior temporal gyrus; <bold>[l]</bold>: left hemisphere; <bold>[r]</bold>: right hemisphere.</p></fn></table-wrap-foot></table-wrap></floats-group></article>