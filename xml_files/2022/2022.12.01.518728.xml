<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS158005</article-id><article-id pub-id-type="doi">10.1101/2022.12.01.518728</article-id><article-id pub-id-type="archive">PPR578801</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>MLcps: Machine Learning Cumulative Performance Score for classification problems</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Akshay</surname><given-names>Akshay</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Abedi</surname><given-names>Masoud</given-names></name><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Shekarchizadeh</surname><given-names>Navid</given-names></name><xref ref-type="aff" rid="A3">3</xref><xref ref-type="aff" rid="A4">4</xref></contrib><contrib contrib-type="author"><name><surname>Burkhard</surname><given-names>Fiona C.</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A5">5</xref></contrib><contrib contrib-type="author"><name><surname>Katoch</surname><given-names>Mitali</given-names></name><xref ref-type="aff" rid="A6">6</xref></contrib><contrib contrib-type="author"><name><surname>Bigger-Allen</surname><given-names>Alex</given-names></name><xref ref-type="aff" rid="A7">7</xref><xref ref-type="aff" rid="A8">8</xref><xref ref-type="aff" rid="A9">9</xref><xref ref-type="aff" rid="A10">10</xref></contrib><contrib contrib-type="author"><name><surname>Adam</surname><given-names>Rosalyn M.</given-names></name><xref ref-type="aff" rid="A8">8</xref><xref ref-type="aff" rid="A9">9</xref><xref ref-type="aff" rid="A10">10</xref></contrib><contrib contrib-type="author"><name><surname>Monastyrskaya</surname><given-names>Katia</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A5">5</xref></contrib><contrib contrib-type="author"><name><surname>Gheinani</surname><given-names>Ali Hashemi</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A5">5</xref><xref ref-type="aff" rid="A8">8</xref><xref ref-type="aff" rid="A9">9</xref><xref ref-type="aff" rid="A10">10</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib></contrib-group><aff id="A1"><label>1</label>Functional Urology Research Group, Department for BioMedical Research DBMR, University of Bern, Switzerland</aff><aff id="A2"><label>2</label>Graduate School for Cellular and Biomedical Sciences, University of Bern, Switzerland</aff><aff id="A3"><label>3</label>Department of Medical Data Science, Leipzig University Medical Centre, 04107 Leipzig, Germany</aff><aff id="A4"><label>4</label>Center for Scalable Data Analytics and Artificial Intelligence (ScaDS.AI) Dresden/Leipzig, 04105 Leipzig, Germany</aff><aff id="A5"><label>5</label>Department of Urology, Inselspital University Hospital, 3010 Bern, Switzerland</aff><aff id="A6"><label>6</label>Institute of Neuropathology, Universitätsklinikum Erlangen, Friedrich-Alexander-Universität Erlangen-Nürnberg (FAU), Erlangen, Germany</aff><aff id="A7"><label>7</label>Biological &amp; Biomedical Sciences Program, Division of Medical Sciences, Harvard Medical School, Boston, MA</aff><aff id="A8"><label>8</label>Urological Diseases Research Center, Boston Children’s Hospital, MA, USA</aff><aff id="A9"><label>9</label>Harvard Medical School, Boston, Department of Surgery MA, USA</aff><aff id="A10"><label>10</label>Broad Institute of MIT and Harvard, Cambridge, MA, USA</aff><author-notes><corresp id="CR1">
<label>*</label>Corresponding author: Ali Hashemi Gheinani, Urological Diseases Research Center, Boston Children’s Hospital, Harvard Medical School and Broad Institute of MIT and Harvard, Cambridge, MA, USA <email>Ali.HashemiGheinani@childrens.harvard.edu</email></corresp></author-notes><pub-date pub-type="nihms-submitted"><day>04</day><month>12</month><year>2022</year></pub-date><pub-date pub-type="preprint"><day>02</day><month>12</month><year>2022</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nd/4.0/">CC BY-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><sec id="S1"><title>Motivation</title><p id="P1">A performance metric is a tool to measure the correctness of a trained Machine Learning (ML) model. Numerous performance metrics have been developed for classification problems making it overwhelming to select the appropriate one since each of them represents a particular aspect of the model. Furthermore, selection of a performance metric becomes harder for problems with imbalanced and/or small datasets. Therefore, in clinical studies where datasets are frequently imbalanced and, in situations when the prevalence of a disease is low or the collection of patient samples is difficult, deciding on a suitable metric for performance evaluation of an ML model becomes quite challenging. The most common approach to address this problem is measuring multiple metrics and compare them to identify the best-performing ML model. However, comparison of multiple metrics is laborious and prone to user preference bias. Furthermore, evaluation metrics are also required by ML model optimization techniques such as hyperparameter tuning, where we train many models, each with different parameters, and compare their performances to identify the best-performing parameters. In such situations, it becomes almost impossible to assess different models by comparing multiple metrics.</p></sec><sec id="S2"><title>Results</title><p id="P2">Here, we propose a new metric called Machine Learning Cumulative Performance Score (MLcps) as a Python package for classification problems. MLcps combines multiple pre-computed performance metrics into one metric that conserves the essence of all pre-computed metrics for a particular model. We tested MLcps on 4 different publicly available biological datasets and the results reveal that it provides a comprehensive picture of overall model robustness.</p></sec></abstract></article-meta></front><body><sec id="S3" sec-type="intro"><title>Introduction</title><p id="P3">Performance metrics play a crucial role in both evaluating model performance and model optimization [<xref ref-type="bibr" rid="R1">1</xref>]. Different performance metrics are widely available to evaluate and compare the performance of ML classification models. However, previous research has shown that a model that performs well based on a particular metric may not perform well on another metric [<xref ref-type="bibr" rid="R2">2</xref>–<xref ref-type="bibr" rid="R4">4</xref>]. Supervised learning algorithms (such as classification or regression problems), and unsupervised learning algorithms (such as clustering), have different evaluation metrics according to their outputs. In addition, most performance metrics are sensitive to the composition of the dataset under study [<xref ref-type="bibr" rid="R5">5</xref>].</p><p id="P4">In practice, it is not enough to measure only one metric to assess the overall performance of a model because most of the metrics give importance to a particular aspect of the model’s performance. In fact, in many practical applications, there is an unavoidable trade-off between these performance measures. Therefore, ranking a classifier “superior” in terms of a particular metric can result in a relatively “inferior” classifier in terms of another. For example, the “recall” metric can summarize how well a model can predict the positive class but gives no information about the negative class. Therefore, it becomes essential to measure and compare different performance metrics for each model to identify the best-performing model.</p><p id="P5">Although it is reasonable to expect that the best-performing model would have the highest score for all the measured metrics, this is an optimistic assumption and unlikely to be true in practice. Comparison of different metric scores for a large number of models to identify the best-performing model is labour-intensive, and this process is prone to user preference bias [<xref ref-type="bibr" rid="R6">6</xref>]. Apart from that, during the model optimization step, the goal is to identify the best-performing parameter for a model. For this purpose, a very common approach in the ML field is to train a large number of models with different parameters. In such a situation, finding the best-performing model by comparing different metrics becomes very complex.</p><p id="P6">To address this problem, we propose a new metric called Machine Learning Cumulative Performance Score (MLcps) for classification problems that combines multiple pre-computed performance metrics into one metric while preserving the essence of all pre-computed metrics for a particular model. MLcps is available as a Python package and allows the straightforward comparison of trained ML models to rank the model’s performance. The input of MLcps package is a table containing the names of classification ML algorithms and their relevant individual performance scores. The output of the package is a table and the relevant bar chart representing different ML algorithms, ranked based on a cumulative performance score, calculated by MLcps.</p></sec><sec id="S4"><title>MLcps Methodology</title><p id="P7">The input for the MLcps package is a table in which columns contain metrics (such as F1, Accuracy, and Recall) and the rows contain ML methods of choice (such as K-Nearest Neighbors (KNN) and Support-Vector Machine (SVM)). This table should be generated after performing feature extraction on raw data (<xref ref-type="fig" rid="F1">Figure 1.A</xref>), training ML algorithms (<xref ref-type="fig" rid="F1">Figure 1.B</xref>), and performance evaluation (<xref ref-type="fig" rid="F1">Figure 1.C</xref>). To calculate MLcps, first, we draw all pre-calculated performance metrics on a two-dimensional polar coordinates system (<xref ref-type="fig" rid="F1">Figure 1.D</xref>), in which each point on a plane represents an individual metric and is determined by the distance from a reference point that is a pole and an angle from a reference direction. This is similar to a radar graph, which is a circular graphing method and has a series of rays projecting from a reference point, with each ray representing a different metric label (<xref ref-type="supplementary-material" rid="SD2">Figure S1-S2</xref>).</p><p id="P8">In the polar plane, the values of the metrics are encoded into the lengths of the rays. To generate a cumulative score, we compute the area of each polar plane (<xref ref-type="fig" rid="F1">Figure 1.E</xref>). We assume that each plane is divided into multiple triangles and the sum of the individual triangles is the area of the whole plane. In addition, the area of the created surface on the polar plane is proportional to the cumulative magnitude of all metrics being analysed. Finally, the cumulative performance score (cps) is visualized as a bar chart (<xref ref-type="fig" rid="F1">Figure 1.F</xref>).</p><sec id="S5"><title>Area calculation of a two-dimensional polar surface</title><p id="P9">To calculate the cumulative performance score, we need to know the total area of a polar plane generated by multiple performance scores. The surface is then divided into multiple triangles and the sum of the area of individual triangles is the area of the whole plane (cumulative performance score). As the general formula for the area of a triangle is stated in Equation 1: the area of a triangle equals ½ the length of one side times the height drawn to that side (<xref ref-type="fig" rid="F1">Figure 1.G-N</xref>). <disp-formula id="FD1"><label>Equation 1</label><mml:math id="M1"><mml:mrow><mml:msub><mml:mrow><mml:mtext>Area</mml:mtext></mml:mrow><mml:mrow><mml:mi>Δ</mml:mi><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.2em"/><mml:mo>=</mml:mo><mml:mspace width="0.2em"/><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>a</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:math></disp-formula> <inline-graphic xlink:href="EMS158005-i001.jpg"/></p><p id="P10">where <italic>a</italic> represents the side (base)</p><p id="P11">and <italic>h</italic> represents the height drawn to that side.</p><p id="P12">To use this formula, the <italic>h</italic> is needed, which cannot be controlled in radar graph, whereas the angle of all triangles can be controlled by dividing 360 by the number of used performance metrics:</p><p id="P13">The angle between each two-performance metric on a radar graph is: <disp-formula id="FD2"><label>Equation 2</label><mml:math id="M2"><mml:mrow><mml:mtext>Angle</mml:mtext><mml:mspace width="0.2em"/><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>360</mml:mn></mml:mrow><mml:mrow><mml:mtext>Number</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>of</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>performance</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>metrics</mml:mtext></mml:mrow></mml:mfrac><mml:mo>×</mml:mo><mml:mfrac><mml:mi>π</mml:mi><mml:mrow><mml:mn>180</mml:mn></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mtext>Number</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>of</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>performance</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>metrics</mml:mtext></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p id="P14">Therefore, using trigonometry we will rewrite the area formula and express the height as follows: <disp-formula id="FD3"><label>Equation 3</label><mml:math id="M3"><mml:mrow><mml:mi>sin</mml:mi><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mi>h</mml:mi><mml:mi>b</mml:mi></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p id="P15">Therefore, the height h of the triangle can be expressed as <italic>b sin θ.</italic> Now substituting for the height h into the general formula for the area of a triangle gives: <disp-formula id="FD4"><label>Equation 4</label><mml:math id="M4"><mml:mrow><mml:msub><mml:mrow><mml:mtext>Area</mml:mtext></mml:mrow><mml:mrow><mml:mi>Δ</mml:mi><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>a</mml:mi><mml:mi>b</mml:mi><mml:mi>sin</mml:mi><mml:mi>θ</mml:mi><mml:mspace width="0.2em"/><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mspace width="0.2em"/><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mtext>Area</mml:mtext></mml:mrow><mml:mrow><mml:mi>Δ</mml:mi><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>a</mml:mi><mml:mi>b</mml:mi><mml:mi>sin</mml:mi><mml:mi>θ</mml:mi></mml:mrow></mml:math></disp-formula></p><p id="P16">where <italic>a</italic> and <italic>b</italic> can be any two sides and <italic>θ</italic> is the included angle. The parameters <italic>a</italic> and <italic>b</italic> are indeed the actual values for each performance metric.</p><p id="P17">Thus, the sum of areas of all triangles forming the polar coordinate is computed based on the following formula: <disp-formula id="FD5"><label>Equation 5</label><mml:math id="M5"><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mtext>Area</mml:mtext></mml:mrow><mml:mrow><mml:mtext>total</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>sin</mml:mi><mml:mi>θ</mml:mi><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>∑</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>→</mml:mo><mml:msub><mml:mrow><mml:mtext>Area</mml:mtext></mml:mrow><mml:mrow><mml:mtext>total</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>sin</mml:mi><mml:mi>θ</mml:mi><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>∑</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p id="P18">Where:</p><p id="P19">d<sub>i</sub> = length of the ith ray (the value of ith metric score) (<xref ref-type="fig" rid="F1">Figure 1L</xref>)</p><p id="P20">n = number of triangles point of collapse (<xref ref-type="fig" rid="F1">Figure 1M</xref>)</p></sec><sec id="S6"><title>Weighted MLcps</title><p id="P21">In particular cases, certain metrics are more significant than others. For example, if the dataset is imbalanced, a high F1 score might be preferred over higher accuracy [<xref ref-type="bibr" rid="R7">7</xref>]. A user can provide weight variables for metrics of interest while calculating MLcps in such a scenario. A weight variable provides a value (the weight) for each pre-computed metric and the given metrics score will be updated using these weights in the following way: <disp-formula id="FD6"><label>Equation 6</label><mml:math id="M6"><mml:mrow><mml:msub><mml:mtext>s</mml:mtext><mml:mrow><mml:mtext>weightedmetric</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mtext>S</mml:mtext><mml:mrow><mml:mtext>metric</mml:mtext></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mtext>W</mml:mtext><mml:mrow><mml:mtext>metric</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p id="P22">Where: <disp-formula id="FD7"><mml:math id="M7"><mml:mrow><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mtext>S</mml:mtext><mml:mrow><mml:mtext>weightedmetric</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mtext>Weighted</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>metric</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>Score</mml:mtext></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mtext>S</mml:mtext><mml:mrow><mml:mtext>metric</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mtext>Raw</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>metric</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>Score</mml:mtext></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mtext>W</mml:mtext><mml:mrow><mml:mtext>metric</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mtext>Weight</mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p id="P23">The given weight for a metric should always be greater than or equal to zero. Zero weight implies that the user wants to exclude it from the MLcps. Metrics with relatively large weights contribute more to the MLcps than metrics that have smaller weights. An unweighted MLcps is equal to a weighted analysis in which all weights are 1.</p></sec></sec><sec id="S7" sec-type="results | discussion"><title>Results and discussion</title><sec id="S8"><title>Testing MLcps on 4 different real-world dataset examples</title><p id="P24">We have used four different datasets to test MLcps (<xref ref-type="table" rid="T1">Table 1</xref>). The first dataset is an mRNA dataset (n=136) from a study of chronic lymphocytic leukemia (CLL) that measured transcriptome profiles in blood cancer patients [<xref ref-type="bibr" rid="R8">8</xref>]. Here we aimed to train a model to classify male and female patients based on their transcriptomic profiles. For that, we considered the top 5,000 most variable mRNAs after the exclusion of genes from the Y chromosome.</p><p id="P25">The second set of data is taken from a cervical cancer study that measured the expression levels of 714 miRNAs in human samples (n=58) [<xref ref-type="bibr" rid="R9">9</xref>]. The third and fourth datasets are retrieved mRNA (n=1219) and miRNA (n=1207) sequencing of Breast Invasive Carcinoma (BRCA) from The Cancer Genome Atlas (TCGA) using the TCGAbiolinks package [<xref ref-type="bibr" rid="R10">10</xref>] in R. For the BRCA mRNA dataset, we only considered differentially expressed genes from edgeR (FDR &lt;= 0.001 and logFC &gt; ±2) [<xref ref-type="bibr" rid="R11">11</xref>]. We aimed to train a model that distinguishes between normal and tumor samples for cervical cancer and TCGA-BRCA datasets. Two of these datasets are comparatively small datasets (CLL and a cervical cancer study) and the remaining two are imbalanced datasets (<xref ref-type="table" rid="T1">Table 1</xref>). For all datasets, we trained and evaluated 8 different models (<xref ref-type="supplementary-material" rid="SD1">Table S1</xref>) using an in-house developed ML pipeline to find out the best-performing models (<xref ref-type="fig" rid="F2">Figure 2</xref>).</p></sec><sec id="S9"><title>Testing MLcps robustness based on the standard deviation of performance metrics</title><p id="P26">For all datasets, except the TCGA mRNA BRCA dataset, the model with the highest MLcps has the lowest Standard Deviation (SD) in the performance metrics score (<xref ref-type="fig" rid="F3">Figure 3 A-D</xref>, <xref ref-type="fig" rid="F4">Figure 4 A-F</xref>). The Dummy model for the CLL dataset has low SD compared to the GP model (<xref ref-type="fig" rid="F3">Figure 3A</xref>) and the LDA model for the cervical cancer dataset has low SD compared to the ETC, SVM, and RF models (<xref ref-type="fig" rid="F3">Figure 3B</xref>). However, the MLcps of GP model based on the CLL dataset is higher compared to the corresponding MLcps of Dummy model, and the MLcps of ETC, SVM, and RF models for the cervical cancer dataset is higher compared to MLcps of LDA model (<xref ref-type="fig" rid="F4">Figure 4A &amp; 4B</xref>). It confirms that, besides SD, MLcps also considers the overall magnitude of performance metric score. MLcps tends to nominate a model as the best one when it has the lowest SD in metrics score but an overall high metrics score compared to other models. In <xref ref-type="fig" rid="F3">Figure 3D</xref>, LR would be chosen as the best-performing model when relying entirely on SD. However, LR is not even in the top 3 if we look at its performance on the test dataset (<xref ref-type="fig" rid="F4">Figure 4F</xref>). On the other hand, if we sort the performance of models based on MLcps, the order is almost identical on training as well as test dataset (<xref ref-type="fig" rid="F4">Figure 4C &amp; 4D</xref>, <xref ref-type="fig" rid="F4">Figure 4E &amp; 4F</xref>).</p></sec><sec id="S10"><title>Comparing the ML ranking in training and testing datasets</title><p id="P27">The TCGA-BRCA datasets are larger and thus allow us to create an independent testing set (30% of the datasets). Here the best-performing model selected based on MLcps also shows the best performance when applied to an independent test set (<xref ref-type="fig" rid="F4">Figure 4. C-F</xref>).</p></sec><sec id="S11"><title>Visualization of the importance of using multiple performance metrics</title><p id="P28">In <xref ref-type="supplementary-material" rid="SD2">Figures, S1B &amp; C</xref>, and <xref ref-type="supplementary-material" rid="SD2">Figure S2B &amp; C</xref>, the precision and average precision performance metrics showed high scores (&gt;90%) even in the dummy model for TCGA mRNA and miRNA datasets. We would have selected the wrong model as the best-performing one if we had used only precision and average precision metrics to evaluate the model performance for TCGA datasets. It demonstrates the importance of using multiple performance metrics to assess ML model performance accurately. This phenomenon is not observed in the CLL and cervical cancer datasets (<xref ref-type="supplementary-material" rid="SD2">Figure S1A</xref>, <xref ref-type="supplementary-material" rid="SD2">Figure S2A</xref>).</p></sec><sec id="S12"><title>Selection criteria for best-preforming Model</title><p id="P29">Considering that it is highly unlikely to find a model with the highest score across all measured metrics, the use of multiple metrics makes it more difficult to find the best-performing model. Alternatively, one could define a set of criteria, and a model that best meets those criteria would be considered as the best-performing model. In line with the latter approach, we have defined the following criteria for selecting the best-performing model: <list list-type="bullet" id="L1"><list-item><p id="P30"><bold>Standard Deviation (SD) in performance metric score:</bold> Since each of the performance metrics represent a particular aspect of the model’s performance, the most robust overall model will have similar scores for most of the metrics. Therefore, compared to other models, the best-performing model should have a small SD in the performance metrics score (<xref ref-type="fig" rid="F3">Figure 3 A-D</xref>).</p></list-item><list-item><p id="P31"><bold>Overall magnitude of performance metric score:</bold> There is a possibility that a model with poor performance metrics could have a smaller SD compared to other models. Hence, one cannot rely solely on the SD criterion and should also consider the overall magnitude of the metric score (<xref ref-type="fig" rid="F3">Figure 3 A-D</xref>).</p></list-item></list></p></sec></sec><sec id="S13"><title>Usage</title><p id="P32">Note: If you want to use MLcps without installing it on your local machine, please click here <ext-link ext-link-type="uri" xlink:href="https://mybinder.org/v2/gh/FunctionalUrology/MLcps.git/main">https://mybinder.org/v2/gh/FunctionalUrology/MLcps.git/main</ext-link>. It will launch a Jupyterlab server (all the requirements for MLcps are pre-installed) where you can run the already available example Jupyter notebook for MLcps analysis. It may take a while to launch! You can also upload your data or notebook to perform the analysis.</p><sec id="S14"><title>Prerequisites</title><p id="P33"><list list-type="bullet" id="L2"><list-item><p id="P34">Python &gt;=3.8</p></list-item><list-item><p id="P35">R &gt;=4.0</p></list-item><list-item><p id="P36">radarchart, tibble, and dplyr R packages. MLcps can install all these packages at first import if unavailable, but we highly recommend installing them before using MLcps. The user could run the following R code in the R environment to install them:</p></list-item></list>
<preformat>
<styled-content style="color:#8E908C">## Install the unavailable packages</styled-content>
<styled-content style="color:#4D4D4C">install.packages(c(</styled-content><styled-content style="color:#718C00">'radarchart'</styled-content><styled-content style="color:#4D4D4C">,</styled-content><styled-content style="color:#718C00">'tibble'</styled-content><styled-content style="color:#4D4D4C">,</styled-content><styled-content style="color:#718C00">'dplyr'</styled-content><styled-content style="color:#4D4D4C">),dependencies =</styled-content> <styled-content style="color:#F5871F">TRUE</styled-content><styled-content style="color:#4D4D4C">,</styled-content> <styled-content style="color:#4D4D4C">repos=</styled-content><styled-content style="color:#4D4D4C">"<ext-link ext-link-type="uri" xlink:href="https://cloud.r-project.org">https://cloud.r-project.org</ext-link>"</styled-content><styled-content style="color:#4D4D4C">)</styled-content></preformat></p></sec><sec id="S15"><title>Installation</title><p id="P37"><preformat><styled-content style="color:#4D4D4C">pip install MLcps</styled-content></preformat></p><p id="P38">Please refer to <ext-link ext-link-type="uri" xlink:href="https://github.com/FunctionalUrology/MLcps">https://github.com/FunctionalUrology/MLcps</ext-link> for a detailed tutorial.</p></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary file</label><media xlink:href="EMS158005-supplement-Supplementary_file.pdf" mimetype="application" mime-subtype="pdf" id="d21aAdEbB" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD2"><label>Supplementary Figures</label><media xlink:href="EMS158005-supplement-Supplementary_Figures.pdf" mimetype="application" mime-subtype="pdf" id="d21aAdEcB" position="anchor"/></supplementary-material></sec></body><back><ack id="S16"><title>Acknowledgment</title><p>We gratefully acknowledge the financial support of the Swiss National Science Foundation (SNF Grant 310030_175773 to FCB and KM) and the Wings for Life Spinal Cord Research Foundation (WFL-AT-06/19 to KM). AHG and RMA are supported by R01 DK 077195 and R01 DK127673. MK is supported by the Else Kröner-Fresenius-Stiftung (EKFS 2021_EKeA.33). The assistance provided by Nezhla Aghaei is greatly appreciated for guidance in the mathematical formulation and consultation in the calculation of the planar surface area. The authors acknowledge the financial support from the Federal Ministry of Education and Research of Germany and by the Sächsische Staatsministerium für Wissenschaft Kultur und Tourismus in the program Center of Excellence for AI-research “Center for Scalable Data Analytics and Artificial Intelligence Dresden/Leipzig” (project identification number: ScaDS.AI).</p></ack><fn-group><fn id="FN1" fn-type="conflict"><p id="P39"><bold>Conflict of Interest</bold></p><p id="P40">None declared.</p></fn><fn id="FN2"><p id="P41"><bold>Availability and Implementation</bold></p><p id="P42">MLcps is available as a Python package at <ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/MLcps/">https://pypi.org/project/MLcps/</ext-link> and the source code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/FunctionalUrology/MLcps">https://github.com/FunctionalUrology/MLcps</ext-link>.</p><p id="P43">MLcps is developed using Python [<xref ref-type="bibr" rid="R12">12</xref>] and R [<xref ref-type="bibr" rid="R13">13</xref>] programming languages. Pandas [<xref ref-type="bibr" rid="R14">14</xref>] is used to store and process the data. Plotly is used to generate the figures. The radarchart [<xref ref-type="bibr" rid="R15">15</xref>] package in R was used for surface area calculation of the polar plane.</p></fn><fn id="FN3"><p id="P44"><bold>Availability</bold></p><p id="P45">MLcps is available at <ext-link ext-link-type="uri" xlink:href="https://pypi.org/proiect/MLcps/">https://pypi.org/proiect/MLcps/</ext-link> and cases of use are available at <ext-link ext-link-type="uri" xlink:href="https://mybinder.org/v2/gh/FunctionalUrology/MLcps.git/main">https://mybinder.org/v2/gh/FunctionalUrology/MLcps.git/main</ext-link>.</p></fn></fn-group><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>YM</given-names></name><name><surname>Wong</surname><given-names>AKC</given-names></name><name><surname>Kamel</surname><given-names>MS</given-names></name></person-group><article-title>Classification of Imbalanced Data: A Review</article-title><source>International Journal of Pattern Recognition and Artificial Intelligence</source><year>2009</year><volume>23</volume><issue>4</issue><fpage>687</fpage><lpage>719</lpage></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>J</given-names></name><name><surname>Ling</surname><given-names>CX</given-names></name></person-group><article-title>Using AUC and accuracy in evaluating learning algorithms</article-title><source>Ieee Transactions on Knowledge and Data Engineering</source><year>2005</year><volume>17</volume><issue>3</issue><fpage>299</fpage><lpage>310</lpage></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>J</given-names></name><name><surname>Lu</surname><given-names>JJ</given-names></name><name><surname>Ling</surname><given-names>CX</given-names></name></person-group><source>Comparing naive bayes, decision trees, and SVMwith AUC and, accuracy</source><conf-name>Third Ieee International Conference on Data Mining Proceedings</conf-name><year>2003</year><fpage>553</fpage><lpage>556</lpage></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Provost</surname><given-names>F</given-names></name><name><surname>Domingos</surname><given-names>P</given-names></name></person-group><article-title>Tree induction for probability-based ranking</article-title><source>Machine Learning</source><year>2003</year><volume>52</volume><issue>3</issue><fpage>199</fpage><lpage>215</lpage></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Racz</surname><given-names>A</given-names></name><name><surname>Bajusz</surname><given-names>D</given-names></name><name><surname>Heberger</surname><given-names>K</given-names></name></person-group><article-title>Multi-Level Comparison of Machine Learning Classifiers and Their Performance Metrics</article-title><source>Molecules</source><year>2019</year><volume>24</volume><issue>15</issue><pub-id pub-id-type="pmcid">PMC6695655</pub-id><pub-id pub-id-type="pmid">31374986</pub-id><pub-id pub-id-type="doi">10.3390/molecules24152811</pub-id></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Branco</surname><given-names>P</given-names></name><name><surname>Torgo</surname><given-names>L</given-names></name><name><surname>Ribeiro</surname><given-names>RP</given-names></name></person-group><article-title>A Survey of Predictive Modeling on Im balanced Domains</article-title><source>Acm Computing Surveys</source><year>2016</year><volume>49</volume><issue>2</issue></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Galar</surname><given-names>M</given-names></name><etal/></person-group><article-title>A Review on Ensembles for the Class Imbalance Problem: Bagging-, Boosting-, and Hybrid-Based Approaches</article-title><source>Ieee Transactions on Systems Man and Cybernetics Part C-Applications and Reviews</source><year>2012</year><volume>42</volume><issue>4</issue><fpage>463</fpage><lpage>484</lpage></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dietrich</surname><given-names>S</given-names></name><etal/></person-group><article-title>Drug-perturbation-based stratification of blood cancer</article-title><source>Journal of Clinical Investigation</source><year>2018</year><volume>128</volume><issue>1</issue><fpage>427</fpage><lpage>445</lpage><pub-id pub-id-type="pmcid">PMC5749541</pub-id><pub-id pub-id-type="pmid">29227286</pub-id><pub-id pub-id-type="doi">10.1172/JCI93801</pub-id></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Witten</surname><given-names>D</given-names></name><etal/></person-group><article-title>Ultra-high throughput sequencing-based small RNA discovery and discrete statistical biomarker analysis in a collection of cervical tumours and matched controls</article-title><source>Bmc Biology</source><year>2010</year><volume>8</volume><pub-id pub-id-type="pmcid">PMC2880020</pub-id><pub-id pub-id-type="pmid">20459774</pub-id><pub-id pub-id-type="doi">10.1186/1741-7007-8-58</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Colaprico</surname><given-names>A</given-names></name><etal/></person-group><article-title>TCGAbiolinks: an R/Bioconductor package for integrative analysis of TCGA data</article-title><source>Nucleic Acids Research</source><year>2016</year><volume>44</volume><issue>8</issue><pub-id pub-id-type="pmcid">PMC4856967</pub-id><pub-id pub-id-type="pmid">26704973</pub-id><pub-id pub-id-type="doi">10.1093/nar/gkv1507</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robinson</surname><given-names>MD</given-names></name><name><surname>McCarthy</surname><given-names>DJ</given-names></name><name><surname>Smyth</surname><given-names>GK</given-names></name></person-group><article-title>edgeR: a Bioconductor package for differential expression analysis of digital gene expression data</article-title><source>Bioinformatics</source><year>2010</year><volume>26</volume><issue>1</issue><fpage>139</fpage><lpage>140</lpage><pub-id pub-id-type="pmcid">PMC2796818</pub-id><pub-id pub-id-type="pmid">19910308</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/btp616</pub-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Van Rossum</surname><given-names>G</given-names></name><name><surname>Drake</surname><given-names>FL</given-names></name></person-group><source>Python 3 Reference Manual</source><year>2009</year></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="book"><collab>Team, R.C.</collab><source>R: A language and environment for statistical computing</source><publisher-name>R Foundation for Statistical Computing</publisher-name><year>2013</year></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>McKinney</surname></name></person-group><source>Data Structures for Statistical Computing in Python</source><conf-name>Proceedings of the 9th Python in Science Conference</conf-name><year>2010</year></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Porter</surname><given-names>DAaS</given-names></name></person-group><article-title>radarchart: Radar Chart from ‘Chart.js’</article-title><source>R package version 0.3.1</source><year>2016</year></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>Schematics of a full analysis process for MLcps Python package.</title><p>Before using the MLcps Python package, one needs to prepare the raw data (A). This input table can be RNA sequencing, proteomics, patients’ profile, molecular data, etc (normally this data is in txt or csv format). Next step is to perform multiple ML algorithms (B). Performing this step can be done by any package or programming language of choice. The next step is to evaluate the performance of the ML algorithms. We recommend the use of multiple metrics such as F1, Recall, etc (C). The performance metric scores then need to be arranged in a tabular format as depicted in (C). This table will be used as an input for the MLcps package. From here on the MLcps will process the data. MLcps involves three steps: projection, calculation, and visualization (PCV). To calculate the cumulative score of each ML algorithm in the input data, MLcps first projects the performance metric onto the two-dimensional polar coordinates system (D). Next, the projected polygon’s area is calculated (E). Finally, the user can visualize this MLcps to rank the performance of given ML algorithms (F). The lower panel (G-N) visualises the procedure to calculate the surface area as cumulative score in detail. The names of the algorithms are just mentioned as example and other algorithm can be used too. ETC: Extra Trees Classifier, BC: Bagging Classifier, GP: Gaussian Process Classifier, KNN: K-Nearest Neighbors, SVM: Support Vector Machine, RF: Random Forest Classifier, LDA: Linear Discriminant Analysis, DTC: Decision Tree Classifier.</p></caption><graphic xlink:href="EMS158005-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Flowchart describing ML Pipeline</title><p>The Used ML pipeline first splits the datasets into k (3) equal size different bins in a stratified manner, where k-1 bins will be used as training datasets and the remaining bin as a test dataset. Next, it uses the univariate feature selection method for feature selection, SMOTETomek method for data resampling, and eight ML algorithms. Then, it evaluates the model performance on the test dataset using the k-fold and nested CV (k=3) method and calculates seven different performance metrics. As part of k-fold CV methods, it repeats the last two steps for each unique bin. It repeats the complete process ten times and takes average performance as a final model performance. In the end, it provides a list of the intersection of selected features from top 10 best performing models (based on F1 score) as a final list of selected features.</p></caption><graphic xlink:href="EMS158005-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Standard deviation (SD) of performance metrics score of ML algorithms trained on different example datasets.</title><p>Plots are representing A) CLL dataset, B) Cervical cancer dataset, C) TCGA miRNA dataset, and D) TCGA mRNA dataset. Each bar in a plot represents SD of performance metrics score (left y-axis), and red dot represents MLcps (right y-axis).</p></caption><graphic xlink:href="EMS158005-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Bar charts visualizing the MLcps for different example datasets.</title><p>Plots are representing A) CLL dataset, B) Cervical cancer dataset, C) TCGA miRNA training dataset, D) TCGA miRNA test dataset, E) TCGA mRNA training dataset, and F) TCGA mRNA test dataset. The color and the length of the bars represent the MLcps. The darker the color, the lower the score</p></caption><graphic xlink:href="EMS158005-f004"/></fig><table-wrap id="T1" position="float" orientation="portrait"><label>Table 1</label><caption><title>Example datasets used in this study</title></caption><table frame="box" rules="all"><thead><tr><th align="center" valign="top">Dataset</th><th align="center" valign="top">Data type</th><th align="center" valign="top">Number of Samples</th><th align="center" valign="top">Number of Features</th><th align="center" valign="top">Target Class ratio</th></tr></thead><tbody><tr><td align="center" valign="middle">CLL</td><td align="center" valign="middle">mRNA</td><td align="center" valign="middle">136</td><td align="center" valign="middle">5000</td><td align="center" valign="middle">Male (n=82): Female (n=54)</td></tr><tr><td align="center" valign="middle">Cervical cancer</td><td align="center" valign="middle">miRNA</td><td align="center" valign="middle">58</td><td align="center" valign="middle">714</td><td align="center" valign="middle">Normal (n=29): Tumor (n=29)</td></tr><tr><td align="center" valign="middle">TCGA-BRCA</td><td align="center" valign="middle">miRNA</td><td align="center" valign="middle">1207</td><td align="center" valign="middle">1404</td><td align="center" valign="middle">Normal (n=104): Tumor (n=1104)</td></tr><tr><td align="center" valign="middle">TCGA-BRCA</td><td align="center" valign="middle">mRNA</td><td align="center" valign="middle">1219</td><td align="center" valign="middle">5520</td><td align="center" valign="middle">Normal (n=113): Tumor (n=1106)</td></tr></tbody></table></table-wrap></floats-group></article>