<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS157794</article-id><article-id pub-id-type="doi">10.1101/2022.11.28.518224</article-id><article-id pub-id-type="archive">PPR576792</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">3</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Fast protein structure searching using structure graph embeddings</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Greener</surname><given-names>Joe G</given-names></name><email>jgreener@mrc-lmb.cam.ac.uk</email><aff id="A1"><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00tw3jy02</institution-id><institution>Medical Research Council Laboratory of Molecular Biology</institution></institution-wrap><city>Cambridge</city>, <country country="GB">UK</country></aff></contrib><contrib contrib-type="author"><name><surname>Jamali</surname><given-names>Kiarash</given-names></name><aff id="A2"><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00tw3jy02</institution-id><institution>Medical Research Council Laboratory of Molecular Biology</institution></institution-wrap><city>Cambridge</city>, <country country="GB">UK</country></aff></contrib></contrib-group><pub-date pub-type="nihms-submitted"><day>30</day><month>11</month><year>2022</year></pub-date><pub-date pub-type="preprint"><day>28</day><month>11</month><year>2022</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Comparing and searching protein structures independent of primary sequence has proved useful for remote homology detection, function annotation and protein classification. Fast and accurate methods to search with structures will be essential to make use of the vast databases that have recently become available, in the same way that fast protein sequence searching underpins much of bioinformatics. We train a simple graph neural network using supervised contrastive learning to learn a low-dimensional embedding of protein structure. The method, called Progres, is available as software at <ext-link ext-link-type="uri" xlink:href="https://github.com/greener-group/progres">https://github.com/greener-group/progres</ext-link> and as a web server at <ext-link ext-link-type="uri" xlink:href="https://progres.mrc-lmb.cam.ac.uk">https://progres.mrc-lmb.cam.ac.uk</ext-link>. It has accuracy comparable to the best current methods and can search the AlphaFold database TED domains in a tenth of a second per query on CPU.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">A variety of methods have been developed to compare, align and search with protein structures [<xref ref-type="bibr" rid="R1">1</xref>]. Since structure is more conserved than sequence [<xref ref-type="bibr" rid="R2">2</xref>] these methods have proved useful in remote homology detection [<xref ref-type="bibr" rid="R3">3</xref>], protein classification [<xref ref-type="bibr" rid="R4">4</xref>], inferring function from structure [<xref ref-type="bibr" rid="R5">5</xref>], clustering large databases [<xref ref-type="bibr" rid="R6">6</xref>, <xref ref-type="bibr" rid="R7">7</xref>] and assessing the accuracy of structure predictions. Global coordinate comparisons like TM-align [<xref ref-type="bibr" rid="R8">8</xref>] provide interpretable scores that are comparable across protein size, with a challenge being how to align the residues independent of the primary sequence. Mathematical representations of 3D space such as 3D Zernike descriptors [<xref ref-type="bibr" rid="R9">9</xref>, <xref ref-type="bibr" rid="R10">10</xref>] avoid this issue but are limited in accuracy. Other approaches include comparing residue-residue distances [<xref ref-type="bibr" rid="R11">11</xref>–<xref ref-type="bibr" rid="R14">14</xref>], which can access precise geometries conserved in the structural core, and considering local geometry [<xref ref-type="bibr" rid="R15">15</xref>]. The highest accuracy methods tend to be careful comparisons based on coordinates like Dali [<xref ref-type="bibr" rid="R13">13</xref>], but searching large structural databases such as the AlphaFold Protein Structure Database [<xref ref-type="bibr" rid="R16">16</xref>, <xref ref-type="bibr" rid="R17">17</xref>] or the ESM Metagenomic Atlas [<xref ref-type="bibr" rid="R18">18</xref>] with these methods is slow. Recently Foldseek [<xref ref-type="bibr" rid="R19">19</xref>] has addressed this problem by converting protein structure into a sequence of learned local tertiary motifs. It then uses the rich history of fast sequence searching in bioinformatics to dramatically reduce the pairwise comparison time of the query with each member of the database. It follows that to further reduce search time, the pairwise comparison step should be made even faster.</p><p id="P3">Inspired by the impressive performance of simple graph neural networks (GNNs) using coordinate information for a variety of molecular tasks [<xref ref-type="bibr" rid="R20">20</xref>], we decided to train a model to embed protein structures into a low-dimensional representation. Two embeddings can be compared very quickly by cosine similarity and a query can be compared to each member of a pre-embedded database in a vectorised manner on CPU or GPU. It makes sense to use expertly-curated classifications of protein structures when training such an embedding [<xref ref-type="bibr" rid="R21">21</xref>, <xref ref-type="bibr" rid="R4">4</xref>, <xref ref-type="bibr" rid="R22">22</xref>]; we use supervised contrastive learning [<xref ref-type="bibr" rid="R23">23</xref>] to allow the embedding to be learned in a manner that reflects such an understanding of protein structure space and returns search results consistent with it.</p><p id="P4">A number of recent methods have used protein structure graph embeddings [<xref ref-type="bibr" rid="R24">24</xref>–<xref ref-type="bibr" rid="R26">26</xref>] and contrastive learning [<xref ref-type="bibr" rid="R26">26</xref>–<xref ref-type="bibr" rid="R28">28</xref>]. Embedding protein folds has also been done using residue-level features [<xref ref-type="bibr" rid="R29">29</xref>, <xref ref-type="bibr" rid="R7">7</xref>], and GNNs acting on protein structure have been used for function prediction [<xref ref-type="bibr" rid="R30">30</xref>]. Other studies have used unsupervised contrastive learning on protein structures and show that the representations are useful for downstream prediction tasks including protein structural similarity [<xref ref-type="bibr" rid="R31">31</xref>–<xref ref-type="bibr" rid="R33">33</xref>]. Contrastive learning using protein classifications has also improved language models for protein sequences, showing clustering that better preserves protein structure space [<xref ref-type="bibr" rid="R34">34</xref>]. Protein structure has been incorporated into language models more broadly, often with the intention of searching for remote homology [<xref ref-type="bibr" rid="R35">35</xref>–<xref ref-type="bibr" rid="R40">40</xref>]. Progres provides a fast and accurate alternative to these methods that is available as a web server and as software.</p></sec><sec id="S2" sec-type="results"><title>Results</title><p id="P5">We trained a simple GNN, called Progres (PROtein GRaph Embedding Search), to embed a protein structure independent of its sequence (see <xref ref-type="fig" rid="F1">Figure 1A</xref>). Since we use distance and torsion angle features based on coordinates the embedding is SE(3)-invariant, i.e. it doesn’t change with translation or rotation of the input structure. As shown in <xref ref-type="fig" rid="F1">Figure 1B</xref>, supervised contrastive learning [<xref ref-type="bibr" rid="R23">23</xref>] on SCOPe domains [<xref ref-type="bibr" rid="R21">21</xref>, <xref ref-type="bibr" rid="R41">41</xref>] is used to train the model, moving domains closer or further apart in the embedding space depending on whether they are in the same SCOPe family or not. Sinusoidal position encoding [<xref ref-type="bibr" rid="R42">42</xref>] is also used to allow the model to effectively use information on the sequence separation of residues. The main intended use of such an embedding is fast searching for similar structures by comparing the embedding of a query structure to the pre-computed embeddings of a database of structures. Our model does not give structural alignments, but if these are required they can be computed with tools like Dali after fast initial filtering with Progres. The impact of changing model hyperparameters is shown in <xref ref-type="supplementary-material" rid="SD1">Table S1</xref>. The distribution of values across the embedding dimensions is shown in <xref ref-type="supplementary-material" rid="SD1">Figure S1</xref>.</p><p id="P6">In order to assess the accuracy of the model for structure searching, we follow a similar procedure to Foldseek [<xref ref-type="bibr" rid="R19">19</xref>]. Since our model is trained on SCOPe domains it is important not to use domains for training that appear in the test set. We select a random set of 400 domains from the Astral 2.08 40% sequence identity set for testing. No domains in the training set have a sequence identity of 30% or more to these 400 domains. This represents the realistic use case that the query structure has not been seen during training - for example it is a predicted or new experimental structure - but other domains in the family may have been seen during training. The easier case of searching with the exact domains used for training gives superior results that are not reported here, and the harder case of searching with completely unseen folds is discussed later.</p><p id="P7">As shown in <xref ref-type="table" rid="T1">Table 1</xref> our model has sensitivity comparable to Dali [<xref ref-type="bibr" rid="R13">13</xref>] and Foldseek-TM [<xref ref-type="bibr" rid="R19">19</xref>] for recovering domains in SCOPe from the same fold, superfamily and family. Its strong performance at the fold level indicates an ability to find remote homologs. Progres is more sensitive than the EAT [<xref ref-type="bibr" rid="R34">34</xref>] and ESM-2 [<xref ref-type="bibr" rid="R18">18</xref>] protein language model embeddings, and also the baseline sequence searching method of MMseqs2 [<xref ref-type="bibr" rid="R43">43</xref>]. This indicates the benefits of comparing structures rather than just sequences for detecting homology. <xref ref-type="fig" rid="F2">Figure 2A-C</xref> shows the performance across different SCOPe classes, protein sizes and contact orders. Progres does particularly well on all-β domains, smaller domains and domains with higher contact order. This ability to do well in cases where residues separate in sequence form contacts is possibly due to the lack of primary sequence information in the embedding, compared to a method like Foldseek that retains the sequence order for searching. It has lower performance on membrane proteins and larger domains. As shown in <xref ref-type="fig" rid="F2">Figure 2D</xref>, performance drops when the number of embedding dimensions is below 32.</p><p id="P8">For searching a single structure against SCOPe on CPU the model is faster than Foldseek with most run time in Python module loading. For example, going from 1 to 100 query structures increases run time from 1.3 s to 2.4 s. When searching with multiple structures, most run time is in generating the query structure embeddings. Consequently, the speed benefits of the method arise when searching a structure or structures against the pre-computed embeddings of a huge database such as the AlphaFold database [<xref ref-type="bibr" rid="R10">10</xref>, <xref ref-type="bibr" rid="R6">6</xref>, <xref ref-type="bibr" rid="R7">7</xref>]. The recent TED study split the whole AlphaFold database into domains using a consensus-based approach [<xref ref-type="bibr" rid="R45">45</xref>]. We embed the TED domains clustered at 50% sequence identity and use FAISS [<xref ref-type="bibr" rid="R46">46</xref>] to considerably speed up the search time against the resultant database of 53 million structures. This allows a search time of a tenth of a second per query on CPU, after an initial data loading time of around a minute. Since we search exhaustively with FAISS, the results are not changed, though the approximate score calculation means the similarity score does vary slightly from the exact value. For the SCOPe test set used above, the mean difference between FAISS and exact similarity scores for the top hit is 0.006. As shown in <xref ref-type="supplementary-material" rid="SD1">Figure S2</xref>, the best TM-align score to the query among the top 5 hits has a mean of 0.80 across the SCOPe test set, with 94% being over 0.5. This indicates that searching is accurate even when using a large database.</p><p id="P9"><xref ref-type="fig" rid="F3">Figure 3</xref> shows 2D t-SNE embeddings [<xref ref-type="bibr" rid="R47">47</xref>] of the 128 dimensions of our model embedding. This shows the lower-dimensional protein fold space [<xref ref-type="bibr" rid="R48">48</xref>–<xref ref-type="bibr" rid="R50">50</xref>] created by our embedding. SCOPe classes tend to cluster together, with α+β folds appearing between the all-α and all-β folds which show little overlap. There is a clear protein size gradient across the t-SNE embedding. A t-SNE embedding for the AlphaFold database TED domains compared to ECOD [<xref ref-type="bibr" rid="R22">22</xref>] and the AlphaFold 21 organisms set [<xref ref-type="bibr" rid="R17">17</xref>, <xref ref-type="bibr" rid="R51">51</xref>] shows the volume of new structural information available in the AlphaFold database. The Progres score between two embeddings is the cosine similarity score normalised to run between 0 and 1, with 1 indicating identical embeddings. As shown in <xref ref-type="fig" rid="F3">Figure 3E</xref> a Progres score of 0.8 indicates that two proteins share the same fold, analogous to a TM-align score of 0.5.</p></sec><sec id="S3" sec-type="discussion"><title>Discussion</title><p id="P10">The model presented here is trained and validated on protein domains; due to the domain-specific nature of the training it is not expected to work without modification on protein chains containing multiple domains, long disordered regions or complexes. Fortunately, there are a number of tools such as Chainsaw [<xref ref-type="bibr" rid="R52">52</xref>], Merizo [<xref ref-type="bibr" rid="R53">53</xref>] and SWORD2 [<xref ref-type="bibr" rid="R54">54</xref>] that can split query structures into domains. We integrate Chainsaw into Progres to allow automated splitting of query structures into domains, with each domain then searched separately. This can overcome issues that arise from searching with multiple domains at the same time, such as missing related proteins due to differing orientations of the domains. Splitting with Chainsaw takes a few seconds per query. The web server allows visualisation of query and hit domains. As shown in <xref ref-type="supplementary-material" rid="SD1">Figure S3</xref> the Progres embeddings are fairly robust to truncating residues from the termini, with truncations of 20 residues giving an embedding with a similarity of 0.8 to the full length domain embedding for 89% of domains with 200-299 residues. This means that minor inaccuracies in predicting domain boundaries are unlikely to cause a problem.</p><p id="P11">One issue with supervised learning on domains is whether performance drops when searching with domains that the model has not seen anything similar to during training. We trained an identical model on a different dataset where 200 domains were used for testing and domains were removed from the training set if they were from the same SCOPe superfamily as any of the testing domains. The fold, superfamily and family sensitivities analogous to <xref ref-type="table" rid="T1">Table 1</xref> are 0.190, 0.383 and 0.546 respectively. This indicates similar performance at finding distantly related folds, the main use of structure searching over sequence searching, though there is a drop in performance at finding closely-related domains.</p><p id="P12">Aside from searching for similar structures, an accurate protein structure embedding has a number of uses. Fast protein comparison is useful for clustering large sets of structures, for example to identify novel folds in the AlphaFold database [<xref ref-type="bibr" rid="R6">6</xref>, <xref ref-type="bibr" rid="R7">7</xref>, <xref ref-type="bibr" rid="R45">45</xref>]. The embedding of a structure is just a set of numbers, and therefore can be targeted by differentiable approaches for applications like protein design. A decoder could be trained to generate structures from the embedding space [<xref ref-type="bibr" rid="R55">55</xref>, <xref ref-type="bibr" rid="R56">56</xref>], and a diffusion model to move through the embedding space. Properties of proteins such as evolution [<xref ref-type="bibr" rid="R57">57</xref>], topological classification [<xref ref-type="bibr" rid="R58">58</xref>], the completeness of protein fold space [<xref ref-type="bibr" rid="R59">59</xref>], the continuity of fold space [<xref ref-type="bibr" rid="R60">60</xref>], function [<xref ref-type="bibr" rid="R61">61</xref>] and dynamics could also be explored in the context of the low-dimensional fold space. Structure embeddings could also be used to identify regions of unknown density in cryo-electron tomography studies. We believe that the extremely fast pairwise comparison allowed by structural embeddings is an effective way to take advantage of the opportunities provided by the million-structure era.</p></sec><sec id="S4" sec-type="methods"><title>Methods</title><sec id="S5"><title>Training</title><p id="P13">Structures in the Astral 2.08 95% sequence identity set including discontinuous domains were used for training [<xref ref-type="bibr" rid="R62">62</xref>]. We chose 400 domains randomly from the Astral 2.08 40% sequence identity set to use as a test set (see below) and another 200 domains to use as a validation set to monitor training. We removed domains with 30% or greater sequence identity to these 600 domains using MMseqs2 [<xref ref-type="bibr" rid="R43">43</xref>], and also removed domains with fewer than 20 or more than 500 residues. This left 30,549 domains in 4,862 families for training.</p><p id="P14">mmCIF files were downloaded and processed with Biopython [<xref ref-type="bibr" rid="R63">63</xref>]. Some processing was also carried out with BioStructures.jl [<xref ref-type="bibr" rid="R64">64</xref>]. Cα atoms were extracted for the residues corresponding to the domain. Each Cα atom is treated as a node with the following features: number of Cα atoms within 10 Å divided by the largest such number in the protein, whether the Cα atom is at the N-terminus, whether the Cα atom is at the C-terminus, and a 64-dimensional sinusoidal positional encoding for the residue number in the domain [<xref ref-type="bibr" rid="R42">42</xref>].</p><p id="P15">PyTorch was used for training [<xref ref-type="bibr" rid="R65">65</xref>]. The neural network architecture was similar to the E(n)-equivariant GNN in Satorras et al. 2021 [<xref ref-type="bibr" rid="R20">20</xref>]. We used a PyTorch implementation (<ext-link ext-link-type="uri" xlink:href="https://github.com/lucidrains/egnn-pytorch">https://github.com/lucidrains/egnn-pytorch</ext-link>) and a configuration similar to the molecular data prediction task, i.e. not updating the particle position. In this case the model is analogous to a standard GNN with relative squared norms inputted to the edge operation [<xref ref-type="bibr" rid="R20">20</xref>]. Edges are sparse and are between Cα atoms within 10 Å of each other. 6 such layers with residual connections are preceded by a one-layer multilayer perceptron (MLP) acting on node features and followed by a two-layer MLP acting on node features. Node features are then sum-pooled and a two-layer MLP generates the output embedding, which is normalised. Each hidden layer has 128 dimensions and uses the Swish/SiLU activation function [<xref ref-type="bibr" rid="R66">66</xref>], apart from the edge MLP in the GNN which has a hidden layer with 256 dimensions and 64-dimensional output. The final embedding has 128 dimensions.</p><p id="P16">Supervised contrastive learning [<xref ref-type="bibr" rid="R23">23</xref>] is used for training. Each epoch cycles over the 4,862 training families. For each family, 5 other families are chosen randomly. For each of these 6 families, 6 domains from the family present in the training set are chosen randomly. If there are fewer than 6 domains in the family, duplicates are added to give 6. This set of 36 domains with 6 unique labels is embedded with the model and the embeddings are used to calculate the supervised contrastive loss with a temperature of 0.1 [<xref ref-type="bibr" rid="R23">23</xref>]. During training only, Gaussian noise with variance 1.0 Å is added to the x, y and z coordinates of each Cα atom. Training was carried out with the Adam optimiser [<xref ref-type="bibr" rid="R67">67</xref>] with learning rate 5 x 10<sup>−5</sup> and weight decay 1 x 10<sup>−16</sup>. Each set of 36 domains was treated as one batch. Training was stopped after 500 epochs and the epoch with the best family sensitivity on the validation set was used as the final model. Training took around a week on one RTX A6000 GPU.</p></sec><sec id="S6"><title>Testing</title><p id="P17">For testing a similar approach to Foldseek was adopted [<xref ref-type="bibr" rid="R19">19</xref>]. The 15,177 Astral 2.08 40% sequence identity set domains were embedded with the model. The embeddings are stored as Float16 to reduce the size of large databases on disk, but this has no effect on search performance as shown in <xref ref-type="supplementary-material" rid="SD1">Table S1</xref>. 400 of these domains were chosen randomly and held out of the training data as described previously. Like Foldseek, we only chose domains with at least one other family, superfamily and fold member. For each of these 400 domains, the cosine similarity of embeddings to each of the 15,177 domains was calculated and the domains ranked by similarity with the query domain included. For each domain, we measured the fraction of TPs detected up to the first incorrect fold detected. TPs are same family in the case of family-level recognition, same superfamily and not same family in the case of superfamily-level recognition, and same fold and not same superfamily in the case of fold-level recognition. We also report the mean TM-align score and the fraction of hits with the same fold for the top 20 hits for each query.</p><p id="P18">All CPU methods were run on an Intel i9-10980XE CPU and with 256 GB RAM. Progres, Foldseek and MMseqs2 were run on 16 threads. The GPU methods were run on a RTX A6000 GPU. Progres was run with PyTorch 1.11. Foldseek version 8.ef4e960 was used. For TM-align we used the fast mode, which has similar performance to the normal mode [<xref ref-type="bibr" rid="R19">19</xref>]. For 3D-SURFER the neural network model and mainchain atoms were used. EAT was run with the “-use_tucker 1” flag. ESM-2 embeddings used the esm2_t36_3B_UR50D model which has a 2560-dimensional embedding. The mean of the perresidue representations was normalised and comparison between sequences was carried out with cosine similarity. For MMseqs2, easy-search with a sensitivity of 7.5 was used.</p><p id="P19">For contact order, all residue pairs with Cβ atoms (Cα for glycine) within 8 Å are considered. The contact order of a structure is then defined as <disp-formula id="FD1"><mml:math id="M1"><mml:mrow><mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mi>∑</mml:mi><mml:mi>i</mml:mi><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula> where <italic>Si</italic> is the sequence separation of the residues in contacting pair i, <italic>N</italic> is the number of contacting pairs and <italic>L</italic> is the sequence length of the protein.</p></sec><sec id="S7"><title>Databases</title><p id="P20">The AlphaFold database domain embeddings were prepared from the TED set of domains [<xref ref-type="bibr" rid="R45">45</xref>] using cluster representatives from clustering at 50% sequence identity. Clustering was carried out with MMseqs2 using the command “mmseqs easy-cluster ted_100.fasta clusterRes tmp-min-seq-id 0.5 -c 0.9 −cov-mode 5 -s 7.5”. This gave 53,344,209 clusters, fewer than the TED analysis due to the use of easy-cluster over easy-linclust. The FAISS [<xref ref-type="bibr" rid="R46">46</xref>] index was prepared using “IndexFlat?P(128)”, which carries out exhaustive searching using the same cosine similarity as Progres. Query structures may be automatically split into domains before searching using Chainsaw [<xref ref-type="bibr" rid="R52">52</xref>], with each domain searched separately.</p></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary Material</label><media xlink:href="EMS157794-supplement-Supplementary_Material.pdf" mimetype="application" mime-subtype="pdf" id="d29aAcEbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S8"><title>Acknowledgements</title><p>We thank the UCL Bioinformatics Group for useful discussions and Jake Grimmett, Toby Darling and Ivan Clayson for help with high-performance computing and web server deployment. KJ is a member of the group of Sjors Scheres. This work was supported by the Medical Research Council, as part of United Kingdom Research and Innovation (also known as UK Research and Innovation) [MC_UP_1201/33 to JGG and MC_UP_A025-1013 to SS]. For the purpose of open access, the MRC Laboratory of Molecular Biology has applied a CC BY public copyright licence to any Author Accepted Manuscript version arising.</p></ack><sec id="S9" sec-type="data-availability"><title>Availability</title><p id="P21">A Python package allowing structure searching and generation of pre-embedded databases is available along with datasets, training scripts and benchmarking scripts under a permissive license at <ext-link ext-link-type="uri" xlink:href="https://github.com/greener-group/progres">https://github.com/greener-group/progres</ext-link>. The trained model and pre-embedded databases are available at <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/record/7782088">https://zenodo.org/record/7782088</ext-link>. A web server for searching is available at <ext-link ext-link-type="uri" xlink:href="https://progres.mrc-lmb.cam.ac.uk">https://progres.mrc-lmb.cam.ac.uk</ext-link>.</p></sec><ref-list><ref id="R1"><label>[1]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasegawa</surname><given-names>H</given-names></name><name><surname>Holm</surname><given-names>L</given-names></name></person-group><article-title>Advances and pitfalls of protein structural alignment</article-title><source>Curr Opin Struct Biol</source><year>2009</year><volume>19</volume><issue>3</issue><fpage>341</fpage><lpage>348</lpage><pub-id pub-id-type="pmid">19481444</pub-id></element-citation></ref><ref id="R2"><label>[2]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Illergård</surname><given-names>K</given-names></name><name><surname>Ardell</surname><given-names>DH</given-names></name><name><surname>Elofsson</surname><given-names>A</given-names></name></person-group><article-title>Structure is three to ten times more conserved than sequence-a study of structural response in protein cores</article-title><source>Proteins</source><year>2009</year><volume>77</volume><issue>3</issue><fpage>499</fpage><lpage>508</lpage><pub-id pub-id-type="pmid">19507241</pub-id></element-citation></ref><ref id="R3"><label>[3]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Al-Fatlawi</surname><given-names>A</given-names></name><name><surname>Menzel</surname><given-names>M</given-names></name><name><surname>Schroeder</surname><given-names>M</given-names></name></person-group><article-title>Is Protein BLAST a thing of the past?</article-title><source>Nat Commun</source><year>2023</year><volume>14</volume><elocation-id>8195</elocation-id><pub-id pub-id-type="pmcid">PMC10713564</pub-id><pub-id pub-id-type="pmid">38081865</pub-id><pub-id pub-id-type="doi">10.1038/s41467-023-44082-5</pub-id></element-citation></ref><ref id="R4"><label>[4]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sillitoe</surname><given-names>I</given-names></name><name><surname>Bordin</surname><given-names>N</given-names></name><name><surname>Dawson</surname><given-names>N</given-names></name><name><surname>Waman</surname><given-names>VP</given-names></name><name><surname>Ashford</surname><given-names>P</given-names></name><name><surname>Scholes</surname><given-names>HM</given-names></name><name><surname>Pang</surname><given-names>CSM</given-names></name><name><surname>Woodridge</surname><given-names>L</given-names></name><name><surname>Rauer</surname><given-names>C</given-names></name><name><surname>Sen</surname><given-names>N</given-names></name><name><surname>Abbasian</surname><given-names>M</given-names></name><etal/></person-group><article-title>CATH: increased structural coverage of functional space</article-title><source>Nucleic Acids Res</source><year>2021</year><volume>49</volume><issue>D1</issue><fpage>D266</fpage><lpage>D273</lpage><pub-id pub-id-type="pmcid">PMC7778904</pub-id><pub-id pub-id-type="pmid">33237325</pub-id><pub-id pub-id-type="doi">10.1093/nar/gkaa1079</pub-id></element-citation></ref><ref id="R5"><label>[5]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>C</given-names></name><name><surname>Freddolino</surname><given-names>PL</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name></person-group><article-title>COFACTOR: improved protein function prediction by combining structure, sequence and protein-protein interaction information</article-title><source>Nucleic Acids Res</source><year>2017</year><volume>45</volume><issue>W1</issue><fpage>W291</fpage><lpage>W299</lpage><pub-id pub-id-type="pmcid">PMC5793808</pub-id><pub-id pub-id-type="pmid">28472402</pub-id><pub-id pub-id-type="doi">10.1093/nar/gkx366</pub-id></element-citation></ref><ref id="R6"><label>[6]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barrio-Hernandez</surname><given-names>I</given-names></name><name><surname>Yeo</surname><given-names>J</given-names></name><name><surname>Janes</surname><given-names>J</given-names></name><name><surname>Mirdita</surname><given-names>M</given-names></name><name><surname>Gilchrist</surname><given-names>CLM</given-names></name><name><surname>Wein</surname><given-names>T</given-names></name><name><surname>Varadi</surname><given-names>M</given-names></name><name><surname>Velankar</surname><given-names>S</given-names></name><name><surname>Beltrao</surname><given-names>P</given-names></name><name><surname>Steinegger</surname><given-names>M</given-names></name></person-group><article-title>Clustering predicted structures at the scale of the known protein universe</article-title><source>Nature</source><year>2023</year><volume>622</volume><fpage>637</fpage><lpage>645</lpage><pub-id pub-id-type="pmcid">PMC10584675</pub-id><pub-id pub-id-type="pmid">37704730</pub-id><pub-id pub-id-type="doi">10.1038/s41586-023-06510-w</pub-id></element-citation></ref><ref id="R7"><label>[7]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Durairaj</surname><given-names>J</given-names></name><name><surname>Waterhouse</surname><given-names>AM</given-names></name><name><surname>Mets</surname><given-names>T</given-names></name><name><surname>Brodiazhenko</surname><given-names>T</given-names></name><name><surname>Abdullah</surname><given-names>M</given-names></name><name><surname>Studer</surname><given-names>G</given-names></name><name><surname>Tauriello</surname><given-names>G</given-names></name><name><surname>Akdel</surname><given-names>M</given-names></name><name><surname>Andreeva</surname><given-names>A</given-names></name><name><surname>Bateman</surname><given-names>A</given-names></name><name><surname>Tenson</surname><given-names>T</given-names></name><etal/></person-group><article-title>Uncovering new families and folds in the natural protein universe</article-title><source>Nature</source><year>2023</year><volume>622</volume><fpage>646</fpage><lpage>653</lpage><pub-id pub-id-type="pmcid">PMC10584680</pub-id><pub-id pub-id-type="pmid">37704037</pub-id><pub-id pub-id-type="doi">10.1038/s41586-023-06622-3</pub-id></element-citation></ref><ref id="R8"><label>[8]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Skolnick</surname><given-names>J</given-names></name></person-group><article-title>TM-align: a protein structure alignment algorithm based on the TM-score</article-title><source>Nucleic Acids Res</source><year>2005</year><volume>33</volume><issue>7</issue><fpage>2302</fpage><lpage>2309</lpage><pub-id pub-id-type="pmcid">PMC1084323</pub-id><pub-id pub-id-type="pmid">15849316</pub-id><pub-id pub-id-type="doi">10.1093/nar/gki524</pub-id></element-citation></ref><ref id="R9"><label>[9]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guzenko</surname><given-names>D</given-names></name><name><surname>Burley</surname><given-names>SK</given-names></name><name><surname>Duarte</surname><given-names>JM</given-names></name></person-group><article-title>Real time structural search of the Protein Data Bank</article-title><source>PLoS Comput Biol</source><year>2020</year><volume>16</volume><issue>7</issue><elocation-id>e1007970</elocation-id><pub-id pub-id-type="pmcid">PMC7371193</pub-id><pub-id pub-id-type="pmid">32639954</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007970</pub-id></element-citation></ref><ref id="R10"><label>[10]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aderinwale</surname><given-names>T</given-names></name><name><surname>Bharadwaj</surname><given-names>V</given-names></name><name><surname>Christoffer</surname><given-names>C</given-names></name><name><surname>Terashi</surname><given-names>G</given-names></name><name><surname>Zhang</surname><given-names>Z</given-names></name><name><surname>Jahandideh</surname><given-names>R</given-names></name><name><surname>Kagaya</surname><given-names>Y</given-names></name><name><surname>Kihara</surname><given-names>D</given-names></name></person-group><article-title>Real-time structure search and structure classification for AlphaFold protein models</article-title><source>Commun Biol</source><year>2022</year><volume>5</volume><issue>1</issue><fpage>316</fpage><pub-id pub-id-type="pmcid">PMC8983703</pub-id><pub-id pub-id-type="pmid">35383281</pub-id><pub-id pub-id-type="doi">10.1038/s42003-022-03261-8</pub-id></element-citation></ref><ref id="R11"><label>[11]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taylor</surname><given-names>WR</given-names></name><name><surname>Orengo</surname><given-names>CA</given-names></name></person-group><article-title>Protein structure alignment</article-title><source>J Mol Biol</source><year>1989</year><volume>208</volume><issue>1</issue><fpage>1</fpage><lpage>22</lpage><pub-id pub-id-type="pmid">2769748</pub-id></element-citation></ref><ref id="R12"><label>[12]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Ye</surname><given-names>Q</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Peng</surname><given-names>J</given-names></name></person-group><article-title>Learning structural motif representations for efficient protein structure search</article-title><source>Bioinformatics</source><year>2018</year><volume>34</volume><fpage>i773</fpage><lpage>i780</lpage><pub-id pub-id-type="pmcid">PMC6129266</pub-id><pub-id pub-id-type="pmid">30423083</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/bty585</pub-id></element-citation></ref><ref id="R13"><label>[13]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holm</surname><given-names>L</given-names></name></person-group><article-title>Using Dali for Protein Structure Comparison</article-title><source>Methods Mol Biol</source><year>2020</year><volume>2112</volume><fpage>29</fpage><lpage>42</lpage><pub-id pub-id-type="pmid">32006276</pub-id></element-citation></ref><ref id="R14"><label>[14]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guo</surname><given-names>Z</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Ou</surname><given-names>G</given-names></name></person-group><article-title>Utilizing the Scale-Invariant feature transform algorithm to align distance matrices facilitates systematic protein structure comparison</article-title><source>Bioinformatics</source><year>2024</year><volume>40</volume><issue>3</issue><elocation-id>btae064</elocation-id><pub-id pub-id-type="pmcid">PMC10924749</pub-id><pub-id pub-id-type="pmid">38318777</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/btae064</pub-id></element-citation></ref><ref id="R15"><label>[15]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shindyalov</surname><given-names>IN</given-names></name><name><surname>Bourne</surname><given-names>PE</given-names></name></person-group><article-title>Protein structure alignment by incremental combinatorial extension (CE) of the optimal path</article-title><source>Protein Eng</source><year>1998</year><volume>11</volume><issue>9</issue><fpage>739</fpage><lpage>747</lpage><pub-id pub-id-type="pmid">9796821</pub-id></element-citation></ref><ref id="R16"><label>[16]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jumper</surname><given-names>J</given-names></name><name><surname>Evans</surname><given-names>R</given-names></name><name><surname>Pritzel</surname><given-names>A</given-names></name><name><surname>Green</surname><given-names>T</given-names></name><name><surname>Figurnov</surname><given-names>M</given-names></name><name><surname>Ronneberger</surname><given-names>O</given-names></name><name><surname>Tunyasuvunakool</surname><given-names>K</given-names></name><name><surname>Bates</surname><given-names>R</given-names></name><name><surname>Zídek</surname><given-names>A</given-names></name><name><surname>Potapenko</surname><given-names>A</given-names></name><name><surname>Bridgland</surname><given-names>A</given-names></name><etal/></person-group><article-title>Highly accurate protein structure prediction with AlphaFold</article-title><source>Nature</source><year>2021</year><volume>596</volume><issue>7873</issue><fpage>583</fpage><lpage>589</lpage><pub-id pub-id-type="pmcid">PMC8371605</pub-id><pub-id pub-id-type="pmid">34265844</pub-id><pub-id pub-id-type="doi">10.1038/s41586-021-03819-2</pub-id></element-citation></ref><ref id="R17"><label>[17]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Varadi</surname><given-names>M</given-names></name><name><surname>Anyango</surname><given-names>S</given-names></name><name><surname>Deshpande</surname><given-names>M</given-names></name><name><surname>Nair</surname><given-names>S</given-names></name><name><surname>Natassia</surname><given-names>C</given-names></name><name><surname>Yordanova</surname><given-names>G</given-names></name><name><surname>Yuan</surname><given-names>D</given-names></name><name><surname>Stroe</surname><given-names>O</given-names></name><name><surname>Wood</surname><given-names>G</given-names></name><name><surname>Laydon</surname><given-names>A</given-names></name><name><surname>Zídek</surname><given-names>A</given-names></name><etal/></person-group><article-title>AlphaFold Protein Structure Database: massively expanding the structural coverage of protein-sequence space with high-accuracy models</article-title><source>Nucleic Acids Res</source><year>2022</year><volume>50</volume><issue>D1</issue><fpage>D439</fpage><lpage>D444</lpage><pub-id pub-id-type="pmcid">PMC8728224</pub-id><pub-id pub-id-type="pmid">34791371</pub-id><pub-id pub-id-type="doi">10.1093/nar/gkab1061</pub-id></element-citation></ref><ref id="R18"><label>[18]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>Z</given-names></name><name><surname>Akin</surname><given-names>H</given-names></name><name><surname>Rao</surname><given-names>R</given-names></name><name><surname>Hie</surname><given-names>B</given-names></name><name><surname>Zhu</surname><given-names>Z</given-names></name><name><surname>Lu</surname><given-names>W</given-names></name><name><surname>Smetanin</surname><given-names>N</given-names></name><name><surname>Verkuil</surname><given-names>R</given-names></name><name><surname>Kabeli</surname><given-names>O</given-names></name><name><surname>Shmueli</surname><given-names>Y</given-names></name><name><surname>dos Santos Costa</surname><given-names>A</given-names></name><etal/></person-group><article-title>Evolutionary-scale prediction of atomic-level protein structure with a language model</article-title><source>Science</source><year>2023</year><volume>379</volume><issue>6637</issue><fpage>1123</fpage><lpage>1130</lpage><pub-id pub-id-type="pmid">36927031</pub-id></element-citation></ref><ref id="R19"><label>[19]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Kempen</surname><given-names>M</given-names></name><name><surname>Kim</surname><given-names>SS</given-names></name><name><surname>Tumescheit</surname><given-names>C</given-names></name><name><surname>Mirdita</surname><given-names>M</given-names></name><name><surname>Lee</surname><given-names>J</given-names></name><name><surname>Gilchrist</surname><given-names>CLM</given-names></name><name><surname>Soding</surname><given-names>J</given-names></name><name><surname>Steinegger</surname><given-names>M</given-names></name></person-group><article-title>Fast and accurate protein structure search with Foldseek</article-title><source>Nature Biotechnology</source><year>2023</year><volume>42</volume><fpage>243</fpage><lpage>246</lpage><pub-id pub-id-type="pmcid">PMC10869269</pub-id><pub-id pub-id-type="pmid">37156916</pub-id><pub-id pub-id-type="doi">10.1038/s41587-023-01773-0</pub-id></element-citation></ref><ref id="R20"><label>[20]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Satorras</surname><given-names>VG</given-names></name><name><surname>Hoogeboom</surname><given-names>E</given-names></name><name><surname>Welling</surname><given-names>M</given-names></name></person-group><article-title>E(n) equivariant graph neural networks</article-title><year>2021</year><comment>URL <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2102.09844">https://arxiv.org/abs/2102.09844</ext-link></comment></element-citation></ref><ref id="R21"><label>[21]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chandonia</surname><given-names>JM</given-names></name><name><surname>Fox</surname><given-names>NK</given-names></name><name><surname>Brenner</surname><given-names>SE</given-names></name></person-group><article-title>SCOPe: classification of large macromolecular structures in the structural classification of proteins-extended database</article-title><source>Nucleic Acids Res</source><year>2019</year><volume>47</volume><issue>D1</issue><fpage>D475</fpage><lpage>D481</lpage><pub-id pub-id-type="pmcid">PMC6323910</pub-id><pub-id pub-id-type="pmid">30500919</pub-id><pub-id pub-id-type="doi">10.1093/nar/gky1134</pub-id></element-citation></ref><ref id="R22"><label>[22]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheng</surname><given-names>H</given-names></name><name><surname>Schaeffer</surname><given-names>RD</given-names></name><name><surname>Liao</surname><given-names>Y</given-names></name><name><surname>Kinch</surname><given-names>LN</given-names></name><name><surname>Pei</surname><given-names>J</given-names></name><name><surname>Shi</surname><given-names>S</given-names></name><name><surname>Kim</surname><given-names>BH</given-names></name><name><surname>Grishin</surname><given-names>NV</given-names></name></person-group><article-title>ECOD: an evolutionary classification of protein domains</article-title><source>PLoS Comput Biol</source><year>2014</year><volume>10</volume><issue>12</issue><elocation-id>e1003926</elocation-id><pub-id pub-id-type="pmcid">PMC4256011</pub-id><pub-id pub-id-type="pmid">25474468</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003926</pub-id></element-citation></ref><ref id="R23"><label>[23]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khosla</surname><given-names>P</given-names></name><name><surname>Teterwak</surname><given-names>P</given-names></name><name><surname>Wang</surname><given-names>C</given-names></name><name><surname>Sarna</surname><given-names>A</given-names></name><name><surname>Tian</surname><given-names>Y</given-names></name><name><surname>Isola</surname><given-names>P</given-names></name><name><surname>Maschinot</surname><given-names>A</given-names></name><name><surname>Liu</surname><given-names>C</given-names></name><name><surname>Krishnan</surname><given-names>D</given-names></name></person-group><article-title>Supervised contrastive learning</article-title><year>2020</year><comment>URL <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2004.11362">https://arxiv.org/abs/2004.11362</ext-link></comment></element-citation></ref><ref id="R24"><label>[24]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kandathil</surname><given-names>SM</given-names></name><name><surname>Lau</surname><given-names>AM</given-names></name><name><surname>Jones</surname><given-names>DT</given-names></name></person-group><article-title>Foldclass and Merizo-search: embedding-based deep learning tools for protein domain segmentation, fold recognition and comparison</article-title><source>bioRxiv</source><year>2024</year><comment>URL <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/early/2024/03/29/2024.03.25.586696">https://www.biorxiv.org/content/early/2024/03/29/2024.03.25.586696</ext-link></comment></element-citation></ref><ref id="R25"><label>[25]</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>C</given-names></name><name><surname>Zha</surname><given-names>Y</given-names></name><name><surname>Zhu</surname><given-names>D</given-names></name><name><surname>Ning</surname><given-names>K</given-names></name><name><surname>Cui</surname><given-names>X</given-names></name></person-group><source>Hydrogen bonds meet self-attention: all you need for protein structure embedding</source><conf-name>2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)</conf-name><year>2021</year><fpage>12</fpage><lpage>17</lpage></element-citation></ref><ref id="R26"><label>[26]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xia</surname><given-names>C</given-names></name><name><surname>Feng</surname><given-names>S-H</given-names></name><name><surname>Xia</surname><given-names>Y</given-names></name><name><surname>Pan</surname><given-names>X</given-names></name><name><surname>Shen</surname><given-names>H-B</given-names></name></person-group><article-title>Fast protein structure comparison through effective representation learning with contrastive graph neural networks</article-title><source>PLoS Comput Biol</source><year>2022</year><volume>18</volume><issue>3</issue><elocation-id>e1009986</elocation-id><pub-id pub-id-type="pmcid">PMC8982879</pub-id><pub-id pub-id-type="pmid">35324898</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1009986</pub-id></element-citation></ref><ref id="R27"><label>[27]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luo</surname><given-names>J</given-names></name><name><surname>Luo</surname><given-names>Y</given-names></name></person-group><article-title>Contrastive learning of protein representations with graph neural networks for structural and functional annotations</article-title><source>Pac Symp Biocomput</source><year>2023</year><volume>28</volume><fpage>109</fpage><lpage>120</lpage><pub-id pub-id-type="pmid">36540969</pub-id></element-citation></ref><ref id="R28"><label>[28]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hamamsy</surname><given-names>T</given-names></name><name><surname>Barot</surname><given-names>M</given-names></name><name><surname>Morton</surname><given-names>JT</given-names></name><name><surname>Steinegger</surname><given-names>M</given-names></name><name><surname>Bonneau</surname><given-names>R</given-names></name><name><surname>Cho</surname><given-names>K</given-names></name></person-group><article-title>Learning sequence, structure, and function representations of proteins with language models</article-title><source>bioRxiv</source><year>2023</year><comment>URL <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/early/2023/11/26/2023.11.26.568742">https://www.biorxiv.org/content/early/2023/11/26/2023.11.26.568742</ext-link></comment></element-citation></ref><ref id="R29"><label>[29]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Villegas-Morcillo</surname><given-names>A</given-names></name><name><surname>Sanchez</surname><given-names>V</given-names></name><name><surname>Gomez</surname><given-names>AM</given-names></name></person-group><article-title>FoldHSphere: deep hyperspherical embeddings for protein fold recognition</article-title><source>BMC Bioinformatics</source><year>2021</year><volume>22</volume><issue>490</issue><pub-id pub-id-type="pmcid">PMC8507389</pub-id><pub-id pub-id-type="pmid">34641786</pub-id><pub-id pub-id-type="doi">10.1186/s12859-021-04419-7</pub-id></element-citation></ref><ref id="R30"><label>[30]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gligorijevié</surname><given-names>V</given-names></name><name><surname>Renfrew</surname><given-names>PD</given-names></name><name><surname>Kosciolek</surname><given-names>T</given-names></name><name><surname>Leman</surname><given-names>JK</given-names></name><name><surname>Berenberg</surname><given-names>D</given-names></name><name><surname>Vatanen</surname><given-names>T</given-names></name><name><surname>Chandler</surname><given-names>C</given-names></name><name><surname>Taylor</surname><given-names>BC</given-names></name><name><surname>Fisk</surname><given-names>IM</given-names></name><name><surname>Vlamakis</surname><given-names>H</given-names></name><name><surname>Xavier</surname><given-names>RJ</given-names></name><etal/></person-group><article-title>Structure-based protein function prediction using graph convolutional networks</article-title><source>Nat Commun</source><year>2021</year><volume>12</volume><elocation-id>3168</elocation-id><pub-id pub-id-type="pmcid">PMC8155034</pub-id><pub-id pub-id-type="pmid">34039967</pub-id><pub-id pub-id-type="doi">10.1038/s41467-021-23303-9</pub-id></element-citation></ref><ref id="R31"><label>[31]</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Z</given-names></name><name><surname>Xu</surname><given-names>M</given-names></name><name><surname>Jamasb</surname><given-names>AR</given-names></name><name><surname>Chenthamarakshan</surname><given-names>V</given-names></name><name><surname>Lozano</surname><given-names>A</given-names></name><name><surname>Das</surname><given-names>P</given-names></name><name><surname>Tang</surname><given-names>J</given-names></name></person-group><source>Protein representation learning by geometric structure pretraining</source><conf-name>First Workshop on Pre-training: Perspectives, Pitfalls, and Paths Forward at ICML 2022</conf-name><year>2022</year></element-citation></ref><ref id="R32"><label>[32]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hermosilla</surname><given-names>P</given-names></name><name><surname>Ropinski</surname><given-names>T</given-names></name></person-group><article-title>Contrastive representation learning for 3D protein structures</article-title><year>2022</year><comment>URL <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2205.15675">https://arxiv.org/abs/2205.15675</ext-link></comment></element-citation></ref><ref id="R33"><label>[33]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>C</given-names></name><name><surname>Zhou</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>F</given-names></name><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Dou</surname><given-names>D</given-names></name></person-group><article-title>Structure-aware protein self-supervised learning</article-title><year>2022</year><comment>URL <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2204.04213">https://arxiv.org/abs/2204.04213</ext-link></comment><pub-id pub-id-type="pmcid">PMC10139775</pub-id><pub-id pub-id-type="pmid">37052532</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/btad189</pub-id></element-citation></ref><ref id="R34"><label>[34]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heinzinger</surname><given-names>M</given-names></name><name><surname>Littmann</surname><given-names>M</given-names></name><name><surname>Sillitoe</surname><given-names>I</given-names></name><name><surname>Bordin</surname><given-names>N</given-names></name><name><surname>Orengo</surname><given-names>C</given-names></name><name><surname>Rost</surname><given-names>B</given-names></name></person-group><article-title>Contrastive learning on protein embeddings enlightens midnight zone</article-title><source>NAR Genomics and Bioinformatics</source><year>2022</year><volume>4</volume><issue>2</issue><elocation-id>lqac043</elocation-id><pub-id pub-id-type="pmcid">PMC9188115</pub-id><pub-id pub-id-type="pmid">35702380</pub-id><pub-id pub-id-type="doi">10.1093/nargab/lqac043</pub-id></element-citation></ref><ref id="R35"><label>[35]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hamamsy</surname><given-names>T</given-names></name><name><surname>Morton</surname><given-names>JT</given-names></name><name><surname>Blackwell</surname><given-names>R</given-names></name><name><surname>Berenberg</surname><given-names>D</given-names></name><name><surname>Carriero</surname><given-names>N</given-names></name><name><surname>Gligorijevic</surname><given-names>V</given-names></name><name><surname>Strauss</surname><given-names>CEM</given-names></name><name><surname>Leman</surname><given-names>JK</given-names></name><name><surname>Cho</surname><given-names>K</given-names></name><name><surname>Bonneau</surname><given-names>R</given-names></name></person-group><article-title>Protein remote homology detection and structural alignment using deep learning</article-title><source>Nat Biotechnol</source><year>2023</year><pub-id pub-id-type="pmcid">PMC11180608</pub-id><pub-id pub-id-type="pmid">37679542</pub-id><pub-id pub-id-type="doi">10.1038/s41587-023-01917-2</pub-id></element-citation></ref><ref id="R36"><label>[36]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>W</given-names></name><name><surname>Wang</surname><given-names>Z</given-names></name><name><surname>You</surname><given-names>R</given-names></name><name><surname>Xie</surname><given-names>C</given-names></name><name><surname>Wei</surname><given-names>H</given-names></name><name><surname>Xiong</surname><given-names>Y</given-names></name><name><surname>Yang</surname><given-names>J</given-names></name><name><surname>Zhu</surname><given-names>S</given-names></name></person-group><article-title>PLMSearch: Protein language model powers accurate and fast sequence search for remote homology</article-title><source>Nat Commun</source><year>2024</year><volume>15</volume><elocation-id>2775</elocation-id><pub-id pub-id-type="pmcid">PMC10981738</pub-id><pub-id pub-id-type="pmid">38555371</pub-id><pub-id pub-id-type="doi">10.1038/s41467-024-46808-5</pub-id></element-citation></ref><ref id="R37"><label>[37]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Shen</surname><given-names>H-B</given-names></name></person-group><article-title>FoldExplorer: Fast and Accurate Protein Structure Search with Sequence-Enhanced Graph Embedding</article-title><year>2023</year><comment>URL <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2311.18219">https://arxiv.org/abs/2311.18219</ext-link></comment></element-citation></ref><ref id="R38"><label>[38]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>G</given-names></name><name><surname>Huang</surname><given-names>Y</given-names></name><name><surname>Hu</surname><given-names>B</given-names></name><name><surname>Li</surname><given-names>S</given-names></name><name><surname>Tan</surname><given-names>C</given-names></name><name><surname>Fan</surname><given-names>X</given-names></name><name><surname>Li</surname><given-names>SZ</given-names></name></person-group><article-title>Lightweight contrastive protein structure-sequence transformation</article-title><year>2023</year><comment>URL <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2303.11783">https://arxiv.org/abs/2303.11783</ext-link></comment></element-citation></ref><ref id="R39"><label>[39]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iovino</surname><given-names>BG</given-names></name><name><surname>Tang</surname><given-names>H</given-names></name><name><surname>Ye</surname><given-names>Y</given-names></name></person-group><article-title>Protein domain embeddings for fast and accurate similarity search</article-title><source>Genome Res</source><year>2024</year><volume>34</volume><fpage>1434</fpage><lpage>1444</lpage><pub-id pub-id-type="pmcid">PMC11529836</pub-id><pub-id pub-id-type="pmid">39237301</pub-id><pub-id pub-id-type="doi">10.1101/gr.279127.124</pub-id></element-citation></ref><ref id="R40"><label>[40]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heinzinger</surname><given-names>M</given-names></name><name><surname>Weissenow</surname><given-names>K</given-names></name><name><surname>Sanchez</surname><given-names>JG</given-names></name><name><surname>Henkel</surname><given-names>A</given-names></name><name><surname>Mirdita</surname><given-names>M</given-names></name><name><surname>Steinegger</surname><given-names>M</given-names></name><name><surname>Rost</surname><given-names>B</given-names></name></person-group><article-title>Bilingual language model for protein sequence and structure</article-title><source>NAR Genomics and Bioinformatics</source><year>2023</year><volume>6</volume><issue>4</issue><elocation-id>lqae150</elocation-id><pub-id pub-id-type="pmcid">PMC11616678</pub-id><pub-id pub-id-type="pmid">39633723</pub-id><pub-id pub-id-type="doi">10.1093/nargab/lqae150</pub-id></element-citation></ref><ref id="R41"><label>[41]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andreeva</surname><given-names>A</given-names></name><name><surname>Kulesha</surname><given-names>E</given-names></name><name><surname>Gough</surname><given-names>J</given-names></name><name><surname>Murzin</surname><given-names>AG</given-names></name></person-group><article-title>The SCOP database in 2020: expanded classification of representative family and superfamily domains of known protein structures</article-title><source>Nucleic Acids Res</source><year>2020</year><volume>48</volume><issue>D1</issue><fpage>D376</fpage><lpage>D382</lpage><pub-id pub-id-type="pmcid">PMC7139981</pub-id><pub-id pub-id-type="pmid">31724711</pub-id><pub-id pub-id-type="doi">10.1093/nar/gkz1064</pub-id></element-citation></ref><ref id="R42"><label>[42]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vaswani</surname><given-names>A</given-names></name><name><surname>Shazeer</surname><given-names>N</given-names></name><name><surname>Parmar</surname><given-names>N</given-names></name><name><surname>Uszkoreit</surname><given-names>J</given-names></name><name><surname>Jones</surname><given-names>L</given-names></name><name><surname>Gomez</surname><given-names>AN</given-names></name><name><surname>Kaiser</surname><given-names>L</given-names></name><name><surname>Polosukhin</surname><given-names>I</given-names></name></person-group><article-title>Attention is all you need</article-title><year>2017</year><comment>URL <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</ext-link></comment></element-citation></ref><ref id="R43"><label>[43]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steinegger</surname><given-names>M</given-names></name><name><surname>Söding</surname><given-names>J</given-names></name></person-group><article-title>MMseqs2 enables sensitive protein sequence searching for the analysis of massive data sets</article-title><source>Nat Biotechnol</source><year>2017</year><volume>35</volume><issue>11</issue><fpage>1026</fpage><lpage>1028</lpage><pub-id pub-id-type="pmid">29035372</pub-id></element-citation></ref><ref id="R44"><label>[44]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xiong</surname><given-names>Y</given-names></name><name><surname>Esquivel-Rodriguez</surname><given-names>J</given-names></name><name><surname>Sael</surname><given-names>L</given-names></name><name><surname>Kihara</surname><given-names>D</given-names></name></person-group><article-title>3D-SURFER 2.0: Web Platform for Real-Time Search and Characterization of Protein Surfaces</article-title><source>Methods Mol Biol</source><year>2014</year><volume>1137</volume><fpage>105</fpage><lpage>117</lpage><pub-id pub-id-type="pmid">24573477</pub-id></element-citation></ref><ref id="R45"><label>[45]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lau</surname><given-names>AM</given-names></name><name><surname>Bordin</surname><given-names>N</given-names></name><name><surname>Kandathil</surname><given-names>SM</given-names></name><name><surname>Sillitoe</surname><given-names>I</given-names></name><name><surname>Waman</surname><given-names>VP</given-names></name><name><surname>Wells</surname><given-names>J</given-names></name><name><surname>Orengo</surname><given-names>CA</given-names></name><name><surname>Jones</surname><given-names>DT</given-names></name></person-group><article-title>Exploring structural diversity across the protein universe with The Encyclopedia of Domains</article-title><source>Science</source><year>2024</year><volume>386</volume><issue>6721</issue><pub-id pub-id-type="pmid">39480926</pub-id></element-citation></ref><ref id="R46"><label>[46]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Douze</surname><given-names>M</given-names></name><name><surname>Guzhva</surname><given-names>A</given-names></name><name><surname>Deng</surname><given-names>C</given-names></name><name><surname>Johnson</surname><given-names>J</given-names></name><name><surname>Szilvasy</surname><given-names>G</given-names></name><name><surname>Mazaré</surname><given-names>P-E</given-names></name><name><surname>Lomeli</surname><given-names>M</given-names></name><name><surname>Hosseini</surname><given-names>L</given-names></name><name><surname>Jégou</surname><given-names>H</given-names></name></person-group><source>The Faiss library</source><year>2024</year><comment>URL <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2401.08281">https://arxiv.org/abs/2401.08281</ext-link></comment></element-citation></ref><ref id="R47"><label>[47]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Maaten</surname><given-names>L</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><article-title>Visualizing data using t-SNE</article-title><source>Journal of Machine Learning Research</source><year>2008</year><volume>9</volume><issue>86</issue><fpage>2579</fpage><lpage>2605</lpage></element-citation></ref><ref id="R48"><label>[48]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holm</surname><given-names>L</given-names></name><name><surname>Sander</surname><given-names>C</given-names></name></person-group><article-title>Touring protein fold space with Dali/FSSP</article-title><source>Nucleic Acids Res</source><year>1998</year><volume>26</volume><issue>1</issue><fpage>316</fpage><lpage>319</lpage><pub-id pub-id-type="pmcid">PMC147193</pub-id><pub-id pub-id-type="pmid">9399863</pub-id><pub-id pub-id-type="doi">10.1093/nar/26.1.316</pub-id></element-citation></ref><ref id="R49"><label>[49]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kolodny</surname><given-names>R</given-names></name><name><surname>Pereyaslavets</surname><given-names>L</given-names></name><name><surname>Samson</surname><given-names>AO</given-names></name><name><surname>Levitt</surname><given-names>M</given-names></name></person-group><article-title>On the universe of protein folds</article-title><source>Annu Rev Biophys</source><year>2013</year><volume>42</volume><fpage>559</fpage><lpage>582</lpage><pub-id pub-id-type="pmid">23527781</pub-id></element-citation></ref><ref id="R50"><label>[50]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nepomnyachiy</surname><given-names>S</given-names></name><name><surname>Ben-Tal</surname><given-names>N</given-names></name><name><surname>Kolodny</surname><given-names>R</given-names></name></person-group><article-title>Global view of the protein universe</article-title><source>Proc Natl Acad Sci U S A</source><year>2014</year><volume>111</volume><issue>32</issue><fpage>11691</fpage><lpage>11696</lpage><pub-id pub-id-type="pmcid">PMC4136566</pub-id><pub-id pub-id-type="pmid">25071170</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1403395111</pub-id></element-citation></ref><ref id="R51"><label>[51]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bordin</surname><given-names>N</given-names></name><name><surname>Sillitoe</surname><given-names>I</given-names></name><name><surname>Nallapareddy</surname><given-names>V</given-names></name><name><surname>Rauer</surname><given-names>C</given-names></name><name><surname>Lam</surname><given-names>SD</given-names></name><name><surname>Waman</surname><given-names>VP</given-names></name><name><surname>Sen</surname><given-names>N</given-names></name><name><surname>Heinzinger</surname><given-names>M</given-names></name><name><surname>Littmann</surname><given-names>M</given-names></name><name><surname>Kim</surname><given-names>S</given-names></name><name><surname>Velankar</surname><given-names>S</given-names></name><etal/></person-group><article-title>AlphaFold2 reveals commonalities and novelties in protein structure space for 21 model organisms</article-title><source>Commun Biol</source><year>2023</year><volume>6</volume><issue>1</issue><fpage>160</fpage><pub-id pub-id-type="pmcid">PMC9908985</pub-id><pub-id pub-id-type="pmid">36755055</pub-id><pub-id pub-id-type="doi">10.1038/s42003-023-04488-9</pub-id></element-citation></ref><ref id="R52"><label>[52]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wells</surname><given-names>J</given-names></name><name><surname>Hawkins-Hooker</surname><given-names>A</given-names></name><name><surname>Bordin</surname><given-names>N</given-names></name><name><surname>Sillitoe</surname><given-names>I</given-names></name><name><surname>Paige</surname><given-names>B</given-names></name><name><surname>Orengo</surname><given-names>C</given-names></name></person-group><article-title>Chainsaw: protein domain segmentation with fully convolutional neural networks</article-title><source>Bioinformatics</source><year>2024</year><volume>40</volume><issue>5</issue><elocation-id>btae296</elocation-id><pub-id pub-id-type="pmcid">PMC11256964</pub-id><pub-id pub-id-type="pmid">38718225</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/btae296</pub-id></element-citation></ref><ref id="R53"><label>[53]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lau</surname><given-names>AM</given-names></name><name><surname>Kandathil</surname><given-names>SM</given-names></name><name><surname>Jones</surname><given-names>DT</given-names></name></person-group><article-title>Merizo: a rapid and accurate protein domain segmentation method using invariant point attention</article-title><source>Nat Commun</source><year>2023</year><volume>14</volume><elocation-id>8445</elocation-id><pub-id pub-id-type="pmcid">PMC10730818</pub-id><pub-id pub-id-type="pmid">38114456</pub-id><pub-id pub-id-type="doi">10.1038/s41467-023-43934-4</pub-id></element-citation></ref><ref id="R54"><label>[54]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cretin</surname><given-names>G</given-names></name><name><surname>Galochkina</surname><given-names>T</given-names></name><name><surname>Vander Meersche</surname><given-names>Y</given-names></name><name><surname>de Brevern</surname><given-names>AG</given-names></name><name><surname>Postic</surname><given-names>G</given-names></name><name><surname>Gelly</surname><given-names>J-C</given-names></name></person-group><article-title>SWORD2: hierarchical analysis of protein 3D structures</article-title><source>Nucleic Acids Research</source><year>2022</year><volume>50</volume><issue>W1</issue><fpage>W732</fpage><lpage>W738</lpage><pub-id pub-id-type="pmcid">PMC9252838</pub-id><pub-id pub-id-type="pmid">35580056</pub-id><pub-id pub-id-type="doi">10.1093/nar/gkac370</pub-id></element-citation></ref><ref id="R55"><label>[55]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guo</surname><given-names>X</given-names></name><name><surname>Du</surname><given-names>Y</given-names></name><name><surname>Tadepalli</surname><given-names>S</given-names></name><name><surname>Zhao</surname><given-names>L</given-names></name><name><surname>Shehu</surname><given-names>A</given-names></name></person-group><article-title>Generating tertiary protein structures via an interpretative variational autoencoder</article-title><year>2020</year><comment>URL <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2004.07119">https://arxiv.org/abs/2004.07119</ext-link></comment><pub-id pub-id-type="pmcid">PMC9710582</pub-id><pub-id pub-id-type="pmid">36700110</pub-id><pub-id pub-id-type="doi">10.1093/bioadv/vbab036</pub-id></element-citation></ref><ref id="R56"><label>[56]</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Ingraham</surname><given-names>J</given-names></name><name><surname>Garg</surname><given-names>VK</given-names></name><name><surname>Barzilay</surname><given-names>R</given-names></name><name><surname>Jaakkola</surname><given-names>T</given-names></name></person-group><source>Generative models for graph-based protein design</source><conf-name>Proceedings of the 33rd International Conference on Neural Information Processing Systems</conf-name><year>2019</year></element-citation></ref><ref id="R57"><label>[57]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname><given-names>X</given-names></name><name><surname>Zou</surname><given-names>Z</given-names></name><name><surname>Brooks</surname><given-names>CL</given-names><suffix>III</suffix></name></person-group><article-title>Deciphering protein evolution and fitness landscapes with latent space models</article-title><source>Nat Commun</source><year>2019</year><volume>10</volume><elocation-id>5644</elocation-id><pub-id pub-id-type="pmcid">PMC6904478</pub-id><pub-id pub-id-type="pmid">31822668</pub-id><pub-id pub-id-type="doi">10.1038/s41467-019-13633-0</pub-id></element-citation></ref><ref id="R58"><label>[58]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taylor</surname><given-names>WR</given-names></name></person-group><article-title>A ‘periodic table’ for protein structures</article-title><source>Nature</source><year>2002</year><volume>416</volume><issue>6881</issue><fpage>657</fpage><lpage>660</lpage><pub-id pub-id-type="pmid">11948354</pub-id></element-citation></ref><ref id="R59"><label>[59]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cossio</surname><given-names>P</given-names></name><name><surname>Trovato</surname><given-names>A</given-names></name><name><surname>Pietrucci</surname><given-names>F</given-names></name><name><surname>Seno</surname><given-names>F</given-names></name><name><surname>Maritan</surname><given-names>A</given-names></name><name><surname>Laio</surname><given-names>A</given-names></name></person-group><article-title>Exploring the universe of protein structures beyond the Protein Data Bank</article-title><source>PLoS Comput Biol</source><year>2010</year><volume>6</volume><issue>11</issue><elocation-id>e1000957</elocation-id><pub-id pub-id-type="pmcid">PMC2973819</pub-id><pub-id pub-id-type="pmid">21079678</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000957</pub-id></element-citation></ref><ref id="R60"><label>[60]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skolnick</surname><given-names>J</given-names></name><name><surname>Arakaki</surname><given-names>AK</given-names></name><name><surname>Lee</surname><given-names>SY</given-names></name><name><surname>Brylinski</surname><given-names>M</given-names></name></person-group><article-title>The continuity of protein structure space is an intrinsic property of proteins</article-title><source>Proc Natl Acad Sci U S A</source><year>2009</year><volume>106</volume><issue>37</issue><fpage>15690</fpage><lpage>15695</lpage><pub-id pub-id-type="pmcid">PMC2747181</pub-id><pub-id pub-id-type="pmid">19805219</pub-id><pub-id pub-id-type="doi">10.1073/pnas.0907683106</pub-id></element-citation></ref><ref id="R61"><label>[61]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leman</surname><given-names>JK</given-names></name><name><surname>Szczerbiak</surname><given-names>P</given-names></name><name><surname>Renfrew</surname><given-names>PD</given-names></name><name><surname>Gligorijevic</surname><given-names>V</given-names></name><name><surname>Berenberg</surname><given-names>D</given-names></name><name><surname>Vatanen</surname><given-names>T</given-names></name><name><surname>Taylor</surname><given-names>BC</given-names></name><name><surname>Chandler</surname><given-names>C</given-names></name><name><surname>Janssen</surname><given-names>S</given-names></name><name><surname>Pataki</surname><given-names>A</given-names></name><name><surname>Carriero</surname><given-names>N</given-names></name><etal/></person-group><article-title>Sequence-structure-function relationships in the microbial protein universe</article-title><source>Nat Commun</source><year>2023</year><volume>14</volume><elocation-id>2351</elocation-id><pub-id pub-id-type="pmcid">PMC10133388</pub-id><pub-id pub-id-type="pmid">37100781</pub-id><pub-id pub-id-type="doi">10.1038/s41467-023-37896-w</pub-id></element-citation></ref><ref id="R62"><label>[62]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chandonia</surname><given-names>JM</given-names></name><name><surname>Hon</surname><given-names>G</given-names></name><name><surname>Walker</surname><given-names>NS</given-names></name><name><surname>Lo Conte</surname><given-names>L</given-names></name><name><surname>Koehl</surname><given-names>P</given-names></name><name><surname>Levitt</surname><given-names>M</given-names></name><name><surname>Brenner</surname><given-names>SE</given-names></name></person-group><article-title>The ASTRAL Compendium in 2004</article-title><source>Nucleic Acids Res</source><year>2004</year><volume>32</volume><fpage>D189</fpage><lpage>D192</lpage><pub-id pub-id-type="pmcid">PMC308768</pub-id><pub-id pub-id-type="pmid">14681391</pub-id><pub-id pub-id-type="doi">10.1093/nar/gkh034</pub-id></element-citation></ref><ref id="R63"><label>[63]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cock</surname><given-names>PJ</given-names></name><name><surname>Antao</surname><given-names>T</given-names></name><name><surname>Chang</surname><given-names>JT</given-names></name><name><surname>Chapman</surname><given-names>BA</given-names></name><name><surname>Cox</surname><given-names>CJ</given-names></name><name><surname>Dalke</surname><given-names>A</given-names></name><name><surname>Friedberg</surname><given-names>I</given-names></name><name><surname>Hamelryck</surname><given-names>T</given-names></name><name><surname>Kauff</surname><given-names>F</given-names></name><name><surname>Wilczynski</surname><given-names>B</given-names></name><name><surname>de Hoon</surname><given-names>MJ</given-names></name></person-group><article-title>Biopython: freely available Python tools for computational molecular biology and bioinformatics</article-title><source>Bioinformatics</source><year>2009</year><volume>25</volume><issue>11</issue><fpage>1422</fpage><lpage>1423</lpage><pub-id pub-id-type="pmcid">PMC2682512</pub-id><pub-id pub-id-type="pmid">19304878</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/btp163</pub-id></element-citation></ref><ref id="R64"><label>[64]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greener</surname><given-names>JG</given-names></name><name><surname>Selvaraj</surname><given-names>J</given-names></name><name><surname>Ward</surname><given-names>BJ</given-names></name></person-group><article-title>BioStructures.jl: read, write and manipulate macromolecular structures in Julia</article-title><source>Bioinformatics</source><year>2020</year><volume>36</volume><issue>14</issue><fpage>4206</fpage><lpage>4207</lpage><pub-id pub-id-type="pmid">32407511</pub-id></element-citation></ref><ref id="R65"><label>[65]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paszke</surname><given-names>A</given-names></name><name><surname>Gross</surname><given-names>S</given-names></name><name><surname>Massa</surname><given-names>F</given-names></name><name><surname>Lerer</surname><given-names>A</given-names></name><name><surname>Bradbury</surname><given-names>J</given-names></name><name><surname>Chanan</surname><given-names>G</given-names></name><name><surname>Killeen</surname><given-names>T</given-names></name><name><surname>Lin</surname><given-names>Z</given-names></name><name><surname>Gimelshein</surname><given-names>N</given-names></name><name><surname>Antiga</surname><given-names>L</given-names></name><name><surname>Desmaison</surname><given-names>A</given-names></name><etal/></person-group><article-title>Pytorch: An imperative style, high-performance deep learning library</article-title><source>Advances in Neural Information Processing Systems 32</source><year>2019</year><fpage>8024</fpage><lpage>8035</lpage></element-citation></ref><ref id="R66"><label>[66]</label><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Hendrycks</surname><given-names>D</given-names></name><name><surname>Gimpel</surname><given-names>K</given-names></name></person-group><article-title>Gaussian error linear units (GELUs)</article-title><year>2016</year><comment>URL <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1606.08415">https://arxiv.org/abs/1606.08415</ext-link></comment></element-citation></ref><ref id="R67"><label>[67]</label><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Kingma</surname><given-names>DP</given-names></name><name><surname>Ba</surname><given-names>J</given-names></name></person-group><article-title>Adam: A method for stochastic optimization</article-title><year>2014</year><comment>URL <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</ext-link></comment></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>Protein structure embedding.</title><p>(A) Protein domains are treated as a graph with Cα atoms as nodes and edges between Cα atoms within 10 Å. A GNN embeds the graph into a 128-dimensional representation. This can be compared quickly to a pre-embedded search database. (B) Supervised contrastive learning [<xref ref-type="bibr" rid="R23">23</xref>] is used to train the model, with embeddings for domains in the same SCOPe family pushed together and embeddings for domains in different SCOPe families pushed apart. Structures can be automatically split into domains before searching.</p></caption><graphic xlink:href="EMS157794-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Model performance on different protein types.</title><p>In each case the “Any” category is the same as in <xref ref-type="table" rid="T1">Table 1</xref>. (A) Sensitivity for fold searching by SCOPe class. (B) Sensitivity for fold searching by protein sequence length. (C) Sensitivity for fold searching by contact order, a measure of the sequence separation of contacting residues. (D) Sensitivity for fold searching across different embedding sizes. A model was trained from scratch for each embedding size. See <xref ref-type="supplementary-material" rid="SD1">Table S1</xref> for further ablations.</p></caption><graphic xlink:href="EMS157794-f002"/></fig><fig id="F3" position="float"><label>Figure 2</label><caption><title>Exploring Progres embeddings.</title><p>(A) 2D t-SNE embedding of the 128 dimensions of our model embedding for the Astral set of SCOPe domains clustered at 40% sequence identity (15,177 domains). The domains are coloured by SCOPe class. t-SNE was carried out using a perplexity value of 30. (B) The same data coloured by number of residues in the domain. The median length of domains is 149 residues. For colouring, the maximum number of residues in a domain is treated as 400. (C) 2D t-SNE of the AlphaFold database TED domains [<xref ref-type="bibr" rid="R45">45</xref>] clustered at 50% sequence identity and the ECOD F70 set of domains in the PDB [<xref ref-type="bibr" rid="R22">22</xref>]. 5m (9%) of the TED domains are chosen randomly for the t-SNE for computational reasons. (D) A similar comparison of the TED domains to the AlphaFold 21 model organisms set [<xref ref-type="bibr" rid="R17">17</xref>, <xref ref-type="bibr" rid="R51">51</xref>]. (E) Comparison of Progres score to TM-align score. For each of the 400 domains in the test set the top 200 matches in the Astral 40% sequence identity set according to TM-align are considered. The Pearson correlation coefficient is 0.60. The green line shows the TM-align score threshold of 0.5 indicating the same fold. The purple line shows the Progres score threshold of 0.8 indicating the same fold.</p></caption><graphic xlink:href="EMS157794-f003"/></fig><table-wrap id="T1" position="float" orientation="portrait"><label>Table 1</label><caption><p>Comparison of ability to retrieve homologous proteins from SCOPe. A similar procedure to Foldseek [<xref ref-type="bibr" rid="R19">19</xref>] is followed for searching sensitivity with a set of 400 domains. For each domain the fraction of true positives (TPs) detected up to the first incorrect fold is calculated (higher is better). TPs are same family in the case of family-level recognition, same superfamily and not same family in the case of superfamily-level recognition, and same fold and not same superfamily in the case of fold-level recognition. The mean of this fraction over all 400 domains is reported. Run time (single) is the time taken to search a structure of 150 residues (d1a6ja_ in PDB format) against all the 15,177 Astral 2.08 40% sequence identity set domains, with the database pre-prepared. Run time (all-v-all) is the time taken to calculate all pairwise distances between the 15,177 domains from structure. EAT, ESM-2 and MMseqs2 use sequence not structure for searching. 3D-SURFER and EAT are trained with structural information and may have seen proteins in the test set during training.</p></caption><table frame="hsides" rules="groups"><colgroup><col span="1"/><col span="3"/><col span="2"/></colgroup><thead><tr><th align="left" valign="top" rowspan="2">Software</th><th align="left" valign="top" colspan="3">Searching sensitivity</th><th align="left" valign="top" colspan="2">Top 20 hits</th><th align="left" valign="top" colspan="2">Run time</th></tr><tr style="border-bottom: solid thin"><th align="left" valign="top"><italic>Fold</italic></th><th align="left" valign="top"><italic>Superfamily</italic></th><th align="left" valign="top"><italic>Family</italic></th><th align="left" valign="top"><italic>Mean TM-align</italic></th><th align="left" valign="top"><italic>Fraction correct folds</italic></th><th align="left" valign="top"><italic>Single</italic></th><th align="left" valign="top"><italic>All-v-all</italic></th></tr></thead><tbody><tr><td align="left" valign="top" style="border-right: solid thin">Progres (this work)</td><td align="left" valign="top">0.177</td><td align="left" valign="top">0.706</td><td align="left" valign="top" style="border-right: solid thin">0.877</td><td align="left" valign="top">0.621</td><td align="left" valign="top" style="border-right: solid thin">0.853</td><td align="left" valign="top">1.3 s (CPU)</td><td align="left" valign="top">163 s (CPU), 127 s (GPU)</td></tr><tr><td align="left" valign="top" style="border-right: solid thin">Dali [<xref ref-type="bibr" rid="R13">13</xref>]</td><td align="left" valign="top">0.168</td><td align="left" valign="top">0.709</td><td align="left" valign="top" style="border-right: solid thin">0.885</td><td align="left" valign="top">0.673</td><td align="left" valign="top" style="border-right: solid thin">0.920</td><td align="left" valign="top">508 s</td><td align="left" valign="top">&gt; 1 month</td></tr><tr><td align="left" valign="top" style="border-right: solid thin">Foldseek-TM [<xref ref-type="bibr" rid="R19">19</xref>]</td><td align="left" valign="top">0.158</td><td align="left" valign="top">0.666</td><td align="left" valign="top" style="border-right: solid thin">0.859</td><td align="left" valign="top">0.662</td><td align="left" valign="top" style="border-right: solid thin">0.898</td><td align="left" valign="top">4.8 s</td><td align="left" valign="top">2 h 47 m</td></tr><tr><td align="left" valign="top" style="border-right: solid thin">Foldseek [<xref ref-type="bibr" rid="R19">19</xref>]</td><td align="left" valign="top">0.111</td><td align="left" valign="top">0.644</td><td align="left" valign="top" style="border-right: solid thin">0.850</td><td align="left" valign="top">0.656</td><td align="left" valign="top" style="border-right: solid thin">0.889</td><td align="left" valign="top">2.3 s</td><td align="left" valign="top">250 s</td></tr><tr><td align="left" valign="top" style="border-right: solid thin">TM-align fast [<xref ref-type="bibr" rid="R8">8</xref>]</td><td align="left" valign="top">0.100</td><td align="left" valign="top">0.594</td><td align="left" valign="top" style="border-right: solid thin">0.806</td><td align="left" valign="top">0.688</td><td align="left" valign="top" style="border-right: solid thin">0.847</td><td align="left" valign="top">390 s</td><td align="left" valign="top">~23 days</td></tr><tr><td align="left" valign="top" style="border-bottom: solid thin">3D-SURFER [<xref ref-type="bibr" rid="R44">44</xref>]</td><td align="left" valign="top">0.046</td><td align="left" valign="top">0.140</td><td align="left" valign="top" style="border-right: solid thin">0.349</td><td align="left" valign="top">0.511</td><td align="left" valign="top" style="border-right: solid thin">0.560</td><td align="left" valign="top">7.2 s</td><td align="left" valign="top">24 h</td></tr><tr><td align="left" valign="top" style="border-right: solid thin">EAT [<xref ref-type="bibr" rid="R34">34</xref>]</td><td align="left" valign="top">0.101</td><td align="left" valign="top">0.615</td><td align="left" valign="top" style="border-right: solid thin">0.843</td><td align="left" valign="top">0.627</td><td align="left" valign="top" style="border-right: solid thin">0.825</td><td align="left" valign="top">34 s (GPU)</td><td align="left" valign="top">4 h 37 m (GPU)</td></tr><tr><td align="left" valign="top" style="border-right: solid thin">ESM-2 [<xref ref-type="bibr" rid="R18">18</xref>]</td><td align="left" valign="top">0.014</td><td align="left" valign="top">0.221</td><td align="left" valign="top" style="border-right: solid thin">0.477</td><td align="left" valign="top">0.546</td><td align="left" valign="top" style="border-right: solid thin">0.598</td><td align="left" valign="top">28 s (GPU)</td><td align="left" valign="top">590 s (GPU)</td></tr><tr><td align="left" valign="top" style="border-right: solid thin">MMseqs2 [<xref ref-type="bibr" rid="R43">43</xref>]</td><td align="left" valign="top">0.001</td><td align="left" valign="top">0.165</td><td align="left" valign="top" style="border-right: solid thin">0.433</td><td align="left" valign="top">0.488</td><td align="left" valign="top" style="border-right: solid thin">0.390</td><td align="left" valign="top">0.9 s</td><td align="left" valign="top">17.1 s</td></tr></tbody></table></table-wrap></floats-group></article>