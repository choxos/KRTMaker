<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS157329</article-id><article-id pub-id-type="doi">10.1101/2022.11.17.516938</article-id><article-id pub-id-type="archive">PPR573119</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>DeepBryo: a web app for Al-assisted morphometric characterization of cheilostome bryozoans</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Martino</surname><given-names>Emanuela Di</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Berning</surname><given-names>Björn</given-names></name><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Gordon</surname><given-names>Dennis P</given-names></name><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Kuklinski</surname><given-names>Piotr</given-names></name><xref ref-type="aff" rid="A4">4</xref></contrib><contrib contrib-type="author"><name><surname>Liow</surname><given-names>Lee Hsiang</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Ramsfjell</surname><given-names>Mali H</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Ribeiro</surname><given-names>Henrique L</given-names></name><xref ref-type="aff" rid="A5">5</xref></contrib><contrib contrib-type="author"><name><surname>Smith</surname><given-names>Abigail M</given-names></name><xref ref-type="aff" rid="A6">6</xref></contrib><contrib contrib-type="author"><name><surname>Taylor</surname><given-names>Paul D</given-names></name><xref ref-type="aff" rid="A7">7</xref></contrib><contrib contrib-type="author"><name><surname>Voje</surname><given-names>Kjetil L</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Waeschenbach</surname><given-names>Andrea</given-names></name><xref ref-type="aff" rid="A7">7</xref></contrib><contrib contrib-type="author"><name><surname>Porto</surname><given-names>Arthur</given-names></name><xref ref-type="aff" rid="A5">5</xref><xref ref-type="aff" rid="A8">8</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib></contrib-group><aff id="A1"><label>1</label>Natural History Museum, University of Oslo, Oslo, Norway</aff><aff id="A2"><label>2</label>Oberösterreichische Landes-Kultur GmbH, Geowissenschaftliche Sammlungen, Welser Str. 20, 4060 Leonding, Austria</aff><aff id="A3"><label>3</label>National Institute of Water &amp; Atmospheric Research, Wellington, New Zealand</aff><aff id="A4"><label>4</label>Institute of Oceanology, Polish Academy of Sciences, Sopot, Poland</aff><aff id="A5"><label>5</label>Department of Biological Sciences, Louisiana State University, Baton Rouge, US</aff><aff id="A6"><label>6</label>Department of Marine Science, University of Otago, Dunedin, New Zealand</aff><aff id="A7"><label>7</label>Natural History Museum, London, UK</aff><aff id="A8"><label>8</label>Center for Computation and Technology, Louisiana State University, Baton Rouge, US</aff><author-notes><corresp id="CR1">
<label>*</label>corresponding author: <email>agporto@wustl.edu</email>
</corresp></author-notes><pub-date pub-type="nihms-submitted"><day>19</day><month>11</month><year>2022</year></pub-date><pub-date pub-type="preprint"><day>17</day><month>11</month><year>2022</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">
<list list-type="order" id="L1"><list-item><p id="P2">Bryozoans are becoming an increasingly popular study system in macroevolutionary, ecological, and paleobiological research. Members of this colonial invertebrate phylum are notable for displaying an exceptional degree of division of labor in the form of specialized modules (polymorphs), which allow for the inference of individual allocation of resources to reproduction, defense, and growth using simple morphometric tools. However, morphometric characterizations of bryozoans are notoriously labored, due to the high number of structures often captured per image, as well as the need for specialized knowledge necessary for classifying individual skeletal structures within those images.</p></list-item><list-item><p id="P3">We here introduce DeepBryo, a web application for deep learning-based morphometric characterization of cheilostome bryozoans. DeepBryo requires a single image as input and performs measurements automatically using instance segmentation algorithms. DeepBryo is capable of detecting objects belonging to six classes and outputting fourteen morphological shape measurements for each object based on the inferred segmentation maps. The users can visualize the predictions, check for errors, and directly filter model outputs on the web browser. Measurements can then be downloaded as a comma-separated values file.</p></list-item><list-item><p id="P4">DeepBryo has been trained and validated on a total of 72,412 structures, belonging to six different object classes in 935 SEM images of cheilostome bryozoans belonging to 109 different families. The model shows high (&gt;0.8) recall and precision for zooid-level structures. Its misclassification rate is low (~4%) and largely concentrated in a single object class (opesia). The model’s estimated structure-level area, height, and width measurements are statistically indistinguishable from those obtained via manual annotation (r<sup>2</sup> varying from 0.89 to 0.98) and show no detectable bias. DeepBryo reduces the person-hours required for characterizing the zooids in individual colonies to less than 1% of the time required for manual annotation at no significant loss of measurement accuracy.</p></list-item><list-item><p id="P5">Our results indicate that DeepBryo enables cost-, labor,- and time-efficient morphometric characterization of cheilostome bryozoans. DeepBryo can greatly increase the scale of macroevolutionary, ecological, taxonomic, and paleobiological analyses, as well as the accessibility of deep learning tools for this emerging model system. Finally, DeepBryo provides the building blocks necessary for adapting the current application to other study groups.</p></list-item></list></p></abstract><kwd-group><kwd>Artificial Intelligence</kwd><kwd>Computer Vision</kwd><kwd>Machine Learning</kwd><kwd>Marine invertebrates</kwd><kwd>Morphometrics</kwd></kwd-group></article-meta></front><body><sec id="S1" sec-type="intro"><label>1</label><title>Introduction</title><p id="P6">Recent advances in macroevolutionary research emphasize that a large number of evolutionary phenomena are better explained when using data from both extant and extinct taxa (<xref ref-type="bibr" rid="R20">Love et al., 2022</xref>; <xref ref-type="bibr" rid="R23">Mongiardino Koch et al., 2021</xref>; <xref ref-type="bibr" rid="R30">Parry et al., 2016</xref>; <xref ref-type="bibr" rid="R35">Slater, 2013</xref>; <xref ref-type="bibr" rid="R36">Slater et al., 2012</xref>). Yet, most macroevolutionary analyses of trait diversification patterns have been disproportionately focused on organisms with poor fossil records (e.g., terrestrial vertebrates and plants) (<xref ref-type="bibr" rid="R29">Orr et al., 2022</xref>). As a consequence, our understanding of trait diversification dynamics is still highly biased by the limited temporal sampling of most datasets currently being used to infer trait dynamics, as well as the difficulties of integrating neontological and paleontological datasets into a single phylogenetic framework. Compounding this bias, most empirical studies of trait diversification focus on one trait at a time and are therefore blind to the multivariate nature of genotype-to-phenotype maps, in which pleiotropy, epistasis, and genotype-by-environment interactions are prevalent (<xref ref-type="bibr" rid="R14">Houle et al., 2010</xref>; <xref ref-type="bibr" rid="R22">Melo et al., 2016</xref>). This univariate focus of macroevolutionary research is not surprising when taking into account the labor and financial costs associated with high-dimensional phenotyping. It does imply that our current views of macroevolutionary diversification often do not account for the role of trait correlations (<xref ref-type="bibr" rid="R22">Melo et al., 2016</xref>).</p><p id="P7">Members of the colonial phylum Bryozoa have played a fundamental role in classical debates regarding tempo and mode of morphological evolution (<xref ref-type="bibr" rid="R5">Cheetham, 1986a</xref>, <xref ref-type="bibr" rid="R6">1986b</xref>, <xref ref-type="bibr" rid="R7">1987</xref>; <xref ref-type="bibr" rid="R8">Cheetham et al., 1993</xref>, <xref ref-type="bibr" rid="R9">1994</xref>; <xref ref-type="bibr" rid="R40">Voje et al., 2020</xref>), and represent an emerging model system in macroevolutionary, ecological, and paleobiological research (<xref ref-type="bibr" rid="R11">Clark et al., 2010</xref>; <xref ref-type="bibr" rid="R12">Di Martino &amp; Liow, 2021</xref>, <xref ref-type="bibr" rid="R13">2022</xref>; <xref ref-type="bibr" rid="R17">Liow et al., 2017</xref>; <xref ref-type="bibr" rid="R18">Liow &amp; Taylor, 2019</xref>; <xref ref-type="bibr" rid="R25">O’Dea &amp; Jackson, 2009</xref>, <xref ref-type="bibr" rid="R26">2002</xref>; <xref ref-type="bibr" rid="R27">O’Dea &amp; Okamura, 2000</xref>; <xref ref-type="bibr" rid="R28">Okamura et al., 2013</xref>). Bryozoans have an old (Cambrian) (<xref ref-type="bibr" rid="R41">Zhang et al., 2021</xref>), species-rich (&gt;22,000 described species), and high temporal resolution fossil record (<xref ref-type="bibr" rid="R38">Taylor, 2020</xref>). Their skeletal features are finely preserved over large timescales, to the point where fossil taxa can often be identified at the species level (<xref ref-type="bibr" rid="R15">Jackson &amp; Cheetham, 1990</xref>; <xref ref-type="bibr" rid="R34">Simpson &amp; Jackson, 2022</xref>). Order Cheilostomatida, in particular, represents the most abundant and diverse order within Bryozoa, containing around 80% of the phylum’s living species diversity plus as many as 7,900 described fossil species (<xref ref-type="bibr" rid="R1">Bock &amp; Gordon, 2013</xref>). Members of this order are known for the high degree of modularity (and division of labor) in their colonies, in which genetically identical zooids can develop into a wide array of polymorphs (<xref ref-type="bibr" rid="R33">Schack et al., 2019</xref>). These zooid polymorphs and modified skeletal structures can devote themselves to functions such as reproduction (ovicells), defense (avicularia), feeding (autozooid), structural integrity (kenozooids), among others, and provide a window into how individual colonies allocate resources in response to environmental cues (<xref ref-type="bibr" rid="R33">Schack et al., 2019</xref>), given their genetic background.</p><p id="P8">For a long time (e.g, <xref ref-type="bibr" rid="R3">Buss, 1979</xref>), researchers have emphasized that the biology of bryozoans provides a unique opportunity to study ecological and life-history traits in the fossil record, in which colony-level allocation of resources can be estimated using simple morphometric tools (<xref ref-type="bibr" rid="R12">Di Martino &amp; Liow, 2021</xref>; <xref ref-type="bibr" rid="R17">Liow et al., 2017</xref>; <xref ref-type="bibr" rid="R24">O’Dea, 2003</xref>; <xref ref-type="bibr" rid="R26">O’Dea &amp; Jackson, 2002</xref>; <xref ref-type="bibr" rid="R27">O’Dea &amp; Okamura, 2000</xref>). On the analytical front, the main bottleneck for a more widespread adoption of bryozoans as a model system in macroevolutionary biology is the laborious nature of the morphometric data. In particular, bryozoan skeletal morphology is usually captured using scanning electron microscopy (SEM) images of dry specimens, which can contain hundreds of structures within just one image. The recognition and classification of these structures are not trivial and often require expert domain knowledge (see (<xref ref-type="bibr" rid="R33">Schack et al., 2019</xref>)). Morphometric characterizations of skeletal morphology in the group are thus usually carried out manually by a dwindling number of taxonomic experts, a process that is low-throughput, costly, and time-consuming to reproduce.</p><p id="P9">Over the last decade, rapid changes in morphometric investigations have been spurred by developments in computer vision and machine learning (<xref ref-type="bibr" rid="R21">Lürig et al., 2021</xref>). In particular, deep-learning-based computer vision tools have shown exceptional performance in a wide variety of tasks both in scientific and real-world settings (e.g., (<xref ref-type="bibr" rid="R16">Lin et al., 2014</xref>)). Consequently, vision-based morphometric approaches are fast becoming an integral part of a biologist’s toolkit, both in the field and the laboratory (<xref ref-type="bibr" rid="R21">Lürig et al., 2021</xref>; <xref ref-type="bibr" rid="R31">Porto et al., 2021</xref>; <xref ref-type="bibr" rid="R32">Porto &amp; Voje, 2020</xref>; <xref ref-type="bibr" rid="R39">Vandaele et al., 2018</xref>).</p><p id="P10">We here introduce DeepBryo, a deep-learning-based web application that allows rapid and accurate morphometric characterization of cheilostome bryozoan images directly in a web browser. DeepBryo approaches the problem of instance segmentation of SEM images using state-of-the-art transformer models (<xref ref-type="bibr" rid="R19">Liu et al., 2021</xref>) wrapped in a simple user interface. After uploading an image, the application, the user can visualize, filter, and download segmentation results. Given the recent explosion in the availability of cheilostome SEM images, we expect this simple framework will greatly increase the scale and robustness of macroevolutionary, ecological, taxonomic, and paleobiological research based on this emerging study system.</p></sec><sec id="S2"><label>2</label><title>Deepbryo App</title><sec id="S3"><label>2.1</label><title>Description</title><p id="P11">DeepBryo (<xref ref-type="fig" rid="F1">Figure 1</xref>) is available as a web application (<ext-link ext-link-type="uri" xlink:href="https://www.deepbryo.ngrok.io">https://www.deepbryo.ngrok.io</ext-link>) or can be deployed locally (<ext-link ext-link-type="uri" xlink:href="https://www.github.com/agporto/DeepBryo">https://www.github.com/agporto/DeepBryo</ext-link>). The web application runs on a central server capable of running multiple parallel user sessions using a 12GB NVIDIA QUADRO P4000 GPU. A single SEM image is expected as input. The specimen should lie flat within the image, with its surface perpendicular to the observer. The optimal range of zoom magnification for the input images lies between 30x and 90x, as typically used for bryozoan species identification. Higher or lower magnification will likely result in poorer model predictions and a significant reduction in model recall and precision. Once uploaded, the model predictions are automatically generated and cached using the <italic>streamlit v.1.10.0</italic> python library. The caching mechanism is a key component of DeepBryo, as it allows multiple users to perform filtering and scaling of model predictions without the need to rerun the initial prediction steps. From the user's point of view, model predictions appear on the browser as a colored mask, in which the color represents six possible object classes: ascopore, autozooid, avicularium, opesia, orifice, ovicell (<xref ref-type="fig" rid="F2">Figure 2</xref>; See <xref ref-type="supplementary-material" rid="SD1">Supplemental File 1</xref> for a glossary of terms). Users also have the option of visualizing the corresponding bounding boxes and identification numbers for each structure on the image using the sidebar (<xref ref-type="supplementary-material" rid="SD1">Figure S1</xref>).</p><p id="P12">On the backend, DeepBryo performs instance segmentation and shape measurement as separate tasks. Given an input image, instance segmentation is performed using a Swin Transformer-based Mask R-CNN (<xref ref-type="bibr" rid="R19">Liu et al., 2021</xref>). This Swin Transformer model has been fine-tuned using pre-trained weights (ImageNet-1K) (<xref ref-type="bibr" rid="R19">Liu et al., 2021</xref>) and an annotated image dataset composed of 935 cheilostome bryozoan images (<xref ref-type="supplementary-material" rid="SD1">Table S1</xref>), containing 72,412 structures, and captured within the optimal range of magnification (see <xref ref-type="sec" rid="S5">3. Validation</xref> for performance details).</p><p id="P13">DeepBryo then performs shape measurement based on the predicted masks using contour functions in the <italic>opencv 4.6.0</italic> python library (<xref ref-type="bibr" rid="R2">Bradski, 2000</xref>). The application currently outputs seven commonly used shape descriptors and seven Hu moments derived from each contour’s central moments (<xref ref-type="table" rid="T1">Table 1</xref>) (<xref ref-type="bibr" rid="R2">Bradski, 2000</xref>).</p></sec><sec id="S4"><label>2.2</label><title>Usage</title><p id="P14">We here present the steps necessary for using DeepBryo as a web application (<ext-link ext-link-type="uri" xlink:href="https://www.deepbryo.ngrok.io">https://www.deepbryo.ngrok.io</ext-link>). For command-line interface (CLI) usage, please refer to the official GitHub repository (<ext-link ext-link-type="uri" xlink:href="https://github.com/agporto/DeepBryo">www.github.com/agporto/DeepBryo</ext-link>). <list list-type="simple" id="L2"><list-item><label>-</label><p id="P15">Click the “Browse files” button on the right uppermost corner of the screen to upload your image, or simply drag and drop the image into the gray rectangle area next to it (<xref ref-type="fig" rid="F1">Figure 1A</xref>). An upload progress bar will detail how much of the file has been uploaded.</p></list-item><list-item><label>-</label><p id="P16">Once the image is uploaded, the model is automatically initialized and model predictions are shown on the screen as colored masks (<xref ref-type="fig" rid="F1">Figure 1B</xref>). Model predictions have been cached at this point in time, so further steps will not require the model to be reinitialized.</p></list-item><list-item><label>-</label><p id="P17">On the sidebar (<xref ref-type="fig" rid="F1">Figure 1C</xref>), you will find five main sections. In the uppermost section (<italic><bold>Object Class</bold></italic>, <xref ref-type="fig" rid="F1">Figure 1C-1</xref>), you can choose whether to isolate certain object classes using a drop-down menu (“Search for which objects?”). By selecting a specific class, the image masks will be replaced by those belonging exclusively to the class in question. In the same section, you can choose whether to display the bounding boxes corresponding to each detected object. Similarly, you can add a class label or individual structure identification numbers by clicking on checkboxes. By adding the class label, you will also see the model’s confidence in each object’s prediction.</p></list-item><list-item><label>-</label><p id="P18">In the second section (<bold><italic>Set Confidence Threshold</italic></bold>, <xref ref-type="fig" rid="F1">Figure 1C</xref>-<xref ref-type="fig" rid="F2">2</xref>), you can choose whether to filter out objects based on model confidence. The default value is set to 0.5, but can be adjusted based on your filtering needs. Most users will not need to adjust this parameter. Setting this value too low tends to increase the number of spurious detections while setting it too high leads to poor recall performance.</p></list-item><list-item><label>-</label><p id="P19">In the third section (<italic><bold>Filter Objects</bold></italic>, <xref ref-type="fig" rid="F1">Figure 1C</xref>-<xref ref-type="fig" rid="F3">3</xref>), additional filtering options can be enabled using checkboxes. Two main filters are currently available. The “Distance from image border” checkbox filters objects that touch the border of the image. The main purpose of this checkbox is to remove partially incomplete objects from the output. Alternatively, an automated filtering model can further clean the predictions. Automated filtering utilizes a gradient boosting algorithm (<xref ref-type="bibr" rid="R10">Chen &amp; Guestrin, 2016</xref>) to classify predictions into “good” or “bad”, “bad” meaning that the object is partially incomplete, not properly cleaned, or simply poorly preserved to be of use. The parameter “Strictness” regulates how strict the gradient boosting algorithm is when filtering out model predictions. Low strictness leads to more filtering out of predictions, while high strictness leads to less filtering out.</p></list-item><list-item><label>-</label><p id="P20">In the fourth section (<italic><bold>Output Table</bold></italic>, <xref ref-type="fig" rid="F1">Figure 1C</xref>-<xref ref-type="fig" rid="F4">4</xref>), you can generate a table output (<xref ref-type="fig" rid="F1">Figure 1D</xref>) containing fourteen traditionally used shape measurements for each detected object using a checkbox. You can also opt to remove certain objects from the table output based on their identification number. To do so, simply type the number in question under “Please select ID numbers” followed by the ‘Enter’ key. Alternatively, select identification numbers using the drop-down menu. Note, however, that the table output will be in pixel units unless you use the next section.</p></list-item><list-item><label>-</label><p id="P21">In the final sidebar section (<bold><italic>Set Scale</italic></bold>, <xref ref-type="fig" rid="F1">Figure 1C</xref>-<xref ref-type="fig" rid="F5">5</xref>), you can scale your measurements using scale bar annotation. While some measurements in DeepBryo are unitless (e.g., eccentricity), others are not (e.g., area, perimeter). If the scale is not set, DeepBryo will output measurements in pixel units. If set, it will output them in millimeters. To set the scale, check ‘Set image scale using two points’ and manually type the scale bar length in μm under ‘Length(μm)’. This will convert the image into a canvas capable of user interaction. You can now place points on the image corresponding to the position and size of the scale bar. You should place one point at the leftmost extreme of the scale bar and another at the rightmost extreme. If the placement is correct, press the ‘Send to streamlit’ button at the left bottom corner of the image. If it is not, press the trash can icon (‘Reset canvas and history’) to have the option of placing new points. Once points have been placed on the scale bar, your table output will be automatically converted to millimeters.</p></list-item></list></p></sec></sec><sec id="S5"><label>3</label><title>Validation</title><sec id="S6"><label>3.1</label><title>Dataset</title><p id="P22">The dataset used to train and validate the instance segmentation model behind DeepBryo consists of 72,412 structures which were manually annotated on 935 SEM images of bryozoan colonies belonging to ~75% of the families (N=109) and ~30 % of the genera (N=206) within Cheilostomatida (<xref ref-type="supplementary-material" rid="SD1">Table S1</xref>). The species richness in the dataset is best represented as a range since some taxa could not be identified at the species level from the images available. We estimate that species richness in this dataset ranges from a minimum of ~ 8% (N=443) to a maximum of 9.2% (N=505) of the species diversity among cheilostomes (<xref ref-type="supplementary-material" rid="SD1">Table S1</xref>). These data have been acquired independently by the coauthors of this manuscript over the years or obtained from public image repositories. They encompass a large array of image quality, resolution, taphonomic degradation, magnification, and equipment used. We consider these pictures to represent most encrusting morphotypes within cheilostomes in which recognition of individual skeletal structures is possible, as well as representative of the images being collected for morphometric research in the group. Some erect species with large flat colony areas are also represented.</p><p id="P23">We annotated all individual structures contained within the images using polygons. These structures belong to six classes (<xref ref-type="fig" rid="F2">Figure 2</xref>), representing different colony life history traits, such as reproduction, defense, and growth (see <xref ref-type="supplementary-material" rid="SD1">Supplemental File 1</xref>). Broken, occluded and taphonomically degraded structures were marked as “poor” quality and further used to train a binary automated filtering algorithm based on gradient boosting (<xref ref-type="bibr" rid="R10">Chen &amp; Guestrin, 2016</xref>). When training each model, we randomly sampled 90% of the images for training and 10% for validation. The instance segmentation model was trained for 120 epochs, using a learning rate of 10<sup>-4</sup> and the AdamW optimizer, following general guidelines presented in the original Swin Transformer manuscript (<xref ref-type="bibr" rid="R19">Liu et al., 2021</xref>). Image augmentations were performed during training using the <italic>albumentations</italic> library (<xref ref-type="bibr" rid="R4">Buslaev et al., 2020</xref>) to increase the model’s generalizability.</p></sec><sec id="S7"><label>3.2</label><title>Performance</title><p id="P24">Instance segmentation models can be evaluated in terms of their three underlying tasks: detection, classification, and segmentation. In other words, we can evaluate them in terms of their ability to detect objects (structures) in images, correctly classify them, and produce segmentation masks that have similar morphometric properties to those manually annotated.</p><sec id="S8"><label>3.2.1</label><title>Detection</title><p id="P25">The performance of DeepBryo in terms of object detection can be evaluated using average precision (AP). AP is a common metric used to evaluate object detection performance (<xref ref-type="bibr" rid="R16">Lin et al., 2014</xref>). Essentially, it measures the degree to which objects present in the ground-truth data are recovered by the model as valid detections. AP values range from 0 (no recall and/or no precision) to 1 (100% recall and precision). Detections are considered valid if they overlap substantially with manually annotated (ground-truth) objects. As commonly done in the field of computer vision, we use an intersection-over-union value of 0.5 as our threshold for recognizing an object as valid.</p><p id="P26">In <xref ref-type="fig" rid="F3">Figure 3</xref>, we break down AP values by object class (autozooid, ovicell, etc.) and by object size. We define size according to the area occupied by the object in each image: small (x &lt; 32x32 pixels), medium (32x32 &lt; x &lt; 96x96 pixels), and large (x &gt; 96x96 pixels).</p><p id="P27">As can readily be seen (<xref ref-type="fig" rid="F3">Figure 3A</xref>), AP values are generally high (&gt; 0.7) for most object classes, and decrease considerably with decreased object area (<xref ref-type="fig" rid="F3">Figure 3B</xref>). Autozooids had the highest AP (0.814) among all object classes, followed by opesiae (0.755) and orifices (0.744). This is not surprising, given these are among the largest and most common object types in images of this group. Small structures, such as ascopores, tend to present low levels of AP (0.242) and are, therefore, severely undersampled from images. In other words, the model generally shows high levels of recall and precision as long as objects are large, and vice versa. The same pattern can be observed in the recall and precision curves (<xref ref-type="supplementary-material" rid="SD1">Figure S2</xref>), which indicate that performance reduction usually occurs through decreased recall rates.</p></sec><sec id="S9"><label>3.2.2</label><title>Classification</title><p id="P28">Once an object is detected, we can measure the extent to which it is correctly classified. <xref ref-type="fig" rid="F4">Figure 4</xref> illustrates a confusion matrix of object classes. Confusion matrices are a common visualization tool to illustrate the classification performance of machine learning models (<xref ref-type="bibr" rid="R37">Stehman, 1997</xref>). It is usually presented as a matrix in which each row represents the percent instances of a ground-truth class that get predicted as belonging to the different classes (columns).</p><p id="P29">With the exception of the opesia, class confusion is rather rare and most objects get correctly classified by the model (&gt;0.95). Among opesia objects, a notable percentage (8%) is incorrectly classified as an autozooid. This observation is not surprising given that, in many species, as much as 80-90% of the area of the zooid is occupied by the opesia (see <xref ref-type="fig" rid="F2">Figure 2</xref>). Overall, the observed patterns suggest that classification errors are not a significant source of concern, due to their rarity.</p></sec><sec id="S10"><label>3.2.3</label><title>Segmentation</title><p id="P30">Ultimately, a user that might be interested in DeepBryo will want to know the extent to which the model recovers measurements that are directly comparable to measurements currently used in the literature. To compare the DeepBryo segmentation results with conventional methods, we regressed the predicted area, height (major axis) and width (minor axis) of each detected object against their ground-truth counterparts (<xref ref-type="fig" rid="F5">Figure 5</xref>). We then compare the ability of the model to recover ground-truth measurements based on the coefficient of determination (r<sup>2</sup>) and the relative root-mean-squared error (RMSE) metrics. Finally, we test for deviations from a regression slope of one using the confidence interval of regression of slopes. Deviations from a slope of one would indicate that the model either overestimates (&gt;1) or underestimates (&lt;1) object-level measurements.</p><p id="P31">As seen in <xref ref-type="fig" rid="F5">Figure 5</xref>, all object classes and measurement types have high r<sup>2</sup> values (&gt;0.89) and low relative RMSE (&lt; or equal to 5% of the range of variation across specimens). Not surprisingly, the confidence interval of the regression slope includes the value of one for all classes, indicating a failure to reject the null hypothesis of a 1:1 relationship between observed and predicted area measurements. Likewise, univariate ANOVAs comparing the means of the distributions of area values per class are equally not significant using p=0.05. In other words, measurements produced by DeepBryo are directly comparable to those obtained manually.</p></sec><sec id="S11"><label>3.2.4</label><title>Time</title><p id="P32">Given the number and diversity of structures, cheilostome bryozoan images take a significant amount of time to be manually annotated. Not surprisingly, taxonomic studies in the group will often collect no more than 20 measurements of each structure, which is considered a fair compromise between the accuracy of the morphometric characterization and the effort in person-hours necessary to do so. Annotation of the entire validation set used in this study took an estimated total of approximately 270 person-hours to complete. In its batch-processing form, as described in the GitHub repository, the model is capable of annotating the same image set in less than a minute. In the web application form, a user can annotate the same set in anywhere between 30 min to 2 person-hours. In other words, DeepBryo reduces the person-hours required for measuring cheilostome bryozoan colonies to less than one percent of the time required to manually annotate such image set.</p></sec></sec></sec><sec id="S12" sec-type="discussion"><label>4</label><title>Discussion</title><p id="P33">DeepBryo is a web application for AI-assisted segmentation of SEM images of cheilostome bryozoan colonies (<xref ref-type="fig" rid="F1">Figure 1</xref>). We here demonstrated that it greatly increases the scale and reproducibility of morphometric characterization of bryozoans, as typically done in macroevolutionary, ecological, paleobiological, and taxonomic research. DeepBryo shows high levels of recall and precision for six different structure classes within images (<xref ref-type="fig" rid="F3">Figure 3</xref>) and calculates measurements that are directly comparable to those obtained via expert-based image annotation for a large array of cheilostome genera (<xref ref-type="fig" rid="F5">Figure 5</xref>). Class confusion is rare and is highly concentrated in a single object class (opesia) (<xref ref-type="fig" rid="F4">Figure 4</xref>). Finally, the model has been trained and performs well on a wide array of species of cheilostomes (<xref ref-type="supplementary-material" rid="SD1">Table S1</xref>).</p><p id="P34">DeepBryo makes two major contributions to the use of cheilostome bryozoans as a model system in evolution, ecology, and paleobiology. First, it captures (and provides to users) the specialized domain knowledge that is often required to make use of this emerging model system. In our view, the model’s ability to capture domain knowledge will greatly expand the pool of researchers that will be interested in using bryozoans to address important questions in the macroevolutionary, ecological, and paleobiological literature. Second, DeepBryo removes important analytical bottlenecks from morphometric research studies using this clade. For example, a taxonomist interested in capturing the morphological variability within a taxon will be able to do so without making compromises in terms of the number of structures being measured or in terms of the person-hour requirements. Such a taxonomist will also be able to present measurements that can be easily replicated in another laboratory. Similarly, an evolutionary biologist interested in multivariate diversification patterns will be able to do so in a high-throughput and replicable fashion, even if asking questions that require characterizing a wide array of structures and/or species. With small changes in the source code, one could even combine the object detection abilities of DeepBryo with other approaches, such as automated landmarking algorithms (<xref ref-type="bibr" rid="R32">Porto &amp; Voje, 2020</xref>). Note, also, that our repository contains all key elements (i.e., building blocks) necessary to adapt the tool to other study systems. The instance segmentation model, for example, can be retrained using a standard COCO dataset (<xref ref-type="bibr" rid="R16">Lin et al., 2014</xref>) with simple changes in the configuration file (e.g., change the name of object classes), as described in our GitHub repository.</p><p id="P35">We do not intend to imply, however, that there are no shortcomings with the current implementation. Most notably, DeepBryo currently focuses on Cheilostomatida. While cheilostomes are the most diverse order within Bryozoa (<xref ref-type="bibr" rid="R1">Bock &amp; Gordon, 2013</xref>; <xref ref-type="bibr" rid="R38">Taylor, 2020</xref>), containing around 80% of extant species, other orders are also mineralized and could be included in future model retraining. Therefore, future work will concentrate on increasing taxonomic coverage and expanding the app to other bryozoan orders. Likewise, the object detection performance of DeepBryo has clear room for improvement. Currently, it focuses on images obtained within the optimal magnification range for morphometric analyses (between 30x and 90x magnification) and therefore shows poor recall for small objects. It could, however, be adapted to lower magnification levels through the use of a sliding window approach, in which one large image gets subdivided into smaller high-resolution sub-windows. We generally consider larger magnifications (&gt;90x) as unlikely to be employed in morphometric studies of whole colonies, as the entire image would only encompass partial structures. Another significant challenge relates to the scale bars. Currently, DeepBryo utilizes manual digitization of scale bars. Automated recognition of scale bar size would reduce the need for human intervention during the prediction process. Finally, Deepbryo cannot account for discrepancies in the standards of different fields. For example, in macroevolutionary work, researchers tend to include the cystid as part of avicularia-related measurements. In taxonomic work, researchers will often keep the cystid as a separate entity and measure only the mandible and the proximal membranous part. Currently, DeepBryo adopts the standard used in macroevolutionary studies.</p><p id="P36">In summary, DeepBryo is a new web application that enables rapid morphometric characterization of cheilostome bryozoan images captured using SEM machines. The application has a simple web interface that requires no pre-processing of the image data. It enables users to predict, visualize, filter, and download segmentation results. With further image annotation and user feedback, we expect DeepBryo to grow significantly over time, providing researchers from different areas of biology the ability to use this emerging model system in tackling important research questions in their respective fields.</p></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplemental Material</label><media xlink:href="EMS157329-supplement-Supplemental_Material.pdf" mimetype="application" mime-subtype="pdf" id="d26aAdEbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S13"><title>Acknowledgements</title><p>This work was supported in part by grants from the Research Council of Norway (grant 314499 to EDM) and from NVIDIA Corporation (Nvidia Hardware Grant to AP). LHL and MHR received funding from the European Research Council under the European Union’s Horizon 2020 research and innovation program (grant agreement no. 724324 to LHL).</p></ack><sec id="S14" sec-type="data-availability"><title>Data Availability Statement</title><p id="P37">The entire training/validation dataset will be made available in appropriate repositories upon publication. A live server is available at <ext-link ext-link-type="uri" xlink:href="https://www.deepbryo.ngrok.io">https://www.deepbryo.ngrok.io</ext-link>. The DeepBryo source code can be found at <ext-link ext-link-type="uri" xlink:href="https://www.github.com/agporto/DeepBryo">https://www.github.com/agporto/DeepBryo</ext-link>.</p></sec><fn-group><fn id="FN1" fn-type="con"><p id="P38"><bold>AUTHORS' CONTRIBUTIONS</bold></p><p id="P39">AP and EDM conceived the study; AP trained the model and developed the application with inputs from all authors; All authors captured images, tested the application, and defined the taxonomy; AP, HLR, MHR and EDM annotated images; AP and EDM wrote the manuscript. All authors contributed to the manuscript revision.</p></fn><fn id="FN2" fn-type="conflict"><p id="P40"><bold>CONFLICT OF INTEREST</bold></p><p id="P41">The authors declare no conflict of interest.</p></fn></fn-group><ref-list><ref id="R1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bock</surname><given-names>P</given-names></name><name><surname>Gordon</surname><given-names>D</given-names></name></person-group><article-title>Phylum Bryozoa Ehrenberg, 1831</article-title><source>Zootaxa</source><year>2013</year><volume>3703</volume><fpage>67</fpage><lpage>74</lpage><pub-id pub-id-type="doi">10.11646/zootaxa.3703.1.14</pub-id></element-citation></ref><ref id="R2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bradski</surname><given-names>G</given-names></name></person-group><article-title>The OpenCV Library. Dr. Dobb’s</article-title><source>Software Tools for the Professional Programmer</source><year>2000</year><volume>25</volume><issue>11</issue><comment><ext-link ext-link-type="uri" xlink:href="https://www.elibrary.ru/item.asp?id=4934581">https://www.elibrary.ru/item.asp?id=4934581</ext-link></comment></element-citation></ref><ref id="R3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buss</surname><given-names>LW</given-names></name></person-group><article-title>Bryozoan overgrowth interactions—the interdependence of competition for space and food</article-title><source>Nature</source><year>1979</year><volume>281</volume><fpage>475</fpage><lpage>477</lpage><pub-id pub-id-type="doi">10.1038/281475a0</pub-id></element-citation></ref><ref id="R4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buslaev</surname><given-names>A</given-names></name><name><surname>Iglovikov</surname><given-names>VI</given-names></name><name><surname>Khvedchenya</surname><given-names>E</given-names></name><name><surname>Parinov</surname><given-names>A</given-names></name><name><surname>Druzhinin</surname><given-names>M</given-names></name><name><surname>Kalinin</surname><given-names>AA</given-names></name></person-group><article-title>Albumentations: Fast and Flexible Image Augmentations</article-title><source>Information</source><year>2020</year><volume>11</volume><issue>2</issue><comment>Article 2</comment><pub-id pub-id-type="doi">10.3390/info11020125</pub-id></element-citation></ref><ref id="R5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheetham</surname><given-names>AH</given-names></name></person-group><article-title>Tempo of Evolution in a Neogene Bryozoan: Rates of Morphologic Change Within and Across Species Boundaries</article-title><source>Paleobiology</source><year>1986a</year><volume>12</volume><issue>2</issue><fpage>190</fpage><lpage>202</lpage><pub-id pub-id-type="doi">10.1017/S0094837300013658</pub-id></element-citation></ref><ref id="R6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheetham</surname><given-names>AH</given-names></name></person-group><article-title>Branching, Biomechanics and Bryozoan evolution</article-title><source>Proceedings of the Royal Society of London Series B. Biological Sciences</source><year>1986b</year><pub-id pub-id-type="doi">10.1098/rspb.1986.0048</pub-id></element-citation></ref><ref id="R7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheetham</surname><given-names>AH</given-names></name></person-group><article-title>Tempo of Evolution in a Neogene Bryozoan: Are Trends in Single Morphologic Characters Misleading?</article-title><source>Paleobiology</source><year>1987</year><volume>13</volume><issue>3</issue><fpage>286</fpage><lpage>296</lpage></element-citation></ref><ref id="R8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheetham</surname><given-names>AH</given-names></name><name><surname>Jackson</surname><given-names>JBC</given-names></name><name><surname>Hayek</surname><given-names>L-AC</given-names></name></person-group><article-title>Quantitative Genetics of Bryozoan Phenotypic Evolution. I. Rate Tests for Random Change versus Selection in Differentiation of Living Species</article-title><source>Evolution: International Journal of Organic Evolution</source><year>1993</year><volume>47</volume><issue>5</issue><fpage>1526</fpage><lpage>1538</lpage><pub-id pub-id-type="pmid">28564886</pub-id></element-citation></ref><ref id="R9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheetham</surname><given-names>AH</given-names></name><name><surname>Jackson</surname><given-names>JBC</given-names></name><name><surname>Hayek</surname><given-names>L-AC</given-names></name></person-group><article-title>Quantitative Genetics of Bryozoan Phenotypic Evolution. II. Analysis of Selection and Random Change in Fossil Species Using Reconstructed Genetic Parameters</article-title><source>Evolution: An International Journal of Organic Evolution</source><year>1994</year><volume>48</volume><issue>2</issue><fpage>360</fpage><lpage>375</lpage><pub-id pub-id-type="pmid">28568292</pub-id></element-citation></ref><ref id="R10"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>T</given-names></name><name><surname>Guestrin</surname><given-names>C</given-names></name></person-group><source>XGBoost: A Scalable Tree Boosting System</source><conf-name>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</conf-name><year>2016</year><fpage>785</fpage><lpage>794</lpage><pub-id pub-id-type="doi">10.1145/2939672.2939785</pub-id></element-citation></ref><ref id="R11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clark</surname><given-names>N</given-names></name><name><surname>Williams</surname><given-names>M</given-names></name><name><surname>Okamura</surname><given-names>B</given-names></name><name><surname>Smellie</surname><given-names>J</given-names></name><name><surname>Nelson</surname><given-names>A</given-names></name><name><surname>Knowles</surname><given-names>T</given-names></name><name><surname>Taylor</surname><given-names>P</given-names></name><name><surname>Leng</surname><given-names>M</given-names></name><name><surname>Zalasiewicz</surname><given-names>J</given-names></name><name><surname>Haywood</surname><given-names>A</given-names></name></person-group><article-title>Early Pliocene Weddell Sea Seasonality Determined from Bryozoans</article-title><source>Stratigraphy</source><year>2010</year><volume>7</volume><fpage>199</fpage><lpage>206</lpage></element-citation></ref><ref id="R12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Di Martino</surname><given-names>E</given-names></name><name><surname>Liow</surname><given-names>LH</given-names></name></person-group><article-title>Trait-Fitness Associations do not Predict Within-Species Phenotypic Evolution over 2 Million Years</article-title><source>Proceedings of the Royal Society B: Biological Sciences</source><year>2021</year><volume>288</volume><issue>1943</issue><fpage>2020</fpage><lpage>2047</lpage><pub-id pub-id-type="pmcid">PMC7893266</pub-id><pub-id pub-id-type="pmid">33468005</pub-id><pub-id pub-id-type="doi">10.1098/rspb.2020.2047</pub-id></element-citation></ref><ref id="R13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Di Martino</surname><given-names>E</given-names></name><name><surname>Liow</surname><given-names>LH</given-names></name></person-group><article-title>Changing Allometric Relationships among Fossil and Recent Populations in Two Colonial Species</article-title><source>Evolution: An International Journal of Organic Evolution</source><year>2022</year><pub-id pub-id-type="pmid">35993139</pub-id></element-citation></ref><ref id="R14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Houle</surname><given-names>D</given-names></name><name><surname>Govindaraju</surname><given-names>DR</given-names></name><name><surname>Omholt</surname><given-names>S</given-names></name></person-group><article-title>Phenomics: The Next Challenge</article-title><source>Nature Reviews Genetics</source><year>2010</year><volume>11</volume><issue>12</issue><fpage>855</fpage><lpage>866</lpage><pub-id pub-id-type="pmid">21085204</pub-id></element-citation></ref><ref id="R15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jackson</surname><given-names>JBC</given-names></name><name><surname>Cheetham</surname><given-names>AH</given-names></name></person-group><article-title>Evolutionary Significance of Morphospecies: A Test with Cheilostome Bryozoa</article-title><source>Science</source><year>1990</year><volume>248</volume><issue>4955</issue><fpage>579</fpage><lpage>583</lpage><pub-id pub-id-type="pmid">17791464</pub-id></element-citation></ref><ref id="R16"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>T-Y</given-names></name><name><surname>Maire</surname><given-names>M</given-names></name><name><surname>Belongie</surname><given-names>S</given-names></name><name><surname>Hays</surname><given-names>J</given-names></name><name><surname>Perona</surname><given-names>P</given-names></name><name><surname>Ramanan</surname><given-names>D</given-names></name><name><surname>Dollár</surname><given-names>P</given-names></name><name><surname>Zitnick</surname><given-names>CL</given-names></name></person-group><chapter-title>Microsoft COCO: Common Objects in Context</chapter-title><person-group person-group-type="editor"><name><surname>Fleet</surname><given-names>D</given-names></name><name><surname>Pajdla</surname><given-names>T</given-names></name><name><surname>Schiele</surname><given-names>B</given-names></name><etal/></person-group><source>Computer Vision – ECCV 2014</source><publisher-name>Springer International Publishing</publisher-name><year>2014</year><fpage>740</fpage><lpage>755</lpage><pub-id pub-id-type="doi">10.1007/978-3-319-10602-1_48</pub-id></element-citation></ref><ref id="R17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liow</surname><given-names>LH</given-names></name><name><surname>Di Martino</surname><given-names>E</given-names></name><name><surname>Krzeminska</surname><given-names>M</given-names></name><name><surname>Ramsfjell</surname><given-names>M</given-names></name><name><surname>Rust</surname><given-names>S</given-names></name><name><surname>Taylor</surname><given-names>PD</given-names></name><name><surname>Voje</surname><given-names>KL</given-names></name></person-group><article-title>Relative Size Predicts Competitive Outcome through 2 Million Years</article-title><source>Ecology Letters</source><year>2017</year><volume>20</volume><issue>8</issue><fpage>981</fpage><lpage>988</lpage><pub-id pub-id-type="pmid">28614907</pub-id></element-citation></ref><ref id="R18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liow</surname><given-names>LH</given-names></name><name><surname>Taylor</surname><given-names>PD</given-names></name></person-group><article-title>Cope’s Rule in a Modular Organism: Directional Evolution Without an Overarching Macroevolutionary Trend</article-title><source>Evolution</source><year>2019</year><volume>73</volume><issue>9</issue><fpage>1863</fpage><lpage>1872</lpage><pub-id pub-id-type="pmcid">PMC6771556</pub-id><pub-id pub-id-type="pmid">31301184</pub-id><pub-id pub-id-type="doi">10.1111/evo.13800</pub-id></element-citation></ref><ref id="R19"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Z</given-names></name><name><surname>Lin</surname><given-names>Y</given-names></name><name><surname>Cao</surname><given-names>Y</given-names></name><name><surname>Hu</surname><given-names>H</given-names></name><name><surname>Wei</surname><given-names>Y</given-names></name><name><surname>Zhang</surname><given-names>Z</given-names></name><name><surname>Lin</surname><given-names>S</given-names></name><name><surname>Guo</surname><given-names>B</given-names></name></person-group><source>Swin Transformer: Hierarchical Vision Transformer using Shifted Windows</source><conf-name>2021 IEEE/CVF International Conference on Computer Vision (ICCV)</conf-name><year>2021</year><fpage>9992</fpage><lpage>10002</lpage><pub-id pub-id-type="doi">10.1109/ICCV48922.2021.00986</pub-id></element-citation></ref><ref id="R20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Love</surname><given-names>AC</given-names></name><name><surname>Grabowski</surname><given-names>M</given-names></name><name><surname>Houle</surname><given-names>D</given-names></name><name><surname>Liow</surname><given-names>LH</given-names></name><name><surname>Porto</surname><given-names>A</given-names></name><name><surname>Tsuboi</surname><given-names>M</given-names></name><name><surname>Voje</surname><given-names>KL</given-names></name><name><surname>Hunt</surname><given-names>G</given-names></name></person-group><article-title>Evolvability in the Fossil Record</article-title><source>Paleobiology</source><year>2022</year><volume>48</volume><issue>2</issue><fpage>186</fpage><lpage>209</lpage><pub-id pub-id-type="doi">10.1017/pab.2021.36</pub-id></element-citation></ref><ref id="R21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lürig</surname><given-names>MD</given-names></name><name><surname>Donoughe</surname><given-names>S</given-names></name><name><surname>Svensson</surname><given-names>EI</given-names></name><name><surname>Porto</surname><given-names>A</given-names></name><name><surname>Tsuboi</surname><given-names>M</given-names></name></person-group><article-title>Computer Vision, Machine Learning, and the Promise of Phenomics in Ecology and Evolutionary Biology</article-title><source>Frontiers in Ecology and Evolution</source><year>2021</year><volume>9</volume><pub-id pub-id-type="doi">10.3389/fevo.2021.642774</pub-id></element-citation></ref><ref id="R22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Melo</surname><given-names>D</given-names></name><name><surname>Porto</surname><given-names>A</given-names></name><name><surname>Cheverud</surname><given-names>JM</given-names></name><name><surname>Marroig</surname><given-names>G</given-names></name></person-group><article-title>Modularity: Genes, development and evolution</article-title><source>Annual Review of Ecology, Evolution, and Systematics</source><year>2016</year><volume>47</volume><fpage>463</fpage><lpage>486</lpage><pub-id pub-id-type="pmcid">PMC5617135</pub-id><pub-id pub-id-type="pmid">28966564</pub-id><pub-id pub-id-type="doi">10.1146/annurev-ecolsys-121415-032409</pub-id></element-citation></ref><ref id="R23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mongiardino Koch</surname><given-names>N</given-names></name><name><surname>Garwood</surname><given-names>RJ</given-names></name><name><surname>Parry</surname><given-names>LA</given-names></name></person-group><article-title>Fossils Improve Phylogenetic Analyses of Morphological Characters</article-title><source>Proceedings of the Royal Society B: Biological Sciences</source><year>2021</year><volume>288</volume><issue>1950</issue><elocation-id>20210044</elocation-id><pub-id pub-id-type="pmcid">PMC8246652</pub-id><pub-id pub-id-type="pmid">33947239</pub-id><pub-id pub-id-type="doi">10.1098/rspb.2021.0044</pub-id></element-citation></ref><ref id="R24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Dea</surname><given-names>A</given-names></name></person-group><article-title>Seasonality and Zooid Size Variation in Panamanian Encrusting Bryozoans</article-title><source>Journal of the Marine Biological Association of the UK</source><year>2003</year><volume>83</volume><fpage>1107</fpage><lpage>1108</lpage><pub-id pub-id-type="doi">10.1017/S0025315403008348h</pub-id></element-citation></ref><ref id="R25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Dea</surname><given-names>A</given-names></name><name><surname>Jackson</surname><given-names>J</given-names></name></person-group><article-title>Environmental Change Drove Macroevolution in Cupuladriid Bryozoans</article-title><source>Proceedings of the Royal Society B: Biological Sciences</source><year>2009</year><volume>276</volume><issue>1673</issue><fpage>3629</fpage><lpage>3634</lpage><pub-id pub-id-type="pmcid">PMC2817302</pub-id><pub-id pub-id-type="pmid">19640882</pub-id><pub-id pub-id-type="doi">10.1098/rspb.2009.0844</pub-id></element-citation></ref><ref id="R26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Dea</surname><given-names>A</given-names></name><name><surname>Jackson</surname><given-names>JBC</given-names></name></person-group><article-title>Bryozoan Growth Mirrors Contrasting Seasonal Regimes across the Isthmus of Panama</article-title><source>Palaeogeography, Palaeoclimatology, Palaeoecology</source><year>2002</year><volume>185</volume><issue>1</issue><fpage>77</fpage><lpage>94</lpage><pub-id pub-id-type="doi">10.1016/S0031-0182(02)00278-X</pub-id></element-citation></ref><ref id="R27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Dea</surname><given-names>A</given-names></name><name><surname>Okamura</surname><given-names>B</given-names></name></person-group><article-title>Intracolony Variation in Zooid Size in Cheilostome Bryozoans as a New Technique for Investigating Palaeoseasonality</article-title><source>Palaeogeography, Palaeoclimatology, Palaeoecology</source><year>2000</year><volume>162</volume><issue>3</issue><fpage>319</fpage><lpage>332</lpage><pub-id pub-id-type="doi">10.1016/S0031-0182(00)00136-X</pub-id></element-citation></ref><ref id="R28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Okamura</surname><given-names>B</given-names></name><name><surname>O’Dea</surname><given-names>A</given-names></name><name><surname>Taylor</surname><given-names>P</given-names></name><name><surname>Taylor</surname><given-names>A</given-names></name></person-group><article-title>Evidence of El Niño/La Niña-Southern Oscillation Variability in the Neogene-Pleistocene of Panama Revealed by a New Bryozoan Assemblage-Based Proxy</article-title><source>Bulletin of Marine Science</source><year>2013</year><volume>89</volume><issue>4</issue><fpage>857</fpage><lpage>876</lpage><pub-id pub-id-type="doi">10.5343/bms.2012.1041</pub-id></element-citation></ref><ref id="R29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Orr</surname><given-names>RJS</given-names></name><name><surname>Di Martino</surname><given-names>E</given-names></name><name><surname>Ramsfjell</surname><given-names>MH</given-names></name><name><surname>Gordon</surname><given-names>DP</given-names></name><name><surname>Berning</surname><given-names>B</given-names></name><name><surname>Chowdhury</surname><given-names>I</given-names></name><name><surname>Craig</surname><given-names>S</given-names></name><name><surname>Cumming</surname><given-names>RL</given-names></name><name><surname>Figuerola</surname><given-names>B</given-names></name><name><surname>Florence</surname><given-names>W</given-names></name><name><surname>Harmelin</surname><given-names>J-G</given-names></name><etal/></person-group><article-title>Paleozoic Origins of Cheilostome Bryozoans and their Parental Care Inferred by a New Genome-Skimmed Phylogeny</article-title><source>Science Advances</source><year>2022</year><volume>8</volume><issue>13</issue><elocation-id>eabm7452</elocation-id><pub-id pub-id-type="pmcid">PMC8967238</pub-id><pub-id pub-id-type="pmid">35353568</pub-id><pub-id pub-id-type="doi">10.1126/sciadv.abm7452</pub-id></element-citation></ref><ref id="R30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parry</surname><given-names>LA</given-names></name><name><surname>Edgecombe</surname><given-names>GD</given-names></name><name><surname>Eibye-Jacobsen</surname><given-names>D</given-names></name><name><surname>Vinther</surname><given-names>J</given-names></name></person-group><article-title>The Impact of Fossil Data on Annelid Phylogeny Inferred from Discrete Morphological Characters</article-title><source>Proceedings of the Royal Society B: Biological Sciences</source><year>2016</year><volume>283</volume><issue>1837</issue><elocation-id>20161378</elocation-id><pub-id pub-id-type="pmcid">PMC5013799</pub-id><pub-id pub-id-type="pmid">27581880</pub-id><pub-id pub-id-type="doi">10.1098/rspb.2016.1378</pub-id></element-citation></ref><ref id="R31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Porto</surname><given-names>A</given-names></name><name><surname>Rolfe</surname><given-names>S</given-names></name><name><surname>Maga</surname><given-names>AM</given-names></name></person-group><article-title>ALPACA: A Fast and Accurate Computer Vision Approach for Automated Landmarking of Three-Dimensional Biological Structures</article-title><source>Methods in Ecology and Evolution</source><year>2021</year><volume>12</volume><issue>11</issue><fpage>2129</fpage><lpage>2144</lpage><pub-id pub-id-type="pmcid">PMC9291522</pub-id><pub-id pub-id-type="pmid">35874971</pub-id><pub-id pub-id-type="doi">10.1111/2041-210X.13689</pub-id></element-citation></ref><ref id="R32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Porto</surname><given-names>A</given-names></name><name><surname>Voje</surname><given-names>KL</given-names></name></person-group><article-title>ML-morph: A Fast, Accurate and General Approach for Automated Detection and Landmarking of Biological Structures in Images</article-title><source>Methods in Ecology and Evolution</source><year>2020</year><volume>11</volume><issue>4</issue><fpage>500</fpage><lpage>512</lpage><pub-id pub-id-type="doi">10.1111/2041-210X.13373</pub-id></element-citation></ref><ref id="R33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schack</surname><given-names>CR</given-names></name><name><surname>Gordon</surname><given-names>DP</given-names></name><name><surname>Ryan</surname><given-names>KG</given-names></name></person-group><article-title>Modularity is the Mother of Invention: A Review of Polymorphism in Bryozoans</article-title><source>Biological Reviews</source><year>2019</year><volume>94</volume><issue>3</issue><fpage>773</fpage><lpage>809</lpage><pub-id pub-id-type="pmid">30450650</pub-id></element-citation></ref><ref id="R34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simpson</surname><given-names>C</given-names></name><name><surname>Jackson</surname><given-names>JBC</given-names></name></person-group><article-title>Bryozoan Revelations</article-title><source>Science Advances</source><year>2022</year><volume>8</volume><issue>13</issue><elocation-id>eabp9344</elocation-id><pub-id pub-id-type="pmid">35353562</pub-id></element-citation></ref><ref id="R35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Slater</surname><given-names>GJ</given-names></name></person-group><article-title>Phylogenetic Evidence for a Shift in the Mode of Mammalian Body Size Evolution at the Cretaceous-Palaeogene Boundary</article-title><source>Methods in Ecology and Evolution</source><year>2013</year><volume>4</volume><issue>8</issue><fpage>734</fpage><lpage>744</lpage><pub-id pub-id-type="doi">10.1111/2041-210X.12084</pub-id></element-citation></ref><ref id="R36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Slater</surname><given-names>GJ</given-names></name><name><surname>Harmon</surname><given-names>LJ</given-names></name><name><surname>Alfaro</surname><given-names>ME</given-names></name></person-group><article-title>Integrating Fossils with Molecular Phylogenies Improves Inference of Trait Evolution</article-title><source>Evolution</source><year>2012</year><volume>66</volume><issue>12</issue><fpage>3931</fpage><lpage>3944</lpage><pub-id pub-id-type="pmid">23206147</pub-id></element-citation></ref><ref id="R37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stehman</surname><given-names>SV</given-names></name></person-group><article-title>Selecting and Interpreting Measures of Thematic Classification Accuracy</article-title><source>Remote Sensing of Environment</source><year>1997</year><volume>62</volume><issue>1</issue><fpage>77</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1016/S0034-4257(97)00083-7</pub-id></element-citation></ref><ref id="R38"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Taylor</surname><given-names>PD</given-names></name></person-group><source>Bryozoan Paleobiology</source><publisher-name>John Wiley Sons</publisher-name><year>2020</year></element-citation></ref><ref id="R39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vandaele</surname><given-names>R</given-names></name><name><surname>Aceto</surname><given-names>J</given-names></name><name><surname>Muller</surname><given-names>M</given-names></name><name><surname>Péronnet</surname><given-names>F</given-names></name><name><surname>Debat</surname><given-names>V</given-names></name><name><surname>Wang</surname><given-names>C-W</given-names></name><name><surname>Huang</surname><given-names>C-T</given-names></name><name><surname>Jodogne</surname><given-names>S</given-names></name><name><surname>Martinive</surname><given-names>P</given-names></name><name><surname>Geurts</surname><given-names>P</given-names></name><name><surname>Marée</surname><given-names>R</given-names></name></person-group><article-title>Landmark Detection in 2D Bioimages for Geometric Morphometrics: A Multi-Resolution Tree-Based Approach</article-title><source>Scientific Reports</source><year>2018</year><volume>8</volume><issue>1</issue><comment>Article 1</comment><pub-id pub-id-type="pmcid">PMC5765108</pub-id><pub-id pub-id-type="pmid">29323201</pub-id><pub-id pub-id-type="doi">10.1038/s41598-017-18993-5</pub-id></element-citation></ref><ref id="R40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Voje</surname><given-names>KL</given-names></name><name><surname>Di Martino</surname><given-names>E</given-names></name><name><surname>Porto</surname><given-names>A</given-names></name></person-group><article-title>Revisiting a Landmark Study System: No Evidence for a Punctuated Mode of Evolution in Metrarabdotos</article-title><source>The American Naturalist</source><year>2020</year><volume>195</volume><issue>5</issue><fpage>899</fpage><lpage>917</lpage><pub-id pub-id-type="pmid">32364786</pub-id></element-citation></ref><ref id="R41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Z</given-names></name><name><surname>Zhang</surname><given-names>Z</given-names></name><name><surname>Ma</surname><given-names>J</given-names></name><name><surname>Taylor</surname><given-names>PD</given-names></name><name><surname>Strotz</surname><given-names>LC</given-names></name><name><surname>Jacquet</surname><given-names>SM</given-names></name><name><surname>Skovsted</surname><given-names>CB</given-names></name><name><surname>Chen</surname><given-names>F</given-names></name><name><surname>Han</surname><given-names>J</given-names></name><name><surname>Brock</surname><given-names>GA</given-names></name></person-group><article-title>Fossil Evidence Unveils an Early Cambrian Origin for Bryozoa</article-title><source>Nature</source><year>2021</year><volume>599</volume><issue>7884</issue><comment>Article 7884</comment><pub-id pub-id-type="pmcid">PMC8580826</pub-id><pub-id pub-id-type="pmid">34707285</pub-id><pub-id pub-id-type="doi">10.1038/s41586-021-04033-w</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>DeepBryo layout as displayed on a web browser.</title><p>(A) Image upload area; (B) Visualizing the model prediction; (C) Sidebar containing filtering, scaling, and output options; (D) Table output (optional).</p></caption><graphic xlink:href="EMS157329-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>DeepBryo output for unseen images from the validation set.</title><p>Segmentation masks are overlaid upon the original image using class-specific colors. All six object classes are represented across the four images. AZ (yellow): autozooid; Av (purple): avicularia; Or (pink): orifice; Asc (neon yellow): ascopore; Ov (light green): ovicell; Op (dark green): opesia. See <xref ref-type="supplementary-material" rid="SD1">Supplemental File 1</xref> for a glossary of terms. All scale bars are 100 μm.</p></caption><graphic xlink:href="EMS157329-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Average precision (AP) of the segmentation masks for an intersection-over-union (IoU) threshold of 50%.</title><p>(A) AP per object class; (B) AP per object size (small, medium, large). Note the clear association between AP values and object size. Refer to the main text for a description of the size classes and see <xref ref-type="supplementary-material" rid="SD1">Supplemental File 1</xref> for a glossary of terms.</p></caption><graphic xlink:href="EMS157329-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Confusion matrix illustrating the percentage of object predictions falling within each ground-truth object class. Note that the vast majority of object classes are correctly classified by the model.</title></caption><graphic xlink:href="EMS157329-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>Regression of predicted measurements against their ground truth counterparts. r2 and relative RMSE values are also reported within their respective plot. Rows: (A) Area; (B) Height (contour major axis); (C) Width (contour minor axis).</title></caption><graphic xlink:href="EMS157329-f005"/></fig><table-wrap id="T1" position="float" orientation="portrait"><label>Table 1</label><caption><title>Fourteen contour-based measurements that can be output by the DeepBryo web application for each object.</title><p>The first seven are basic shape descriptors and the remaining ones are the Hu moments of each contour. Hu Moments, routinely used int the computer vision literature for shape matching, are image moments that are invariant under translations, scale, and rotation.</p></caption><table frame="box" rules="all"><thead><tr style="background-color:#f3eec1"><th align="center" valign="middle">Measurements</th><th align="center" valign="middle">Description</th></tr></thead><tbody><tr style="background-color:#f7f7f7"><td align="center" valign="middle">Area</td><td align="center" valign="middle">area of the mask contour</td></tr><tr style="background-color:#f7f7f7"><td align="center" valign="middle">Perimeter</td><td align="center" valign="middle">perimeter of the mask contour</td></tr><tr style="background-color:#f7f7f7"><td align="center" valign="middle">Solidity</td><td align="center" valign="middle">area of the contour divided by the area of its convex hull</td></tr><tr style="background-color:#f7f7f7"><td align="center" valign="middle">Circularity</td><td align="center" valign="middle">measures how close the contour is to a circle</td></tr><tr style="background-color:#f7f7f7"><td align="center" valign="middle">Eccentricity</td><td align="center" valign="middle">ratio between the minor axis and the major axis</td></tr><tr style="background-color:#f7f7f7"><td align="center" valign="middle">Major Axis</td><td align="center" valign="middle">major axis of the contour (height of the structure)</td></tr><tr style="background-color:#f7f7f7"><td align="center" valign="middle">Minor Axis</td><td align="center" valign="middle">minor axis of the contour (width of the structure)</td></tr><tr style="background-color:#f7f7f7"><td align="center" valign="middle">Hu moments (1-7)</td><td align="center" valign="middle">contour moments that are invariant to translation, scale and rotation</td></tr></tbody></table><table-wrap-foot><fn id="TFN1"><label>*</label><p id="P42">Note: Circularity is measured as (4.πArea)/Perimeter<sup>2</sup></p></fn></table-wrap-foot></table-wrap></floats-group></article>