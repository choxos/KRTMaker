<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS157967</article-id><article-id pub-id-type="doi">10.1101/2022.11.30.518473</article-id><article-id pub-id-type="archive">PPR578205</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group><subj-group subj-group-type="europepmc-category"><subject>Covid-19</subject></subj-group></article-categories><title-group><article-title>DAPTEV: Deep aptamer evolutionary modelling for COVID-19 drug design</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Andress</surname><given-names>Cameron</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Kappel</surname><given-names>Kalli</given-names></name><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Cuperlovic-Culf</surname><given-names>Miroslava</given-names></name><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Yan</surname><given-names>Hongbin</given-names></name><xref ref-type="aff" rid="A4">4</xref></contrib><contrib contrib-type="author"><name><surname>Li</surname><given-names>Yifeng</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A5">5</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib></contrib-group><aff id="A1"><label>1</label>Department of Computer Science, Brock University, St. Catharines, ON, Canada</aff><aff id="A2"><label>2</label>Broad Institute of MIT and Harvard, Cambridge, MA, United States</aff><aff id="A3"><label>3</label>Digital Technologies Research Centre, National Research Council Canada, Ottawa, ON, Canada</aff><aff id="A4"><label>4</label>Department of Chemistry, Brock University, St. Catharines, ON, Canada</aff><aff id="A5"><label>5</label>Department of Biological Sciences, Brock University, St. Catharines, ON, Canada</aff><author-notes><corresp id="CR1"><label>*</label>corresponding author: <email>yli2@brocku.ca</email></corresp></author-notes><pub-date pub-type="nihms-submitted"><day>03</day><month>12</month><year>2022</year></pub-date><pub-date pub-type="preprint"><day>30</day><month>11</month><year>2022</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Typical drug discovery and development processes are costly, time consuming and often biased by expert opinion. Aptamers are short, single-stranded oligonucleotides (RNA/DNA) that bind to target proteins and other types of biomolecules. Compared with small-molecule drugs, aptamers can bind to their targets with high affinity (binding strength) and specificity (uniquely interacting with the target only). The conventional development process for aptamers utilizes a manual process known as Systematic Evolution of Ligands by Exponential Enrichment (SELEX), which is costly, slow, dependent on library choice and often produces aptamers that are not optimized. To address these challenges, in this research, we create an intelligent approach, named DAPTEV, for generating and evolving aptamer sequences to support aptamer-based drug discovery and development. Using the COVID-19 spike protein as a target, our computational results suggest that DAPTEV is able to produce structurally complex aptamers with strong binding affinities.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">Viruses contain <italic>deoxyribonucleic acid</italic> (DNA) or <italic>ribonucleic acid</italic> (RNA) but are incapable of self-reproduction and rely on commandeering the cell’s protein creation capabilities to reproduce. After the viral protein has been successfully reproduced, it goes on to infect other cells in a process known as <italic>viral proliferation</italic>. Attaching and injecting of viral DNA or RNA to host cells is achieved through binding to cellular receptor through <italic>receptor-binding domain</italic> (RBD), an area on the viral protein evolved to specifically bind hosts’ cell receptor. In the case of the SARS-CoV-2 spike protein, the RBD targets the lung cell angiotensin-converting enzyme (ACE2) receptor [<xref ref-type="bibr" rid="R1">1</xref>–<xref ref-type="bibr" rid="R6">6</xref>].</p><p id="P3">Typical drug discovery focuses on either preventative triggering of host’s immune system or interrupting the life cycle of the virus. The former usually refers to vaccines. The latter is known as a therapeutic, attempting to halt the infection process in a currently-infected host [<xref ref-type="bibr" rid="R1">1</xref>, <xref ref-type="bibr" rid="R7">7</xref>, <xref ref-type="bibr" rid="R8">8</xref>]. While vaccines tend to focus on infection prevention [<xref ref-type="bibr" rid="R8">8</xref>, <xref ref-type="bibr" rid="R9">9</xref>], therapy development can help alleviate suffering following infection.</p><p id="P4"><italic>Aptamers</italic> are short, single-stranded, oligonucleotides that can bind to targets with high affinity and specificity and it is hypothesize that specific aptamers can halt a virus during its life cycle by binding to the viral protein RBD there-by inhibiting its binding to host cell receptors. Aptamers can be created and modified easily and can bind to specific targets. One of the main ways to design aptamers is through a process known as <italic>systematic evolution of ligands by exponential enrichment</italic> (SELEX) [<xref ref-type="bibr" rid="R10">10</xref>] or <italic>high-throughput SELEX</italic> (HT-SELEX) [<xref ref-type="bibr" rid="R11">11</xref>] which applies high-throughput sequencing in each SELEX cycle. Design of aptamers through either SELEX or HT-SELEX is a slow, highly experimentally demanding process, possibly still providing sub-optimal designs [<xref ref-type="bibr" rid="R12">12</xref>–<xref ref-type="bibr" rid="R14">14</xref>] as these approaches rely of essentially a random search of top hits that are highly dependent on the initial choice of libraries [<xref ref-type="bibr" rid="R1">1</xref>,<xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R14">14</xref>–<xref ref-type="bibr" rid="R20">20</xref>].</p><p id="P5"><italic>Artificial intelligence</italic> (AI) techniques involve the modelling of brain intelligence to solve various challenging tasks [<xref ref-type="bibr" rid="R21">21</xref>]. As the most influential area in AI, <italic>machine learning</italic> (ML) improves intelligent agents or models using data and experience [<xref ref-type="bibr" rid="R22">22</xref>]. In the past few decades, machine learning has seen unprecedented progress. A variety of supervised and generative <italic>deep learning</italic> (DL) methods, <italic>i.e</italic>. neural networks, have been designed and achieved state-of-the-art performances in many domains [<xref ref-type="bibr" rid="R23">23</xref>]. Even though various AI and ML models have been recently developed for small-molecule drug design and achieved promising results [<xref ref-type="bibr" rid="R24">24</xref>–<xref ref-type="bibr" rid="R27">27</xref>], the end-to-end design of aptamers is a relatively unexplored domain [<xref ref-type="bibr" rid="R16">16</xref>, <xref ref-type="bibr" rid="R19">19</xref>]. This is partially due to the unfamiliarity of aptamers in the AI community, unavailability of quality data, and the shortage of chemoinformatics tools for this class of molecules. In this research, to determine if AI approaches can accelerate aptamer drug discovery and development for the treatment of SARS-CoV-2 infection, we developed an <italic>in silico</italic> RNA aptamer design process, named <italic>deep aptamer evolutionary model</italic> (DAPTEV), similar to the experimental SELEX process. DAPTEV takes advantage of the embedding and generating capacity of <italic>deep generative models</italic> (DGMs), the high-throughput exploration power of evolutionary computation, and the quantitative measure of RNA-target binding affinities through molecular mechanism. The performance of DAPTEV was evaluated using the SARS-CoV-2 spike protein as a target. This work has the following major contributions: (1) we designed a novel end-to-end aptamer generation and optimization model to explore its performance, which is highly informative to researchers in the drug design domain; (2) using the SARS-CoV-2 spike protein as a target, we assembled a benchmark dataset for aptamer drug development, which can be used and improved by researchers in the future; (3) we applied our framework to search for RNA aptamer therapeutics for COVID-19 treatment, discovering new aptamers that can be further validated as an alternative means to address our pandemic challenge.</p></sec><sec id="S2"><title>Related Work</title><p id="P6">Until recently, patents for the SELEX process limited the potential exploration and innovation in the field of aptamer-based drug development [<xref ref-type="bibr" rid="R19">19</xref>]. Moreover, sources on ML applied to aptamers were even more scarce. However, with the patents now expired, new research is being released, some of which implement a model related to the one proposed in this research.</p></sec><sec id="S3"><title>Unsupervised Aptamer Identification Methods</title><p id="P7">A naive method for aptamer selection in SELEX is based on read counts. However, due to bias in <italic>polymerase chain reaction</italic> (PCR) [<xref ref-type="bibr" rid="R28">28</xref>], the high abundance of reads does not indicate a high binding affinity. To address this issue, early computational methods focused on aptamer identification from SELEX pools using <italic>clustering</italic> and <italic>motif finding</italic>. Clustering techniques, such as AptaCluster [<xref ref-type="bibr" rid="R29">29</xref>] and FASTAptamer-Cluster [<xref ref-type="bibr" rid="R30">30</xref>], attempt to learn aptamer sequence commonalities, but suffer from a lack of secondary structure considerations. Motif-finding approaches, such as MEMRIS [<xref ref-type="bibr" rid="R31">31</xref>], Aptamotif [<xref ref-type="bibr" rid="R32">32</xref>], MPBind [<xref ref-type="bibr" rid="R28">28</xref>], and APtaTrace [<xref ref-type="bibr" rid="R33">33</xref>], attempt to identify structure patterns with strong binding affinities. However, motif-finding approaches do not consider entire secondary structures. Both options struggle with processing times associated to large HT-SELEX libraries. To address these issues while utilizing the strengths of these two approaches, <italic>Sequential Multidimensional Analysis AlgoRiThm for aptamer discovery</italic> (SMART-Aptamer) is presented in [<xref ref-type="bibr" rid="R14">14</xref>] which accurately and efficiently identifies aptamers from SELEX libraries containing hundreds of millions of short sequences. SMART-Aptamer first applies a Markov clustering method to obtain aptamer families and then filters out the majority of the aptamers using multiple scores considering the enrichment of motifs, the abundance of aptamer families, and the overall secondary structures.</p></sec><sec id="S4"><title>Supervised Aptamer-Protein Interaction Prediction Methods</title><p id="P8">Aptamers that bind to a small number of protein targets have been selected to form limited aptamer-protein interaction (API) data, enabling the use of supervised models to learn from known APIs and then predict whether a new aptamer interacts with one of the protein targets listed in the training data. Due to limited training samples, conventional classifiers and hand-crafted features have been applied to API prediction and obtained moderate performance (70-80% accuracy). In [<xref ref-type="bibr" rid="R34">34</xref>] a <italic>random forest</italic> classifier learns on an API dataset containing a few hundred positive samples. Their input features include nucleotide composition, traditional amino acid composition, and pseudo amino acid composition. Similarly, in [<xref ref-type="bibr" rid="R35">35</xref>], an ensemble method (random forests) with hybrid features is presented to predict APIs using <italic>Pseudo K-tuple Nucleotide Composition</italic> (PseKNC) features to encode aptamers along with protein features including <italic>discrete cosine transformation</italic> (DCT), disorder information, and bi-gram <italic>position specific scoring matrix</italic> (PSSM). The task of ncRNA-protein interaction prediction is similar to API prediction, but has more data available to enable the training of a deep classifier. For instance in [<xref ref-type="bibr" rid="R36">36</xref>], RPITER, a hierarchical deep learning model with <italic>convolutional neural network</italic> (CNN) and <italic>autoencoder</italic> (AE) modules, is developed to automatically learn features from a few thousands ncRNA-protein pairs and obtained promising performance for ncRNA-protein interaction prediction. When more API data becomes available in the future, similar deep models are anticipated for API prediction.</p></sec><sec id="S5"><title>Aptamer Generation</title><p id="P9">Im <italic>et al</italic>. used a generative model to build statically sized (20 nt) DNA and RNA sequences that bind to a target protein [<xref ref-type="bibr" rid="R37">37</xref>]. At the time of publication, it was specified that their research was ongoing, but they were able to train a <italic>long short-term memory</italic> (LSTM) model on a “huge dataset of sequences from high-throughput experimental technologies . . . such as HT-SELEX or CLIP-seq”. This dataset, which is still not available publicly, was obtained from DeepBind [<xref ref-type="bibr" rid="R38">38</xref>]. DeepBind was used to estimate the affinity and specificity of generated sequences. The target proteins in their research were as follows: DRGX, GCM1, OLIG1, RXRB, NFATC1, NFKB1, and MBNL1. It was found that the produced sequences possessed structural motifs similar to known motifs, and that the produced sequences had a strong binding affinity and specificity to their intended target [<xref ref-type="bibr" rid="R37">37</xref>]. This research was continued by Park <italic>et al</italic>. and a similar conclusion was drawn for RNA aptamers specifically [<xref ref-type="bibr" rid="R39">39</xref>]. In [<xref ref-type="bibr" rid="R40">40</xref>], Iwano <italic>et al</italic>. propose RaptGen which is similar to [<xref ref-type="bibr" rid="R37">37</xref>] and [<xref ref-type="bibr" rid="R39">39</xref>]. They too utilized DeepBind, however, RaptGen implemented a CNN-LSTM as their encoder and a profile <italic>hidden Markov model</italic> as their decoder. Additionally, while RaptGen starts with static sequence lengths (10 nt), it utilizes some post-processing techniques to extend the sequence lengths to a set of other fixed sizes, technically achieving sequence generation with variable lengths. Iwano <italic>et al</italic>.’s target proteins were the TGM2 and <italic>α</italic>v<italic>β</italic>3. The main difference between the research mentioned above and our own is as follows: (1) our model allows for the specification of a target RBD and calculating binding affinity based on thermodynamic principles rather than estimating binding via ML surrogate models; (2) our model optimizes aptamers to produce sequences with better binding affinity and specificity to the intended target instead of only generating aptamers having the same distribution as the training data; and (3) our model allows for true variable length sequences as input and output rather than fixed sized sequences.</p><p id="P10">In [<xref ref-type="bibr" rid="R13">13</xref>], Lee <italic>et al</italic>. present an aptamer generation method called Apt-MCTS. This method uses limited positive and negative aptamer-protein pairs to train a random forest classifier as a surrogate model to predict whether an aptamer can bind to a fixed protein target (one of 6GOF, 3V79_1, 5VOE, 3SN6_4, 2RH1_1, and 1ERK_1). The prediction result is used as a score to guide a <italic>Monte Carlo tree search</italic> (MCTS) [<xref ref-type="bibr" rid="R41">41</xref>] process for the generation of new aptamers. Apt-MCTS and our DAPTEV research utilize the same starting real aptamer data, but we further expanded this data by generating additional RNA sequences for model training. Apt-MCTS requires the availability of aptamer-protein pairs to train a surrogate model for API predictions. This disables the application of Apt-MCTS in our situation where experimental aptamer-spike protein interaction data are unavailable.</p><p id="P11">Wornow proposed a conditional VAE to generate novel strong-binding aptamers [<xref ref-type="bibr" rid="R19">19</xref>]. This too is similar to our work and findings. However, Wornow’s work utilized 8 rounds of SELEX data as a proof of concept on DNA data only. This creates a limitation of requiring experimental data to be collected before the model’s efficacy can be illustrated or be used in practice and does not explore the RNA landscape. The target for Wornow’s research is the chemotherapeutic agent daunomycin. Binding affinity was approximated based on ground truth fitness scores which were later confirmed by wet-lab experiments. They avoid the use of <italic>molecular dynamics</italic> (MD) simulations, stating they are computationally expensive and infeasible for use in the field.</p></sec><sec id="S6"><title>Molecular Optimization</title><p id="P12">Grantham <italic>et al</italic>. have developed a multi-objective deep learning framework named <italic>deep evolutionary learning</italic> (DEL) for small-molecule design. DEL is beneficial for improving sample populations in terms of property distributions and outperforms other multi-objective baseline molecular optimization algorithms [<xref ref-type="bibr" rid="R26">26</xref>]. While DEL does not work with aptamer data, it does focus on molecular optimization. Thus, it serves as inspiration for our DAPTEV.</p></sec><sec id="S7" sec-type="methods"><title>Method</title><p id="P13">Our <italic>deep aptamer evolutionary modelling</italic> (DAPTEV) framework is visualized in <xref ref-type="fig" rid="F1">Fig. 1</xref>. It is a hybrid approach that integrates the strengths of DGMs (variational autoencoders) for aptamer encoding and modelling, computational intelligence (evolutionary computation) for aptamer optimization, and bioinformatics tools for RNA secondary and tertiary structure prediction and RNA-protein folding-and-docking (Rosetta). The continuous docking score is used as the fitness value or objective in the evolutionary computation component to guide aptamer optimization.</p><p id="P14">First, a dataset must be collected for the training of the deep learning model and the initialization of the optimization process. The dataset should include a large number of aptamer sequences of certain lengths, their corresponding secondary structures, and docking scores to a protein target of interest. The secondary structures are needed by the Rosetta package [<xref ref-type="bibr" rid="R42">42</xref>] for docking. If secondary structures are unknown, they can be quickly computed using Arnie [<xref ref-type="bibr" rid="R43">43</xref>]. For details of assembling data to generate aptamers targeting SARS-CoV-2 spike protein, please refer to Section .</p><p id="P15">As an initialization step, a <italic>variational autoencoder</italic> (VAE) [<xref ref-type="bibr" rid="R44">44</xref>] is pretrained using the dataset. This VAE provides an encoding process that transforms an aptamer sequence to a vector of continuous values which is called the <italic>embedding vector</italic> or <italic>latent vector</italic> of the aptamer. Since the latent space is continuous, various metaheuristic techniques can be applied in this space for aptamer optimization. The decoder of the VAE enables a decoding process that converts a latent vector (either randomly sampled or modified using computational intelligence operations) to an aptamer sequence. Please refer to Section for details of our developed VAE.</p><p id="P16">The main body of the DAPTEV framework is an iterative evolutionary process. At the beginning of the loop, a population of aptamers are randomly sampled from the original dataset, then they are passed to the encoder to obtain latent representations. Evolutionary operations are applied to these latent representations and then these modified latent representations are decoded using the decoder to obtain their corresponding primary sequences. The fitness of these new sequences can be measured through aptamer-protein docking. After that, the newly produced aptamer sequences and the previous population of aptamer sequences are ranked together and only top aptamers are kept to form a new population of aptamers for the next generation. In the next generation, this new population is used to fine-tune the VAE model and then uses the encoder of the fine-tuned VAE to project the new population into the latent space where evolutionary operations are again applied. See Section for detailed discussion of the evolutionary operations. Each time when a new aptamer sequence is generated, Rosetta needs to be called to calculate the docking score. The docking component is detailed in Section . Furthermore, docking is a time-consuming process. Its speed-up is discussed in Section .</p></sec><sec id="S8"><title>Variational Autoencoder for Aptamer Modelling</title><p id="P17">VAE is a probabilistic deep generative model that takes advantage of the autoencoder architecture where the encoder network corresponds to the inference <italic>q<sub>ϕ</sub></italic>(<italic><bold>z</bold></italic>|<italic><bold>x</bold></italic>) and the decoder network realizes the generative component <italic>p<sub><bold>θ</bold></sub></italic>(<italic><bold>z</bold></italic>)<italic>p<sub><bold>θ</bold></sub></italic>(<italic><bold>x</bold></italic>|<italic><bold>z</bold></italic>). Here <italic><bold>x</bold></italic> is the vector of random variables for observed data (i.e., an aptamer sequence in our case), <italic><bold>z</bold></italic> is the vector of latent random variables, <italic><bold>ϕ</bold></italic> and <italic><bold>θ</bold></italic> are respectively the parameters of the inference network (encoder) and generative network (decoder) [<xref ref-type="bibr" rid="R44">44</xref>]. In our work, since aptamers are represented in primary sequences, <italic>gated recurrent units</italic> (GRU) [<xref ref-type="bibr" rid="R45">45</xref>] are used in the encoding and decoding processes. Thus, the resulted VAE is a probabilistic Seq2Sep structure. See <xref ref-type="fig" rid="F2">Fig. 2</xref> for a depiction of the implemented VAE.</p><p id="P18">Using “A” for adenine, “C” for cytosine, “G” for guanine, and “U” for uracil, an aptamer sequence of length <italic>L</italic> can be represented as <italic><bold>x</bold></italic> = [<italic>x<sub>i</sub></italic>|<italic>x<sub>i</sub></italic> ∈ {<italic>A, C, G, U</italic>}, <italic>i</italic> = 1, 2, … , <italic>L</italic>]. The <italic>word embedding</italic> representation techniques [<xref ref-type="bibr" rid="R46">46</xref>, <xref ref-type="bibr" rid="R47">47</xref>] can be used here by treating each letter as a word. However, this alone does not provide the model with enough context for how an RNA structure will interact with itself and the possible structural motifs that can occur. Thus, the combination of all possible 1, 2, and 3-mer strings (as tokens) are included in the vocabulary <inline-formula><mml:math id="M1"><mml:mrow><mml:mi mathvariant="script">V</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mtext>A</mml:mtext><mml:mo>,</mml:mo><mml:mtext>C</mml:mtext><mml:mo>,</mml:mo><mml:mtext>G</mml:mtext><mml:mo>,</mml:mo><mml:mtext>U</mml:mtext><mml:mo>,</mml:mo><mml:mtext>AA</mml:mtext><mml:mo>,</mml:mo><mml:mtext>AC</mml:mtext><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:mtext>UU</mml:mtext><mml:mo>,</mml:mo><mml:mtext>AAA</mml:mtext><mml:mo>,</mml:mo><mml:mtext>AAC</mml:mtext><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:mtext>UUU</mml:mtext><mml:mo>}</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> Conversely, adding too many combinations could drastically increase the computing time and the need for more training data. Thus, we restrict our vocabulary up to 3-mer. Three more special tokens are inserted into the vocabulary: &lt;BOS&gt; for beginning of sequence, &lt;EOS&gt; for end of sequence, and &lt;PAD&gt; for padding. Both the &lt;BOS&gt; and the &lt;EOS&gt; tokens inform DAPTEV of the character boundaries for each sequence. When working with sequences, one inevitably must choose how to handle sequences of variable lengths. Rather than restricting all sequences to the same length, limiting the versatility and learning capabilities of the model, &lt;PAD&gt; tokens are inserted into each sequence. In the encoding process, the sequence needs to be parsed into tokens. The 3-mer tokens have the highest priority in this process. A 2 or 1-mer token only appears at the end of the parsed result when a 3-mer parsing is no longer possible. Taking sequence GGCACAGAAGAUAUGGCUUCGUGCC for example, the parsed sequence of tokens is [GGC, ACA, GAA, GAU, AUG, GCU, UCG, UGC, C]. The decoding process follows a similar scheme. The decoding will stop when (1) it generates a 2 or 1-mer token, (2) an &lt;EOS&gt; token is generated, or (3) the length of the generated sequence meets the prespecified maximal length.</p><p id="P19">The bottleneck between the encoder and decoder is the latent layer representing the embedding of the whole sequence. From the autoencoder perspective, a latent vector contains the compressed key information about the corresponding input and this latent vector can be decoded to reconstruct the input. From the generative model perspective, the latent vector, following a simple prior distribution (a multivariate standard Gaussian distribution in our case), is the start of the generation process. The feasible domain of the latent vector forms the latent space.</p><p id="P20">Up to this point, the VAE designed above is not necessarily learning what makes an RNA sequence good or bad with respect to the Rosetta docking score. The VAE should be able to produce sequences with strong docking capabilities to a specified target. It is for this reason that an MLP component was included in the architecture of the VAE. This MLP performs score-based classification and further regularizes the latent representation. It takes a latent vector as input and predicts whether the sequence associated with the latent vector is good in terms of target binding, this vector and its associated score will be given to the MLP. A lower docking score implies a tighter binding. Thus, a “good docking score” is defined as ≤ the user-chosen score threshold parameter and a “bad docking score” is defined as &gt; the score threshold. This converts the scores to 1 (good) or 0 (bad). Note that one cannot simply set the score threshold to any low value desired as it can result in highly imbalanced data. To determine the optimal score threshold, one may locate the lowest score that still labels at least 25% of the data to Class 1 (as a rule of thumb only). For example, it was found that 26.28% of our data (see Section ) fell within the docking score range of 3,500 and below for this research. Thus, a score threshold of 3,500 was chosen in our experiment. Why is the docking quality prediction modelled as a classification problem rather than a regression problem? According to our experience in docking score modelling, regression usually has unsatisfactory performance.</p><p id="P21">The loss function of the VAE to be minimized in DAPTEV is formulated below <disp-formula id="FD1"><label>(1)</label><mml:math id="M2"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold-italic" mathsize="normal"><mml:mi>θ</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mtext>E</mml:mtext><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>ϕ</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold-italic" mathsize="normal"><mml:mi>z</mml:mi></mml:mstyle><mml:mo>∣</mml:mo><mml:mstyle mathvariant="bold-italic" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mi>log</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mstyle mathvariant="bold-italic" mathsize="normal"><mml:mi>θ</mml:mi></mml:mstyle></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold-italic" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo>∣</mml:mo><mml:mstyle mathvariant="bold-italic" mathsize="normal"><mml:mi>z</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mi>K</mml:mi><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mi>ϕ</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold-italic" mathsize="normal"><mml:mi>z</mml:mi></mml:mstyle><mml:mo>∣</mml:mo><mml:mstyle mathvariant="bold-italic" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo>∥</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mstyle mathvariant="bold-italic" mathsize="normal"><mml:mi>θ</mml:mi></mml:mstyle></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold-italic" mathsize="normal"><mml:mi>z</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mtext>E</mml:mtext><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>ϕ</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold-italic" mathsize="normal"><mml:mi>z</mml:mi></mml:mstyle><mml:mo>∣</mml:mo><mml:mstyle mathvariant="bold-italic" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mi>B</mml:mi><mml:mi>C</mml:mi><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>ψ</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p id="P22">where the first term corresponds to the reconstruction error, the second term is the <italic>Kullback-Leibler</italic> (KL) divergence that pushes the posterior towards the prior, and the last term is the <italic>binary cross-entropy</italic> (BCE) loss for the MLP (parameterized by <italic><bold>ψ</bold></italic>) performance where <italic>f<sub><bold>ψ</bold></sub></italic>(<italic><bold>z</bold></italic>) is the predicted value and <italic>y</italic> is the actual class label. The trade-off hyperparameters <italic>α</italic> and <italic>β</italic> control the balance among these three terms. The KL loss term tends to vanish easily during training in the vanilla VAE where <italic>β</italic> = 1. This can negatively affect the reconstruction learning process. To address this issue, we implemented a technique known as <italic>KL annealing</italic> [<xref ref-type="bibr" rid="R26">26</xref>, <xref ref-type="bibr" rid="R48">48</xref>] to control the value of <italic>β</italic>. The annealing process applies a small weight, between 0 and 1, to the KL loss value and linearly increases this weight during training.</p></sec><sec id="S9"><title>Evolutionary Operations for Aptamer Optimization</title><p id="P23">Each evolutionary generation ensures the VAE has finished a round of training (fine-tuning) such that DAPTEV can then begin the sequence optimization step. This is when DAPTEV searches for better sequences and update its running data accordingly in every generation. Three Darwinian evolutionary operations are involved in this step.</p><p id="P24">The first operation is known as <italic>tournament selection with elitism</italic>. <italic>Elitism</italic> is the action of selecting the top <italic>e</italic> best individuals (sequences) in a population to be carried forward into the next generation. This ensures the best individuals remain in the running data and are not filtered out during tournament selection. Tournament selection is the process of randomly sampling sequences from the population and having these candidates compete in a tournament. The winner of each tournament will be selected as a <italic>parent</italic> to produce the next generation of <italic>children</italic>. This process is repeated multiple times until the parent pool equals the chosen population size. The tournament selection operation is controlled by two hyperparameters. One is the <italic>k</italic> value which indicates how many contenders with which to build a tournament round. The higher the <italic>k</italic> value, the more likely a stronger performing individual will be selected to win the tournament and proceed as a parent for the next generation. This, in turn, means there is a higher likelihood that poor-performing individuals will not be selected to proceed as parents (referred to as <italic>selection pressure</italic>), which can often have a detrimental effect on exploration. The other hyperparameter is the <italic>selection rate</italic>. This parameter creates a possibility for the best-performing individual in a tournament pool to opt out, allowing some poor-performing individuals to be selected instead.</p><p id="P25">The second evolutionary operation is <italic>crossover</italic>. This is the process of producing children from two parents, attempting to simulate a child obtaining features from their parents. After the selection operation is performed, the sequences are passed through the VAE’s encoder to obtain their latent representations (<italic><bold>z</bold></italic>s). Then, the crossover operation is applied to these parent <italic><bold>z</bold></italic> vectors whereby parent <italic><bold>z</bold><sub>pa</sub></italic> and parent <italic><bold>z</bold><sub>pb</sub></italic> will each copy random parts of their latent vectors to new children vectors <italic><bold>z</bold><sub>ca</sub></italic> and <italic><bold>z</bold><sub>cb</sub></italic>. This procedure is repeated until the number of children equals the population size. Similar to the tournament selection, this operation also has a probability of occurring (called <italic>crossover rate</italic>). Note that too small of a population size will result in a low amount of “<italic>genetic diversity</italic>” which can quickly converge to a local minimum (suboptimal solution). This means that there will not be enough sequences in a given generation to produce sufficiently dissimilar children from the parent sequences. Eventually, all produced sequences could start to resemble each other and/or the algorithm will be unable to find better sequences due to the lack of “genetic diversity” among available sequences.</p><p id="P26">The last evolutionary operation is <italic>mutation</italic>, mimicking random mutations in evolution. Some random influence should be allowed such that an individual may find themselves performing significantly better than the rest. In DAPTEV, mutation is implemented by selecting, with a probability called <italic>mutation rate</italic>, a child from the crossover result. Then a random index of that child’s <italic><bold>z</bold></italic> vector is chosen and replaced with a random, normally distributed value. The mutation rate should be very small. A large rate will result in the algorithm essentially performing just a random search, corrupting any learning.</p><p id="P27">Once the new latent vectors have completed a round of evolutionary operations, they are sent through the VAE’s decoder. This will generate the sequences based on the VAE’s previously trained decoding capabilities. The output will be a list of new sequences. Any duplicates in this list, as compared to themselves, the starting data, and any previously predicted sequences will be removed and replaced with new, folded, random sequences. However, docking scores for these new sequences are unknown. Thus, the docking simulation is repeated before the VAE continues to fine-tune using the new population.</p></sec><sec id="S10"><title>RNA-Protein Docking</title><p id="P28">Rosetta models RNA-protein complexes by simultaneously folding and docking an RNA to a protein surface via a statistical RNA-protein docking scoring function [<xref ref-type="bibr" rid="R42">42</xref>]. This allows one to specify a target protein and the target’s RBD. There are two scoring functions within DAPTEV’s usage of Rosetta: <italic>native Rosetta docking score function</italic> and <italic>constraint scoring function</italic>.</p><p id="P29">The native Rosetta scoring function is a low-resolution, coarse-grained, knowledge-based (statistical) RNA-protein potential. This serves as an energy function for scoring Monte Carlo steps within the tertiary structure prediction and docking simulation. The lower the returned score is after the tertiary structure prediction and docking simulation, the more stable the predicted complex is considered to be. In Rosetta, all previously published score terms describing RNA structure and RNA-protein interactions are included in this scoring function [<xref ref-type="bibr" rid="R42">42</xref>], while also providing rapid computation and maintaining coarse-granularity. It is reported in [<xref ref-type="bibr" rid="R42">42</xref>] that, over ten popular scoring systems, the best-performing scoring models achieved an average atomic <italic>root-mean-squared deviation</italic> (RMSD) of 11.6 Å for 3dRPC and 10.2 Å for DARS-RNP, whereas Rosetta’s score function achieved an RMSD of 6.4 Å.</p><p id="P30">The constraint scoring function applies to where on the protein the RNA docks. This constraint function allows one to specify the target’s RBD region without having to force a fixed binary interaction between specific atoms of the RNA and the target protein. Instead, one indicates to Rosetta their chosen constraint type, to which atoms on the target and the RNA the constraint applies, and what built-in formula the constraint will use to calculate an energetic penalty. This penalty will be applied against the returned Rosetta score to passively discourage the RNA from docking elsewhere on the target. As a result, the RNA has a range of acceptable distances it can deviate from the target’s RBD during the docking simulation.</p><p id="P31">DAPTEV uses an “atom pair” constraint with a flat harmonic function. The middle position (nucleotide) of every produced RNA sequence is chosen as the constrained RNA nucleotide. This function is formulated below, <disp-formula id="FD2"><label>(2)</label><mml:math id="M3"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mtable columnalign="left" equalrows="true" equalcolumns="true"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mn>0</mml:mn></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext><mml:mspace width="0.2em"/><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mo>≤</mml:mo><mml:mi>x</mml:mi><mml:mo>≤</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>otherwise</mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P32">where, <italic>x</italic> represents the distance between the two atoms (this varies as Rosetta attempts multiple conformations), <italic>x</italic><sub>0</sub> is the ideal distance between the atoms, <italic>sd</italic> is the standard deviation from the ideal distance, and <italic>f</italic>(<italic>x</italic>) is the returned penalty. This function produces a penalty of 0 if <italic>x</italic> falls in the range [<italic>x</italic><sub>0</sub> – <italic>tol, x</italic><sub>0</sub> + <italic>tol</italic>], where <italic>tol</italic> means tolerance. In our research, we set <italic>x</italic><sub>0</sub> = 0, <italic>sd</italic> = 0.125, and <italic>tol</italic> = 1.</p></sec><sec id="S11"><title>Computing Time Improvement</title><p id="P33">A challenge for utilizing Rosetta in DAPTEV is the computational demand and time required to perform docking simulations. For an experiment with population size 800, generation number 10, and 3 runs, it could take about 4 years if the <italic>full</italic> SARS-CoV-2 spike protein was used and docking simulations ran <italic>sequentially</italic>. The running time can be reduced to roughly one-third of a year by reducing the protein file to just the RBD. However, this is still too long to wait for one experiment to finish. As such, <italic>multiprocessing</italic> was implemented into DAPTEV. Multiprocessing is a technique to run multiple docking simulations on a computer’s multiple CPUs at the same time (in parallel). DAPTEV utilized 18 CPUs to effectively reduce computing time for each docking simulation from roughly 6.5 minutes (also using the reduced protein) to 1 minute per aptamer sequence.</p></sec><sec id="S12"><title>Experimental Results</title><sec id="S13"><title>Data</title><p id="P34">In our experiments, we used the SARS-CoV-2 spike glycoprotein (closed state, PDB: 6VXX) [<xref ref-type="bibr" rid="R5">5</xref>] as the docking target with an RBD between residues 333 and 524 [<xref ref-type="bibr" rid="R2">2</xref>, <xref ref-type="bibr" rid="R4">4</xref>–<xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R49">49</xref>]. See <xref ref-type="fig" rid="F3">Fig. 3</xref> for an illustration. As it shows, the SARS-CoV-2 spike protein’s RBD represents a relatively small area at the apical face of the protein. Using the entire spike protein in the docking procedure would drastically increase the computation time. For example, performing five runs of the docking process with an RNA base count of 25 on the full SARS-CoV-2 spike protein took over 98 minutes to finish computing. Thus, one should remove all unnecessary residues from the target PDB file and save the new PDB structure and the new FASTA sequence. Unnecessary residues are those on the target that an RNA could not possibly interact with during the RBD-docking process due to constraint specification. Once these residues are removed, the PDB file must be cleaned (renumbered and sequenced).</p><p id="P35">For the implementation in the docking, the protein is cropped according to the RBD and renumbered. The chosen RBD residue number is 201 and the associated chain is “A” for the Rosetta constraint. <xref ref-type="fig" rid="F3">Fig. 3</xref> shows a visual of the chosen residue. The carbon atom “C5” is ubiquitous among RNA bases [<xref ref-type="bibr" rid="R50">50</xref>]. This was the reason behind choosing “C5” as the RNA atom parameter. Doing so required no additional calculations to be performed and was simple to implement.</p><p id="P36">While an entire dataset can be created using the random sequence generator, it is best to augment the dataset with known aptamers. Providing existing aptamer data will add diversity into the dataset, will expose the model to physical characteristics of existing aptamers, and will help the model learn these traits. This will also allow DAPTEV to rule out or confirm existing aptamers as potential solutions to the given problem as it is possible that a known aptamer is already a good fit for the specified target. As a result, supplying existing aptamer data could provide DAPTEV with a strong starting position before it begins exploring other options.</p><p id="P37">We do not allow unfolded RNA secondary structures to be created when performing random sequence generation. Associated secondary structures will be restricted to having at least one set of brackets (base pair connections). It has been observed during the experimental phase that unfolded secondary structures produce RNA tertiary structures that are more malleable when docking to the target’s RBD. Thus, unfolded sequences can better form to the target’s RBD topology, producing strong binding scores (binding affinity). However, aptamers are designed not only for high binding affinity but also for target specificity [<xref ref-type="bibr" rid="R1">1</xref>, <xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R15">15</xref>–<xref ref-type="bibr" rid="R18">18</xref>,<xref ref-type="bibr" rid="R20">20</xref>]. An unfolded structure would not be considered “specific” to a target because it could potentially bind just as well to another target. Furthermore, the Rosetta scoring function for the docking process includes the quality of the RNA tertiary structure prediction. This means that the returned score for any sequence in this model may be deceptively “improved” due to encountering few stability-related penalties during the structure prediction and docking process. As a result, the scores produced by unfolded RNA structures are artificially and significantly better than their more structurally-complex peers. This can result in the algorithm producing many unfolded RNA aptamers, which would not be ideal for aptamer drug development as the goal is to optimize the aptamer discovery process for a specific target only (specificity).</p><p id="P38">After obtaining 849 unique known aptamer sequences [<xref ref-type="bibr" rid="R13">13</xref>, <xref ref-type="bibr" rid="R51">51</xref>, <xref ref-type="bibr" rid="R52">52</xref>], only 390 met the condition of being between the minimum (20) and maximum (40) sequence lengths. Of those 390 aptamer, 344 contained at least one connection (base pairing) in their secondary structures. 44 sequences were too small, 417 sequences were too large and an additional 44 sequences were unfolded (based on the returned Arnie secondary structure predictions). As 12,000 data points were required, an additional 11,656 random sequences were generated and scored. These sequences were restricted to having lengths between 20 and 40 nts, an approximate GC percentage of 50%, and containing at least one secondary structure connection.</p></sec><sec id="S14"><title>Hyperparameter Setting</title><p id="P39">In our experiments, the settings of hyperparameters for the data collection process, the evolutionary optimization process, and the structure and training of the VAE are listed in <xref ref-type="table" rid="T1">Table 1</xref>.</p></sec><sec id="S15"><title>Baselines</title><p id="P40">The experiment of DAPTEV is accompanied by two additional comparison models: a genetic algorithm on the sequence space (GA), and a “hill climer” algorithm (HC).</p><p id="P41">The GA baseline is to simply remove the VAE from DAPTEV, resulting in a GA operating on the problem space rather than the latent space, to see how their performance differs. It is worth noting that the VAE and the GA are not restricted to producing only folded structures. As such, these models do have a possibility of generating unfolded sequences. This is allowed to more deeply explore the solution landscape and potentially encounter stronger sequences through the prediction process. For the crossover function in GA, instead of selecting random indices of parent <italic><bold>z</bold><sub>pa</sub></italic> and parent <italic><bold>z</bold><sub>pb</sub></italic> (latent vectors), parents <italic><bold>x</bold><sub>pa</sub></italic> and <italic><bold>x</bold><sub>pb</sub></italic> will have random indices of the sequence space selected for crossover. The resulting children will be two new sequences. For the mutation function in GA, an individual is selected with a small probability. If selected, a random index of within the sequence is randomly chosen such that the corresponding letter is replaced with a random token from the vocabulary list excluding &lt;BOS&gt;, &lt;PAD&gt;, and &lt;EOS&gt;.</p><p id="P42">The HC baseline generates <italic>random</italic> sequences using our dataset creation script with the same chosen hyperparameters as the DAPTEV. This process is repeated for the same number of sequences, generations, and runs as the DAPTEV. The best performing sequences are carried forward into the next generation and all other sequences up to the chosen population size are discarded. This is known as a “hill climber” because this algorithm employs the simple heuristic of “always take the best” without any actual “learning”.</p></sec><sec id="S16"><title>VAE Performance</title><p id="P43"><xref ref-type="fig" rid="F4">Fig. 4</xref> shows how the VAE’s encoder, MLP, and decoder modules performed per epoch and over each generation (plotted separately on the same graph). The total loss values are also shown in this figure. In the first generation, the VAE is trained on the entire dataset of 12,000 sequences. It shows that, the KL loss can quickly decrease to a small value after 10 epochs. Each subsequent generation shows the encoder module continues to improve on the KL loss and approaches a near zero loss value. The MLP regularization module performs similarly. It shows that this module is also refining its performance. In fact, the module learned to perfectly classify the data halfway through generation five. The reconstruction loss graph suggests that, after the first generation, the decoder is learning how to reproduce the encoded latent vectors very well. The total loss graph shows the VAE’s overall performance per epoch per generation. As each model effectively reduced its loss values, it stands to reason that the total loss would reflect this performance.</p></sec><sec id="S17"><title>Comparison in Terms of Docking Score</title><p id="P44"><xref ref-type="table" rid="T2">Table 2</xref> provides details on the overall docking score optimization performance for each model. Here, it can be seen that both DAPTEV and the GA improved significantly from their worst scores to their best scores, with GA outperforming DAPTEV. However, in comparison to the hill climber model, both DAPTEV and GA have performed better.</p><p id="P45"><xref ref-type="fig" rid="F5">Fig. 5</xref> shows the best, worst, mean, and median performing docking scores produced by each model per generation. The provided graphs are scaled logarithmically as the hill climber (“Random” in the legend) experiment performed significantly worse than DAPTEV and GA. It is clear that GA produced better results than DAPTEV in terms of docking scores. The lowest (best) score produced by DAPTEV was 98 in generation three, whereas GA obtained its lowest score of 4 in generation nine. DAPTEV’s worst scores fell from 1,470 to 857 whereas GA’s worst score fell from 1,439 to 460. Both the means and medians seem to follow a fairly similar trend and are comparable in score output.</p><p id="P46">It also seemed prudent to consider the best five and worst five mean scores for each experiment. The absolute best and worst can send an extreme message and may not convey the true performance of each experiment. This is because the absolute best and worst do not include neighbouring sequence performance. If these models are indeed performing well, then one would expect to see the sequences near the best and worst improving overall. <xref ref-type="fig" rid="F6">Fig. 6</xref> depicts the best and worst five score means per generation. Here, one can see that GA is indeed performing better than DAPTEV in terms of docking score statistics across generations.</p><p id="P47">Furthermore, to have a full view of the binding score distribution for each method, the density curves of Aptamers’ binding scores in the last generations of DAPTEV, GA, and HC (i.e., Random) are displayed in <xref ref-type="fig" rid="F7">Fig. 7</xref>. From the density plots, one can conclude that (1) DAPTEV and GA obtained Aptamer sequences with significantly better binding scores than HC (Mann-Whitney U test, p-value=7.25e-226 and p-value=2.31e-256, respectively), and (2) GA’s result is better than DAPTEV’s result in terms of docking score distribution (Mann-Whitney U test, p-value=8.47e-142).</p></sec><sec id="S18"><title>Comparison in Terms of Base Pairing</title><p id="P48">Thus far, it has seemed as though GA is the best suited model for this application. However, there are two goals for this experiment. While the first goal is to optimize the docking scores, the second goal is to produce sequences with at least one connection (nucleotide base pairing) in the secondary structures. In other words, these models were also supposed to learn the key features of well-performing structural motifs applied to the SARS-CoV-2 spike protein RBD.</p><p id="P49"><xref ref-type="table" rid="T3">Table 3</xref> provides further details on the produced folded sequences. The GA performed rather poorly in this task, only producing 47 (on average) folded structures out of 800 total sequences, achieving an 6% fold rate. Conversely, DAPTEV produced 272 (on average) folded structures out of 800 total sequences, achieving a 34% fold rate. It is important to note that the HC (random) algorithm entirely constructed folded RNAs as the dataset creation script does not allow for unfolded structures in its random search.</p><p id="P50">In <xref ref-type="fig" rid="F8">Fig. 8a</xref>, the best folded complex has a docking score of 128 with two base pairings in its secondary structure. Interestingly, every model produced the same best performing folded RNA. The median complex has a score of 653, also with two base pairings, and the worst has a score of 857 with one base pairing. <xref ref-type="fig" rid="F8">Fig. 8b</xref> has a median docking score of 358 with four base pairings, and the worst score of 460 has three base pairings. Every complex in <xref ref-type="fig" rid="F8">Fig. 8c</xref> has folded RNAs due to the nature of the dataset creation script. The median score is 1,122 with three base pairings and the worst score is 1,530 with one base pairing.</p></sec><sec id="S19"><title>Novelty and Diversity of Generated Aptamers</title><p id="P51">Lastly, two additional metrics were calculated to assess model performance. These metrics, expressed as ratios, include novelty and diversity. <italic>Novelty</italic> is calculated as the number of generated sequences that do not exist in the initial training data versus the total number of generated sequences in a generation (the “population size”). <italic>Diversity</italic> is calculated as the number of generated unique sequences versus the total number of generated sequences in a generation. The novelty values calculated for DAPTEV and GA’s last generations are 0.8475 and 0.9962 respectively. Similarly, the diversity values were 0.8487 and 0.9937 respectively. Hence, both DAPTEV and GA show good novelty and diversity, and GA seems always to produce novel and unique sequences.</p></sec></sec><sec id="S20" sec-type="discussion | conclusions"><title>Discussion and Conclusion</title><sec id="S21"><title>Observations</title><p id="P52">While it may seem that GA performed the best in terms of docking scores, this is not actually the case if the aptamer structures are considered as well. As previously mentioned, the docking score can be artificially improved by producing an unfolded RNA secondary structure which, in turn, will incur fewer penalties during the RNA tertiary structure prediction and the docking simulation. If a model prioritizes only unconnected structures, it stands to reason that it would seem to perform better when only considering score output. However, the expectation of this research is three-fold. (1) The docking scores has to be optimized. This was accomplished best by GA as substantiated by the returned scores and statistical analysis. (2) Some learning of well-performing structural motifs in the provided RNA secondary structures is required. Producing unfolded RNAs is not overly helpful when attempting to develop aptamer-based drugs. Even if this is a desirable trait, we expect to produce more complex structures from intelligent models and not be forced to sacrifice these features. Based on the percentage of folded structures in the last generation, it is clear that DAPTEV performs significantly better than GA. This points to the conclusion that GA solely prioritized the optimization of scores to the detriment of structural complexity. These results also indicate that DAPTEV is indeed able to learn structural motif patterns from the training data. (3) The deep learning model has to possess the ability to be queried for new, well-performing, structurally connected RNAs to explore aptamer-based drug discovery. This point implies the persistence of a trained model and a way to request new data. A GA must be trained every time new sequences are required. A VAE, conversely, can have its current state of learning saved and reloaded nearly immediately. Furthermore, new sequences can be obtained immediately. With everything mentioned above, one could posit that DAPTEV performs admirably in all three requirements. Additionally, every score produced in the last generation of DAPTEV was below the score threshold of 3,500, which was docking score limit set initially to tell the VAE that a sequence was performing well. DAPTEV was able to learn structural features and other characteristics that make RNA perform well when docking to a specific target. Finally, the model can be saved and queried for new sequences that should perform well at docking to a specific target’s RBD while also maintaining some structural complexity. In contrast, GA and the hill climber algorithm must both be retrained every time, GA prioritized score optimization at the cost of motif preservation, and the hill climber is likely to yield poor results due to premature convergence at a local minimum.</p></sec><sec id="S22"><title>Limitations</title><p id="P53">There are some limitations of this research. Firstly, DAPTEV did not have enough starting aptamer data in the initial dataset. Only 849 unique, known, aptamer sequences were found during the literature review stage, but that was narrowed down further to only 344 due to parameter and computation time constraints.</p><p id="P54">Secondly, at present DAPTEV does not work with DNAs due to the limitations of utilized software. While this research was mainly focused on RNAs, some other research has worked on DNAs. It would have been preferable to include DNAs in the capabilities of this model.</p><p id="P55">The randomly generated sequences must have at least one connection. However, more control over the secondary structure is preferred. The specification of connection amounts or a range of acceptable connections would be beneficial. Furthermore, the DAPTEV model is affected by limited accuracy from the structure/energy prediction process of both secondary and tertiary structures.</p><p id="P56">Currently, DAPTEV assumes that the latent space follows a Gaussian distribution. This distribution may not be robust enough to capture the complexity of the task. Testing different distributions could have yielded further insight into the VAE’s ability to operate in this problem space.</p></sec><sec id="S23" sec-type="conclusions"><title>Conclusion</title><p id="P57">The goal of this research was to see if a deep generative model would be efficient at accelerating the RNA aptamer drug development process. While this research was applied to the SARS-CoV-2 spike protein, careful consideration was placed into the universal design for nearly any protein target. With regard to target affinity, one could conclude that both DAPTEV and GA performed well at this task. While the GA did outperform DAPTEV in this regard, the difference between these two models was not very large. Especially when considering that the score threshold was set to 3,500 and DAPTEV was still able to produce scores significantly lower than that. For target specificity, DAPTEV certainly shows some promising results. This is especially true when compared to GA. DAPTEV had an output with 34% of its produced sequences containing at least one connection in the secondary structure. This number could have been even higher if more vocabulary combinations had been implemented and some additional parameter tests were run. Conversely, GA only produced a 6% fold rate. This indicates that the VAE was indeed able to learn some structural features of the data and the MLP regularizer performed well at its task. The code for this model is accessible at <ext-link ext-link-type="uri" xlink:href="https://github.com/candress/DAPTEV_Model">https://github.com/candress/DAPTEV_Model</ext-link>.</p></sec><sec id="S24"><title>Future Work</title><p id="P58">Several additional features and considerations could improve this research. (1) One such consideration is the fact that there was not enough starting real aptamer data. It would have been preferable to add more to the starting dataset. Unfortunately, at the time of searching, it seemed most of the aptamer datasets and databases were taken down. (2) Currently, this model only accepts RNA data. However, DNA aptamers are more common in literature. It would be beneficial to include the capability to work with DNA data. (3) Allowing the user to perform tertiary structure prediction separately, or to provide pre-calculated tertiary structure could be beneficial. (4) Also, statically choosing the protein atom of CA and the RNA atom of C5 may be negatively affecting the performance as there is no determination of which atoms are more likely to interact. Instead, the interactions between each atom present in the protein residue and the possible RNA bases could have been pre-calculated. (5) It would be beneficial to increase the vocabulary combination amount. This DAPTEV only allows for combinations up to three characters long to reduce computation time. However, a vocabulary length of size three impedes the model’s ability to learn more complex structural motifs. (6) Some additional considerations and implementations could be the following: a learnable KL/reconstruction loss balancing component could be implemented so the model regulates the weights of the KL and the reconstruction loss [<xref ref-type="bibr" rid="R53">53</xref>]. Transformer is another versatile deep learning model that relies entirely on self-attention and is well-suited for design tasks [<xref ref-type="bibr" rid="R54">54</xref>], but requires more data to train. Given more data available in the future, it would be interesting to switch out the VAE with a Transformer to see how the results are affected. (7) It is difficult to make conclusive observations at this moment due to the few number of experimental runs. Ideally, at least 30 runs per experiment per model should be performed. However, this would take an inordinate amount of time given the current computing restrictions for this research. The only way this would be feasible is if one had access to a cluster to distribute the workload. (8) Our discovered new aptamers with promising binding affinity and specificity to the SARS-CoV-2 spike protein can be tested in wet-lab experiments.</p></sec></sec></body><back><ack id="S25"><title>Acknowledgements</title><p>The use of Rosetta was technical supported by Das Lab’s Dr. Rhiju Das, Dr. Ramya Rangan, and Dr. Andy Watkins. Funding was provided by the AI for Design Challenging Program at the National Research Council Canada, the Discovery Grant from the Natural Sciences and Engineering Research Council of Canada, and the Ontario Graduate Scholarships. Dr. Kalli Kappel is supported by the Schmidt Science Fellows, in partnership with the Rhodes Trust, and the HHMI Hanna H. Gray Fellows Program. Additional insights were rendered by Brock University’s Dr. Robson De Grande, Dr. Sheridan Houghten, and Dr. Ali Emami.</p></ack><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>TH</given-names></name><name><surname>Lee</surname><given-names>SW</given-names></name></person-group><article-title>Aptamers for Anti-Viral Therapeutics and Diagnostics</article-title><source>International Journal of Molecular Sciences</source><year>2021</year><volume>22</volume><issue>8</issue><fpage>4168</fpage><pub-id pub-id-type="pmcid">PMC8074132</pub-id><pub-id pub-id-type="pmid">33920628</pub-id><pub-id pub-id-type="doi">10.3390/ijms22084168</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lan</surname><given-names>J</given-names></name><name><surname>Ge</surname><given-names>J</given-names></name><name><surname>Yu</surname><given-names>J</given-names></name><name><surname>Shan</surname><given-names>S</given-names></name><name><surname>Zhou</surname><given-names>H</given-names></name><name><surname>Fan</surname><given-names>S</given-names></name><etal/></person-group><article-title>Structure of the SARS-COV-2 Spike Receptor-binding Domain Bound to the ACE2 Receptor</article-title><source>Nature</source><year>2020</year><volume>581</volume><issue>7807</issue><fpage>215</fpage><lpage>220</lpage><pub-id pub-id-type="pmid">32225176</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>Y</given-names></name><name><surname>Song</surname><given-names>J</given-names></name><name><surname>Wei</surname><given-names>X</given-names></name><name><surname>Huang</surname><given-names>M</given-names></name><name><surname>Sun</surname><given-names>M</given-names></name><name><surname>Zhu</surname><given-names>L</given-names></name><etal/></person-group><article-title>Discovery of Aptamers Targeting the Receptor-Binding Domain of the SARS-CoV-2 Spike Glycoprotein</article-title><source>Analytical Chemistry</source><year>2020</year><volume>92</volume><issue>14</issue><fpage>9895</fpage><lpage>9900</lpage><pub-id pub-id-type="pmcid">PMC7336720</pub-id><pub-id pub-id-type="pmid">32551560</pub-id><pub-id pub-id-type="doi">10.1021/acs.analchem.0c01394</pub-id></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tai</surname><given-names>W</given-names></name><name><surname>He</surname><given-names>L</given-names></name><name><surname>Zhang</surname><given-names>X</given-names></name><name><surname>Pu</surname><given-names>J</given-names></name><name><surname>Voronin</surname><given-names>D</given-names></name><name><surname>Jiang</surname><given-names>S</given-names></name><etal/></person-group><article-title>Characterization of the Receptor-binding Domain (RBD) of 2019 Novel Coronavirus: Implication for Development of RBD Protein as a Viral Attachment Inhibitor and Vaccine</article-title><source>Cellular and Molecular Immunology</source><year>2020</year><volume>17</volume><issue>6</issue><fpage>613</fpage><lpage>620</lpage><pub-id pub-id-type="pmcid">PMC7091888</pub-id><pub-id pub-id-type="pmid">32203189</pub-id><pub-id pub-id-type="doi">10.1038/s41423-020-0400-4</pub-id></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walls</surname><given-names>AC</given-names></name><name><surname>Park</surname><given-names>YJ</given-names></name><name><surname>Tortorici</surname><given-names>MA</given-names></name><name><surname>Wall</surname><given-names>A</given-names></name><name><surname>McGuire</surname><given-names>AT</given-names></name><name><surname>Veesler</surname><given-names>D</given-names></name></person-group><article-title>Structure, Function, and Antigenicity of the SARS-CoV-2 Spike Glycoprotein</article-title><source>Cell</source><year>2020</year><volume>181</volume><issue>2</issue><fpage>281</fpage><lpage>292</lpage><elocation-id>e6</elocation-id><pub-id pub-id-type="pmcid">PMC7102599</pub-id><pub-id pub-id-type="pmid">32155444</pub-id><pub-id pub-id-type="doi">10.1016/j.cell.2020.02.058</pub-id></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yi</surname><given-names>C</given-names></name><name><surname>Sun</surname><given-names>X</given-names></name><name><surname>Ye</surname><given-names>J</given-names></name><name><surname>Ding</surname><given-names>L</given-names></name><name><surname>Liu</surname><given-names>M</given-names></name><name><surname>Yang</surname><given-names>Z</given-names></name><etal/></person-group><article-title>Key Residues of the Receptor Binding Motif in the Spike Protein of SARS-CoV-2 that Interact with ACE2 and Neutralizing Antibodies</article-title><source>Cellular &amp; Molecular Immunology</source><year>2020</year><volume>17</volume><issue>6</issue><fpage>621</fpage><lpage>630</lpage><pub-id pub-id-type="pmcid">PMC7227451</pub-id><pub-id pub-id-type="pmid">32415260</pub-id><pub-id pub-id-type="doi">10.1038/s41423-020-0458-z</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wengerter</surname><given-names>BC</given-names></name><name><surname>Katakowski</surname><given-names>JA</given-names></name><name><surname>Rosenberg</surname><given-names>JM</given-names></name><name><surname>Park</surname><given-names>CG</given-names></name><name><surname>Almo</surname><given-names>SC</given-names></name><name><surname>Palliser</surname><given-names>D</given-names></name><etal/></person-group><article-title>Aptamer-targeted Antigen Delivery</article-title><source>Molecular Therapy: The Journal of the American Society of Gene Therapy</source><year>2014</year><volume>22</volume><issue>7</issue><fpage>1375</fpage><lpage>1387</lpage><pub-id pub-id-type="pmcid">PMC4089008</pub-id><pub-id pub-id-type="pmid">24682172</pub-id><pub-id pub-id-type="doi">10.1038/mt.2014.51</pub-id></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yoon</surname><given-names>SY</given-names></name><name><surname>Gee</surname><given-names>G</given-names></name><name><surname>Hong</surname><given-names>KJ</given-names></name><name><surname>Seo</surname><given-names>SH</given-names></name></person-group><article-title>Application of Aptamers for Assessment of Vaccine Efficacy</article-title><source>Clinical and Experimental Vaccine Research</source><year>2017</year><volume>6</volume><issue>2</issue><fpage>160</fpage><lpage>163</lpage><pub-id pub-id-type="pmcid">PMC5540965</pub-id><pub-id pub-id-type="pmid">28775981</pub-id><pub-id pub-id-type="doi">10.7774/cevr.2017.6.2.160</pub-id></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Plotkin</surname><given-names>S</given-names></name><name><surname>Robinson</surname><given-names>JM</given-names></name><name><surname>Cunningham</surname><given-names>G</given-names></name><name><surname>Iqbal</surname><given-names>R</given-names></name><name><surname>Larsen</surname><given-names>S</given-names></name></person-group><article-title>The Complexity and Cost of Vaccine Manufacturing - An Overview</article-title><source>Vaccine</source><year>2017</year><volume>35</volume><issue>33</issue><fpage>4064</fpage><lpage>4071</lpage><pub-id pub-id-type="pmcid">PMC5518734</pub-id><pub-id pub-id-type="pmid">28647170</pub-id><pub-id pub-id-type="doi">10.1016/j.vaccine.2017.06.003</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tuerk</surname><given-names>C</given-names></name><name><surname>Gold</surname><given-names>L</given-names></name></person-group><article-title>Systematic Evolution of Ligands by Exponential Enrichment: RNA Ligands to Bacteriophage T4 DNA Polymerase</article-title><source>Science</source><year>1990</year><volume>249</volume><issue>4968</issue><fpage>505</fpage><lpage>510</lpage><pub-id pub-id-type="pmid">2200121</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kupakuwana</surname><given-names>GV</given-names></name><name><surname>II</surname><given-names>JEC</given-names></name><name><surname>McPike</surname><given-names>MP</given-names></name><name><surname>Borer</surname><given-names>PN</given-names></name></person-group><article-title>Acyclic Identification of Aptamers for Human Alpha-thrombin Using Over-represented Libraries and Deep Sequencing</article-title><source>PloS One</source><year>2020</year><volume>6</volume><issue>5</issue><fpage>e19395</fpage><pub-id pub-id-type="pmcid">PMC3098231</pub-id><pub-id pub-id-type="pmid">21625587</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0019395</pub-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahirwar</surname><given-names>R</given-names></name><name><surname>Nahar</surname><given-names>S</given-names></name><name><surname>Aggarwal</surname><given-names>S</given-names></name><name><surname>Ramachandran</surname><given-names>S</given-names></name><name><surname>Maiti</surname><given-names>S</given-names></name><name><surname>Nahar</surname><given-names>P</given-names></name></person-group><article-title>In Silico Selection Of An Aptamer To Estrogen Receptor Alpha Using Computational Docking Employing Estrogen Response Elements As Aptamer-Alike Molecules</article-title><source>Scientific Reports</source><year>2016</year><volume>6</volume><issue>1</issue><elocation-id>21285</elocation-id><pub-id pub-id-type="pmcid">PMC4761961</pub-id><pub-id pub-id-type="pmid">26899418</pub-id><pub-id pub-id-type="doi">10.1038/srep21285</pub-id></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>G</given-names></name><name><surname>Jang</surname><given-names>GH</given-names></name><name><surname>Kang</surname><given-names>HY</given-names></name><name><surname>Song</surname><given-names>G</given-names></name></person-group><article-title>Predicting Aptamer Sequences that Interact with Target Proteins Using an Aptamer-protein Interaction Classifier and a Monte Carlo Tree Search Approach</article-title><source>PLOS ONE</source><year>2021</year><volume>16</volume><issue>6</issue><elocation-id>e0253760</elocation-id><pub-id pub-id-type="pmcid">PMC8232527</pub-id><pub-id pub-id-type="pmid">34170922</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0253760</pub-id></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>J</given-names></name><name><surname>Zheng</surname><given-names>Y</given-names></name><name><surname>Huang</surname><given-names>M</given-names></name><name><surname>Wu</surname><given-names>L</given-names></name><name><surname>Wang</surname><given-names>W</given-names></name><name><surname>Zhu</surname><given-names>Z</given-names></name><etal/></person-group><article-title>A Sequential Multidimensional Analysis Algorithm for Aptamer Identification Based on Structure Analysis and Machine Learning</article-title><source>Analytical Chemistry</source><year>2020</year><volume>92</volume><issue>4</issue><fpage>3307</fpage><lpage>3314</lpage><pub-id pub-id-type="pmid">31876151</pub-id></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Becker</surname><given-names>KCD</given-names></name><name><surname>Becker</surname><given-names>RC</given-names></name></person-group><article-title>Nucleic Acid Aptamers as Adjuncts to Vaccine Development</article-title><source>Current Opinion in Molecular Therapeutics</source><year>2006</year><volume>8</volume><issue>2</issue><fpage>122</fpage><lpage>129</lpage><pub-id pub-id-type="pmid">16610764</pub-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>Z</given-names></name><name><surname>Hu</surname><given-names>L</given-names></name><name><surname>Zhang</surname><given-names>BT</given-names></name><name><surname>Lu</surname><given-names>A</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Yu</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Artificial Intelligence in Aptamer-Target Binding Prediction</article-title><source>International Journal of Molecular Sciences</source><year>2021</year><volume>22</volume><issue>7</issue><fpage>3605</fpage><pub-id pub-id-type="pmcid">PMC8038094</pub-id><pub-id pub-id-type="pmid">33808496</pub-id><pub-id pub-id-type="doi">10.3390/ijms22073605</pub-id></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keefe</surname><given-names>AD</given-names></name><name><surname>Pai</surname><given-names>S</given-names></name><name><surname>Ellington</surname><given-names>A</given-names></name></person-group><article-title>Aptamers as Therapeutics</article-title><source>Nature Reviews Drug Discovery</source><year>2010</year><volume>9</volume><issue>7</issue><fpage>537</fpage><lpage>550</lpage><pub-id pub-id-type="pmcid">PMC7097324</pub-id><pub-id pub-id-type="pmid">20592747</pub-id><pub-id pub-id-type="doi">10.1038/nrd3141</pub-id></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kinghorn</surname><given-names>AB</given-names></name><name><surname>Fraser</surname><given-names>LA</given-names></name><name><surname>Lang</surname><given-names>S</given-names></name><name><surname>Shiu</surname><given-names>SCC</given-names></name><name><surname>Tanner</surname><given-names>JA</given-names></name></person-group><article-title>Aptamer Bioinformatics</article-title><source>International Journal of Molecular Sciences</source><year>2017</year><volume>18</volume><issue>12</issue><pub-id pub-id-type="pmcid">PMC5751119</pub-id><pub-id pub-id-type="pmid">29186809</pub-id><pub-id pub-id-type="doi">10.3390/ijms18122516</pub-id></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wornow</surname><given-names>M</given-names></name></person-group><source>Applying Deep Learning to Discover Highly Functionalized Nucleic Acid Polymers That Bind to Small Molecules [Bachelor’s Thesis]</source><publisher-name>Harvard College</publisher-name><publisher-loc>Cambridge, USA</publisher-loc><year>2020</year></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zou</surname><given-names>X</given-names></name><name><surname>Wu</surname><given-names>J</given-names></name><name><surname>Gu</surname><given-names>J</given-names></name><name><surname>Shen</surname><given-names>L</given-names></name><name><surname>Mao</surname><given-names>L</given-names></name></person-group><article-title>Application of Aptamers in Virus Detection and Antiviral Therapy</article-title><source>Frontiers in Microbiology</source><year>2019</year><volume>10</volume><fpage>1462</fpage><pub-id pub-id-type="pmcid">PMC6618307</pub-id><pub-id pub-id-type="pmid">31333603</pub-id><pub-id pub-id-type="doi">10.3389/fmicb.2019.01462</pub-id></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Russell</surname><given-names>S</given-names></name><name><surname>Norvig</surname><given-names>P</given-names></name></person-group><source>Artificial Intelligence: A Modern Approach</source><edition>4th ed</edition><publisher-name>Pearson</publisher-name><year>2020</year></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bishop</surname><given-names>CM</given-names></name></person-group><source>Pattern Recognition and Machine Learning</source><publisher-name>Springer</publisher-name><publisher-loc>New York</publisher-loc><year>2006</year></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LeCun</surname><given-names>Y</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><article-title>Deep Learning</article-title><source>Nature</source><year>2015</year><volume>521</volume><fpage>436</fpage><lpage>444</lpage><pub-id pub-id-type="pmid">26017442</pub-id></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Romez-Bombarelli</surname><given-names>R</given-names></name><name><surname>Wei</surname><given-names>JN</given-names></name><name><surname>Duvenaud</surname><given-names>D</given-names></name><name><surname>Hernarndez-Lobato</surname><given-names>JM</given-names></name><name><surname>Sanchez-Lengeling</surname><given-names>B</given-names></name><name><surname>Sheberla</surname><given-names>D</given-names></name><etal/></person-group><article-title>Automatic Chemical Design Using a Data-driven Continuous Representation of Molecules</article-title><source>ACS Central Science</source><year>2018</year><volume>4</volume><fpage>268</fpage><lpage>276</lpage><pub-id pub-id-type="pmcid">PMC5833007</pub-id><pub-id pub-id-type="pmid">29532027</pub-id><pub-id pub-id-type="doi">10.1021/acscentsci.7b00572</pub-id></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>J</given-names></name><name><surname>Park</surname><given-names>S</given-names></name><name><surname>Min</surname><given-names>D</given-names></name><name><surname>Kim</surname><given-names>W</given-names></name></person-group><article-title>Comprehensive Survey of Recent Drug Discovery Using Deep Learning</article-title><source>International Journal of Molecular Sciences</source><year>2021</year><volume>22</volume><fpage>9983</fpage><pub-id pub-id-type="pmcid">PMC8470987</pub-id><pub-id pub-id-type="pmid">34576146</pub-id><pub-id pub-id-type="doi">10.3390/ijms22189983</pub-id></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grantham</surname><given-names>K</given-names></name><name><surname>Mukaidaisi</surname><given-names>M</given-names></name><name><surname>Ooi</surname><given-names>HK</given-names></name><name><surname>Ghaemi</surname><given-names>MS</given-names></name><name><surname>Tchagang</surname><given-names>A</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name></person-group><article-title>Deep Evolutionary Learning for Molecular Design</article-title><source>IEEE Computational Intelligence Magazine</source><year>2022</year><volume>17</volume><issue>2</issue><fpage>14</fpage><lpage>28</lpage></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mukaidaisi</surname><given-names>M</given-names></name><name><surname>Vu</surname><given-names>A</given-names></name><name><surname>Grantham</surname><given-names>K</given-names></name><name><surname>Tchagang</surname><given-names>A</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name></person-group><article-title>Multi-objective Drug Design Based on Graph-fragment Molecular Representation and Deep Evolutionary Learning</article-title><source>Frontier in Pharmacology</source><year>2022</year><volume>13</volume><elocation-id>920747</elocation-id><pub-id pub-id-type="pmcid">PMC9291509</pub-id><pub-id pub-id-type="pmid">35860028</pub-id><pub-id pub-id-type="doi">10.3389/fphar.2022.920747</pub-id></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>P</given-names></name><name><surname>Meyer</surname><given-names>S</given-names></name><name><surname>Hou</surname><given-names>Z</given-names></name><name><surname>Propson</surname><given-names>NE</given-names></name><name><surname>Soh</surname><given-names>HT</given-names></name><name><surname>Thomson</surname><given-names>JA</given-names></name><etal/></person-group><article-title>MPBind: A Meta-motif-based Statistical Framework and Pipeline to Predict Binding Potential of SELEX-derived Aptamers</article-title><source>Bioinformatics</source><year>2014</year><volume>30</volume><issue>18</issue><fpage>2665</fpage><lpage>2667</lpage><pub-id pub-id-type="pmcid">PMC4155251</pub-id><pub-id pub-id-type="pmid">24872422</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/btu348</pub-id></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Hoinka</surname><given-names>J</given-names></name><name><surname>Berezhnoy</surname><given-names>A</given-names></name><name><surname>Sauna</surname><given-names>ZE</given-names></name><name><surname>Gilboa</surname><given-names>E</given-names></name><name><surname>Przytycka</surname><given-names>TM</given-names></name></person-group><source>AptaCluster - A Method to Cluster HT-SELEX Aptamer Pools and Lessons from Its Application</source><conf-name>International Conference on Research in Computational Molecular Biology</conf-name><year>2014</year><fpage>115</fpage><lpage>128</lpage></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alam</surname><given-names>KK</given-names></name><name><surname>Chang</surname><given-names>JL</given-names></name><name><surname>Burke</surname><given-names>DH</given-names></name></person-group><article-title>FASTAptamer: A Bioinformatic Toolkit for High-throughput Sequence Analysis of Combinatorial Selections</article-title><source>Molecular Therapy - Nucleic Acids</source><year>2015</year><volume>4</volume><elocation-id>e230</elocation-id><pub-id pub-id-type="pmcid">PMC4354339</pub-id><pub-id pub-id-type="pmid">25734917</pub-id><pub-id pub-id-type="doi">10.1038/mtna.2015.4</pub-id></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hiller</surname><given-names>M</given-names></name><name><surname>Pudimat</surname><given-names>R</given-names></name><name><surname>Busch</surname><given-names>A</given-names></name><name><surname>Backofen</surname><given-names>R</given-names></name></person-group><article-title>Using RNA Secondary Structures to Guide Sequence Motif Finding Towards Single-stranded Regions</article-title><source>Nucleic Acids Research</source><year>2006</year><volume>34</volume><issue>17</issue><fpage>e117</fpage><pub-id pub-id-type="pmcid">PMC1903381</pub-id><pub-id pub-id-type="pmid">16987907</pub-id><pub-id pub-id-type="doi">10.1093/nar/gkl544</pub-id></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoinka</surname><given-names>J</given-names></name><name><surname>Zotenko</surname><given-names>E</given-names></name><name><surname>Friedman</surname><given-names>A</given-names></name><name><surname>Sauna</surname><given-names>ZE</given-names></name><name><surname>Przytycka</surname><given-names>TM</given-names></name></person-group><article-title>Identification of Sequence-structure RNA Binding Motifs for SELEX-derived Aptamers</article-title><source>Bioinformatics</source><year>2012</year><volume>28</volume><issue>12</issue><fpage>i215</fpage><lpage>i223</lpage><pub-id pub-id-type="pmcid">PMC3371842</pub-id><pub-id pub-id-type="pmid">22689764</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/bts210</pub-id></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dao</surname><given-names>P</given-names></name><name><surname>Hoinka</surname><given-names>J</given-names></name><name><surname>Takahashi</surname><given-names>M</given-names></name><name><surname>Zhou</surname><given-names>J</given-names></name><name><surname>Ho</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><etal/></person-group><article-title>AptaTRACE Elucidates RNA Sequence-Structure Motifs from Selection Trends in HT-SELEX Experiments</article-title><source>Cell Systems</source><year>2016</year><volume>3</volume><fpage>62</fpage><lpage>70</lpage><pub-id pub-id-type="pmcid">PMC5042215</pub-id><pub-id pub-id-type="pmid">27467247</pub-id><pub-id pub-id-type="doi">10.1016/j.cels.2016.07.003</pub-id></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>BQ</given-names></name><name><surname>Zhang</surname><given-names>YC</given-names></name><name><surname>Huang</surname><given-names>GH</given-names></name><name><surname>Cui</surname><given-names>WR</given-names></name><name><surname>Zhang</surname><given-names>N</given-names></name><name><surname>Cai</surname><given-names>YD</given-names></name></person-group><article-title>Prediction of Aptamer-Target Interacting Pairs with Pseudo-Amino Acid Composition</article-title><source>PLoS ONE</source><year>2014</year><volume>9</volume><issue>1</issue><elocation-id>e86729</elocation-id><pub-id pub-id-type="pmcid">PMC3899287</pub-id><pub-id pub-id-type="pmid">24466214</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0086729</pub-id></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>L</given-names></name><name><surname>Zhang</surname><given-names>C</given-names></name><name><surname>Gao</surname><given-names>R</given-names></name><name><surname>Yang</surname><given-names>R</given-names></name><name><surname>Song</surname><given-names>Q</given-names></name></person-group><article-title>Prediction of Aptamer-protein Interacting Pairs Using an Ensemble Classifier in Combination with Various Protein Sequence Attributes</article-title><source>BMC Bioinformatics</source><year>2016</year><volume>17</volume><fpage>225</fpage><pub-id pub-id-type="pmcid">PMC4888498</pub-id><pub-id pub-id-type="pmid">27245069</pub-id><pub-id pub-id-type="doi">10.1186/s12859-016-1087-5</pub-id></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peng</surname><given-names>C</given-names></name><name><surname>Han</surname><given-names>S</given-names></name><name><surname>Zhang</surname><given-names>H</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name></person-group><article-title>RPITER: A Hierarchical Deep Learning Framework for ncRNA-Protein Interaction Prediction</article-title><source>International Journal of Molecular Sciences</source><year>2019</year><volume>20</volume><fpage>1070</fpage><pub-id pub-id-type="pmcid">PMC6429152</pub-id><pub-id pub-id-type="pmid">30832218</pub-id><pub-id pub-id-type="doi">10.3390/ijms20051070</pub-id></element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Im</surname><given-names>J</given-names></name><name><surname>Park</surname><given-names>B</given-names></name><name><surname>Han</surname><given-names>K</given-names></name></person-group><article-title>A Generative Model for Constructing Nucleic Acid Sequences Binding to a Protein</article-title><source>BMC Genomics</source><year>2019</year><volume>20</volume><issue>13</issue><fpage>967</fpage><pub-id pub-id-type="pmcid">PMC6933682</pub-id><pub-id pub-id-type="pmid">31881936</pub-id><pub-id pub-id-type="doi">10.1186/s12864-019-6299-4</pub-id></element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alipanhi</surname><given-names>B</given-names></name><name><surname>Delong</surname><given-names>A</given-names></name><name><surname>Weirauch</surname><given-names>MT</given-names></name><name><surname>Frey</surname><given-names>BJ</given-names></name></person-group><article-title>Predicting the Sequence Specificities of DNA- and RNA-binding Proteins by Deep Learning</article-title><source>Nature Biotechnology</source><year>2015</year><volume>33</volume><issue>8</issue><fpage>831</fpage><lpage>838</lpage><pub-id pub-id-type="pmid">26213851</pub-id></element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>B</given-names></name><name><surname>Han</surname><given-names>K</given-names></name></person-group><article-title>Discovering Protein-binding RNA Motifs with a Generative Model of RNA Sequences</article-title><source>Computational Biology and Chemistry</source><year>2020</year><volume>84</volume><pub-id pub-id-type="pmid">31931434</pub-id></element-citation></ref><ref id="R40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iwano</surname><given-names>N</given-names></name><name><surname>Adachi</surname><given-names>T</given-names></name><name><surname>Aoki</surname><given-names>K</given-names></name><name><surname>Nakamura</surname><given-names>Y</given-names></name><name><surname>Hamada</surname><given-names>M</given-names></name></person-group><article-title>RaptGen: A Variational Autoencoder with Profile Hidden Markov Model for Generative Aptamer Discovery</article-title><source>bioRxiv</source><year>2021</year><elocation-id>2021.02.17.431338</elocation-id></element-citation></ref><ref id="R41"><label>41</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chaslot</surname><given-names>GMJB</given-names></name><name><surname>Winands</surname><given-names>MHM</given-names></name><name><surname>Herik</surname><given-names>HJVD</given-names></name><name><surname>Uiterwijk</surname><given-names>JWHM</given-names></name></person-group><article-title>Progressive Strategies for Monte-Carlo Tree Search</article-title><source>New Mathematics and Natural Computation</source><year>2008</year><volume>4</volume><issue>3</issue><fpage>343</fpage><lpage>357</lpage></element-citation></ref><ref id="R42"><label>42</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kappel</surname><given-names>K</given-names></name><name><surname>Das</surname><given-names>R</given-names></name></person-group><article-title>Sampling Native-like Structures of RNA-Protein Complexes Through Rosetta Folding and Docking</article-title><source>Structure</source><year>2019</year><volume>27</volume><issue>1</issue><fpage>140</fpage><lpage>151</lpage><elocation-id>e5</elocation-id><pub-id pub-id-type="pmcid">PMC6318048</pub-id><pub-id pub-id-type="pmid">30416038</pub-id><pub-id pub-id-type="doi">10.1016/j.str.2018.10.001</pub-id></element-citation></ref><ref id="R43"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wayment-Steele</surname><given-names>HK</given-names></name><name><surname>Kladwang</surname><given-names>W</given-names></name><name><surname>Strom</surname><given-names>AI</given-names></name><name><surname>Lee</surname><given-names>J</given-names></name><name><surname>Treuille</surname><given-names>A</given-names></name><collab>Eterna Participants</collab><etal/></person-group><article-title>RNA Secondary Structure Packages Evaluated and Improved by High-throughput Experiments</article-title><source>Biophysics</source><year>2020</year><pub-id pub-id-type="pmid">36192461</pub-id></element-citation></ref><ref id="R44"><label>44</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kingma</surname><given-names>DP</given-names></name><name><surname>Welling</surname><given-names>M</given-names></name></person-group><source>Auto-Encoding Variational Bayes</source><conf-name>International Conference on Learning Representations</conf-name><year>2014</year></element-citation></ref><ref id="R45"><label>45</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Chung</surname><given-names>J</given-names></name><name><surname>Gulcehre</surname><given-names>C</given-names></name><name><surname>Cho</surname><given-names>K</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name></person-group><source>Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling</source><conf-name>NIPS 2014 Deep Learning and Representation Learning Workshop</conf-name><year>2014</year></element-citation></ref><ref id="R46"><label>46</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Mikolov</surname><given-names>T</given-names></name><name><surname>Chen</surname><given-names>K</given-names></name><name><surname>Corrado</surname><given-names>GS</given-names></name><name><surname>Dean</surname><given-names>J</given-names></name></person-group><source>Efficient Estimation of Word Representations in Vector Space</source><conf-name>International Conference on Learning Representations</conf-name><year>2013</year></element-citation></ref><ref id="R47"><label>47</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Pennington</surname><given-names>J</given-names></name><name><surname>Socher</surname><given-names>R</given-names></name><name><surname>Manning</surname><given-names>C</given-names></name></person-group><source>GloVe: Global Vectors for Word Representation</source><conf-name>Conference on Empirical Methods in Natural Language</conf-name><conf-sponsor>Association for Computational Linguistics</conf-sponsor><conf-loc>Doha, Qatar</conf-loc><year>2014</year><fpage>1532</fpage><lpage>1543</lpage></element-citation></ref><ref id="R48"><label>48</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fu</surname><given-names>H</given-names></name><name><surname>Li</surname><given-names>C</given-names></name><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Gao</surname><given-names>J</given-names></name><name><surname>Celikyilmaz</surname><given-names>A</given-names></name><name><surname>Carin</surname><given-names>L</given-names></name></person-group><article-title>Cyclical Annealing Schedule: A Simple Approach to Mitigating KL Vanishing</article-title><source>ArXiv</source><year>2019</year><elocation-id>arXiv.1903.10145</elocation-id></element-citation></ref><ref id="R49"><label>49</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Premkumar</surname><given-names>L</given-names></name><name><surname>Segovia-Chumbez</surname><given-names>B</given-names></name><name><surname>Jadi</surname><given-names>R</given-names></name><name><surname>Martinez</surname><given-names>DR</given-names></name><name><surname>Raut</surname><given-names>R</given-names></name><name><surname>Markmann</surname><given-names>A</given-names></name><etal/></person-group><article-title>The Receptor Binding Domain of the Viral Spike Protein is an Immunodominant and Highly Specific Target of Antibodies in SARS-CoV-2 Patients</article-title><source>Science Immunology</source><year>2020</year><volume>5</volume><issue>48</issue><elocation-id>eabc8413</elocation-id><pub-id pub-id-type="pmcid">PMC7292505</pub-id><pub-id pub-id-type="pmid">32527802</pub-id><pub-id pub-id-type="doi">10.1126/sciimmunol.abc8413</pub-id></element-citation></ref><ref id="R50"><label>50</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markley</surname><given-names>JL</given-names></name><name><surname>Bax</surname><given-names>A</given-names></name><name><surname>Arata</surname><given-names>Y</given-names></name><name><surname>Hilbers</surname><given-names>CW</given-names></name><name><surname>Kaptein</surname><given-names>R</given-names></name><name><surname>Sykes</surname><given-names>BD</given-names></name><etal/></person-group><article-title>Recommendations for the Presentation of NMR Structures of Proteins and Nucleic Acids - IUPAC-IUBMB-IUPAB Inter-Union Task Group on the Standardization of Data Bases of Protein and Nucleic Acid Structures Determined by NMR Spectroscopy</article-title><source>Journal of Biomolecular NMR</source><year>1998</year><volume>12</volume><issue>1</issue><fpage>1</fpage><lpage>23</lpage><pub-id pub-id-type="pmid">9729785</pub-id></element-citation></ref><ref id="R51"><label>51</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berman</surname><given-names>HM</given-names></name><name><surname>Westbrook</surname><given-names>J</given-names></name><name><surname>Feng</surname><given-names>Z</given-names></name><name><surname>Gilliland</surname><given-names>G</given-names></name><name><surname>Bhat</surname><given-names>TN</given-names></name><name><surname>Weissig</surname><given-names>H</given-names></name><etal/></person-group><article-title>The Protein Data Bank</article-title><source>Nucleic Acids Research</source><year>2000</year><volume>28</volume><issue>1</issue><fpage>235</fpage><lpage>242</lpage><pub-id pub-id-type="pmcid">PMC102472</pub-id><pub-id pub-id-type="pmid">10592235</pub-id><pub-id pub-id-type="doi">10.1093/nar/28.1.235</pub-id></element-citation></ref><ref id="R52"><label>52</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>BQ</given-names></name><name><surname>Zhang</surname><given-names>YC</given-names></name><name><surname>Huang</surname><given-names>GH</given-names></name><name><surname>Cui</surname><given-names>WR</given-names></name><name><surname>Zhang</surname><given-names>N</given-names></name><name><surname>Cai</surname><given-names>YD</given-names></name></person-group><article-title>Prediction of Aptamer-Target Interacting Pairs with Pseudo-Amino Acid Composition</article-title><source>PLOS ONE</source><year>2014</year><volume>9</volume><issue>1</issue><elocation-id>e86729</elocation-id></element-citation></ref><ref id="R53"><label>53</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Asperti</surname><given-names>A</given-names></name><name><surname>Trentin</surname><given-names>M</given-names></name></person-group><article-title>Balancing Reconstruction Error and Kullback-Leibler Divergence in Variational Autoencoders</article-title><source>arXiv</source><year>2020</year><elocation-id>ArXiv.2002.07514</elocation-id></element-citation></ref><ref id="R54"><label>54</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vaswani</surname><given-names>A</given-names></name><name><surname>Shazeer</surname><given-names>N</given-names></name><name><surname>Parmar</surname><given-names>N</given-names></name><name><surname>Uszkoreit</surname><given-names>J</given-names></name><name><surname>Jones</surname><given-names>L</given-names></name><name><surname>Gomez</surname><given-names>AN</given-names></name><etal/></person-group><article-title>Attention is All You Need</article-title><source>Neural Information Processing Systems</source><year>2017</year></element-citation></ref></ref-list></back><floats-group><boxed-text id="BX1" position="float" orientation="portrait"><caption><title>Author summary</title></caption><p>Compared with small-molecule drugs, aptamer drugs are short RNAs/DNAs that can specifically bind to targets with high strength. With the interest of discovering novel aptamer drugs as an alternative to address the long-lasting COVID-19 pandemic, in this research, we developed an artificial intelligence (AI) framework for the in silico design of novel aptamer drugs that can prevent the SARS-CoV-2 virus from entering human cells. Our research is valuable as we explore a novel approach for the treatment of SARS-CoV-2 infection and the AI framework could be applied to address future health crises.</p></boxed-text><fig id="F1" position="float"><label>Figure 1</label><caption><title>Flowchart depicting the DAPTEV process for aptamer design.</title></caption><graphic xlink:href="EMS157967-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Depiction of the implemented VAE.</title></caption><graphic xlink:href="EMS157967-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Location of the chosen residue (201A, atom C5, dark blue dot) on the renumbered SARS-CoV-2 spike protein RBD.</title><p>Note: the full spike protein shown (left) is for reference but the protein file in DAPTEV is cropped. PDB: 6VXX.</p></caption><graphic xlink:href="EMS157967-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><p>KL loss values (top-left), MLP regularization loss values (top-right), reconstruction loss values (bottom-left), and total loss values (bottom-right) per epoch for each generation. Note: total loss values include the KL weight factor over time.</p></caption><graphic xlink:href="EMS157967-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>The three models’ best (top-left), worst (bottom-left), mean (top-right), and median (bottom-right) scores plotted per generation on a logarithmic scale in a computational run.</title></caption><graphic xlink:href="EMS157967-f005"/></fig><fig id="F6" position="float"><label>Figure 6</label><caption><title>The three models’ 5 best (left) and worst (right) mean scores plotted per generation on a logarithmic scale.</title></caption><graphic xlink:href="EMS157967-f006"/></fig><fig id="F7" position="float"><label>Figure 7</label><caption><p>Density curves of binding scores of aptamer samples in the last generations of DAPTEV, GA, and HC (Random), respectively. The top-left graph shows all scores produced in run 2. The top-right graph shows all folded complex scores from run 2. The bottom-left shows all scores from all three runs. The bottom-right shows all folded complex scores from all three runs.</p></caption><graphic xlink:href="EMS157967-f007"/></fig><fig id="F8" position="float"><label>Figure 8</label><caption><title>Folded RNAs docked to the SARS-CoV-2 RBD based on Rosetta-returned scores.</title><p>Associated docking scores are in brackets next to the classification of each complex.</p></caption><graphic xlink:href="EMS157967-f008"/></fig><table-wrap id="T1" position="float" orientation="portrait"><label>Table 1</label><caption><title>DAPTEV hyperparameters used in our experiments.</title></caption><table frame="box" rules="cols"><thead><tr style="border-bottom: solid thin"><th align="center" valign="middle" colspan="4">Initial Data Collection Hyperparameters</th></tr></thead><tbody><tr><td align="center" valign="middle"><bold>Min Seq Length</bold></td><td align="center" valign="middle">20</td><td align="center" valign="middle"><bold>Max Seq Length</bold></td><td align="center" valign="middle">40</td></tr><tr><td align="center" valign="middle"><bold>GC Content</bold></td><td align="center" valign="middle">50%</td><td align="center" valign="middle"><bold>Force Folded</bold></td><td align="center" valign="middle">True</td></tr><tr style="border-bottom: solid thin"><td align="center" valign="middle"><bold>Data Size</bold></td><td align="center" valign="middle">12,000</td><td align="center" valign="middle"/></tr><tr style="border-bottom: solid thin"><td align="center" valign="middle" colspan="4">Evolutionary Optimization Hyperparameters</td></tr><tr><td align="center" valign="middle"><italic>k</italic> <bold>in Tournament</bold></td><td align="center" valign="middle">2</td><td align="center" valign="middle"><bold>Selection Rate</bold></td><td align="center" valign="middle">0.95</td></tr><tr><td align="center" valign="middle"><bold>Elitism Rate</bold></td><td align="center" valign="middle">0.01</td><td align="center" valign="middle"><bold>Crossover Rate</bold></td><td align="center" valign="middle">0.01</td></tr><tr><td align="center" valign="middle"><bold>Population Size</bold></td><td align="center" valign="middle">800</td><td align="center" valign="middle"><bold># Generations</bold></td><td align="center" valign="middle">10</td></tr><tr style="border-bottom: solid thin"><td align="center" valign="middle">Repeated Runs</td><td align="center" valign="middle">3</td><td align="center" valign="middle"/></tr><tr style="border-bottom: solid thin"><td align="center" valign="middle" colspan="4">Encoder Structure</td></tr><tr><td align="center" valign="middle"><bold>Embedding Size</bold></td><td align="center" valign="middle">87</td><td align="center" valign="middle"><bold>Hidden Layers</bold></td><td align="center" valign="middle">[256]</td></tr><tr><td align="center" valign="middle"><italic>μ</italic> <bold>Layer</bold></td><td align="center" valign="middle">[512]</td><td align="center" valign="middle">log <italic>σ</italic> <bold>Layer</bold></td><td align="center" valign="middle">[512]</td></tr><tr style="border-bottom: solid thin"><td align="center" valign="middle"><bold>Latent Vector Size</bold></td><td align="center" valign="middle">10</td><td align="center" valign="middle"><bold>Bidirectional</bold></td><td align="center" valign="middle">True</td></tr><tr style="border-bottom: solid thin"><td align="center" valign="middle" colspan="4">Decoder Structure</td></tr><tr><td align="center" valign="middle"><bold>Hidden Layers</bold></td><td align="center" valign="middle">[512,1024]</td><td align="center" valign="middle"><bold>Output Layer</bold></td><td align="center" valign="middle">[87]</td></tr><tr style="border-bottom: solid thin"><td align="center" valign="middle"><bold>Bidirectional</bold></td><td align="center" valign="middle">False</td><td align="center" valign="middle"/></tr><tr style="border-bottom: solid thin"><td align="center" valign="middle" colspan="4">MLP Structure</td></tr><tr style="border-bottom: solid thin"><td align="center" valign="middle"><bold>Hidden Layers</bold></td><td align="center" valign="middle">[64,32]</td><td align="center" valign="middle"><bold>Output Layer</bold></td><td align="center" valign="middle">[1]</td></tr><tr style="border-bottom: solid thin"><td align="center" valign="middle" colspan="4">VAE-Specific Training Hyperparameters</td></tr><tr><td align="center" valign="middle"><bold>Score Threshold</bold></td><td align="center" valign="middle">3,500</td><td align="center" valign="middle"><bold>Pretrain. Epochs</bold></td><td align="center" valign="middle">45</td></tr><tr><td align="center" valign="middle"><bold>Fine-tun. Epochs</bold></td><td align="center" valign="middle">10</td><td align="center" valign="middle"><bold>Initial Learn. Rate</bold></td><td align="center" valign="middle">3e-3</td></tr><tr><td align="center" valign="middle"><bold>End Learn. Rate</bold></td><td align="center" valign="middle">3e-4</td><td align="center" valign="middle"><bold>Starting</bold> <italic>β</italic></td><td align="center" valign="middle">1e-3</td></tr><tr><td align="center" valign="middle"><bold>End</bold> <italic>β</italic></td><td align="center" valign="middle">0.5</td><td align="center" valign="middle">1</td><td align="center" valign="middle"><italic>α</italic></td></tr></tbody></table></table-wrap><table-wrap id="T2" position="float" orientation="portrait"><label>Table 2</label><caption><title>The average score performance in the first and last generations for each experiment. Standard deviation provided in brackets. DAPTEV and GA were, respectively, run for 3 times. HC was simulated based on our original dataset, thus was only run once.</title></caption><table frame="box" rules="all"><thead><tr><th align="center" valign="middle" colspan="2">Docking Score</th><th align="center" valign="middle">DAPTEV</th><th align="right" valign="middle">GA</th><th align="right" valign="middle">HC</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="4"><bold>First Gen</bold></td><td align="right" valign="middle"><italic>Best</italic></td><td align="right" valign="middle">118 (14)</td><td align="right" valign="middle">100 (41)</td><td align="right" valign="middle">18,250</td></tr><tr><td align="right" valign="middle"><italic>Mean</italic></td><td align="right" valign="middle">897 (207)</td><td align="right" valign="middle">781 (337)</td><td align="right" valign="middle">23,635</td></tr><tr><td align="right" valign="middle"><italic>Median</italic></td><td align="right" valign="middle">925 (204)</td><td align="right" valign="middle">801 (343)</td><td align="right" valign="middle">21,957</td></tr><tr><td align="right" valign="middle"><italic>Worst</italic></td><td align="right" valign="middle">1,256 (297)</td><td align="right" valign="middle">1,098 (489)</td><td align="right" valign="middle">60,677</td></tr><tr><td align="center" valign="middle" rowspan="4"><bold>Last Gen</bold></td><td align="right" valign="middle"><italic>Best</italic></td><td align="right" valign="middle">72 (31)</td><td align="right" valign="middle">32 (24)</td><td align="right" valign="middle">128</td></tr><tr><td align="right" valign="middle"><italic>Mean</italic></td><td align="right" valign="middle">578 (49)</td><td align="right" valign="middle">292 (58)</td><td align="right" valign="middle">1,098</td></tr><tr><td align="right" valign="middle"><italic>Median</italic></td><td align="right" valign="middle">602 (49)</td><td align="right" valign="middle">303 (59)</td><td align="right" valign="middle">1,122</td></tr><tr><td align="right" valign="middle"><italic>Worst</italic></td><td align="right" valign="middle">796 (77)</td><td align="right" valign="middle">390 (86)</td><td align="right" valign="middle">1,530</td></tr></tbody></table></table-wrap><table-wrap id="T3" position="float" orientation="portrait"><label>Table 3</label><caption><title>Average docking scores and base pairings relating to the folded RNAs in each model. Standard deviation provided in brackets. Note: all values relate only to the folded RNAs in the last generation.</title></caption><table frame="box" rules="all"><thead><tr><th align="center" valign="middle" style="border-top: hidden; border-right: hidden; border-left: hidden"/><th align="center" valign="middle" style="border-top: hidden; border-left hidden"/><th align="center" valign="middle">DAPTEV</th><th align="right" valign="middle">GA</th><th align="right" valign="middle">HC</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-top: hidden; border-left: hidden"/><td align="center" valign="middle"><italic>Folded</italic></td><td align="right" valign="middle">272 (35)</td><td align="right" valign="middle">47 (21)</td><td align="right" valign="middle">100</td></tr><tr><td align="center" valign="middle" style="border-top: hidden; border-left: hidden"/><td align="center" valign="middle"><italic>Rate (%)</italic></td><td align="right" valign="middle">34 (4)</td><td align="right" valign="middle">6 (3)</td><td align="right" valign="middle">100</td></tr><tr><td align="center" valign="middle" rowspan="4"><bold>Docking Scores</bold></td><td align="center" valign="middle"><italic>Best</italic></td><td align="right" valign="middle">128 (0)</td><td align="right" valign="middle">128 (0)</td><td align="right" valign="middle">128</td></tr><tr><td align="center" valign="middle"><italic>Mean</italic></td><td align="right" valign="middle">631 (57)</td><td align="right" valign="middle">315 (62)</td><td align="right" valign="middle">1,098</td></tr><tr><td align="center" valign="middle"><italic>Median</italic></td><td align="right" valign="middle">664 (57)</td><td align="right" valign="middle">324 (65)</td><td align="right" valign="middle">1,122</td></tr><tr><td align="center" valign="middle"><italic>Worst</italic></td><td align="right" valign="middle">796 (77)</td><td align="right" valign="middle">388 (88)</td><td align="right" valign="middle">1,530</td></tr><tr><td align="center" valign="middle" rowspan="4"><bold>Base Pairs</bold></td><td align="center" valign="middle"><italic>Minimum</italic></td><td align="right" valign="middle">1.0 (0)</td><td align="right" valign="middle">1.0 (0)</td><td align="right" valign="middle">1.0</td></tr><tr><td align="center" valign="middle"><italic>Mean</italic></td><td align="right" valign="middle">2.3 (0.1)</td><td align="right" valign="middle">2.1 (0.1)</td><td align="right" valign="middle">2.6</td></tr><tr><td align="center" valign="middle"><italic>Median</italic></td><td align="right" valign="middle">2.0 (0)</td><td align="right" valign="middle">2.0 (0)</td><td align="right" valign="middle">3.0</td></tr><tr><td align="center" valign="middle"><italic>Maximum</italic></td><td align="right" valign="middle">5.0 (0)</td><td align="right" valign="middle">3.7 (0.5)</td><td align="right" valign="middle">7.0</td></tr></tbody></table></table-wrap></floats-group></article>