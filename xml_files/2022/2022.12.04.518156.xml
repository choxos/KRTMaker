<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS158183</article-id><article-id pub-id-type="doi">10.1101/2022.12.04.518156</article-id><article-id pub-id-type="archive">PPR580120</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Stimulus information guides the emergence of behavior related signals in primary somatosensory cortex during learning</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Panniello</surname><given-names>Mariangela</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><contrib contrib-type="author"><name><surname>Gillon</surname><given-names>Colleen J</given-names></name><xref ref-type="aff" rid="A4">4</xref><xref ref-type="aff" rid="A5">5</xref><xref ref-type="aff" rid="A6">6</xref></contrib><contrib contrib-type="author"><name><surname>Maffulli</surname><given-names>Roberto</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A7">7</xref></contrib><contrib contrib-type="author"><name><surname>Celotto</surname><given-names>Marco</given-names></name><xref ref-type="aff" rid="A7">7</xref><xref ref-type="aff" rid="A8">8</xref><xref ref-type="aff" rid="A9">9</xref></contrib><contrib contrib-type="author"><name><surname>Panzeri</surname><given-names>Stefano</given-names></name><xref ref-type="aff" rid="A7">7</xref><xref ref-type="aff" rid="A8">8</xref></contrib><contrib contrib-type="author"><name><surname>Richards</surname><given-names>Blake A</given-names></name><xref ref-type="aff" rid="A6">6</xref><xref ref-type="aff" rid="A10">10</xref><xref ref-type="aff" rid="A11">11</xref><xref ref-type="aff" rid="A12">12</xref><xref ref-type="aff" rid="A13">13</xref></contrib><contrib contrib-type="author"><name><surname>Kohl</surname><given-names>Michael M</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib></contrib-group><aff id="A1"><label>1</label>Department of Physiology, Anatomy and Genetics, University of Oxford, Oxford, OX1 3PT, UK</aff><aff id="A2"><label>2</label>School of Psychology and Neuroscience, University of Glasgow, Glasgow, G12 8QQ, UK</aff><aff id="A3"><label>3</label>Optical Approaches to Brain Function Laboratory, Istituto Italiano di Tecnologia, Genova, Italy</aff><aff id="A4"><label>4</label>Department of Biological Sciences, University of Toronto Scarborough, Toronto, Ontario, Canada</aff><aff id="A5"><label>5</label>Department of Cell &amp; Systems Biology, University of Toronto, Toronto, Ontario, Canada</aff><aff id="A6"><label>6</label>Mila, Montréal, Québec, Canada</aff><aff id="A7"><label>7</label>Neural Computation Laboratory, Center for Human Technologies, Istituto Italiano di Tecnologia, Genova, Italy</aff><aff id="A8"><label>8</label>Department of Neural Information Processing, Center for Molecular Neurobiology (ZMNH), University Medical Center Hamburg-Eppendorf (UKE), Hamburg, Germany</aff><aff id="A9"><label>9</label>Department of Pharmacy and Biotechnology, University of Bologna, Bologna, Italy</aff><aff id="A10"><label>10</label>School of Computer Science, McGill University, Montréal, Québec, Canada</aff><aff id="A11"><label>11</label>Department of Neurology &amp; Neurosurgery, McGill University, Montréal, Québec, Canada</aff><aff id="A12"><label>12</label>Learning in Machines and Brains Program, Canadian Institute for Advanced Research, Toronto, Ontario, Canada</aff><aff id="A13"><label>13</label>Montreal Neurological Institute, Montréal, Québec, Canada</aff><author-notes><corresp id="CR1">
<label>*</label>Correspondence: <email>mariangela.panniello@iit.it</email> &amp; <email>michael.kohl@glasgow.ac.uk</email>
</corresp></author-notes><pub-date pub-type="nihms-submitted"><day>07</day><month>12</month><year>2022</year></pub-date><pub-date pub-type="preprint"><day>05</day><month>12</month><year>2022</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0 International license</ext-link>.</license-p></license><license><ali:license_ref>https://europepmc.org/downloads/openaccess</ali:license_ref><license-p>This preprint is made available via the <ext-link ext-link-type="uri" xlink:href="https://europepmc.org/downloads/openaccess">Europe PMC open access subset</ext-link>, for unrestricted research re-use and secondary analysis in any form or by any means with acknowledgement of the original preprint source.</license-p></license></permissions><abstract><p id="P1">Cortical neurons in primary sensory cortex carry not only sensory but also behavior-related information. However, it remains unclear how these types of information emerge and are integrated with one another over learning and what the relative contribution of activity in individual cells versus neuronal populations is in this process. Current evidence supports two opposing views of learning-related changes: 1) sensory information increases in primary cortex or 2) sensory information remains stable in primary cortex but its readout efficiency in association cortices increases. Here, we investigate these questions in primary sensory cortex during learning of a sensory task. Over the course of weeks, we imaged neuronal activity at different depths within layers 2 and 3 of the mouse vibrissal primary somatosensory cortex (vS1) before, during, and after training on a whisker-based object-localization task. We leveraged information theoretical analysis to quantify stimulus and behavior-related information in vS1 and estimate how much neural activity encoding sensory information is used to inform perceptual choices as sensory learning progresses. We also quantified the extent to which these types of information are supported by an individual neuron or population code. We found that, while sensory information rises progressively from the start of training, choice information is only present in the final stages of learning and is increasingly supported by a population code. Moreover, we demonstrate that not only the increase in available information, but also a more efficient readout of such information in primary sensory cortex mediate sensory learning. Together, our results highlight the importance of primary cortical neurons in perceptual learning.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">Neuronal activity in the vibrissal primary somatosensory cortex (vS1) of mice successfully trained on a sensory task reflects not only sensory stimuli but also various types of behavior-related information<sup><xref ref-type="bibr" rid="R1">1</xref>,<xref ref-type="bibr" rid="R2">2</xref></sup>, including information about behavioral choice<sup><xref ref-type="bibr" rid="R3">3</xref>–<xref ref-type="bibr" rid="R8">8</xref></sup>. Insight into learning-related changes in cortical neuronal activity is key to understanding how the brain enables flexible behavior. On an individual neuron level, a variety of learning-related changes have been observed in vS1, including sharpening of neuronal responses<sup><xref ref-type="bibr" rid="R3">3</xref>,<xref ref-type="bibr" rid="R9">9</xref></sup> and changes in the magnitude of neuronal signals<sup><xref ref-type="bibr" rid="R7">7</xref></sup>. It has been theorized that such changes serve to increase the ability of neurons to discriminate between similar pieces of information, thereby improving behavioral performance on related tasks<sup><xref ref-type="bibr" rid="R10">10</xref></sup>. Yet, some studies report minimal changes in the response properties of individual vS1 neurons over the course of learning<sup><xref ref-type="bibr" rid="R5">5</xref>,<xref ref-type="bibr" rid="R11">11</xref></sup> and instead find learning-related alterations at the population level, for example in the relative spike-timing<sup><xref ref-type="bibr" rid="R12">12</xref></sup>, in neuronal gain<sup><xref ref-type="bibr" rid="R3">3</xref></sup>, or in population activity correlations (for review, see <sup><xref ref-type="bibr" rid="R13">13</xref></sup>). The field still lacks a comprehensive picture of how stimulus and behavior-related information emerge and are integrated with one another over time as learning takes place, and what the relative contribution of activity in individual cells <italic>versus</italic> neuronal populations is in this process. We hypothesized that task-learning is supported by gradual changes at the individual neuron and population levels, which result in both increased information about sensory stimuli, and a more efficient use of this information to guide behavior. We anticipate that this, in turn, contributes to generating novel, task-specific information, necessary for behavioral improvement. We tested this hypothesis by training mice on a head-fixed tactile object localization task<sup><xref ref-type="bibr" rid="R14">14</xref>,<xref ref-type="bibr" rid="R15">15</xref></sup>, using two-photon imaging to longitudinally record the activity of excitatory neurons at different depths within layers 2 and 3 (L2/3) of vS1 before, during and after training. We quantified, on a trial-by-trial basis and at different stages of learning, stimulus information (MI-RS), behavioral choice information (MI-RC), and intersection information (II). II quantifies the amount of sensory information carried in the neural response that is read out to inform behavioral choice and provides potential insight into how information encoding supports sensory-guided behavior. We revealed that stimulus information was already present at the beginning of training, while choice information only emerged over the course of learning. Furthermore, we found that the improvement in behavioral performance was not simply accompanied by increased stimulus information but that, across learning stages, this information was more efficiently read out to instruct behavior. Finally, while changes in sensory information content were mainly shaped by changes at the individual neuron level, an increase in information encoded at the neuronal population level was associated more with behavioral choice.</p></sec><sec id="S2" sec-type="results"><title>Results</title><sec id="S3"><title>Multi-depth two-photon calcium imaging over the course of learning</title><p id="P3">We trained mice to learn a whisker-based object localization task<sup><xref ref-type="bibr" rid="R14">14</xref>,<xref ref-type="bibr" rid="R15">15</xref></sup> while they were head-fixed but freely running on a cylindrical treadmill. Mice learned to report a Go or No-go position of a vertical metal pole presented against the left whiskers by licking for a water reward. Learning was classified into three stages, based on the percentage of correct licking responses: ≤55% (stage 1), &gt;55 to ≤75% (stage 2), &gt;75% (stage 3) (<xref ref-type="fig" rid="F1">Fig. 1a-c</xref>). During each of the three learning stages, we recorded the responses of excitatory neurons at four depths in the supragranular portion of the vibrissal primary somatosensory cortex (vS1) which expressed the genetically encoded calcium indicator GCaMP6s<sup><xref ref-type="bibr" rid="R16">16</xref></sup>, using multi-depth two-photon calcium imaging<sup><xref ref-type="bibr" rid="R17">17</xref></sup>. Learning progress was monitored using lick events. Over the course of learning, the time until the first lick after stimulus offset decreased substantially during correct Hit, but not incorrect false alarm (FA) trials (Hits: from 1.25±0.06 to 0.52±0.02 seconds; Kolmogorov-Smirnov test (ks-test) p&lt;0.001; FAs: from 1.13±0.95 to 1.31±0.08 seconds; ks-test p=0.011; mean; <xref ref-type="fig" rid="F1">Fig. 1d</xref>). On average, mice took 10.4±0.9 days of training to reach learning stage 3 (<xref ref-type="fig" rid="F1">Fig. 1e</xref>). The mean percentage of correct responses on the day of best performance was 82.7% across mice (sd: 4.06; mean d’: 2.31±0.47). In each animal, we recorded vS1 neuronal activity in the same four fields of views (FOVs) in layer 2 and 3 (L2/3) across training sessions (<xref ref-type="fig" rid="F1">Fig. 1f &amp; g</xref>). The overall number of neurons imaged over the course of learning stages (<xref ref-type="supplementary-material" rid="SD1">Supp. Table 1</xref>) as well as image quality (<xref ref-type="supplementary-material" rid="SD1">Supp. Fig. 1</xref>) remained stable.</p></sec><sec id="S4"><title>Individual neurons in vS1 gain both stimulus and choice information over the course of learning</title><p id="P4">Neuronal responses to whisker touch were variable within individual FOVs, both in terms of stimulus preference (Go <italic>vs</italic>. No-go positions) and timing (early <italic>vs</italic>. late responses) at all learning stages (<xref ref-type="fig" rid="F2">Fig. 2a</xref>). To quantify how much information about stimulus position was carried in the activity of each imaged neuron at each time point during a trial, we calculated instantaneous Mutual Information (MI) between a neuron’s calcium response and stimulus identity across trials (MI-RS; <xref ref-type="fig" rid="F2">Fig. 2b</xref>). We repeated the process for each depth and learning stage. When averaging the frame-by-frame MI-RS values obtained for each imaged neuron, we found that the overall MI-RS increased across the learning stages at all imaging depths (ks-test p: all &lt;0.001; <xref ref-type="fig" rid="F2">Fig. 2c</xref>). MI-RS was already present during learning stage 1, as might be expected for a primary sensory region (p&lt;0.001 when compared to the null distribution, for all depths). The percentage of neurons carrying significant MI-RS was very similar across cortical layers (-130 μm: 24.7%, -190 μm: 25.5%, -260 μm: 32.6%, -320 μm: 25.7%; <xref ref-type="fig" rid="F2">Fig. 2d</xref>). MI-RS of individual neurons was higher for superficial than deep layers, but there was 4-fold increase in MI-RS at -320 μm between stage 1 and stage 3 of learning (MI-RS stage 1/MI-RS stage 3 at -130 μm: 2.46, -190 μm: 3.08, -260 μm: 2.37, -320 μm: 3.88), and a doubling of the number of neurons carrying significant MI-RS (-130 μm: 50.92%, -190 μm: 59.34%, -260 μm: 62.22%, -320 μm: 53.23%). Interestingly, MI-RS values showed a steep increase right after stimulus onset (defined as the moment when the metal pole reached its final position against the whiskers) but kept increasing after stimulus offset (defined as the moment when the metal pole started moving away from the whiskers), suggesting that stimulus information builds and persists in vS1 even when the stimulus is not present anymore.</p><p id="P5">We next asked whether individual neurons in vS1 also represent the behavioral choice to lick or withhold licking, and whether this representation changes with learning. We therefore assessed MI between neural responses and choice (MI-RC), as above (<xref ref-type="fig" rid="F2">Fig. 2e &amp; f</xref>). Similar to MI-RS, we found that MI-RC increased across learning stages. However, whereas MI-RS was already present in learning stage 1, the mean MI-RC across imaged neurons was near zero early during training, but progressively increased through the following learning stages (MI-RC stage 3/stage 1 at -130 μm: 10.85, -190 μm: 4.17, -260 μm: 8.84, -320 μm: 5.26; <xref ref-type="fig" rid="F2">Fig. 2g</xref>). This trend is reflected in the lower fraction of neurons carrying significant MI-RC, compared to MI-RS, in stage 1 (-130 μm: 18.1%, - 190 μm: 22.86%, -260 μm: 18.29%, -320 μm: 9.6%), increasing to more than half of the imaged neurons at stage 3 (-130 μm: 50.39%, -190 μm: 55.31%, -260 μm: 60.58%, -320 μm: 50.74%; <xref ref-type="fig" rid="F2">Fig. 2h</xref>).</p><p id="P6">Moreover, by stage 3, the majority of neurons carrying significant MI-RS also showed significant MI-RC (<xref ref-type="fig" rid="F2">Fig. 2i</xref>), hinting at a computation taking place during learning, where primary cortical neurons encoding sensory stimulus information are recruited to inform behavioral choice as well, and contribute to task performance.</p><p id="P7">Over the course of learning, information about the tactile stimulus and behavioral choice increased as mice improved their behavioral performance. Two notable cortical layer differences could be observed: First, stimulus information stops increasing during stage 2 in superficial L2 (-130 μm) and deep L3 (-320 μm). Second, the increase in stimulus information is strongest in deep L3 while the increase in choice information is strongest in superficial L2. Overall, these results show that, at the start of sensory training, stimulus information is already present, particularly in superficial layer 2 neurons, while choice information is absent.</p></sec><sec id="S5"><title>Learning-related increase in choice information is supported by population coding</title><p id="P8">Neurons in the same brain region vary in how strongly they encode sensory stimulus information, and neuronal activity in vS1 tends to be particularly sparse<sup><xref ref-type="bibr" rid="R18">18</xref>–<xref ref-type="bibr" rid="R20">20</xref></sup>. Thus, we next sought to evaluate how the learning-related changes in stimulus and choice information across neurons in vS1 reflect the contribution of individual neurons to the neuronal population encoding as a whole. Calculating MI on the activity of increasing numbers of individual neurons is subject to a systematic bias due to the limited number of experimental trials available<sup><xref ref-type="bibr" rid="R21">21</xref></sup>. Therefore, following established practices, we estimated the MI for groups of neurons using the MI computed on the confusion matrices obtained by training linear regression models to decode stimulus (decMI-RS) or choice (decMI-RC) from neural activity. decMI-RS and decMI-RC computed for groups of neurons offer a lower-bound to the amount of stimulus and choice information encoded by the neural population<sup><xref ref-type="bibr" rid="R22">22</xref></sup>. When computed for individual neurons, decMI-RS and decMI-RC correlated well with the previously estimated MI-RS and MI-RC, indicating that the measure was reliable (<xref ref-type="supplementary-material" rid="SD1">Supp. Fig. 2</xref>).</p><p id="P9">We first sought to use decMI to evaluate the contribution of each neuron to population-level encoding of task-relevant information. We classified each neuron as “discriminative” if it carried sufficient decMI on its own to enable above-chance decoding of the trial type (<italic>i</italic>.<italic>e</italic>., above the 95<sup>th</sup> percentile of the null distribution) and “non-discriminative” otherwise<sup><xref ref-type="bibr" rid="R15">15</xref></sup>. We then evaluated whether the increase in stimulus and choice information over the course of learning reflected a population level change or the emergence of a sparse set of highly-informative discriminative neurons. Over the course of learning, median decMI-RS did not change but the percentage of discriminative neurons increased (stage 1: 16.0±1.2%, stage 2: 19.5±1.1%, stage 3: 24.4±2.2%; mean±sem across depths and FOVs) and the distribution of decMI-RS values changed, reflecting a change in the 95<sup>th</sup> percentile (stage 1: 0.31, stage 2: 0.39, stage 3: 0.47; <xref ref-type="fig" rid="F3">Fig. 3a</xref>). Similarly, for decMI-RC the percentage of discriminative neurons increased (stage 1: 7.4±1.0%, stage 2: 11.9±0.8%, stage 3: 19.6±2.0%) and the distribution of decMI-RS values changed (95<sup>th</sup> percentile in stage 1: 0.21, stage 2: 0.25, stage 3: 0.32; <xref ref-type="fig" rid="F3">Fig. 3b</xref>). Together, these results indicate that the increase in stimulus and choice information observed in L2-3 of vS1 reflects both an increase in the number of discriminative neurons, as well as an increase in the information about stimulus and choice carried by the most informative neurons.</p><p id="P10">Previous work has shown that neurons which on their own do not enable above-chance decoding of task-relevant variables, can still contribute to population encoding and improve the decoding performance of neurons that carry high information content, when put together<sup><xref ref-type="bibr" rid="R23">23</xref></sup>. This points to a role for non-discriminative neurons in supporting robust population codes for task-relevant information. We wanted to determine the relative importance of these non-discriminative neurons for stimulus and choice information. We therefore asked how information about stimulus and choice increased as we added neurons, from least to most informative, to the pool used for calculating decMI. For each session, we ran decoders sequentially as we added neurons with progressively increasing decMI, drawn from either the full population (<xref ref-type="fig" rid="F3">Fig. 3c &amp; d</xref>, left) or only from the non-discriminative neuron population (<xref ref-type="fig" rid="F3">Fig. 3c &amp; d</xref>, right). We then compared decMI-RS in stages 2 and 3 to stage 1 values, as neurons were added, to identify differences between stages (t-test p&lt;0.05, Bonferroni corrected for all neuron % × stage comparisons). When it came to decMI-RS, we found that as neurons were added to the pool, decMI-RS tended to increase for all stages. Only once 90% or more of the entire population of recorded neurons was included, decMI-RS was substantially higher for stage 3 FOVs compared to stage 1 FOVs, and no differences were found for stage 2 <italic>vs</italic>. 1 FOVs (<xref ref-type="fig" rid="F3">Fig. 3c</xref>, left). No differences emerged between the stages when only non-discriminative neurons were included (<xref ref-type="fig" rid="F3">Fig. 3c</xref>, right). In contrast, during stage 1, decMI-RC remained low regardless of the number of neurons added to the decoder (<xref ref-type="fig" rid="F3">Fig. 3d</xref>). In stages 2 and 3, however, decMI-RC increased beyond stage 1 levels once 70% of all neurons were included in stage 2, and with as few as 55% of all neurons in stage 3. In contrast to decMI-RS, even adding only non-discriminative neurons significantly increased decMI-RC in stages 2 and 3 compared to stage 1 (<xref ref-type="fig" rid="F3">Fig. 3d</xref>). Overall, these results suggest that, as mice learn to perform the task, choice information is increasingly supported by a distributed population code. In contrast, stimulus information shows a consistent reliance on a distributed population code across learning, that is already present at the start of training.</p><p id="P11">Finally, we wanted to quantify how much stimulus or choice information individual discriminative neurons gain from the activity of a population of non-discriminative neurons. We calculated the decMI of each discriminative neuron on its own and then measured the gain in information when the decoder also received as input the neuronal activity from the session’s non-discriminative neurons. Including the non-discriminative population greatly increases the dimensionality of the input to the decoders which, if the added input data is not informative, can impair a decoder’s performance. For stimulus decoding, this was the case for approximately half of all discriminative neurons which showed a negative gain when paired with the non-discriminative population, as shown by median gains near 0 (0.05 in stage 1, 0.05 in stage 2, 0.08 in stage 3; <xref ref-type="fig" rid="F3">Fig. 3e-g</xref>). The discriminative neurons that showed positive gains were generally a subset of the ones that had the lowest individual decMI-RS (&lt;0.5; <xref ref-type="fig" rid="F3">Fig. 3e</xref>). The overall distribution of the gains in stimulus decoding showed negligible change across learning (<xref ref-type="fig" rid="F3">Fig. 3e-g</xref>). In contrast, non-discriminative neurons had a much stronger effect on choice decoding by discriminative neurons. The median gain increased steadily with learning (stage 1: -0.16, stage 2: -0.06, stage 3: 0.02; <xref ref-type="fig" rid="F3">Fig. 3h-j</xref>). The overall distribution of the gains in choice decoding showed a strong overall rightward shift (ks-test p&lt;0.001 for all pairs of stages), with the 95<sup>th</sup> percentile increasing substantially across stages (stage 1: 0.04, stage 2: 0.11, stage 3: 0.27). As for stimulus decoding, the discriminative neurons that gained the most from being paired with the non-discriminative population, across all stages, were generally those with lower individual decMI-RC (<xref ref-type="fig" rid="F3">Fig. 3h</xref>). Together, these results suggest that, in vS1, over learning, neurons that encode task-relevant variables well on their own become progressively more supported in population encoding by neurons that would not be significantly discriminative on their own, particularly for choice encoding.</p></sec><sec id="S6"><title>Stimulus information increasingly guides behavioral choice throughout learning</title><p id="P12">The increase in perceptual abilities when learning a sensory-guided task may be due, as traditionally hypothesized, to an increase of the sensory information encoded in early sensory cortices<sup><xref ref-type="bibr" rid="R5">5</xref>,<xref ref-type="bibr" rid="R24">24</xref>–<xref ref-type="bibr" rid="R26">26</xref></sup>. Alternatively, it may be the consequence of an improved readout of such information<sup><xref ref-type="bibr" rid="R27">27</xref></sup>. To gain insights into how sensory information encoded in vS1 is used to generate accurate behavior across stages of learning, we used intersection information (II)<sup><xref ref-type="bibr" rid="R28">28</xref>,<xref ref-type="bibr" rid="R29">29</xref></sup>, an information-theoretic quantification of how much sensory information in neural activity is read out to inform behavioral choices (<xref ref-type="fig" rid="F4">Fig. 4a</xref>). By definition, II is non-negative, on a scale of bits, and is bounded by both MI-RS and MI-RC. First, we calculated the frame-by-frame II carried by each imaged neuron, across trials, at each depth and learning stage. II was, as expected, absent before stimulus onset, at all learning stages, because there was no stimulus information during this time window. After stimulus-onset, II was weak during learning stage 1, but increased in stages 2 and 3 (<xref ref-type="fig" rid="F4">Fig. 4b</xref>). The percentage of neurons carrying significant II was low in all recorded layers in stage 1 but increased to more than half of the imaged neurons in stage 3, irrespective of cortical depth (-130 μm: 52.0%, -190 μm: 57.1%, -260 μm: 58.7%, -320 μm: 50.9%; <xref ref-type="fig" rid="F4">Fig. 4c</xref>). The emergence of II may be the result of two processes: (1) the increase in sensory information (MI-RS) available in neural activity over learning (<xref ref-type="fig" rid="F2">Fig. 2</xref>) or (2) an increase in the efficiency by which sensory information stored in vS1 is read out downstream to inform behavior. To determine the relative contribution of either process, we calculated the ratio of II/MI-RS for each neuron carrying significant II, at each depth and learning stage. This ratio quantifies the proportion of sensory information available in neural activity that is actually read out to inform sensory behavior. We found that II/MI-RS increased over learning in all recorded cortical depths, peaking at ratios &gt;0.75 in stage 3 (<xref ref-type="fig" rid="F4">Fig. 4d &amp; e</xref>). Importantly, all these findings also held when controlling for increased correlation between stimulus and choice across learning by trial stratification (<xref ref-type="supplementary-material" rid="SD1">Supp. Fig. 4</xref>.) In summary, during learning stage 1, some stimulus information is present but very little of it is read out. The increase in object-localization performance across learning is accompanied not only by an increase of sensory information available in the neural activity of vS1, but also by an increase in the efficiency by which this sensory information is read out to inform behavioral choices. By learning stage 3, more than 75% of the MI-RS could be used to guide the animal’s behavioral choice. These results were confirmed when using a simple decoder analysis<sup><xref ref-type="bibr" rid="R30">30</xref>,<xref ref-type="bibr" rid="R31">31</xref></sup> (<xref ref-type="supplementary-material" rid="SD1">Supp. Fig. 3</xref>). This suggests that increased object-localization accuracy with learning is mediated by both the traditionally posited increase of sensory information in sensory areas and, more surprisingly, by an increased efficiency of the downstream readout of this information.</p></sec><sec id="S7"><title>Correct readout of stimulus information in neural activity developed during learning is altered by rule switch</title><p id="P13">We next sought to investigate how changing the relationship between stimulus and reward after learning affects neuronal encoding of stimulus and choice information. To do this, we recorded a “switch day” in three mice that had achieved &gt;70% correct trials over three consecutive days. On this switch day, the task rule was reversed, and mice received a water reward if they licked when the stimulus was in the No-go position, while no water was delivered when mice licked in the Go position (<xref ref-type="fig" rid="F5">Fig. 5a</xref>). Mouse performance during the switch day dropped to 37.9±3.5% (mean±sd).</p><p id="P14">Mean MI-RS and MI-RC also dropped but stayed above the levels seen during stage 1 (<xref ref-type="supplementary-material" rid="SD1">Supp. Fig. 4</xref>). We wondered about the time course of this drop in information relative to the drastic changes in behavioral performance during the switch. We therefore considered behavioral performance, MI-RS and MI-RC separately for each of the three daily training blocks. During learning stages 1 and 3, behavioral performance was stable across the three daily training blocks. In contrast, performance collapsed to very low levels in the first block of the switch, recovering to chance levels by the last, third block (<xref ref-type="fig" rid="F5">Fig. 5b</xref>). Concurrently, MI-RS remained relatively high during block 1, and decreased gradually over the course of the switch session, whereas MI-RC was low throughout (<xref ref-type="fig" rid="F5">Fig. 5c</xref>). We next sought to assess the difference in stimulus and choice information between the individual blocks of the switch session and learning stages 1 and 3. We therefore subtracted, for each FOV, the frame-by-frame MI values of the switch session from the MI values of learning stages 1 and 3. MI-RS<sub>switch</sub> was overall higher than MI-RS<sub>stage1</sub> throughout the switch session, and especially during block 1 (<xref ref-type="fig" rid="F5">Fig. 5e</xref>, top), although the behavioral performance of each of the three mice was lower in this block than during stage 1 (<xref ref-type="fig" rid="F5">Fig. 5b</xref>, left and right). MI-RS<sub>switch</sub> was closer to MI-RS<sub>stage1</sub> during blocks 2 and 3. When comparing MI-RS<sub>switch</sub> to MI-RS<sub>stage3</sub>, MI-RS<sub>switch</sub> was still slightly higher during block 1 (<xref ref-type="fig" rid="F5">Fig. 5e</xref>, top), despite the lower behavioral performance (<xref ref-type="fig" rid="F5">Fig. 5b</xref>, center and right). In contrast, MI-RS<sub>switch</sub>, which remained stable in blocks 2 and 3, was lower during these blocks than it had been in stage 3. These results show that learning the association between a stimulus and a reward strengthens the former’s representation in layer 2-3 vS1 (MI-RS<sub>switch</sub> was initially higher than MI-RS<sub>stage1</sub>). Moreover, this representation remains stable only briefly (in our paradigm, about 50 trials) after the association with the reward has been altered (MI-RS<sub>switch</sub> was initially slightly higher than MI-RS<sub>stage3</sub>), in a way that is independent from behavioral performance (<italic>i</italic>.<italic>e</italic>., independent from the animal being able to fully recognize the change in association). On the other hand, information about choice followed a different time course, showing a faster drop during the switch session. Whereas MI-RC<sub>switch</sub> was slightly higher than MI-RC<sub>stage1</sub> during all 3 blocks (<xref ref-type="fig" rid="F5">Fig. 5f</xref>, top), it dropped below MI-RC<sub>stage3</sub> as early as in block 1 (<xref ref-type="fig" rid="F5">Fig. 5f</xref>, bottom). When measuring II<sub>switch</sub>, we found that it was still present in vS1 at the start of the switch session. This indicates that during block 1 of the switch session stimulus information was still read out to guide behavior, but the readout was incorrect (as performance dropped below chance level). During block 2 post switch, II<sub>switch</sub> and II<sub>stage1</sub> were both near zero, indicating that, at that point stimulus information was no longer used to inform choice. As expected, II<sub>switch</sub> was lower than II<sub>stage3</sub> during all 3 blocks of the switch session (<xref ref-type="fig" rid="F5">Fig. 5g</xref>). These results show that information about stimulus and choice decrease but remain present throughout the switch session. However, their relationship changes after the switch. Stimulus information did not inform behavioral choice and became rapidly decoupled from it after the association stimulus-reward was altered, as intersection information disappeared. Together, these results further underline that the efficient and correct readout of stimulus information, built during sensory training, is key to the learning of object-localization tasks.</p></sec><sec id="S8"><title>Task-learning produces generalized and persistent increase in information</title><p id="P15">We have so far described the changes in information present in cortical circuits that occur when sensory stimuli are associated with a reward. To conclude, we wanted to know whether these learning-related changes in information generalize to stimuli not used in the task and persist without reward.</p><p id="P16">In seven of the eight mice trained on the object localization task, we imaged activity in L2-3 vS1 neurons during two further sessions (“pre-training” and “post-training”) in which sensory stimuli were presented outside of the context of the Go/No-go task, <italic>i</italic>.<italic>e</italic>., without the spout to lick or the associated water reward. The pre-training session was performed before water regulation and task training started, while the post-training session took place two days after the end of the task training. The stimulus was now presented in six different positions of which position 3 and 6 corresponded to the Go and No-go cue positions used during task training (<xref ref-type="fig" rid="F6">Fig. 6a</xref>). To find out how much information about stimuli 3 and 6 was present in neurons of vS1 before and after training, we calculated the frame-by-frame MI-RS carried by each imaged neuron, across trials, at each depth and learning stage. Average MI-RS across neurons was low at all cortical depths when the mice experienced the whisker stimulation for the first time (<italic>i</italic>.<italic>e</italic>., during the pre-training session). Stimulus information more than doubled after training and the fraction of neurons carrying significant MI-RS increased in all cortical layers (<xref ref-type="fig" rid="F6">Fig. 6b &amp; c</xref>). The fraction of neurons carrying significant MI-RS during the pre-training session was consistently lower than the fraction of neurons carrying significant MI-RS during stage 1 of training (<xref ref-type="fig" rid="F2">Fig. 2d</xref>), suggesting that more neurons are recruited to encode stimulus information as soon as the stimulus-reward association is introduced.</p><p id="P17">We then asked whether sensory information improved specifically for the stimulus positions used in the object localization task, or whether the MI-RS increase reflected a general increase in object location information in vS1. We computed MI-RS on pairs of pole positions (1 and 4, 2 and 5) separated by the same distance as the Go / No-go positions 3 and 6. Before training, the percentage of significant MI-RS neurons was comparable across pairs of stimuli (mean across layers for 3 and 6: 17.3%; 1 and 4: 14.8%; 2 and 5: 16.9%). This percentage increased for all pairs of stimuli in the post-training session, together with a significant increase in MI-RS values (p&lt;0.001 for each pair of stimuli) (<xref ref-type="supplementary-material" rid="SD1">Supp. Fig. 5 a-d</xref>). In summary, MI-RS is significantly lower pre-training than in learning stage 1 (p&lt;0.001, Mann-Whitney test), and increases across learning stages 1 to 3, before declining post-training to levels below stage 3, but above those seen pre-training (p&lt;0.001, Mann-Whitney test, only neurons with significant MI-RS were considered; <xref ref-type="fig" rid="F6">Fig. 6d</xref>). To obtain a direct measure of this MI-RS change for individual cells, we considered 849 neurons tracked between the pre-training and post-training imaging sessions for the three pairs of stimuli. In these neurons MI-RS increased for all pairs of object locations (KW test, p=0.987; <xref ref-type="fig" rid="F6">Fig. 6e</xref>). This post-training effect can also be seen by a stronger contribution of non-discriminative neurons to improving decMI-RS for individual discriminative neurons (<xref ref-type="fig" rid="F6">Fig. 6f</xref> and <xref ref-type="supplementary-material" rid="SD1">Supp. Fig. 5 e-h</xref>). These results demonstrate that learning-related changes in information generalize to stimuli not used in the task and persist even when the animal is no longer engaged in the task.</p></sec></sec><sec id="S9" sec-type="discussion"><title>Discussion</title><p id="P18">This study provides a quantitative description of stimulus and choice information and their interplay over the course of task learning in L2/3 neurons of vS1 in mice. We find that the amount of choice information encoded by the neuronal population is more strongly tied to behavioral performance than the amount of stimulus information. Furthermore, we show that choice information is increasingly supported by a population code across learning more than stimulus information. Finally, we present data in support of our hypothesis that the emergence of choice information in vS1 reflects a more efficient use of stimulus information, resulting in changes to behavioral performance over the course of learning.</p><sec id="S10"><title>Learning-related changes to stimulus and choice information in L2/3</title><p id="P19">The physiological manifestation of the perceptual changes observed in learning remains a focus of intense study. Previous reports have shown that neurons in the rodent vS1 and other primary areas not only carry sensory information, but can also encode multiple task variables, from navigational signals<sup><xref ref-type="bibr" rid="R32">32</xref></sup> to behavioral choice<sup><xref ref-type="bibr" rid="R33">33</xref>–<xref ref-type="bibr" rid="R38">38</xref></sup> and expectation<sup><xref ref-type="bibr" rid="R39">39</xref></sup>. Such representations may become stronger as animals learn behavioral tasks. We confirmed that both stimulus and choice information build up progressively during learning, with choice information being more dependent on task engagement than stimulus information. Traditionally, sensory learning has been considered as the result of an improvement in the representation of sensory inputs in primary cortex. On the other hand, recent studies have found that perceptual improvements over the course of learning may correspond to an increasingly efficient readout of sensory information in higher cortical regions while sensory representations remain stable in primary areas<sup><xref ref-type="bibr" rid="R27">27</xref></sup>. In our study, comparisons between the levels of mutual information and intersection information over the course of learning revealed that not only stimulus information increases but also that stimulus information is more efficiently used by neurons in primary sensory cortex during the late phase of training. In other words, stimulus and choice information do not simply increase independently of one another during task learning. Instead, the increase in readout efficacy of the stimulus information leads to the increase in choice information and, consequently, in behavioral performance. Our findings give support to both hypotheses on learning-related neuronal changes. Critically, we revealed that neurons in early sensory cortex were key in such a process, even before the involvement of higher cortical regions. Our results, therefore, are in line with a model where cortical areas are not hierarchically organized, but rather operate in parallel<sup><xref ref-type="bibr" rid="R38">38</xref></sup>.</p><p id="P20">In our study, we use linear decoders and information theory to directly quantify information contained in neuronal activity. Our decoder analysis shows levels of stimulus and choice decoding in vS1 that are comparable to recent reports<sup><xref ref-type="bibr" rid="R5">5</xref>,<xref ref-type="bibr" rid="R40">40</xref>,<xref ref-type="bibr" rid="R41">41</xref></sup>. Most studies quantified neuronal representations of information using a number of other measures, including the magnitude and frequency of neuronal activity or classification model accuracy. This difference in approach may account for some diverging observations: 1. We find that the amount of stimulus information and the number of neurons carrying it increase steadily with task training. This aligns with some previous studies<sup><xref ref-type="bibr" rid="R3">3</xref>,<xref ref-type="bibr" rid="R7">7</xref>,<xref ref-type="bibr" rid="R9">9</xref></sup>, but contrasts with other reports showing that stimulus-related neuronal representations remain unchanged with learning<sup><xref ref-type="bibr" rid="R5">5</xref>,<xref ref-type="bibr" rid="R11">11</xref></sup>. 2. We find that a large number of neurons carry significant levels of both stimulus and choice information. This significantly expands on previous work which segregated neurons based on stimulus and choice representation<sup><xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R34">34</xref>,<xref ref-type="bibr" rid="R35">35</xref></sup>. Furthermore, the level of stimulus information used to inform choice in expert mice is similar to that recently reported in A1<sup><xref ref-type="bibr" rid="R37">37</xref></sup>.</p></sec><sec id="S11"><title>Role of single neuron <italic>versus</italic> population codes</title><p id="P21">The relative contribution of changes in single neurons <italic>vs</italic>. the population to successful task learning is still unknown. Learning has been shown to change single neuron response patterns in vS1<sup><xref ref-type="bibr" rid="R3">3</xref>,<xref ref-type="bibr" rid="R9">9</xref></sup> and elsewhere<sup><xref ref-type="bibr" rid="R34">34</xref>,<xref ref-type="bibr" rid="R42">42</xref>,<xref ref-type="bibr" rid="R43">43</xref></sup>, but also to influence population encoding<sup><xref ref-type="bibr" rid="R44">44</xref></sup>. By combining information theory with linear classifiers, we show that choice, but not stimulus, information benefits increasingly from a population code across learning. Together with the observation that stimulus and choice information emerge and are lost over different time courses in vS1, these findings indicate that different cellular and molecular mechanisms may support stimulus and choice encoding in primary sensory cortices. Furthermore, we find that when task contingencies were switched, significant changes in stimulus information are seen over the course of hours, suggesting a role for local, long-term plasticity<sup><xref ref-type="bibr" rid="R45">45</xref>,<xref ref-type="bibr" rid="R46">46</xref></sup>. In comparison, changes in choice information occur much more rapidly than would be expected if they were supported solely by local long-term plasticity, suggesting that they may be driven by an instructive top-down signal. Such signals from secondary somatosensory cortex<sup><xref ref-type="bibr" rid="R4">4</xref></sup> or orbitofrontal cortex<sup><xref ref-type="bibr" rid="R44">44</xref></sup> have been shown previously to be required for choice coding. In agreement with findings that these top-down signals preferentially synapse with superficial L2/3 neurons, we show that during learning choice information increases most in superficial L2. In contrast, stimulus information increases most on L3, as also seen in <sup><xref ref-type="bibr" rid="R47">47</xref></sup>.</p></sec><sec id="S12"><title>Persistence of learning-related changes outside of task conditions</title><p id="P22">Lastly, we show that following learning, when mice are re-exposed to the same stimuli outside of the context of the task, the changes in stimulus encoding observed during learning appear persist in vS1 in a weaker, but more generalized way. Stimulus information about the task-relevant pole positions, and also nearby pole locations, increases relative to before learning began. Furthermore, it is more dependent on a population code than it was before training. This is consistent with<sup><xref ref-type="bibr" rid="R48">48</xref></sup> who found that experience-induced plasticity in vS1 increased responsiveness particularly in neurons that initially showed weak stimulus responses. Together, these findings suggest that, outside of task conditions, vS1 may rely on a strengthened population code, instead of strong individual neuron responses, to continue to efficiently encode behaviorally relevant stimuli. Since this change in encoding is also context-dependent, it points to another way in which instructive top-down signals may shape how information is encoded in the vS1 population.</p></sec><sec id="S13" sec-type="conclusions"><title>Conclusion</title><p id="P23">Tools from information theory provided us with novel insights into how different types of information are encoded and integrated during learning. This approach should be of great importance in identifying promising targets for manipulation to test the causal relationship between neuronal information and behavioral performance on a related task<sup><xref ref-type="bibr" rid="R29">29</xref></sup>. While a growing body of work demonstrates that the manipulation of a few dozens of cortical neurons is sufficient to modulate behavior in sensory-guided tasks<sup><xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R49">49</xref>–<xref ref-type="bibr" rid="R51">51</xref></sup>, it remains unclear why targeting so few neurons has such an effect. Our work suggests that a common feature of such neurons could be that they carry sensory information used to inform choice, offering concrete future avenues for cracking the neural code.</p></sec></sec><sec id="S14" sec-type="methods"><title>Methods</title><sec id="S15" sec-type="subjects"><title>Subjects</title><p id="P24">All animal experimental procedures were approved and conducted in accordance with the United Kingdom Animals (Scientific Procedures) Act 1986 under project license P8E8BBDAD and personal licenses from the Home Office. Mice were housed in groups in a climate-controlled vivarium (lights on 7:00 to 19:00). The holding room temperature was 23±1 degrees Celsius and humidity was set to 40±10%. The experiments were conducted during the light portion of the photoperiod. Mice had <italic>ad libitum</italic> access to food, but access to water was restricted from one week before the start of behavioral training until the end of the training period. All weights were kept at 85–90% of the free-drinking weight for the duration of the behavioral experiments. All mice belonged to a GCaMP6s reporter line obtained by mating the TRE-GCaMP6s line (Jackson Laboratories strain # 024742) with the CaMKII-tTA line (Jackson Laboratories strain # 003010).</p></sec><sec id="S16"><title>Surgery</title><p id="P25">Eight males aged 9 to 12 weeks underwent surgery for headbar and chronic optical window implantation. Before surgery, mice received injections of meloxicam (5 mg/kg, Metacam, Boehringer Ingelheim International GmbH, Ingelheim am Rhein, Germany) and vetergesic (0.1 mg/kg, Ceva Animal Health Ltd, Amersham, UK). They also received a marcaine (AstraZeneca, Cambridge, UK) injection under the scalp. Eye cream was applied to the eyes (lacri-Lube, Allergan, UK). Anesthesia was induced via inhalation of 4% isoflurane (Zoetis, Leatherhead, UK) at 1 L/min. When mice were fully anesthetized, they were placed in a stereotaxic frame (Kopf instruments, Tujunga, CA). Depth of anesthesia was monitored by checking pedal withdrawal reflex and respiration rate. Body temperature was kept at 37±1°C. Isoflurane rate was kept at 0.8–1.2% at 0.7 L/min during surgery. A circular incision was made into the scalp, the skull was cleaned, and the periosteum removed. A 3 mm diameter craniotomy was centered over the right vS1 following stereotaxic coordinates (3.1 mm lateral from the midline and 1.3 mm posterior from the Bregma suture). The dura mater was left intact. The craniotomy was then sealed with two glass coverslips (3 mm and 4 mm diameter, Thermo Fisher Scientific, UK) glued to one another using optical adhesive (Norland, New Jersey, USA). A stainless steel headbar was cemented onto the skull using dental cement (Super-Bond C&amp;B, Sund Medical, Japan). After surgery, mice were allowed to recover for one to two weeks before starting handling and water regulation. Handling and gentle restraint by the experimenter were performed over three days. Mice were then habituated to be headfixed under the imaging setup, and to receive water from a spout placed in front of them. This habituation phase lasted three further days, after which behavioral training started.</p></sec><sec id="S17"><title>Sensory stimulation</title><p id="P26">Tactile stimuli consisted of a small metallic pole (a blunt 18G needle, diameter 1.27 mm), held vertically and contacting the majority of the left whiskers of the mouse for 1 to 1.5 seconds at approximately 0.3 cm from the whisker pad. Mice were free to whisk against the pole. The pole was connected to a perpendicular plastic arm mounted onto the shaft of a stepper motor (RS PRO Hybrid 535-0467; RS Components, UK). The stepper motor was mounted onto a motorized linear stage (DDSM100/M; Thorlabs. controlled by a K-Cube Brushless DC Servo Driver [KBD101; Thorlabs]), which moved the metallic pole close to the whiskers or away from them. The length traveled by the linear stage was identical during Go and No-go trials. During the pre-training and post-training sessions, the pole contacted the whiskers in six positions along the antero-posterior axis of the animal, separated 2.4 mm from one another. The most anterior position is denoted as position 1 throughout the text, while the most posterior is position 6. During the behavioral training phase, positions 3 and 6 were the only two used as tactile stimuli. The stepper motor only rotated between the positions once it had traveled away from the whisker pad via the linear stage. Rotating from position 1 into position 6 took approximately 90 ms longer than rotating into position 3. The sound frequency emitted consisted primarily of energy below 1 kHz, which is outside the mouse frequency hearing range<sup><xref ref-type="bibr" rid="R52">52</xref></sup>. Sound intensity of the stepper motor and linear stage was &lt;30 dB SPL. Ambient noise inside the microscope box was below 40 dB SPL. Intensity thresholds for primary auditory cortical neurons in the mouse range between 4 and 39 db SPL<sup><xref ref-type="bibr" rid="R53">53</xref></sup>. Our measurements allowed us to exclude the presence of potential auditory cues during the task.</p></sec><sec id="S18"><title>Behavioral training</title><p id="P27">Hardware and software for behavioral experiments were controlled through the open-source toolbox pyControl (OEPS Electrónica e Produção, Alges, Portugal)<sup><xref ref-type="bibr" rid="R54">54</xref></sup>. We trained mice on a whisker-based object localization Go/No-go task<sup><xref ref-type="bibr" rid="R55">55</xref></sup>. As described in the previous section, the metallic pole came into contact with the whiskers for 1 to 1.5 s in one of two possible positions along the anterior-posterior axis of the mouse. The first lick latency was calculated from stimulus offset. During Go trials, mice were rewarded with an 8 μl drop of sweetened water (10% sucrose solution) when they licked from a spout during a response / licking window starting 100 ms after the retraction of the pole and lasting four seconds (Hit trials). Water was not delivered if mice licked while the pole was still in contact with the whiskers (“Too soon” trials, not included in the analysis). Licks during No-go trials were considered as False Alarms and were punished with an extended inter-trial interval (time-out). No punishment nor time-out were presented when mice did not lick during Go trials (Misses). Daily training took place in three consecutive blocks of about 16 minutes duration each. Across the three blocks, mice performed on average 187±48 trials per training day. Learning was classified into three stages, based on the percentage of correct responses in each block: 0-55% (stage 1), 55-75% (stage 2), 75-100% (stage 3). Training ended when a mouse’s performance averaged higher than 70% across the three blocks, for three consecutive days. Only mice that performed above 70% for three consecutive days were retained for analysis (n=8). During pre-training and post-training sessions, mice (n=3) were not water-regulated but had <italic>ad libitum</italic> access to water in their home cage. This was to avoid potential confounds related to the animals being thirsty during these sessions. Two of the mice imaged pre- and post-training were also used in “switch” session. At the end of the switch session, each of them was tested on the task based on the original contingencies. They both reached 70% within one session, at the end of which training was ended.</p></sec><sec id="S19"><title>Two-photon imaging</title><p id="P28">Quasi-simultaneous double-plane two photon calcium imaging was performed using the set up described in detail in<sup><xref ref-type="bibr" rid="R17">17</xref></sup>. Two photon excitation light was emitted by a femtosecond Ti:Sapphire laser (MaiTai BB, Spectra Physics, USA) tuned to 900 nm. Double-plane imaging was achieved using a system including a DTSX-400-980 Acousto-Optic Deflector (AOD; Photon Lines Ltd., UK), a SF11 equilateral prism (Thorlabs, UK), and two aspheric lenses (C330TMD-B, Thorlabs, UK). The laser beam was directed to the AOD, whose acoustic frequency switched between 83.5 MHz and 91.5 MHz, generating two optical paths: one leading to the nominal focal plane, and the second encompassing the aspheric lenses for refocusing onto a second focal plane, placed 130 μm below the first one. This permitted efficient acquisition of multiple planes while keeping the behavioral experiment short. During each of the three behavioral blocks (ca. 16 min, see above), we re-focused the imaging path once to acquire imaging data from fields of view (FOVs) at four depths below the cortical surface (-130, -190, -260 and -320 μm), equivalent to approximately cortical layers 2 and 3. The same FOVs were imaged in each mouse across training sessions. The two beams were then recombined through a polarizing beamsplitter. Calcium transients were acquired using a Sutter Moveable Objective microscope (MOM, Sutter, USA) controlled by ScanImage 5.2.1 software (<ext-link ext-link-type="uri" xlink:href="http://scanimage.org">http://scanimage.org</ext-link>) with minor modifications for the AOD beam steering control. The beam was scanned through an 8 kHz resonant scanner in the x-plane and a galvanometric scanning mirror in the y-plane. The resonant scanner was used in bidirectional mode, at a resolution of 512 × 512 pixels, allowing us to acquire frames at a rate of ~15 Hz per imaging plane. A 16X/0.80W LWD immersion objective (Nikon, UK) was used. Laser power, as measured under the microscope objective, was between 80 mW and 95 mW. Emitted photons were guided through a 525/50 filter onto GaAsP photomultipliers (Hamamatsu Photonics, Japan). Neuronal fields were 400 × 400 μm in size.</p></sec><sec id="S20"><title>Intrinsic Optical Signal Imaging</title><p id="P29">Intrinsic Optical Signal Imaging (IOSI) was carried out at the end of the experimental procedure to confirm that 2p imaging was performed in vS1. General anesthesia was induced with 4% isoflurane (Zoetis, Leatherhead, UK) at 1 L/min, and was then kept at 0.6–0.8% at 0.7 L/min during imaging. An <italic>intra muscular</italic> injection of chlorprothixene hydrochloride (1 mg/kg) was administered to inhibit whisker movements. Mice were head-fixed and placed on a heated mat. Temperature was kept at 37±1°C. One whisker from the left row B, C or D was identified and threaded through a glass capillary, which was attached to a ceramic piezoelectric stimulator (<italic>e.g.</italic>, PB4NB2W Piezoelectric Bimorph Bending Actuator with Wires, Thorlabs). If the surrounding whiskers touched the external side of the capillary, they were carefully trimmed using a pair of iris scissors under a dissecting microscope. A Retiga R1 camera with a 50 mm and a 135 mm lens (Nikon) attached in tandem configuration was used for imaging<sup><xref ref-type="bibr" rid="R56">56</xref></sup>. Imaging was performed through the chronic cranial window previously implanted over the right parietal lobe. The whisker stimulation protocol consisted of 1 s stimulation at 10 Hz with 20 s ITI, repeated 40 times, for a total of 400 deflections. This protocol was repeated 3-4 times per mouse on different whiskers in order to map the barrel fields in vS1. For post-hoc confirmation of the imaging location in vS1, a map of the vS1 barrels obtained through IOSI was overlaid upon images of the areas investigated with 2p imaging (see, <xref ref-type="fig" rid="F1">Fig. 1</xref>).</p></sec><sec id="S21"><title>Two photon imaging analysis</title><p id="P30">Raw 2p images were imported into the Suite2p software (<ext-link ext-link-type="uri" xlink:href="https://github.com/MouseLand/suite2p">https://github.com/MouseLand/suite2p</ext-link><sup><xref ref-type="bibr" rid="R57">57</xref></sup>), which performed correction for mechanical drift along the x and y axes, image segmentation, and neuronal and neuropil trace extraction. We manually inspected all regions of interest detected by the Suite2p built-in classifier, to confirm that they corresponded to neurons rather than structures such as fragments of neuronal projections or perpendicular blood vessels. For each confirmed neuron, the signal at each time frame (F<bold><italic>(t)</italic></bold>) was calculated as the average fluorescence of all pixels inside the ROI. The time series of the neuronal calcium trace and the neuropil calcium trace were exported to Matlab for further analysis. Baseline Fluorescence (F<sub><italic>0</italic></sub>) was considered to be the median of the 10th to the 70th percentile of the fluorescence distribution across all frames acquired. Each neuron’s fluorescent trace was then corrected for the baseline using the formula: (F(t) – F<sub>0</sub>)/F<sub>0</sub>, commonly denoted as ΔF/F<sub>0</sub>. Subtraction of the neuropil signal was applied to each neuron’s trace as described previously<sup><xref ref-type="bibr" rid="R58">58</xref></sup>, using a contamination ratio of r = 0.7. Semi-automatic ROI registration across the pre-training and post-training imaging sessions was performed using the “registers2p” package (<ext-link ext-link-type="uri" xlink:href="https://github.com/cortex-lab/Suite2P/tree/master/registers2p">https://github.com/cortex-lab/Suite2P/tree/master/registers2p</ext-link>). Although the majority of our analysis did not require to systematically track neurons over the course of daily imaging sessions, examples of tracked neurons are given, <italic>e</italic>.<italic>g</italic>., in <xref ref-type="fig" rid="F1">Fig. 1g</xref> or <xref ref-type="fig" rid="F6">Fig. 6e</xref>. The signal-to-noise ratio (SNR) was calculated during pre-training and post-training imaging sessions on the raw fluorescent trace for each ROI. The signal was the maximum fluorescence value of the whole trace. The noise was the standard deviation of the distribution of fluorescence values recorded during the first 3 seconds of acquisition, when sensory stimulation was not yet present<sup><xref ref-type="bibr" rid="R17">17</xref></sup>.</p></sec><sec id="S22"><title>Mutual information analyses</title><p id="P31">The information content of the neuronal response about stimulus (MI-RS) and choice (MI-RC) has been quantified using Shannon’s Mutual Information. Mutual information between two discrete random variables is defined as: <disp-formula id="FD1"><label>[Eq.1]</label><mml:math id="M1"><mml:mi>M</mml:mi><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>;</mml:mo><mml:mi>Y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>∑</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mi>Y</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msubsup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mi>g</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula> We used a plug-in direct method in which probabilities are computed directly from discretized data and then plugged into the information equation, as follows. Continuous values of the ΔF/F<sub>0</sub> traces were discretized using two equally populated bins. Calculation of the marginal and joint probabilities in <xref ref-type="disp-formula" rid="FD1">Eq. 1</xref> was performed by building a histogram of the discretized values of the neuronal response and stimulus/choice across trials. Values of MI obtained were corrected for limited sampling bias using the Panzeri-Treves method<sup><xref ref-type="bibr" rid="R59">59</xref></sup>. For each time frame during the trial (3 seconds after stimulus onset), a single calculation of MI was performed by considering the neural response as the set of values of ΔF/F<sub>0</sub> for that time point across trials. Binning of the ΔF/F<sub>0</sub> values has been performed independently at each time frame. Assessment of significance for mutual information values was performed through a permutation test limited to the first second of neural activity after stimulus onset (i.e., before the opening of the time window for licking). A null distribution of MI values was built through randomly permuting the neuronal response across trials<sup><xref ref-type="bibr" rid="R60">60</xref></sup>. Permutation of trials was performed consistently across all time points. This allowed us to abolish the association between stimulus (or choice) and neuronal response while preserving the autocorrelation in the fluorescence signal. Evaluation of the significance level of the MI carried by each neuron was performed as follows. For each time point, 50 bootstrapped values of MI were calculated. Bootstrapping was performed without correcting for limited sampling bias, owing to the larger statistical power of non bias-corrected null distribution<sup><xref ref-type="bibr" rid="R61">61</xref></sup>. Significance of MI for a single neuron was assessed by comparing (using the Kruskal-Wallis test) the distribution of non bias-corrected MI across frames, with the distribution of the mean values of bootstrapped MI for the same frames. Values of MI reported for significant neurons are corrected for limited sampling bias. Within a trial, MI-RC peaked about 1 second after the pole moved away from the whiskers (<xref ref-type="fig" rid="F2">Fig. 2g</xref>). This peak comes later than the mean first lick latency in Hit trials observed during stage 2 and 3 of learning but is in line with the first lick latency during FA trials (<xref ref-type="fig" rid="F1">Fig. 1d</xref>). However, since mice do not lick during CR and Miss trials, a behavioral paradigm different from the Go/No-go used here would be required to properly evaluate any temporal coincidence between choice and peak MI-RC.</p></sec><sec id="S23"><title>Intersection information analyses</title><p id="P32">Intersection Information<sup><xref ref-type="bibr" rid="R28">28</xref>,<xref ref-type="bibr" rid="R29">29</xref></sup> is an information-theoretic measure quantifying the amount of stimulus information, present in the neural activity, that is used to inform choice. The quantity is based on the Partial Information Decomposition formalism<sup><xref ref-type="bibr" rid="R62">62</xref></sup>, and is bound by both MI-RS and MI-RC. This property allows one to conveniently express II/MI-RS as the fraction of stimulus information that is used to inform choice. We computed II following the procedure in <sup><xref ref-type="bibr" rid="R28">28</xref></sup> and using the same plug-in direct method used for MI-RS and MI-RC and described above. Correction of limited sampling bias has been performed using quadratic extrapolation<sup><xref ref-type="bibr" rid="R63">63</xref></sup>. To reduce the computational cost of the analysis, the dimensionality of the ΔF/F<sub>0</sub> traces in the post-stimulus epoch was halved by considering the average ΔF/F<sub>0</sub> across two consecutive time frames. Discretization of the neuronal response was performed, independently at each time frame, using two equally populated bins. Assessment of the significance of II for a single neuron was performed using a permutation test, similarly to what we did for mutual information. The null distribution for II, at each time frame, was calculated by permuting neuronal responses across all trials.</p></sec><sec id="S24"><title>Decoder analyses</title><p id="P33">Linear logistic regressions were trained using 5-fold cross-validation with an L<sub>2</sub> penalty. Decoders were trained separately on each session FOV, <italic>i</italic>.<italic>e</italic>., each FOV recorded during each imaging session. All decoders received, as input, neuronal activity from the first second following stimulus onset, and all trial types except ones where mice licked too soon were included (Hit, FA, CR, Miss). This ensured that the inputs to the decoders did not coincide with any licking, creating confounds. Decoders trained on individual neurons received as input the ΔF/F<sub>0</sub> response of a single neuron (<xref ref-type="fig" rid="F3">Fig. 3a-b</xref>, <xref ref-type="supplementary-material" rid="SD1">Supp. Fig. 2 and Supp. Fig. 4e</xref>), whereas decoders trained on multiple neurons received as input the concatenated ΔF/F<sub>0</sub> responses of all included neurons (<xref ref-type="fig" rid="F3">Fig. 3c-j</xref>, <xref ref-type="fig" rid="F4">Fig. 4a-b</xref>, <xref ref-type="fig" rid="F6">Fig. 6f</xref>, and <xref ref-type="supplementary-material" rid="SD1">Supp. Fig. 4f-h</xref>).</p><p id="P34">Decoders were trained to predict for each trial either stimulus identity (Go/No-go) (<xref ref-type="fig" rid="F3">Fig. 3a &amp; c &amp; e-g</xref>, <xref ref-type="fig" rid="F6">Fig. 6f</xref>, and <xref ref-type="supplementary-material" rid="SD1">Supp. Fig. 4e-h</xref>) or choice (Lick/No-lick) (<xref ref-type="fig" rid="F3">Fig. 3b &amp; d &amp; h-j</xref>), or both (<xref ref-type="fig" rid="F4">Fig. 4a-b</xref>). To evaluate decoder performance, we computed a mutual information score on the confusion matrices obtained from the validation fold predictions (decMI)<sup><xref ref-type="bibr" rid="R22">22</xref></sup>. This approach allows us to estimate information content not only for individual neurons, but also for groups of neurons. We confirmed the validity of our decMI measure by comparing decMI values obtained for individual neurons to the previously computed MI measures (<xref ref-type="supplementary-material" rid="SD1">Supp. Fig. 2</xref>). Decoder performance was reported as decMI-RS for stimulus identity (MI when predicting stimulus from neural response) and decMI-RC for choice (MI when predicting choice from neural response). We report results grouped across depths, at each stage of learning.</p><p id="P35">When decoder performance for individual neurons was plotted against behavioral performance, jitter was added to the behavioral performance for visualization purposes to enable values for individual neurons to be distinguished. This was done by resampling the behavioral performance value for each neuron using a normal distribution centered on the true value with a standard deviation of 1.2% (<xref ref-type="fig" rid="F4">Fig. 4a-b</xref>). For all decoders, to ensure sufficient numbers of each trial type were available for training the decoders, for choice decoding, only sessions with at least six Lick and six No-lick trials were included (number of session FOVs removed: eight for stage 1, on for stage 2, zero for stage 3) (<xref ref-type="fig" rid="F3">Fig. 3a &amp; c &amp; e-g</xref>, <xref ref-type="fig" rid="F4">Fig. 4a-b</xref> and <xref ref-type="supplementary-material" rid="SD1">Supp Fig. 2b</xref>). Furthermore, to ensure that choice decoding and stimulus decoding results could be appropriately distinguished, only sessions that included at least six correct and six wrong trials were included for all decoders trained on task training sessions (number of session FOVs removed: zero for stage 1, four for stage 2, 23 for stage 3) (<xref ref-type="fig" rid="F3">Fig. 3</xref>, <xref ref-type="fig" rid="F4">Fig. 4a-b</xref> and <xref ref-type="supplementary-material" rid="SD1">Supp Fig. 2</xref>).</p><p id="P36">Null distributions were estimated by running, for each neuron, ten 5-fold cross-validations, each computed on data where the trial types had been randomly shuffled. By aggregating decMI values resulting from shuffled data across neurons from the same session FOV, a null distribution over decoder performance was constructed for each session FOV. Neurons with decMIs above the 95<sup>th</sup> percentile of the null distribution were identified as carrying significant information and labeled as “discriminative” neurons for the session FOV. Neurons that did not meet the threshold for their session FOV were labeled as “non-discriminative” (<xref ref-type="fig" rid="F3">Fig. 3a &amp; c</xref> and <xref ref-type="supplementary-material" rid="SD1">Supp Fig. 4e</xref>).</p><p id="P37">To compare decMI and MI values for each neuron, we recomputed both maximum MI and MI significance over the same trial length used for the decoders, i.e., the first second following stimulus onset. The MI-RS values thus obtained were then compared to decMI-RS for each neuron (<xref ref-type="supplementary-material" rid="SD1">Supp. Fig. 2a</xref>), whereas MI-RC values were compared to decMI-RC values (<xref ref-type="supplementary-material" rid="SD1">Supp. Fig. 2b</xref>). For each stage of learning, a linear regression model was fit to the data, and the goodness-of-fit was measured using the R<sup>2</sup> coefficient of determination (<xref ref-type="supplementary-material" rid="SD1">Supp. Fig. 2a</xref>). The same process was repeated to compare MI-RC and decMI-RC values for neurons significant for both (<xref ref-type="supplementary-material" rid="SD1">Supp. Fig. 2b</xref>).</p><p id="P38">To evaluate how decoder performance changed as neurons were added to the pool of data provided to the decoders, neurons were first ordered from the lowest to highest individual decMI(R;S) (<xref ref-type="fig" rid="F3">Fig. 3c</xref> and <xref ref-type="supplementary-material" rid="SD1">Supp. Fig. 4f</xref>) or decMI(R;C) (<xref ref-type="fig" rid="F3">Fig. 3d</xref>). Decoders were trained to classify stimulus or choice, respectively, as neurons were added in that order, for each FOV from either the full pool of neurons (<xref ref-type="fig" rid="F3">Fig. 3c &amp; d</xref>, left and <xref ref-type="supplementary-material" rid="SD1">Supp. Fig. 4f</xref>, left) or the pool of non-discriminative neurons (<xref ref-type="fig" rid="F3">Fig. 3c &amp; d</xref>, right and <xref ref-type="supplementary-material" rid="SD1">Supp. Fig. 4f</xref>, right). Since different FOVs comprise different total numbers of neurons, to enable the pooling, the data from each FOVs was downsampled down to the lowest number of neurons present in at least 5 FOVs (18 neurons for the full population, and 11 neurons for the non-discriminative pool). Neuron numbers were then converted to percentages and mean ± sem was calculated across FOVs. Statistical comparisons between stage 1 and 2, as well as stage 2 and 3 were computed for each datapoint using t-tests. As elsewhere, p-values were Bonferroni corrected for multiple comparisons, calculated here as the total number of comparisons for each data panel.</p><p id="P39">To determine the gain contributed by non-discriminative neurons to classification performance for discriminative neurons, in addition to training decoders on data from individual discriminative neurons, additional decoders were trained on data from each individual discriminative neuron paired with all the non-discriminative ones from the same session FOV. These decoders received as input the concatenated responses of all included neurons for each trial. The gain contributed by the non-discriminative population was then measured by, for each discriminative neuron, subtracting the decMI of the decoder trained only on the individual discriminative neuron data from the decMI of the decoder trained on data from the same discriminative neuron and the pool of non-discriminative neurons (<xref ref-type="fig" rid="F3">Fig. 3e &amp; h</xref> and <xref ref-type="supplementary-material" rid="SD1">Supp Fig. 4g</xref>). Positive gain reflected an improvement when including non-discriminative data, whereas negative gain reflected a drop in performance. Histograms over these gains were computed by binning the data into 40 bins (<xref ref-type="fig" rid="F3">Fig. 3f &amp; i</xref> and <xref ref-type="supplementary-material" rid="SD1">Supp Fig. 4h</xref>). Cumulative distributions over the same data, binned into 80 bins (<xref ref-type="fig" rid="F3">Fig. 3g &amp; j</xref> and <xref ref-type="fig" rid="F6">Fig. 6f</xref>).</p><p id="P40">Lastly, to determine whether decoders trained on stimulus classification performance carried choice information, decoders were first trained on the entire pool of neurons for each session FOV to classify stimulus identity (Go vs NoGo). We then sorted trials according to whether the decoder classified stimulus identity correctly (“S+”, <italic>e</italic>.<italic>g</italic>., for a trial where the stimulus was classified as Go and it was Go) or incorrectly (“S-”, <italic>e</italic>.<italic>g</italic>., for a trial where the stimulus was classified as Go but it was NoGo).</p><p id="P41">Finally, we calculated the % correct choice across session FOVs for each stage of learning enabling corresponding animal behavior (% correct choice in S+ trials - % correct choice in S- trials). Paired t-tests were then computed between both behavioral performances in order to determine whether the performance levels observed differed significantly at any learning stage for S+ <italic>vs</italic>. S- trials.</p><p id="P42">Although decoder mutual information is primarily reported in this paper, we also computed balanced accuracies for the decoders (data not shown) and found that the decoding accuracies computed for discriminative neurons at all stages were comparable to those reported in previous work on decoding tactile stimuli and choice from neural activity<sup><xref ref-type="bibr" rid="R3">3</xref>,<xref ref-type="bibr" rid="R11">11</xref>,<xref ref-type="bibr" rid="R41">41</xref></sup>.</p></sec><sec id="S25"><title>Statistical analysis</title><p id="P43">Differences between the distributions over population data for pairs of learning stages were evaluated using two-sided Kolmogorov-Smirnov tests with Bonferroni corrections for multiple comparisons. Corrected p-values &lt;0.05 are considered significant. Mean ± standard error of the mean (sem) is reported unless otherwise indicated. One, two and three significance stars indicate p &lt;0.05, p &lt;0.01, and p &lt;0.001 respectively.</p></sec><sec id="S26"><title>Analysis software</title><p id="P44">Mutual Information calculations were carried out using the Information Breakdown Toolbox<sup><xref ref-type="bibr" rid="R64">64</xref></sup>. Intersection information calculations were performed using custom MATLAB routines, coupled with Python package BROJA2-PID<sup><xref ref-type="bibr" rid="R65">65</xref></sup>. Decoder analyses were performed in Python 3.9 with custom scripts developed using the following packages: NumPy<sup><xref ref-type="bibr" rid="R66">66</xref></sup>, SciPy 1.6.2<sup><xref ref-type="bibr" rid="R67">67</xref></sup>, Pandas<sup><xref ref-type="bibr" rid="R68">68</xref></sup>, Matplotlib<sup><xref ref-type="bibr" rid="R69">69</xref></sup>, and Scikit-learn 0.24.1<sup><xref ref-type="bibr" rid="R70">70</xref></sup>. The remaining analysis was using custom scripts written in MATLAB2021b.</p></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary Information</label><media xlink:href="EMS158183-supplement-Supplementary_Information.pdf" mimetype="application" mime-subtype="pdf" id="d29aAdEbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S27"><title>Acknowledgements</title><p>We thank Dr Ana Bottura de Barros and Dr Severin Limal for help with the behavioral set up, Dr James Rowland for help on the preprocessing of 2-photon imaging data, Dr Liad Baruchin and Dr Severin Limal for help with Intrinsic Optical Signal Imaging.</p><p>This work was enabled by the resources provided by Compute Ontario and the Digital Research Alliance of Canada (<ext-link ext-link-type="uri" xlink:href="https://www.computeontario.ca/">www.computeontario.ca</ext-link> and <ext-link ext-link-type="uri" xlink:href="https://alliancecan.ca/en">www.alliancecan.ca</ext-link>).</p><sec id="S28"><title>Funding</title><p>This work was supported by the Wellcome Trust (109908/Z/15/Z, to M.M.K.) and the Human Frontiers Science Programme (RGY0073/2015, to B.A.R. and M.M.K.). M.P. and R.M. are Marie Sklodowska-Curie Fellows (EnlightenedLoom - 101024523, and MoWS - 894032). C.J.G. was supported by an NSERC Canada Graduate Scholarship - Doctoral Program, and an Ontario Graduate Scholarship. S.P. was supported by EU H2020 under Grant Agreement No. 945539 (Human Brain Project SGA3). B.A.R. was supported by a CIFAR Catalyst grant, a CIFAR AI Chair grant, an NSERC Discovery grant (RGPIN-2014-04947), and an Ontario Early Researcher Award (ER17-13-242).</p></sec></ack><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fanselow</surname><given-names>EE</given-names></name><name><surname>Nicolelis</surname><given-names>MAL</given-names></name></person-group><article-title>Behavioral Modulation of Tactile Responses in the Rat Somatosensory System</article-title><source>J Neurosci</source><year>1999</year><volume>19</volume><fpage>7603</fpage><lpage>7616</lpage><pub-id pub-id-type="pmcid">PMC6782523</pub-id><pub-id pub-id-type="pmid">10460266</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.19-17-07603.1999</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pantoja</surname><given-names>J</given-names></name><etal/></person-group><article-title>Neuronal Activity in the Primary Somatosensory Thalamocortical Loop Is Modulated by Reward Contingency during Tactile Discrimination</article-title><source>J Neurosci</source><year>2007</year><volume>27</volume><fpage>10608</fpage><lpage>10620</lpage><pub-id pub-id-type="pmcid">PMC6673144</pub-id><pub-id pub-id-type="pmid">17898232</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5279-06.2007</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>JL</given-names></name><etal/></person-group><article-title>Pathway-specific reorganization of projection neurons in somatosensory cortex during learning</article-title><source>Nat Neurosci</source><year>2015</year><volume>18</volume><fpage>1101</fpage><lpage>1108</lpage><pub-id pub-id-type="pmid">26098757</pub-id></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>H</given-names></name><name><surname>Kwon</surname><given-names>SE</given-names></name><name><surname>Severson</surname><given-names>KS</given-names></name><name><surname>O’Connor</surname><given-names>DH</given-names></name></person-group><article-title>Origins of choice-related activity in mouse somatosensory cortex</article-title><source>Nat Neurosci</source><year>2016</year><volume>19</volume><fpage>127</fpage><lpage>134</lpage><pub-id pub-id-type="pmcid">PMC4696889</pub-id><pub-id pub-id-type="pmid">26642088</pub-id><pub-id pub-id-type="doi">10.1038/nn.4183</pub-id></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bale</surname><given-names>MR</given-names></name><name><surname>Bitzidou</surname><given-names>M</given-names></name><name><surname>Giusto</surname><given-names>E</given-names></name><name><surname>Kinghorn</surname><given-names>P</given-names></name><name><surname>Maravall</surname><given-names>M</given-names></name></person-group><article-title>Sequence Learning Induces Selectivity to Multiple Task Parameters in Mouse Somatosensory Cortex</article-title><source>Curr Biol</source><year>2021</year><volume>31</volume><fpage>473</fpage><lpage>485</lpage><elocation-id>e5</elocation-id><pub-id pub-id-type="pmcid">PMC7883307</pub-id><pub-id pub-id-type="pmid">33186553</pub-id><pub-id pub-id-type="doi">10.1016/j.cub.2020.10.059</pub-id></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harrell</surname><given-names>ER</given-names></name><name><surname>Renard</surname><given-names>A</given-names></name><name><surname>Bathellier</surname><given-names>B</given-names></name></person-group><article-title>Fast cortical dynamics encode tactile grating orientation during active touch</article-title><source>Sci Adv</source><year>2021</year><volume>7</volume><elocation-id>eabf7096</elocation-id><pub-id pub-id-type="pmcid">PMC8442870</pub-id><pub-id pub-id-type="pmid">34516895</pub-id><pub-id pub-id-type="doi">10.1126/sciadv.abf7096</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rabinovich</surname><given-names>RJ</given-names></name><name><surname>Kato</surname><given-names>DD</given-names></name><name><surname>Bruno</surname><given-names>RM</given-names></name></person-group><article-title>Learning enhances encoding of time and temporal surprise in mouse primary sensory cortex</article-title><source>Nat Commun</source><year>2022</year><volume>13</volume><elocation-id>5504</elocation-id><pub-id pub-id-type="pmcid">PMC9489862</pub-id><pub-id pub-id-type="pmid">36127340</pub-id><pub-id pub-id-type="doi">10.1038/s41467-022-33141-y</pub-id></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buetfering</surname><given-names>C</given-names></name><etal/></person-group><article-title>Behaviorally relevant decision coding in primary somatosensory cortex neurons</article-title><source>Nat Neurosci</source><year>2022</year><volume>25</volume><fpage>1225</fpage><lpage>1236</lpage><pub-id pub-id-type="pmcid">PMC7613627</pub-id><pub-id pub-id-type="pmid">36042310</pub-id><pub-id pub-id-type="doi">10.1038/s41593-022-01151-0</pub-id></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chéreau</surname><given-names>R</given-names></name><etal/></person-group><article-title>Dynamic perceptual feature selectivity in primary somatosensory cortex upon reversal learning</article-title><source>Nat Commun</source><year>2020</year><volume>11</volume><elocation-id>3245</elocation-id><pub-id pub-id-type="pmcid">PMC7319990</pub-id><pub-id pub-id-type="pmid">32591523</pub-id><pub-id pub-id-type="doi">10.1038/s41467-020-17005-x</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Teich</surname><given-names>AF</given-names></name><name><surname>Qian</surname><given-names>N</given-names></name></person-group><article-title>Learning and Adaptation in a Recurrent Model of V1 Orientation Selectivity</article-title><source>J Neurophysiol</source><year>2003</year><volume>89</volume><fpage>2086</fpage><lpage>2100</lpage><pub-id pub-id-type="pmid">12611961</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peron</surname><given-names>SP</given-names></name><name><surname>Freeman</surname><given-names>J</given-names></name><name><surname>Iyer</surname><given-names>V</given-names></name><name><surname>Guo</surname><given-names>C</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name></person-group><article-title>A Cellular Resolution Map of Barrel Cortex Activity during Tactile Behavior</article-title><source>Neuron</source><year>2015</year><volume>86</volume><fpage>783</fpage><lpage>799</lpage><pub-id pub-id-type="pmid">25913859</pub-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petersen</surname><given-names>RS</given-names></name><name><surname>Panzeri</surname><given-names>S</given-names></name><name><surname>Diamond</surname><given-names>ME</given-names></name></person-group><article-title>Population Coding of Stimulus Location in Rat Somatosensory Cortex</article-title><source>Neuron</source><year>2001</year><volume>32</volume><fpage>503</fpage><lpage>514</lpage><pub-id pub-id-type="pmid">11709160</pub-id></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Panzeri</surname><given-names>S</given-names></name><name><surname>Moroni</surname><given-names>M</given-names></name><name><surname>Safaai</surname><given-names>H</given-names></name><name><surname>Harvey</surname><given-names>CD</given-names></name></person-group><article-title>The structures and functions of correlations in neural population codes</article-title><source>Nat Rev Neurosci</source><year>2022</year><volume>23</volume><fpage>551</fpage><lpage>567</lpage><pub-id pub-id-type="pmid">35732917</pub-id></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Connor</surname><given-names>DH</given-names></name><etal/></person-group><article-title>Vibrissa-Based Object Localization in Head-Fixed Mice</article-title><source>J Neurosci</source><year>2010</year><volume>30</volume><fpage>1947</fpage><lpage>1967</lpage><pub-id pub-id-type="pmcid">PMC6634009</pub-id><pub-id pub-id-type="pmid">20130203</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3762-09.2010</pub-id></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Connor</surname><given-names>DH</given-names></name><name><surname>Peron</surname><given-names>SP</given-names></name><name><surname>Huber</surname><given-names>D</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name></person-group><article-title>Neural Activity in Barrel Cortex Underlying Vibrissa-Based Object Localization in Mice</article-title><source>Neuron</source><year>2010</year><volume>67</volume><fpage>1048</fpage><lpage>1061</lpage><pub-id pub-id-type="pmid">20869600</pub-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wekselblatt</surname><given-names>JB</given-names></name><name><surname>Flister</surname><given-names>ED</given-names></name><name><surname>Piscopo</surname><given-names>DM</given-names></name><name><surname>Niell</surname><given-names>CM</given-names></name></person-group><article-title>Large-scale imaging of cortical dynamics during sensory perception and behavior</article-title><source>J Neurophysiol</source><year>2016</year><volume>115</volume><fpage>2852</fpage><lpage>2866</lpage><pub-id pub-id-type="pmcid">PMC4922607</pub-id><pub-id pub-id-type="pmid">26912600</pub-id><pub-id pub-id-type="doi">10.1152/jn.01056.2015</pub-id></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chong</surname><given-names>EZ</given-names></name><name><surname>Panniello</surname><given-names>M</given-names></name><name><surname>Barreiros</surname><given-names>I</given-names></name><name><surname>Kohl</surname><given-names>MM</given-names></name><name><surname>Booth</surname><given-names>MJ</given-names></name></person-group><article-title>Quasi-simultaneous multiplane calcium imaging of neuronal circuits</article-title><source>Biomed Opt Express</source><year>2019</year><volume>10</volume><fpage>267</fpage><pub-id pub-id-type="pmcid">PMC6363184</pub-id><pub-id pub-id-type="pmid">30775099</pub-id><pub-id pub-id-type="doi">10.1364/BOE.10.000267</pub-id></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hromádka</surname><given-names>T</given-names></name><name><surname>DeWeese</surname><given-names>MR</given-names></name><name><surname>Zador</surname><given-names>AM</given-names></name></person-group><article-title>Sparse Representation of Sounds in the Unanesthetized Auditory Cortex</article-title><source>Plos Biol</source><year>2008</year><volume>6</volume><fpage>e16</fpage><pub-id pub-id-type="pmcid">PMC2214813</pub-id><pub-id pub-id-type="pmid">18232737</pub-id><pub-id pub-id-type="doi">10.1371/journal.pbio.0060016</pub-id></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jadhav</surname><given-names>SP</given-names></name><name><surname>Wolfe</surname><given-names>J</given-names></name><name><surname>Feldman</surname><given-names>DE</given-names></name></person-group><article-title>Sparse temporal coding of elementary tactile features during active whisker sensation</article-title><source>Nat Neurosci</source><year>2009</year><volume>12</volume><fpage>792</fpage><lpage>800</lpage><pub-id pub-id-type="pmid">19430473</pub-id></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barth</surname><given-names>AL</given-names></name><name><surname>Poulet</surname><given-names>JFA</given-names></name></person-group><article-title>Experimental evidence for sparse firing in the neocortex</article-title><source>Trends Neurosci</source><year>2012</year><volume>35</volume><fpage>345</fpage><lpage>355</lpage><pub-id pub-id-type="pmid">22579264</pub-id></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Panzeri</surname><given-names>S</given-names></name><name><surname>Senatore</surname><given-names>R</given-names></name><name><surname>Montemurro</surname><given-names>MA</given-names></name><name><surname>Petersen</surname><given-names>RS</given-names></name></person-group><article-title>Correcting for the Sampling Bias Problem in Spike Train Information Measures</article-title><source>J Neurophysiol</source><year>2007</year><volume>98</volume><fpage>1064</fpage><lpage>1072</lpage><pub-id pub-id-type="pmid">17615128</pub-id></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quiroga</surname><given-names>RQ</given-names></name><name><surname>Panzeri</surname><given-names>S</given-names></name></person-group><article-title>Extracting information from neuronal populations: information theory and decoding approaches</article-title><source>Nat Rev Neurosci</source><year>2009</year><volume>10</volume><fpage>173</fpage><lpage>185</lpage><pub-id pub-id-type="pmid">19229240</pub-id></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Safaai</surname><given-names>H</given-names></name><name><surname>von Heimendahl</surname><given-names>M</given-names></name><name><surname>Sorando</surname><given-names>JM</given-names></name><name><surname>Diamond</surname><given-names>ME</given-names></name><name><surname>Maravall</surname><given-names>M</given-names></name></person-group><article-title>Coordinated Population Activity Underlying Texture Discrimination in Rat Barrel Cortex</article-title><source>J Neurosci</source><year>2013</year><volume>33</volume><fpage>5843</fpage><lpage>5855</lpage><pub-id pub-id-type="pmcid">PMC6705064</pub-id><pub-id pub-id-type="pmid">23536096</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3486-12.2013</pub-id></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cooke</surname><given-names>SF</given-names></name><name><surname>Bear</surname><given-names>MF</given-names></name></person-group><article-title>Visual Experience Induces Long-Term Potentiation in the Primary Visual Cortex</article-title><source>J Neurosci</source><year>2010</year><volume>30</volume><fpage>16304</fpage><lpage>16313</lpage><pub-id pub-id-type="pmcid">PMC3078625</pub-id><pub-id pub-id-type="pmid">21123576</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4333-10.2010</pub-id></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frenkel</surname><given-names>MY</given-names></name><etal/></person-group><article-title>Instructive Effect of Visual Experience in Mouse Visual Cortex</article-title><source>Neuron</source><year>2006</year><volume>51</volume><fpage>339</fpage><lpage>349</lpage><pub-id pub-id-type="pmid">16880128</pub-id></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Polley</surname><given-names>DB</given-names></name><name><surname>Steinberg</surname><given-names>EE</given-names></name><name><surname>Merzenich</surname><given-names>MM</given-names></name></person-group><article-title>Perceptual Learning Directs Auditory Cortical Map Reorganization through Top-Down Influences</article-title><source>J Neurosci</source><year>2006</year><volume>26</volume><fpage>4970</fpage><lpage>4982</lpage><pub-id pub-id-type="pmcid">PMC6674159</pub-id><pub-id pub-id-type="pmid">16672673</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3771-05.2006</pub-id></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Law</surname><given-names>C-T</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><article-title>Neural correlates of perceptual learning in a sensory-motor, but not a sensory, cortical area</article-title><source>Nat Neurosci</source><year>2008</year><volume>11</volume><fpage>505</fpage><lpage>513</lpage><pub-id pub-id-type="pmcid">PMC2424192</pub-id><pub-id pub-id-type="pmid">18327253</pub-id><pub-id pub-id-type="doi">10.1038/nn2070</pub-id></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Pica</surname><given-names>G</given-names></name><etal/></person-group><chapter-title>Quantifying how much sensory information in a neural code is relevant for behavior</chapter-title><source>Advances in Neural Information Processing Systems</source><publisher-name>Curran Associates, Inc</publisher-name><year>2017</year><volume>30</volume></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Panzeri</surname><given-names>S</given-names></name><name><surname>Piasini</surname><given-names>E</given-names></name><name><surname>Fellin</surname><given-names>T</given-names></name></person-group><article-title>Cracking the Neural Code for Sensory Perception by Combining Statistics, Intervention, and Behavior</article-title><source>Neuron</source><year>2017</year><volume>93</volume><fpage>491</fpage><lpage>507</lpage><pub-id pub-id-type="pmcid">PMC5308795</pub-id><pub-id pub-id-type="pmid">28182905</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2016.12.036</pub-id></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zuo</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Complementary Contributions of Spike Timing and Spike Rate to Perceptual Decisions in Rat S1 and S2 Cortex</article-title><source>Curr Biol</source><year>2015</year><volume>25</volume><fpage>357</fpage><lpage>363</lpage><pub-id pub-id-type="pmid">25619766</pub-id></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Valente</surname><given-names>M</given-names></name><etal/></person-group><article-title>Correlations enhance the behavioral readout of neural population activity in association cortex</article-title><source>Nat Neurosci</source><year>2021</year><volume>24</volume><fpage>975</fpage><lpage>986</lpage><pub-id pub-id-type="pmcid">PMC8559600</pub-id><pub-id pub-id-type="pmid">33986549</pub-id><pub-id pub-id-type="doi">10.1038/s41593-021-00845-1</pub-id></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saleem</surname><given-names>AB</given-names></name><name><surname>Diamanti</surname><given-names>EM</given-names></name><name><surname>Fournier</surname><given-names>J</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name></person-group><article-title>Coherent encoding of subjective spatial position in visual cortex and hippocampus</article-title><source>Nature</source><year>2018</year><volume>562</volume><fpage>124</fpage><lpage>127</lpage><pub-id pub-id-type="pmcid">PMC6309439</pub-id><pub-id pub-id-type="pmid">30202092</pub-id><pub-id pub-id-type="doi">10.1038/s41586-018-0516-1</pub-id></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>JL</given-names></name><name><surname>Carta</surname><given-names>S</given-names></name><name><surname>Soldado-Magraner</surname><given-names>J</given-names></name><name><surname>Schneider</surname><given-names>BL</given-names></name><name><surname>Helmchen</surname><given-names>F</given-names></name></person-group><article-title>Behaviour-dependent recruitment of long-range projection neurons in somatosensory cortex</article-title><source>Nature</source><year>2013</year><volume>499</volume><fpage>336</fpage><lpage>340</lpage><pub-id pub-id-type="pmid">23792559</pub-id></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poort</surname><given-names>J</given-names></name><etal/></person-group><article-title>Learning Enhances Sensory and Multiple Non-sensory Representations in Primary Visual Cortex</article-title><source>Neuron</source><year>2015</year><volume>86</volume><fpage>1478</fpage><lpage>1490</lpage><pub-id pub-id-type="pmcid">PMC4503798</pub-id><pub-id pub-id-type="pmid">26051421</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2015.05.037</pub-id></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Francis</surname><given-names>NA</given-names></name><etal/></person-group><article-title>Small Networks Encode Decision-Making in Primary Auditory Cortex</article-title><source>Neuron</source><year>2018</year><volume>97</volume><fpage>885</fpage><lpage>897</lpage><elocation-id>e6</elocation-id><pub-id pub-id-type="pmcid">PMC6289180</pub-id><pub-id pub-id-type="pmid">29398362</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2018.01.019</pub-id></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stringer</surname><given-names>C</given-names></name><etal/></person-group><article-title>Spontaneous behaviors drive multidimensional, brainwide activity</article-title><source>Science</source><year>2019</year><volume>364</volume><elocation-id>eaav7893</elocation-id><pub-id pub-id-type="pmcid">PMC6525101</pub-id><pub-id pub-id-type="pmid">31000656</pub-id><pub-id pub-id-type="doi">10.1126/science.aav7893</pub-id></element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Francis</surname><given-names>NA</given-names></name><etal/></person-group><article-title>Sequential transmission of task-relevant information in cortical neuronal networks</article-title><source>Cell Reports</source><year>2022</year><volume>39</volume><elocation-id>110878</elocation-id><pub-id pub-id-type="pmcid">PMC9387204</pub-id><pub-id pub-id-type="pmid">35649366</pub-id><pub-id pub-id-type="doi">10.1016/j.celrep.2022.110878</pub-id></element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tseng</surname><given-names>S-Y</given-names></name><name><surname>Chettih</surname><given-names>SN</given-names></name><name><surname>Arlt</surname><given-names>C</given-names></name><name><surname>Barroso-Luque</surname><given-names>R</given-names></name><name><surname>Harvey</surname><given-names>CD</given-names></name></person-group><article-title>Shared and specialized coding across posterior cortical areas for dynamic navigation decisions</article-title><source>Neuron</source><year>2022</year><volume>110</volume><fpage>2484</fpage><lpage>2502</lpage><elocation-id>e16</elocation-id><pub-id pub-id-type="pmcid">PMC9357051</pub-id><pub-id pub-id-type="pmid">35679861</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2022.05.012</pub-id></element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keller</surname><given-names>GB</given-names></name><name><surname>Bonhoeffer</surname><given-names>T</given-names></name><name><surname>Hubener</surname><given-names>M</given-names></name></person-group><article-title>Sensorimotor Mismatch Signals in Primary Visual Cortex of the Behaving Mouse</article-title><source>Neuron</source><year>2012</year><volume>74</volume><fpage>809</fpage><lpage>815</lpage><pub-id pub-id-type="pmid">22681686</pub-id></element-citation></ref><ref id="R40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McGuire</surname><given-names>LM</given-names></name><etal/></person-group><article-title>Short Time-Scale Sensory Coding in S1 during Discrimination of Whisker Vibrotactile Sequences</article-title><source>Plos Biol</source><year>2016</year><volume>14</volume><elocation-id>e1002549</elocation-id><pub-id pub-id-type="pmcid">PMC5004814</pub-id><pub-id pub-id-type="pmid">27574970</pub-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1002549</pub-id></element-citation></ref><ref id="R41"><label>41</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pala</surname><given-names>A</given-names></name><name><surname>Stanley</surname><given-names>GB</given-names></name></person-group><article-title>Ipsilateral Stimulus Encoding in Primary and Secondary Somatosensory Cortex of Awake Mice</article-title><source>J Neurosci</source><year>2022</year><volume>42</volume><fpage>2701</fpage><lpage>2715</lpage><pub-id pub-id-type="pmcid">PMC8973421</pub-id><pub-id pub-id-type="pmid">35135855</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1417-21.2022</pub-id></element-citation></ref><ref id="R42"><label>42</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schoups</surname><given-names>A</given-names></name><name><surname>Vogels</surname><given-names>R</given-names></name><name><surname>Qian</surname><given-names>N</given-names></name><name><surname>Orban</surname><given-names>G</given-names></name></person-group><article-title>Practising orientation identification improves orientation coding in V1 neurons</article-title><source>Nature</source><year>2001</year><volume>412</volume><fpage>549</fpage><lpage>553</lpage><pub-id pub-id-type="pmid">11484056</pub-id></element-citation></ref><ref id="R43"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kato</surname><given-names>HK</given-names></name><name><surname>Gillet</surname><given-names>SN</given-names></name><name><surname>Isaacson</surname><given-names>JS</given-names></name></person-group><article-title>Flexible Sensory Representations in Auditory Cortex Driven by Behavioral Relevance</article-title><source>Neuron</source><year>2015</year><volume>88</volume><fpage>1027</fpage><lpage>1039</lpage><pub-id pub-id-type="pmcid">PMC4670799</pub-id><pub-id pub-id-type="pmid">26586181</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2015.10.024</pub-id></element-citation></ref><ref id="R44"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Banerjee</surname><given-names>A</given-names></name><etal/></person-group><article-title>Value-guided remapping of sensory cortex by lateral orbitofrontal cortex</article-title><source>Nature</source><year>2020</year><volume>585</volume><fpage>245</fpage><lpage>250</lpage><pub-id pub-id-type="pmid">32884146</pub-id></element-citation></ref><ref id="R45"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feldman</surname><given-names>DE</given-names></name></person-group><article-title>Timing-Based LTP and LTD at Vertical Inputs to Layer II/III Pyramidal Cells in Rat Barrel Cortex</article-title><source>Neuron</source><year>2000</year><volume>27</volume><fpage>45</fpage><lpage>56</lpage><pub-id pub-id-type="pmid">10939330</pub-id></element-citation></ref><ref id="R46"><label>46</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bender</surname><given-names>VA</given-names></name><name><surname>Bender</surname><given-names>KJ</given-names></name><name><surname>Brasier</surname><given-names>DJ</given-names></name><name><surname>Feldman</surname><given-names>DE</given-names></name></person-group><article-title>Two Coincidence Detectors for Spike Timing-Dependent Plasticity in Somatosensory Cortex</article-title><source>J Neurosci</source><year>2006</year><volume>26</volume><fpage>4166</fpage><lpage>4177</lpage><pub-id pub-id-type="pmcid">PMC3071735</pub-id><pub-id pub-id-type="pmid">16624937</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0176-06.2006</pub-id></element-citation></ref><ref id="R47"><label>47</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Voelcker</surname><given-names>B</given-names></name><name><surname>Pancholi</surname><given-names>R</given-names></name><name><surname>Peron</surname><given-names>S</given-names></name></person-group><article-title>Transformation of primary sensory cortical representations from layer 4 to layer 2</article-title><source>Nat Commun</source><year>2022</year><volume>13</volume><elocation-id>5484</elocation-id><pub-id pub-id-type="pmcid">PMC9485231</pub-id><pub-id pub-id-type="pmid">36123376</pub-id><pub-id pub-id-type="doi">10.1038/s41467-022-33249-1</pub-id></element-citation></ref><ref id="R48"><label>48</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Margolis</surname><given-names>DJ</given-names></name><etal/></person-group><article-title>Reorganization of cortical population activity imaged throughout long-term sensory deprivation</article-title><source>Nat Neurosci</source><year>2012</year><volume>15</volume><fpage>1539</fpage><lpage>1546</lpage><pub-id pub-id-type="pmid">23086335</pub-id></element-citation></ref><ref id="R49"><label>49</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carrillo-Reid</surname><given-names>L</given-names></name><name><surname>Han</surname><given-names>S</given-names></name><name><surname>Yang</surname><given-names>W</given-names></name><name><surname>Akrouh</surname><given-names>A</given-names></name><name><surname>Yuste</surname><given-names>R</given-names></name></person-group><article-title>Controlling Visually Guided Behavior by Holographic Recalling of Cortical Ensembles</article-title><source>Cell</source><year>2019</year><volume>178</volume><fpage>447</fpage><lpage>457</lpage><elocation-id>e5</elocation-id><pub-id pub-id-type="pmcid">PMC6747687</pub-id><pub-id pub-id-type="pmid">31257030</pub-id><pub-id pub-id-type="doi">10.1016/j.cell.2019.05.045</pub-id></element-citation></ref><ref id="R50"><label>50</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dalgleish</surname><given-names>HW</given-names></name><etal/></person-group><article-title>How many neurons are sufficient for perception of cortical activity?</article-title><source>Elife</source><year>2020</year><volume>9</volume><elocation-id>e58889</elocation-id><pub-id pub-id-type="pmcid">PMC7695456</pub-id><pub-id pub-id-type="pmid">33103656</pub-id><pub-id pub-id-type="doi">10.7554/eLife.58889</pub-id></element-citation></ref><ref id="R51"><label>51</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gill</surname><given-names>JV</given-names></name><etal/></person-group><article-title>Precise Holographic Manipulation of Olfactory Circuits Reveals Coding Features Determining Perceptual Detection</article-title><source>Neuron</source><year>2020</year><volume>108</volume><fpage>382</fpage><lpage>393</lpage><elocation-id>e5</elocation-id><pub-id pub-id-type="pmcid">PMC8289117</pub-id><pub-id pub-id-type="pmid">32841590</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2020.07.034</pub-id></element-citation></ref><ref id="R52"><label>52</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heffner</surname><given-names>HE</given-names></name><name><surname>Heffner</surname><given-names>RS</given-names></name></person-group><article-title>Hearing ranges of laboratory animals</article-title><source>J Am Assoc Laboratory Animal Sci Jaalas</source><year>2007</year><volume>46</volume><fpage>20</fpage><lpage>2</lpage><pub-id pub-id-type="pmid">17203911</pub-id></element-citation></ref><ref id="R53"><label>53</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Linden</surname><given-names>JF</given-names></name><name><surname>Liu</surname><given-names>RC</given-names></name><name><surname>Sahani</surname><given-names>M</given-names></name><name><surname>Schreiner</surname><given-names>CE</given-names></name><name><surname>Merzenich</surname><given-names>MM</given-names></name></person-group><article-title>Spectrotemporal Structure of Receptive Fields in Areas AI and AAF of Mouse Auditory Cortex</article-title><source>J Neurophysiol</source><year>2003</year><volume>90</volume><fpage>2660</fpage><lpage>2675</lpage><pub-id pub-id-type="pmid">12815016</pub-id></element-citation></ref><ref id="R54"><label>54</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akam</surname><given-names>T</given-names></name><etal/></person-group><article-title>Open-source, Python-based, hardware and software for controlling behavioural neuroscience experiments</article-title><source>Elife</source><year>2022</year><volume>11</volume><elocation-id>e67846</elocation-id><pub-id pub-id-type="pmcid">PMC8769647</pub-id><pub-id pub-id-type="pmid">35043782</pub-id><pub-id pub-id-type="doi">10.7554/eLife.67846</pub-id></element-citation></ref><ref id="R55"><label>55</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guo</surname><given-names>ZV</given-names></name><etal/></person-group><article-title>Flow of Cortical Activity Underlying a Tactile Decision in Mice</article-title><source>Neuron</source><year>2014</year><volume>81</volume><fpage>179</fpage><lpage>194</lpage><pub-id pub-id-type="pmcid">PMC3984938</pub-id><pub-id pub-id-type="pmid">24361077</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2013.10.020</pub-id></element-citation></ref><ref id="R56"><label>56</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Juavinett</surname><given-names>AL</given-names></name><name><surname>Nauhaus</surname><given-names>I</given-names></name><name><surname>Garrett</surname><given-names>ME</given-names></name><name><surname>Zhuang</surname><given-names>J</given-names></name><name><surname>Callaway</surname><given-names>EM</given-names></name></person-group><article-title>Automated identification of mouse visual areas with intrinsic signal imaging</article-title><source>Nat Protoc</source><year>2017</year><volume>12</volume><fpage>32</fpage><lpage>43</lpage><pub-id pub-id-type="pmcid">PMC5381647</pub-id><pub-id pub-id-type="pmid">27906169</pub-id><pub-id pub-id-type="doi">10.1038/nprot.2016.158</pub-id></element-citation></ref><ref id="R57"><label>57</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pachitariu</surname><given-names>M</given-names></name><etal/></person-group><article-title>Suite2p: beyond 10,000 neurons with standard two-photon microscopy</article-title><source>Biorxiv</source><year>2017</year><elocation-id>061507</elocation-id><pub-id pub-id-type="doi">10.1101/061507</pub-id></element-citation></ref><ref id="R58"><label>58</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>T-W</given-names></name><etal/></person-group><article-title>Ultra-sensitive fluorescent proteins for imaging neuronal activity</article-title><source>Nature</source><year>2013</year><volume>499</volume><fpage>295</fpage><lpage>300</lpage><pub-id pub-id-type="pmcid">PMC3777791</pub-id><pub-id pub-id-type="pmid">23868258</pub-id><pub-id pub-id-type="doi">10.1038/nature12354</pub-id></element-citation></ref><ref id="R59"><label>59</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Panzeri</surname><given-names>S</given-names></name><name><surname>Treves</surname><given-names>A</given-names></name></person-group><article-title>Analytical estimates of limited sampling biases in different information measures</article-title><source>Netw Comput Neural Syst</source><year>2018</year><volume>7</volume><fpage>87</fpage><lpage>107</lpage><pub-id pub-id-type="pmid">29480146</pub-id></element-citation></ref><ref id="R60"><label>60</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Optican</surname><given-names>LM</given-names></name><name><surname>Richmond</surname><given-names>BJ</given-names></name></person-group><article-title>Temporal encoding of two-dimensional patterns by single units in primate inferior temporal cortex. III. Information theoretic analysis</article-title><source>J Neurophysiol</source><year>1987</year><volume>57</volume><fpage>162</fpage><lpage>178</lpage><pub-id pub-id-type="pmid">3559670</pub-id></element-citation></ref><ref id="R61"><label>61</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ince</surname><given-names>RAA</given-names></name><name><surname>Mazzoni</surname><given-names>A</given-names></name><name><surname>Bartels</surname><given-names>A</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name><name><surname>Panzeri</surname><given-names>S</given-names></name></person-group><article-title>A novel test to determine the significance of neural selectivity to single and multiple potentially correlated stimulus features</article-title><source>J Neurosci Meth</source><year>2012</year><volume>210</volume><fpage>49</fpage><lpage>65</lpage><pub-id pub-id-type="pmid">22142889</pub-id></element-citation></ref><ref id="R62"><label>62</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bertschinger</surname><given-names>N</given-names></name><name><surname>Rauh</surname><given-names>J</given-names></name><name><surname>Olbrich</surname><given-names>E</given-names></name><name><surname>Jost</surname><given-names>J</given-names></name><name><surname>Ay</surname><given-names>N</given-names></name></person-group><article-title>Quantifying Unique Information</article-title><source>Entropy</source><year>2014</year><volume>16</volume><fpage>2161</fpage><lpage>2183</lpage></element-citation></ref><ref id="R63"><label>63</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Strong</surname><given-names>SP</given-names></name><name><surname>Koberle</surname><given-names>R</given-names></name><name><surname>van Steveninck</surname><given-names>RR de R</given-names></name><name><surname>Bialek</surname><given-names>W</given-names></name></person-group><article-title>Entropy and Information in Neural Spike Trains</article-title><source>Phys Rev Lett</source><year>1998</year><volume>80</volume><fpage>197</fpage><lpage>200</lpage></element-citation></ref><ref id="R64"><label>64</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Magri</surname><given-names>C</given-names></name><name><surname>Whittingstall</surname><given-names>K</given-names></name><name><surname>Singh</surname><given-names>V</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name><name><surname>Panzeri</surname><given-names>S</given-names></name></person-group><article-title>A toolbox for the fast information analysis of multiple-site LFP, EEG and spike train recordings</article-title><source>Bmc Neurosci</source><year>2009</year><volume>10</volume><elocation-id>81</elocation-id><pub-id pub-id-type="pmcid">PMC2723115</pub-id><pub-id pub-id-type="pmid">19607698</pub-id><pub-id pub-id-type="doi">10.1186/1471-2202-10-81</pub-id></element-citation></ref><ref id="R65"><label>65</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Makkeh</surname><given-names>A</given-names></name><name><surname>Theis</surname><given-names>DO</given-names></name><name><surname>Vicente</surname><given-names>R</given-names></name></person-group><article-title>BROJA-2PID: A Robust Estimator for Bivariate Partial Information Decomposition</article-title><source>Entropy</source><year>2018</year><volume>20</volume><elocation-id>271</elocation-id><pub-id pub-id-type="pmcid">PMC7512785</pub-id><pub-id pub-id-type="pmid">33265362</pub-id><pub-id pub-id-type="doi">10.3390/e20040271</pub-id></element-citation></ref><ref id="R66"><label>66</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>CR</given-names></name><etal/></person-group><article-title>Array programming with NumPy</article-title><source>Nature</source><year>2020</year><volume>585</volume><fpage>357</fpage><lpage>362</lpage><pub-id pub-id-type="pmcid">PMC7759461</pub-id><pub-id pub-id-type="pmid">32939066</pub-id><pub-id pub-id-type="doi">10.1038/s41586-020-2649-2</pub-id></element-citation></ref><ref id="R67"><label>67</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Virtanen</surname><given-names>P</given-names></name><etal/></person-group><article-title>SciPy 1.0: fundamental algorithms for scientific computing in Python</article-title><source>Nat Methods</source><year>2020</year><volume>17</volume><fpage>261</fpage><lpage>272</lpage><pub-id pub-id-type="pmcid">PMC7056644</pub-id><pub-id pub-id-type="pmid">32015543</pub-id><pub-id pub-id-type="doi">10.1038/s41592-019-0686-2</pub-id></element-citation></ref><ref id="R68"><label>68</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>McKinney</surname><given-names>W</given-names></name></person-group><source>Data Structures for Statistical Computing in Python</source><conf-name>Proceedings of the 9th Python in Science Conference SCIPY 2010</conf-name><year>2010</year><volume>445</volume><fpage>51</fpage><lpage>56</lpage></element-citation></ref><ref id="R69"><label>69</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hunter</surname><given-names>JD</given-names></name></person-group><article-title>Matplotlib: A 2D Graphics Environment</article-title><source>Comput Sci Eng</source><year>2007</year><volume>9</volume><fpage>90</fpage><lpage>95</lpage></element-citation></ref><ref id="R70"><label>70</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F</given-names></name><etal/></person-group><article-title>Scikit-learn: Machine Learning in Python</article-title><source>Journal of Machine Learning Research</source><year>2011</year><volume>12</volume></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>Learning of a tactile object localization task with concomitant vS1 calcium imaging</title><p><bold>a</bold>. Experimental set up and protocol for imaging and sensory training. Mice were head-fixed, but free to run on a treadmill. On each trial, a metallic pole was moved toward the left whiskers to one of two positions (anterior: Go, and posterior: No-go). A spout was placed in front of the mice and used to deliver water when a lick was detected during a Go trial. Mice underwent water regulation before starting sensory training. Calcium transients in the right vS1 were recorded from the start of sensory training until the mouse achieved &gt;70% correct responses for three consecutive days. Sensory learning was divided into 3 stages, based on their correct performance (stage 1, black: ≤55%; stage 2, dark green: &gt;55%&lt; to ≤75%; stage 3, light green: &gt;75%). <bold>b. &amp; c</bold>. Lick timings during each trial of an early training session (b., 49% correct), and a late training session (c., 77% correct). Trials are sorted according to trial outcomes. Trials where the mouse licked only during tactile stimulation were excluded from the plot and from the analysis. The gray shaded area indicates the time during which the pole was in contact with the whiskers. The blue shaded area indicates the 4-seconds-long licking window. Correct responses included licking on Go trials (Hit), and withholding licks on No-go trials (correct rejection, CR). Incorrect responses included withholding licks on Go trials (Miss), and licking on No-go trials (false alarm, FA). <bold>d</bold>. First lick latencies during Hit trials and FA trials for early training sessions (performance &lt;55% correct; black data points, n=286 licks for Hits, 303 licks for FAs, across 8 mice) and late training sessions (performance &gt;75% correct; green data points, n=949 licks for Hits, 150 licks for FAs, across 8 mice). Latency is calculated from stimulus offset. White dots indicate the median of the distribution, horizontal black bars indicate the mean value, vertical black bars indicate the 25th and 75th percentiles. <bold>e</bold>. Fraction of correct responses ((Hits + CR) / total trials) in all 8 mice, across up to 17 days of training. <bold>f</bold>. A representative IOSI image showing the location of the barrels corresponding to the whiskers stimulated during the procedure (yellow shading) in one mouse. A projection of the two-photon imaging FOV acquired throughout learning is overlaid on the IOSI image. Scale bar indicates 200 μm. g. Mean ΔF/F0 across Go trials (red) and No-go trials (blue) for one example neuron at each of the four cortical depths imaged. In this example, the same neuron was imaged during stages 1 and 3 of learning.</p></caption><graphic xlink:href="EMS158183-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Stimulus and choice information increase over learning</title><p><bold>a</bold>. (Left) Frame-by-frame mean ΔF/F<sub>0</sub> across Go trials (top) and No-go trials (bottom) for all neurons (ROI #) in one example FOV, -190 μm below the cortical surface. Imaging was performed during learning stage 1. White lines indicate stimulus onset and offset. (Right) ΔF/F<sub>0</sub> activity from the same FOV, but when the mouse was in learning stage 3. <bold>b</bold>. Left: Frame-by-frame mutual information between stimulus and response (MI-RS) in the same neurons represented in a., during stage 1. Right: MI-RS from the same FOV, when the mouse was in stage 3. Bottom left and right show the average MI-RS across all neurons in the field. The gray shaded area indicates stimulus duration. The blue shaded area indicates the licking window. <bold>c</bold>. Mean frame-by-frame MI-RS across all neurons (n=8 mice) at each cortical depth and for each learning stage. MI-RS was first averaged framewise across all neurons in the same FOV, and then averaged across all FOVs imaged at the same cortical depth and during the same learning stage (stage 1: black, stage 2: dark green, stage 3: light green). <bold>d</bold>. Fraction of neurons showing significant MI-RS at each cortical depth and at each learning stage. Learning stage is indicated by the color inside each concentric circle. Full circles correspond to 100% of imaged neurons. The gray shaded area in the circles indicates the fraction of neurons with non-significant MI-RS (p&gt;=0.05). The remaining portion indicates significant neurons. <bold>e</bold>. ΔF/F<sub>0</sub> activity for the same neurons as shown in a. Here, responses were separated into Lick (top) <italic>vs</italic>. No-lick trials (bottom). <bold>f</bold>. Same as in b, but for mutual information between response and mouse choice (<italic>i</italic>.<italic>e</italic>., Lick <italic>vs</italic>. No-lick, MI-RC). <bold>g</bold>. Same as in c. and d., but for MI-RC. <bold>i</bold>. Fraction of neurons carrying both significant MI-RS and significant MI-RC, calculated over the total number of neurons carrying significant MI-RS.</p></caption><graphic xlink:href="EMS158183-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Population codes contribute more strongly to choice than stimulus information over learning</title><p><bold>a</bold>. decMI-RS (mutual information calculated on stimulus decoding confusion matrices) plotted for individual neurons, against mouse task performance (plotted with some jitter in x). The learning stages are delineated by color and vertical black dashed lines. Only discriminative neurons (decMI-RS p&lt;0.05, compared to the null distribution) are plotted in the learning stage color (stage 1: black, stage 2: dark green, stage 3: light green), with non-discriminative neurons plotted in gray (decMI-RS p&gt;=0.05). Colored shading indicates values above the 95th percentile (indicated by bold line). <bold>b</bold>. Same as a., but for decMI-RC (MI calculated on behavioral choice decoding confusion matrices). <bold>c</bold>. Mean across FOVs of population decMI-RS as neurons are added to the pool fed to the decoder, in order of lowest to highest individual decMI-RS. The full pool includes either all neurons (left) or only non-discriminative neurons (right) (stage 1: black, stage 2: dark green, stage 3: light green). Asterisks indicate a significant difference between stage 1 and either stage 2 (dark green) or stage 3 (light green) (t-test p&lt;0.05 corrected, as elsewhere, for multiple comparisons). The horizontal dashed line marks zero decMI-RS. <bold>d</bold>. Same as c., but for dec MI-RC. <bold>e</bold>. Discriminative neuron decMI-RS plotted against the gain in decMI-RS with respect to individual decMI-RS, when decoders also received non-discriminative neuron responses as input. Contour lines qualitatively show data density levels. Stages 1, 2 and 3 are plotted left to right. <bold>f</bold>. Histograms of decMI-RS gain (y axis data from e.), with stages 1, 2 and 3 plotted top to bottom. The black lines mark 0 gain, whereas median gain is indicated by a dashed line, and shaded areas show values below the 5<sup>th</sup> or above the 95<sup>th</sup> percentile of the distribution. <bold>g</bold>. Data from f., represented as cumulative sums. The vertical dashed line marks zero gain, whereas the horizontal dashed line marks the median of each distribution. As shown by the legend in j., data for each learning stage is plotted in the stage’s color (listed in a.). <bold>h-j</bold>. Same as e-g., but for decMI-RC (choice).</p></caption><graphic xlink:href="EMS158183-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Contribution of stimulus information to behavioral choice</title><p><bold>a</bold>. Schematic representation of the information theoretic framework showing the 2 stages of information processing. Stimulus encoding represents the mapping of the tactile stimuli onto the responses of neurons in L2-3 of vS1. Information readout is represented by the mapping of neuronal activity onto the mouse choice to lick or withhold licking in the presence of the tactile stimuli. Neurons, represented as circles, carry only MI-RS (pink) only MI-RC (blue), neither (white) or both. The latter neurons are represented as half blue, half pink, if they carry both MI-RS and MI-RC, but not intersection information (II). However, they are represented as purple if they carry II, with thick arrows coming in from the stimulus and going out to the choice, as these neurons carry stimulus information that directly informs mouse choice. <bold>b</bold>. Mean frame-by-frame II across all neurons (8 mice) at each cortical depth and for each learning stage. Gray shading indicates stimulus duration. Blue shading indicates the duration of the licking window. II was first averaged framewise across all neurons in the same FOV, and then averaged across all FOVs imaged at the same cortical depth and during the same learning stage. Learning stages are color coded (stage 1: black, stage 2: dark green, stage 3: light green). <bold>c</bold>. Fraction of neurons carrying significant II at each cortical depth and at each learning stage. Learning stage is indicated by the color inside each concentric circle. Full circles correspond to 100% of imaged neurons. The gray area in the circles indicates the fraction of neurons with non-significant II (p&gt;=0.05). The remaining portion indicates neurons with significant II. <bold>d</bold>. Frame-by-frame II/MIRS for all the neurons that showed significant II, at each cortical depth and during each learning stage. Color code is the same as in b and c. <bold>e</bold>. Mean II/MIRS across frames for all neurons with significant II for each learning stage and cortical depth. Empty dots are outlier neurons. Horizontal lines indicate the median, and error bars indicate the lower and upper quartiles.</p></caption><graphic xlink:href="EMS158183-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>Choice information decreases before stimulus information when stimulus-reward association is altered</title><p><bold>a</bold>. Experimental protocol. After reaching behavioral threshold (performance over 70% correct trials for three consecutive days) vS1 activity was imaged while 3 mice were tested on a “switch day”. On that day, the Go and No-go contingencies were switched. <bold>b</bold>. Behavioral performance of the three individual mice used for the switch sessions (mouse 1: black, mouse 2: dark gray, mouse 3: light gray), separately for each of the 3 blocks, during stage 1 (left), stage 3 (center) and switch (right) sessions. <bold>c</bold>. MI-RS for all neurons in one example FOV, during a switch session. MI-RS is shown frame-by-frame, for each putative neuron (top), and as the mean across neurons (bottom). Above the plots, the behavioral performance of the mouse is reported as the % of correct responses, for each of the three imaging blocks of the switch session. White lines in the top row indicate stimulus onset and offset. The gray and blue shaded areas in the bottom row indicate stimulus duration and licking window duration, respectively. <bold>d</bold>. Same as in c, but for MI-RC. <bold>e-g</bold>. Top: for each of the 3 blocks, the MI-RS, MI-RC and II computed during the switch session were subtracted respectively from the MI-RS, MI-RC and II obtained in the same FOV during learning stage 1. Data show mean across FOVs in three mice. Bottom: same, but in this case MI-RS, MI-RC and II computed during the switch session were subtracted from the values obtained in the same FOV during stage 3.</p></caption><graphic xlink:href="EMS158183-f005"/></fig><fig id="F6" position="float"><label>Figure 6</label><caption><title>Sensory information persists in vS1 after learning</title><p><bold>a</bold>. Schematic representation of the experimental protocol (n=7 mice). ΔF/F<sub>0</sub> was measured for putative neurons in vS1 while mice were presented with a metallic pole in six different positions along their anterior-posterior axis, both before (pre-training session, gray) and after training on the pole localization task (post-training, orange). <bold>b</bold>. Mean frame-by-frame MI-RS across all neurons imaged during the pre-training (gray) and post-training (orange) sessions, for each frame and for each cortical depth (-130 μm: 659 (pre) and 527 (post) neurons, -190 μm: 879 (pre) and 765 (post) neurons, -260 μm: 554 (pre) and 557 (post) neurons, -320 μm: 747 (pre) and 567 (post) neurons). MI-RS was calculated on responses to stimulus positions 3 and 6 only (<italic>i</italic>.<italic>e</italic>., the pole positions used for sensory training). It was first averaged framewise across all neurons in the same FOV, and then across all FOVs imaged at the same cortical depth and during the same session. The gray shaded areas indicate stimulus duration. <bold>c</bold>. Fraction of neurons carrying significant MI-RS at each cortical depth (p&lt;0.05). Full circles reflect 100% of imaged neurons. The light-gray area in each circle indicates the fraction of neurons with non-significant MI-RS. The dark-gray and orange portions indicate the fraction of neurons with significant MI-RS during the pre-training and post-training sessions, respectively. <bold>d</bold>. Distribution of the maximum MI-RS value (across frames) for each putative neuron with significant MI-RS. Data are shown for each depth, and for each passive and active imaging session: pre-training (gray), stage 1 training (black), stage 2 training (dark green), stage 3 training (light green), post-training (orange). Light blue bars indicate the mean value for each distribution. <bold>e</bold>. Ratio between maximum MI-RS value during post-training and the maximum MI-RS value during pre-training, calculated on each putative neuron that was tracked across the two imaging sessions (n=849 neurons in seven mice). MI-RS and ratios were calculated separately for stimuli 3 and 6 (also used during training, left), for stimuli 1 and 4 (center), and for stimuli 2 and 5 (right). Data were pooled across cortical depths. Blue lines indicate the mean for each distribution. <bold>f</bold>. Cumulative sums of gain in decMI-RS observed for each discriminative neuron when decoders also received non-discriminative neuron responses as input. The vertical dashed line marks zero gain, whereas the horizontal dashed line marks the median of each distribution. As in panels b. and c., the data for pre and post training are plotted in gray and orange, respectively.</p></caption><graphic xlink:href="EMS158183-f006"/></fig></floats-group></article>