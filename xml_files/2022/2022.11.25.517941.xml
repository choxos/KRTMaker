<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS157690</article-id><article-id pub-id-type="doi">10.1101/2022.11.25.517941</article-id><article-id pub-id-type="archive">PPR576101</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Dendritic modulation enables multitask representation learning in hierarchical sensory processing pathways</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Wybo</surname><given-names>Willem A.M.</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="fn" rid="FN1">†</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><contrib contrib-type="author"><name><surname>Tsai</surname><given-names>Matthias C.</given-names></name><xref ref-type="aff" rid="A2">2</xref><xref ref-type="fn" rid="FN1">†</xref></contrib><contrib contrib-type="author"><name><surname>Tran</surname><given-names>Viet Anh Khoa</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Illing</surname><given-names>Bernd</given-names></name><xref ref-type="aff" rid="A4">4</xref></contrib><contrib contrib-type="author"><name><surname>Jordan</surname><given-names>Jakob</given-names></name><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Morrison</surname><given-names>Abigail</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A3">3</xref><xref ref-type="fn" rid="FN2">‡</xref></contrib><contrib contrib-type="author"><name><surname>Senn</surname><given-names>Walter</given-names></name><xref ref-type="aff" rid="A2">2</xref><xref ref-type="fn" rid="FN2">‡</xref></contrib></contrib-group><aff id="A1"><label>1</label>Institute for Advanced Simulation (IAS-6) and Institute for Neuroscience an Medicine (INM-6), Jülich Research Center, Jülich, Germany</aff><aff id="A2"><label>2</label>Department of Physiology, University of Bern, Bern, Switzerland</aff><aff id="A3"><label>3</label>Department of Computer Science - 3, Faculty 1, RWTH Aachen University, Aachen, Germany</aff><aff id="A4"><label>4</label>Brain Mind Institute, École polytechnique fédérale de Lausanne, Lausanne, Switzerland</aff><author-notes><corresp id="CR1"><label>*</label><italic>Correspondence:</italic> <email>willem.a.m.wybo@gmail.com</email></corresp><fn id="FN1"><label>†</label><p id="P1">Co-first author</p></fn><fn id="FN2"><label>‡</label><p id="P2">Co-senior author</p></fn></author-notes><pub-date pub-type="nihms-submitted"><day>27</day><month>11</month><year>2022</year></pub-date><pub-date pub-type="preprint"><day>26</day><month>11</month><year>2022</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nd/4.0/">CC BY-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P3">While sensory representations in the brain depend on context, it remains unclear how such modulations are implemented at the biophysical level, and how processing layers further in the hierarchy can extract useful features for each possible contextual state. Here, we first demonstrate that thin dendritic branches are well suited to implementing contextual modulation of feedforward processing. Such neuron-specific modulations exploit prior knowledge, encoded in stable feedforward weights, to achieve transfer learning across contexts. In a network of biophysically realistic neuron models with context-independent feedforward weights, we show that modulatory inputs to thin dendrites can solve linearly non-separable learning problems with a Hebbian, error-modulated learning rule. Finally, we demonstrate that local prediction of whether representations originate either from different inputs, or from different contextual modulations of the same input, results in representation learning of hierarchical feedforward weights across processing layers that accommodate a multitude of contexts.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P4">Sensory processing in the brain is commonly thought of as proceeding through an increasingly abstract and invariant hierarchy of representations<sup><xref ref-type="bibr" rid="R1">1</xref>, <xref ref-type="bibr" rid="R2">2</xref></sup>. According to this view, neurons have a fixed tuning to specific stimuli: in early sensory areas neurons identify basic features such as lines, gratings<sup><xref ref-type="bibr" rid="R3">3</xref></sup> or simple auditory waveforms<sup><xref ref-type="bibr" rid="R4">4</xref></sup>, whilst neurons further in the processing stream are selective to faces<sup><xref ref-type="bibr" rid="R5">5</xref>, <xref ref-type="bibr" rid="R6">6</xref></sup>, speakers<sup><xref ref-type="bibr" rid="R7">7</xref></sup> or words<sup><xref ref-type="bibr" rid="R8">8</xref></sup>. Artificial neurons in feedforward network models also exhibit such receptive field properties, and similarity between responses in these networks and in sensory brain regions lends support to this view of sensory processing<sup><xref ref-type="bibr" rid="R9">9</xref>, <xref ref-type="bibr" rid="R10">10</xref></sup>. However, the activity of sensory neurons is not driven purely by bottom-up inputs, but is also modulated by internal mental states<sup><xref ref-type="bibr" rid="R11">11</xref></sup>. These modulating inputs, relayed by top-down connections from various cortical areas (<xref ref-type="fig" rid="F1">Fig 1A</xref>), communicate high-level information about behavioural context<sup><xref ref-type="bibr" rid="R12">12</xref>–<xref ref-type="bibr" rid="R14">14</xref></sup>, task demands<sup><xref ref-type="bibr" rid="R15">15</xref>–<xref ref-type="bibr" rid="R17">17</xref></sup>, expectations<sup><xref ref-type="bibr" rid="R18">18</xref>–<xref ref-type="bibr" rid="R20">20</xref></sup>, motor commands<sup><xref ref-type="bibr" rid="R19">19</xref>, <xref ref-type="bibr" rid="R21">21</xref>, <xref ref-type="bibr" rid="R22">22</xref></sup> and memory<sup><xref ref-type="bibr" rid="R23">23</xref>, <xref ref-type="bibr" rid="R24">24</xref></sup>.</p><p id="P5">While it is attractive to assume that such top-down connections to sensory areas adapt feedforward processing to the many contexts that may occur in natural environments, the computational utility of modulating neurons at all levels in the processing stream remains poorly understood. Such modulations induce a dependence on the contextual state in sensory representations at any given processing layer. Consequently, the next processing layer in the hierarchy has to be connected in such a way that it can extract useful features, not only for each possible sensory input, but also for each possible contextual state. Most artificial neural network approaches that seek to implement multitask learning avoid this complication by defining separate output networks for each task, on top of a common trunk that generates a context-independent representation of the inputs<sup><xref ref-type="bibr" rid="R25">25</xref>, <xref ref-type="bibr" rid="R26">26</xref></sup>. Nevertheless, the pervasiveness of contextual modulation in sensory processing indicates that this adaptation is an important component of cortical computation, and reshapes the functional mapping of sensory processing pathways (<xref ref-type="fig" rid="F1">Fig 1B</xref>)<sup><xref ref-type="bibr" rid="R27">27</xref></sup>. While some authors have explored modulations to early processing layers<sup><xref ref-type="bibr" rid="R28">28</xref>–<xref ref-type="bibr" rid="R30">30</xref></sup>, their networks were trained through error backpropagation in a purely supervised fashion. Unsupervised, representation-based learning is considered more biologically plausible<sup><xref ref-type="bibr" rid="R31">31</xref>–<xref ref-type="bibr" rid="R33">33</xref></sup>, but has not been applied to context-modulated representations.</p><p id="P6">Biophysically, the way in which modulations to sensory neurons are implemented remains unknown. A probable constraint is that contextual modulations have a longer time-scale than rapid feedforward processing, where volleys of action potentials propagate upwards through the processing hierarchy<sup><xref ref-type="bibr" rid="R34">34</xref>, <xref ref-type="bibr" rid="R35">35</xref></sup>, their trajectories modulated by the contextual inputs. Two candidate mechanisms appear well adapted to implement neuron-specific modulations with long time scales. One possibility is that fast-spiking inhibitory interneurons target the somata of pyramidal cells (PCs)<sup><xref ref-type="bibr" rid="R36">36</xref></sup>, effectively opening quasi-tonic conductances in the membrane that decrease input resistance and render it harder for the neuron to emit action potentials (<xref ref-type="fig" rid="F1">Fig 1C</xref>)<sup><xref ref-type="bibr" rid="R37">37</xref>, <xref ref-type="bibr" rid="R38">38</xref></sup>. Another possibility is that modulating inputs target thin dendritic branches<sup><xref ref-type="bibr" rid="R30">30</xref>, <xref ref-type="bibr" rid="R39">39</xref>, <xref ref-type="bibr" rid="R40">40</xref></sup>, opening N-Methyl-D-Aspartate (NMDA) channels and eliciting NMDA-spikes<sup><xref ref-type="bibr" rid="R41">41</xref>, <xref ref-type="bibr" rid="R42">42</xref></sup>. These events, whose duration of 50-100 ms outlasts the duration of action potentials by one to two orders of magnitude<sup><xref ref-type="bibr" rid="R43">43</xref>, <xref ref-type="bibr" rid="R44">44</xref></sup>, can also implement a sustained modulation of the neuronal output (<xref ref-type="fig" rid="F1">Fig 1C</xref>).</p><p id="P7">Here, we study the modulation of feedforward processing in networks of biophysically realistic neurons. By assessing effective membrane conductance changes, we find that NMDA-spikes are the more likely candidate to modulate the neuronal input-output (IO) relation. We then study the computational features of neuron-specific modulations in abstract feedforward network models, and show that these modulations allow networks without task-specific readout components to solve multiple tasks. We find that feedforward weights that extract useful information from modulated layers can indeed be learned, because multitask performance increases with network depth. This in turn allows the network to learn new tasks by adapting solely the modulating synapses, and inspired us to ask whether unsupervised learning principles exist for feedforward weights that support multitask learning through neuron-specific modulations. While the contextual modulations in abstract models are trained through gradient descent on a classification loss, we show that our approach translates to biologically realistic spiking models equipped with a Hebbian, error-modulated learning rule for the contextual synapses. Finally, we show that context-modulated representations promote self-supervised learning across a hierarchy of processing layers, by providing a form of data augmentation for contrastive learning that allows deeper processing layers to extract general, high-level features, without the need for error backpropagation across layers. Thus, instead of being a complication, such modulations could constitute an integral feature of cortical learning.</p></sec><sec id="S2" sec-type="results"><title>Results</title><sec id="S3"><title>Biophysical implementation of neuron-specific modulations</title><p id="P8">To understand how sustained modulations of individual neurons can be implemented in cortical networks, we simulate modulatory afferents of varying strengths to a biophysically realistic layer 5 (L5) PC model<sup><xref ref-type="bibr" rid="R45">45</xref></sup>. We compare two possible candidate mechanisms: one where fast-spiking interneurons target the peri-somatic region of PCs, providing shunting inhibition, and another where excitatory afferents target the dendritic tips of the basal and apical oblique dendrites, eliciting NMDA-spikes (<xref ref-type="fig" rid="F1">Fig 1C</xref>).</p><p id="P9">In both cases, we implement feedforward inputs as short Gaussian bursts, with a width of 6 ms, and examine conditions where, for identical bursts of feedforward input, the modulatory afferents change the number of somatic outputs between zero and two spikes. Since the first mechanism is inhibitory, we tune the number of feedforward inputs per burst so that two output spikes are emitted without modulatory input (175 feedforward inputs), and increase the number of shunt inputs until all output spikes are prevented (<xref ref-type="fig" rid="F1">Fig 1D, E</xref>). Conversely, as the second mechanism is excitatory, we tune the number of feedforward inputs per burst so that no output spikes are emitted without modulatory input (40 feedforward inputs), and increase the number of inputs eliciting dendritic NMDA-spikes until two output spikes are emitted (<xref ref-type="fig" rid="F1">Fig 1F, G</xref>).</p><p id="P10">An experimentally testable measure that distinguishes between the candidate mechanisms is the change in effective conductance of the neuron. The time course of this conductance can be measured in voltage clamp by repeating the same input pattern at different holding potentials, and is given by the slope of the current-voltage relationship at all time points<sup><xref ref-type="bibr" rid="R46">46</xref></sup>. Experimental studies estimate effective conductance changes of 1 to 10 nS<sup><xref ref-type="bibr" rid="R46">46</xref>, <xref ref-type="bibr" rid="R47">47</xref></sup>. In the case of somatic modulations through shunting inhibition, our simulations show that the effective conductance change required to modulate the output firing from two to zero spikes is between 100 and 150 nS, values far outside the experimentally measured range (<xref ref-type="fig" rid="F1">Fig 1H</xref>). Conversely, the effective conductance change for modulating output firing from zero to two spikes with dendritic NMDA-spikes is between 1 and 10 nS. This demonstrates that dendritic NMDA-spikes are a biologically plausible candidate to implement neuron-specific modulations (<xref ref-type="fig" rid="F1">Fig 1H</xref>), on which we will focus in the remainder of this work.</p></sec><sec id="S4"><title>Neuron-specific modulations as bias and/or gain changes</title><p id="P11">Conceptually, neuron-specific modulations can be thought of as changing the slope and/or threshold of the neuronal IO relationship. In abstract neuron models of the form <disp-formula id="FD1"><label>(1)</label><mml:math id="M1"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mspace width="0.2em"/><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>x</mml:mtext></mml:mstyle><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula> this can be implemented through modulations of gain <italic>g</italic> and bias <italic>b</italic>, with <italic>g</italic> primarily affecting the slope and <italic>b</italic> exclusively affecting the threshold. Here, <italic>y</italic> represents the neuronal activation, <italic>σ</italic> the activation function, <bold>w</bold> the feedforward weight vector, and <bold>x</bold> the feedforward input vector. Note that although <italic>y</italic> typically stands for the average neuronal firing rate, here we interpret it rather as the average number of somatic output spikes in response to a short burst of feedforward inputs. In this case, the ReLU activation function <italic>σ</italic>(<italic>x</italic>) = max(<italic>x</italic>, 0) is a reasonable choice (<xref ref-type="fig" rid="F2">Fig 2A,C</xref>).</p><p id="P12">We maintain the same input configuration to the L5 PC model as before (<xref ref-type="fig" rid="F1">Fig 1F</xref>), and construct IO curves for different levels of modulation by varying the number of feedforward inputs. We then model the effect of modulation on the IO dependency either as gain or bias adaptation. To fit these curves, we retain the thresholds – computed as the points where the interpolation line crosses the mid-point between discrete values – as the fit points (<xref ref-type="fig" rid="F2">Fig 2A</xref>). We then fit all obtained curves together, either with a curve-specific gain and shared bias (<xref ref-type="fig" rid="F2">Fig 2B</xref>, left) or with a curve-specific bias and shared gain (<xref ref-type="fig" rid="F2">Fig 2B</xref>, middle). We found that the bias-modulated fits were more accurate than the gain-modulated fits (<xref ref-type="fig" rid="F2">Fig 2E</xref>), but the large residual indicated that there nonetheless appeared to be a significant change in IO slope. We therefore introduced a constant <italic>x</italic><sub>shift</sub> parameter <disp-formula id="FD2"><label>(2)</label><mml:math id="M2"><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mi>y</mml:mi></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>x</mml:mtext></mml:mstyle><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mtext>shift</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>x</mml:mtext></mml:mstyle><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>b</mml:mi><mml:mo>−</mml:mo><mml:mi>g</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mtext>shift</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula> resulting in concerted additive and multiplicative modulation by gain changes. This fit produced the most accurate representation of the modulatory effect (<xref ref-type="fig" rid="F2">Fig 2B</xref>, right, <xref ref-type="fig" rid="F2">Fig 2E</xref>). Together, these considerations suggest a conceptual picture of sensory neurons where peri-somatic feed-forward inputs are modulated by top-down inputs impinging onto dendritic subunits (<xref ref-type="fig" rid="F2">Fig 2F</xref>). These modulatory inputs increase IO slope and decrease IO threshold. For completeness, we note that somatic modulation through shunting inhibition is better fitted by pure gain modulation than bias modulation (<xref ref-type="fig" rid="F2">Fig 2C-E</xref>, configuration as in <xref ref-type="fig" rid="F1">Fig 1D</xref>), in agreement with prior work<sup><xref ref-type="bibr" rid="R37">37</xref></sup>, and that introducing a constant x-shift parameter also decreased the residual markedly.</p></sec><sec id="S5"><title>Multitask learning with task-dependent modulations to individual neurons</title><p id="P13">In feedforward neural network architectures, implementing task switching by providing neuron-specific modulations to the neurons in the hidden layers (<xref ref-type="fig" rid="F3">Fig 3A</xref>) is a departure from the standard approach, in which task-specific output units are trained on top of a shared trunk network<sup><xref ref-type="bibr" rid="R25">25</xref>, <xref ref-type="bibr" rid="R26">26</xref></sup>. We therefore first assess whether multitask learning in this manner is even computationally feasible, and learn task-specific gains to the individual neurons in feedforward networks together with feedforward weights, x-shifts, and biases that are shared across tasks. All parameters are optimized through supervised error backpropagation.</p><p id="P14">To demonstrate that neuron-specific modulations can successfully change the functional mapping of feedforward processing pathways, we train networks with one or four hidden layers to solve 48 binary classification tasks on two-dimensional inputs. These networks, each with a single set of feedforward weights, but task- and neuron-specific gains, solved all 48 tasks, demonstrating that such modulations achieve multitask learning (<xref ref-type="fig" rid="F3">Fig 3B</xref>, <xref ref-type="supplementary-material" rid="SD1">S1A</xref>). The deeper network was more accurate (less black area in <xref ref-type="fig" rid="F3">Fig 3B</xref>, <xref ref-type="supplementary-material" rid="SD1">S1A</xref>), indicating that multilayer architectures with neuron-specific modulations are computationally useful.</p><p id="P15">To more thoroughly test neuron-specific modulations on a dataset that is both sufficiently rich in tasks and sufficiently simple to subsequently combine with biophysical models, we convert the EMNIST dataset<sup><xref ref-type="bibr" rid="R48">48</xref></sup> into a multitask learning problem (multitask EMNIST) by defining a one-vs-all classification task for every class in the original dataset (47 tasks, <xref ref-type="fig" rid="F3">Fig 3C</xref>). We find that implementing neuron-specific modulations through independent gain and bias changes achieves the same performance as a task-specific readout, and that combined gain and bias changes through a constant x-shift result in a slightly reduced performance (<xref ref-type="fig" rid="F3">Fig 3D, E</xref>). Qualitatively, the same behaviour is observed for both investigated forms of neuron-specific modulations: performance increases with network depth (<xref ref-type="fig" rid="F3">Fig 3D</xref>), and performance increases strongly with layer size (<xref ref-type="fig" rid="F3">Fig 3E</xref>). Hyperparameters, such as learning rates, are optimized for each method and architecture separately (<xref ref-type="supplementary-material" rid="SD1">Fig S1B</xref>). Note that we have also implemented other neuron-specific modulations <xref ref-type="supplementary-material" rid="SD1">Fig S1C</xref>), but the minute differences between modulation types could not be decoupled fully from choices such as network architecture, task design and training method.</p><p id="P16">In the brain, mounting evidence suggests that top-down inputs dynamically select salient features from a stable feedforward connectivity<sup><xref ref-type="bibr" rid="R24">24</xref></sup>. We therefore test whether our framework with neuron-specific modulations is efficient at making use of prior knowledge, encoded in the learned feedforward weights. We train shared parameters on a subset of the 47 tasks, and learn the remaining tasks by exclusively adapting the task-specific parameters. For networks with one hidden layer, we found that all approaches achieve similar transfer learning. For networks with more than one hidden layer, our approach transferred much better to the remaining tasks than networks with task-specific readouts (<xref ref-type="fig" rid="F3">Fig 3F</xref>). Presuming that with more hidden layers, networks become increasingly adept at filtering out task-irrelevant information, we hypothesize that task-specific readouts for new tasks have no access to information that was not relevant for the original tasks. Conversely, neuron-specific modulations to early layers could recover such information, leading to improved transfer learning.</p></sec><sec id="S6"><title>Unsupervised weight matrices for networks with neuron-specific modulations</title><p id="P17">So far our supervised results have demonstrated that a network with a single set of feedforward weights, and contextual modulations to individual neurons, can solve many tasks. However, much of the learning in the brain is thought to proceed in an unsupervised fashion<sup><xref ref-type="bibr" rid="R49">49</xref>, <xref ref-type="bibr" rid="R50">50</xref></sup>. While unsupervised learning has been studied thoroughly in combination with a supervised readout on the hidden representation<sup><xref ref-type="bibr" rid="R32">32</xref>, <xref ref-type="bibr" rid="R51">51</xref></sup>, it has yet to be combined with neuron-specific modulations. We therefor investigate how to find unsupervised feedforward weight matrices that facilitate the construction of task-specific decision boundaries through supervised learning of the neuronal gains.</p><p id="P18">To explain our approach, we note that the decision of any given neuron in the feedforward pathway to become active represents a decision boundary on the sensory input space. Locally, this boundary is characterized by its normal vector (<xref ref-type="sec" rid="S10">methods</xref>), which captures the input features that the neuron uses to make a decision about whether to become active, and is always a linear combination of the input weight vectors to the network (<xref ref-type="fig" rid="F4">Fig 4A</xref>). A necessary condition to be able to construct a given decision boundary is that its normal vectors can all be constructed with the feedforward weight matrices (<xref ref-type="fig" rid="F4">Fig 4B</xref>). Our rationale, thus, is that neuron-specific modulations select a concatenation of decision boundary segments with constructible normal vectors that optimally approximates the desired decision boundary. By consequence, input weight vectors are preferentially constrained to the subspace of the data, so that all constructible normal vectors also lie within this subspace (<xref ref-type="fig" rid="F4">Fig 4C</xref>). When there is no <italic>a priori</italic> information on the decision boundaries that might be drawn through the data, a reasonable heuristic for the constructible normal vectors is that they approximate the set of difference vectors between data samples. In turn, decision boundaries can be seen as a concatenation of segments with normal vectors that are close to difference vectors between nearby, but differently classified data samples (<xref ref-type="fig" rid="F4">Fig 4D</xref>). Consequently, by aligning the set of constructible normal vectors of the network to the set of difference vectors between data samples, we ensure that constructible normal vectors lie within the data subspace, and that they constitute useful putative decision boundary directions.</p><p id="P19">To achieve such alignment, we minimize the residual min<sub><bold>c</bold></sub> ‖Δ<bold>x</bold> − <bold>c<italic>W</italic></bold>‖<sub>2</sub> between any given difference Δ<bold>x</bold> and its optimal reconstruction as a linear combination of input weight vectors (the rows of the input weight matrix <italic>W</italic>, <xref ref-type="fig" rid="F4">Fig 4E</xref>) with respect to <italic>W</italic> for a representative set of differences <disp-formula id="FD3"><label>(3)</label><mml:math id="M3"><mml:mrow><mml:munder><mml:mrow><mml:mtext>argmin</mml:mtext></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>W</mml:mi></mml:mrow></mml:munder><mml:mo>∥</mml:mo><mml:mtext>Δ</mml:mtext><mml:mi>X</mml:mi><mml:mo>−</mml:mo><mml:mi>C</mml:mi><mml:mi>W</mml:mi><mml:msub><mml:mo>∥</mml:mo><mml:mn>2</mml:mn></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P20">In this reconstruction loss, Δ<italic>X</italic> is a matrix with as rows the difference vectors and <italic>C</italic> the matrix with as rows the optimal coefficients <bold>c</bold>. We minimize (3) in three different ways (Table S1, <xref ref-type="supplementary-material" rid="SD1">Fig S2A</xref>). First, the optimum of (3) without regularizer or constraint (for lower hidden layer dimensionality <italic>k</italic> than input dimensionality <italic>n</italic>) is given by the principal components of Δ<italic>X</italic> (ΔPCA), and this problem can be solved in a biologically plausible manner through Hebbian learning rules<sup><xref ref-type="bibr" rid="R31">31</xref></sup>. Second, to encourage alignment between input weight vectors and difference vectors, we ask that any given Δ<bold>x</bold> can be expressed with few weight vectors. We achieve this by adding an L1-regularization term <italic>λ</italic> ‖<italic>C</italic>‖<sub>1</sub> to (3). Thus (3) becomes the canonical sparse dictionary learning problem (ΔSD)<sup><xref ref-type="bibr" rid="R52">52</xref>,<xref ref-type="bibr" rid="R53">53</xref></sup>, which can also be solved by neural networks with biologically plausible Hebbian learning rules<sup><xref ref-type="bibr" rid="R32">32</xref></sup>. Finally, we encourage input weight vectors to capture local pixel correlations. We achieve this by placing an L1 constraint on ‖<bold>w</bold><sub><italic>j</italic>:</sub>‖<sub>1</sub> ≤ <italic>ε</italic> on the rows of <italic>W</italic>, next to an L1 constraint ‖<bold>c</bold><sub>:<italic>j</italic></sub>‖<sub>1</sub> ≤ <italic>δ</italic> for the columns of <italic>C</italic>. This doubly constrained minimization is known as the penalized matrix decomposition (ΔPMD)<sup><xref ref-type="bibr" rid="R54">54</xref></sup>.</p><p id="P21">We then embed the obtained feedforward weight matrices <italic>W</italic> in a network architecture with a single hidden layer of gain-modulated neurons, with shared x-shift and bias. The hidden neurons target a single gain-modulated output unit through identical feedforward weights. We find that solving (3) for differences between data samples instead of the data samples themselves generally results in a performance increase when combined with neuron-specific modulations to solve multitask EMNIST (<xref ref-type="supplementary-material" rid="SD1">Fig S2B</xref>). Assessing the relationship between input dimensionality (<italic>n</italic> = 784) and dimensionality of the hidden layer (number of hidden neurons <italic>k</italic>), we find that ΔPCA performs well for low numbers of hidden neurons, but that task performance saturates quickly and decreases for <italic>k</italic> ≥ 100 (<xref ref-type="fig" rid="F4">Fig 4F</xref>, blue). This result is in agreement with our theoretical considerations: when the effective dimensionality of the data is reached, further orthogonal components do not contribute usefully to the decision boundary, as they lie outside of the subspace of the input data. In contrast, using random projections (RP) in <italic>W</italic> by sampling from a Gaussian distribution results in performances that increase strongly with <italic>k</italic> (<xref ref-type="fig" rid="F4">Fig 4G</xref>, red). This can be understood by considering that with increasing numbers of random vectors, it becomes more likely that their linear combinations can approximate difference vectors between data points. Finally, we find that ΔPMD reached the highest performances for all <italic>k</italic> (<xref ref-type="fig" rid="F4">Fig 4G</xref>, purple). These weight vectors being sparse likely facilitates learning performant sets of neuron-specific modulations, as up- or down-regulating a specific hidden neuron influences only a localized area of the input space. By consequence, neurons with receptive fields in other areas of the input space do not need re-adjustment, whereas neurons with non-local receptive fields would need to be re-adjusted. In these optimizations, the shared x-shift and bias, as well as the learning rate, were optimized through an evolutionary algorithm for each configuration separately (<xref ref-type="supplementary-material" rid="SD1">Fig S2C</xref>).</p><p id="P22">Finally, we investigate whether the supervised approach trained purely on the classification loss (as in <xref ref-type="fig" rid="F3">Fig 3</xref>) also minimizes (3), to understand the extend to which supervised training adapts the input weight matrix to the subspace of the data, and how that depends on the task set. To that end, we compare the value of the residual min<sub><italic>C</italic></sub> ‖Δ<italic>X</italic> −<italic>CW</italic>‖ of the reconstruction loss (3) during training of <italic>W</italic> in a fully supervised fashion (as in <xref ref-type="fig" rid="F3">Fig 3</xref>), with the reconstruction loss when <italic>W</italic> was given by ΔPMD. We assess the case where the entire network was task-specific (feedforward weights included) and the gain-modulated case, and find that the sharp initial reduction in train loss (i.e. the classification loss) is associated with a sharp reduction in reconstruction loss (<xref ref-type="fig" rid="F4">Fig 4H</xref>). The reconstruction loss for the gain-modulated network, where a single feedforward weight matrix has to contribute to solving a multitude of tasks, decreased to a value much closer to the ΔPMD optimum than the task-specific network average, where the feedforward weight matrix only has to solve a single task. Thus, supervised training forgets the initialization by adapting feedforward weights to the data subspace, and then fine tunes to the specific set of tasks, as validation performance during the later phase increases from the unsupervised value (obtained with ΔPMD) to its maximum. The unsupervised approach on the other hand is generalist, and admits any task that might be defined post hoc, at the cost of forgoing task-specific fine tuning.</p></sec><sec id="S7"><title>Spiking networks with biophysically realistic dendritic branches learn task switching online</title><p id="P23">To investigate whether our biologically inspired learning strategy holds with biophysically realistic neurons, we implement a spiking network of cortical pyramidal cell models (<xref ref-type="fig" rid="F5">Fig 5A</xref>). We simplify the L5 PC model using the method developed in our previous work<sup><xref ref-type="bibr" rid="R55">55</xref></sup>, obtaining a model that was computationally sufficiently inexpensive to permit the network to be run over long timescales, thus allowing us to present a large amount of inputs. The output neuron is a single compartment model, obtained by only fitting the soma of the full L5 PC model, whereas the hidden layer consists of 100 neurons, each equipped with 20 dendritic compartments where context-modulating AMPA+NMDA synapses impinge (<xref ref-type="fig" rid="F5">Fig 5A</xref>, blue). Feedforward weights to the hidden neurons are given by either ΔPMD, ΔSD, PCA or RP, whereas all feedforward weights to the output neuron have the same value.</p><p id="P24">Learning at the dendritic synapses was orchestrated by an online error-weighted Hebbian plasticity rule during a continuous stream of inputs (<xref ref-type="fig" rid="F5">Fig 5B</xref>). Because of our choice of architecture, with identical weights from all hidden neurons to the output neuron, this learning rule approximately follows the error gradient of the classification loss (<xref ref-type="sec" rid="S10">methods</xref>). For each data sample, the pixel intensities are converted into short, Gaussian bursts of spikes (width of 6 ms), with spike numbers proportional to pixel intensity. These spikes are fed into feedforward synapses whose weights were scaled according to the matrices computed in the previous section. Conversely, the task context is encoded by a wide Gaussian burst (width of 20 ms), consisting of on average 60 spikes if the context is active and zero spikes otherwise. The first of the feedforward spikes opens a 50 ms window in which the output neuron should either generate an output spike – in response to a random sample – or generate <italic>no</italic> output spike – in response to a sample from the class to be recognized. In case of erroneous firing, a global error signal (<xref ref-type="fig" rid="F5">Fig 5B</xref>, red) is relayed to the dendritic synapses of the hidden neurons. This error signal is then multiplied by a low-pass filter of the somatic spike output (<xref ref-type="fig" rid="F5">Fig 5B</xref>, green), a low-pass filter of the presynaptic spike input (<xref ref-type="fig" rid="F5">Fig 5B</xref>, blue), and a learning rate modulation (<xref ref-type="fig" rid="F5">Fig 5B</xref>, purple) based on a low-pass filter of the local dendritic voltage (<xref ref-type="fig" rid="F5">Fig 5B</xref>, black).</p><p id="P25">This network architecture solves multitask EMNIST, and tasks that are demonstrably not linearly separable, such as XOR (<xref ref-type="supplementary-material" rid="SD1">Fig S3</xref>). Initially, the output neuron fires indiscriminately, but learns to spike correctly during the target intervals (<xref ref-type="fig" rid="F5">Fig 5C</xref>, <xref ref-type="supplementary-material" rid="SD1">Fig S3C,D</xref>, shaded boxes). Assessing network performances averaged over all 47 tasks (<xref ref-type="fig" rid="F5">Fig 5D</xref>), we find that performance differences observed between alternative feedforward matrices for the artificial network architecture (<xref ref-type="fig" rid="F4">Fig 4F,G</xref>) are exacerbated, with RP performing barely better than chance level. Thus, in the noisy and imprecise spiking system, it is all the more important that the feedforward weight matrix consists of localized receptive fields, well-adapted to the input data. Our ΔPMD matrix achieves this for multitask EMNIST. Finally, we assess the somatic and dendritic activity after learning in the same hidden neuron, for the same feedforward input, across different tasks (<xref ref-type="fig" rid="F5">Fig 5E</xref>, in the ΔPMD-network). We find that between zero and three output spikes are emitted, depending on the precise dendritic state. Thus, this network successfully learns multitask EMNIST by expressing a different dendritic state for each task. These learned dendritic states modulate rapid feedforward processing to solve a multitude of tasks, supporting our central hypothesis.</p></sec><sec id="S8"><title>Task-modulated contrastive learning for stacking processing layers</title><p id="P26">Sensory processing in the brain is thought to proceed in a hierarchical manner through a number of processing layers<sup><xref ref-type="bibr" rid="R9">9</xref>, <xref ref-type="bibr" rid="R10">10</xref></sup>. Deep artificial networks also implement hierarchical processing through a stack of layers, the learning of which is orchestrated by error backprogagation<sup><xref ref-type="bibr" rid="R56">56</xref>, <xref ref-type="bibr" rid="R57">57</xref></sup>. Nevertheless, the question of whether this algorithm could plausibly be implemented in the brain is still a matter of debate<sup><xref ref-type="bibr" rid="R58">58</xref></sup>, in contrast to representation learning approaches such as PCA<sup><xref ref-type="bibr" rid="R31">31</xref></sup> or SD<sup><xref ref-type="bibr" rid="R32">32</xref></sup>, which have biologically plausible implementations. These representation learning approaches, however, do not extract higher-order features when stacked in a deep network<sup><xref ref-type="bibr" rid="R51">51</xref></sup>. Furthermore, by introducing neuron-specific modulations to the hidden processing layers, the representation learning problem becomes even more complex, as now the hidden representations depend on task modulation.</p><p id="P27">Here, we propose a representation learning algorithm that does not rely on error backpropagation between layers, and where the task dependence of the hidden representations is an integral feature that improves generalization. As we have shown above, sparse feedforward connectivity is beneficial in concert with neuron-specific modulations. We therefore apply our algorithm to a convolutional architecture (<xref ref-type="fig" rid="F6">Fig 6A</xref>), which by design features localized receptive fields adapted for visual processing<sup><xref ref-type="bibr" rid="R59">59</xref></sup>. Our representation learning approach takes inspiration from a successful contrastive learning (CL) algorithm<sup><xref ref-type="bibr" rid="R60">60</xref></sup>. In this algorithm, augmentations (e.g. occlusions, rotations, scalings and combinations thereof) are applied to the input data and the convolutional feedforward network creates hidden representations thereof. A multi-layer perceptron (CL-MLP) – applied to these hidden representations – is trained in concert with the convolutional feedforward weights to maximize similarity between representations if they originate from augmentations of the same input sample; conversely to maximize contrast if they originate from different input samples. In the original formulation<sup><xref ref-type="bibr" rid="R60">60</xref></sup>, the CL-MLP is applied once at the end of the feedforward pathway, and weight changes are orchestrated across layers by error backpropagation of the CL loss. Here, we construct our networks layer by layer by applying this algorithm in a layer-wise fashion. Hence, a local CL-MLP minimizes the CL loss to learn the feedforward weights between the previous and the current layer, and no error gradients propagate across layers (<xref ref-type="fig" rid="F6">Fig 6A</xref>, see <xref ref-type="sec" rid="S10">methods</xref> for details). After this CL phase, we learn task-specific gains for the hidden neurons in the current layer through a task-independent output unit (OU) that maximises classification performance in a supervised manner (<xref ref-type="fig" rid="F6">Fig 6A</xref>, blue). To train feedforward weights to the next layer in the next CL phase, the task-modulations learned in the previous layers are treated as additional data augmentations, across which similarity has to be maximized (<xref ref-type="fig" rid="F6">Fig 6B</xref>).</p><p id="P28">We test our task-modulated contrastive learning (TMCL) algorithm on multitask CIFAR-10<sup><xref ref-type="bibr" rid="R61">61</xref></sup>, and find that network performance, averaged over all tasks, increases with the number of layers (<xref ref-type="fig" rid="F6">Fig 6C</xref>, blue). To establish a performance envelope, we test equivalent network architectures trained in a fully supervised manner through end-to-end error backpropagation (<xref ref-type="fig" rid="F6">Fig 6C</xref>, red). The performance of networks with RP starts at lower values, and does not increase as much, or even decreases, across layers (<xref ref-type="fig" rid="F6">Fig 6C</xref>, black). Similarly, stacking RP layers on top of a TMCL layer does not increase performance across multiple layers (<xref ref-type="fig" rid="F6">Fig 6C</xref>, grey). Removing similarity maximization across task representations from TMCL also abolishes the performance increase with stacking (<xref ref-type="fig" rid="F6">Fig 6C</xref>, green). We furthermore assess network performance while using different numbers of tasks during the TMCL phase. For each number of tasks, we select ten random but distinct subsets containing that amount of tasks, and use only those tasks as hidden augmentations. We then evaluate network performance across all tasks, and find that performance increases with subset size (<xref ref-type="fig" rid="F6">Fig 6D</xref>), indicating that using representations with many tasks improves generalization.</p><p id="P29">Finally, we visualize how the network constructs and modulates hidden representations, to investigate whether high-level information is extracted across layers. We apply the uniform manifold approximation and projection (UMAP<sup><xref ref-type="bibr" rid="R62">62</xref></sup>), a non-linear visualisation method, to TMCL-generated hidden representations. In the first layer, at most a general distinction between manmade objects (red shades) and animals (blue shades) can be observed, while in the fourth layer individual classes appear in a localized pattern (<xref ref-type="fig" rid="F6">Fig 6F</xref>). Such localized patterns cannot be distinguished for CL without task-modulations (<xref ref-type="fig" rid="F6">Fig 6F</xref>) or for RP (<xref ref-type="supplementary-material" rid="SD1">Fig S4</xref>).</p></sec></sec><sec id="S9" sec-type="discussion"><title>Discussion</title><p id="P30">In this work, we have laid out a biophysical theory of how contextual modulations can be achieved in the brain. We have shown that the dendritic trees of neurons are ideally suited to integrate contextual inputs, resulting in concerted gain and threshold modulations to the IO relationship of individual neurons. We have then demonstrated that such task-modulations achieve performant transfer learning. Furthermore, the architecture of our models, with task-modulations that are applied prior to the non-linear activation – i.e. the spiking output in networks of biophysically realistic neurons – and identical feedforward weights to the output neuron, allows a Hebbian plasticity rule modulated by a global error signal to learn non-linear task-specific decision boundaries. Finally, we have shown that task-modulations to hidden layers augment sensory representations, facilitating the extraction of high-level features through contrastive learning.</p><p id="P31">While the component of our task-modulated contrastive learning approach that learns task-modulations can be implemented in a biologically plausible fashion, as shown through our network model with realistic dendritic subunits, the contrastive learning step in our study relies on precise error backpropagation through the CL-MLP. However, a contrastive learning algorithm has recently been proposed in the context of predictive coding that relies solely on Hebbian learning rules<sup><xref ref-type="bibr" rid="R33">33</xref></sup>. This algorithm shows that contrastive learning could be implemented in a self-supervised manner, by neurons connecting locally to principal feedforward cells (L5 PCs), and using gaze information to assess whether similarity or contrast have to be maximised.</p><p id="P32">A puzzling observation, first discovered in high-level areas<sup><xref ref-type="bibr" rid="R63">63</xref>, <xref ref-type="bibr" rid="R64">64</xref></sup> and later also in early sensory regions<sup><xref ref-type="bibr" rid="R65">65</xref>–<xref ref-type="bibr" rid="R67">67</xref></sup>, is that the participation of a neuron in the representation of a sensory stimulus changes over time. This representational drift raises questions about the framework of classical representation learning, and about how stable perception can be achieved<sup><xref ref-type="bibr" rid="R68">68</xref>, <xref ref-type="bibr" rid="R69">69</xref></sup>. As we show, changes to the sensory representation could help in extracting high level information in further processing layers. The drift itself could be a manifestation of changes in the internal mental state – encoded on dendritic trees and thus invisible in most imaging experiments.</p><p id="P33">Feedforward processing needs to be rapid, for instance to initiate evasive action when a threat is identified, while contextual modulation likely proceeds on a slower time scale, for instance to bias the feedforward pathway towards detection of relevant threats given an environment. We have linked this difference in time scales to the underlying biophysical processes: the short duration of somatic spikes (1-5 ms) and by extension the whole feedforward pathway (100-150 ms)<sup><xref ref-type="bibr" rid="R34">34</xref>, <xref ref-type="bibr" rid="R35">35</xref></sup> in comparison to the duration of dendritic spikes (50-100 ms, or possibly longer<sup><xref ref-type="bibr" rid="R42">42</xref>, <xref ref-type="bibr" rid="R44">44</xref></sup>). These temporal scales match the frequency bands associated with feedforward processing (gamma, 60-80 Hz) and top-down processing (alpha-beta, 10-20 Hz) observed across a large range of tasks and stimuli<sup><xref ref-type="bibr" rid="R70">70</xref>–<xref ref-type="bibr" rid="R75">75</xref></sup>.</p><p id="P34">In the brain, the contextual signal to a neuron is likely a rich combination of cross-modal information, recurrent information about the recent past, and top-down signals about high-level goals, behavioral state and environment characteristics. That these signals impinge on dendritic branches, which function as semi-independent feature detectors<sup><xref ref-type="bibr" rid="R76">76</xref></sup>, has the added benefit of suppressing noise by preventing spurious activations by random subsets of dendritic inputs<sup><xref ref-type="bibr" rid="R77">77</xref></sup>. Furthermore, distinct contextual pathways may target distinct loci on the dendritic tree. Local recurrent connections, e.g. L5 PC to L5 PC or L5 PC to L2/3 PC to L5 PC<sup><xref ref-type="bibr" rid="R78">78</xref></sup>, target basal and proximal apical dendrites<sup><xref ref-type="bibr" rid="R79">79</xref></sup>, and may relay information about the recent past as a context for the present. Axons carrying top-down signals target L5 and L6<sup><xref ref-type="bibr" rid="R40">40</xref></sup>, where they generate NMDA spikes in basal dendrites of L5 PCs, as well as L1<sup><xref ref-type="bibr" rid="R80">80</xref></sup>, where they generate Ca<sup>2+</sup> spikes in the apical dendrites of L5 PCs<sup><xref ref-type="bibr" rid="R42">42</xref>, <xref ref-type="bibr" rid="R81">81</xref></sup>. Whereas we have focused on NMDA-spikes in this work, Ca<sup>2+</sup> also provide gain modulation over long time-scales and are thus suited for implementing contextual adaptation<sup><xref ref-type="bibr" rid="R82">82</xref></sup>. Note furthermore that top-down signals targetting L1 need not remain constrained to the apical dendrites of L5 PCs. These signals also target GABAergic somatostatin-expressing (SST) and vasoactive intestinal peptide-expressing (VIP) interneurons<sup><xref ref-type="bibr" rid="R80">80</xref></sup>, which in turn provide inhibition and disinhibition, respectively, to the basal dendrites of L5 PCs<sup><xref ref-type="bibr" rid="R36">36</xref></sup>, and powerfully regulate NMDA-spike genesis and duration<sup><xref ref-type="bibr" rid="R83">83</xref>, <xref ref-type="bibr" rid="R84">84</xref></sup>.</p><p id="P35">Taken together, our work reframes feedforward processing in the brain as a fundamentally adaptable process, steered dynamically by contextual inputs that modify the dendritic state. Our theory matches environmental constraints to the underlying biophysical layout, and may help to explain diverse observations, such as the frequency bands associated with feedforward and top-down processing, and the apparent instability of sensory representations.</p></sec><sec id="S10" sec-type="methods" specific-use="web-only"><title>Methods</title><sec id="S11"><title>Biophysical modelling</title><p id="P36">The morphology, ion channels and physiological parameters for the L5 PC model were taken from Hay et al.<sup><xref ref-type="bibr" rid="R45">45</xref></sup> and implemented in the NEURON simulator<sup><xref ref-type="bibr" rid="R85">85</xref></sup>. Contextual and background synapses were conductance based, either containing AMPA+NMDA (excitatory) or GABA (inhibitory) receptors. AMPA and GABA receptors were implemented as the product of a double exponential conductance profile<sup><xref ref-type="bibr" rid="R86">86</xref></sup> <italic>g</italic> with a driving force: <disp-formula id="FD4"><label>(4)</label><mml:math id="M4"><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mtext>syn</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P37">AMPA rise resp. decay times were <italic>τ<sub>r</sub></italic> = 0.2 ms, <italic>τ<sub>d</sub></italic> = 3 ms and AMPA reversal potential was <italic>e</italic> = 0 mV. For GABA, we set <italic>τ<sub>r</sub></italic> = 0.2 ms, <italic>τ<sub>d</sub></italic> = 10 ms and <italic>e</italic> = −80 mV. N-methyl-D-aspartate (NMDA) currents<sup><xref ref-type="bibr" rid="R87">87</xref></sup> were implemented as: <disp-formula id="FD5"><label>(5)</label><mml:math id="M5"><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mtext>syn</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo>−</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula> with rise resp. decay time <italic>τ<sub>r</sub></italic> = 0.2 ms, <italic>τ<sub>d</sub></italic> = 43 ms, and <italic>e</italic> = 0 mV, while <italic>σ</italic>(<italic>v</italic>) – the channel’s magnesium block – had the form<sup><xref ref-type="bibr" rid="R88">88</xref></sup>:<disp-formula id="FD6"><label>(6)</label><mml:math id="M6"><mml:mrow><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mn>0.3</mml:mn><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>0.1</mml:mn><mml:mi>v</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P38">The weight of a synapse signifies the maximum value of its conductance profile. For an AMPA+NMDA synapse, the weight is the maximal value of the AMPA conductance profile, and the maximal value of the NMDA profice is twice that of the AMPA window (NMDA ratio of 2). Feedforward synapses where current based, with a dual exponential current profile with <italic>τ<sub>r</sub></italic> = 0.2 ms and <italic>τ<sub>d</sub></italic> = 3 ms. The excitatory synaptic weight corresponded to the maximal value of the current profile. For inhibitory feedforward synapses, the weight was negative and corresponded to the minimum value.</p><p id="P39">For dendritic modulation, we identified 20 dendritic compartments suited for semi-independent NMDA-spike generation (e.g. avoiding compartments on sister branches, <xref ref-type="fig" rid="F1">Fig 1F</xref>) and equipped each of these compartments with an AMPA+NMDA synapse. Both the feedforward and shunt inputs targeted the somatic compartment. The 20 dendritic compartments as well as the soma were also equipped with an AMPA and GABA background synapse. All parameters for the simulations are shown in <xref ref-type="table" rid="T1">Table 1</xref>.</p><p id="P40">To measure the membrane conductance change induced by the contextual inputs (<xref ref-type="fig" rid="F1">Fig 1H</xref>), we follow Haider et al.<sup><xref ref-type="bibr" rid="R46">46</xref></sup> and measure the time-dependent electrode current in voltage clamp (<italic>i</italic>(<italic>t</italic>; <italic>v<sub>h</sub></italic>), with <italic>v<sub>h</sub></italic> the holding potential) for two different holding potentials: <italic>v</italic><sub><italic>h</italic>1</sub> = −80 mV and <italic>v</italic><sub><italic>h</italic>2</sub> = 0 mV. Following the Ohmic relationship <italic>g</italic>(<italic>t</italic>)(<italic>v<sub>h</sub></italic> − <italic>v</italic><sub>0</sub>) = <italic>i<sub>h</sub></italic>(<italic>t</italic>; <italic>v<sub>h</sub></italic>), with <italic>v</italic><sub>0</sub> the equilibrium potential, we find the membrane conductance as <disp-formula id="FD7"><label>(7)</label><mml:math id="M7"><mml:mrow><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P41">To visualize <italic>g</italic>(<italic>t</italic>) as in <xref ref-type="fig" rid="F1">Fig 1H</xref>, we subtract the pre-stimulus baseline and plot the min-max envelope obtained over 10 trial runs.</p></sec><sec id="S12"><title>IO curve parameter fitting</title><p id="P42">To obtain the IO curves, we change the number of feedforward inputs in each burst (weights as in <xref ref-type="table" rid="T1">Table 1</xref>), and either have only excitatory inputs (no. of feedforward inputs &gt; 0) or inhibitory inputs (no. of feedforward inputs &lt; 0). For each number of inputs, we present ten independently sampled bursts featuring that number of inputs, and measure the average number of output spikes generated in response.</p><p id="P43">To fit the IO curves (<xref ref-type="fig" rid="F2">Fig 2</xref>), we a use linear least squares fit (argmin<sub><bold>u</bold></sub>‖<italic>A</italic><bold>u</bold> − <bold>y</bold>‖<sub>2</sub>) both for the shared gain and shared bias cases, but construct the feature matrix <italic>A</italic> and parameter vector <bold>u</bold> differently. On the domain where <italic>y</italic> &gt; 0, the IO curve is <disp-formula id="FD8"><label>(8)</label><mml:math id="M8"><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>ff</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mspace width="0.2em"/><mml:mtext>for</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>gain</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>modulation</mml:mtext></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mtext>and</mml:mtext></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>ff</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mspace width="0.2em"/><mml:mtext>for</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>bias</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>modulation</mml:mtext><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula> with <italic>n</italic><sub>ff</sub> the number of feedforward inputs. For M modulation levels, we have parameter vectors <bold>u</bold> = (<italic>g</italic><sub>1</sub>, <italic>g</italic><sub>2</sub>, …, <italic>g<sub>M</sub></italic>, <italic>b</italic>) for gain modulation and <bold>u</bold> = (<italic>g</italic>, <italic>b</italic><sub>1</sub>, <italic>b</italic><sub>2</sub>, …, <italic>b<sub>M</sub></italic>) for bias modulation, and corresponding feature matrices <disp-formula id="FD9"><label>(9)</label><mml:math id="M9"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>ff</mml:mtext><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mo>|</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mo>…</mml:mo></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>ff</mml:mtext><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mo>|</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mo>…</mml:mo></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>ff</mml:mtext><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mo>|</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>…</mml:mo></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>ff</mml:mtext><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mo>|</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>…</mml:mo></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋱</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mo>…</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>ff</mml:mtext><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mo>|</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mo>…</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>ff</mml:mtext><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mo>|</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> for gain modulation and<disp-formula id="FD10"><label>(10)</label><mml:math id="M10"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mo>[</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>ff</mml:mtext><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mo>|</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mo>…</mml:mo></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>ff</mml:mtext><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mo>|</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mo>…</mml:mo></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>ff</mml:mtext><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mo>|</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mo>…</mml:mo></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>ff</mml:mtext><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mo>|</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mo>…</mml:mo></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋱</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>ff</mml:mtext><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mo>|</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mo>…</mml:mo></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>ff</mml:mtext><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mo>|</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mo>…</mml:mo></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:math></disp-formula> for bias modulation, with <italic>n</italic><sub>ff1</sub>|<sub><italic>m</italic></sub> corresponding to the number of feedforward inputs where the output transitioned from 0 to 1 spikes and <italic>n</italic><sub>ff2</sub>|<sub><italic>m</italic></sub> from 1 to 2 spikes, given a modulation level <italic>m</italic>. The output vector <bold>y</bold> = (0.5, 1.5, 0.5, 1.5, …, 0.5, 1.5) was identical in both cases. To extend gain modulation with a shared x-shift, we modified the entries in the gain modulation feature matrix <italic>A</italic> from <italic>n</italic><sub>ff<italic>i</italic></sub>|<sub><italic>m</italic></sub> to <italic>n</italic><sub>ff<italic>i</italic></sub>|<sub><italic>m</italic></sub> − <italic>x</italic><sub>shift</sub> (<italic>i</italic> = 1, 2, <italic>m</italic> = 1, …, <italic>M</italic>) and minimized the fit residual min<sub><bold>u</bold></sub> ‖<italic>A</italic>(<italic>x</italic><sub>shift</sub>)<bold>u</bold> − <bold>y</bold>‖<sub>2</sub> over the <italic>x</italic><sub>shift</sub> values.</p></sec><sec id="S13"><title>Supervised learning in the fully connected networks</title><p id="P44">The fully connected network architectures with neuron-specific modulations consisted of a fixed number of layers of equal size, the final layer connected to a single output unit. The neuron-specific modulations were implemented in an abstract fashion, as task-specific parameters, although it is straightforward to extend the network architecture to implement the modulations as synaptic inputs. The networks were trained through end-to-end error backpropagation. For the networks with task-specific outputs, the hidden units had unit gain (fixed) and a trained bias shared across tasks, and as many output units as there were tasks. The hidden layer neurons had ReLU transfer functions and the output unit a tanh(·) transfer function. The networks were implemented in PyTorch<sup><xref ref-type="bibr" rid="R89">89</xref></sup>, trained on batches of size 1000 using Adam<sup><xref ref-type="bibr" rid="R90">90</xref></sup> and we computed the mean squared error between target and network output as loss. The targets were defined as either −1 or +1, and a custom sampler assured batches consisted of an equal number of samples from each task and task-class. The training was interrupted with an early stopping criterion with a patience of 5 epochs on the validation performance evaluated after each epoch on a validation set of 47932 samples, or after 50 epochs, whichever came first. Independent learning rates for shared and task-specific parameters were optimized for each form of multitask leaning separately with an iterative grid search (<xref ref-type="supplementary-material" rid="SD1">Fig S1C</xref>). Performances are measured by averaging over all tasks, and by additionally averaging over twenty initialization seeds (error bars show standard deviation of task-performance across seeds, averaged over all tasks).</p></sec><sec id="S14"><title>Decision boundary normal vectors</title><p id="P45">To explain our approach, we consider the pre-activation <italic>a</italic> : ℝ<sup><italic>n</italic></sup> → ℝ : <bold>x</bold> → <italic>a</italic>(<bold>x</bold>) of a neuron in a feedforward network as a function of the sensory input <bold>x</bold> (the activation <italic>y</italic> being given by <italic>y</italic>(<bold>x</bold>) = <italic>σ</italic>(<italic>a</italic>(<bold>x</bold>))). Biophysically, this quantity most closely corresponds with the somatic voltage under Na<sup>+</sup>-channel blockage; it is the aggregate of all inputs and when it crosses a threshold, the neuron would emit a spike if the non-linear activation function (the Na<sup>+</sup>-channels) were applied. The neuron may be active (<italic>a</italic>(<bold>x</bold>) &gt; 0) or inactive (<italic>a</italic>(<bold>x</bold>) &lt; 0), and its decision boundary on the input domain is given by the set D = {<bold>x</bold><sub>D</sub> ∈ ℝ<sup><italic>n</italic></sup> | <italic>a</italic>(<bold>x</bold><sub>D</sub>) = 0}. In a small enough region around a point <bold>x</bold><sub>D</sub> ∈ D, <italic>a</italic>(<bold>x</bold>) can be approximated as being linear: <disp-formula id="FD11"><label>(11)</label><mml:math id="M11"><mml:mrow><mml:mi>a</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold"><mml:mtext>x</mml:mtext></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo>≃</mml:mo><mml:msub><mml:mstyle mathvariant="bold"><mml:mtext>W</mml:mtext></mml:mstyle><mml:mo>⊥</mml:mo></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold"><mml:mtext>x</mml:mtext></mml:mstyle><mml:mo>−</mml:mo><mml:msub><mml:mstyle mathvariant="bold"><mml:mtext>x</mml:mtext></mml:mstyle><mml:mtext>D</mml:mtext></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula> and <inline-formula><mml:math id="M12"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext></mml:mstyle><mml:mo>⊥</mml:mo></mml:msub><mml:mo>≔</mml:mo><mml:mfrac><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>a</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold"><mml:mtext>x</mml:mtext></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mtext>d</mml:mtext><mml:mstyle mathvariant="bold"><mml:mtext>x</mml:mtext></mml:mstyle></mml:mrow></mml:mfrac><mml:msub><mml:mo>|</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mtext>D</mml:mtext></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the local normal vector of the decision boundary. This normal vector is always a linear sum of the input weight vectors <bold>w</bold><sub><italic>j</italic></sub> to the first layer neurons (<italic>j</italic> = 1, …,<italic>k</italic>, with <italic>k</italic> the number of neurons in the first layer), and is perpendicular to the local decision boundary (see <xref ref-type="sec" rid="S10">methods</xref>), thus capturing the local input features that <italic>a</italic> uses to make a decision about whether to become active close to <bold>x</bold><sub>D</sub> (<xref ref-type="fig" rid="F4">Fig 4A</xref>).</p><p id="P46">First, we note that for input <bold>x</bold> ∈ D on the decision boundary D close enough to <bold>x</bold><sub>D</sub>, <italic>a</italic>(<italic>x</italic>) = 0, and thus, following (11): <disp-formula id="FD12"><label>(12)</label><mml:math id="M13"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext></mml:mstyle><mml:mo>⊥</mml:mo></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold"><mml:mtext>x</mml:mtext></mml:mstyle><mml:mo>−</mml:mo><mml:msub><mml:mstyle mathvariant="bold"><mml:mtext>x</mml:mtext></mml:mstyle><mml:mtext>D</mml:mtext></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>≈</mml:mo><mml:mn>0.</mml:mn></mml:mrow></mml:math></disp-formula></p><p id="P47">By consequence, <bold>w</bold><sub>⊥</sub> is perpendicular to the local decision boundary and indeed its normal vector.</p><p id="P48">Second, we compute <bold>w</bold><sub>⊥</sub> explicitly, and to that purpose write the preactivation <italic>a</italic> of a neuron in layer K of the network as: <disp-formula id="FD13"><label>(13)</label><mml:math id="M14"><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="right"><mml:mi>a</mml:mi></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>g</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext></mml:mstyle><mml:msup><mml:mstyle mathvariant="bold"><mml:mtext>y</mml:mtext></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>K</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mtext>xshift</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mstyle mathvariant="bold"><mml:mtext>y</mml:mtext></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:msup><mml:mstyle mathvariant="bold"><mml:mtext>g</mml:mtext></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⊙</mml:mo><mml:mo>(</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mstyle mathvariant="bold"><mml:mtext>y</mml:mtext></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msubsup><mml:mstyle mathvariant="bold"><mml:mtext>x</mml:mtext></mml:mstyle><mml:mrow><mml:mtext>xshift</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mstyle mathvariant="bold"><mml:mtext>b</mml:mtext></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mspace width="1.2em"/><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mstyle mathvariant="bold"><mml:mtext>y</mml:mtext></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mstyle mathvariant="bold"><mml:mtext>x</mml:mtext></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula> with <bold>y</bold><sup>(<italic>i</italic>)</sup> the neural activations in layer <italic>i</italic>, <italic>σ</italic> : ℝ → ℝ the neural activation function applied element-wise to its inputs, <italic>W</italic><sup>(<italic>i</italic>)</sup> the weight matrix from layer <italic>i</italic> − 1 to layer <italic>i</italic>, <bold>g</bold><sup>(<italic>i</italic>)</sup>, <inline-formula><mml:math id="M15"><mml:mrow><mml:msubsup><mml:mtext mathvariant="bold">x</mml:mtext><mml:mrow><mml:mtext>xshift</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> resp. <bold>b</bold><sup>(<italic>i</italic>)</sup> the gains, x-shifts resp. biases in layer <italic>i</italic>, <italic>w</italic> the weight vector to the neuron and <italic>g</italic>, <italic>x</italic><sub>xshift</sub> resp. <italic>b</italic> its gain, x-shift and bias. <bold>w</bold><sub>⊥</sub> is then found as <disp-formula id="FD14"><label>(14)</label><mml:math id="M16"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext></mml:mstyle><mml:mo>⊥</mml:mo></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold"><mml:mtext>x</mml:mtext></mml:mstyle><mml:mtext>D</mml:mtext></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>g</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext></mml:mstyle><mml:mfrac><mml:mrow><mml:mtext>d</mml:mtext><mml:msup><mml:mstyle mathvariant="bold"><mml:mtext>y</mml:mtext></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>K</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mtext>d</mml:mtext><mml:msup><mml:mstyle mathvariant="bold"><mml:mtext>y</mml:mtext></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>K</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>⋯</mml:mo><mml:mfrac><mml:mrow><mml:mtext>d</mml:mtext><mml:msup><mml:mstyle mathvariant="bold"><mml:mtext>y</mml:mtext></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mtext>d</mml:mtext><mml:msup><mml:mstyle mathvariant="bold"><mml:mtext>y</mml:mtext></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mtext>d</mml:mtext><mml:msup><mml:mstyle mathvariant="bold"><mml:mtext>y</mml:mtext></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mtext>d</mml:mtext><mml:mstyle mathvariant="bold"><mml:mtext>x</mml:mtext></mml:mstyle></mml:mrow></mml:mfrac><mml:msub><mml:mo>|</mml:mo><mml:mrow><mml:mstyle mathvariant="bold"><mml:mtext>x</mml:mtext></mml:mstyle><mml:mo>=</mml:mo><mml:msub><mml:mstyle mathvariant="bold"><mml:mtext>x</mml:mtext></mml:mstyle><mml:mtext>D</mml:mtext></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula> with d<bold>y</bold><sup>(<italic>i</italic>)</sup>/d<bold>y</bold><sup>(<italic>i</italic>−1)</sup> the Jacobian matrix of <bold>y</bold><sup>(<italic>i</italic>)</sup> with respect to <bold>y</bold><sup>(<italic>i</italic>−1)</sup>. This Jacobian is given by <disp-formula id="FD15"><label>(15)</label><mml:math id="M17"><mml:mrow><mml:mtext>d</mml:mtext><mml:msup><mml:mstyle mathvariant="bold"><mml:mtext>y</mml:mtext></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>/</mml:mo><mml:msup><mml:mrow><mml:mtext>d</mml:mtext><mml:mstyle mathvariant="bold"><mml:mtext>y</mml:mtext></mml:mstyle></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mspace width="0.6em"/><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mtext>diag</mml:mtext><mml:mo>(</mml:mo><mml:mo>(</mml:mo><mml:msup><mml:mstyle mathvariant="bold"><mml:mtext>g</mml:mtext></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⊙</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>(</mml:mo><mml:msup><mml:mstyle mathvariant="bold"><mml:mtext>g</mml:mtext></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⊙</mml:mo><mml:mo>(</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mstyle mathvariant="bold"><mml:mtext>y</mml:mtext></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msubsup><mml:mstyle mathvariant="bold"><mml:mtext>x</mml:mtext></mml:mstyle><mml:mrow><mml:mtext>xshift</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mstyle mathvariant="bold"><mml:mtext>b</mml:mtext></mml:mstyle><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo><mml:mo>)</mml:mo><mml:mo>)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P49">Thus, we find for (14): <disp-formula id="FD16"><label>(16)</label><mml:math id="M18"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext></mml:mstyle><mml:mo>⊥</mml:mo></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold"><mml:mtext>x</mml:mtext></mml:mstyle><mml:mtext>D</mml:mtext></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>g</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>K</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>K</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⋯</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P50">By rearranging this matrix product, we obtain <disp-formula id="FD17"><label>(17)</label><mml:math id="M19"><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext></mml:mstyle><mml:mo>⊥</mml:mo></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold"><mml:mtext>x</mml:mtext></mml:mstyle><mml:mtext>D</mml:mtext></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mstyle mathsize="140%" displaystyle="true"><mml:mi>∑</mml:mi></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>k</mml:mi></mml:munderover><mml:munder><mml:munder><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>g</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>K</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>K</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⋯</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msubsup><mml:mstyle mathvariant="bold"><mml:mtext>d</mml:mtext></mml:mstyle><mml:mrow><mml:mo>:</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">︸</mml:mo></mml:munder><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold"><mml:mtext>x</mml:mtext></mml:mstyle><mml:mtext>D</mml:mtext></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:msubsup><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>:</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mstyle mathsize="140%" displaystyle="true"><mml:mi>∑</mml:mi></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>k</mml:mi></mml:munderover><mml:msub><mml:mi>c</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold"><mml:mtext>x</mml:mtext></mml:mstyle><mml:mtext>D</mml:mtext></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>:</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula> a linear weighted sum of the inputs weight vectors (with <inline-formula><mml:math id="M20"><mml:mrow><mml:msubsup><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>:</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> the <italic>j</italic>’th row of <italic>W</italic><sup>(1)</sup> and <inline-formula><mml:math id="M21"><mml:mrow><mml:msubsup><mml:mstyle mathvariant="bold"><mml:mtext>d</mml:mtext></mml:mstyle><mml:mrow><mml:mo>:</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> the <italic>j</italic>’th column of <italic>D</italic><sup>(1)</sup>).</p></sec><sec id="S15"><title>Unsupervised learning of weights combined with supervised gain modulation</title><p id="P51">The unsupervised optimization problems for PCA, ΔPCA, SC, SD, and ΔSD are solved using Scikit-learn<sup><xref ref-type="bibr" rid="R91">91</xref></sup>, and for PMD and ΔPMD we use a custom implementation. The networks consisted of a single hidden layer, with weights resulting from optimising the loss functions in <xref ref-type="table" rid="T2">Table 2</xref> (for RP, weights were drawn from a Gaussian distribution and then normalized so that <inline-formula><mml:math id="M22"><mml:mrow><mml:mo>∥</mml:mo><mml:msubsup><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>:</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mo>∥</mml:mo><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>). Weights to the output unit were uniform, and also normalized to have unit Euclidean norm (<inline-formula><mml:math id="M23"><mml:mrow><mml:msup><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext></mml:mstyle><mml:mrow><mml:mtext>out</mml:mtext></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:msqrt><mml:mi>k</mml:mi></mml:msqrt></mml:mrow></mml:math></inline-formula>, with <italic>k</italic> the dimensionality of the hidden layer). Activation functions, target outputs, the optimizer and the way in which performance was measured were identical to the fully supervised networks.</p><p id="P52">We optimized gains for each task separately by performing gradient descent with batches of 100 samples, and performed an evolutionary meta-parameter optimization using DEAP<sup><xref ref-type="bibr" rid="R92">92</xref></sup> to find optimal values for x-shift, bias, and learning rate by maximizing validation performance on a subset of 10 tasks (<xref ref-type="supplementary-material" rid="SD1">Fig S4C</xref>).</p><p id="P53">To construct <xref ref-type="fig" rid="F4">Fig 4G</xref>, we evaluate the residual min<sub><italic>C</italic></sub> ‖Δ<italic>X</italic> − <italic>CW</italic>‖ of the reconstruction loss (3) during supervised training without regularizer or constraint (i.e. the least mean squares optimum with respect to <italic>C</italic>) on matrices Δ<italic>X</italic> containing 1000 differences.</p></sec><sec id="S16"><title>Loss gradient with respect to task gains as a Hebbian learning rule with global error modulation</title><p id="P54">Here, we show that in the network architecture described in the previous section, the error gradient with respect to the task-dependent gains can be expressed as a Hebbian learning rule modulated by a global error signal. We interpret task-dependent gains to the hidden neurons with activity <italic>y<sub>i</sub></italic> (<italic>i</italic> = 1, …,<italic>k</italic>) as synaptic inputs originating from task-encoding neurons. With <italic>g<sub>i,t</sub></italic> the weight of the connection to neuron <italic>i</italic> associated with task <italic>t</italic>, and <italic>z<sub>t</sub></italic> ∈ {0, 1} the activity of the associated task-encoding neuron (1 if the task is active and 0 otherwise), the total gain is <italic>g</italic> = ∑<sub><italic>t</italic></sub> <italic>g<sub>i,t</sub>z<sub>t</sub></italic>.</p><p id="P55">The structure of these networks then becomes <disp-formula id="FD18"><label>(18)</label><mml:math id="M24"><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:munder><mml:mstyle mathsize="140%" displaystyle="true"><mml:mi>∑</mml:mi></mml:mstyle><mml:mi>t</mml:mi></mml:munder><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>z</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mstyle mathvariant="bold"><mml:mtext>x</mml:mtext></mml:mstyle><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mtext>shift</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mspace width="0.6em"/><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mtext>tanh</mml:mtext><mml:mo>(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:munder><mml:mstyle mathsize="140%" displaystyle="true"><mml:mi>∑</mml:mi></mml:mstyle><mml:mi>t</mml:mi></mml:munder><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>z</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mstyle mathsize="140%" displaystyle="true"><mml:mi>∑</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mi>k</mml:mi></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>ℒ</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>o</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula> with <italic>y<sub>o</sub></italic> the activity of the output neuron, <italic>b<sub>o</sub></italic> its bias and <italic>g<sub>o,t</sub></italic> the weight of the task-gain connection to the output neuron. <italic>ŷ<sub>o,t</sub></italic> ∈ −1, 1 is the task-dependent target value for a given input sample. Computing the gradient of the task-loss <inline-formula><mml:math id="M25"><mml:mrow><mml:msub><mml:mi>ℒ</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> with respect to the task-gains in the hidden layer yields <disp-formula id="FD19"><label>(19)</label><mml:math id="M26"><mml:mrow><mml:mfrac><mml:mrow><mml:mtext>d</mml:mtext><mml:msub><mml:mi>ℒ</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mtext>d</mml:mtext><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:munder><mml:munder><mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>o</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>tan</mml:mi><mml:msup><mml:mtext>h</mml:mtext><mml:mo>′</mml:mo></mml:msup><mml:mo>(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:msub><mml:mstyle mathsize="140%" displaystyle="true"><mml:mi>∑</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mi>k</mml:mi></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>)</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mi>k</mml:mi></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow><mml:mo stretchy="true">︸</mml:mo></mml:munder><mml:mi>ε</mml:mi></mml:munder><mml:munder><mml:munder><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mstyle mathvariant="bold"><mml:mtext>x</mml:mtext></mml:mstyle><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mtext>shift</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mstyle mathvariant="bold"><mml:mtext>x</mml:mtext></mml:mstyle><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mtext>shift</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="true">︸</mml:mo></mml:munder><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:munder><mml:munder><mml:munder><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">︸</mml:mo></mml:munder><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:munder><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P56">One crucial observation here is that since the feedforward weights to the output unit are all identical, they do not modify the error signal in a neuron-specific manner. By consequence, the error signal to the hidden layer is global, i.e. identical for all hidden neurons. A second crucial observation is that while it may seem as if the <italic>post</italic> factor could change the sign of the gradient, if <disp-formula id="FD20"><label>(20)</label><mml:math id="M27"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mstyle mathvariant="bold"><mml:mtext>x</mml:mtext></mml:mstyle><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mtext>shift</mml:mtext></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula> this is actually impossible with the ReLU activation function (which results in <italic>σ</italic>′ ∈ {0, 1}), and positive gains together with negative bias, as obtained from the L5 PC model. Indeed, for the neuron to be active (<italic>σ</italic>′ = 1), the inputs need to be sufficiently strong, so that <disp-formula id="FD21"><label>(21)</label><mml:math id="M28"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mstyle mathvariant="bold"><mml:mtext>x</mml:mtext></mml:mstyle><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mtext>shift</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⇒</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mstyle mathvariant="bold"><mml:mtext>x</mml:mtext></mml:mstyle><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mtext>shift</mml:mtext></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mi>b</mml:mi><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula> where the second inequality holds because we have negative bias and positive gains. Thus, whenever (20) is satisfied, the neuron is inactive (<italic>σ</italic>′ = 0) and <bold>w</bold><sub><italic>i</italic></sub><bold>x</bold> − <italic>x</italic><sub>shift</sub> does not influence the update of <italic>g<sub>i,t</sub></italic>. We will leverage this fact in the spiking neural network, where we replace the <italic>post</italic> factor by a low pass filter of the somatic output spikes to obtain a learning rule that follows the approximate gradient.</p></sec><sec id="S17"><title>Spiking network</title><p id="P57">In order to simulate the network model, which consisted of one hidden layer with 100 neurons, over sufficiently long time scales to allow significant learning, we reduced the L5 PC model by retaining only the dendritic compartments and the soma (<xref ref-type="fig" rid="F5">Fig 5A</xref>), using the method proposed by Wybo et al.<sup><xref ref-type="bibr" rid="R55">55</xref></sup> to conserve dendro-somatic response properties. We then equip each dendritic compartment with an AMPA+NMDA synapse for each context – 47 in multitask EMNIST (<xref ref-type="fig" rid="F5">Fig 5</xref>) and 14 for the boolean tasks (<xref ref-type="supplementary-material" rid="SD1">Fig S3</xref>) – whose weight evolved according to <disp-formula id="FD22"><label>(22)</label><mml:math id="M29"><mml:mrow><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mtext>dend</mml:mtext></mml:mrow></mml:msub><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mtext>post</mml:mtext></mml:mrow></mml:msub><mml:mi>ε</mml:mi></mml:mrow></mml:math></disp-formula> with <italic>η</italic><sub>dend</sub> a learning rate dependent on a low-pass filter <italic>u</italic><sub>dend</sub> of the local dendritic voltage <italic>v</italic><sub>dend</sub>, <italic>u</italic><sub>pre</sub> a low pass filter of the input spikes to the contextual synapse, <italic>u</italic><sub>post</sub> a low pass filter of the output spikes and <italic>ε</italic> a global error signal, implemented as the low pass filter of an error pulse whose amplitude <italic>a<sub>e</sub></italic> was proportional to the difference between the number of generated output spikes in the ‘reward window’ and the expected number (i.e. 0 or 1). This 50 ms reward window opened upon the arrival of the first feedforward input spike associated with a data sample. A delta pulse with amplitude <italic>a<sub>ε</sub></italic> was then injected into <italic>ε</italic> at the closure time <italic>t<sub>e</sub></italic> of this reward window. Summarizing the above, we had the following: <disp-formula id="FD23"><label>(23)</label><mml:math id="M30"><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mrow><mml:mtext>dend</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mtext>dend</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mtext>dend</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mtext>dend</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mtext>dend</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>for</mml:mtext><mml:mspace width="0.2em"/><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mtext>dend</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>for</mml:mtext><mml:mspace width="0.2em"/><mml:msub><mml:mi>θ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mtext>dend</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>for</mml:mtext><mml:mspace width="0.2em"/><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mtext>dend</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:munder><mml:mstyle mathsize="140%" displaystyle="true"><mml:mi>∑</mml:mi></mml:mstyle><mml:mrow><mml:mi>s</mml:mi><mml:mo>∈</mml:mo><mml:mtext>pre</mml:mtext></mml:mrow></mml:munder><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mrow><mml:mtext>post</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mtext>post</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mtext>post</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:munder><mml:mstyle mathsize="140%" displaystyle="true"><mml:mi>∑</mml:mi></mml:mstyle><mml:mrow><mml:mi>s</mml:mi><mml:mo>∈</mml:mo><mml:mtext>post</mml:mtext></mml:mrow></mml:munder><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mtext>post</mml:mtext></mml:mrow></mml:msub><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mspace width="1.2em"/><mml:mrow><mml:mover accent="true"><mml:mi>ε</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>ε</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>ε</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:munder><mml:mstyle mathsize="140%" displaystyle="true"><mml:mi>∑</mml:mi></mml:mstyle><mml:mi>e</mml:mi></mml:munder><mml:msub><mml:mi>a</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p id="P58">Note that <italic>η</italic><sub>dend</sub>, <italic>u</italic><sub>dend</sub>, <italic>u</italic><sub>pre</sub> and <italic>u</italic><sub>post</sub> are all specific to the synapse, whereas <italic>ε</italic> is global and shared across all synapses. Model parameters are summarized in <xref ref-type="table" rid="T3">Table 3</xref>.</p><p id="P59">To ensure that the combined feedforward post-synaptic potential (PSP) varied within a reasonable dynamic range, we took the feedforwards weights derived previously (ΔPMD, ΔSD, PCA, and RP to the hidden layer, and <inline-formula><mml:math id="M31"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:msqrt><mml:mi>k</mml:mi></mml:msqrt></mml:mrow></mml:math></inline-formula> to the output neuron) and applied a scale factor <disp-formula id="FD24"><label>(24)</label><mml:math id="M32"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>w</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mtext>range</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>∥</mml:mo><mml:msub><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext></mml:mstyle><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:msub><mml:msub><mml:mo>∥</mml:mo><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:msub><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula> to the input weight vector <bold>w</bold><sub>in</sub> of each neuron, with <italic>z</italic><sub>in</sub> the somatic input resistance of the L5 PC, <italic>v</italic><sub>range</sub> a voltage range parameter and <italic>n</italic><sub>in</sub> the number of feedforward inputs (<italic>n</italic> = 784 for a neuron in the hidden layer and <italic>k</italic> = 100 for the output neuron in multitask EMNIST, and <italic>n</italic> = 2 and <italic>k</italic> = {4, 10} for the boolean tasks). <italic>v</italic><sub>range</sub> is a parameter that allowed us to fine tune the dynamic range of the combined feedforward PSPs. For the hidden neurons, <italic>v</italic><sub>range</sub> was set heuristically to 120 mV on multitask EMNIST and 60 mV on the boolean tasks, and for the output neuron, <italic>v</italic><sub>range</sub> was set to 450 mV on multitask EMNIST and 600 mV on the boolean tasks. Together with <italic>z</italic><sub>in</sub>, this yielded feedforward weights in nA.</p><p id="P60">To train this system, we presented 600000 samples for each task in multitask EMNIST (balanced across task-classes, so repetition of the same sample may occur) by converting them to Gaussian input spike bursts (the number of input spikes in a burst varied between 0 and 10 and was proportional to pixel intensity), and injecting these burst in the network at 150 ms intervals. We then froze the plasticity rule and tested performance on 500 samples for each task taken from the EMNIST test set (again balanced across task-classes).</p></sec><sec id="S18"><title>Task-modulated contrastive learning</title><p id="P61">For TMCL (<xref ref-type="fig" rid="F6">Fig 6</xref>), we convert CIFAR-10<sup><xref ref-type="bibr" rid="R61">61</xref></sup> into a multitask learning problem (multitask CIFAR-10) as before, by defining 10 1-vs-all classification tasks, and sampled data in a balanced manner across tasks and task-classes. We kept 9000 samples as validation set. Each color channel was centered, then normalized to unit variance.</p><p id="P62">We implement a visual geometry group-like (VGG) architecture following Illing et al.<sup><xref ref-type="bibr" rid="R33">33</xref></sup> Precisely, we train a stack of <italic>L</italic> convolutional layers with kernel size 3, stride 1 and 64 channels, and applied batch normalization<sup><xref ref-type="bibr" rid="R93">93</xref></sup> to the task-modulated convolution outputs before applying the ReLU activation function. Batch normalization renders the task-independent bias <italic>b</italic> obsolete; it was not included in our simulations. By consequence, the output of a convolutional unit was <disp-formula id="FD25"><label>(25)</label><mml:math id="M33"><mml:mrow><mml:mtext>ReLU</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mtext>BatchNorm</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo>∗</mml:mo><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mtext>shift</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula> where <italic>x</italic> denotes the image patch, <italic>w</italic> refers to the respective convolutional filter, * denotes the convolution operation, and <italic>g<sub>t</sub></italic> the task-specific gain. Every second layer was succeeded by a MaxPool layer with stride 2x2.</p><p id="P63">Our approach learns a stack of convolutional layers iteratively, by adding the next layer on top of the previously learnt ones. Each iteration consists of two distinct phases: first, feedforward filters to the next layer are learned through CL, and subsequently we learn task- and neuron-specific gains for the new layer in a supervised manner.</p><p id="P64">For CL phase, we follow the SimCLR algorithm<sup><xref ref-type="bibr" rid="R60">60</xref></sup>. We use the same image augmentations that the authors used on their CIFAR-10 experiments: <preformat preformat-type="computer code">random_resized_crop(32, scale=(0.08, 1.0), ratio=(1., 1.))

random_horizontal_flip(p=0.5)

color_jitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1, p=0.8)

random_grayscale(p=0.2)</preformat> followed by standard score normalization according to the statistics of the original dataset. To train the filters from layer <italic>l</italic> − 1 to layer <italic>l</italic> (<italic>l</italic> = 1, …,<italic>L</italic>), we first generate batches of augmented hidden representations in layer <italic>l</italic> − 1. With <italic>x</italic><sub>1</sub>, …,<italic>x<sub>N</sub></italic> a batch of input samples (see <xref ref-type="table" rid="T4">Table 4</xref> for batch size), we generate an augmented batch <inline-formula><mml:math id="M34"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mn>2</mml:mn><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> of twice the original size, with samples <inline-formula><mml:math id="M35"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> being positive pairs, i.e. generated through image augmentations from the same source sample <italic>x<sub>k</sub></italic>. We then propagate this augmented batch through the hierarchy to layer <italic>l</italic> − 1, while applying task-gains from a random task to each augmented sample, to obtain a batch of task-modulated hidden representations <inline-formula><mml:math id="M36"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mn>2</mml:mn><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. Next, the convolutions with the to be learned filters from layer <italic>l</italic> − 1 to layer <italic>l</italic> are computed and the ReLU is applied to obtain the representation that is fed into the CL-MLP. The CL-MLP consists of a hidden layer and an output layer with dimension 64, and uses ReLU activation. The similarity <italic>s<sub>i,j</sub></italic> between representations <italic>z<sub>i</sub></italic> and <italic>z<sub>j</sub></italic> obtained from final layer of the CL-MLP is computed as their cosine similarity <disp-formula id="FD26"><label>(26)</label><mml:math id="M37"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mo>‖</mml:mo><mml:mn>2</mml:mn></mml:msub><mml:mo>‖</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mo>‖</mml:mo><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P65">The loss was computed as <disp-formula id="FD27"><mml:math id="M38"><mml:mrow><mml:mi>ℒ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:munderover><mml:mstyle mathsize="140%" displaystyle="true"><mml:mi>∑</mml:mi></mml:mstyle><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mo stretchy="false">[</mml:mo><mml:mi>ℓ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>ℓ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula> with <disp-formula id="FD28"><label>(27)</label><mml:math id="M39"><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mtext>log</mml:mtext><mml:mfrac><mml:mrow><mml:mtext>exp</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msubsup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mi>∑</mml:mi></mml:mstyle><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>l</mml:mi><mml:mo>≠</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mtext>exp</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula> and temperature <italic>τ</italic> = 0.5. The error gradient of this loss is then used to train the filters from layer <italic>l</italic> − 1 to layer <italic>l</italic>. All parameters, including convolutional filters, for layers &lt; <italic>l</italic> − 1 remained frozen. For <italic>l</italic> = 1, layer <italic>l</italic> − 1 is the input layer and no task-modulation could be applied, so that <inline-formula><mml:math id="M40"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:mo>≡</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>.</p><p id="P66">To perform the classification for all one-vs-all tasks, we reduce the height and width axes by averaging, retaining a 64-dimensional vector with the per-channel averages. Finally, an output unit applies tanh(·) to the inner product of the 64-dimensional representation vector and a learned, task-independent weight vector <bold>w</bold><sub>out</sub>. Task-specific gains in layer <italic>l</italic> are then trained to minimize the classification loss (same as in our fully connected architectures) at the output unit (test performance at this output unit is what is reported in <xref ref-type="fig" rid="F6">Fig 6B,C</xref>), and the process is continued recursively at layer <italic>l</italic> + 1.</p><p id="P67">Except for the task-specific gains, all parameters (i.e. the CL-MLP parameters, convolutional filters, the x-shift and the output unit) follow the Kaiming initialization, a standard approach in the VGG literature<sup><xref ref-type="bibr" rid="R94">94</xref></sup>. For the task-specific gains, we tested the following initialization strategies <list list-type="bullet" id="L1"><list-item><p id="P68"><bold>Constant(1):</bold> Initialize each entry to 1.</p></list-item><list-item><p id="P69"><bold>Rademacher:</bold> Sample each entry from Uniform{−1, 1}.</p></list-item><list-item><p id="P70"><bold>KaimingUniform:</bold> Each entry is sampled i.i.d. from Uniform(−<italic>γ</italic>, <italic>γ</italic>) with <inline-formula><mml:math id="M41"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:msqrt><mml:mrow><mml:mfrac><mml:mn>3</mml:mn><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula> and where <italic>n</italic><sub>in</sub> is the number of inputs targeting a given unit.</p></list-item><list-item><p id="P71"><bold>Rademacher+KaimingUniform:</bold> Sample each entry from <bold>Rademacher</bold>, then add a sample from <bold>KaimingUniform</bold> to each entry.</p></list-item></list></p><p id="P72">The final performance numbers reported were selected from the grid search described in <xref ref-type="table" rid="T4">Table 4</xref>, according to the best accuracy on the validation set. All experiments were implemented in PyTorch<sup><xref ref-type="bibr" rid="R89">89</xref></sup> and training was performed using Adam<sup><xref ref-type="bibr" rid="R90">90</xref></sup>.</p></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary Figures</label><media xlink:href="EMS157690-supplement-Supplementary_Figures.pdf" mimetype="application" mime-subtype="pdf" id="d29aAdEbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S19"><title>Acknowledgements</title><p>We thank Angela Fischer and Dr. Sanne Rutten for generous help with the schematic diagrams in this paper. This work was supported by the Helmholtz Portfolio theme Supercomputing and Modeling for the Human Brain, the Excellence Strategy of the Federal Government and the Länder [G:(DE-82)EXS-PF-JARA-SDS005, G:(DE-82)EXS-SF-neuroIC002] and by the Swiss National Science Foundation (Grant 180316 to WS). The project received additional funding from the European Union’s Horizon 2020 research and innovation programme under Specific Grant Agreement Nos. 720270, 785907 and 945539 (Human Brain Project SGA1-3). The authors gratefully acknowledge the computing time granted by the JARA Vergabegremium and provided on the JARA Partition part of the supercomputer JURECA at Forschungszentrum Jülich (Grant 25241 to WW). We also thank the Insel Data Science Center for using their HPC Cluster.</p></ack><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Riesenhuber</surname><given-names>M</given-names></name><name><surname>Poggio</surname><given-names>T</given-names></name></person-group><article-title>Hierarchical models of object recognition in cortex</article-title><source>Nature Neuroscience</source><year>1999</year><volume>2</volume><fpage>1019</fpage><lpage>1025</lpage><pub-id pub-id-type="pmid">10526343</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Siegle</surname><given-names>JH</given-names></name><etal/></person-group><article-title>Survey of spiking in the mouse visual system reveals functional hierarchy</article-title><source>Nature</source><year>2021</year><pub-id pub-id-type="pmid">33473216</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname><given-names>DH</given-names></name><name><surname>Wiesel</surname><given-names>TN</given-names></name></person-group><article-title>Receptive fields, binocular interaction and functional architecture in the cat’s visual cortex</article-title><source>The Journal of physiology</source><year>1962</year><volume>160</volume><fpage>106</fpage><lpage>154</lpage><pub-id pub-id-type="pmcid">PMC1359523</pub-id><pub-id pub-id-type="pmid">14449617</pub-id><pub-id pub-id-type="doi">10.1113/jphysiol.1962.sp006837</pub-id></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Formisano</surname><given-names>E</given-names></name><etal/></person-group><article-title>Mirror-Symmetric Tonotopic Maps in Human Primary Auditory Cortex</article-title><source>Neuron</source><year>2003</year><volume>40</volume><fpage>859</fpage><lpage>869</lpage><pub-id pub-id-type="pmid">14622588</pub-id></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bruce</surname><given-names>C</given-names></name><name><surname>Desimone</surname><given-names>R</given-names></name><name><surname>Gross</surname><given-names>CG</given-names></name></person-group><article-title>Visual properties of neurons in a polysensory area in superior temporal sulcus of the macaque</article-title><source>Journal of Neurophysiology</source><year>1981</year><volume>46</volume><fpage>369</fpage><lpage>384</lpage><pub-id pub-id-type="pmid">6267219</pub-id></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Landi</surname><given-names>SM</given-names></name><name><surname>Viswanathan</surname><given-names>P</given-names></name><name><surname>Serene</surname><given-names>S</given-names></name><name><surname>Freiwald</surname><given-names>WA</given-names></name></person-group><article-title>A fast link between face perception and memory in the temporal pole</article-title><source>Science</source><year>2021</year><volume>373</volume><fpage>581</fpage><lpage>585</lpage><pub-id pub-id-type="pmcid">PMC8645414</pub-id><pub-id pub-id-type="pmid">34210891</pub-id><pub-id pub-id-type="doi">10.1126/science.abi6671</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mesgarani</surname><given-names>N</given-names></name><name><surname>Chang</surname><given-names>EF</given-names></name></person-group><article-title>Selective cortical representation of attended speaker in multi-talker speech perception</article-title><source>Nature</source><year>2012</year><volume>485</volume><fpage>233</fpage><lpage>236</lpage><pub-id pub-id-type="pmcid">PMC3870007</pub-id><pub-id pub-id-type="pmid">22522927</pub-id><pub-id pub-id-type="doi">10.1038/nature11020</pub-id></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chan</surname><given-names>AM</given-names></name><etal/></person-group><article-title>Speech-Specific Tuning of Neurons in Human Superior Temporal Gyrus</article-title><source>Cerebral Cortext</source><year>2014</year><volume>24</volume><fpage>2679</fpage><lpage>93</lpage><pub-id pub-id-type="pmcid">PMC4162511</pub-id><pub-id pub-id-type="pmid">23680841</pub-id><pub-id pub-id-type="doi">10.1093/cercor/bht127</pub-id></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yamins</surname><given-names>DLK</given-names></name><etal/></person-group><article-title>Performance-optimized hierarchical models predict neural responses in higher visual cortex</article-title><source>Proceedings of the National Academy of Sciences</source><year>2014</year><volume>111</volume><fpage>8619</fpage><lpage>8624</lpage><pub-id pub-id-type="pmcid">PMC4060707</pub-id><pub-id pub-id-type="pmid">24812127</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1403112111</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hong</surname><given-names>H</given-names></name><name><surname>Yamins</surname><given-names>DLK</given-names></name><name><surname>Majaj</surname><given-names>NJ</given-names></name><name><surname>DiCarlo</surname><given-names>JJ</given-names></name></person-group><article-title>Explicit information for category-orthogonal object properties increases along the ventral stream</article-title><source>Nature Neuroscience</source><year>2016</year><volume>19</volume><fpage>613</fpage><lpage>622</lpage><pub-id pub-id-type="pmid">26900926</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilbert</surname><given-names>CD</given-names></name><name><surname>Li</surname><given-names>W</given-names></name></person-group><article-title>Top-down influences on visual processing</article-title><source>Nature Reviews Neuroscience</source><year>2013</year><volume>14</volume><fpage>350</fpage><lpage>363</lpage><pub-id pub-id-type="pmcid">PMC3864796</pub-id><pub-id pub-id-type="pmid">23595013</pub-id><pub-id pub-id-type="doi">10.1038/nrn3476</pub-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roth</surname><given-names>MM</given-names></name><etal/></person-group><article-title>Thalamic nuclei convey diverse contextual information to layer 1 of visual cortex</article-title><source>Nature Neuroscience</source><year>2016</year><volume>19</volume><fpage>299</fpage><lpage>307</lpage><pub-id pub-id-type="pmcid">PMC5480596</pub-id><pub-id pub-id-type="pmid">26691828</pub-id><pub-id pub-id-type="doi">10.1038/nn.4197</pub-id></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mineault</surname><given-names>PJ</given-names></name><name><surname>Tring</surname><given-names>E</given-names></name><name><surname>Trachtenberg</surname><given-names>JT</given-names></name><name><surname>Ringach</surname><given-names>DL</given-names></name></person-group><article-title>Enhanced Spatial Resolution During Locomotion and Heightened Attention in Mouse Primary Visual Cortex</article-title><source>The Journal of Neuroscience</source><year>2016</year><volume>36</volume><fpage>6382</fpage><lpage>6392</lpage><pub-id pub-id-type="pmcid">PMC4909779</pub-id><pub-id pub-id-type="pmid">27307228</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0430-16.2016</pub-id></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Busse</surname><given-names>L</given-names></name><etal/></person-group><article-title>Sensation during Active Behaviors</article-title><source>The Journal of Neuroscience</source><year>2017</year><volume>37</volume><fpage>10826</fpage><lpage>10834</lpage><pub-id pub-id-type="pmcid">PMC5678015</pub-id><pub-id pub-id-type="pmid">29118211</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1828-17.2017</pub-id></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Atiani</surname><given-names>S</given-names></name><name><surname>Elhilali</surname><given-names>M</given-names></name><name><surname>David</surname><given-names>SV</given-names></name><name><surname>Fritz</surname><given-names>JB</given-names></name><name><surname>Shamma</surname><given-names>SA</given-names></name></person-group><article-title>Task Difficulty and Performance Induce Diverse Adaptive Patterns in Gain and Shape of Primary Auditory Cortical Receptive Fields</article-title><source>Neuron</source><year>2009</year><volume>61</volume><fpage>467</fpage><lpage>480</lpage><pub-id pub-id-type="pmcid">PMC3882691</pub-id><pub-id pub-id-type="pmid">19217382</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2008.12.027</pub-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rutten</surname><given-names>S</given-names></name><name><surname>Santoro</surname><given-names>R</given-names></name><name><surname>Hervais-adelman</surname><given-names>A</given-names></name><name><surname>Formisano</surname><given-names>E</given-names></name><name><surname>Golestani</surname><given-names>N</given-names></name></person-group><article-title>Cortical encoding of speech enhances task-relevant acoustic information</article-title><source>Nature Human Behaviour</source><year>2019</year><pub-id pub-id-type="pmid">31285622</pub-id></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Popovkina</surname><given-names>DV</given-names></name><name><surname>Pasupathy</surname><given-names>A</given-names></name></person-group><article-title>Task Context Modulates Feature-Selective Responses in Area V4</article-title><source>The Journal of Neuroscience</source><year>2022</year><volume>42</volume><fpage>6408</fpage><lpage>6423</lpage><pub-id pub-id-type="pmcid">PMC9398541</pub-id><pub-id pub-id-type="pmid">35840322</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1386-21.2022</pub-id></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keller</surname><given-names>GB</given-names></name><name><surname>Bonhoeffer</surname><given-names>T</given-names></name><name><surname>Hübener</surname><given-names>M</given-names></name></person-group><article-title>Sensorimotor Mismatch Signals in Primary Visual Cortex of the Behaving Mouse</article-title><source>Neuron</source><year>2012</year><volume>74</volume><fpage>809</fpage><lpage>815</lpage><pub-id pub-id-type="pmid">22681686</pub-id></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pakan</surname><given-names>JM</given-names></name><name><surname>Currie</surname><given-names>SP</given-names></name><name><surname>Fischer</surname><given-names>L</given-names></name><name><surname>Rochefort</surname><given-names>NL</given-names></name></person-group><article-title>The Impact of Visual Cues, Reward, and Motor Feedback on the Representation of Behaviorally Relevant Spatial Locations in Primary Visual Cortex</article-title><source>Cell Reports</source><year>2018</year><volume>24</volume><fpage>2521</fpage><lpage>2528</lpage><pub-id pub-id-type="pmcid">PMC6137817</pub-id><pub-id pub-id-type="pmid">30184487</pub-id><pub-id pub-id-type="doi">10.1016/j.celrep.2018.08.010</pub-id></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Banerjee</surname><given-names>A</given-names></name><etal/></person-group><article-title>Value-guided remapping of sensory cortex by lateral orbitofrontal cortex</article-title><source>Nature</source><year>2020</year><volume>585</volume><fpage>245</fpage><lpage>250</lpage><pub-id pub-id-type="pmid">32884146</pub-id></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiser</surname><given-names>A</given-names></name><etal/></person-group><article-title>Experience-dependent spatial expectations in mouse visual cortex</article-title><source>Nature Neuroscience</source><year>2016</year><volume>19</volume><fpage>1658</fpage><lpage>1664</lpage><pub-id pub-id-type="pmid">27618309</pub-id></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vélez-Fort</surname><given-names>M</given-names></name><etal/></person-group><article-title>A Circuit for Integration of Head- and Visual-Motion Signals in Layer 6 of Mouse Primary Visual Cortex</article-title><source>Neuron</source><year>2018</year><volume>98</volume><fpage>179</fpage><lpage>191</lpage><elocation-id>e6</elocation-id><pub-id pub-id-type="pmcid">PMC5896233</pub-id><pub-id pub-id-type="pmid">29551490</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2018.02.023</pub-id></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doron</surname><given-names>G</given-names></name><etal/></person-group><article-title>Perirhinal input to neocortical layer 1 controls learning</article-title><source>Science</source><year>2020</year><volume>370</volume><elocation-id>eaaz3136</elocation-id><pub-id pub-id-type="pmcid">PMC7612443</pub-id><pub-id pub-id-type="pmid">33335033</pub-id><pub-id pub-id-type="doi">10.1126/science.aaz3136</pub-id></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shin</surname><given-names>JN</given-names></name><name><surname>Doron</surname><given-names>G</given-names></name><name><surname>Larkum</surname><given-names>ME</given-names></name></person-group><article-title>Memories off the top of your head</article-title><source>Science</source><year>2021</year><volume>374</volume><fpage>538</fpage><lpage>539</lpage><pub-id pub-id-type="pmcid">PMC7612398</pub-id><pub-id pub-id-type="pmid">34709915</pub-id><pub-id pub-id-type="doi">10.1126/science.abk1859</pub-id></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruder</surname><given-names>S</given-names></name></person-group><article-title>An Overview of Multi-Task Learning in Deep Neural Networks</article-title><source>arXiv preprint</source><year>2017</year><elocation-id>1706.05098</elocation-id></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crawshaw</surname><given-names>M</given-names></name></person-group><article-title>Multi-Task Learning with Deep Neural Networks: A Survey</article-title><year>2020</year><elocation-id>2009.09796</elocation-id></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cardin</surname><given-names>JA</given-names></name></person-group><article-title>Functional flexibility in cortical circuits</article-title><source>Current Opinion in Neurobiology</source><year>2019</year><volume>58</volume><fpage>175</fpage><lpage>180</lpage><pub-id pub-id-type="pmcid">PMC6981226</pub-id><pub-id pub-id-type="pmid">31585330</pub-id><pub-id pub-id-type="doi">10.1016/j.conb.2019.09.008</pub-id></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Perez</surname><given-names>E</given-names></name><name><surname>Strub</surname><given-names>F</given-names></name><name><surname>De Vries</surname><given-names>H</given-names></name><name><surname>Dumoulin</surname><given-names>V</given-names></name><name><surname>Courville</surname><given-names>A</given-names></name></person-group><source>FiLM: Visual Reasoning with a General Conditioning Layer</source><conf-name>Proceedings of the AAAI Conference on Artificial Intelligence</conf-name><year>2018</year><volume>32</volume></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>T</given-names></name><etal/></person-group><source>Learning Sparse Sharing Architectures for Multiple Tasks</source><conf-name>Proceedings of the AAAI Conference on Artificial Intelligence</conf-name><year>2020</year><volume>34</volume><fpage>8936</fpage><lpage>8943</lpage></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iyer</surname><given-names>A</given-names></name><etal/></person-group><article-title>Avoiding Catastrophe: Active Dendrites Enable Multi-Task Learning in Dynamic Environments</article-title><source>Frontiers in Neurorobotics</source><year>2022</year><volume>16</volume><elocation-id>2201.00042</elocation-id><pub-id pub-id-type="pmcid">PMC9100780</pub-id><pub-id pub-id-type="pmid">35574225</pub-id><pub-id pub-id-type="doi">10.3389/fnbot.2022.846219</pub-id></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oja</surname><given-names>E</given-names></name></person-group><article-title>Principal components, minor components, and linear neural networks</article-title><source>Neural Networks</source><year>1992</year><volume>5</volume><fpage>927</fpage><lpage>935</lpage></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brito</surname><given-names>CSN</given-names></name><name><surname>Gerstner</surname><given-names>W</given-names></name></person-group><article-title>Nonlinear Hebbian Learning as a Unifying Principle in Receptive Field Formation</article-title><source>PLOS Computational Biology</source><year>2016</year><volume>12</volume><elocation-id>e1005070</elocation-id><pub-id pub-id-type="pmcid">PMC5045191</pub-id><pub-id pub-id-type="pmid">27690349</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005070</pub-id></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Illing</surname><given-names>B</given-names></name><name><surname>Ventura</surname><given-names>J</given-names></name><name><surname>Bellec</surname><given-names>G</given-names></name><name><surname>Gerstner</surname><given-names>W</given-names></name></person-group><source>Local plasticity rules can learn deep representations using self-supervised contrastive predictions</source><conf-name>Advances in Neural Information Processing Systems</conf-name><year>2021</year><volume>34</volume><fpage>30365</fpage><lpage>30379</lpage><conf-sponsor>Curran Associates, Inc.</conf-sponsor></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perrett</surname><given-names>DI</given-names></name><etal/></person-group><article-title>Organization and functions of cells responsive to faces in the temporal cortex</article-title><source>Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences</source><year>1992</year><volume>335</volume><fpage>23</fpage><lpage>30</lpage><pub-id pub-id-type="pmid">1348133</pub-id></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thorpe</surname><given-names>S</given-names></name><name><surname>Fize</surname><given-names>D</given-names></name><name><surname>Marlot</surname><given-names>C</given-names></name></person-group><article-title>Speed of processing in the human visual system</article-title><source>Nature</source><year>1996</year><volume>381</volume><fpage>520</fpage><lpage>522</lpage><pub-id pub-id-type="pmid">8632824</pub-id></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tremblay</surname><given-names>R</given-names></name><name><surname>Lee</surname><given-names>S</given-names></name><name><surname>Rudy</surname><given-names>B</given-names></name></person-group><article-title>GABAergic Interneurons in the Neocortex: From Cellular Properties to Circuits</article-title><source>Neuron</source><year>2016</year><volume>91</volume><fpage>260</fpage><lpage>292</lpage><pub-id pub-id-type="pmcid">PMC4980915</pub-id><pub-id pub-id-type="pmid">27477017</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2016.06.033</pub-id></element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chance</surname><given-names>FS</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name><name><surname>Reyes</surname><given-names>AD</given-names></name></person-group><article-title>Gain Modulation from Background Synaptic Input</article-title><source>Neuron</source><year>2002</year><volume>35</volume><fpage>773</fpage><lpage>782</lpage><pub-id pub-id-type="pmid">12194875</pub-id></element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferguson</surname><given-names>KA</given-names></name><name><surname>Cardin</surname><given-names>JA</given-names></name></person-group><article-title>Mechanisms underlying gain modulation in the cortex</article-title><source>Nature Reviews Neuroscience</source><year>2020</year><volume>21</volume><fpage>80</fpage><lpage>92</lpage><pub-id pub-id-type="pmcid">PMC7408409</pub-id><pub-id pub-id-type="pmid">31911627</pub-id><pub-id pub-id-type="doi">10.1038/s41583-019-0253-y</pub-id></element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Self</surname><given-names>MW</given-names></name><name><surname>Kooijmans</surname><given-names>RN</given-names></name><name><surname>Supèr</surname><given-names>H</given-names></name><name><surname>Lamme</surname><given-names>VA</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name></person-group><article-title>Different glutamate receptors convey feedforward and recurrent processing in macaque V1</article-title><source>Proceedings of the National Academy of Sciences</source><year>2012</year><volume>109</volume><fpage>11031</fpage><lpage>11036</lpage><pub-id pub-id-type="pmcid">PMC3390882</pub-id><pub-id pub-id-type="pmid">22615394</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1119527109</pub-id></element-citation></ref><ref id="R40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Manita</surname><given-names>S</given-names></name><etal/></person-group><article-title>A Top-Down Cortical Circuit for Accurate Sensory Perception</article-title><source>Neuron</source><year>2015</year><volume>86</volume><fpage>1304</fpage><lpage>1316</lpage><pub-id pub-id-type="pmid">26004915</pub-id></element-citation></ref><ref id="R41"><label>41</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schiller</surname><given-names>J</given-names></name><name><surname>Major</surname><given-names>G</given-names></name><name><surname>Koester</surname><given-names>H</given-names></name><name><surname>Schiller</surname><given-names>Y</given-names></name></person-group><article-title>NMDA spikes in basal dendrites of cortical pyramidal neurons</article-title><source>Nature</source><year>2000</year><volume>1261</volume><fpage>285</fpage><lpage>289</lpage><pub-id pub-id-type="pmid">10749211</pub-id></element-citation></ref><ref id="R42"><label>42</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Major</surname><given-names>G</given-names></name><name><surname>Larkum</surname><given-names>ME</given-names></name><name><surname>Schiller</surname><given-names>J</given-names></name></person-group><article-title>Active properties of neocortical pyramidal neuron dendrites</article-title><source>Annual review of neuroscience</source><year>2013</year><volume>36</volume><fpage>1</fpage><lpage>24</lpage><pub-id pub-id-type="pmid">23841837</pub-id></element-citation></ref><ref id="R43"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Major</surname><given-names>G</given-names></name><name><surname>Polsky</surname><given-names>A</given-names></name><name><surname>Denk</surname><given-names>W</given-names></name><name><surname>Schiller</surname><given-names>J</given-names></name><name><surname>Tank</surname><given-names>DW</given-names></name></person-group><article-title>Spatiotemporally Graded NMDA Spike/Plateau Potentials in Basal Dendrites of Neocortical Pyramidal Neurons (Supplementary figures)</article-title><source>Journal of neurophysiology</source><year>2008</year><pub-id pub-id-type="pmid">18337370</pub-id></element-citation></ref><ref id="R44"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Larkum</surname><given-names>ME</given-names></name></person-group><article-title>The Guide to Dendritic Spikes of the Mammalian Cortex In Vitro and In Vivo</article-title><volume>19</volume><year>2022</year><pub-id pub-id-type="pmid">35182699</pub-id></element-citation></ref><ref id="R45"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hay</surname><given-names>E</given-names></name><name><surname>Hill</surname><given-names>S</given-names></name><name><surname>Schürmann</surname><given-names>F</given-names></name><name><surname>Markram</surname><given-names>H</given-names></name><name><surname>Segev</surname><given-names>I</given-names></name></person-group><article-title>Models of neocortical layer 5b pyramidal cells capturing a wide range of dendritic and perisomatic active properties</article-title><source>PLoS computational biology</source><year>2011</year><volume>7</volume><elocation-id>e1002107</elocation-id><pub-id pub-id-type="pmcid">PMC3145650</pub-id><pub-id pub-id-type="pmid">21829333</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1002107</pub-id></element-citation></ref><ref id="R46"><label>46</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haider</surname><given-names>B</given-names></name><name><surname>Häusser</surname><given-names>M</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name></person-group><article-title>Inhibition dominates sensory responses in the awake cortex</article-title><source>Nature</source><year>2013</year><volume>493</volume><fpage>97</fpage><lpage>100</lpage><pub-id pub-id-type="pmcid">PMC3537822</pub-id><pub-id pub-id-type="pmid">23172139</pub-id><pub-id pub-id-type="doi">10.1038/nature11665</pub-id></element-citation></ref><ref id="R47"><label>47</label><element-citation publication-type="journal"><collab>Destexhe</collab><article-title>Inhibitory “noise”</article-title><source>Frontiers in Cellular Neuroscience</source><year>2010</year><pub-id pub-id-type="pmcid">PMC2854575</pub-id><pub-id pub-id-type="pmid">20407587</pub-id><pub-id pub-id-type="doi">10.3389/fncel.2010.00009</pub-id></element-citation></ref><ref id="R48"><label>48</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>G</given-names></name><name><surname>Afshar</surname><given-names>S</given-names></name><name><surname>Tapson</surname><given-names>J</given-names></name><name><surname>van Schaik</surname><given-names>A</given-names></name></person-group><article-title>EMNIST: An extension of MNIST to handwritten letters</article-title><year>2017</year><elocation-id>1702.05373</elocation-id></element-citation></ref><ref id="R49"><label>49</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>N</given-names></name><name><surname>DiCarlo</surname><given-names>JJ</given-names></name></person-group><article-title>Unsupervised Natural Experience Rapidly Alters Invariant Object Representation in Visual Cortex</article-title><source>Science</source><year>2008</year><volume>321</volume><fpage>1502</fpage><lpage>1507</lpage><pub-id pub-id-type="pmcid">PMC3307055</pub-id><pub-id pub-id-type="pmid">18787171</pub-id><pub-id pub-id-type="doi">10.1126/science.1160028</pub-id></element-citation></ref><ref id="R50"><label>50</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marblestone</surname><given-names>AH</given-names></name><name><surname>Wayne</surname><given-names>G</given-names></name><name><surname>Kording</surname><given-names>KP</given-names></name></person-group><article-title>Toward an Integration of Deep Learning and Neuroscience</article-title><source>Frontiers in Computational Neuroscience</source><year>2016</year><volume>10</volume><pub-id pub-id-type="pmcid">PMC5021692</pub-id><pub-id pub-id-type="pmid">27683554</pub-id><pub-id pub-id-type="doi">10.3389/fncom.2016.00094</pub-id></element-citation></ref><ref id="R51"><label>51</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Illing</surname><given-names>B</given-names></name><name><surname>Gerstner</surname><given-names>W</given-names></name><name><surname>Brea</surname><given-names>J</given-names></name></person-group><article-title>Biologically plausible deep learning — But how far can we go with shallow networks?</article-title><source>Neural Networks</source><year>2019</year><volume>118</volume><fpage>90</fpage><lpage>101</lpage><elocation-id>1905.04101</elocation-id><pub-id pub-id-type="pmid">31254771</pub-id></element-citation></ref><ref id="R52"><label>52</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olshausen</surname><given-names>BA</given-names></name><name><surname>Field</surname><given-names>DJ</given-names></name></person-group><article-title>Code for Natural Images</article-title><source>Nature</source><year>1996</year><volume>381</volume><fpage>607</fpage><lpage>609</lpage><pub-id pub-id-type="pmid">8637596</pub-id></element-citation></ref><ref id="R53"><label>53</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Mairal</surname><given-names>J</given-names></name><name><surname>Bach</surname><given-names>F</given-names></name><name><surname>Ponce</surname><given-names>J</given-names></name><name><surname>Sapiro</surname><given-names>G</given-names></name></person-group><source>Online dictionary learning for sparse coding</source><conf-name>Proceedings of the 26th Annual International Conference on Machine Learning - ICML ’09</conf-name><year>2009</year><fpage>1</fpage><lpage>8</lpage><conf-sponsor>ACM Press</conf-sponsor><conf-loc>Montreal, Quebec, Canada</conf-loc></element-citation></ref><ref id="R54"><label>54</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Witten</surname><given-names>DM</given-names></name><name><surname>Tibshirani</surname><given-names>R</given-names></name><name><surname>Hastie</surname><given-names>T</given-names></name></person-group><article-title>A penalized matrix decomposition, with applications to sparse principal components and canonical correlation analysis</article-title><source>Biostatistics (Oxford, England)</source><year>2009</year><volume>10</volume><fpage>515</fpage><lpage>534</lpage><pub-id pub-id-type="pmcid">PMC2697346</pub-id><pub-id pub-id-type="pmid">19377034</pub-id><pub-id pub-id-type="doi">10.1093/biostatistics/kxp008</pub-id></element-citation></ref><ref id="R55"><label>55</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wybo</surname><given-names>WA</given-names></name><etal/></person-group><article-title>Data-driven reduction of dendritic morphologies with preserved dendro-somatic responses</article-title><source>eLife</source><year>2021</year><volume>10</volume><elocation-id>e60936</elocation-id><pub-id pub-id-type="pmcid">PMC7837682</pub-id><pub-id pub-id-type="pmid">33494860</pub-id><pub-id pub-id-type="doi">10.7554/eLife.60936</pub-id></element-citation></ref><ref id="R56"><label>56</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rumelhart</surname><given-names>DE</given-names></name><name><surname>Hintont</surname><given-names>GE</given-names></name><name><surname>Williams</surname><given-names>RJ</given-names></name></person-group><article-title>Learning representations by back-propagating errors</article-title><year>1986</year><volume>4</volume></element-citation></ref><ref id="R57"><label>57</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Goodfellow</surname><given-names>I</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Courville</surname><given-names>A</given-names></name></person-group><source>Deep Learning</source><year>2016</year><publisher-name>The MIT Press</publisher-name></element-citation></ref><ref id="R58"><label>58</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lillicrap</surname><given-names>TP</given-names></name><name><surname>Santoro</surname><given-names>A</given-names></name><name><surname>Marris</surname><given-names>L</given-names></name><name><surname>Akerman</surname><given-names>CJ</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><article-title>Backpropagation and the brain</article-title><source>Nature Reviews Neuroscience</source><year>2020</year><volume>21</volume><fpage>335</fpage><lpage>346</lpage><pub-id pub-id-type="pmid">32303713</pub-id></element-citation></ref><ref id="R59"><label>59</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>LeCun</surname><given-names>Y</given-names></name><name><surname>Kavukcuoglu</surname><given-names>K</given-names></name><name><surname>Farabet</surname><given-names>C</given-names></name></person-group><source>Convolutional networks and applications in vision</source><conf-name>Proceedings of 2010 IEEE International Symposium on Circuits and Systems</conf-name><year>2010</year><fpage>253</fpage><lpage>256</lpage><conf-sponsor>IEEE</conf-sponsor><conf-loc>Paris, France</conf-loc></element-citation></ref><ref id="R60"><label>60</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>T</given-names></name><name><surname>Kornblith</surname><given-names>S</given-names></name><name><surname>Norouzi</surname><given-names>M</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><source>A Simple Framework for Contrastive Learning of Visual Representations</source><conf-name>Proceedings of the 37th International Conference on Machine Learning</conf-name><year>2020</year><fpage>1597</fpage><lpage>1607</lpage><conf-sponsor>PMLR</conf-sponsor></element-citation></ref><ref id="R61"><label>61</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Krizhevsky</surname><given-names>A</given-names></name></person-group><source>Learning Multiple Layers of Features from Tiny Images. Technical Report TR-2009</source><year>2009</year><publisher-name>University of Toronto</publisher-name><publisher-loc>Toronto</publisher-loc></element-citation></ref><ref id="R62"><label>62</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McInnes</surname><given-names>L</given-names></name><name><surname>Healy</surname><given-names>J</given-names></name><name><surname>Melville</surname><given-names>J</given-names></name></person-group><article-title>UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction</article-title><year>2020</year><elocation-id>1802.03426</elocation-id></element-citation></ref><ref id="R63"><label>63</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ziv</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Long-term dynamics of CA1 hippocampal place codes</article-title><source>Nature Neuroscience</source><year>2013</year><volume>16</volume><fpage>264</fpage><lpage>266</lpage><pub-id pub-id-type="pmcid">PMC3784308</pub-id><pub-id pub-id-type="pmid">23396101</pub-id><pub-id pub-id-type="doi">10.1038/nn.3329</pub-id></element-citation></ref><ref id="R64"><label>64</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Driscoll</surname><given-names>LN</given-names></name><name><surname>Pettit</surname><given-names>NL</given-names></name><name><surname>Minderer</surname><given-names>M</given-names></name><name><surname>Chettih</surname><given-names>SN</given-names></name><name><surname>Harvey</surname><given-names>CD</given-names></name></person-group><article-title>Dynamic Reorganization of Neuronal Activity Patterns in Parietal Cortex</article-title><source>Cell</source><year>2017</year><volume>170</volume><fpage>986</fpage><lpage>999</lpage><elocation-id>e16</elocation-id><pub-id pub-id-type="pmcid">PMC5718200</pub-id><pub-id pub-id-type="pmid">28823559</pub-id><pub-id pub-id-type="doi">10.1016/j.cell.2017.07.021</pub-id></element-citation></ref><ref id="R65"><label>65</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deitch</surname><given-names>D</given-names></name><name><surname>Rubin</surname><given-names>A</given-names></name><name><surname>Ziv</surname><given-names>Y</given-names></name></person-group><article-title>Representational drift in the mouse visual cortex</article-title><source>Current Biology</source><year>2021</year><volume>31</volume><fpage>4327</fpage><lpage>4339</lpage><elocation-id>e6</elocation-id><pub-id pub-id-type="pmid">34433077</pub-id></element-citation></ref><ref id="R66"><label>66</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schoonover</surname><given-names>CE</given-names></name><name><surname>Ohashi</surname><given-names>SN</given-names></name><name><surname>Axel</surname><given-names>R</given-names></name><name><surname>Fink</surname><given-names>AJP</given-names></name></person-group><article-title>Representational drift in primary olfactory cortex</article-title><source>Nature</source><year>2021</year><volume>594</volume><fpage>541</fpage><lpage>546</lpage><pub-id pub-id-type="pmid">34108681</pub-id></element-citation></ref><ref id="R67"><label>67</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marks</surname><given-names>TD</given-names></name><name><surname>Goard</surname><given-names>MJ</given-names></name></person-group><article-title>Stimulus-dependent representational drift in primary visual cortex</article-title><source>Nature Communications</source><year>2021</year><volume>12</volume><elocation-id>5169</elocation-id><pub-id pub-id-type="pmcid">PMC8397766</pub-id><pub-id pub-id-type="pmid">34453051</pub-id><pub-id pub-id-type="doi">10.1038/s41467-021-25436-3</pub-id></element-citation></ref><ref id="R68"><label>68</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kalle Kossio</surname><given-names>YF</given-names></name><name><surname>Goedeke</surname><given-names>S</given-names></name><name><surname>Klos</surname><given-names>C</given-names></name><name><surname>Memmesheimer</surname><given-names>R-M</given-names></name></person-group><article-title>Drifting assemblies for persistent memory: Neuron transitions and unsupervised compensation</article-title><source>Proceedings of the National Academy of Sciences</source><year>2021</year><volume>118</volume><elocation-id>e2023832118</elocation-id><pub-id pub-id-type="pmcid">PMC8727022</pub-id><pub-id pub-id-type="pmid">34772802</pub-id><pub-id pub-id-type="doi">10.1073/pnas.2023832118</pub-id></element-citation></ref><ref id="R69"><label>69</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rule</surname><given-names>ME</given-names></name><name><surname>O’Leary</surname><given-names>T</given-names></name></person-group><article-title>Self-healing codes: How stable neural populations can track continually reconfiguring neural representations</article-title><source>Proceedings of the National Academy of Sciences</source><year>2022</year><volume>119</volume><elocation-id>e2106692119</elocation-id><pub-id pub-id-type="pmcid">PMC8851551</pub-id><pub-id pub-id-type="pmid">35145024</pub-id><pub-id pub-id-type="doi">10.1073/pnas.2106692119</pub-id></element-citation></ref><ref id="R70"><label>70</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bosman</surname><given-names>CA</given-names></name><etal/></person-group><article-title>Attentional Stimulus Selection through Selective Synchronization between Monkey Visual Areas</article-title><source>Neuron</source><year>2012</year><volume>75</volume><fpage>875</fpage><lpage>888</lpage><pub-id pub-id-type="pmcid">PMC3457649</pub-id><pub-id pub-id-type="pmid">22958827</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2012.06.037</pub-id></element-citation></ref><ref id="R71"><label>71</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Kerkoerle</surname><given-names>T</given-names></name><etal/></person-group><article-title>Alpha and gamma oscillations characterize feedback and feedforward processing in monkey visual cortex</article-title><source>Proceedings of the National Academy of Sciences</source><year>2014</year><volume>111</volume><fpage>14332</fpage><lpage>14341</lpage><pub-id pub-id-type="pmcid">PMC4210002</pub-id><pub-id pub-id-type="pmid">25205811</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1402773111</pub-id></element-citation></ref><ref id="R72"><label>72</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bastos</surname><given-names>AM</given-names></name><etal/></person-group><article-title>Visual Areas Exert Feedforward and Feedback Influences through Distinct Frequency Channels</article-title><source>Neuron</source><year>2015</year><volume>85</volume><fpage>390</fpage><lpage>401</lpage><pub-id pub-id-type="pmid">25556836</pub-id></element-citation></ref><ref id="R73"><label>73</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Michalareas</surname><given-names>G</given-names></name><etal/></person-group><article-title>Alpha-Beta and Gamma Rhythms Subserve Feedback and Feedforward Influences among Human Visual Cortical Areas</article-title><source>Neuron</source><year>2016</year><volume>89</volume><fpage>384</fpage><lpage>397</lpage><pub-id pub-id-type="pmcid">PMC4871751</pub-id><pub-id pub-id-type="pmid">26777277</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2015.12.018</pub-id></element-citation></ref><ref id="R74"><label>74</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Richter</surname><given-names>CG</given-names></name><name><surname>Thompson</surname><given-names>WH</given-names></name><name><surname>Bosman</surname><given-names>CA</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name></person-group><article-title>Top-Down Beta Enhances Bottom-Up Gamma</article-title><source>The Journal of Neuroscience</source><year>2017</year><volume>37</volume><fpage>6698</fpage><lpage>6711</lpage><pub-id pub-id-type="pmcid">PMC5508256</pub-id><pub-id pub-id-type="pmid">28592697</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3771-16.2017</pub-id></element-citation></ref><ref id="R75"><label>75</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Richter</surname><given-names>CG</given-names></name><name><surname>Coppola</surname><given-names>R</given-names></name><name><surname>Bressler</surname><given-names>SL</given-names></name></person-group><article-title>Top-down beta oscillatory signaling conveys behavioral context in early visual cortex</article-title><source>Scientific Reports</source><year>2018</year><volume>8</volume><elocation-id>6991</elocation-id><pub-id pub-id-type="pmcid">PMC5934398</pub-id><pub-id pub-id-type="pmid">29725028</pub-id><pub-id pub-id-type="doi">10.1038/s41598-018-25267-1</pub-id></element-citation></ref><ref id="R76"><label>76</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poirazi</surname><given-names>P</given-names></name><name><surname>Brannon</surname><given-names>T</given-names></name><name><surname>Mel</surname><given-names>BW</given-names></name></person-group><article-title>Pyramidal neuron as two-layer neural network</article-title><source>Neuron</source><year>2003</year><volume>37</volume><fpage>989</fpage><lpage>999</lpage><pub-id pub-id-type="pmid">12670427</pub-id></element-citation></ref><ref id="R77"><label>77</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hawkins</surname><given-names>J</given-names></name><name><surname>Ahmad</surname><given-names>S</given-names></name></person-group><article-title>Why Neurons Have Thousands of Synapses, a Theory of Sequence Memory in Neocortex</article-title><source>Frontiers in Neural Circuits</source><year>2016</year><volume>10</volume><fpage>1</fpage><lpage>13</lpage><elocation-id>1511.00083</elocation-id><pub-id pub-id-type="pmcid">PMC4811948</pub-id><pub-id pub-id-type="pmid">27065813</pub-id><pub-id pub-id-type="doi">10.3389/fncir.2016.00023</pub-id></element-citation></ref><ref id="R78"><label>78</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kawaguchi</surname><given-names>Y</given-names></name></person-group><article-title>Pyramidal Cell Subtypes and Their Synaptic Connections in Layer 5 of Rat Frontal Cortex</article-title><source>Cerebral Cortex</source><year>2017</year><volume>27</volume><fpage>5755</fpage><lpage>5771</lpage><pub-id pub-id-type="pmid">29028949</pub-id></element-citation></ref><ref id="R79"><label>79</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bannister</surname><given-names>AP</given-names></name></person-group><article-title>Inter- and intra-laminar connections of pyramidal cells in the neocortex</article-title><source>Neuroscience Research</source><year>2005</year><volume>53</volume><fpage>95</fpage><lpage>103</lpage><pub-id pub-id-type="pmid">16054257</pub-id></element-citation></ref><ref id="R80"><label>80</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schuman</surname><given-names>B</given-names></name><name><surname>Dellal</surname><given-names>S</given-names></name><name><surname>Prönneke</surname><given-names>A</given-names></name><name><surname>Machold</surname><given-names>R</given-names></name><name><surname>Rudy</surname><given-names>B</given-names></name></person-group><article-title>Neocortical Layer 1: An Elegant Solution to Top-Down and Bottom-Up Integration</article-title><source>Annual Review of Neuroscience</source><year>2021</year><volume>44</volume><fpage>221</fpage><lpage>252</lpage><pub-id pub-id-type="pmcid">PMC9012327</pub-id><pub-id pub-id-type="pmid">33730511</pub-id><pub-id pub-id-type="doi">10.1146/annurev-neuro-100520-012117</pub-id></element-citation></ref><ref id="R81"><label>81</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Larkum</surname><given-names>ME</given-names></name><name><surname>Zhu</surname><given-names>JJ</given-names></name><name><surname>Sakmann</surname><given-names>B</given-names></name></person-group><article-title>A new cellular mechanism for coupling inputs arriving at different cortical layers</article-title><source>Nature</source><year>1999</year><volume>398</volume><fpage>338</fpage><lpage>41</lpage><pub-id pub-id-type="pmid">10192334</pub-id></element-citation></ref><ref id="R82"><label>82</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Larkum</surname><given-names>ME</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name><name><surname>Lüscher</surname><given-names>H-R</given-names></name></person-group><article-title>Top-down Dendritic Input Increases the Gain of Layer 5 Pyramidal Neurons</article-title><source>Cerebral Cortex</source><year>2004</year><volume>14</volume><fpage>1059</fpage><lpage>1070</lpage><pub-id pub-id-type="pmid">15115747</pub-id></element-citation></ref><ref id="R83"><label>83</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doron</surname><given-names>M</given-names></name><name><surname>Chindemi</surname><given-names>G</given-names></name><name><surname>Muller</surname><given-names>E</given-names></name><name><surname>Markram</surname><given-names>H</given-names></name><name><surname>Segev</surname><given-names>I</given-names></name></person-group><article-title>Timed Synaptic Inhibition Shapes NMDA Spikes, Influencing Local Dendritic Processing and Global I/O Properties of Cortical Neurons</article-title><source>Cell Reports</source><year>2017</year><volume>21</volume><fpage>1550</fpage><lpage>1561</lpage><pub-id pub-id-type="pmid">29117560</pub-id></element-citation></ref><ref id="R84"><label>84</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wybo</surname><given-names>WA</given-names></name><name><surname>Torben-Nielsen</surname><given-names>B</given-names></name><name><surname>Nevian</surname><given-names>T</given-names></name><name><surname>Gewaltig</surname><given-names>MO</given-names></name></person-group><article-title>Electrical Compartmentalization in Neurons</article-title><source>Cell Reports</source><year>2019</year><volume>26</volume><fpage>1759</fpage><lpage>1773</lpage><elocation-id>e7</elocation-id><pub-id pub-id-type="pmid">30759388</pub-id></element-citation></ref><ref id="R85"><label>85</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Carnevale</surname><given-names>NT</given-names></name><name><surname>Hines</surname><given-names>ML</given-names></name></person-group><source>The NEURON Book</source><year>2004</year></element-citation></ref><ref id="R86"><label>86</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rotter</surname><given-names>S</given-names></name><name><surname>Diesmann</surname><given-names>M</given-names></name></person-group><article-title>Exact digital simulation of time-invariant linear systems with applications to neuronal modeling</article-title><source>Biological cybernetics</source><year>1999</year><volume>81</volume><fpage>381</fpage><lpage>402</lpage><pub-id pub-id-type="pmid">10592015</pub-id></element-citation></ref><ref id="R87"><label>87</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jahr</surname><given-names>CE</given-names></name><name><surname>Stevens</surname><given-names>CF</given-names></name></person-group><article-title>A quantitative description of NMDA receptor-channel kinetic behavior</article-title><source>The Journal of neuroscience : the official journal of the Society for Neuroscience</source><year>1990</year><volume>10</volume><fpage>1830</fpage><lpage>1837</lpage><pub-id pub-id-type="pmcid">PMC6570302</pub-id><pub-id pub-id-type="pmid">1693952</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.10-06-01830.1990</pub-id></element-citation></ref><ref id="R88"><label>88</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behabadi</surname><given-names>BF</given-names></name><name><surname>Mel</surname><given-names>BW</given-names></name></person-group><article-title>Mechanisms underlying subunit independence in pyramidal neuron dendrites</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><year>2014</year><volume>111</volume><fpage>498</fpage><lpage>503</lpage><pub-id pub-id-type="pmcid">PMC3890819</pub-id><pub-id pub-id-type="pmid">24357611</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1217645111</pub-id></element-citation></ref><ref id="R89"><label>89</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Paszke</surname><given-names>A</given-names></name><etal/></person-group><source>PyTorch: An Imperative Style, High-Performance Deep Learning Library</source><conf-name>Advances in Neural Information Processing Systems</conf-name><year>2019</year><volume>32</volume><fpage>8024</fpage><lpage>8035</lpage></element-citation></ref><ref id="R90"><label>90</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kingma</surname><given-names>DP</given-names></name><name><surname>Ba</surname><given-names>J</given-names></name></person-group><source>Adam: A Method for Stochastic Optimization</source><conf-name>Proceedings of the 3rd International Conference for Learning Representations</conf-name><year>2015</year><conf-sponsor>arXiv</conf-sponsor><elocation-id>1412.6980</elocation-id></element-citation></ref><ref id="R91"><label>91</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F</given-names></name><etal/></person-group><article-title>Scikit-learn: Machine Learning in Python</article-title><source>Journal of Machine Learning Research</source><year>2011</year><volume>12</volume><fpage>2825</fpage><lpage>2830</lpage></element-citation></ref><ref id="R92"><label>92</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fortin</surname><given-names>F-A</given-names></name><name><surname>De Rainville</surname><given-names>F-M</given-names></name><name><surname>Gardner</surname><given-names>M-A</given-names></name><name><surname>Parizeau</surname><given-names>M</given-names></name><name><surname>Gagné</surname><given-names>C</given-names></name></person-group><article-title>DEAP: Evolutionary Algorithms Made Easy</article-title><source>Journal of Machine Learning Research</source><year>2012</year><volume>13</volume><fpage>2171</fpage><lpage>2175</lpage></element-citation></ref><ref id="R93"><label>93</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Ioffe</surname><given-names>S</given-names></name><name><surname>Szegedy</surname><given-names>C</given-names></name></person-group><source>Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</source><conf-name>Proceedings of the 32nd International Conference on Machine Learning</conf-name><year>2015</year><conf-sponsor>JMLR.org</conf-sponsor><conf-loc>Lille</conf-loc><elocation-id>1502.03167</elocation-id></element-citation></ref><ref id="R94"><label>94</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>He</surname><given-names>K</given-names></name><name><surname>Zhang</surname><given-names>X</given-names></name><name><surname>Ren</surname><given-names>S</given-names></name><name><surname>Sun</surname><given-names>J</given-names></name></person-group><source>Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</source><conf-name>Proceedings of the IEEE International Conference on Computer Vision</conf-name><year>2015</year><fpage>1026</fpage><lpage>1034</lpage><comment>2015</comment><conf-sponsor>Inter</conf-sponsor><elocation-id>1502.01852v1</elocation-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>Contextual modulation of neurons in sensory processing pathways.</title><p><bold>A:</bold> Top-down connections from prefrontal and motor areas relay high-level information to early sensory processing neurons (adapted from Gilbert et al.<sup><xref ref-type="bibr" rid="R11">11</xref></sup>). <bold>B:</bold> We hypothesize that high-level information from prefrontal and motor areas modulates the activity of early sensory neurons, enhancing response properties of neurons with task-relevant receptive fields. These modulations induce a task-dependent functional remapping of sensory processing pathways built on fixed, task-agnostic feedforward connectivity. <bold>C:</bold> At the biophysical level, we investigate two plausible candidate mechanisms that could implement quasi-tonic neuron-specific modulations: somatic shunting inhibition and dendritic NMDA spikes. <bold>D:</bold> L5 PC model configuration to investigate somatic shunting: feedforward and shunting (orange) inputs target the somatic compartment (teal). <bold>E:</bold> The somatic response to identical feedforward inputs (top, green, Gaussian burst of 175 inputs), for three modulation levels resulting in zero, one or two output spikes. <bold>F:</bold> L5 PC model configuration to investigate dendritic modulation: modulatory inputs target up to 20 dendritic compartments (blue), whereas feedforward inputs target the somatic compartment (teal). <bold>G:</bold> Somatic responses (left, teal) to identical feedforward inputs (top, green, Gaussian burst of 40 inputs), for three different levels of dendritic modulation (right, blue) resulting in zero, one or two output spikes. <bold>H:</bold> Comparison of effective conductance changes, as measured at the soma, between shunt and NMDA modulation for the three modulation levels shown in E and G.</p></caption><graphic xlink:href="EMS157690-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Conceptualizing neuron-specific modulations in abstract neuron models.</title><p><bold>A:</bold> Number of output spikes, averaged over ten trials, for two example levels of modulation (determined by the number of compartments with NMDA spikes). The x-axis shows the number of excitatory feedforward inputs (&gt; 0) or inhibitory feedforward inputs (&lt; 0). The thresholds (blue) where the number of emitted spikes increases are taken as the points where the linear interpolation crosses the mid-point between discrete values. We use these thresholds as fit points for the ReLU characterizing the neuronal IO relationship (dashed lines show these fits, performed here for each modulation level separately for illustrative purposes). <bold>B:</bold> ReLU fits to obtained threshold values (as explained in B) for eight modulation levels with a curve-specific gain and shared bias (left), a curve-specific bias and shared gain (middle) and a curve-specific gain, shared bias and additionally a shared x-shift (right). Note that two of the modulation levels had nearly overlapping thresholds, so that only seven levels are visible. <bold>C, D:</bold> Same as A, B, but for modulation through somatic shunting. <bold>E:</bold> Residual summed over the eight modulation levels for the three cases shown in B (blue) and D (orange). <bold>F:</bold> Proposed conceptual model of a neuron participating in sensory feedforward processing: perisomatic feedforward inputs (green) are modulated by dendritic subunits (blue), resulting in a concerted change of slope and threshold of the neuronal IO curve.</p></caption><graphic xlink:href="EMS157690-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Adaptation of feedforward processing through neuron-specific modulations.</title><p><bold>A:</bold> Our network setup learns task-specific gains to each hidden neuron, together with a common x-shift, common bias and common feedforward weights, to implement large sets of tasks. <bold>B:</bold> 15 (out of 48, <xref ref-type="supplementary-material" rid="SD1">Fig S1A</xref>) exemplars of a two-dimensional classification multitask dataset solved with neuron-specific modulations. Correctly classifed samples are plotted in blue and orange, while incorrectly classifed samples are plotted in black. The network architecture contains one hidden layer (left) or four hidden layers (right) with 50 neurons per layer, followed by a single output unit. <bold>C:</bold> EMNIST is converted to a multitask learning problem by defining a one-vs-all classification task for every class in the original dataset. <bold>D:</bold> Performance of networks with a task-specific readout and no neuron-specific modulations (red, triangle), independently learnable task-specific gain and bias (green, square) and task-specific gain together with a shared x-shift and bias (blue, circle) as a function of the number of hidden layers (25 neurons per layer). Performance is measured by averaging over all tasks, and by additionally averaging over five initialization seeds (error bars show standard deviation of task-performance across seeds, averaged over all tasks). <bold>E:</bold> Same as in D but for a varying number of units per layer in networks with two hidden layers. <bold>F:</bold> Transfer learning performance. Networks are multitask trained on a subset of tasks (dashed line, small marker size), and performance is evaluated by training task-specific parameters on the other tasks while freezing shared parameters (averages and standard deviations computed across 128 seeds, dotted line, large marker size). Each hidden layer consists of 100 units, and multitask performances of the equivalent architecture on all tasks are shown on the right. Colors and markers as in D.</p></caption><graphic xlink:href="EMS157690-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Properties of feedforward weights for networks to perform well in concert with neuron-specific modulations.</title><p><bold>A:</bold> The normal vectors associated with segments of the decision boundary capture the local features that the network uses to make decisions about data sample identities (note that with ReLU units, the decision boundary consists of linear sections). In any network architecture (here, a single hidden layer, inset), these normal vectors are weighted sums of the input weight vectors to the first layer neurons. <bold>B:</bold> To learn a multitude of tasks with the same feedforward weights, task-relevant normal vectors to the decision boundaries must be constructible with the network. <bold>C:</bold> Normal vectors to decision boundaries must be constrained to the subspace of the input data. Normal vectors outside this subspace have components orthogonal to it, which do not add useful directions for decision boundaries. <bold>D:</bold> Generic decision boundaries can be constructed by concatenating segments with normal vectors close to difference vectors between close, but differently classified data points. <bold>E:</bold> Combining considerations A-D, we investigate loss functions that minimize the difference between, on the one hand, difference vectors between data points and, on the other hand, their projections on the subspace spanned by the weight vectors to the first layer neurons. <bold>F:</bold> Performance on multitask EMNIST (averaged over five initialization seeds) as a function of layer size for networks with neuron-specific modulations and feedforward weights given by ΔPMD (purple diamonds), ΔSD (grey circles), ΔPCA (blue triangles), and random projections (RP, red circles). <bold>G:</bold> Train loss (top), validation performance (together with ΔPMD test performance as in F for comparison, middle) and reconstruction loss (min<sub><italic>C</italic></sub> ‖Δ<italic>X</italic> −<italic>CW</italic>‖, bottom) during fully supervised learning (as in <xref ref-type="fig" rid="F3">Fig 3</xref>) of the input weight matrix <italic>W</italic>, for an architecture with one hidden layer of 100 units, and for task-specific networks (grey) and neuron-specific modulations (blue, dashed). The reconstruction loss was evaluated on <italic>W</italic> during supervised training, and compared with the case were <italic>W</italic> was given by ΔPMD (purple, dash-dotted).</p></caption><graphic xlink:href="EMS157690-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>Dendritic branches learn to solve multitask EMNIST through a biologically plausible learning rule.</title><p><bold>A:</bold> To simulate a feedforward network consisting of neurons with biophysically realistic dendritic subunits for a sufficiently long time, we reduce the L5 PC and synapse configuration shown in <xref ref-type="fig" rid="F1">Fig 1F</xref><sup><xref ref-type="bibr" rid="R55">55</xref></sup>. We then connect these neurons to an output neuron – implemented as a single-compartment reduction of the same model – that learns to spike in response to a random sample and remain silent in response to a sample from the class to be recognised. <bold>B:</bold> Weight changes of dendritic synapses (brown, bottom) are computed as the product of a global error signal (red), a low-pass filter of the post-synaptic spikes (green), a low-pass filter of the pre-synaptic spikes (blue) and a voltage-dependent learning rate modulation (purple). <bold>C:</bold> Voltage trace of the output neuron before learning (top) and after learning (bottom), for the network with the ΔPMD feedforward weight matrix, during an examplar one-vs-all task (not spiking in response to ‘two’). <bold>D:</bold> Performance on multitask EMNIST of the resulting model for the different feedforward weight matrices, labels as in <xref ref-type="fig" rid="F4">Fig 4F,G</xref>. <bold>E:</bold> Somatic voltage (teal) and a subset of dendritic voltages (blue) in a representative hidden neuron, for the same feedforward input (i.e the inner product of the input weight vector [top, left] and a randomly chosen data sample [top, right]) and five example tasks (left to right).</p></caption><graphic xlink:href="EMS157690-f005"/></fig><fig id="F6" position="float"><label>Figure 6</label><caption><title>Hierarchical stacking of task-modulated convolutional layers.</title><p><bold>A:</bold> We train a stack of gain-modulated convolutional layers on multitask CIFAR-10 using a contrastive learning (CL) objective. Each layer consists of a CL multi-layer perceptron (CL-MLP, yellow) to implement the CL objective, a set of convolutional feedforward weights (purple), and an output unit (blue) to learn the task-specific gains. In this task-modulated contrastive learning (TMCL) paradigm, no error gradients flow back between layers. <bold>B:</bold> To learn the convolutional feedforward weights to the next layer (orange arrow), the CL-MLP maximizes contrast between representations in the last learnt layer that originate from different data samples, and similarity between representation that originate from augmentations (occlusions, scalings, rotations and combinations thereof) of the same data sample to which, additionally, different task-modulations are applied (green arrows represent the feedforward pathway up until the last learnt layer). <bold>C:</bold> Validation (left) and test (right) performances on multitask CIFAR-10 (averaged over five initialisation seeds) for the gain-modulated networks (with shared x-shift), with filters trained by: error backpropagation (red), TMCL (blue), contrastive learning without similarity prediction across task-modulations (green), given by random projections (RP, black), or RP stacked on top of a TMCL layer (grey). <bold>D:</bold> Validation (left) and test (right) performances of TMCL for networks with four layers, where during the TMCL phase the augmentations where fed to a subset of the task-modulations (ten random but distinct subsets where evaluated for each number of tasks). Median performance, orange; box denotes [Q1, Q3] over the ten subsets, whiskers [min,max]. <bold>E:</bold> UMAP projections of the hidden, task-modulated representations for the TMCL-trained network. Color code as in the legend, except that the class to be recognized is black (‘dog’ for task 5 and ‘truck’ for task 9). <bold>F:</bold> UMAP projections of the hidden, task-modulated representations for the TMCL without task-modulation. Color code as in E.</p></caption><graphic xlink:href="EMS157690-f006"/></fig><table-wrap id="T1" position="float" orientation="portrait"><label>Table 1</label><caption><p>Simulation-specific parameters to investigate somatic and dendritic modulation (<xref ref-type="fig" rid="F1">Fig 1</xref>,<xref ref-type="fig" rid="F2">2</xref>). Note that for dendritic modulation, we set the number of compartments with NMDA-spikes <italic>n<sub>c</sub></italic> by targetting <italic>n<sub>c</sub></italic> compartments with an AMPA+NMDA synapse of high weight and 20 − <italic>n<sub>c</sub></italic> compartments with an AMPA+NMDA synapse of low weight, and delivered the same amount of input spikes in each case. For somatic modulation, the weight of the shunt synapses remained the same, but the number of input spikes was modified. Note that the burst width for somatic modulation was enlarged to account for the shorter time-scale of the GABA conductance window compared to the NMDA conductance window.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top"/><th align="right" valign="top">Dendritic modulation</th><th align="right" valign="top">Somatic modulation</th></tr></thead><tbody><tr><td align="left" valign="top">Weight exc (inh) feedforward synapses</td><td align="right" valign="top">0.06 (-0.06) nA</td><td align="right" valign="top">0.06 (-0.06) nA</td></tr><tr><td align="left" valign="top">Feedforward inputs burst width</td><td align="right" valign="top">6 ms</td><td align="right" valign="top">6 ms</td></tr><tr><td align="left" valign="top">No. of AMPA+NMDA inputs</td><td align="right" valign="top">60</td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">High AMPA+NMDA weight</td><td align="right" valign="top">0.08 nS</td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Low AMPA+NMDA weight</td><td align="right" valign="top">0.001 nS</td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">No. of comps with NMDA spike</td><td align="right" valign="top">{0, 3, 6, 9, 11, 14, 17, 20}</td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Shunt weight</td><td align="left" valign="top"/><td align="right" valign="top">5 nS</td></tr><tr><td align="left" valign="top">No. of shunt inputs</td><td align="left" valign="top"/><td align="right" valign="top">{0, 20, 40, 60, 80, 100, 120}</td></tr><tr><td align="left" valign="top">Contextual inputs burst width</td><td align="right" valign="top">20 ms</td><td align="right" valign="top">40 ms</td></tr><tr><td align="left" valign="top">Soma comp AMPA (GABA) background rate</td><td align="right" valign="top">100 (200) Hz</td><td align="right" valign="top">100 (200) Hz</td></tr><tr><td align="left" valign="top">Dend comps AMPA (GABA) background rate</td><td align="right" valign="top">60 (120) Hz</td><td align="right" valign="top">60 (120) Hz</td></tr><tr><td align="left" valign="top">Weight AMPA (GABA) background synapses</td><td align="right" valign="top">1 (1) nS</td><td align="right" valign="top">1 (1) nS</td></tr></tbody></table></table-wrap><table-wrap id="T2" position="float" orientation="portrait"><label>Table 2</label><caption><p>The unsupervised loss functions with their constraints and parameter values. <italic>C</italic><sup>(1)</sup> is commonly referred to as the sparse code (SC) and <italic>W</italic><sup>(1)</sup> as the sparse dictionary (SD). Note that Δ<italic>X</italic>, <italic>X</italic> ∈ ℝ<sup><italic>k</italic>×<italic>n</italic></sup>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top">Abbr.</th><th align="left" valign="top">Unsupervised loss function</th><th align="right" valign="top">Constraints</th><th align="right" valign="top">Parameter values</th></tr></thead><tbody><tr><td align="left" valign="top">PMD</td><td align="left" valign="top">‖<italic>X</italic> − <italic>C</italic><sup>(1)</sup><italic>W</italic><sup>(1)</sup>‖<sub>2</sub></td><td align="right" valign="top"><inline-formula><mml:math id="M42"><mml:mrow><mml:mo>∥</mml:mo><mml:msubsup><mml:mstyle mathvariant="bold"><mml:mtext>c</mml:mtext></mml:mstyle><mml:mrow><mml:mo>:</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mo>∥</mml:mo><mml:mn>1</mml:mn></mml:msub><mml:mo>≤</mml:mo><mml:mi>δ</mml:mi><mml:mo>,</mml:mo><mml:mo>∥</mml:mo><mml:msubsup><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>:</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mo>∥</mml:mo><mml:mn>1</mml:mn></mml:msub><mml:mo>≤</mml:mo><mml:mi>ε</mml:mi><mml:mo>,</mml:mo><mml:mo>∥</mml:mo><mml:msubsup><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>:</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mo>∥</mml:mo><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula></td><td align="right" valign="top"><inline-formula><mml:math id="M43"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>=</mml:mo><mml:mn>.5</mml:mn><mml:msqrt><mml:mi>k</mml:mi></mml:msqrt><mml:mo>,</mml:mo><mml:mi>ε</mml:mi><mml:mo>=</mml:mo><mml:mn>.3</mml:mn><mml:msqrt><mml:mi>n</mml:mi></mml:msqrt></mml:mrow></mml:math></inline-formula></td></tr><tr style="border-bottom: solid thin;"><td align="left" valign="top">ΔPMD</td><td align="left" valign="top">‖Δ<italic>X</italic> − <italic>C</italic><sup>(1)</sup><italic>W</italic><sup>(1)</sup>‖<sub>2</sub></td><td align="right" valign="top"><inline-formula><mml:math id="M44"><mml:mrow><mml:mo>∥</mml:mo><mml:msubsup><mml:mstyle mathvariant="bold"><mml:mtext>c</mml:mtext></mml:mstyle><mml:mrow><mml:mo>:</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mo>∥</mml:mo><mml:mn>1</mml:mn></mml:msub><mml:mo>≤</mml:mo><mml:mi>δ</mml:mi><mml:mo>,</mml:mo><mml:mo>∥</mml:mo><mml:msubsup><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>:</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mo>∥</mml:mo><mml:mn>1</mml:mn></mml:msub><mml:mo>≤</mml:mo><mml:mi>ε</mml:mi><mml:mo>,</mml:mo><mml:mo>∥</mml:mo><mml:msubsup><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>:</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mo>∥</mml:mo><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula></td><td align="right" valign="top"><inline-formula><mml:math id="M45"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>=</mml:mo><mml:mn>.5</mml:mn><mml:msqrt><mml:mi>k</mml:mi></mml:msqrt><mml:mo>,</mml:mo><mml:mi>ε</mml:mi><mml:mo>=</mml:mo><mml:mn>.3</mml:mn><mml:msqrt><mml:mi>n</mml:mi></mml:msqrt></mml:mrow></mml:math></inline-formula></td></tr><tr><td align="left" valign="top">SD</td><td align="left" valign="top">‖<italic>X</italic> − <italic>C</italic><sup>(1)</sup><italic>W</italic><sup>(1)</sup>‖<sub>2</sub> + <italic>λ</italic>‖<italic>C</italic><sup>(1)</sup>‖<sub>1</sub></td><td align="right" valign="top"><inline-formula><mml:math id="M46"><mml:mrow><mml:mo>∥</mml:mo><mml:msubsup><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>:</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mo>∥</mml:mo><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula></td><td align="right" valign="top"><italic>λ</italic> = .1</td></tr><tr><td align="left" valign="top">ΔSD</td><td align="left" valign="top">‖Δ<italic>X</italic> − <italic>C</italic><sup>(1)</sup><italic>W</italic><sup>(1)</sup>‖<sub>2</sub> + <italic>λ</italic>‖<italic>C</italic><sup>(1)</sup>‖<sub>1</sub></td><td align="right" valign="top"><inline-formula><mml:math id="M47"><mml:mrow><mml:mo>∥</mml:mo><mml:msubsup><mml:mstyle mathvariant="bold"><mml:mtext>w</mml:mtext></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>:</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mo>∥</mml:mo><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula></td><td align="right" valign="top"><italic>λ</italic> = .1</td></tr></tbody></table></table-wrap><table-wrap id="T3" position="float" orientation="portrait"><label>Table 3</label><caption><title>Parameters used in the network model with biophysically realistic neurons.</title></caption><table frame="hsides" rules="groups"><thead><tr style="border-bottom: solid thin;"><th align="left" valign="top">Plasiticity rule parameter</th><th align="right" valign="top">Parameter value</th></tr></thead><tbody><tr><td align="left" valign="top"><italic>τ</italic><sub>dend</sub></td><td align="right" valign="top">25 ms</td></tr><tr><td align="left" valign="top"><italic>η</italic><sub>0</sub>,<italic>η</italic><sub>1</sub>,<italic>η</italic><sub>2</sub></td><td align="right" valign="top">10<sup>−5</sup> nS/ms, 10<sup>−4</sup> nS/ms, 5 × 10<sup>−6</sup> nS/ms</td></tr><tr><td align="left" valign="top"><italic>θ</italic><sub>0</sub>,<italic>θ</italic><sub>1</sub></td><td align="right" valign="top">-50 mV, -10 mV</td></tr><tr><td align="left" valign="top"><italic>τ</italic><sub>pre</sub>, <italic>τ</italic><sub>post</sub></td><td align="right" valign="top">25 ms, 10 ms</td></tr><tr><td align="left" valign="top"><italic>c</italic><sub>pre</sub>,<italic>c</italic><sub>post</sub></td><td align="right" valign="top">1/60, 1</td></tr><tr style="border-bottom: solid thin;"><td align="left" valign="top"><italic>τ<sub>ε</sub></italic></td><td align="right" valign="top">15 ms</td></tr><tr style="border-bottom: solid thin;"><td align="left" valign="top"><bold>Network parameter</bold></td><td align="right" valign="top"><bold>Parameter value</bold></td></tr><tr><td align="left" valign="top">No. of feedforward inputs per burst</td><td align="right" valign="top">0-10 depending on pixel intensity</td></tr><tr><td align="left" valign="top">Feedforward inputs burst width</td><td align="right" valign="top">6 ms</td></tr><tr><td align="left" valign="top">No. of AMPA+NMDA inputs per burst</td><td align="right" valign="top">60 for active context, 0 otherwise</td></tr><tr><td align="left" valign="top">Max AMPA+NMDA weight</td><td align="right" valign="top">0.2 nS</td></tr><tr><td align="left" valign="top">Min AMPA+NMDA weight</td><td align="right" valign="top">0.01 nS</td></tr><tr><td align="left" valign="top">Contextual inputs burst width</td><td align="right" valign="top">20 ms</td></tr><tr><td align="left" valign="top">Soma comp AMPA (GABA) background rate</td><td align="right" valign="top">100 (200) Hz</td></tr><tr><td align="left" valign="top">Dend comps AMPA (GABA) background rate</td><td align="right" valign="top">60 (120) Hz</td></tr><tr><td align="left" valign="top">Weight AMPA (GABA) background synapses</td><td align="right" valign="top">1 (1) nS</td></tr></tbody></table></table-wrap><table-wrap id="T4" position="float" orientation="portrait"><label>Table 4</label><caption><title>Hyper-parameters used in our simulations. Sets denote that the hyper-parameter is part of a grid search with the given values.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top">Hyperparameter</th><th align="right" valign="top">Contrastive Learning phase</th><th align="right" valign="top">Task-specific modulation learning phase</th></tr></thead><tbody><tr><td align="left" valign="top">batch size</td><td align="right" valign="top">4096</td><td align="right" valign="top">8192</td></tr><tr><td align="left" valign="top">number of epochs</td><td align="right" valign="top">100</td><td align="right" valign="top">80</td></tr><tr><td align="left" valign="top">learning rate</td><td align="right" valign="top">{0.1, 0.01, 0.001}</td><td align="right" valign="top">{0.1, 0.01, 0.001}</td></tr><tr><td align="left" valign="top">gain initialization</td><td align="center" valign="top" colspan="2">{Constant(1), Rademacher, Rademacher+KaimingUniform, KaimingUniform}</td></tr><tr><td align="left" valign="top">checkpoint selection</td><td align="right" valign="top">lowest loss on train set</td><td align="right" valign="top">lowest loss on validation set</td></tr><tr><td align="left" valign="top">temperature</td><td align="right" valign="top">0.5</td><td align="right" valign="top">N/A</td></tr></tbody></table></table-wrap></floats-group></article>