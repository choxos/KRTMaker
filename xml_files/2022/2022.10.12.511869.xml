<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS155708</article-id><article-id pub-id-type="doi">10.1101/2022.10.12.511869</article-id><article-id pub-id-type="archive">PPR557516</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Is brightfield all you need for mechanism of action prediction?</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><name><surname>Gupta</surname><given-names>Ankit</given-names></name><xref ref-type="aff" rid="A1">†</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Harrison</surname><given-names>Philip J</given-names></name><xref ref-type="aff" rid="A2">‡</xref><xref ref-type="corresp" rid="CR1">§</xref></contrib><contrib contrib-type="author"><name><surname>Wieslander</surname><given-names>Håkan</given-names></name><xref ref-type="aff" rid="A1">†</xref></contrib><contrib contrib-type="author"><name><surname>Rietdijk</surname><given-names>Jonne</given-names></name><xref ref-type="aff" rid="A2">‡</xref></contrib><contrib contrib-type="author"><name><surname>Puigvert</surname><given-names>Jordi Carreras</given-names></name><xref ref-type="aff" rid="A2">‡</xref></contrib><contrib contrib-type="author"><name><surname>Georgiev</surname><given-names>Polina</given-names></name><xref ref-type="aff" rid="A2">‡</xref></contrib><contrib contrib-type="author"><name><surname>Wählby</surname><given-names>Carolina</given-names></name><xref ref-type="aff" rid="A1">†</xref></contrib><contrib contrib-type="author"><name><surname>Spjuth</surname><given-names>Ola</given-names></name><xref ref-type="aff" rid="A2">‡</xref></contrib></contrib-group><aff id="A1"><label>†</label>Department of Information Technology and SciLifeLab, Uppsala University, Uppsala, Sweden</aff><aff id="A2"><label>‡</label>Department of Pharmaceutical Biosciences, Uppsala University, Uppsala, Sweden</aff><author-notes><corresp id="CR1"><label>§</label>Corresponding Author: <email>philip.harrison@farmbio.uu.se</email></corresp></author-notes><pub-date pub-type="nihms-submitted"><day>14</day><month>10</month><year>2022</year></pub-date><pub-date pub-type="preprint"><day>13</day><month>10</month><year>2022</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Fluorescence staining techniques, such as Cell Painting, together with fluorescence microscopy have proven invaluable for visualizing and quantifying the effects that drugs and other perturbations have on cultured cells. However, fluorescence microscopy is expensive, time-consuming, and labor-intensive, and the stains applied can be cytotoxic, interfering with the activity under study. The simplest form of microscopy, brightfield microscopy, lacks these downsides, but the images produced have low contrast and the cellular compartments are difficult to discern. Nevertheless, by harnessing deep learning, these brightfield images may still be sufficient for various predictive purposes. In this study, we compared the predictive performance of models trained on fluorescence images to those trained on brightfield images for predicting the mechanism of action (MoA) of different drugs. We also extracted CellProfiler features from the fluorescence images and used them to benchmark the performance. Overall, we found comparable and correlated predictive performance for the two imaging modalities. This is promising for future studies of MoAs in time-lapse experiments.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><label>1</label><title>Introduction</title><p id="P2">Mechanism of action (MoA) describes the biological process by which a compound exhibits a pharmacological effect, such as the proteins targeted or the pathways modulated. Establishing a compound’s MoA provides particularly useful information for lead compounds prior to clinical trials and for identifying potentially adverse or toxic effects [<xref ref-type="bibr" rid="R1">1</xref>]. Various assays can be used to provide information on a compound’s MoA, including transcriptomics, proteomics and metabolomics assays [<xref ref-type="bibr" rid="R1">1</xref>]. Recently, morphology-based high-content imaging assays have proven beneficial for this task [<xref ref-type="bibr" rid="R2">2</xref>] and are also significantly easier and less expensive to scale to high-throughput than other assay types [<xref ref-type="bibr" rid="R3">3</xref>].</p><p id="P3">The simplest, cheapest, and least invasive form of light microscopy is brightfield (BF) microscopy. Due to the thinness and transparency of most cells, BF images typically have low contrast, making it difficult to detect internal cell structures. To overcome this limitation fluorescent dyes can be used. Fluorescence (FL) microscopy uses fluorescent dyes to stain specific targets (e.g. cell compartments) within the sample [<xref ref-type="bibr" rid="R4">4</xref>]. A noteworthy FL-based protocol is the Cell Painting assay [<xref ref-type="bibr" rid="R5">5</xref>] which combines six different stains to highlight eight different sub-cellular compartments. However, FL imaging is much more labor-intensive and expensive than BF imaging. The dyes required for imaging some cellular components can also be highly toxic to the cells. The problems become amplified for timelapse imaging experiments with many exposures [<xref ref-type="bibr" rid="R6">6</xref>]. Another more pervasive phototoxic effect in FL microscopy is photobleaching which not only decreases the fluorescent signal but also releases free-radicals [<xref ref-type="bibr" rid="R7">7</xref>].</p><p id="P4">Traditional analysis pipelines in image cytometry follow the path of identifying, segmenting, and extracting handcrafted quantitative features from the cells, often using the CellProfiler (CP) [<xref ref-type="bibr" rid="R8">8</xref>] software package. Common features include those related to size, shape, pixel intensity, and texture. For fluorescent images, these features can be extracted at the level of the various cellular compartments. These features can then be used as input to machine learning models. Alternatively, one can use deep learning methods [<xref ref-type="bibr" rid="R9">9</xref>], specifically convolutional neural networks (CNNs), to perform the predictive task directly from the raw pixel intensity data in an end-to-end data-driven fashion, circumventing the need for cell segmentation and determining which features to extract [<xref ref-type="bibr" rid="R10">10</xref>].</p><p id="P5">In this study, we compared the performance of CNNs trained on Cell Painting fluorescence images (five channels) to those trained on brightfield images (six z-planes) for predicting ten MoA classes for U2OS cells treated with various compounds. As a reference/benchmark, we also trained neural networks on CellProfiler-derived features from the fluorescence images. We explored the effect of including the DMSO solvent control data (wells with no compound treatment) as a predictive class in the models, as well as the influence of different normalization strategies. Example Cell Painting images and their BF counterparts for the ten MoA classes and the DMSO are shown in <xref ref-type="fig" rid="F1">Figure 1</xref>.</p></sec><sec id="S2" sec-type="methods"><label>2</label><title>Methods</title><sec id="S3"><title>Dataset</title><p id="P6">We used image data for compounds belonging to ten MoA classes (MoAs that we believed would be reasonably separable and that had a sufficient number of compounds (n) associated with them in our assay). The 10 MoAs were: ATPase inhibitors (ATPase-i, n = 18); Aurora kinase inhibitors (AuroraK-i, n = 20); HDAC inhibitors (HDAC-i, n = 33); HSP inhibitors (HSP-i, n = 24); JAK inhibitors (JAK-i, n = 21); PARP inhibitors (PARP-i, n = 21); protein synthesis inhibitors (Prot.Synth.-i, n = 23); retinoid receptor agonists (Ret.Rec.Ag, n = 19); topoisomerase inhibitors (Topo.-i, n = 32); and tubulin polymerization inhibitors (Tub.Pol.-i, n = 20). The compounds were administered at a dose of 10 <italic>μ</italic>M to U2OS cells, and exposed for 48 h, in 384 well plates. Each compound-level experiment was replicated six times. The compounds were distributed across eighteen microplates using PLAID (Plate Layouts using Artificial Intelligence Design, [<xref ref-type="bibr" rid="R11">11</xref>]), a constrained programming-based method that aims to limit unwanted bias and batch effects. Images (16-bit, 2160x2160 pixels) were captured with a 20X objective at five sites/fields-of-view in each well, with five fluorescence channels for the FL data and six evenly spaced z-planes for the BF data. See <xref ref-type="supplementary-material" rid="SD1">Supplementary Section 5.1</xref> for more details.</p></sec><sec id="S4"><title>Data splitting</title><p id="P7">We performed five splits of the data, at the compound level, into training, validation, and test sets. The splitting was performed in a stratified manner based on the proportion of compounds for each MoA. Each of the five test sets contained approximately 20% of the data, with no overlap of compounds. For each split the remaining non-test data was shuffled, at the compound level, and assigned to training or validation in a stratified manner, with 80% to training and 20% to validation. DMSO data was added to the sets with five, one, and two wells per plate for training, validation, and testing, respectively.</p></sec><sec id="S5"><title>Model training</title><p id="P8">For all the comparisons made we used a standard ResNet-50 [<xref ref-type="bibr" rid="R12">12</xref>] model with consistent hyper-parameters and training strategies. See <xref ref-type="supplementary-material" rid="SD1">Supplementary Section 5.2</xref> for the details.</p></sec><sec id="S6"><title>Normalization</title><p id="P9">The FL data was normalized using the mean and standard deviation of the pixel intensities of the control DMSO wells in each plate, to mitigate plate-level effects [<xref ref-type="bibr" rid="R13">13</xref>]. For BF, there is no well-established normalization protocol. In FL images, the information is present in both intensity and morphological variations. However, in BF images, only the morphological information is present, and thus, to establish a benchmark, different normalization strategies were explored (See <xref ref-type="supplementary-material" rid="SD1">Supplementary 5.3</xref>). The DMSO normalization turned out to be the best-performing normalization strategy also for BF.</p></sec><sec id="S7"><title>CellProfiler features</title><p id="P10">To benchmark the performance, we extracted CellProfiler (CP) features from the FL data on which we trained a fully-connected neural network with one hidden layer. We extracted 672 cell averaged features from the five channel FL image, including those related to (in CP parlance) ‘AreaShape’, ‘Correlation’, ‘Granularity’, ‘Intensity’, ‘Neighbors’, and ‘RadialDistribution’.</p></sec></sec><sec id="S8" sec-type="results | discussion"><label>3</label><title>Result and Discussion</title><p id="P11"><xref ref-type="table" rid="T1">Table 1(a)</xref> shows comparative test set F1 scores for the five data splits (averaged across the MoA prediction classes) for the models trained on BF, FL, and CP data. <xref ref-type="table" rid="T1">Table 1(b)</xref> shows the combined F1 scores (across all five tests sets, i.e. for all the compounds in our dataset) with respect to the ten MoA classes and the DMSO. The BF models perform competitively with respect to the FL and CP models, the F1 scores are quite similar for all the MoAs, except for the retinoid receptor agonists (Ret.Rec.Ag), for which the BF results are slightly lagging. The most pronounced difference is for the DMSO class, for which the BF results are considerably lower than those for both FL and CP.</p><sec id="S9"><title>Feature Representation</title><p id="P12">We also visually explored the feature representation using UMAP projections for the BF and FL models compared to those based on CP features in <xref ref-type="fig" rid="F2">Figure 2</xref>. As can be seen from <xref ref-type="fig" rid="F2">Figure 2A</xref>., the DMSO samples (blue dots) are not clustered together but rather scattered among the MoAs. The same phenomenon can be seen in the FL models (<xref ref-type="fig" rid="F2">Figure 2B</xref>.), although not as severely. This issue is also apparent in the reference CP features (<xref ref-type="fig" rid="F2">Figure 2C</xref>.), where the DMSO samples are not well-separated from many of the MoA classes.</p></sec><sec id="S10"><title>Compound-level accuracy analysis</title><p id="P13">To further explore the performance differences between the models, we compared the compound-level accuracies, as shown in <xref ref-type="fig" rid="F3">Figure 3</xref>. The Pearson correlation coefficient between BF and FL was 0.758, whereas between BF and CP it was 0.833 which indicates that prediction errors made by the BF models are more correlated with the CP benchmark than with the FL. The correlation between FL and CP models was the highest, at 0.875, as expected since they are both based on FL images. Bottom-right and top-left sections of the plots (shown by the dashed boxes in Fig 3) are “interesting" regions as they highlight the compounds where the BF performance was better, or worse than the counterparts, respectively. We identified seven compounds where the BF performance was consistently better than both FL and CP, which suggests that there may be cellular compartments or fine details picked up in the BF images, useful for MoA prediction, that are not detectable based on the Cell Painting protocol. In contrast, there was only one compound for which the BF performance was consistently worse than both the FL and CP models. The results indicate that there are multiple compounds in the dataset that exhibit morphological changes which can be picked up by the deep learning models applied to BF images.</p></sec><sec id="S11"><title>Grit score analysis</title><p id="P14">For assessing the reproducibility of a compound treatment and its perturbation strength (morphological difference) relative to a control (in our case the DMSO) one can compute a grit score (<ext-link ext-link-type="uri" xlink:href="https://github.com/cytomining/cytominer-eval">https://github.com/cytomining/cytominer-eval</ext-link>, [<xref ref-type="bibr" rid="R14">14</xref>]). Based on CP features (extracted for the nuclei, cytoplasm and the entire cells in the FL images) we computed the grit scores for all the imaging sites used. A grit score of three for an imaging site means that on average the site is three standard deviations more similar to replicate sites for the same compound than it is to DMSO controls. The grit scores for some compounds (5 out of 231 compounds) were not calculated due to the images failing quality control, such as no cells present and out-of-focus images, and hence were not included in the grit-based analysis.</p><p id="P15"><xref ref-type="supplementary-material" rid="SD1">Figure 5</xref> in the <xref ref-type="supplementary-material" rid="SD1">Supplementary section</xref> shows the counts of correct and incorrect classifications relative to the grit score for the three cases. For BF models, the error rate is higher for the lower grit scores and lower as the grit score becomes higher. The Area Under the ROC curve (AUROC) scores for logistic regression models (site-level predictions against the grit scores) were 0.662 for BF, 0.578 for FL, and 0.627 for CP. Hence, the grit score can predict the accuracy of the BF models better than the FL and CP-based models. This suggests that highly discriminative morphological features are present in the BF images of the compounds with higher grit scores, which can be leveraged to predict the MoAs with higher accuracy.</p><p id="P16">The grit scores for “interesting" cases in Fig 3 was also examined. The grit score for the seven compounds where BF models outperform both FL and CP models was in the range of 3.04-6.33 (4.61±1.16), and the grit score for the compound where BF accuracy was consistently worse was 0.550.</p><p id="P17">From the experiments in the previous sections the following observations can be made: <list list-type="bullet" id="L1"><list-item><p id="P18">BF models have difficulty in predicting DMSO (<xref ref-type="table" rid="T1">Table 1(b)</xref>) and DMSO features are not well separated from the other MoAs, as shown in <xref ref-type="fig" rid="F2">Figure 2C</xref>.</p></list-item><list-item><p id="P19">The FL models perform comparably to the CP models, as evident in <xref ref-type="table" rid="T1">Table 1(a)</xref>.</p></list-item><list-item><p id="P20">The BF models make more errors than the FL models for samples with lower grit scores, as shown in <xref ref-type="fig" rid="F4">Figure 4</xref> (dashed blue line).</p></list-item></list></p><p id="P21">Based on these observations we hypothesized that in the absence of a clear separation between DMSO and some of the MoA classes, the DMSO samples assist the FL models in learning the subtle intensity difference between compounds with lower grit scores. However, in the absence of such intensity features in the BF data, the models face difficulties in separating the compounds from the DMSO and learning MoA-specific features. To test this hypothesis, we explored the effects of removing the DMSO class from the models.</p></sec><sec id="S12"><title>Models without DMSO as a predictive class</title><p id="P22">With the exclusion of the DMSO class, the BF models actually outperformed both the FL and CP models (see <xref ref-type="table" rid="T2">Table 2</xref>). The average performance of BF models increased by approx. 6%, outperforming the FL models by approx. 2% and performing equivalently to the CP feature-based models. This suggests that subtle morphological changes relevant for MoA prediction are present in the BF data, and by excluding DMSO, the BF models can learn these features and outperform the FL models.</p><p id="P23">This effect is also indicated in <xref ref-type="fig" rid="F4">Figure 4</xref> where the accuracy of the models is compared against the grit scores. We considered the grit score range of 0-6 as higher grit scores can result from cases where the dosage of the compound was too high and became cytotoxic to the cells. The BF accuracy increased by approximately 5% at the lower grit scores (0-2) when DMSO was excluded. An unexpected discovery can be seen in <xref ref-type="fig" rid="F4">Figure 4</xref> where the BF accuracy at higher grit scores (4-6) is higher than the FL and CP models, both with and without DMSO. This suggests that in FL images the morphological feature changes occurring at higher grit scores are not learned by FL models and they are also not represented by the extracted CP features. This could mean either that they are harder to learn or extract from FL images (e.g. signal saturation or channel bleed-through?), or that they are not present in the Cell Painting images. For comparative purposes, <xref ref-type="supplementary-material" rid="SD1">Figure 6</xref> in the <xref ref-type="supplementary-material" rid="SD1">Supplementary section</xref> shows the counts of correct and incorrect classifications relative to the grit score when DMSO was excluded as a predictive class.</p></sec></sec><sec id="S13"><label>4</label><title>Conclusions and Future work</title><p id="P24">In our work, we found comparable predictive performance for models based on BF images to those based on both FL images and CP features derived from them. We found that the BF models made similar prediction errors to both the FL and CP models, although more so with the CP models. The BF models struggled to predict DMSO for cases where it was not well separated from some of the MoAs, however, their performance improved and they outperform the FL models when DMSO was not included as a predictive class. This shows that the features required to delineate the MoAs are present in the BF images and can be extracted by deep learning models.</p><p id="P25">Had the performance been significantly poorer for the BF models, than those based on FL, one avenue for exploration would have been to perform virtual staining [<xref ref-type="bibr" rid="R15">15</xref>, <xref ref-type="bibr" rid="R16">16</xref>, <xref ref-type="bibr" rid="R17">17</xref>] to generate virtually stained images from which to subsequently base the MoA prediction. However, going via this route would lose any morphological information that is only present in the BF images. We had several cases of compounds that were considerably better predicted by the BF model, relative to both the FL and CP models, suggesting that there are cellular compartments/organelles potentially picked up in the BF images that are not stained for in the Cell Painting protocol (such as membraneous organelles – lysosomes, endosomes and peroxisomes). We plan to investigate these cases further alongside those compounds for which the opposite was true (i.e. where the FL models performed well but the BF models did not). We hypothesize that this latter case may be a result of cellular compartments stained for in the Cell Painting protocol, which were useful for prediction, but which are barely visible or not accessible in the BF images (such as the f-actin cytoskeleton).</p><p id="P26">The fact that deep learning can be used on BF images for MoA prediction holds great promise for time-lapse studies, for which using FL data is problematic. With trained BF models we can track the cell populations over time to explore how the features evolve towards the MoAs after drug administration and how quick the process is. A wealth of interesting information will likely come from simply visualizing these temporal dynamics.</p></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary Materials</label><media xlink:href="EMS155708-supplement-Supplementary_Materials.pdf" mimetype="application" mime-subtype="pdf" id="d25aAdEbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S14"><title>Acknowledgments</title><p>The work was supported by the Swedish Foundation for Strategic Research (grant BD15-0008SB16-0046) and the European Research Council (grant ERC-2015-CoG 683810). The computations were enabled by the supercomputing resource Berzelius provided by National Supercomputer Centre at Linköping University and the Knut and Alice Wallenberg foundation. We also thank Maris Lapins for providing the Grit scores.</p></ack><ref-list><ref id="R1"><label>[1]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Trapotsi</surname><given-names>M-A</given-names></name><name><surname>Hosseini-Gerami</surname><given-names>L</given-names></name><name><surname>Bender</surname><given-names>A</given-names></name></person-group><article-title>Computational analyses of mechanism of action (MoA): data, methods and integration</article-title><source>RSC Chemical Biology</source><year>2022</year><volume>3</volume><issue>2</issue><fpage>170</fpage><lpage>200</lpage></element-citation></ref><ref id="R2"><label>[2]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kensert</surname><given-names>A</given-names></name><name><surname>Harrison</surname><given-names>PJ</given-names></name><name><surname>Spjuth</surname><given-names>O</given-names></name></person-group><article-title>Transfer learning with deep convolutional neural networks for classifying cellular morphological changes</article-title><source>SLAS Discovery: Advancing Life Sciences R&amp;D</source><year>2019</year><volume>24</volume><issue>4</issue><fpage>466</fpage><lpage>475</lpage></element-citation></ref><ref id="R3"><label>[3]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caicedo</surname><given-names>JC</given-names></name><name><surname>Singh</surname><given-names>S</given-names></name><name><surname>Carpenter</surname><given-names>AE</given-names></name></person-group><article-title>Applications in image-based profiling of perturbations</article-title><source>Current opinion in biotechnology</source><year>2016</year><volume>39</volume><fpage>134</fpage><lpage>142</lpage></element-citation></ref><ref id="R4"><label>[4]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thorn</surname><given-names>K</given-names></name></person-group><article-title>A quick guide to light microscopy in cell biology</article-title><source>Molecular Biology of the Cell</source><year>2016</year><volume>27</volume><issue>2</issue><fpage>219</fpage><lpage>222</lpage><pub-id pub-id-type="doi">10.1091/mbc.E15-02-0088</pub-id><pub-id pub-id-type="pmcid">PMC4713126</pub-id></element-citation></ref><ref id="R5"><label>[5]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bray</surname><given-names>M-A</given-names></name><name><surname>Singh</surname><given-names>S</given-names></name><name><surname>Han</surname><given-names>H</given-names></name><name><surname>Davis</surname><given-names>CT</given-names></name><name><surname>Borgeson</surname><given-names>B</given-names></name><name><surname>Hartland</surname><given-names>C</given-names></name><name><surname>Kost-Alimova</surname><given-names>M</given-names></name><name><surname>Gustafsdottir</surname><given-names>SM</given-names></name><name><surname>Gibson</surname><given-names>CC</given-names></name><name><surname>Carpenter</surname><given-names>AE</given-names></name></person-group><article-title>Cell painting, a high-content image-based assay for morphological profiling using multiplexed fluorescent dyes</article-title><source>Nature protocols</source><year>2016</year><volume>11</volume><issue>9</issue><fpage>1757</fpage><lpage>1774</lpage></element-citation></ref><ref id="R6"><label>[6]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Purschke</surname><given-names>M</given-names></name><name><surname>Rubio</surname><given-names>N</given-names></name><name><surname>Held</surname><given-names>KD</given-names></name><name><surname>Redmond</surname><given-names>RW</given-names></name></person-group><article-title>Phototoxicity of Hoechst 33342 in timelapse fluorescence microscopy, Photochemical &amp; Photobiological Sciences</article-title><source>Official Journal of the European Photochemistry Association and the European Society for Photobiology</source><year>2010</year><volume>9</volume><issue>12</issue><fpage>1634</fpage><lpage>1639</lpage><pub-id pub-id-type="doi">10.1039/c0pp00234h</pub-id></element-citation></ref><ref id="R7"><label>[7]</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Thorley</surname><given-names>JA</given-names></name><name><surname>Pike</surname><given-names>J</given-names></name><name><surname>Rappoport</surname><given-names>JZ</given-names></name></person-group><chapter-title>Chapter 14-super-resolution microscopy: A comparison of commercially available options</chapter-title><person-group person-group-type="editor"><name><surname>Cornea</surname><given-names>A</given-names></name><name><surname>Conn</surname><given-names>PM</given-names></name></person-group><source>Fluorescence Microscopy</source><publisher-name>Academic Press</publisher-name><publisher-loc>Boston</publisher-loc><year>2014</year><fpage>199</fpage><lpage>212</lpage><comment>URL <ext-link ext-link-type="uri" xlink:href="https://www.sciencedirect.com/science/article/pii/B9780124095137000142">https://www.sciencedirect.com/science/article/pii/B9780124095137000142</ext-link></comment><pub-id pub-id-type="doi">10.1016/B978-0-12-409513-7.00014-2</pub-id></element-citation></ref><ref id="R8"><label>[8]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carpenter</surname><given-names>AE</given-names></name><name><surname>Jones</surname><given-names>TR</given-names></name><name><surname>Lamprecht</surname><given-names>MR</given-names></name><name><surname>Clarke</surname><given-names>C</given-names></name><name><surname>Kang</surname><given-names>IH</given-names></name><name><surname>Friman</surname><given-names>O</given-names></name><name><surname>Guertin</surname><given-names>DA</given-names></name><name><surname>Chang</surname><given-names>JH</given-names></name><name><surname>Lindquist</surname><given-names>RA</given-names></name><name><surname>Moffat</surname><given-names>J</given-names></name><name><surname>Golland</surname><given-names>P</given-names></name><etal/></person-group><article-title>CellProfiler: image analysis software for identifying and quantifying cell phenotypes</article-title><source>Genome Biology</source><year>2006</year><volume>7</volume><issue>10</issue><elocation-id>R100</elocation-id><pub-id pub-id-type="doi">10.1186/gb-2006-7-10-r100</pub-id></element-citation></ref><ref id="R9"><label>[9]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LeCun</surname><given-names>Y</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><article-title>Deep learning</article-title><source>Nature</source><year>2015</year><volume>521</volume><issue>7553</issue><fpage>436</fpage><lpage>444</lpage><comment>URL <ext-link ext-link-type="uri" xlink:href="https://www.nature.com/articles/nature14539">http://www.nature.com/articles/nature14539</ext-link></comment><pub-id pub-id-type="doi">10.1038/nature14539</pub-id></element-citation></ref><ref id="R10"><label>[10]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gupta</surname><given-names>A</given-names></name><name><surname>Harrison</surname><given-names>PJ</given-names></name><name><surname>Wieslander</surname><given-names>H</given-names></name><name><surname>Pielawski</surname><given-names>N</given-names></name><name><surname>Kartasalo</surname><given-names>K</given-names></name><name><surname>Partel</surname><given-names>G</given-names></name><name><surname>Solorzano</surname><given-names>L</given-names></name><name><surname>Suveer</surname><given-names>A</given-names></name><name><surname>Klemm</surname><given-names>AH</given-names></name><name><surname>Spjuth</surname><given-names>O</given-names></name><name><surname>Sintorn</surname><given-names>I-M</given-names></name><etal/></person-group><article-title>Deep Learning in Image Cytometry: A Review</article-title><source>Cytometry Part A</source><year>2019</year><volume>95</volume><issue>4</issue><fpage>366</fpage><lpage>380</lpage><pub-id pub-id-type="doi">10.1002/cyto.a.23701</pub-id></element-citation></ref><ref id="R11"><label>[11]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rodríguez</surname><given-names>MAF</given-names></name><name><surname>Carreras-Puigvert</surname><given-names>J</given-names></name><name><surname>Spjuth</surname><given-names>O</given-names></name></person-group><article-title>Designing microplate layouts using artificial intelligence</article-title><source>bioRxiv</source><year>2022</year><pub-id pub-id-type="doi">10.1101/2022.03.31.486595</pub-id></element-citation></ref><ref id="R12"><label>[12]</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>He</surname><given-names>K</given-names></name><name><surname>Zhang</surname><given-names>X</given-names></name><name><surname>Ren</surname><given-names>S</given-names></name><name><surname>Sun</surname><given-names>J</given-names></name></person-group><source>Deep residual learning for image recognition</source><conf-name>Proceedings of the IEEE conference on computer vision and pattern recognition</conf-name><year>2016</year><fpage>770</fpage><lpage>778</lpage></element-citation></ref><ref id="R13"><label>[13]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caicedo</surname><given-names>JC</given-names></name><name><surname>Cooper</surname><given-names>S</given-names></name><name><surname>Heigwer</surname><given-names>F</given-names></name><name><surname>Warchal</surname><given-names>S</given-names></name><name><surname>Qiu</surname><given-names>P</given-names></name><name><surname>Molnar</surname><given-names>C</given-names></name><name><surname>Vasilevich</surname><given-names>AS</given-names></name><name><surname>Barry</surname><given-names>JD</given-names></name><name><surname>Bansal</surname><given-names>HS</given-names></name><name><surname>Kraus</surname><given-names>O</given-names></name><name><surname>Wawer</surname><given-names>M</given-names></name><etal/></person-group><article-title>Data-analysis strategies for image-based cell profiling</article-title><source>Nature Methods</source><year>2017</year><volume>14</volume><issue>9</issue><fpage>849</fpage><lpage>863</lpage><pub-id pub-id-type="doi">10.1038/nmeth.4397</pub-id></element-citation></ref><ref id="R14"><label>[14]</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Trapotsi</surname><given-names>M-A</given-names></name><name><surname>Mouchet</surname><given-names>E</given-names></name><name><surname>Williams</surname><given-names>G</given-names></name><name><surname>Monteverde</surname><given-names>T</given-names></name><name><surname>Juhani</surname><given-names>K</given-names></name><name><surname>Turkki</surname><given-names>R</given-names></name><name><surname>Miljkovic</surname><given-names>F</given-names></name><name><surname>Martinsson</surname><given-names>A</given-names></name><name><surname>Mervin</surname><given-names>L</given-names></name><name><surname>Pryde</surname><given-names>KR</given-names></name><name><surname>Müllers</surname><given-names>E</given-names></name><etal/></person-group><article-title>Cell Morphological Profiling Enables High-Throughput Screening for PROteolysis TArgeting Chimera (PROTAC) Phenotypic Signature</article-title><source>ACS Chemical Biology</source><publisher-name>American Chemical Society</publisher-name><year>2022</year><volume>17</volume><issue>7</issue><fpage>1733</fpage><lpage>1744</lpage><pub-id pub-id-type="doi">10.1021/acschembio.2c00076</pub-id></element-citation></ref><ref id="R15"><label>[15]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christiansen</surname><given-names>EM</given-names></name><name><surname>Yang</surname><given-names>SJ</given-names></name><name><surname>Ando</surname><given-names>DM</given-names></name><name><surname>Javaherian</surname><given-names>A</given-names></name><name><surname>Skibinski</surname><given-names>G</given-names></name><name><surname>Lipnick</surname><given-names>S</given-names></name><name><surname>Mount</surname><given-names>E</given-names></name><name><surname>ONeil</surname><given-names>A</given-names></name><name><surname>Shah</surname><given-names>K</given-names></name><name><surname>Lee</surname><given-names>AK</given-names></name><name><surname>Goyal</surname><given-names>P</given-names></name><etal/></person-group><article-title>silico labeling: Predicting fluorescent labels in unlabeled images</article-title><source>Cell</source><year>2018</year><volume>173</volume><issue>3</issue><fpage>792</fpage><lpage>803</lpage><elocation-id>e19</elocation-id><pub-id pub-id-type="doi">10.1016/j.cell.2018.03.040</pub-id></element-citation></ref><ref id="R16"><label>[16]</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cross-Zamirski</surname><given-names>JO</given-names></name><name><surname>Mouchet</surname><given-names>E</given-names></name><name><surname>Williams</surname><given-names>G</given-names></name><name><surname>Schönlieb</surname><given-names>C-B</given-names></name><name><surname>Turkki</surname><given-names>R</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name></person-group><article-title>Label-free prediction of cell painting from brightfield images</article-title><source>Scientific Reports</source><publisher-name>Nature Publishing Group</publisher-name><year>2022</year><volume>12</volume><issue>1</issue><elocation-id>10001</elocation-id><comment>number: 1 URL <ext-link ext-link-type="uri" xlink:href="https://www.nature.com/articles/s41598-022-12914-x">https://www.nature.com/articles/s41598-022-12914-x</ext-link></comment><pub-id pub-id-type="doi">10.1038/s41598-022-12914-x</pub-id></element-citation></ref><ref id="R17"><label>[17]</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wieslander</surname><given-names>H</given-names></name><name><surname>Gupta</surname><given-names>A</given-names></name><name><surname>Bergman</surname><given-names>E</given-names></name><name><surname>Hallström</surname><given-names>E</given-names></name><name><surname>Harrison</surname><given-names>PJ</given-names></name></person-group><article-title>Learning to see colours: Biologically relevant virtual staining for adipocyte cell images</article-title><source>PLOS ONE</source><publisher-name>Public Library of Science</publisher-name><year>2021</year><volume>16</volume><issue>10</issue><elocation-id>e0258546</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0258546</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><p>Example Cell Painting images for the ten MoA classes and the DMSO. The panel titles give the compound names for the selected images with the MoA abbreviation in parenthesis, where -i stands for inhibitor and Ag for agonist. The top images in each case show a maximum projection of the 6 BF z-planes, and those below show merged images for the FL channels with nuclei in blue, ER in green, RNA in magenta, Golgi/F-actin in red and mitochondria in yellow.</p></caption><graphic xlink:href="EMS155708-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><p>UMAP plots of features learned by the BF and FL models, and the raw CP features for the best performing split (split 2). <bold>A</bold>. BF features; <bold>B</bold>. FL features; <bold>C</bold>. CP cell-based features.</p></caption><graphic xlink:href="EMS155708-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><p>Comparison of the accuracy at the compound level, across all five test sets, for the BF models with respect to FL models, and CP feature-based models. Each dark dot represents a compound. Brighter dots represent multiple compounds with the same accuracy score. <bold>A.</bold> BF against FL; <bold>B.</bold> BF against CP. In the boxes at the bottom right and top left, thresholded at accuracy values of 0.6 and 0.4, the compounds shown with blue crosses were consistently better for BF than both FL and CP or consistently worse, respectively.</p></caption><graphic xlink:href="EMS155708-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><p>Comparison of accuracy at different grit scores for BF (blue), FL (orange), and CP featurebased (green) models across all five test sets. The dotted lines represent the score when DMSO was included in the experiments and solid lines represent the results when DMSO was excluded.</p></caption><graphic xlink:href="EMS155708-f004"/></fig><table-wrap-group id="T1" position="float" orientation="portrait"><label>Table 1</label><caption><title>Comparison of the results for the models trained on BF and FL images and CP features.</title></caption><table-wrap id="T01" position="float" orientation="portrait"><label>(a)</label><caption><title>Macro-F1 scores on the test sets for the five data splits for BF, FL and CP models.</title></caption><table frame="below" rules="cols"><thead><tr style="border-bottom: solid thin"><th align="center" valign="middle">Modality</th><th align="center" valign="middle">BF</th><th align="center" valign="middle">FL</th><th align="center" valign="middle">CP</th></tr></thead><tbody><tr><td align="center" valign="middle">Split 1</td><td align="center" valign="middle">0.688</td><td align="center" valign="middle"><bold>0.777</bold></td><td align="center" valign="middle">0.774</td></tr><tr><td align="center" valign="middle">Split 2</td><td align="center" valign="middle">0.773</td><td align="center" valign="middle">0.799</td><td align="center" valign="middle"><bold>0.800</bold></td></tr><tr><td align="center" valign="middle">Split 3</td><td align="center" valign="middle">0.700</td><td align="center" valign="middle"><bold>0.793</bold></td><td align="center" valign="middle">0.773</td></tr><tr><td align="center" valign="middle">Split4</td><td align="center" valign="middle">0.731</td><td align="center" valign="middle"><bold>0.738</bold></td><td align="center" valign="middle">0.728</td></tr><tr><td align="center" valign="middle">Split5</td><td align="center" valign="middle">0.701</td><td align="center" valign="middle">0.716</td><td align="center" valign="middle"><bold>0.760</bold></td></tr></tbody></table></table-wrap><table-wrap id="T02" position="float" orientation="portrait"><label>(b)</label><caption><title>F1 scores per MoA, across all five test sets, for BF, FL, and CP models.</title></caption><table frame="below" rules="cols"><thead><tr style="border-bottom: solid thin"><th align="center" valign="middle">MoA</th><th align="center" valign="middle">BF</th><th align="center" valign="middle">FL</th><th align="center" valign="middle">CP</th></tr></thead><tbody><tr><td align="center" valign="middle">ATPase-i</td><td align="center" valign="middle">0.674</td><td align="center" valign="middle"><bold>0.701</bold></td><td align="center" valign="middle">0.699</td></tr><tr><td align="center" valign="middle">AuroraK-i</td><td align="center" valign="middle"><bold>0.742</bold></td><td align="center" valign="middle">0.675</td><td align="center" valign="middle">0.677</td></tr><tr><td align="center" valign="middle">HDAC-i</td><td align="center" valign="middle"><bold>0.792</bold></td><td align="center" valign="middle">0.773</td><td align="center" valign="middle">0.779</td></tr><tr><td align="center" valign="middle">HSP-i</td><td align="center" valign="middle">0.728</td><td align="center" valign="middle"><bold>0.730</bold></td><td align="center" valign="middle">0.712</td></tr><tr><td align="center" valign="middle">JAK-i</td><td align="center" valign="middle">0.677</td><td align="center" valign="middle">0.653</td><td align="center" valign="middle"><bold>0.681</bold></td></tr><tr><td align="center" valign="middle">PARP-i</td><td align="center" valign="middle">0.833</td><td align="center" valign="middle">0.886</td><td align="center" valign="middle"><bold>0.925</bold></td></tr><tr><td align="center" valign="middle">Prot.Synth.-i</td><td align="center" valign="middle">0.768</td><td align="center" valign="middle"><bold>0.793</bold></td><td align="center" valign="middle">0.770</td></tr><tr><td align="center" valign="middle">Ret.Rec.Ag</td><td align="center" valign="middle">0.684</td><td align="center" valign="middle">0.769</td><td align="center" valign="middle"><bold>0.795</bold></td></tr><tr><td align="center" valign="middle">Topo.-i</td><td align="center" valign="middle">0.729</td><td align="center" valign="middle">0.728</td><td align="center" valign="middle"><bold>0.761</bold></td></tr><tr><td align="center" valign="middle">Tub.Pol.-i</td><td align="center" valign="middle">0.881</td><td align="center" valign="middle">0.854</td><td align="center" valign="middle"><bold>0.887</bold></td></tr><tr style="border-bottom: solid thin"><td align="center" valign="middle">DMSO</td><td align="center" valign="middle">0.459</td><td align="center" valign="middle"><bold>0.866</bold></td><td align="center" valign="middle">0.845</td></tr><tr><td align="center" valign="middle">Macro average</td><td align="center" valign="middle">0.724</td><td align="center" valign="middle">0.766</td><td align="center" valign="middle"><bold>0.776</bold></td></tr></tbody></table></table-wrap></table-wrap-group><table-wrap-group id="T2" position="float" orientation="portrait"><label>Table 2</label><caption><title>Comparison of results from the models trained on BF and FL images and CP features when DMSO was excluded as a predictive class.</title></caption><table-wrap id="T03" position="float" orientation="portrait"><label>(a)</label><caption><title>Macro-F1 scores on the test sets across the five data splits for BF, FL and CP models.</title></caption><table frame="below" rules="cols"><thead><tr style="border-bottom: solid thin"><th align="center" valign="middle">Modality</th><th align="center" valign="middle">BF</th><th align="center" valign="middle">FL</th><th align="center" valign="middle">CP</th></tr></thead><tbody><tr><td align="center" valign="middle">Split1</td><td align="center" valign="middle">0.765</td><td align="center" valign="middle">0.753</td><td align="center" valign="middle"><bold>0.781</bold></td></tr><tr><td align="center" valign="middle">Split2</td><td align="center" valign="middle">0.821</td><td align="center" valign="middle">0.809</td><td align="center" valign="middle"><bold>0.829</bold></td></tr><tr><td align="center" valign="middle">Split 3</td><td align="center" valign="middle">0.767</td><td align="center" valign="middle"><bold>0.782</bold></td><td align="center" valign="middle">0.775</td></tr><tr><td align="center" valign="middle">Split4</td><td align="center" valign="middle"><bold>0.746</bold></td><td align="center" valign="middle">0.714</td><td align="center" valign="middle">0.729</td></tr><tr><td align="center" valign="middle">Split5</td><td align="center" valign="middle"><bold>0.795</bold></td><td align="center" valign="middle">0.718</td><td align="center" valign="middle">0.763</td></tr></tbody></table></table-wrap><table-wrap id="T04" position="float" orientation="portrait"><label>(b)</label><caption><title>F1 scores per MoA, across all five test sets, for BF, FL, and CP models.</title></caption><table frame="below" rules="cols"><thead><tr style="border-bottom: solid thin"><th align="center" valign="middle">MoA</th><th align="center" valign="middle">BF</th><th align="center" valign="middle">FL</th><th align="center" valign="middle">CP</th></tr></thead><tbody><tr><td align="center" valign="middle">ATPase-i</td><td align="center" valign="middle"><bold>0.760</bold></td><td align="center" valign="middle">0.706</td><td align="center" valign="middle">0.731</td></tr><tr><td align="center" valign="middle">AuroraK-i</td><td align="center" valign="middle"><bold>0.744</bold></td><td align="center" valign="middle">0.743</td><td align="center" valign="middle">0.700</td></tr><tr><td align="center" valign="middle">HDAC-i</td><td align="center" valign="middle"><bold>0.800</bold></td><td align="center" valign="middle">0.785</td><td align="center" valign="middle">0.772</td></tr><tr><td align="center" valign="middle">HSP-i</td><td align="center" valign="middle"><bold>0.744</bold></td><td align="center" valign="middle">0.708</td><td align="center" valign="middle">0.716</td></tr><tr><td align="center" valign="middle">JAK-i</td><td align="center" valign="middle"><bold>0.756</bold></td><td align="center" valign="middle">0.671</td><td align="center" valign="middle">0.705</td></tr><tr><td align="center" valign="middle">PARP-i</td><td align="center" valign="middle">0.890</td><td align="center" valign="middle">0.878</td><td align="center" valign="middle"><bold>0.960</bold></td></tr><tr><td align="center" valign="middle">Prot.Synth.-i</td><td align="center" valign="middle"><bold>0.884</bold></td><td align="center" valign="middle">0.767</td><td align="center" valign="middle">0.799</td></tr><tr><td align="center" valign="middle">Ret.Rec.Ag</td><td align="center" valign="middle">0.682</td><td align="center" valign="middle">0.765</td><td align="center" valign="middle"><bold>0.815</bold></td></tr><tr><td align="center" valign="middle">Topo.-i</td><td align="center" valign="middle">0.733</td><td align="center" valign="middle">0.715</td><td align="center" valign="middle"><bold>0.771</bold></td></tr><tr style="border-bottom: solid thin"><td align="center" valign="middle">Tub.Pol.-i</td><td align="center" valign="middle"><bold>0.891</bold></td><td align="center" valign="middle">0.852</td><td align="center" valign="middle">0.871</td></tr><tr><td align="center" valign="middle">Macro average</td><td align="center" valign="middle"><bold>0.788</bold></td><td align="center" valign="middle">0.759</td><td align="center" valign="middle">0.784</td></tr></tbody></table></table-wrap></table-wrap-group></floats-group></article>