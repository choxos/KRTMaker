<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS156517</article-id><article-id pub-id-type="doi">10.1101/2021.11.16.468360</article-id><article-id pub-id-type="archive">PPR421147</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">6</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Optimal information loading into working memory in prefrontal cortex explains dynamic coding</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Stroud</surname><given-names>Jake P.</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="corresp" rid="CR1">@</xref></contrib><contrib contrib-type="author"><name><surname>Watanabe</surname><given-names>Kei</given-names></name><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Suzuki</surname><given-names>Takafumi</given-names></name><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Stokes</surname><given-names>Mark G.</given-names></name><xref ref-type="aff" rid="A4">4</xref><xref ref-type="aff" rid="A5">5</xref></contrib><contrib contrib-type="author"><name><surname>Lengyel</surname><given-names>Máté</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A6">6</xref></contrib></contrib-group><aff id="A1"><label>1</label>Computational and Biological Learning Lab, Department of Engineering, University of Cambridge, Cambridge, UK</aff><aff id="A2"><label>2</label>Graduate School of Frontier Biosciences, Osaka University, Osaka, Japan</aff><aff id="A3"><label>3</label>Center for Information and Neural Networks, National Institute of Communication and Information Technology, Osaka, Japan</aff><aff id="A4"><label>4</label>Department of Experimental Psychology, University of Oxford, Oxford, UK</aff><aff id="A5"><label>5</label>Oxford Centre for Human Brain Activity, Wellcome Centre for Integrative Neuroimaging, Department of Psychiatry, University of Oxford, Oxford, UK</aff><aff id="A6"><label>6</label>Center for Cognitive Computation, Department of Cognitive Science, Central European University, Budapest, Hungary</aff><author-notes><corresp id="CR1"><label>@</label>corresponding author: <email>j.stroud@eng.cam.ac.uk</email></corresp></author-notes><pub-date pub-type="nihms-submitted"><day>02</day><month>11</month><year>2022</year></pub-date><pub-date pub-type="preprint"><day>31</day><month>10</month><year>2022</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Working memory involves the short-term maintenance of information and is critical in many tasks. The neural circuit dynamics underlying working memory remain poorly understood, with different aspects of prefrontal cortical (PFC) responses explained by different putative mechanisms. By mathematical analysis, numerical simulations, and using recordings from monkey PFC, we investigate a critical but hitherto ignored aspect of working memory dynamics: information loading. We find that, contrary to common assumptions, optimal loading of information into working memory involves inputs that are largely orthogonal, rather than similar, to the persistent activities observed during memory maintenance, naturally leading to the widely observed phenomenon of dynamic coding in PFC. Using a novel, theoretically principled metric, we show that PFC exhibits the hallmarks of optimal information loading. We also find that optimal loading emerges as a general dynamical strategy in task-optimized recurrent neural networks. Our theory unifies previous, seemingly conflicting theories of memory maintenance based on attractor or purely sequential dynamics, and reveals a normative principle underlying dynamic coding.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">Working memory requires the ability to temporarily hold information in mind, and it is essential to performing cognitively demanding tasks<sup><xref ref-type="bibr" rid="R1">1</xref>,<xref ref-type="bibr" rid="R2">2</xref></sup>. A widely observed neural correlate of the maintenance of information in working memory is selective persistent activity. For example, in the paradigmatic memory-guided saccade task<sup><xref ref-type="bibr" rid="R3">3</xref>–<xref ref-type="bibr" rid="R13">13</xref></sup>, subjects must maintain the location of one out of several cues during a delay period after which they must respond with a saccade to the correct location (<xref ref-type="fig" rid="F1">Fig. 1a</xref>). Cells in the lateral prefrontal cortex (lPFC) show elevated levels of activity that persist during the delay period and that is selective to the location of the now-absent cue<sup><xref ref-type="bibr" rid="R3">3</xref>–<xref ref-type="bibr" rid="R5">5</xref>,<xref ref-type="bibr" rid="R9">9</xref></sup>. However, neurons typically only reach a steady, persistent level of activity late in the delay period of a trial<sup><xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R10">10</xref>,<xref ref-type="bibr" rid="R11">11</xref>,<xref ref-type="bibr" rid="R14">14</xref>–<xref ref-type="bibr" rid="R20">20</xref></sup>. In contrast, during the cue and early delay period, neurons in lPFC often exhibit strong transient dynamics during a variety of working memory tasks<sup><xref ref-type="bibr" rid="R3">3</xref>,<xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R10">10</xref>,<xref ref-type="bibr" rid="R11">11</xref>,<xref ref-type="bibr" rid="R14">14</xref>–<xref ref-type="bibr" rid="R24">24</xref></sup>.</p><p id="P3">It remains unknown what mechanism underlies the combination of persistent and dynamically changing neural activities in lPFC—especially in light of recent population-level analyses. These analyses, using the technique of ‘cross-temporal decoding’, place particularly stringent constraints on any candidate neural mechanism of working memory maintenance. Crosstemporal decoding measures how well information about the cue location can be decoded from neural responses when a decoder is trained and tested on any pair of time points during a trial<sup><xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R10">10</xref>,<xref ref-type="bibr" rid="R11">11</xref>,<xref ref-type="bibr" rid="R14">14</xref>,<xref ref-type="bibr" rid="R15">15</xref>,<xref ref-type="bibr" rid="R25">25</xref></sup> (<xref ref-type="fig" rid="F1">Fig. 1b</xref>). These analyses reveal a consistent but somewhat puzzling set of results. First, when decoder training and testing times are identical, decodability is high (<xref ref-type="fig" rid="F1">Fig. 1b</xref>, dark along the diagonal), confirming that information about cue location is indeed present in the population at all times. Decodability is also high when both training and testing occurs during the late delay period, suggesting that even if there are changes in neural responses during this period, the coding of cue location remains stable (<xref ref-type="fig" rid="F1">Fig. 1b</xref>, black inside cyan square). However, decoding performance remains low when a decoder is trained during the cue or early delay period and tested during the late delay period, and vice-versa (<xref ref-type="fig" rid="F1">Fig. 1b</xref>, light gray inside pink rectangles). This demonstrates that the neural code for cue location undergoes substantial change between these these two periods—a phenomenon that has been called ‘dynamic coding’<sup><xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R10">10</xref>,<xref ref-type="bibr" rid="R14">14</xref>–<xref ref-type="bibr" rid="R16">16</xref>,<xref ref-type="bibr" rid="R25">25</xref></sup>.</p><p id="P4">Classically, the neural mechanism of working memory maintenance is thought to rely on attractor network dynamics. Attractor networks<sup><xref ref-type="bibr" rid="R5">5</xref>,<xref ref-type="bibr" rid="R7">7</xref>,<xref ref-type="bibr" rid="R12">12</xref>,<xref ref-type="bibr" rid="R28">28</xref>–<xref ref-type="bibr" rid="R33">33</xref></sup>, and closely related ‘integrator’ networks<sup><xref ref-type="bibr" rid="R34">34</xref>,<xref ref-type="bibr" rid="R35">35</xref></sup>, naturally account for selective persistent activity (<xref ref-type="fig" rid="F1">Fig. 1c</xref>, left and middle). However, in these models, neurons show limited transient activity during the delay period, and crosstemporal decoding reveals stable coding throughout the whole trial, lacking the characteristic dynamic coding seen in experimental data (compare <xref ref-type="fig" rid="F1">Fig. 1b to c</xref>, right). This behavior emerges across several variants of attractor networks, whether they express a continuum of persistent activity patterns (‘ring’ or ‘bump’ attractor networks) or a finite number of discrete patterns (<xref ref-type="fig" rid="F7">Extended Data Fig. 1a–b</xref>; see also <xref ref-type="supplementary-material" rid="SD1">Supplementary Information S1</xref>). Critically, even when external inputs were specifically chosen so that neural activity showed longer transient dynamics<sup><xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R26">26</xref></sup> (<xref ref-type="fig" rid="F1">Fig. 1d</xref>), these inputs still relied on a large overlap with the desired persistent state (<xref ref-type="fig" rid="F1">Fig. 1d</xref>, left). As a result, these models also exhibited strongly stable stimulus coding over time (<xref ref-type="fig" rid="F1">Fig. 1d</xref>, right and <xref ref-type="fig" rid="F7">Extended Data Fig. 1c</xref>) and the transient dynamics were regarded as being purely epiphenomenal<sup><xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R26">26</xref></sup>.</p><p id="P5">To capture transient dynamics more naturally, a very different class of models have been developed based on mechanisms that generate neural activity sequences. These models typically rely either on effectively feedforward network connectivity<sup><xref ref-type="bibr" rid="R21">21</xref>,<xref ref-type="bibr" rid="R27">27</xref></sup> or chaotic network dynamics<sup><xref ref-type="bibr" rid="R24">24</xref>,<xref ref-type="bibr" rid="R36">36</xref>–<xref ref-type="bibr" rid="R38">38</xref></sup>. The dynamics of such models rapidly transition between orthogonal subspaces over time (<xref ref-type="fig" rid="F1">Fig. 1e</xref>, left), thus cross-temporal decoding is high only between neighbouring time-points (<xref ref-type="fig" rid="F1">Fig. 1e</xref>, black along diagonal). Although such models are ideally suited to capturing transient neural responses (<xref ref-type="fig" rid="F1">Fig. 1e</xref>, center), they fail to exhibit persistent activities and stable coding during the late delay period (<xref ref-type="fig" rid="F1">Fig. 1e</xref>, right; gray inside blue square). Therefore, previous work leaves open two interrelated key questions: how can a neural circuit exhibit early sequential dynamics followed by stable late-delay dynamics, and more importantly, why would it use such a counterintuitive dynamical regime?</p><p id="P6">In order to study the network mechanisms underlying the combination of persistent and dynamic neural activities during working memory, we build on recent advances in using task-optimized neural networks<sup><xref ref-type="bibr" rid="R13">13</xref>,<xref ref-type="bibr" rid="R17">17</xref>,<xref ref-type="bibr" rid="R20">20</xref>,<xref ref-type="bibr" rid="R24">24</xref>,<xref ref-type="bibr" rid="R36">36</xref>,<xref ref-type="bibr" rid="R39">39</xref>–<xref ref-type="bibr" rid="R41">41</xref></sup>. We find that the behaviour of such task-optimized networks unifies attractor and sequential activity models, showing both early transient dynamics and late persistent activities, giving rise to dynamic coding (<xref ref-type="fig" rid="F1">Fig. 1f</xref>). To understand the principles and functional significance of this dynamical behavior, we focus on a hitherto ignored aspect of the operation of attractor networks: optimal information loading. Through numerical simulations and mathematical analyses, we show that inputs that most efficiently drive network activities into a desired attractor state tend to be orthogonal to the attractor state itself (<xref ref-type="fig" rid="F1">Fig. 1f</xref>, left). Critically, this results in an initial period of strong transient dynamics with dynamic coding (<xref ref-type="fig" rid="F1">Fig. 1f</xref>, right), which are thus fundamental and functionally useful features of attractor dynamics when used with optimal inputs. Based on our theoretical results, we develop a specific neural measure for assessing whether a network uses optimal information loading. Using this measure, we demonstrate key signatures of optimal information loading in neural recordings from lPFC. Finally, we show that optimal information loading emerges naturally in task-optimized neural networks with a variety of architectures, including linear integrators, as well as nonlinear discrete and ring attractor models.</p><p id="P7">Our results offer a novel, normative perspective on a core but hitherto ignored component of attractor networks dynamics—information loading—and challenge long-held assumptions about pattern completion-like mechanisms in neural circuits.</p></sec><sec id="S2" sec-type="results"><title>Results</title><sec id="S3"><title>Pattern completion and optimal information loading in attractor networks</title><p id="P8">Traditional approaches to studying attractor networks used models in which the connectivity between neurons was constrained to be effectively symmetric<sup><xref ref-type="bibr" rid="R5">5</xref>,<xref ref-type="bibr" rid="R7">7</xref>,<xref ref-type="bibr" rid="R28">28</xref>,<xref ref-type="bibr" rid="R30">30</xref>,<xref ref-type="bibr" rid="R32">32</xref>,<xref ref-type="bibr" rid="R34">34</xref>,<xref ref-type="bibr" rid="R35">35</xref>,<xref ref-type="bibr" rid="R42">42</xref>–<xref ref-type="bibr" rid="R45">45</xref></sup>, making the analysis of their dynamics mathematically more convenient<sup><xref ref-type="bibr" rid="R28">28</xref>,<xref ref-type="bibr" rid="R34">34</xref>,<xref ref-type="bibr" rid="R42">42</xref>,<xref ref-type="bibr" rid="R46">46</xref></sup>. Thus, we first replicated results with such symmetric networks that were optimized to perform the working memory task shown in <xref ref-type="fig" rid="F1">Fig. 1a</xref>. In particular, we defined optimal information loading to be achieved by a set of inputs when they maximize the performance of a network in terms of how well the cue can be decoded from its neural activities at the end of the delay period. For simplicity, we only modelled the intrinsic dynamics of the network during the delay period and the effect of the cue was captured by cue-specific initial neural activities (i.e. neural activities at the beginning of the delay period<sup><xref ref-type="bibr" rid="R35">35</xref>,<xref ref-type="bibr" rid="R42">42</xref>,<xref ref-type="bibr" rid="R43">43</xref></sup>; <xref ref-type="fig" rid="F2">Fig. 2b</xref>). To study optimal information loading, we optimized these initial activities for cue-decodability at the end of the delay period (<xref ref-type="sec" rid="S17">Methods 1.3.1</xref>).</p><p id="P9">Optimal initial activities gave rise to classical pattern completion dynamics in symmetric networks. First, initial activities were noisy versions of (and in fact highly similar to) the desired persistent patterns (<xref ref-type="fig" rid="F2">Fig. 2b</xref> inset, and <xref ref-type="fig" rid="F2">Fig. 2c</xref>). Second, the ensuing dynamics were driven directly into the corresponding persistent state, resulting in only small and gradual changes in activities over the delay period (<xref ref-type="fig" rid="F2">Fig. 2b</xref>). Further analysis of these dynamics showed that the optimal initial activities aligned well with directions in neural state space that best distinguished between the desired persistent activities (<xref ref-type="fig" rid="F2">Fig. 2d</xref>, ‘persistent PC1’ component of pale arrows and circles; <xref ref-type="fig" rid="F8">Extended Data Fig. 2b</xref>), with only a comparably small component in orthogonal directions specific to these initial activities (<xref ref-type="fig" rid="F2">Fig. 2d</xref>, ‘initial PC1, orthogonalized’) which subsequently changed little over time (<xref ref-type="fig" rid="F2">Fig. 2d</xref>, dark trajectories). As a result, cross-temporal decoding performance was high for all pairs of times (<xref ref-type="fig" rid="F2">Fig. 2e</xref>), and—as a special case—a decoder based on templates of neural activity during the late delay period (i.e. during the steady state of the network), generalized well to all times and was able to decode the cue identity from neural activities with high accuracy throughout the delay period (<xref ref-type="fig" rid="F2">Fig. 2f</xref>, black line).</p><p id="P10">The similarity between initial and persistent activities was critical for these networks. When constrained to use initial activities that were orthogonal in neural state space to persistent activities (i.e. lying in the ‘persistent nullspace’), these networks performed substantially more poorly (<xref ref-type="fig" rid="F2">Fig. 2f</xref>, red line) and activity often did not settle into the correct attractor state (<xref ref-type="fig" rid="F8">Extended Data Fig. 2d</xref>). In contrast, explicitly enforcing these networks to use initial activities that were similar to persistent activities (i.e. lying in the ‘persistent subspace’) did not compromise their performance (<xref ref-type="fig" rid="F2">Fig. 2f</xref>, green line; <xref ref-type="fig" rid="F8">Extended Data Fig. 2c</xref>). Thus, when connectivities were constrained to be symmetric, our approach using explicitly optimized inputs and connectivities recapitulated earlier results obtained with classical attractor networks using hand-crafted inputs and connectivities<sup><xref ref-type="bibr" rid="R5">5</xref>,<xref ref-type="bibr" rid="R7">7</xref>,<xref ref-type="bibr" rid="R12">12</xref>,<xref ref-type="bibr" rid="R28">28</xref>,<xref ref-type="bibr" rid="R30">30</xref>,<xref ref-type="bibr" rid="R33">33</xref>,<xref ref-type="bibr" rid="R42">42</xref></sup>.</p><p id="P11">In contrast, attractor networks optimized without a symmetry constraint exhibited dynamics distinctly unlike simple pattern completion (<xref ref-type="fig" rid="F2">Fig. 2g–l</xref>). First, initial activities resembled persistent activity much less than in symmetric networks (<xref ref-type="fig" rid="F2">Fig. 2i</xref>), such that their correlation could even be negative (<xref ref-type="fig" rid="F2">Fig. 2h</xref> inset). Second, neural activities often underwent substantial and non-monotonic changes before ultimately settling into an attractor state (<xref ref-type="fig" rid="F2">Fig. 2h</xref>). This was also reflected in optimal initial activities (<xref ref-type="fig" rid="F2">Fig. 2j</xref>, pale arrows and open circles) being strongly orthogonal to persistent activities (<xref ref-type="fig" rid="F2">Fig. 2j</xref>, black crosses; <xref ref-type="fig" rid="F8">Extended Data Fig. 2f</xref>), with this orthogonality decaying over the delay period (<xref ref-type="fig" rid="F2">Fig. 2j</xref>, dark trajectories). Such dynamics are consistent with PFC recordings from primates performing a variety of working memory tasks<sup><xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R17">17</xref>,<xref ref-type="bibr" rid="R22">22</xref>–<xref ref-type="bibr" rid="R24">24</xref>,<xref ref-type="bibr" rid="R32">32</xref>,<xref ref-type="bibr" rid="R47">47</xref>–<xref ref-type="bibr" rid="R49">49</xref></sup>. Decoding analyses revealed further similarities with experimental data: a decoder trained on neural activity from the late delay period generalized poorly to early times (<xref ref-type="fig" rid="F2">Fig. 2k</xref>, and <xref ref-type="fig" rid="F2">Fig. 2l</xref>, black line) and vice versa (<xref ref-type="fig" rid="F2">Fig. 2k</xref>), thus exhibiting a fundamental signature of ‘dynamic coding’<sup><xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R10">10</xref>,<xref ref-type="bibr" rid="R14">14</xref>–<xref ref-type="bibr" rid="R16">16</xref></sup> (cf. <xref ref-type="fig" rid="F1">Fig. 1b</xref>). Importantly, we found that the orthogonality of initial conditions in these networks was instrumental for high performance: in a double dissociation from symmetrically constrained networks, restricting initial conditions to be in the persistent subspace (<xref ref-type="fig" rid="F2">Fig. 2l</xref>, green line; <xref ref-type="fig" rid="F8">Extended Data Fig. 2g</xref>), but not in the persistent nullspace (<xref ref-type="fig" rid="F2">Fig. 2l</xref>, red line; <xref ref-type="fig" rid="F8">Extended Data Fig. 2h</xref>), diminished decodability at the end of the delay period (cf. <xref ref-type="fig" rid="F2">Fig. 2f</xref>).</p><p id="P12">The above results were obtained with networks storing a small number of discrete attractors, corresponding to the six cue conditions. Previous work found that several aspects of working memory dynamics in lPFC are better captured by networks in which instead a large number (or even a continuum) of attractor states form a ring in neural state space<sup><xref ref-type="bibr" rid="R5">5</xref>,<xref ref-type="bibr" rid="R7">7</xref>,<xref ref-type="bibr" rid="R44">44</xref>,<xref ref-type="bibr" rid="R45">45</xref></sup>. Thus, we repeated our analyses on optimized networks while explicitly encouraging such a ring attractor to form during optimization (<xref ref-type="sec" rid="S20">Methods 1.3.4</xref>). We found a highly similar pattern of results in ring attractor networks as compared with discrete attractor networks (<xref ref-type="fig" rid="F9">Extended Data Fig. 3</xref>).</p></sec><sec id="S4"><title>Dynamical analysis of optimal information loading</title><p id="P13">To understand why optimal information loading in classical symmetrically constrained versus unconstrained attractor networks is so different, and in particular why inputs orthogonal to attractor states are optimal for unconstrained networks, we reduced these networks to a canonical minimal model class consisting of only two neurons<sup><xref ref-type="bibr" rid="R35">35</xref>,<xref ref-type="bibr" rid="R50">50</xref>,<xref ref-type="bibr" rid="R51">51</xref></sup>. For analytical tractability, we considered networks with linear dynamics (i.e. in which neurons had linear activation functions). Critically, with the appropriate set of synaptic connections, even linear networks can exhibit persistent activity<sup><xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R26">26</xref>,<xref ref-type="bibr" rid="R34">34</xref>,<xref ref-type="bibr" rid="R35">35</xref>,<xref ref-type="bibr" rid="R46">46</xref>,<xref ref-type="bibr" rid="R52">52</xref></sup>—the key feature of working memory maintenance in attractor networks.</p><p id="P14">For our analyses, we again distinguished between models with symmetric connectivity between neurons (<xref ref-type="fig" rid="F3">Fig. 3a</xref>; top)<sup><xref ref-type="bibr" rid="R34">34</xref>,<xref ref-type="bibr" rid="R35">35</xref>,<xref ref-type="bibr" rid="R51">51</xref></sup>, and models without this constraint (<xref ref-type="fig" rid="F3">Fig. 3a</xref>; bottom)<sup><xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R26">26</xref></sup>. In either case, the specific connection strengths were chosen to create illustrative examples providing intuitions that—as we show below—also generalize to large networks with randomly sampled connection strengths (<xref ref-type="fig" rid="F3">Fig. 3d–e</xref>, <xref ref-type="fig" rid="F4">Fig. 4</xref>). The dynamics of these networks are fully described in a two-dimensional neural state space spanned by the activities of the two neurons (<xref ref-type="fig" rid="F3">Fig. 3b</xref>) and define a flow-field in this space determining how neural activities change over time (<xref ref-type="fig" rid="F3">Fig. 3b</xref>; blue arrows). An important subspace of the full neural state space of these networks is the ‘persistent subspace’ corresponding to persistent patterns of activities. In our two-neuron linear networks, the persistent subspace simply corresponds to a line onto which the neural activities ultimately converge over time (<xref ref-type="fig" rid="F3">Fig. 3b</xref>; green lines showing the persistent mode). Therefore, the persistent mode allows these networks to distinguish between two stimuli depending on which side of the origin the state of the network is. The larger the magnitude of its activity along this persistent mode at the end of the delay period, the more robustly the identity of the stimulus can be decoded (e.g. in the presence of noise, as we show below).</p><p id="P15">To understand the mechanisms of information loading, we considered three distinct stimulus input directions. We then analysed the time course of the neural activities projected onto the persistent mode<sup><xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R26">26</xref>,<xref ref-type="bibr" rid="R30">30</xref></sup> after being initialised in each of these directions. First, we considered inputs aligned with the persistent mode, the input direction studied in classical attractor networks<sup><xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R26">26</xref>,<xref ref-type="bibr" rid="R34">34</xref>,<xref ref-type="bibr" rid="R35">35</xref>,<xref ref-type="bibr" rid="R51">51</xref></sup> (<xref ref-type="fig" rid="F3">Fig. 3b</xref>; pale green arrows and open circles). Second, we considered the ‘most amplifying mode’, which is defined as the stimulus direction that generates the most divergent and thus best discriminable activity over time<sup><xref ref-type="bibr" rid="R53">53</xref>–<xref ref-type="bibr" rid="R57">57</xref></sup> (<xref ref-type="sec" rid="S32">Methods 1.7.1</xref>; <xref ref-type="fig" rid="F3">Fig. 3b</xref>, red lines, and pale red arrows and open circles). Third, we considered a random input direction (<xref ref-type="fig" rid="F3">Fig. 3b</xref>; gray lines/circles).</p><p id="P16">We were able to show mathematically that optimal information loading, in the sense of maximizing overlap with the persistent mode at sufficiently long delays, is always achieved with inputs aligned with the most amplifying mode (<xref ref-type="supplementary-material" rid="SD1">Supplementary Information S2</xref>). Equivalently, the most amplifying mode is the input direction that requires the smallest magnitude initial condition to achieve a desired level of persistent activity (i.e. a desired level of performance). More generally, we could also show both mathematically and in simulations (<xref ref-type="fig" rid="F10">Extended Data Fig. 4</xref>) that the most amplifying mode is near optimal in achieving a desired level of performance while minimizing total neural activity over time (i.e. the total energy used by the network) for sufficiently long delay lengths.</p><p id="P17">In symmetric networks, the most amplifying mode is aligned with the most persistent mode (<xref ref-type="fig" rid="F3">Fig. 3b</xref>; top)<sup><xref ref-type="bibr" rid="R58">58</xref>,<xref ref-type="bibr" rid="R59">59</xref></sup>, and thus does not generate activity transients (<xref ref-type="fig" rid="F3">Fig. 3c</xref>; top)—accounting for the simple pattern completion dynamics seen in classical attractor networks with symmetric connectivity<sup><xref ref-type="bibr" rid="R5">5</xref>,<xref ref-type="bibr" rid="R7">7</xref>,<xref ref-type="bibr" rid="R28">28</xref>,<xref ref-type="bibr" rid="R30">30</xref>,<xref ref-type="bibr" rid="R32">32</xref>,<xref ref-type="bibr" rid="R34">34</xref>,<xref ref-type="bibr" rid="R35">35</xref>,<xref ref-type="bibr" rid="R42">42</xref>,<xref ref-type="bibr" rid="R43">43</xref></sup> (<xref ref-type="fig" rid="F2">Fig. 2a–f</xref>). However, in unconstrained networks, the most amplifying mode is typically different from the most persistent mode (<xref ref-type="fig" rid="F3">Fig. 3b</xref>; bottom). Intuitively, this is because effective feedforward connections exist in unconstrained networks<sup><xref ref-type="bibr" rid="R21">21</xref>,<xref ref-type="bibr" rid="R27">27</xref>,<xref ref-type="bibr" rid="R50">50</xref>,<xref ref-type="bibr" rid="R56">56</xref>,<xref ref-type="bibr" rid="R60">60</xref></sup>. For example, neurons 1 and 2 in the example network shown in <xref ref-type="fig" rid="F3">Fig. 3a</xref> (bottom) respectively align strongly with the persistent and amplifying modes (<xref ref-type="fig" rid="F3">Fig. 3b</xref>, bottom). Thus, feeding neuron 1 indirectly through the feedforward connection from neuron 2 can increase its activity more than just feeding it directly. This means that activity evolving from the most amplifying mode exhibits a distinct transient behaviour: its overlap with the most persistent mode is initially low and then increases over time (<xref ref-type="fig" rid="F3">Fig. 3c</xref>; bottom, red line), accounting for the richer transients seen in unconstrained attractor networks (<xref ref-type="fig" rid="F2">Fig. 2g–l</xref>). Thus, there is a form of ‘speed–accuracy’ trade-off between whether inputs should use the most amplifying or persistent mode: if information is required immediately following stimulus offset, such as in a perceptual decision-making task<sup><xref ref-type="bibr" rid="R13">13</xref>,<xref ref-type="bibr" rid="R40">40</xref>,<xref ref-type="bibr" rid="R59">59</xref></sup>, inputs need to use the persistent mode. However, if there is a time delay until the information is needed, as is the case in all working memory tasks<sup><xref ref-type="bibr" rid="R2">2</xref>,<xref ref-type="bibr" rid="R61">61</xref></sup>, then the most amplifying mode becomes the optimal input direction. Indeed, an analogous trade-off was already apparent between the persistent sub- vs. nullspace inputs in the nonlinear attractor networks we analysed earlier (<xref ref-type="fig" rid="F2">Fig. 2l</xref>, red vs. green).</p><p id="P18">The insights obtained in the simple two-neuron network also generalized to large randomly connected linear integrator networks, with more than two neurons (<xref ref-type="fig" rid="F3">Fig. 3d,e</xref>; see <xref ref-type="sec" rid="S22">Methods 1.4.1</xref>). Moreover, as network size grows, in unconstrained (but not in symmetric) networks, the most amplifying direction becomes increasingly orthogonal to the most persistent mode<sup><xref ref-type="bibr" rid="R62">62</xref></sup>, further accentuating the advantage of amplifying over persistent mode inputs<sup><xref ref-type="bibr" rid="R62">62</xref></sup> (<xref ref-type="fig" rid="F3">Fig. 3d–e</xref>, <xref ref-type="fig" rid="F11">Extended Data Fig. 5a–b</xref>; red vs. green). This is because in large unconstrained networks, there are many effectively feedforward motifs embedded in the full recurrent connectivity of the circuit, which can all contribute to transient amplification<sup><xref ref-type="bibr" rid="R21">21</xref></sup>. Random initial conditions become fully orthogonal in both networks and result in poor overlap with the persistent mode (<xref ref-type="fig" rid="F3">Fig. 3d–e</xref>, <xref ref-type="fig" rid="F11">Extended Data Fig. 5a–b</xref>; black). Numerical simulations confirmed that these results also generalized to networks with noisy dynamics (<xref ref-type="fig" rid="F11">Extended Data Fig. 5c</xref>). Moreover, explicitly optimizing the initial condition of such a network so as to maximize the persistent activity it generated at the end of a delay period also made this initial condition overlap strongly with the network’s most amplifying mode (<xref ref-type="fig" rid="F11">Extended Data Fig. 5d</xref>).</p><p id="P19">As our mathematical analyses only applied to linear dynamics, we used numerical simulations to study how they generalized to nonlinear dynamics. We found that the same principles applied to the dynamics of a canonical 2-dimensional nonlinear attractor system (analogous to the networks in <xref ref-type="fig" rid="F3">Fig. 3a–c</xref>), when the persistent and most amplifying directions were defined locally around its ground state (<xref ref-type="sec" rid="S30">Methods 1.6</xref>; <xref ref-type="fig" rid="F12">Extended Data Fig. 6</xref>, see also <xref ref-type="supplementary-material" rid="SD1">Supplementary Information S3</xref>). Importantly, we also found that large optimized nonlinear neural networks (with discrete or ring attractors) also showed a similar pattern of results (<xref ref-type="fig" rid="F9">Extended Data Fig. 3e</xref>, and <xref ref-type="fig" rid="F13">Extended Data Fig. 7a–c</xref>, see also <xref ref-type="supplementary-material" rid="SD1">Supplementary Information S4</xref>).</p></sec><sec id="S5"><title>Neural signatures of optimal information loading</title><p id="P20">Our dynamical analysis suggested that there should be clearly identifiable neural signatures of a network performing optimal information loading. To demonstrate this, and to allow a more direct comparison with data, we used the same large, randomly connected, unconstrained networks that we analysed earlier (<xref ref-type="fig" rid="F3">Fig. 3d–e</xref>, bottom), with noisy dynamics (as in <xref ref-type="fig" rid="F11">Extended Data Fig. 5c–d</xref>) and the cue period modelled using temporally extended constant inputs—mimicking typical experiments<sup><xref ref-type="bibr" rid="R3">3</xref>–<xref ref-type="bibr" rid="R5">5</xref>,<xref ref-type="bibr" rid="R10">10</xref></sup> (<xref ref-type="fig" rid="F4">Fig. 4</xref>). We studied the three different information loading strategies that we identified earlier: inputs aligned with either the persistent mode, the most amplifying mode, or a cuespecific random direction.</p><p id="P21">We began by conducting a decoding analysis using templates of late delay activity, as is often done for prefrontal cortical recordings<sup><xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R10">10</xref>,<xref ref-type="bibr" rid="R14">14</xref>,<xref ref-type="bibr" rid="R15">15</xref>,<xref ref-type="bibr" rid="R25">25</xref></sup> (and also in <xref ref-type="fig" rid="F2">Fig. 2f,l</xref>). We first verified that for a fixed level of neuronal noise, the most amplifying inputs were indeed optimal for achieving high decodability at the end of the delay period (<xref ref-type="fig" rid="F4">Fig. 4a</xref>, compare red line to pale green and gray lines). We were also able to show mathematically that, in line with our original definition of optimal information loading, the most amplifying inputs in noisy linear networks are optimal for maximizing average decodability during the delay period (<xref ref-type="supplementary-material" rid="SD1">Supplementary Information S2.7</xref>). In contrast, random inputs performed considerably more poorly (<xref ref-type="fig" rid="F4">Fig. 4a</xref>, gray line). Remarkably, persistent mode inputs achieved a similarly low level of decodability at late delay times (<xref ref-type="fig" rid="F4">Fig. 4a</xref>, compare pale green and gray lines).</p><p id="P22">The level of noise in the networks we have studied so far was not constrained by data, which typically shows high decodability<sup><xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R10">10</xref>,<xref ref-type="bibr" rid="R14">14</xref>,<xref ref-type="bibr" rid="R15">15</xref>,<xref ref-type="bibr" rid="R25">25</xref></sup>. This is important because the sub-optimal input conditions (<xref ref-type="fig" rid="F4">Fig. 4a</xref>, pale green and gray lines) could achieve high decoding performance by appropriately reducing the noise level in our simulations (<xref ref-type="fig" rid="F4">Fig. 4a</xref>, asymptotic values of dark green and black lines). Thus, asymptotic decoding performance alone cannot be used to identify the information loading strategy employed by a network. To address this, in subsequent analyses, we used networks in which the level of late-delay performance was matched between the three information loading strategies by appropriately reducing the level of noise when using persistent or random inputs. Nevertheless, a critical difference emerged between the different information loading strategies even in these ‘performance-matched’ networks. For both random and most amplifying input directions, the delay-trained decoder only performed well when tested late in the delay period (<xref ref-type="fig" rid="F4">Fig. 4a</xref>, black and red lines), whereas for inputs aligned with the persistent direction this decoder performed near ceiling at all times after cue onset (<xref ref-type="fig" rid="F4">Fig. 4a</xref>, dark green line).</p><p id="P23">Next, in order to more fully characterise the differences between persistent versus random or most amplifying inputs, and for a comprehensive comparison with experimental data<sup><xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R10">10</xref>,<xref ref-type="bibr" rid="R14">14</xref>,<xref ref-type="bibr" rid="R15">15</xref>,<xref ref-type="bibr" rid="R25">25</xref></sup>, we also employed full cross-temporal decoding (<xref ref-type="fig" rid="F4">Fig. 4b</xref>). This analysis showed that all information loading strategies led to dynamics in which stimulus information was present at all times after cue onset (<xref ref-type="fig" rid="F4">Fig. 4b</xref>, diagonals are all black). Moreover, for the persistent mode inputs, stimulus information was maintained using a ‘stable code’<sup><xref ref-type="bibr" rid="R10">10</xref>,<xref ref-type="bibr" rid="R11">11</xref>,<xref ref-type="bibr" rid="R14">14</xref>,<xref ref-type="bibr" rid="R16">16</xref></sup> (<xref ref-type="fig" rid="F4">Fig. 4b</xref>, left, all off-diagonals are black)—similar to previous integrator models of working memory<sup><xref ref-type="bibr" rid="R34">34</xref>,<xref ref-type="bibr" rid="R35">35</xref></sup> (<xref ref-type="fig" rid="F7">Extended Data Fig. 1c</xref>). In contrast, random and most amplifying mode inputs led to poor cross-temporal decodability between early and late time points after cue onset (<xref ref-type="fig" rid="F4">Fig. 4b</xref>, center and right, off-diagonals indicated by pink rectangles are white/gray). This gave rise to the phenomenon of ‘dynamic coding’<sup><xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R10">10</xref>,<xref ref-type="bibr" rid="R11">11</xref>,<xref ref-type="bibr" rid="R14">14</xref>–<xref ref-type="bibr" rid="R16">16</xref></sup>, and suggested sequential activities during the early-to-late delay transition<sup><xref ref-type="bibr" rid="R21">21</xref>,<xref ref-type="bibr" rid="R27">27</xref>,<xref ref-type="bibr" rid="R36">36</xref></sup>. These activities then stabilised during the late delay period as the network dynamics converged to a persistent pattern of activity (<xref ref-type="fig" rid="F4">Fig. 4b</xref>, center and right, off-diagonals inside cyan squares are black). In sum, these decoding analyses were able to clearly distinguish between persistent mode and random or amplifying inputs, but not between the latter two.</p><p id="P24">To clearly distinguish between networks using most amplifying inputs or merely a random input direction, we constructed a targeted measure for identifying networks using most amplifying inputs. To achieve this, we exploited the fact that in large networks, random inputs typically have negligible overlap with any other direction in neural state space, including the most amplifying mode. Thus, we directly measured the time courses of the overlap of neural activities with the top 25% most amplifying modes. We quantified this overlap as the fraction of across-condition variance of neural activities that these modes collectively explained (<xref ref-type="fig" rid="F4">Fig. 4c</xref>, red lines; <xref ref-type="sec" rid="S34">Methods 1.7.3</xref>). For a comparison, we also measured the overlap of neural activities with the top 25% most persistent modes (<xref ref-type="fig" rid="F4">Fig. 4c</xref>, green lines).</p><p id="P25">Persistent mode inputs led to constant high and moderate overlaps with the persistent and most amplifying modes, respectively (<xref ref-type="fig" rid="F4">Fig. 4c</xref>, left). Random inputs started with chance overlap for both modes, which then increased to the same levels that resulted from persistent mode inputs (<xref ref-type="fig" rid="F4">Fig. 4c</xref>, right). In contrast, most amplifying inputs were uniquely characterised by a cross-over between the time courses of the two overlap measures. Initially, neural activities overlapped strongly with the most amplifying mode, but showed only chance overlap with the persistent mode (<xref ref-type="fig" rid="F4">Fig. 4c</xref>, middle). Over time, these overlap measures changed in opposite directions, such that by the end of the delay period overlap was high with the persistent mode and lower with the most amplifying mode (<xref ref-type="fig" rid="F4">Fig. 4c</xref>, middle). Therefore, the cross-over of these overlap measures can be used as a signature of optimal information loading utilizing inputs aligned with the most amplifying modes.</p><p id="P26">To further illustrate how our overlap measures can distinguish between optimal and random input directions, we modified an earlier integrator model of working memory<sup><xref ref-type="bibr" rid="R6">6</xref></sup> (<xref ref-type="fig" rid="F7">Extended Data Fig. 1c</xref>, <xref ref-type="fig" rid="F14">Extended Data Fig. 8a,d</xref>) so that inputs lay in a purely randomly oriented subspace. This resulted in cross-temporal decoding matrices that looked similar to that achieved by the most amplifying mode (<xref ref-type="fig" rid="F14">Extended Data Fig. 8b</xref>), but the overlap measures that we developed here clearly revealed the lack of optimal information loading, even in this modified model (<xref ref-type="fig" rid="F14">Extended Data Fig. 8 e</xref>). In addition, we confirmed in numerical simulations that the same signature of optimal information loading remains detectable (and distinguishable from other information loading strategies) even under the practical constraints of experimental data analysis: when the underlying network dynamics is nonlinear, and only accessible indirectly by fitting linear dynamical models to the neural responses they generate (<xref ref-type="fig" rid="F13">Extended Data Fig. 7d</xref>, <xref ref-type="sec" rid="S24">Methods 1.4.3</xref> and <xref ref-type="supplementary-material" rid="SD1">Supplementary Information S4.4</xref>).</p></sec><sec id="S6"><title>Signatures of optimal information loading in monkey lPFC</title><p id="P27">To study whether the PFC shows the dynamical signatures of optimal information loading that our theoretical analyses identified, we analysed a d ata set<sup><xref ref-type="bibr" rid="R48">48</xref></sup> of multi-channel recordings of the lateral prefrontal cortex (lPFC) in two monkeys during a variable-delay memory-guided saccade task (<xref ref-type="fig" rid="F1">Fig. 1a</xref>). These recordings yielded 438 and 625 neurons (for monkeys K and T, respectively; <xref ref-type="fig" rid="F15">Extended Data Fig. 9</xref>, <xref ref-type="sec" rid="S10">Methods 1.1</xref>). We analysed the population dynamics of all recorded neurons in each monkey and applied the same metrics to this dataset that we applied to our models. Population dynamics appeared to show rich transient dynamics during the cue and early delay period, followed by relatively stable dynamics during the late delay period (<xref ref-type="fig" rid="F5">Fig. 5a</xref>). This was reminiscent of the dynamics we found in unconstrained attractor networks following optimal information loading (<xref ref-type="fig" rid="F2">Fig. 2h</xref>).</p><p id="P28">To further quantify this behaviour, we conducted decoding analyses. First, we found that a delay-trained decoder did not generalize to times outside of the delay period (<xref ref-type="fig" rid="F5">Fig. 5b</xref>). In particular, performance was near-chance level during the cue period and increased over the first 1 s of the delay period—in line with previous studies<sup><xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R10">10</xref>,<xref ref-type="bibr" rid="R14">14</xref>–<xref ref-type="bibr" rid="R16">16</xref>,<xref ref-type="bibr" rid="R25">25</xref></sup>. This was distinct from the pattern completion dynamics seen in classical attractor network models of working memory (<xref ref-type="fig" rid="F2">Fig. 2f,l</xref> green and <xref ref-type="fig" rid="F4">Fig. 4a</xref> green), but similar to that expected from random or optimal inputs in unconstrained networks (<xref ref-type="fig" rid="F2">Fig. 2l</xref> black and red; <xref ref-type="fig" rid="F4">Fig. 4a</xref> bottom, black and red).</p><p id="P29">Full cross-temporal decoding reinforced these results: decoders trained during the delay period did not generalize to the cue or go periods and vice versa (<xref ref-type="fig" rid="F5">Fig. 5c</xref> and <xref ref-type="fig" rid="F16">Extended Data Fig. 10a</xref>, pink rectangles). Thus, neural activity exhibited dynamic coding<sup><xref ref-type="bibr" rid="R14">14</xref>,<xref ref-type="bibr" rid="R15">15</xref></sup> rather than the stable coding characteristic of simple pattern completion (<xref ref-type="fig" rid="F1">Fig. 1c</xref> right; <xref ref-type="fig" rid="F4">Fig. 4b</xref> left; and <xref ref-type="fig" rid="F7">Extended Data Fig. 1a–c</xref> right). Importantly, same-time decoding performance was close to 1 throughout the cue and delay periods (<xref ref-type="fig" rid="F5">Fig. 5c</xref> and <xref ref-type="fig" rid="F16">Extended Data Fig. 10a</xref>, orange arrow). This confirmed that the poor cross-temporal generalization between early and late periods of a trial was not because the cue information had not yet reached PFC, or was maintained by activity-silent mechanisms<sup><xref ref-type="bibr" rid="R11">11</xref>,<xref ref-type="bibr" rid="R41">41</xref>,<xref ref-type="bibr" rid="R45">45</xref></sup>. At the same time, also in line with previous studies<sup><xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R10">10</xref>,<xref ref-type="bibr" rid="R14">14</xref>–<xref ref-type="bibr" rid="R16">16</xref></sup>, we found relatively stable coding during the late delay period (<xref ref-type="fig" rid="F5">Fig. 5c</xref> and <xref ref-type="fig" rid="F16">Extended Data Fig. 10a</xref>, cyan square). This ruled out purely sequential activity-based dynamics<sup><xref ref-type="bibr" rid="R21">21</xref>,<xref ref-type="bibr" rid="R27">27</xref>,<xref ref-type="bibr" rid="R37">37</xref>,<xref ref-type="bibr" rid="R38">38</xref>,<xref ref-type="bibr" rid="R63">63</xref></sup> (<xref ref-type="fig" rid="F1">Fig. 1d</xref> and <xref ref-type="fig" rid="F7">Extended Data Fig. 1d</xref>).</p><p id="P30">Quantifying the relative alignment of the subspaces occupied by neural dynamics across time using PCA<sup><xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R64">64</xref></sup> confirmed the orthogonality of n eural activities between different task periods (<xref ref-type="fig" rid="F16">Extended Data Fig. 10b–c</xref>). Further analyses showed that this orthogonality was not simply due to distinct sub-populations of neurons being active in different task periods (due to either feedforward connections between these populations, or single-neuron adaptation mechanisms), but was instead largely due to changes in population-wide activities patterns<sup><xref ref-type="bibr" rid="R10">10</xref>,<xref ref-type="bibr" rid="R49">49</xref></sup> (<xref ref-type="fig" rid="F16">Extended Data Fig. 10d–e</xref>).</p><p id="P31">These results, in line with previous findings<sup><xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R10">10</xref>,<xref ref-type="bibr" rid="R15">15</xref>,<xref ref-type="bibr" rid="R16">16</xref></sup>, clearly indicated that activities during the cue period were largely orthogonal from those during the delay period. However, these analyses alone were unable to distinguish between two fundamentally different information loading strategies PFC could employ: random input directions, or optimal input directions. Thus, in order to clearly identify the information loading strategy underlying the combination of dynamic and stable coding that we found, we applied our overlap measure (<xref ref-type="fig" rid="F4">Fig. 4c</xref>) to these PFC recordings. For this, we first fitted a 20-dimensional linear dynamical system model to the cue and early delay periods of our recordings (0–1 s after cue onset, <xref ref-type="sec" rid="S24">Methods 1.4.3</xref>). We confirmed that linear dynamics provided a reasonably accurate cross-validated fit to the data compared to a time shuffled control (which destroyed the lawful dynamics of the data; <xref ref-type="fig" rid="F5">Fig. 5d</xref>, dark gray, see also <xref ref-type="sec" rid="S24">Methods 1.4.3</xref>), and model-free train vs. test performance (which indicated that cross-validated errors were mostly due to sampling noise differences between the train and test data; <xref ref-type="fig" rid="F5">Fig. 5d</xref>, light gray) and recapitulated the most important aspects of the trial-average dynamics in each condition (<xref ref-type="fig" rid="F5">Fig. 5e</xref>).</p><p id="P32">We then performed the same overlap analysis on the fitted linear dynamics of the data that we used on our simulated networks with linear dynamics (<xref ref-type="fig" rid="F4">Fig. 4c</xref>; <xref ref-type="sec" rid="S34">Methods 1.7.3</xref>). As expected from our decoding analyses (<xref ref-type="fig" rid="F5">Fig. 5b,c</xref>), the overlap of neural activities with the most persistent modes was at chance initially and gradually increased (<xref ref-type="fig" rid="F5">Fig. 5f</xref>, green and <xref ref-type="fig" rid="F16">Extended Data Fig. 10i</xref>). Critically however, the overlap of neural activities with the most amplifying modes was high initially and decreased with time (<xref ref-type="fig" rid="F5">Fig. 5f</xref>, red and <xref ref-type="fig" rid="F16">Extended Data Fig. 10i</xref>). Consistent with these results, we found that at early times, stimulus information was just as decodable within the amplifying subspace as in the full space and was more poorly decodable in the persistent subspace (<xref ref-type="fig" rid="F16">Extended Data Fig. 10h</xref>, <italic>t</italic> = 0). Later in the delay period, stimulus information was significantly better decodable in the persistent subspace than in the amplifying subspace (<xref ref-type="fig" rid="F16">Extended Data Fig. 10h</xref>, <italic>t &gt;</italic> 0).</p><p id="P33">We also noted that the overlap with the most amplifying directions became significantly lower than chance over time. This suggests that PFC circuits may be more mathematically ‘non-normal’<sup><xref ref-type="bibr" rid="R21">21</xref>,<xref ref-type="bibr" rid="R27">27</xref>,<xref ref-type="bibr" rid="R56">56</xref>,<xref ref-type="bibr" rid="R57">57</xref>,<xref ref-type="bibr" rid="R60">60</xref></sup> than the networks with randomly chosen weights that we used in <xref ref-type="fig" rid="F4">Fig. 4</xref>. For example, <xref ref-type="fig" rid="F14">Extended Data Fig. 8f</xref> shows this phenomenon in a highly non-normal (purely feedforward) network using optimal information loading (see also <xref ref-type="sec" rid="S8">Discussion</xref>).</p><p id="P34">As a control, we repeated the same analyses on time-shuffled data, or on data taken from the late delay period (when the network should already be near an attractor state). Neither control analyses resulted in the same cross-over pattern that we found in our main analysis. In particular, the overlap with the most amplifying modes remained at (or below) chance at all times (<xref ref-type="fig" rid="F16">Extended Data Fig. 10f,g,i</xref>).</p><p id="P35">Therefore, these analyses provide strong experimental evidence that PFC circuit dynamics utilize optimal information loading with inputs aligning with the most amplifying modes (compare to <xref ref-type="fig" rid="F4">Fig. 4c</xref>; middle and <xref ref-type="fig" rid="F16">Extended Data Fig. 10i</xref>, third vs. fourth row) rather than simply using random input directions (compare to <xref ref-type="fig" rid="F4">Fig. 4c</xref>; right and <xref ref-type="fig" rid="F16">Extended Data Fig. 10i</xref>, first vs. fourth row).</p></sec><sec id="S7"><title>Information loading in task-optimized nonlinear networks</title><p id="P36">The definition of most amplifying inputs relies on full access to the algebraic form of the dynamics of a network, something that the brain will not have explicitly when performing a working memory task. In turn, the formal equivalence of using the most amplifying input directions to optimal information loading could only be established for networks with linear dynamics receiving instantaneous inputs, while fixing the magnitude of those inputs. Thus, an important question is whether optimizing simple task-relevant cost functions in nonlinear networks<sup><xref ref-type="bibr" rid="R13">13</xref>,<xref ref-type="bibr" rid="R17">17</xref>,<xref ref-type="bibr" rid="R20">20</xref>,<xref ref-type="bibr" rid="R24">24</xref>,<xref ref-type="bibr" rid="R39">39</xref>–<xref ref-type="bibr" rid="R41">41</xref>,<xref ref-type="bibr" rid="R65">65</xref></sup>, under only a generic energy constraint<sup><xref ref-type="bibr" rid="R13">13</xref>,<xref ref-type="bibr" rid="R39">39</xref>–<xref ref-type="bibr" rid="R41">41</xref>,<xref ref-type="bibr" rid="R65">65</xref></sup>, can be sufficient for such networks to adopt an optimal information loading strategy.</p><p id="P37">We trained nonlinear recurrent networks (<xref ref-type="fig" rid="F6">Fig. 6a</xref>; <xref ref-type="sec" rid="S18">Methods 1.3.2</xref>) on the same memory-guided saccade task as that which our animals performed (<xref ref-type="fig" rid="F1">Fig. 1a</xref>). Following previous approaches<sup><xref ref-type="bibr" rid="R13">13</xref>,<xref ref-type="bibr" rid="R39">39</xref>,<xref ref-type="bibr" rid="R40">40</xref></sup>, all recurrent weights in the network, as well as weights associated with the input and read-out channels, were optimized, while only penalizing the average magnitude of neural responses over the course of the whole trial (<xref ref-type="sec" rid="S19">Methods 1.3.3</xref>).</p><p id="P38">To study the generality of optimal information loading, we first implemented two standard cost functions that have been widely used in previous work<sup><xref ref-type="bibr" rid="R13">13</xref>,<xref ref-type="bibr" rid="R17">17</xref>,<xref ref-type="bibr" rid="R24">24</xref>,<xref ref-type="bibr" rid="R39">39</xref>,<xref ref-type="bibr" rid="R40">40</xref></sup>. These cost functions required networks to maintain cue information either stably throughout the delay period, starting immediately after cue onset (cuedelay; <xref ref-type="fig" rid="F6">Fig. 6b</xref>, left), or only at response time (after-go; <xref ref-type="fig" rid="F6">Fig. 6b</xref>, center). Both networks achieved high performance, as measured by a late-delay decoder, in line with what their respective cost functions required: immediately after cue onset for the cue-delay cost (<xref ref-type="fig" rid="F6">Fig. 6c</xref> and <xref ref-type="fig" rid="F17">Extended Data Fig. 11a</xref>, green), or only shortly before go time for the after-go-time cost (<xref ref-type="fig" rid="F6">Fig. 6c</xref> orange and <xref ref-type="fig" rid="F18">Extended Data Fig. 12b</xref>).</p><p id="P39">We then further analyzed the dynamics with which these networks achieved competent performance. In particular, we evaluated whether they employed optimal information loading, and how well they reproduced critical aspects of the empirical data. The cuedelay network showed signatures of classical attractor dynamics with simple pattern completion: crosstemporal decoding was high at all times, including between the cue and delay periods (<xref ref-type="fig" rid="F6">Fig. 6d</xref>, left; cf. <xref ref-type="fig" rid="F1">Fig. 1c</xref>, <xref ref-type="fig" rid="F7">Extended Data Fig. 1a–c</xref>), neural activity overlapped strongly between the cue and delay periods (<xref ref-type="fig" rid="F17">Extended Data Fig. 11c</xref>, left), and at the time of cue offset, neural activity was already very close to its final attractor location in state space (<xref ref-type="fig" rid="F17">Extended Data Fig. 11d</xref>, left). In line with our theory of optimal information loading, this was achieved by neural activities during the cue period aligning predominantly with the most amplifying modes (<xref ref-type="fig" rid="F6">Fig. 6e</xref>, left, red). However, at the same time, activities were also already aligned well above chance with the most persistent modes (<xref ref-type="fig" rid="F6">Fig. 6e</xref>, left, green). This was consistent with these networks being explicitly required to exhibit stable coding at all times by the cue-delay cost. These features also made this network a poor match to the experimental data, which showed a combination of dynamic and stable coding and at-chance overlap of activities with the most persistent mode during the cue period (<xref ref-type="fig" rid="F5">Fig. 5b–c,f</xref>,<xref ref-type="fig" rid="F16">Extended Data Fig. 10a–b</xref>). We also found similar behavior for networks optimizing a ‘full-delay’ cost, in which cue information must be stably maintained only after cue offset (<xref ref-type="fig" rid="F19">Extended Data Fig. 13</xref>, <xref ref-type="sec" rid="S19">Methods 1.3.3</xref>).</p><p id="P40">At the other extreme, the after-go-time network did not make particular use of attractor dynamics. Instead, it generated largely sequential activities, i.e. pure dynamic coding akin to the dynamics of a feedforward network: cross-temporal decoding was only high at the very end of the delay period (<xref ref-type="fig" rid="F6">Fig. 6d</xref>, center; cf. <xref ref-type="fig" rid="F1">Fig. 1d</xref> and <xref ref-type="fig" rid="F7">Extended Data Fig. 1d</xref>, right), neural activity was strongly orthogonal between the cue and delay periods (<xref ref-type="fig" rid="F18">Extended Data Fig. 12d</xref>, left), and these networks did not exhibit attractor states (<xref ref-type="fig" rid="F18">Extended Data Fig. 12e</xref>, left). This was particularly the case for a fixed delay task, for which this cost function yielded purely sequential dynamics (<xref ref-type="fig" rid="F18">Extended Data Fig. 12c–e</xref>, right). As required by optimal information loading, neural activities also had a strong initial overlap with the most amplifying modes in this network (<xref ref-type="fig" rid="F6">Fig. 6e</xref>, center, green). However, as expected for sequential dynamics, the overlap with the most persistent modes never significantly exceeded that with the most amplifying modes (<xref ref-type="fig" rid="F6">Fig. 6e</xref>, center). Again, the apparent lack of attractor dynamics was well explained by the cost function not requiring any stable coding during the delay period. Therefore, this network also deviated from the data in important ways, in this case by failing to exhibit stable coding and high overlap with the persistent mode during the late delay period (cf. <xref ref-type="fig" rid="F5">Fig. 5b–c,f</xref>,<xref ref-type="fig" rid="F16">Extended Data Fig. 10a–b</xref>). In summary, network dynamics trained for standard cost functions exhibited optimal information loading and recovered classical network models of working memory (<xref ref-type="fig" rid="F1">Fig. 1c,d</xref> and <xref ref-type="fig" rid="F7">Extended Data Fig. 1a–d</xref>), but were different from those seen in experimental recordings<sup><xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R10">10</xref>,<xref ref-type="bibr" rid="R14">14</xref>–<xref ref-type="bibr" rid="R16">16</xref>,<xref ref-type="bibr" rid="R25">25</xref></sup> (<xref ref-type="fig" rid="F5">Fig. 5b,c,f</xref>).</p><p id="P41">However, we reasoned that neither of these standard cost functions may be appropriate for understanding PFC function. The cue-delay cost is well justified when stimuli need to be decoded potentially instantaneously after cue onset, and as such it is most relevant for sensory areas<sup><xref ref-type="bibr" rid="R59">59</xref></sup>. Conversely, the after-go-time cost may be most directly relevant for motor areas, by only requiring stable coding during the short response period<sup><xref ref-type="bibr" rid="R65">65</xref></sup>. Therefore, we also considered a third cost function that required stable coding just in time before the go cue appeared, i.e. during a period that was divorced from the stimulus or response time windows, and as such was more consistent with the putative role of PFC in cognitive flexibility<sup><xref ref-type="bibr" rid="R2">2</xref>,<xref ref-type="bibr" rid="R25">25</xref>,<xref ref-type="bibr" rid="R61">61</xref></sup> (just-in-time; <xref ref-type="fig" rid="F6">Fig. 6b</xref>, right).</p><p id="P42">In contrast to both standard training costs, just-in-time networks showed the signatures of a combination of attractor and sequential dynamics which were consistent with its cost function. The performance of a latedelay decoder was high only after cue offset but remained so for most of the delay period (<xref ref-type="fig" rid="F6">Fig. 6c</xref> and <xref ref-type="fig" rid="F17">Extended Data Fig. 11a</xref>, red), cross-temporal decoding was poor between early and late periods of a trial, but high during the late delay period (<xref ref-type="fig" rid="F6">Fig. 6d</xref>, right; <xref ref-type="fig" rid="F17">Extended Data Fig. 11b</xref>; cf. center, <xref ref-type="fig" rid="F5">Fig. 5c</xref>; see also <xref ref-type="fig" rid="F17">Extended Data Fig. 11d</xref> for state-space plots), neural activity was strongly orthogonal between the cue and delay periods (<xref ref-type="fig" rid="F18">Extended Data Fig. 12d</xref>, right), and at the time of cue offset, neural activity was far from its final attractor location in state space (<xref ref-type="fig" rid="F17">Extended Data Fig. 11d</xref>, right). Critically, the overlap of neural activities with the most amplifying and persistent modes showed the characteristic cross-over that we found experimentally (<xref ref-type="fig" rid="F6">Fig. 6e</xref>, right; cf. <xref ref-type="fig" rid="F5">Fig. 5f</xref>). Thus, this network both used optimal information loading and reproduced the key features of the experimental data.</p><p id="P43">In summary, all task-optimized networks exhibited a key feature of optimal information loading: they made use of most amplifying modes early during the trial (<xref ref-type="fig" rid="F6">Fig. 6e</xref>, all red lines start high at 0 s). The extent to which they showed the complete cross-over of amplifying and persistent overlaps predicted by our earlier analyses (<xref ref-type="fig" rid="F4">Fig. 4c</xref>, center), and characteristic of the experimental data (<xref ref-type="fig" rid="F5">Fig. 5f</xref>), was consistent with how much they were required to exhibit stable coding<sup><xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R10">10</xref>,<xref ref-type="bibr" rid="R11">11</xref>,<xref ref-type="bibr" rid="R14">14</xref>–<xref ref-type="bibr" rid="R16">16</xref></sup>. These results suggest that optimal information loading emerges naturally as a dynamical strategy in task-optimized networks, without explicit requirements on their inputs.</p></sec></sec><sec id="S8" sec-type="discussion"><title>Discussion</title><p id="P44">While attractor networks have been proposed to underlie a number of core cognitive functions<sup><xref ref-type="bibr" rid="R12">12</xref>,<xref ref-type="bibr" rid="R17">17</xref>,<xref ref-type="bibr" rid="R17">17</xref>,<xref ref-type="bibr" rid="R28">28</xref>–<xref ref-type="bibr" rid="R31">31</xref>,<xref ref-type="bibr" rid="R33">33</xref>–<xref ref-type="bibr" rid="R35">35</xref>,<xref ref-type="bibr" rid="R42">42</xref>,<xref ref-type="bibr" rid="R51">51</xref>,<xref ref-type="bibr" rid="R66">66</xref>–<xref ref-type="bibr" rid="R68">68</xref></sup>, prominently including working memory<sup><xref ref-type="bibr" rid="R5">5</xref>–<xref ref-type="bibr" rid="R7">7</xref>,<xref ref-type="bibr" rid="R26">26</xref>,<xref ref-type="bibr" rid="R29">29</xref>,<xref ref-type="bibr" rid="R31">31</xref>–<xref ref-type="bibr" rid="R33">33</xref>,<xref ref-type="bibr" rid="R69">69</xref></sup>, their operation was almost exclusively analyzed in terms of how their intrinsic connectivity supports information maintenance<sup><xref ref-type="bibr" rid="R5">5</xref>,<xref ref-type="bibr" rid="R7">7</xref>,<xref ref-type="bibr" rid="R12">12</xref>,<xref ref-type="bibr" rid="R29">29</xref>–<xref ref-type="bibr" rid="R31">31</xref>,<xref ref-type="bibr" rid="R34">34</xref>,<xref ref-type="bibr" rid="R35">35</xref>,<xref ref-type="bibr" rid="R70">70</xref>,<xref ref-type="bibr" rid="R71">71</xref></sup> (but see Refs. 6,26, discussed below). We instead studied information loading by external inputs in attractor networks and showed that optimal information loading provides a normative account of the widely observed and puzzling phenomenon of dynamic coding<sup><xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R10">10</xref>,<xref ref-type="bibr" rid="R14">14</xref>–<xref ref-type="bibr" rid="R16">16</xref></sup>. We predict that these results should also generalize to more cognitively demanding working memory tasks in which, unlike in the simple memory-guided saccade task we studied here, the correct response is unknown during the delay period, thus requiring the maintenance of stimulus information before a response can be prepared<sup><xref ref-type="bibr" rid="R14">14</xref>,<xref ref-type="bibr" rid="R15">15</xref>,<xref ref-type="bibr" rid="R23">23</xref>,<xref ref-type="bibr" rid="R72">72</xref>,<xref ref-type="bibr" rid="R73">73</xref></sup>. Indeed, strongly dynamic population activity, similar to those that we identified here, has been observed in monkey PFC<sup><xref ref-type="bibr" rid="R10">10</xref>,<xref ref-type="bibr" rid="R14">14</xref>–<xref ref-type="bibr" rid="R16">16</xref>,<xref ref-type="bibr" rid="R23">23</xref>,<xref ref-type="bibr" rid="R24">24</xref>,<xref ref-type="bibr" rid="R73">73</xref></sup> and in neural networks<sup><xref ref-type="bibr" rid="R20">20</xref>,<xref ref-type="bibr" rid="R24">24</xref>,<xref ref-type="bibr" rid="R39">39</xref></sup> trained on such tasks. To fully test the generality of these principles, it will also be important to extend the theory and these analyses even further, to tasks with multiple delay periods<sup><xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R15">15</xref></sup>.</p><p id="P45">For understanding the dynamics of optimal information loading, we used networks whose connectivity was constrained to be symmetric as a pedagogical stepping stone. Some classical attractor and integrator networks indeed used purely symmetric connectivities<sup><xref ref-type="bibr" rid="R28">28</xref>,<xref ref-type="bibr" rid="R33">33</xref>–<xref ref-type="bibr" rid="R35">35</xref>,<xref ref-type="bibr" rid="R42">42</xref></sup>, and these continue to form the basis of our analytical understanding of the capacity, noise-tolerance, and input amplification of more realistic networks<sup><xref ref-type="bibr" rid="R46">46</xref></sup>. The perfect symmetry of classical models has been relaxed by more recent, highly influential models of working memory that instead used quasi-symmetric connectivities, i.e. connectivities that were only weakly non-symmetric. These include models whose connectivity is not strictly symmetric at the microscopic level of cell-to-cell connections, but their macroscopic connectivity (at the level of connections between groups of similarly tuned cells) is strongly symmetric<sup><xref ref-type="bibr" rid="R71">71</xref>,<xref ref-type="bibr" rid="R74">74</xref></sup>, as well as models in which excitatory cells are connected symmetrically, but perfect symmetry is broken by the introduction of effectively a single inhibitory neuron providing a spatially uniform, global level of inhibition<sup><xref ref-type="bibr" rid="R5">5</xref>,<xref ref-type="bibr" rid="R7">7</xref>,<xref ref-type="bibr" rid="R12">12</xref>,<xref ref-type="bibr" rid="R30">30</xref>,<xref ref-type="bibr" rid="R32">32</xref>,<xref ref-type="bibr" rid="R44">44</xref>,<xref ref-type="bibr" rid="R45">45</xref></sup>. Indeed, previous analyses of such weakly non-symmetric networks<sup><xref ref-type="bibr" rid="R5">5</xref>–<xref ref-type="bibr" rid="R7">7</xref>,<xref ref-type="bibr" rid="R30">30</xref>,<xref ref-type="bibr" rid="R44">44</xref></sup> and our simulations of such networks revealed largely stable coding dynamics (e.g. see <xref ref-type="fig" rid="F7">Extended Data Fig. 1a–b</xref>). In contrast, we showed that dynamic coding naturally arises in networks whose connectivity is not constrained to be symmetric, and especially so under optimal information loading.</p><p id="P46">Our dynamical analysis revealed a novel, theoretically-grounded aspect of dynamic coding: not only should neural activities during the cue and early delay period be orthogonal to those during the late delay period, but they should be orthogonal in the specific directions that are aligned with the most amplifying directions. We found strong evidence for these predictions of optimal information loading in lPFC during a memory-guided saccade task. These results unify previous, seemingly conflicting m odels o f working memory maintenance that typically either use attractor dynamics<sup><xref ref-type="bibr" rid="R5">5</xref>,<xref ref-type="bibr" rid="R7">7</xref>,<xref ref-type="bibr" rid="R29">29</xref></sup> or rely on sequential activities often generated by non-normal dynamics<sup><xref ref-type="bibr" rid="R21">21</xref>,<xref ref-type="bibr" rid="R27">27</xref>,<xref ref-type="bibr" rid="R36">36</xref>,<xref ref-type="bibr" rid="R37">37</xref></sup>.</p><p id="P47">We found that although both classes of models can capture select aspects of neural data (e.g. sequential models can capture early delay activity whereas attractors are better suited to capturing late delay activity), no model could capture the experimentally observed rich combination of sequential and persistent dynamics<sup><xref ref-type="bibr" rid="R72">72</xref></sup> (<xref ref-type="fig" rid="F1">Fig. 1</xref>; see also<sup><xref ref-type="bibr" rid="R39">39</xref></sup>). We showed that optimal information loading in attractor models with realistic, unconstrained connectivity, leads to the specific combination of sequential and persistent dynamics that has been observed in experiments. We found that this was true across a range of different specific network architectures: using either hand-set (<xref ref-type="fig" rid="F3">Figs. 3</xref> and <xref ref-type="fig" rid="F4">4</xref> and <xref ref-type="fig" rid="F11">Extended Data Fig. 5a,b</xref>) or optimized stimulus inputs (<xref ref-type="fig" rid="F11">Extended Data Fig. 5c,d</xref>); and linear integrator (<xref ref-type="fig" rid="F3">Figs. 3</xref> and <xref ref-type="fig" rid="F4">4</xref> and <xref ref-type="fig" rid="F11">Extended Data Fig. 5</xref>), nonlinear discrete attractor (<xref ref-type="fig" rid="F2">Figs. 2</xref> and <xref ref-type="fig" rid="F6">6</xref> and <xref ref-type="fig" rid="F8">Extended Data Figs. 2</xref>, <xref ref-type="fig" rid="F13">7</xref> and <xref ref-type="fig" rid="F17">11</xref>–<xref ref-type="fig" rid="F19">13</xref>) or nonlinear ring attractor dynamics (<xref ref-type="fig" rid="F9">Extended Data Fig. 3</xref>).</p><p id="P48">In contrast to our optimal information loading-based account, previous attempts to reconcile transient and persistent dynamics specifically proposed that transient dynamics do not affect the delay (or ‘mnemonic’) coding of the stimulus information<sup><xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R26">26</xref></sup>. These stable delay dynamics are very different from dynamic coding as observed in experiments<sup><xref ref-type="bibr" rid="R3">3</xref>,<xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R10">10</xref>,<xref ref-type="bibr" rid="R11">11</xref>,<xref ref-type="bibr" rid="R14">14</xref>–<xref ref-type="bibr" rid="R24">24</xref></sup>, and as predicted by our theory of optimal information loading. Put simply, in previous models, the stimulus input is strongly aligned with the desired persistent state (<xref ref-type="fig" rid="F1">Fig. 1d</xref>, left). In real data, and in models that exhibit optimal information loading, stimulus inputs drive network activity strongly orthogonal to the desired persistent state (and specifically in a direction that is aligned with the most amplifying mode) before activity ultimately settles into the correct state (<xref ref-type="fig" rid="F1">Fig. 1f</xref>, left). Indeed, previously observed high correlations between cue and delay periods<sup><xref ref-type="bibr" rid="R6">6</xref></sup>, which partially motivates using inputs aligned with the persistent state, are likely due to high overall baseline firing rates, and they have been shown to disappear (and even become negative) when data is mean-centered across cue conditions<sup><xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R24">24</xref></sup>.</p><p id="P49">There are aspects of the data that were not reproduced accurately by any of the specific models we implemented. First, the overlap with the most amplifying directions became significantly lower than chance over time in the data. This suggests that PFC circuits may be more mathematically ‘non-normal’ (i.e. include stronger effective feedforward loops<sup><xref ref-type="bibr" rid="R21">21</xref>,<xref ref-type="bibr" rid="R27">27</xref>,<xref ref-type="bibr" rid="R57">57</xref></sup>, or excitatory–inhibitory interactions<sup><xref ref-type="bibr" rid="R53">53</xref>,<xref ref-type="bibr" rid="R56">56</xref></sup>) than the networks with randomly chosen or initialised weights we used here<sup><xref ref-type="bibr" rid="R60">60</xref>,<xref ref-type="bibr" rid="R62">62</xref></sup>. (For example, we found that networks with strong feedforward connectivity reproduced this phenomenon; <xref ref-type="fig" rid="F14">Extended Data Fig. 8f</xref>.) Second, the time evolution of the overlaps with the most persistent and most amplifying modes seemed to obey different time constants, with the persistent overlap evolving substantially slower than the amplifying overlap. This may be a result of high dimensional, graded dynamical transitions between multiple amplifying and persistent modes compared to the less complex dynamical transitions that we observed in our models. More generally, analysing the data at single trial resolution, as opposed to the across-trial averages we analysed, may provide further important constraints on the underlying circuit dynamics<sup><xref ref-type="bibr" rid="R72">72</xref>,<xref ref-type="bibr" rid="R75">75</xref>,<xref ref-type="bibr" rid="R76">76</xref></sup>. Conversely, constraining the models to be more biologically plausible, e.g. by using spiking neurons or Hebbian forms of plasticity, may provide better fits to the data and more detailed predictions.</p><p id="P50">There have been multiple mechanisms proposed to account for some of the features of the data, most prominently dynamic coding<sup><xref ref-type="bibr" rid="R14">14</xref>,<xref ref-type="bibr" rid="R15">15</xref></sup>, that previously seemed to be at odds with basic attractor network dynamics. These hypothetical mechanisms include short-term plasticity<sup><xref ref-type="bibr" rid="R11">11</xref>,<xref ref-type="bibr" rid="R23">23</xref>,<xref ref-type="bibr" rid="R39">39</xref>,<xref ref-type="bibr" rid="R41">41</xref>,<xref ref-type="bibr" rid="R77">77</xref></sup>, specific changes in the strength of input and recurrent connections<sup><xref ref-type="bibr" rid="R44">44</xref>,<xref ref-type="bibr" rid="R78">78</xref></sup>, and separate stimulus- and delay-responsive cells<sup><xref ref-type="bibr" rid="R3">3</xref>,<xref ref-type="bibr" rid="R10">10</xref></sup>. We showed that the core phenomenon of dynamic coding emerges naturally, without any of these additional mechanisms, from the same ultimate principle that explains persistent activities (robust memory maintenance implemented by attractor dynamics). Moreover, the high initial overlap with the most amplifying modes, which was a core prediction of our theory confirmed by the data and our optimized networks, is not specifically predicted by any of these alternative mechanisms. Nevertheless, these mechanisms are not mutually exclusive with ours. In fact, they might help explain the more nuanced aspects of the data that our specific network implementations did not capture (see above), as well as aspects of the data that lie outside the scope of our theory (e.g. activity silent information maintenance during inter-trial intervals<sup><xref ref-type="bibr" rid="R45">45</xref></sup>).</p><p id="P51">A number of recent studies of neural network dynamics have analysed the relationship between the direction of inputs and the magnitude of responses they evoke<sup><xref ref-type="bibr" rid="R53">53</xref>,<xref ref-type="bibr" rid="R57">57</xref>,<xref ref-type="bibr" rid="R59">59</xref>,<xref ref-type="bibr" rid="R62">62</xref></sup>. However, these studies focused on networks with transient dynamics, such as those relevant for perception<sup><xref ref-type="bibr" rid="R59">59</xref></sup>, or motor control<sup><xref ref-type="bibr" rid="R53">53</xref>,<xref ref-type="bibr" rid="R62">62</xref></sup>. In particular, Ref. 62 found that optimal inputs (resulting in the largest transients) are typically orthogonal to the activity patterns that the network expresses in response to them, providing a normative account for the experimentally observed orthogonality of preparation and execution subspaces in motor cortex<sup><xref ref-type="bibr" rid="R64">64</xref>,<xref ref-type="bibr" rid="R79">79</xref></sup>. Our work suggests that the use of optimal inputs to drive network dynamics, and the orthogonality of those inputs to network responses, is a more general principle of cortical circuits, extending beyond the motor cortex. In particular, our results demonstrate the importance of optimal initialization even when the transients following initialization themselves may be irrelevant, as information is ultimately maintained by stable attractor states.</p><p id="P52">In line with our results, previous studies optimizing networks on related tasks requiring persistent, rather than transient, responses also exhibited key features of dynamic coding: neural activities initially pointed strongly orthogonal to the ultimate attractor location in state space<sup><xref ref-type="bibr" rid="R17">17</xref></sup>; the dynamics during the stimulus period had 0 correlation with late delay activity<sup><xref ref-type="bibr" rid="R24">24</xref></sup>; and cross-temporal decoding of time revealed strongly sequential dynamics in a variety of tasks<sup><xref ref-type="bibr" rid="R20">20</xref></sup> (see also<sup><xref ref-type="bibr" rid="R39">39</xref>,<xref ref-type="bibr" rid="R41">41</xref></sup> for related results). In fact, these features of model activities were also shown to be reflected in the corresponding experimental data in each case<sup><xref ref-type="bibr" rid="R17">17</xref>,<xref ref-type="bibr" rid="R20">20</xref>,<xref ref-type="bibr" rid="R24">24</xref></sup>. Nevertheless, it remained unclear whether these features were epiphenomenal or an integral part of the functioning of these networks. Our results suggest optimal information loading as a unifying principle underlying these observations.</p></sec><sec id="S9" sec-type="methods" specific-use="web-only"><label>1</label><title>Methods</title><sec id="S10"><label>1.1</label><title>Experimental materials and methods</title><p id="P53">Experimental methods have been described before<sup><xref ref-type="bibr" rid="R48">48</xref></sup> and largely followed those used in our previous publications<sup><xref ref-type="bibr" rid="R10">10</xref>,<xref ref-type="bibr" rid="R80">80</xref>,<xref ref-type="bibr" rid="R81">81</xref></sup>. We briefly summarize the methods below.</p><sec id="S11"><label>1.1.1</label><title>Subjects and apparatus</title><p id="P54">We used two female macaques (monkey T, <italic>Macaca mulatta</italic>, 5 kg; monkey K, <italic>Macaca fuscata</italic>, 8 kg). Both monkeys were housed individually. The light/dark cycle was 12/12 hr. (light, from 8:30 a.m. to 8:30 p.m.). The monkeys sat quietly in a primate chair in a dark, sound-attenuated shield room. During both training and neural recording sessions, we restrained the monkeys’ head movement non-invasively using a thermoplastic head cap as described in<sup><xref ref-type="bibr" rid="R82">82</xref></sup>. This head cap is made of a standard thermoplastic splint material (MT-APU, 3.2 mm thick, CIVCO Radiotherapy, IA., USA), and was molded out so that it conformed to the contours of the animals’ scalp, cheek bone, and occipital ridge. Visual stimuli were presented on a 17 inch TFT monitor placed 50 cm from the monkeys’ eyes. Eye movements were sampled at 120 Hz using an infrared eye tracking system (ETL-200, ISCAN, MA.). Eye fixation was controlled within a 6.5° imaginary square window. TEMPO software (Reflective Computing, WA.) was used to control behavioral tasks. All experimental procedures were approved by the Animal Research Committee at the Graduate School of Frontier Biosciences, Osaka University, Japan and were in full compliance with the guidelines of the National BioResource Project ‘Japanese Macaques’. Experimental work performed in non-human primates that was not funded by Wellcome may not adhere to the principles outlined in the NC3Rs guidance on Non-human Primate Accommodation, Care and Use.</p></sec><sec id="S12"><label>1.1.2</label><title>Behavioral task</title><p id="P55">The monkeys were trained on a memory-guided saccade task requiring them to remember the location of a visual stimulus cue on a screen and to make a correct eye movement after a delay period (<xref ref-type="fig" rid="F1">Fig. 1a</xref>). Specifically, this task required monkeys to fixate on a central ring for a period of 2.6–7.4 s followed by a stimulus cue (a white square) appearing in one of six pre-determined locations for 0.25 s. After a variable delay period of 1.4–7.5 s, the fixation ring was replaced by placeholders at all six possible stimulus cue locations (go cue). Monkeys were required to make a saccade within 0.5 s to the placeholder where the original stimulus cue was presented and maintain their gaze for 0.25 s for monkey T and either 0.25 s or 0.6 s for monkey K (these two gaze maintenance times were switched in different blocks for monkey K) to receive a juice reward. The monkeys were extensively trained, with close to perfect performance (monkey T, 96.1%; monkey K, 96.3%, mean across sessions). Fixation break errors were excluded from the calculation of percent correct rate.</p></sec><sec id="S13"><label>1.1.3</label><title>Recordings</title><p id="P56">After training was completed, we conducted an aseptic surgery under general anesthesia. We stereotypically implanted a plastic recording chamber on the lateral surface of the prefrontal cortex, under the guidance of structural MRI images (<xref ref-type="fig" rid="F15">Extended Data Fig. 9</xref>). In monkey T, we implanted a cylindrical chamber (RC-T-S-P, internal diameter 12.7 mm, Gray Matter Research, MT.) in the right hemisphere (AP = 33, ML = 14.5; AP, anteriorposterior; ML, medio-lateral). A 32-channel semi-chronic microdrive system (SC-32, Gray Matter Research) was mounted inside this chamber. In monkey K, we implanted a cuboid chamber (width 12 mm, depth 16 mm, height, 15 mm, S-company ltd., Tokyo, Japan) over the principal sulcus in the left hemisphere.</p><p id="P57">We collected neural data in a total of 48 daily sessions (21 in monkey T; 27 in monkey K). In monkey T, we used the 32-ch microdrive (SC-32) that housed 32 single-contact tungsten electrodes with inter-electrode spacing of 1.5 mm. In monkey K, we used a 32-ch linear microelectrode array (Plexon U-Probe, Plexon, TX.) with an interelectrode spacing of 150 <italic>µ</italic>m along a single shaft. We positioned the U-Probe by using a custom-made grid (width 12 mm, depth 16 mm, height, 10 mm) which had a total of 165 holes with 1 mm spacing. We advanced the U-Probe by a custom-made hydraulic microdrive (S-company ltd.).</p><p id="P58">Raw extracellular neural signals were amplified and recorded in reference to a titanium bone screw at the vertex (in monkey T) or the shaft of the linear array (monkey K) using a neural signal amplifier RZ2 Bioamp Processor (Tucker-Davis Technologies, FL.). Behavioral data (task-event information and eye-movement information) were also sent to the RZ2 Bioamp. Neural data acquisition was performed at a sampling frequency of 24414.08 Hz, and behavioral data acquisition at 1017.25 Hz. For analysis of spiking activity, the raw neural signal was filtered (300 Hz to 6 kHz) for offline sorting (Offline Sorter, Plexon). In monkey T, approximately three hours before each recording session, we took the monkey to the testing room and advanced each electrode in the SC-32 by a minimum of 62.5 <italic>µ</italic>m in order to ensure recording of new neurons. We then put the monkey back in the home cage until we brought it out again for the recording session. In monkey K, we adopted the method of the U-Probe insertion reported in<sup><xref ref-type="bibr" rid="R83">83</xref></sup>. We first punctuated the dura using a guide tube (a shortened 23 gauge needle), and inserted the U-Probe array slowly, usually with a step of 500 <italic>µ</italic>m. We kept monitoring electrocardiogram (pulsatory fluctuation) on superficial electrodes to identify the point of cortical entry. We usually left 3–5 superficial channels outside the cortex. After array insertion, we waited 1–1.5 hours until the recorded single-unit and multiunit activities indicated that the electrode array was stably positioned in the cortex. While waiting, the monkey watched nature and animal video clips and received a small snack on a monkey chair.</p><p id="P59">In monkey T only, to determine location of the frontal eye field (FEF), and confirm that our recording area was outside it, intracortical microstimulations (22 biphasic pulses, 0.2 ms duration at 333 Hz, ≤ 150 <italic>µ</italic>A) were applied through microelectrodes. When eye movements were elicited below 50 <italic>µ</italic>A, the site was considered to be in the low-threshold FEF. In monkey T, our recording area did not include the low-threshold FEF.</p></sec><sec id="S14"><label>1.1.4</label><title>Pre-processing</title><p id="P60">We excluded neurons that were recorded in fewer than 10 trials for any cue condition. For each monkey, we pooled neurons from all recording sessions to create pseudopopulations of 438 neurons for Monkey K (after we removed 1 neuron from monkey K’s dataset due to an insufficient number of trials) and 625 neurons for Monkey T (no neurons were removed from monkey T’s dataset). To compute neural firing rates, we convolved spike trains with a Gaussian kernel with a standard deviation of 25 ms. Trial-averaged trajectories of time-varying mean firing rates were computed separately for each neuron and each cue condition. For analysis methods that used crossvalidation (see below), we split trials into separate train and test sets with a 1:1 train:test ratio, and computed trial-averaged trajectories for each training and test set (using 1:1 splits). For non-cross validated analyses, we either computed trial averages based on all the data, or on a subset of the data (see below). We aligned neural activity to either stimulus or go cue onset (see also below in <xref ref-type="sec" rid="S31">Methods 1.7</xref>) and shifted activity by -50 ms to allow for the delay in time for information about these cues to enter PFC. For consistency with our simulations (see below), we subsampled neural firing rates at a 1-ms time resolution.</p></sec></sec><sec id="S15"><label>1.2</label><title>Neural network models: overview</title><p id="P61">All our simulated networks (<xref ref-type="fig" rid="F2">Figs. 2</xref>–<xref ref-type="fig" rid="F4">4</xref> and <xref ref-type="fig" rid="F6">6</xref> and <xref ref-type="fig" rid="F8">Extended Data Figs. 2</xref>–<xref ref-type="fig" rid="F11">5</xref>, <xref ref-type="fig" rid="F13">7</xref> and <xref ref-type="fig" rid="F17">11</xref>–<xref ref-type="fig" rid="F19">13</xref>) evolved according to a canonical model of stochastic recurrent neural circuit dynamics<sup><xref ref-type="bibr" rid="R40">40</xref>,<xref ref-type="bibr" rid="R84">84</xref></sup>: <disp-formula id="FD1"><label>(1)</label><mml:math id="M1"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:msup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:msup><mml:mrow><mml:mtext mathvariant="bold">r</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mrow><mml:mtext>h</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mtext mathvariant="bold">h</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mrow><mml:mtext>g</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mtext mathvariant="bold">g</mml:mtext></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mtext mathvariant="bold">b</mml:mtext></mml:mrow><mml:mo>+</mml:mo><mml:mi>σ</mml:mi><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> with <disp-formula id="FD2"><label>(2)</label><mml:math id="M2"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msup><mml:mrow><mml:mtext mathvariant="bold">r</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mtext mathvariant="bold">f</mml:mtext></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> where <inline-formula><mml:math id="M3"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mi>N</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> corresponds to the vector of (unitless) trial-averaged raw somatic membrane potentials of the <italic>N</italic> neurons of the network<sup><xref ref-type="bibr" rid="R84">84</xref></sup> in cue condition <italic>c</italic> = 1, …, <italic>C</italic> (initialised at <bold>x</bold><sup>(<italic>c</italic>)</sup>(<italic>t</italic><sub>0</sub>) at the beginning of the simulation <italic>t</italic><sub>0</sub>, which could be at or before stimulus onset at <italic>t</italic> = 0). <bold>r</bold><sup>(<italic>c</italic>)</sup>(<italic>t</italic>) is their momentary firing rates, with <bold>f</bold>(<bold>x</bold>) being the activation function that converts membrane potentials to firing rates, <italic>τ</italic> is the effective time constant of the cell), <bold>W</bold> is the recurrent weight matrix (shown e.g. in <xref ref-type="fig" rid="F2">Fig. 2a</xref> and <xref ref-type="fig" rid="F2">g</xref>), <bold>h</bold><sup>(<italic>c</italic>)</sup> is the input given to the network depending on the stimulus cue, <bold>g</bold> is the stimulus-cue-independent go cue that occurs at the go time <italic>t</italic><sub>go</sub>, <italic>m</italic><sub>h</sub>(<italic>t</italic>) and <italic>m</italic><sub>g</sub>(<italic>t</italic>) are box car ‘masking’ kernels such that the stimulus and go cues are only effective within a limited period at the beginning and end of the trial, respectively, <bold>b</bold> is a cue-independent bias, <italic>σ</italic> is the standard deviation of the noise process, and <bold><italic>η</italic></bold><sup>(<italic>c</italic>)</sup>(<italic>t</italic>) is a sample from a standard (mean 0 and variance 1) Gaussian white (temporally and spatially) noise process.</p><p id="P62">Networks shown in different figures corresponded to different special cases of <xref ref-type="disp-formula" rid="FD1">Eqs. 1</xref> and <xref ref-type="disp-formula" rid="FD2">2</xref> (see <xref ref-type="table" rid="T1">Table 1</xref>). Specifically, for linear networks <bold>f</bold>(<bold>x</bold>) = <bold>x</bold> was the identity function. For nonlinear networks <italic>f</italic><sub><italic>i</italic></sub>(<bold>x</bold>) = [<italic>x</italic><sub><italic>i</italic></sub>]<sub>+</sub> was the rectified linear (ReLU) activation function applied element-wise (except for the ring attractor networks where we used <italic>f</italic><sub><italic>i</italic></sub>(<bold>x</bold>) = tanh(<italic>x</italic><sub><italic>i</italic></sub>); <xref ref-type="fig" rid="F9">Extended Data Fig. 3</xref>). Given that the focus of our study was optimal information loading, stimulus inputs were either optimized numerically (<xref ref-type="fig" rid="F2">Fig. 2</xref>, <xref ref-type="fig" rid="F6">Fig. 6</xref>, <xref ref-type="fig" rid="F8">Extended Data Figs. 2</xref> and <xref ref-type="fig" rid="F9">3</xref>, <xref ref-type="fig" rid="F11">Extended Data Fig. 5c,d</xref>, and <xref ref-type="fig" rid="F17">Extended Data Figs. 11</xref>–<xref ref-type="fig" rid="F19">13</xref>), or set to analytically computed values as dictated by our mathematical analysis (<xref ref-type="fig" rid="F3">Figs. 3</xref> and <xref ref-type="fig" rid="F4">4</xref>, <xref ref-type="fig" rid="F10">Extended Data Fig. 4c,d</xref>, and <xref ref-type="fig" rid="F11">Extended Data Fig. 5a,b</xref>), or as a baseline, set to random values (<xref ref-type="fig" rid="F3">Figs. 3</xref> and <xref ref-type="fig" rid="F4">4</xref>, <xref ref-type="fig" rid="F10">Extended Data Fig. 4a,b</xref>, and <xref ref-type="fig" rid="F11">Extended Data Fig. 5a,b</xref>). For networks used to study the effects of instantaneous initial conditions (<xref ref-type="fig" rid="F2">Figs. 2</xref> and <xref ref-type="fig" rid="F3">3</xref> and <xref ref-type="fig" rid="F8">Extended Data Figs. 2</xref>–<xref ref-type="fig" rid="F11">5</xref> and <xref ref-type="fig" rid="F13">7</xref>), the stimulus masking kernel was zero and instead the initial condition was set to the stimulus input; for other networks (<xref ref-type="fig" rid="F4">Fig. 4</xref>, <xref ref-type="fig" rid="F5">Fig. 5e–f</xref>, <xref ref-type="fig" rid="F6">Fig. 6</xref> and <xref ref-type="fig" rid="F17">Extended Data Figs. 11</xref>–<xref ref-type="fig" rid="F19">13</xref>) the stimulus masking kernel was a boxcar between 0 and 0.25 s. For task-optimized networks (<xref ref-type="fig" rid="F6">Fig. 6</xref> and <xref ref-type="fig" rid="F17">Extended Data Figs. 11</xref>–<xref ref-type="fig" rid="F19">13</xref>), the go cue masking kernel <italic>m</italic><sub>g</sub>(<italic>t</italic>) was a boxcar starting at go cue onset, <italic>t</italic><sub>go</sub> and lasting for 0.5 s, for all other networks it was set to 0 everywhere. The networks used to analyse the dynamics of information loading (<xref ref-type="fig" rid="F3">Fig. 3</xref>, <xref ref-type="fig" rid="F10">Extended Data Fig. 4</xref>, and <xref ref-type="fig" rid="F11">Extended Data Fig. 5a,b</xref>) were deterministic by setting <italic>σ</italic> = 0, all other networks used noisy dynamics (see <xref ref-type="table" rid="T1">Table 1</xref>). We solved the dynamics of <xref ref-type="disp-formula" rid="FD1">Eqs. 1</xref> and <xref ref-type="disp-formula" rid="FD2">2</xref> using a first-order Euler–Maruyama approximation between <italic>t</italic><sub>0</sub> and the simulation end time, <italic>t</italic><sub>max</sub>, with a discretization time step of 1 ms.</p><p id="P63">For analysis methods that used cross-validation (see below), for each cue condition, we simulated network dynamics twice with independent realizations of <bold><italic>η</italic></bold><sup>(<italic>c</italic>)</sup>(<italic>t</italic>), to serve as train and test data. For other analyses, we used a single set of simulated trajectories. All analyses involving networks with randomly generated (or initialized) connectivities that also did not require re-fitting their responses with other networks (<xref ref-type="fig" rid="F2">Fig. 2</xref>, <xref ref-type="fig" rid="F4">Fig. 4</xref>, <xref ref-type="fig" rid="F6">Fig. 6c,d</xref>, <xref ref-type="fig" rid="F7">Extended Data Figs. 1</xref>–<xref ref-type="fig" rid="F9">3</xref>, <xref ref-type="fig" rid="F13">Extended Data Fig. 7a–c</xref>, and <xref ref-type="fig" rid="F17">Extended Data Figs. 11</xref>–<xref ref-type="fig" rid="F19">13</xref>) were repeated a total of <italic>n</italic> = 100 times, consisting of 10 different networks and 10 different simulations. For those analyses that did require the re-fitting of nonlinear networks’ responses with linear deterministic networks (<xref ref-type="fig" rid="F13">Extended Data Fig. 7d</xref> and <xref ref-type="fig" rid="F6">Fig. 6e</xref>), we used one simulation of the original (stochastic nonlinear) network, so <italic>n</italic> = 10 simulations in total.</p></sec><sec id="S16"><label>1.3</label><title>Nonlinear networks</title><p id="P64">For the dynamical equations of nonlinear networks, see <xref ref-type="sec" rid="S15">Methods 1.2</xref>. For nonlinear networks (<xref ref-type="fig" rid="F2">Figs. 2</xref> and <xref ref-type="fig" rid="F6">6</xref>, <xref ref-type="fig" rid="F8">Extended Data Figs. 2</xref> and <xref ref-type="fig" rid="F9">3</xref>, <xref ref-type="fig" rid="F13">Extended Data Fig. 7c</xref>, and <xref ref-type="fig" rid="F17">Extended Data Figs. 11</xref>–<xref ref-type="fig" rid="F19">13</xref>), we ensured that they performed working memory maintenance competently by optimizing their free parameters, <bold>W, b</bold>, and <bold>h</bold><sup>(<italic>c</italic>)</sup> for appropriate cost functions (see below, <xref ref-type="sec" rid="S19">Methods 1.3.3</xref>).</p><sec id="S17"><label>1.3.1</label><title>Nonlinear networks with instantaneous inputs</title><p id="P65">Following classical theoretical approaches to attractor network dynamics, we first used nonlinear neural networks in which stimulus inputs acted instantaneously to determine the initial conditions of the dynamics <xref ref-type="fig" rid="F2">Fig. 2</xref> and <xref ref-type="fig" rid="F8">Extended Data Figs. 2</xref>, <xref ref-type="fig" rid="F9">3</xref> and <xref ref-type="fig" rid="F13">7</xref>. These networks were optimized using a ‘just-in-time’ cost function (<xref ref-type="sec" rid="S19">Methods 1.3.3</xref>) under one or two constraints. First, for all these networks, we constrained stimulus inputs to have a Euclidean norm of 3 so that we could compare information loading strategies fairly when inputs were constrained to lie in certain subspaces (see also below): either the persistent subspace, persistent nullspace, locally persistent subspace, locally most amplifying subspace, or a random subspace (<xref ref-type="fig" rid="F2">Fig. 2f,l</xref>, <xref ref-type="fig" rid="F8">Extended Data Fig. 2</xref>, and <xref ref-type="fig" rid="F13">Extended Data Fig. 7</xref>).. We also obtained qualitatively very similar results without this norm constraint, with only a more general energy-based penalty<sup><xref ref-type="bibr" rid="R13">13</xref>,<xref ref-type="bibr" rid="R39">39</xref>,<xref ref-type="bibr" rid="R40">40</xref>,<xref ref-type="bibr" rid="R65">65</xref></sup> (<xref ref-type="fig" rid="F6">Fig. 6</xref> and <xref ref-type="fig" rid="F9">Extended Data Figs. 3</xref> and <xref ref-type="fig" rid="F17">11</xref>–<xref ref-type="fig" rid="F19">13</xref>, see also <xref ref-type="sec" rid="S19">Methods 1.3.3</xref>). Second, for symmetric networks, we enforced <inline-formula><mml:math id="M4"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mo stretchy="false">←</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula></p><p id="P66">These networks were trained in two epochs. For the first 1000 training iterations, we optimized all free parameters. After this, we confirmed that our trained networks did indeed have attractors (i.e. that they were attractor networks) and determined where these attractors were in state space by finding the stable fixed points of the networks’ dynamics (<xref ref-type="fig" rid="F2">Fig. 2d,j</xref>, <xref ref-type="fig" rid="F8">Extended Data Fig. 2b,f</xref>, and <xref ref-type="fig" rid="F9">Extended Data Fig. 3a</xref>)—see below. We then continued for another 1000 training iterations (without any firing rate regularization, <inline-formula><mml:math id="M5"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mtext>nonlin</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="FD3">Eq. 3</xref>) with only optimizing the initial conditions, <bold>h</bold><sup>(<italic>c</italic>)</sup>, while keeping the other parameters, <bold>W</bold> (<xref ref-type="fig" rid="F2">Fig. 2a,g</xref>) and <bold>b</bold>, fixed at the values obtained at the end of the first 1000 iterations. We did this so that we could fairly compare different initial conditions that are constrained to lie in different subspaces but which otherwise rely on the same underlying network dynamics. We considered three possible scenarios for introducing additional constraints on the initial conditions (beside the one on their norm, see above): they were either projected and then restricted to the persistent subspace or to the persistent nullspace (see <xref ref-type="sec" rid="S32">Methods 1.7.1</xref> for how these subspaces were computed), or there was no such constraint applied so that they could utilize any direction in the full state space of the network. In addition, to understand the link between the linearized (<xref ref-type="sec" rid="S23">Methods 1.4.2</xref>) and original (above) forms of the dynamics of these networks, we also considered three more constraints on the initial conditions: constraining them to the most persistent, most amplifying, or a random subspace of the linearized dynamics (<xref ref-type="fig" rid="F13">Extended Data Fig. 7a–c</xref>).</p></sec><sec id="S18"><label>1.3.2</label><title>Nonlinear networks with temporally extended inputs</title><p id="P67">To more closely follow the experimental paradigms which we modelled, we also used nonlinear networks in which stimuli provided temporally extended inputs (<xref ref-type="fig" rid="F6">Fig. 6</xref> and <xref ref-type="fig" rid="F17">Extended Data Figs. 11</xref>–<xref ref-type="fig" rid="F19">13</xref>). To construct these networks, stimulus inputs and the weight matrix were freely optimized (<xref ref-type="sec" rid="S19">Methods 1.3.3</xref>), without any constraints, and optimization proceeded for a full 2000 iterations, without dividing training into different epochs.</p></sec><sec id="S19"><label>1.3.3</label><title>Cost functions and training for nonlinear networks</title><p id="P68">To investigate how different cost functions impact network dynamics (<xref ref-type="fig" rid="F6">Fig. 6</xref>), we trained networks using one of four cost functions: a ‘cue-delay’ cost, a ‘full-delay’, a ‘just-in-time’ cost, and an ‘after-go’ cost. These costs only differed in terms of the time period in which we applied the cost function. The general form of the cost function we used was a cross entropy loss plus a regularisation term: <disp-formula id="FD3"><label>(3)</label><mml:math id="M6"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mi>ℒ</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>⟨</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mtext>nonlin</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="0.2em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:munderover><mml:mi>∑</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>6</mml:mn></mml:munderover><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mtext mathvariant="bold">y</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msubsup><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>Softmax</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mrow><mml:mtext>out</mml:mtext></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mspace width="0.2em"/><mml:mtext mathvariant="bold">r</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">b</mml:mtext></mml:mrow><mml:mrow><mml:mtext>out</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mtext>nonlin</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="0.2em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:munderover><mml:mi>∑</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>6</mml:mn></mml:munderover><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mo>∥</mml:mo><mml:msup><mml:mrow><mml:mtext mathvariant="bold">r</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mspace width="0.2em"/><mml:mtext>d</mml:mtext></mml:mrow><mml:mi>t</mml:mi><mml:mo>⟩</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> where <italic>T</italic><sub>1</sub> and <italic>T</italic><sub>2</sub> determine the time period in which we applied the cost, <inline-formula><mml:math id="M7"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mtext>nonlin</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="0.2em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mspace width="0.2em"/><mml:mtext>and</mml:mtext><mml:mspace width="0.2em"/><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mtext>nonlin</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="0.2em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> control the relative contributions of the cross-entropy loss and firing rate regularisation, <bold>W</bold><sub>out</sub> ∈ <italic>ℛ</italic><sup>6<italic>×N</italic></sup> and <bold>b</bold><sub>out</sub> ∈ <italic>ℛ</italic><sup>6</sup> include the 6 sets of ‘readout’ weights and biases, respectively, and <bold>y</bold><sup>(<italic>c</italic>)</sup> ∈ <italic>ℛ</italic><sup>6</sup> is a one-hot vector where <inline-formula><mml:math id="M8"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>y</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mtext>if</mml:mtext><mml:mspace width="0.2em"/><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mi>c</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mspace width="0.2em"/><mml:mtext>otherwise</mml:mtext></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> defining the ‘target’ output for each cue condition. We initialized elements of the network parameters <bold>W, b, h</bold><sup>(<italic>c</italic>)</sup>, as well as the readout parameters <bold>W</bold><sub>out</sub> and <bold>b</bold><sub>out</sub> from a Gaussian distribution with mean 0 and variance 1<italic>/N</italic>, and then optimized using gradient descent with Adam optimization<sup><xref ref-type="bibr" rid="R85">85</xref></sup>, where gradients were obtained from backpropagation through time. The angle brackets,⟨·⟩, denote averaging over batch sizes of 50 random realisations of <bold>r</bold><sup>(<italic>c</italic>)</sup>. We used a learning rate of 0.0005.</p><p id="P69">See <xref ref-type="table" rid="T2">Table 2</xref> for how we set the parameters of <xref ref-type="disp-formula" rid="FD3">Eq. 3</xref> <inline-formula><mml:math id="M9"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mtext>nonlin</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="0.2em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mspace width="0.2em"/><mml:mtext>and</mml:mtext><mml:mspace width="0.2em"/><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mtext>nonlin</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="0.2em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> depending on the cost function and the level of regularization. Briefly, the cue-delay cost included both the cue (between stimulus cue onset and offset) and the delay period (between stimulus cue offset and go cue onset), the full-delay cost the included delay period but not the cue period, the just-in-time cost started between stimulus onset and the earliest go time and ended at the onset of the go cue, and the after-go cost started at go cue onset and lasted for the duration of the go cue (0.5 s). For simulating the random delay task (<xref ref-type="fig" rid="F6">Fig. 6</xref> and <xref ref-type="fig" rid="F17">Extended Data Figs. 11</xref>–<xref ref-type="fig" rid="F19">13</xref>), analogous to what animals need to solve (see below), we sampled the go time uniformly between <italic>t</italic><sub>go</sub> = 0.75 s and <italic>t</italic><sub>go</sub> = 2 s. For just-in-time (<xref ref-type="fig" rid="F2">Fig. 2</xref> and <xref ref-type="fig" rid="F8">Extended Data Fig. 2</xref>) and after-go trained networks (<xref ref-type="fig" rid="F18">Extended Data Fig. 12</xref>), we also used a fixed delay task with a simulation end time of <italic>t</italic><sub>max</sub> = 2 s or a go time of <italic>t</italic><sub>go</sub> = 2 s, respectively. For the other cost functions, networks trained on the fixed delay task yielded very similar dynamics to their counterparts trained on the variable delay task (not shown). We set <inline-formula><mml:math id="M10"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mtext>nonlin</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="0.2em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mspace width="0.2em"/><mml:mtext>and</mml:mtext><mml:mspace width="0.2em"/><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mtext>nonlin</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="0.2em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> so that networks could reliably learn the task (at performance levels comparable across different settings) while also exhibiting relatively stable dynamics (i.e. if <inline-formula><mml:math id="M11"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mtext>nonlin</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="0.2em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mtext>nonlin</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="0.2em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> is too large, the network dynamics can explode whereas if <inline-formula><mml:math id="M12"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mtext>nonlin</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="0.2em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mtext>nonlin</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="0.2em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> is too small, the network is not able to learn the task). Note that vanishing gradients during training also impacted the value of <inline-formula><mml:math id="M13"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mtext>nonlin</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="0.2em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> that was required for different networks to exhibit similar performance (<xref ref-type="fig" rid="F6">Fig. 6c</xref>). Nevertheless, <inline-formula><mml:math id="M14"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mtext>nonlin</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="0.2em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> was varied by an order of magnitude between <xref ref-type="fig" rid="F6">Fig. 6</xref> and <xref ref-type="fig" rid="F17">Extended Data Figs. 11</xref>–<xref ref-type="fig" rid="F19">13</xref> to specifically test the robustness of our results to this parameter.</p></sec><sec id="S20"><label>1.3.4</label><title>Optimized ring attractor networks</title><p id="P70">When training to create ring attractor networks (<xref ref-type="fig" rid="F9">Extended Data Fig. 3</xref>), we made three modifications to the nonlinear networks described above. First, in line with other approaches for optimizing recurrent neural networks<sup><xref ref-type="bibr" rid="R17">17</xref>,<xref ref-type="bibr" rid="R20">20</xref>,<xref ref-type="bibr" rid="R24">24</xref>,<xref ref-type="bibr" rid="R65">65</xref></sup>, we used a hyperbolic tangent nonlinearity because the saturation of this nonlinearity greatly encouraged a continuous attractor to form compared with a ReLu nonlinearity. Second, we trained networks with 36 cue conditions, and then subsequently restricted our analyses to 6 evenly spaced cue conditions to keep consistency with our other analyses. Third, we used a cost function that measured estimation (or fine, rather than coarse, discrimination) performance across those 36 conditions, thus encouraging a ring attractor to form: <disp-formula id="FD4"><label>(4)</label><mml:math id="M15"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mi>ℒ</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>⟨</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mtext>nonlin</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="0.2em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:munderover><mml:mi>∑</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>36</mml:mn></mml:mrow></mml:munderover><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msubsup><mml:mrow><mml:mo>[</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>θ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mtext>nonlin</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="0.2em"/><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:munderover><mml:mi>∑</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>36</mml:mn></mml:mrow></mml:munderover><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mo>∥</mml:mo><mml:msup><mml:mrow><mml:mtext mathvariant="bold">r</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mspace width="0.2em"/><mml:mtext>d</mml:mtext></mml:mrow><mml:mi>t</mml:mi><mml:mo>⟩</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> with <disp-formula id="FD5"><label>(5)</label><mml:math id="M16"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>atan</mml:mi><mml:mo>⁡</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mrow><mml:mtext>out</mml:mtext><mml:mspace width="0.2em"/></mml:mrow><mml:mrow><mml:mrow><mml:mtext>y</mml:mtext></mml:mrow></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mtext mathvariant="bold">r</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mrow><mml:mtext>out</mml:mtext><mml:mspace width="0.2em"/></mml:mrow><mml:mrow><mml:mrow><mml:mtext>x</mml:mtext></mml:mrow></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mtext mathvariant="bold">r</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> where <inline-formula><mml:math id="M17"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> is the population vector-decoded stimulus angle, such that atan2(<italic>y, x</italic>) gives the angle that the vector [<italic>x, y</italic>] makes with the x-axis, <inline-formula><mml:math id="M18"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mrow><mml:mtext>out</mml:mtext></mml:mrow><mml:mrow><mml:mrow><mml:mtext>x</mml:mtext></mml:mrow></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mrow><mml:mtext>out</mml:mtext></mml:mrow><mml:mrow><mml:mrow><mml:mtext>y</mml:mtext></mml:mrow></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℛ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> are 2 sets of ‘readout’ weights defining the plane in which decoded angles are defined, and <inline-formula><mml:math id="M19"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msup><mml:mi>θ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mfrac><mml:mi>c</mml:mi><mml:mn>36</mml:mn></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> is the target angle for cue condition <italic>c</italic>. All other terms were the same as those defined in <xref ref-type="sec" rid="S19">Methods 1.3.3</xref>. See also <xref ref-type="supplementary-material" rid="SD1">Supplementary Information S5</xref> for a derivation showing how the cost function <xref ref-type="disp-formula" rid="FD4">Eq. 4</xref> relates to Fisher information.</p></sec></sec><sec id="S21"><label>1.4</label><title>Linear networks</title><p id="P71">For the dynamical equations of linear networks, see <xref ref-type="sec" rid="S15">Methods 1.2</xref>. Linear networks were either constructed ‘<italic>de novo</italic>’ (<xref ref-type="fig" rid="F3">Figs. 3</xref> and <xref ref-type="fig" rid="F4">4</xref> and <xref ref-type="fig" rid="F10">Extended Data Figs. 4</xref> and <xref ref-type="fig" rid="F11">5</xref>), obtained by a local linearization of canonical nonlinear dynamical systems (<xref ref-type="fig" rid="F12">Extended Data Fig. 6</xref>) or of nonlinear neural network dynamics (<xref ref-type="fig" rid="F9">Extended Data Fig. 3e</xref> and <xref ref-type="fig" rid="F13">Extended Data Fig. 7a–c</xref>), or they were fitted to neural responses obtained from experiments (<xref ref-type="fig" rid="F5">Fig. 5f</xref>, and <xref ref-type="fig" rid="F16">Extended Data Fig. 10f,g</xref>) or the simulation of nonlinear networks (<xref ref-type="fig" rid="F6">Fig. 6e</xref> and <xref ref-type="fig" rid="F13">Extended Data Fig. 7d</xref>).</p><sec id="S22"><label>1.4.1</label><title>De novo linear networks</title><p id="P72">We used <italic>de novo</italic> linear networks to develop an analytical understanding of the dynamics of optimal information loading. These networks included small 2-neuron networks with hand-picked parameters (see <xref ref-type="table" rid="T1">Table 1</xref>) chosen to illustrate the differences between normal (symmetric) and non-normal (unconstrained) dynamics and the effects of different initial conditions (<xref ref-type="fig" rid="F3">Fig. 3a–c</xref>), as well as large networks (with 10, 100, or 1000 neurons) with randomly generated parameters (<xref ref-type="fig" rid="F3">Fig. 3d,e</xref>, <xref ref-type="fig" rid="F4">Fig. 4</xref>, <xref ref-type="fig" rid="F10">Extended Data Fig. 4</xref>, and <xref ref-type="fig" rid="F11">Extended Data Fig. 5a,b</xref>; see <xref ref-type="table" rid="T1">Table 1</xref>). We always set the largest eigenvalue of the weight matrix to be exactly 1 (thus setting the largest eigenvalue of the associated Jacobian to 0 due to the leak term) so that these networks had an integrating or ‘persistent’ mode<sup><xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R26">26</xref>,<xref ref-type="bibr" rid="R34">34</xref>,<xref ref-type="bibr" rid="R35">35</xref></sup> (see <xref ref-type="table" rid="T1">Table 1</xref>)</p><p id="P73">Initial conditions (<xref ref-type="fig" rid="F3">Fig. 3</xref>, <xref ref-type="fig" rid="F10">Extended Data Fig. 4</xref>, and <xref ref-type="fig" rid="F11">Extended Data Fig. 5a,b</xref>) or temporally extended inputs (<xref ref-type="fig" rid="F4">Fig. 4</xref>) were determined by computing the most persistent and amplifying direction(s) based on the Jacobian of the dynamics (<xref ref-type="fig" rid="F3">Figs. 3</xref> and <xref ref-type="fig" rid="F4">4</xref>, and <xref ref-type="fig" rid="F11">Extended Data Fig. 5a,b</xref>, see <xref ref-type="sec" rid="S32">Methods 1.7.1</xref>; for how initial conditions were determined in <xref ref-type="fig" rid="F10">Extended Data Fig. 4c,d</xref> see <xref ref-type="supplementary-material" rid="SD1">Supplementary Information S2.8</xref>). For the networks in <xref ref-type="fig" rid="F4">Fig. 4</xref>, we also added a small amount of noise to the input to allow for some transient dynamics for all input directions (see <xref ref-type="fig" rid="F4">Fig. 4c</xref> at 0 s). Alternatively, we optimized initial conditions for maximal asymptotic overlap with the most persistent mode (<xref ref-type="fig" rid="F11">Extended Data Fig. 5c,d</xref>; see below). For setting the noise level, <italic>σ</italic>, in these networks, we considered two scenarios: noise matched (<xref ref-type="fig" rid="F4">Fig. 4a</xref>, light green and gray) and performance matched (<xref ref-type="fig" rid="F4">Fig. 4a</xref>, dark green and black). For noise matched simulations, we first determined the highest value of <italic>σ</italic> that still allowed us to obtain 100% decodability (using a delay-trained decoder) for all networks when receiving inputs aligned with the most amplifying mode (<xref ref-type="fig" rid="F4">Fig. 4a</xref>, red). This resulted in <italic>σ</italic> = 0.1 for symmetric models, and <italic>σ</italic> = 0.17 for unconstrained models. We then used the same <italic>σ</italic> for simulations using inputs aligned with the most persistent and random directions. For performance matched simulations, we used a different value of <italic>σ</italic> for each possible input direction so that all models achieved 100% decodability using a delay-trained decoder. For symmetric models, this required <italic>σ</italic> = 0.1 for inputs aligned with either the persistent or most amplifying modes, and <italic>σ</italic> = 0.005 for random inputs. For unconstrained models, this required <italic>σ</italic> = 0.17 for inputs aligned with the most amplifying mode, <italic>σ</italic> = 0.02 for inputs aligned with the persistent mode, and <italic>σ</italic> = 0.005 for random inputs. (Note that, consistent with our theory, smaller noise levels were necessary to achieve the same desired level of performance for input directions that were predicted to be increasingly suboptimal by our analysis.)</p><p id="P74">To demonstrate that the initial conditions along the most amplifying directions, obtained by control theoretic analyses, were indeed optimal for maximising the overlap with the most persistent mode (the measure of optimality we used for these networks, <xref ref-type="fig" rid="F3">Fig. 3c,e</xref>), we also used a direct numerical optimization approach, analogous to that used to optimize initial conditions in our nonlinear networks (<xref ref-type="fig" rid="F2">Figs. 2</xref> and <xref ref-type="fig" rid="F6">6</xref>, see also <xref ref-type="sec" rid="S19">Methods 1.3.3</xref>). Specifically, we optimized <bold>h</bold><sup>(<italic>c</italic>)</sup> (constrained to have unit Euclidean norm) with gradient descent using Adam optimization<sup><xref ref-type="bibr" rid="R85">85</xref></sup> with gradients obtained from back-propagation through time using the following cost function <disp-formula id="FD6"><label>(6)</label><mml:math id="M20"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mi>ℒ</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>1.5</mml:mn><mml:mrow><mml:mspace width="0.2em"/><mml:mtext>s</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mspace width="0.2em"/><mml:mtext>s</mml:mtext></mml:mrow></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mi>tanh</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">v</mml:mtext></mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mspace width="0.2em"/><mml:mtext>d</mml:mtext></mml:mrow><mml:mi>t</mml:mi></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> where <bold>v</bold><sub>1</sub> is the eigenvector associated with eigenvalue 0 of the Jacobian (i.e. the most persistent mode). We used a learning rate of 0.0001. We performed the above training procedure independently for 100 random noisy networks (either symmetric or unconstrained) and we show averaged results in <xref ref-type="fig" rid="F11">Extended Data Fig. 5c,d</xref>. We also used random initial conditions as controls. These had elements that were either sampled from a standard normal distribution (re-scaled to have unit Euclidean norm) in large networks (<xref ref-type="fig" rid="F3">Fig. 3d,e</xref>, <xref ref-type="fig" rid="F4">Fig. 4</xref>, and <xref ref-type="fig" rid="F11">Extended Data Fig. 5a,b</xref>), or in the case of 2-neuron networks, quasi-randomly chosen (with unit Euclidean norm) for illustrative purposes (<xref ref-type="fig" rid="F3">Fig. 3a–c</xref>).</p></sec><sec id="S23"><label>1.4.2</label><title>Local linearization of nonlinear dynamics</title><p id="P75">To better understand how the dynamics of optimal information loading that we identified in linear networks apply to nonlinear attractor dynamics, we performed a local linearization of our simulated nonlinear networks (<xref ref-type="fig" rid="F9">Extended Data Fig. 3e</xref>, <xref ref-type="fig" rid="F12">Extended Data Fig. 6</xref>, and <xref ref-type="fig" rid="F13">Extended Data Fig. 7a–c</xref>). This approach required access to the ‘true’ dynamical equations of the nonlinear networks—which we had by construction.</p><p id="P76">We performed local linearizations of the original nonlinear network dynamics in <bold>x</bold>-space (the space of variables in which the dynamics was defined, <xref ref-type="disp-formula" rid="FD1">Eq. 1</xref>) around the origin (we found empirically that initial conditions were distributed close to the origin)—which served as the reference point with respect to which the norm of optimized initial conditions was constrained in the networks we linearized (<xref ref-type="sec" rid="S16">Methods 1.3</xref>; analogous to our analysis of information loading in linear networks, <xref ref-type="fig" rid="F3">Fig. 3a–e</xref>, and see also <xref ref-type="sec" rid="S33">Methods 1.7.2</xref>). As the ReLU firing rate nonlinearity of these networks is non-differentiable at exactly the origin, we computed the ‘average’ Jacobian of the system in the immediate vicinity of the origin instead (this allowed us to use the same linearization and the same set of amplifying modes for all initial conditions; we obtained similar results by linearizing separately for each initial condition). Because the derivative of each ReLU is 0 or 1 in half of the activity space of the network, this resulted in the Jacobian <inline-formula><mml:math id="M21"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mtext mathvariant="bold">J</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mo>∗</mml:mo></mml:msup><mml:mo>−</mml:mo><mml:mrow><mml:mtext mathvariant="bold">I</mml:mtext></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> where <bold>W</bold><sup><italic>*</italic></sup> is the weight matrix of the original nonlinear network. Note that one obtains the same result even without averaging, by regarding the ReLu nonlinearity as the limiting case of the soft-ReLu nonlinearity: <inline-formula><mml:math id="M22"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mo stretchy="false">[</mml:mo><mml:mi>x</mml:mi><mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mtext>lim</mml:mtext><mml:mrow><mml:mi>β</mml:mi><mml:mo stretchy="false">→</mml:mo><mml:mo>∞</mml:mo></mml:mrow></mml:munder><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>β</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> of which the derivative at <italic>x</italic> = 0 is <inline-formula><mml:math id="M23"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> (at any value of the inverse temperature, <italic>β</italic>) and thus results in the same Jacobian as above. We confirmed that the resulting dynamics were always stable (largest real eigenvalue of <bold>J</bold> was less than 0). We then used this system to identify the locally (around the origin) most amplifying or most persistent modes (<xref ref-type="fig" rid="F13">Extended Data Fig. 7a</xref>).</p><p id="P77">For simulating these linearized networks (<xref ref-type="fig" rid="F13">Extended Data Fig. 7b</xref>), we then used the Jacobian we thus obtained to map the resulting linearized dynamics to a deterministic integrator with the effective weight matrix <bold>W</bold> = (<bold>J</bold> + <bold>I</bold>) <italic>− λ</italic><sub>max</sub> <bold>I</bold>, where <italic>λ</italic><sub>max</sub> is the largest real eigenvalue of <bold>J</bold>. Thus, the resulting dynamics were always marginally stable (largest real eigenvalue of <bold>J</bold> was exactly 0). (Note that for subsequent analyses involving most persistent and amplifying modes, we used the original weight matrix, see more in <xref ref-type="sec" rid="S32">Methods 1.7.1</xref>. Nevertheless, the most persistent modes of the weight matrices we used for simulation and those we used in subsequent analyses were identical, as they only relied on the eigenvectors of the weight matrix, or the Jacobian, and the rank order of their associated eigenvalues, which this stabilization did not affect. We also checked numerically that making the system marginally stable only had very minor effects on the most amplifying modes, with correlations between the most amplifying modes of the original and simulated dynamics being above 0.9. Thus, in these respects, our simulations were representative of the dynamics of the original systems.) The bias parameters, <bold>b</bold>, were the same as in the original nonlinear networks. The initial conditions, <bold>h</bold><sup>(<italic>c</italic>)</sup>, were either the ones we originally optimized for the nonlinear dynamics without any constraints (beside a constraint on their norm), or they were optimized while constraining them to the most persistent, most amplifying, or a randomly chosen subspace of these linearized dynamics (all were of the same dimensionality for a fair comparison, <xref ref-type="fig" rid="F13">Extended Data Fig. 7</xref>).</p><p id="P78">For ring attractor networks (<xref ref-type="fig" rid="F9">Extended Data Fig. 3</xref>), which used a tanh nonlinearity (<xref ref-type="sec" rid="S20">Methods 1.3.4</xref>), the associated linearized system around the origin was given by the Jacobian <bold>J</bold> = <bold>W</bold> − <bold>I</bold>, which we then used to identify the locally most amplifying and persistent modes (<xref ref-type="fig" rid="F9">Extended Data Fig. 3e</xref>).</p><p id="P79">We used the same approach to linearize the dynamics of the canonical minimal nonlinear attractor dynamics that we used to gain insights into information loading in nonlinear systems (<xref ref-type="sec" rid="S30">Methods 1.6</xref>, see also <xref ref-type="supplementary-material" rid="SD1">Supplementary Information S3</xref> and <xref ref-type="fig" rid="F12">Extended Data Fig. 6</xref>). In this case, the Jacobian was well defined at the origin, so there was no need to average it. For consistency with the notation and terminology we use in the rest of this paper, and without loss of generality (as linear dynamical systems and linear neural networks are isomorphic), we refer to the resulting linear dynamical system as a ‘linear neural network’ and define it by its ‘effective’ weight matrix (defined via the Jacobian as above). Initial conditions were magnitude-matched and chosen to align with the most persistent or the most amplifying direction extracted from the Jacobian (<xref ref-type="sec" rid="S32">Methods 1.7.1</xref>), or chosen randomly, or varied systematically to cover the whole range of possible directions. There were no other parameters for these linearized ‘networks’.</p></sec><sec id="S24"><label>1.4.3</label><title>Fitting linear neural networks to neural responses</title><p id="P80">In order to be able to apply our theoretically derived measures of optimal information loading without having access to the true dynamics of the system, we also created linear neural networks whose parameters were fitted to experimental data (see below). As a control, we repeated the same fitting procedure with simulated nonlinear networks to validate that our approach provides meaningful results when 1. we do not have access to the true dynamics but only to samples of activities generated by those dynamics, and 2. we also cannot assume that the true dynamics are linear.</p><p id="P81">We fitted deterministic linear neural networks to 1 s of trial-averaged neural activity (experimentally recorded, or simulated by a nonlinear neural network model). For the main analyses (<xref ref-type="fig" rid="F5">Fig. 5d–f</xref>, <xref ref-type="fig" rid="F6">Fig. 6e</xref>, and <xref ref-type="fig" rid="F13">Extended Data Fig. 7d</xref>), we used data starting from the onset of the stimulus cue. For the control analysis of late delay experimental recordings (<xref ref-type="fig" rid="F16">Extended Data Fig. 10g</xref>), we used the final 1 s of neural activity just prior to the go cue. For the shuffle control (<xref ref-type="fig" rid="F5">Fig. 5d</xref>; dark gray, and <xref ref-type="fig" rid="F16">Extended Data Fig. 10f</xref>), we again used data starting from stimulus onset but randomly shuffled neural activity across time and proceeded by fitting this shuffled data instead.</p><p id="P82">For fitting high dimensional neural data, we first performed principal components analysis on neural activity (dimensions: neurons, data points: time points, indexed by <italic>t</italic>, and cue conditions, indexed by <italic>c</italic>), and projected it through the principal components <inline-formula><mml:math id="M24"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mo stretchy="false">(</mml:mo><mml:mtext>PCs</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mo>:</mml:mo><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mo>∗</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mtext mathvariant="bold">P</mml:mtext></mml:mrow><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">r</mml:mtext></mml:mrow><mml:mo>∗</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> where the columns of <bold>P</bold> are top 20 principal components of the data, and <inline-formula><mml:math id="M25"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">r</mml:mtext></mml:mrow><mml:mo>∗</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> is trial averaged neural responses (mean-centered, see above) at time <italic>t</italic> in condition <italic>c</italic>. These top 20 PCs captured approximately 75% and 76% of variance for monkeys K and T, respectively during the cue and early delay period (<xref ref-type="fig" rid="F5">Fig. 5d–f</xref>), 70% and 60% of variance for monkeys K and T, respectively during the late delay period (<xref ref-type="fig" rid="F16">Extended Data Fig. 10g</xref>), and over 95% of the variance for all simulated neural activities (<xref ref-type="fig" rid="F6">Fig. 6e</xref>). The projected neural activity time courses of the neural data, <inline-formula><mml:math id="M26"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mo>∗</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> served as the targets that needed to be matched (after a suitable linear transformation with ‘read-out’ matrix <bold>C</bold> ∈ <italic>ℛ</italic><sup>20<italic>×</italic>20</sup>) by the neural activity time courses generated by the fitted neural network’s dynamics in the corresponding cue conditions, <bold>x</bold><sup>(<italic>c</italic>)</sup>(<italic>t</italic>) (<xref ref-type="disp-formula" rid="FD1">Eqs. 1</xref> and <xref ref-type="disp-formula" rid="FD2">2</xref>). For fitting the parameters of the network (<bold>W, h</bold><sup>(<italic>c</italic>)</sup>, <bold>b</bold>) and the readout matrix (<bold>C</bold>), we used the following cost function: <disp-formula id="FD7"><label>(7)</label><mml:math id="M27"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mi>ℒ</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>ε</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mtext>lin</mml:mtext><mml:mspace width="0.2em"/></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mo>∥</mml:mo><mml:mrow><mml:mtext mathvariant="bold">C</mml:mtext></mml:mrow><mml:msubsup><mml:mo>∥</mml:mo><mml:mrow><mml:mrow><mml:mtext>F</mml:mtext></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:mo>∥</mml:mo><mml:mrow><mml:mtext mathvariant="bold">b</mml:mtext></mml:mrow><mml:msubsup><mml:mo>∥</mml:mo><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:munderover><mml:mi>∑</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>6</mml:mn></mml:munderover><mml:msubsup><mml:mrow><mml:mo>∥</mml:mo><mml:msup><mml:mrow><mml:mtext mathvariant="bold">h</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> with <disp-formula id="FD8"><label>(8)</label><mml:math id="M28"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msup><mml:mi>ε</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>6</mml:mn></mml:mfrac><mml:munderover><mml:mi>∑</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>6</mml:mn></mml:munderover><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mrow><mml:mspace width="0.2em"/><mml:mtext>s</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mspace width="0.2em"/><mml:mtext>s</mml:mtext></mml:mrow></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mtext mathvariant="bold">e</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mtext mathvariant="bold">D</mml:mtext></mml:mrow><mml:msup><mml:mrow><mml:mtext mathvariant="bold">e</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:mi>t</mml:mi><mml:mspace width="2em"/><mml:mtext>being</mml:mtext><mml:mspace width="2em"/><mml:mtext>the</mml:mtext><mml:mspace width="2em"/><mml:mtext>mean</mml:mtext><mml:mspace width="2em"/><mml:mtext>squared</mml:mtext><mml:mspace width="2em"/><mml:mtext>error</mml:mtext><mml:mspace width="2em"/><mml:mtext>of</mml:mtext><mml:mspace width="2em"/><mml:mtext>the</mml:mtext><mml:mspace width="2em"/><mml:mtext>fit</mml:mtext></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> and <disp-formula id="FD9"><label>(9)</label><mml:math id="M29"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msup><mml:mrow><mml:mtext mathvariant="bold">e</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mtext mathvariant="bold">C</mml:mtext></mml:mrow><mml:msup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mo>∗</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="3em"/><mml:mtext>the</mml:mtext><mml:mspace width="2em"/><mml:mtext>momentary</mml:mtext><mml:mspace width="2em"/><mml:mtext>error</mml:mtext></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> where <bold>D</bold> is a diagonal matrix with the variances explained by the corresponding PCs in <bold>P</bold> on the diagonal (encouraging the optimization procedure to prioritize fitting the top PCs), <inline-formula><mml:math id="M30"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mo>∥</mml:mo><mml:mo>⋅</mml:mo><mml:msubsup><mml:mo>∥</mml:mo><mml:mtext>F</mml:mtext><mml:mn>2</mml:mn></mml:msubsup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> is the Frobenius norm of a matrix.</p><p id="P83">Also note that we had no constraints on <bold>W</bold> to define stable dynamics. Nevertheless, when fitting experimental recordings, and responses generated by nonlinear attractor networks, we found that the largest real eigenvalue of the fitted <bold>W</bold> was typically within the 0.95 ≤ λ<sub>max</sub> ≤ 1.05 range, i.e. the dynamics were near marginal stability, in line with the dynamics of our <italic>de novo</italic> linear neural networks (<xref ref-type="sec" rid="S22">Methods 1.4.1</xref>), as well as of those that we obtained by local linearization (<xref ref-type="sec" rid="S23">Methods 1.4.2</xref>). The only exception was when fitting the responses of nonlinear networks trained on an after-go-time cost (<xref ref-type="sec" rid="S19">Methods 1.3.3</xref>) which resulted in dynamics without attractors and, consequently, the fitted linear dynamics typically had <italic>λ</italic><sub>max</sub> &gt; 1.05.</p><p id="P84">We used Adam<sup><xref ref-type="bibr" rid="R85">85</xref></sup> to perform gradient descent optimization of <bold>W, h</bold><sup>(<italic>c</italic>)</sup>, <bold>b</bold>, and <bold>C</bold> with gradients obtained from backpropagation through time, and a learning rate of 0.0001. We initialized elements of all of these parameters from a Gaussian distribution with mean 0 and variance 1<italic>/</italic>20 and we set the regularisation parameter to <italic>α</italic><sub>lin</sub> = 1<italic>/</italic>12.</p><p id="P85">The stimulus-masking kernel (<italic>m</italic><sub>h</sub>(<italic>t</italic>), <xref ref-type="table" rid="T1">Table 1</xref>) was matched to how the responses being fitted were obtained: with temporally extended or instantaneous inputs. Specifically, when fitting responses to temporally extended inputs (experimentally measured, <xref ref-type="fig" rid="F5">Fig. 5f</xref> and <xref ref-type="fig" rid="F16">Extended Data Fig. 10f</xref>, or simulated, <xref ref-type="fig" rid="F6">Fig. 6e</xref>), the masking kernel of the fitted linear network matched the cue period. When fitting responses generated by networks driven by instantaneous inputs (<xref ref-type="fig" rid="F13">Extended Data Fig. 7d</xref>), or when fitting the late delay period of experimental recordings (during which no stimulus is present, <xref ref-type="fig" rid="F16">Extended Data Fig. 10g</xref>), the stimulus masking kernel was set to zero, and instead the initial condition of the fitted linear network was tuned to match the responses (see below).</p><p id="P86">In most cases (<xref ref-type="fig" rid="F5">Fig. 5f</xref>, <xref ref-type="fig" rid="F6">Fig. 6e</xref>, and <xref ref-type="fig" rid="F16">Extended Data Fig. 10f</xref>), we set the initial condition <bold>x</bold><sup>(<italic>c</italic>)</sup>(<italic>t</italic><sub>0</sub>) = <bold>0</bold>. There were two exceptions to this. First, when fitting the late delay dynamics in the experimental recordings (<xref ref-type="fig" rid="F16">Extended Data Fig. 10g</xref>), we set <inline-formula><mml:math id="M31"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mtext mathvariant="bold">C</mml:mtext></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mo>∗</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> (i.e. we fixed the initial condition of the latent dynamics to the data as no stimulus is present during the late delay period; we also observed qualitatively similar results when we included <bold>x</bold><sup>(<italic>c</italic>)</sup>(<italic>t</italic><sub>0</sub>) as a separate optimizable parameter in this case). Second, when fitting simulated data from models that used instantaneous stimulus inputs (<xref ref-type="fig" rid="F13">Extended Data Fig. 7d</xref>), we set <bold>x</bold><sup>(<italic>c</italic>)</sup>(<italic>t</italic><sub>0</sub>) = <bold>h</bold><sup>(<italic>c</italic>)</sup>.</p></sec></sec><sec id="S25"><label>1.5</label><title>Previous working memory models</title><p id="P87">We used the following dynamics for implementing all previous neural network models of working memory: <disp-formula id="FD10"><label>(10)</label><mml:math id="M32"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:msup><mml:mrow><mml:mtext mathvariant="bold">r</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mrow><mml:mtext>h</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mtext mathvariant="bold">h</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mrow><mml:mtext>g</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mtext mathvariant="bold">g</mml:mtext></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="FD11"><label>(11)</label><mml:math id="M33"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mrow><mml:mtext>r</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:msup><mml:mrow><mml:mtext mathvariant="bold">r</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mtext mathvariant="bold">r</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mrow><mml:mtext mathvariant="bold">f</mml:mtext></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">b</mml:mtext></mml:mrow><mml:mrow><mml:mrow><mml:mtext>r</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mrow><mml:mtext>r</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:msubsup><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mtext>r</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> where all symbols refer to the same (or a closely analogous, see below) quantity as in <xref ref-type="disp-formula" rid="FD1">Eqs. 1</xref> and <xref ref-type="disp-formula" rid="FD2">2</xref>. Note that we use this notation to best expose the similarities with and differences from the dynamics of our networks (<xref ref-type="disp-formula" rid="FD1">Eqs. 1</xref> and <xref ref-type="disp-formula" rid="FD2">2</xref>), rather than the original notation used for describing these models<sup><xref ref-type="bibr" rid="R5">5</xref>,<xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R27">27</xref></sup>, but the dynamics are nevertheless identical to those previously published. Overall, these dynamics are closely analogous to those that we used earlier for our networks with the following differences. First, for us, dynamics were defined in <bold>x</bold>-space, with <bold>r</bold> being an instantaneous function of <bold>x</bold>. Here, the dynamics are defined instead in <bold>r</bold>-space (<xref ref-type="fig" rid="F7">Extended Data Fig. 1a–d</xref> and <xref ref-type="fig" rid="F14">Extended Data Fig. 8</xref>), with <bold>x</bold> being an instantaneous function of <bold>r</bold>. (There are slightly different assumptions underlying these rate-based formulations of neural network dynamics when deriving them as approximations of the dynamics of spiking neural networks<sup><xref ref-type="bibr" rid="R46">46</xref></sup>, and the two become identical in the case of linear dynamics.) As a result, time constants, <bold><italic>τ</italic></bold><sub>r</sub>, biases, <bold>b</bold><sub>r</sub>, and the variance of noise, <bold><italic>σ</italic></bold><sub>r</sub> (as well as noise itself, <inline-formula><mml:math id="M34"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mtext>r</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> are defined for <bold>r</bold> rather than <bold>x</bold>. For nonlinear variants of these networks, there are also differences for the choice of single neuron nonlinearities, <bold>f</bold>(·). Furthermore, some of these networks distinguish between excitatory and inhibitory cells, with different time constants, and noise standard deviations. Thus, each of these parameters is represented as a diagonal matrix, <bold><italic>τ</italic></bold><sub>r</sub> and <bold><italic>σ</italic></bold><sub>r</sub>, respectively, with each element on the diagonal storing one of two possible values of that parameter depending on the type (excitatory or inhibitory) of the corresponding neuron (<inline-formula><mml:math id="M35"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow><mml:mrow><mml:mtext>r</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mtext>E</mml:mtext></mml:mrow></mml:mrow></mml:msubsup><mml:mspace width="0.2em"/><mml:mtext>and</mml:mtext><mml:mspace width="0.2em"/><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mrow><mml:mtext>r</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mtext>E</mml:mtext></mml:mrow></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mspace width="0.2em"/><mml:mtext>or</mml:mtext><mml:mspace width="0.2em"/><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow><mml:mrow><mml:mtext>r</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow></mml:mrow></mml:msubsup><mml:mspace width="0.2em"/><mml:mtext>and</mml:mtext><mml:mspace width="0.2em"/><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> respectively). Most importantly, all of these networks used a set of parameters which were hand-crafted to produce the required type of dynamics, rather than optimized for a function (or to fit data) as in the case of our networks. In line with our analyses of experimental data and task-optimized networks (<xref ref-type="fig" rid="F5">Figs. 5</xref> and <xref ref-type="fig" rid="F6">6</xref>), simulations started at <italic>t</italic><sub>0</sub> = −0.5 s, i.e. 0.5 s before stimulus cue onset (defined as <italic>t</italic> = 0), the stimulus cue lasted for 0.25 s, and the go cue appeared at <italic>t</italic><sub>go</sub> = 2 s and lasted for 0.5 s. (Note that for these networks we considered the fixed-delay variant of the task as that is what these networks were originally constructed to solve.) As with our networks (<xref ref-type="sec" rid="S15">Methods 1.2</xref>), we solved the dynamics of <xref ref-type="disp-formula" rid="FD10">Eqs. 10</xref> and <xref ref-type="disp-formula" rid="FD11">11</xref> using a first-order Euler–Maruyama approximation between <italic>t</italic><sub>0</sub> and the simulation end time with a discretization time step of 1 ms.</p><p id="P88">For analysis methods that used cross-validation (see below), we simulated network dynamics twice (for each cue condition) with independent realizations of <inline-formula><mml:math id="M36"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mtext>r</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> to serve as (trial-averaged) train and test data. For other analyses, we used a single set of simulated trajectories. All analyses involving these networks were repeated <italic>n</italic> = 10 times, using 10 different simulations (non-cross-validated) or simulation-pairs (cross-validated), each time with independent samples of <inline-formula><mml:math id="M37"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>η</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula></p><p id="P89"><xref ref-type="table" rid="T3">Table 3</xref> provides the values of most network and other parameters used for simulating each model. In the following we provide the additional details for each of these models that are not included in <xref ref-type="table" rid="T3">Table 3</xref>.</p><sec id="S26"><label>1.5.1</label><title>Classical bump attractor model</title><p id="P90">The bump attractor model that we used (<xref ref-type="fig" rid="F7">Extended Data Fig. 1a</xref>) has been described previously (see Ref. 5). The model contained separate excitatory and inhibitory populations. As in the discrete attractors model, the weight matrix was of the form <disp-formula id="FD12"><label>(12)</label><mml:math id="M38"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mtable columnalign="left left"><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mrow><mml:mrow><mml:mtext>EE</mml:mtext></mml:mrow></mml:mrow></mml:msup></mml:mtd><mml:mtd><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mrow><mml:mrow><mml:mtext>IE</mml:mtext></mml:mrow></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mrow><mml:mrow><mml:mtext>EI</mml:mtext></mml:mrow></mml:mrow></mml:msup></mml:mtd><mml:mtd><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mrow><mml:mrow><mml:mtext>II</mml:mtext></mml:mrow></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> where the elements of <bold>W</bold><sup>IE</sup>,<bold>W</bold><sup>EI</sup>, and <bold>W</bold><sup>II</sup> were set to 6.8<italic>/N</italic>, 8<italic>/N</italic>, and 1.7<italic>/N</italic>, respectively. The excitatory sub-matrix <bold>W</bold><sup>EE</sup> had a circulant form: <disp-formula id="FD13"><label>(13)</label><mml:math id="M39"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mtext>EE</mml:mtext></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>6</mml:mn><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mn>1.5</mml:mn><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mn>4</mml:mn><mml:mi>π</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>N</mml:mi></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:munderover><mml:mi>∑</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mn>1.5</mml:mn><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mn>4</mml:mn><mml:mi>π</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> for cell-pairs <italic>i, j</italic> = 1, …, <italic>N</italic> /2.</p><p id="P91">Stimulus cue inputs were also analogous to those used in the discrete attractors models and were set to <disp-formula id="FD14"><label>(14)</label><mml:math id="M40"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>200</mml:mn><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mn>1.5</mml:mn><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>π</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mn>4</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>6</mml:mn></mml:mfrac><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:munderover><mml:mi>∑</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:munderover><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mn>1.5</mml:mn><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>π</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mn>4</mml:mn><mml:mi>k</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>6</mml:mn></mml:mfrac><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> for cues <italic>c</italic> = 1, …, 6 and cells <italic>i</italic> = 1, …, <italic>N</italic> /2 (i.e., as above, inputs were only delivered to the excitatory neurons).</p></sec><sec id="S27"><label>1.5.2</label><title>Discrete attractors model</title><p id="P92">The discrete attractors model that we used (<xref ref-type="fig" rid="F7">Extended Data Fig. 1b</xref>) has been described previously (see the methods of Ref. 5). The model contained separate excitatory and inhibitory populations.</p><p id="P93">The weight matrix was of the form <disp-formula id="FD15"><label>(15)</label><mml:math id="M41"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnalign="left left"><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mrow><mml:mrow><mml:mtext>EE</mml:mtext></mml:mrow></mml:mrow></mml:msup></mml:mtd><mml:mtd><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mrow><mml:mrow><mml:mtext>IE</mml:mtext></mml:mrow></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mrow><mml:mrow><mml:mtext>EI</mml:mtext></mml:mrow></mml:mrow></mml:msup></mml:mtd><mml:mtd><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mrow><mml:mrow><mml:mtext>II</mml:mtext></mml:mrow></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> where the elements of <bold>W</bold><sup>IE</sup>,<bold>W</bold><sup>EI</sup>, and <bold>W</bold><sup>II</sup> were set to 2.4/<italic>N</italic>, 8/<italic>N</italic>, and 2.6/<italic>N</italic>, respectively. The excitatory sub-matrix <bold>W</bold><sup>EE</sup> was constructed by dividing the population of excitatory cells into six clusters (of 9 neurons each), with each cluster corresponding to one of the stimulus cue conditions. Connections within each cluster were strong, with a value of 30/<italic>N</italic>. Connections between neurons belonging to clusters that corresponded to adjacent stimulus cues were weaker, with a value of 2.5/<italic>N</italic>. All other connections were very weak, with a value of 0.02/<italic>N</italic>. This resulted in a block circulant structure for <bold>W</bold><sup>EE</sup>.</p><p id="P94">Stimulus cue inputs were set to <disp-formula id="FD16"><label>(16)</label><mml:math id="M42"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∝</mml:mo><mml:mfrac><mml:mrow><mml:mn>350</mml:mn><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mn>8</mml:mn><mml:mi>cos</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>π</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mn>4</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>6</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:munderover><mml:mi>∑</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:munderover><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mn>8</mml:mn><mml:mi>cos</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>π</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mn>4</mml:mn><mml:mi>k</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>6</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> for cues <italic>c</italic> = 1, …, 6 and cells <italic>i</italic> = 1, …, <italic>N</italic> /2 (i.e. inputs were only delivered to the excitatory neurons).</p></sec><sec id="S28"><label>1.5.3</label><title>Linear integrator model</title><p id="P95">The linear integrator model that we used (<xref ref-type="fig" rid="F7">Extended Data Fig. 1c</xref> and <xref ref-type="fig" rid="F14">Extended Data Fig. 8a,d</xref>) has been described previously (see Ref. 6). There were no separate excitatory and inhibitory populations in this model, and the weight matrix was constructed such that network dynamics were non-normal, non-oscillatory, and stable with a single two-dimensional neutrally stable subspace (i.e. a plane attractor). We achieved this by defining <bold>W</bold> via its eigen-decomposition: <disp-formula id="FD17"><label>(17)</label><mml:math id="M43"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mtext mathvariant="bold">VD</mml:mtext></mml:mrow><mml:msup><mml:mrow><mml:mtext mathvariant="bold">V</mml:mtext></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> where the eigenvectors (columns of <bold>V</bold>, denoted as <bold>v</bold><sub><italic>j</italic></sub>, for <italic>j</italic> = 1, …, <italic>N</italic>, with elements <italic>v</italic><sub><italic>ij</italic></sub>, for <italic>i, j</italic> = 1, …, <italic>N</italic>) were generated by the following process:</p><list list-type="order" id="L1"><list-item><p id="P96">Generating a random vector: <disp-formula id="FD18"><label>(18)</label><mml:math id="M44"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msub><mml:mi>ν</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mspace width="0.2em"/><mml:mrow><mml:mover><mml:mrow><mml:mo>∼</mml:mo></mml:mrow><mml:mrow><mml:mtext>iid.</mml:mtext></mml:mrow></mml:mover></mml:mrow><mml:mspace width="0.2em"/><mml:mrow><mml:mi>𝒩</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> for <italic>i</italic> = 1, …, <italic>N</italic>.</p></list-item><list-item><p id="P97">Making the first 10% of vectors overlapping so that the resulting matrix is non-normal: <disp-formula id="FD19"><label>(19)</label><mml:math id="M45"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>ν</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> where <disp-formula id="FD20"><label>(20)</label><mml:math id="M46"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mi>ϵ</mml:mi><mml:msub><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mspace width="0.2em"/><mml:mrow><mml:mover><mml:mrow><mml:mo>∼</mml:mo></mml:mrow><mml:mrow><mml:mtext>iid.</mml:mtext></mml:mrow></mml:mover></mml:mrow><mml:mspace width="0.2em"/><mml:mrow><mml:mi>𝒩</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mn>0.05</mml:mn><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> for <italic>i</italic> = 1, …, <italic>N</italic> and <italic>k</italic> = 1, …, <italic>K</italic> with <italic>K</italic> = 0.1 <italic>N</italic>.</p></list-item><list-item><p id="P98">Making the the other 90% of vectors orthogonal: <disp-formula id="FD21"><label>(21)</label><mml:math id="M47"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msub><mml:mrow><mml:mtext mathvariant="bold">v</mml:mtext></mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mspace width="0.2em"/><mml:mo>the</mml:mo><mml:mspace width="0.2em"/><mml:mi>k</mml:mi><mml:mspace width="0.2em"/><mml:mtext>th</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>column</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>of</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>Nullspace</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">v</mml:mtext></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">v</mml:mtext></mml:mrow><mml:mi>K</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> for <italic>k</italic> = 1, …, <italic>N − K</italic></p></list-item><list-item><p id="P99">Unit normalizing each vector: <disp-formula id="FD22"><label>(22)</label><mml:math id="M48"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msub><mml:mrow><mml:mtext mathvariant="bold">v</mml:mtext></mml:mrow><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">←</mml:mo><mml:mfrac><mml:msub><mml:mrow><mml:mtext mathvariant="bold">v</mml:mtext></mml:mrow><mml:mi>k</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mo>∥</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">v</mml:mtext></mml:mrow><mml:mi>k</mml:mi></mml:msub><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> and the eigenvalues (<italic>λ</italic><sub><italic>i</italic></sub>, for <italic>i</italic> = 1, …, <italic>N</italic>, the diagonal elements of the diagonal matrix <bold>D</bold>) were generated by the following process</p></list-item></list><list list-type="order" id="L2"><list-item><p id="P100">Generating random (real) values: <disp-formula id="FD23"><label>(23)</label><mml:math id="M49"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msub><mml:mi>λ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mspace width="0.2em"/><mml:mrow><mml:mover><mml:mrow><mml:mo>∼</mml:mo></mml:mrow><mml:mrow><mml:mtext>iid.</mml:mtext></mml:mrow></mml:mover></mml:mrow><mml:mspace width="0.2em"/><mml:mtext>Uniform</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0.8</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> for <italic>i</italic> = 1, …, <italic>N −</italic> 2.</p></list-item><list-item><p id="P101">Creating a pair of neutrally stable eigenmodes: <disp-formula id="FD24"><label>(24)</label><mml:math id="M50"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p></list-item></list><p id="P102">The stimulus cue inputs were set to <disp-formula id="FD25"><label>(25)</label><mml:math id="M51"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msup><mml:mrow><mml:mtext mathvariant="bold">h</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mtext mathvariant="bold">K</mml:mtext></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mtext>cos</mml:mtext><mml:mo>⁡</mml:mo><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>π</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>sin</mml:mtext><mml:mo>⁡</mml:mo><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>π</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> for cues <italic>c</italic> = 1, …, 6, and we considered two forms for <bold>K</bold>: either <inline-formula><mml:math id="M52"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mtext mathvariant="bold">K</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">v</mml:mtext></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">v</mml:mtext></mml:mrow><mml:mi>N</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">v</mml:mtext></mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">v</mml:mtext></mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">v</mml:mtext></mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">v</mml:mtext></mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>4</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> (<xref ref-type="fig" rid="F7">Extended Data Fig. 1c</xref> and <xref ref-type="fig" rid="F14">Extended Data Fig. 8a,d</xref>; as in the original formulation<sup><xref ref-type="bibr" rid="R6">6</xref></sup>) or <inline-formula><mml:math id="M53"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mtext mathvariant="bold">K</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">v</mml:mtext></mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">v</mml:mtext></mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">v</mml:mtext></mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> (<xref ref-type="fig" rid="F14">Extended Data Fig. 8b,e</xref>), where <italic>r</italic><sub>1</sub>, <italic>r</italic><sub>2</sub>, <italic>r</italic><sub>3</sub>, <italic>r</italic><sub>4</sub> were randomly drawn integers over the range 1 to <italic>N</italic> − 2. The first formulation of <bold>K</bold> ensured that stimulus cue inputs partially align with the persistent subspace, whereas the second formulation of <bold>K</bold> ensured that stimulus cue inputs align only with random directions.</p></sec><sec id="S29"><label>1.5.4</label><title>Feedforward network model</title><p id="P103">The linear feedforward network model that we used (<xref ref-type="fig" rid="F7">Extended Data Fig. 1d</xref> and <xref ref-type="fig" rid="F14">Extended Data Fig. 8c,f</xref>) has been described previously (see Refs. 21,27). (For pedagogical purposes, we used the simplest set up consisting of a feedforward chain of neurons, see below. However, using a more general network model that contained ‘hidden’ feedforward chains<sup><xref ref-type="bibr" rid="R21">21</xref></sup> did not affect our analyses except for <xref ref-type="fig" rid="F16">Extended Data Fig. 10e</xref> which, in contrast to the simple feedforward chain, could display overlap values greater than 0.5.) There were no separate excitatory and inhibitory populations in this model, and the weight matrix included a single chain running from neuron 1 to neuron <italic>N</italic>: <disp-formula id="FD26"><label>(26)</label><mml:math id="M54"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> for cell-pairs <italic>i, j</italic> = 1, …, <italic>N</italic>.</p><p id="P104">The stimulus cues provided random inputs delivered to only the first 10 neurons so that each input could pass through the feedforward network: <disp-formula id="FD27"><label>(27)</label><mml:math id="M55"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mspace width="0.2em"/><mml:mrow><mml:mover><mml:mrow><mml:mo>∼</mml:mo></mml:mrow><mml:mrow><mml:mtext>iid.</mml:mtext></mml:mrow></mml:mover></mml:mrow><mml:mspace width="0.2em"/><mml:mrow><mml:mi>𝒩</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> for cues <italic>c</italic> = 1, …, 6 and cells <italic>i</italic> = 1, …, 10.</p></sec></sec><sec id="S30"><label>1.6</label><title>Canonical nonlinear systems with two stable fixed points</title><p id="P105">In order to illustrate the applicability of our analysis of optimal information loading in linear dynamical systems to the behaviour of nonlinear dynamical systems, we first studied two variants (either symmetric or non-symmetric) of a canonical nonlinear system that can exhibit two stable fixed points. (These systems are closely related to the damped, unforced Duffing oscillator which is a classic example of a [non-symmetric] system that can exhibit two stable fixed points. Additionally, the analysis of these systems also holds for the Duffing oscillator.)</p><p id="P106">The dynamics of the first system (which has a symmetric Jacobian matrix) are governed by <disp-formula id="FD28"><label>(28)</label><mml:math id="M56"><mml:mtable><mml:mtr><mml:mtd><mml:mtable><mml:mtr><mml:mtd><mml:mstyle/></mml:mtd><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mrow><mml:mtext>c</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mn>1</mml:mn><mml:mn>3</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mrow><mml:mtext>c</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> and the dynamics of the second system (which has a non-symmetric Jacobian matrix) are governed by: <disp-formula id="FD29"><label>(29)</label><mml:math id="M57"><mml:mtable><mml:mtr><mml:mtd><mml:mtable><mml:mtr><mml:mtd><mml:mstyle/></mml:mtd><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mrow><mml:mtext>c</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mn>1</mml:mn><mml:mn>3</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mn>3</mml:mn><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mrow><mml:mtext>c</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p id="P107">We used a cubic polynomial in <xref ref-type="disp-formula" rid="FD28">Eqs. 28</xref> and <xref ref-type="disp-formula" rid="FD29">29</xref> because it is the lowest order polynomial that allows a system to exhibit 2 stable fixed points. Both systems exhibit 3 fixed points: both have a saddle point at the origin and both have 2 asymptotically stable fixed points at (± 1, 0) (see <xref ref-type="fig" rid="F12">Extended Data Fig. 6</xref> for the state space dynamics of these two systems).</p><p id="P108">We solved the dynamics of <xref ref-type="disp-formula" rid="FD28">Eqs. 28</xref> and <xref ref-type="disp-formula" rid="FD29">29</xref> using a first-order Euler approximation starting from <italic>t</italic> = 0 with a discretization time step of 0.02 and a time constant of <italic>τ</italic><sub>c</sub> = 0.4 (note time was unitless for this model).</p></sec><sec id="S31"><label>1.7</label><title>Analysis methods</title><p id="P109">Here we describe methods that we used to analyse neural data. Whenever applicable, the same processing and analysis steps were applied to both experimentally recorded and model simulated data. As a first step in all our analyses, in line with previous work analysing neural population dynamics<sup><xref ref-type="bibr" rid="R86">86</xref></sup>, we removed the stimulus cueindependent time-varying mean activity from each neuron’s firing rate time series (see <xref ref-type="fig" rid="F5">Fig. 5a</xref> for an example). (This was done separately for training and test data for cross-validated analyses, see below.) In most of our analyses, neural activities were aligned to stimulus cue onset defined to be at <italic>t</italic> = 0. However, due to the variable delay duration of the task (<xref ref-type="fig" rid="F1">Fig. 1a</xref>), experimentally recorded neural activities were also aligned to go cue onset for analyses that required incorporating the late delay and go epochs (i.e. beyond the first 1.65 s after the stimulus cue onset; <xref ref-type="fig" rid="F5">Fig. 5b–c</xref>, <xref ref-type="fig" rid="F16">Extended Data Fig. 10a–c,g</xref>). For simulated neural activities, this was not necessary, as we always simulated our networks in a fixed-delay task for ease of analysis, even if they were optimized for a variable-delay task in accordance with how our experimental monkey subjects were trained.</p><sec id="S32"><label>1.7.1</label><title>Identifying amplifying, persistent, and other subspaces in network dynamics</title><p id="P110">In order to understand the dynamics of neural networks with potentially complex and high-dimensional dynamics, and the way these dynamics depend on initial conditions, we identified specific subspaces within the full state space of these networks that were of particular relevance for our analyses. These subspaces served dual roles. First, as ‘intervention tools’, to ascertain their causal roles in high dimensional network dynamics, we used them to constrain the initial conditions of the dynamics of our networks (see also <xref ref-type="sec" rid="S33">Methods 1.7.2</xref>). Second, as ‘measurement tools’, to reveal key aspects of the high-dimensional dynamics of neural networks, we used them to project high-dimensional neural trajectories into these lower dimensional subspaces (see also <xref ref-type="sec" rid="S34">Methods 1.7.3</xref>).</p><p id="P111">Our main analyses relied on identifying the most persistent and most amplifying modes of a network. This required dynamics that were linear—either by construction, or by (locally) linearizing or linearly fitting dynamics that were originally nonlinear (see <xref ref-type="table" rid="T1">Table 1</xref>). We computed the most persistent mode(s) in one of two different ways. First, for networks that were either guaranteed to have stable dynamics by construction (i.e. those constructed <italic>de novo</italic>; <xref ref-type="fig" rid="F3">Figs. 3</xref> and <xref ref-type="fig" rid="F4">4</xref> and <xref ref-type="fig" rid="F10">Extended Data Figs. 4</xref>, <xref ref-type="fig" rid="F11">5</xref> and <xref ref-type="fig" rid="F14">8</xref>), or were confirmed to be always stable in practice (i.e. those constructed by local linearization; <xref ref-type="fig" rid="F9">Extended Data Fig. 3e</xref>, <xref ref-type="fig" rid="F12">Extended Data Fig. 6</xref>, and <xref ref-type="fig" rid="F13">Extended Data Fig. 7</xref>), we simply used the eigenvector(s) of the weight matrix <bold>W</bold> associated with the eigenvalue(s) that had the largest real part(s). Second, for networks that were fitted to nonlinear dynamics or recorded data, and whose dynamics could thus not be guaranteed to be stable (<xref ref-type="fig" rid="F5">Fig. 5f</xref>, <xref ref-type="fig" rid="F6">Fig. 6e</xref>, <xref ref-type="fig" rid="F13">Extended Data Fig. 7d</xref>, and <xref ref-type="fig" rid="F16">Extended Data Fig. 10f–h</xref>), we used the eigenvectors of <bold>W</bold> associated with the largest real eigenvalues that were less than or equal to 1 + <italic>δ</italic> (with <italic>δ</italic> = 0.05) (i.e. we find the slowest, or most persistent, modes of the network—the <italic>δ</italic> was mostly relevant only for the after-go-time networks of <xref ref-type="fig" rid="F6">Fig. 6</xref> and <xref ref-type="fig" rid="F18">Extended Data Fig. 12</xref> which exhibited eigenvalues substantially greater than 1 and setting <italic>δ</italic> less than 0.05 did not substantially change our results). (Note that an eigenvalue of 1 for <bold>W</bold> corresponds to an eigenvalue of 0 for the associated Jacobian of the dynamics due to the leak term.)</p><p id="P112">For computing the most amplifying modes, we performed an eigen-decomposition of the associated Observability Gramian <bold>Q</bold><sup><xref ref-type="bibr" rid="R53">53</xref>,<xref ref-type="bibr" rid="R62">62</xref></sup>. Specifically, we obtained <bold>Q</bold> by solving the following Lyapunov equation: <disp-formula id="FD30"><label>(30)</label><mml:math id="M58"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mtext mathvariant="bold">Q</mml:mtext></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mtext mathvariant="bold">Q</mml:mtext></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mtext mathvariant="bold">C</mml:mtext></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mtext mathvariant="bold">C</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> where <inline-formula><mml:math id="M59"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mover><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> is the ‘stabilized’ weight matrix of the dynamics (and the −<bold>I</bold> terms represent the effect of the leak on the Jacobian of the dynamics, <xref ref-type="disp-formula" rid="FD1">Eq. 1</xref>) and <bold>C</bold> is the read-out matrix of the network. The most amplifying mode(s) of the network are given as the eigenvector(s) of <bold>Q</bold> associated with the largest eigenvalue(s). Again, for networks that were guaranteed to have stable dynamics by construction (<xref ref-type="fig" rid="F3">Figs. 3</xref> and <xref ref-type="fig" rid="F4">4</xref>, <xref ref-type="fig" rid="F13">Extended Data Fig. 7a–c</xref>, <xref ref-type="fig" rid="F11">Extended Data Fig. 5</xref>, and <xref ref-type="fig" rid="F14">Extended Data Fig. 8</xref>), <inline-formula><mml:math id="M60"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mover><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mo>−</mml:mo><mml:mi>ϵ</mml:mi><mml:mrow><mml:mtext mathvariant="bold">I</mml:mtext></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> where <bold>W</bold> is the original weight matrix of the dynamics and <italic>ϵ</italic> = 0.01 (to ensure dynamical stability). For other networks, i.e. either linear networks fitted to experimental data (<xref ref-type="fig" rid="F5">Fig. 5f</xref> and <xref ref-type="fig" rid="F16">Extended Data Fig. 10f–h</xref>), linear networks fitted to simulated nonlinear dynamics (<xref ref-type="fig" rid="F6">Fig. 6e</xref> and <xref ref-type="fig" rid="F13">Extended Data Fig. 7d</xref>), or local linearizations of nonlinear dynamics (<xref ref-type="fig" rid="F12">Extended Data Fig. 6</xref>, <xref ref-type="fig" rid="F9">Extended Data Fig. 3e</xref>, and <xref ref-type="fig" rid="F13">Extended Data Fig. 7a–c</xref>), we used <inline-formula><mml:math id="M61"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mover><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> unless the largest eigenvalue <italic>λ</italic><sub>max</sub> of <bold>W</bold> was greater than or equal 1, in which case we used <inline-formula><mml:math id="M62"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mover><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mtext mathvariant="bold">I</mml:mtext></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> to ensure that the linear dynamics with <inline-formula><mml:math id="M63"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mover><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> were stable (which is required for calculating <bold>Q</bold>). For networks obtained by fitting neural responses (experimentally recorded or simulated; <xref ref-type="fig" rid="F5">Fig. 5f</xref>, <xref ref-type="fig" rid="F6">Fig. 6e</xref>, <xref ref-type="fig" rid="F13">Extended Data Fig. 7d</xref>, and <xref ref-type="fig" rid="F16">Extended Data Fig. 10f–h</xref>), <bold>C</bold> was obtained by fitting those responses (<xref ref-type="sec" rid="S24">Methods 1.4.3</xref>), as we wanted to understand how the fitted dynamics taking place in a latent space can generate the most discriminable fluctuations in (the principal components of) the neural responses to which they are related by this read-out matrix (although using <bold>C</bold> = <bold>I</bold> did not change our results substantially). For all other networks (<xref ref-type="fig" rid="F3">Figs. 3</xref> and <xref ref-type="fig" rid="F4">4</xref>, <xref ref-type="fig" rid="F13">Extended Data Fig. 7a–c</xref>, <xref ref-type="fig" rid="F9">Extended Data Fig. 3e</xref>, <xref ref-type="fig" rid="F11">Extended Data Fig. 5</xref>, and <xref ref-type="fig" rid="F14">Extended Data Fig. 8</xref>), we simply used <bold>C</bold> = <bold>I</bold>, as the activity of these networks was supposed to be read out in the same space within which their dynamics took place.</p><p id="P113">We also applied methods which did not rely on the linearization (or linear fitting) of network dynamics. Our goal was to develop basic intuitions for how much the dynamics of the different simulated nonlinear networks of <xref ref-type="fig" rid="F2">Fig. 2</xref> and <xref ref-type="fig" rid="F8">Extended Data Fig. 2</xref> used the persistent subspace of their dynamics. For this, we determined the ‘persistent subspace’ as the subspace spanned by the 5 principal components of the final 500 ms of neural activities (<bold>x</bold>) across all 6 cue conditions, corresponding to 6 distinct attractors, and the ‘persistent nullspace’ of the network as the 45-dimensional subspace orthogonal to the persistent subspace. For plots showing the projection of network activities within the persistent subspace (<xref ref-type="fig" rid="F8">Extended Data Fig. 2b,f</xref> and <xref ref-type="fig" rid="F8">Extended Data Fig. 2c–d</xref> and <xref ref-type="fig" rid="F8">g–h</xref>, bottom) we used the first two principal components of the full, five-dimensional persistent subspace of the network, as determined above. For plots showing the projection of network activities to persistent vs. cue-aligned directions (<xref ref-type="fig" rid="F2">Fig. 2d,j</xref>, and <xref ref-type="fig" rid="F8">Extended Data Fig. 2c–d</xref> and <xref ref-type="fig" rid="F8">g–h</xref>, top right), ‘persistent PC1’ was determined as the direction spanning the two persistent states corresponding to the two cue conditions being illustrated (i.e. as above, spanning the final 500 ms of neural activities across the two cue conditions), and ‘initial PC1 (orthogonalized)’ was determined as the the direction spanning the two initial conditions corresponding to the two cue conditions being illustrated, orthogonalized with respect to the corresponding persistent PC1.</p></sec><sec id="S33"><label>1.7.2</label><title>Subspace-constrained initial conditions</title><p id="P114">When using the subspaces identified above as ‘intervention tools’, to constrain the initial conditions of our networks, we either used the single top most persistent or amplifying mode for linear networks with low-dimensional coding spaces (including the linearized canonical nonlinear attractor dynamical system; <xref ref-type="fig" rid="F3">Figs. 3</xref> and <xref ref-type="fig" rid="F4">4</xref> and <xref ref-type="fig" rid="F11">Extended Data Figs. 5</xref> and <xref ref-type="fig" rid="F12">6</xref>), or numerically optimized initial conditions within the corresponding higher-dimensional subspaces (<xref ref-type="fig" rid="F2">Fig. 2f,l</xref>, <xref ref-type="fig" rid="F8">Extended Data Fig. 2c,d,g,h</xref>, <xref ref-type="fig" rid="F13">Extended Data Fig. 7</xref>; see also <xref ref-type="sec" rid="S16">Methods 1.3</xref> and <xref ref-type="sec" rid="S21">Methods 1.4</xref>). When the persistent subspace was extracted from neural responses (rather than from the dynamical equations of the network, <xref ref-type="sec" rid="S32">Methods 1.7.1</xref>; <xref ref-type="fig" rid="F2">Fig. 2f,l</xref>, <xref ref-type="fig" rid="F8">Extended Data Fig. 2c,d,g,h</xref>, <xref ref-type="fig" rid="F13">Extended Data Fig. 7a</xref>) we used different sets of simulations to generate data from which we could estimate the persistent subspace (as explained above), and to analyse network dynamics when initialized within these subspaces. In all cases, for a fair comparison, the magnitude of initial conditions was fixed (<xref ref-type="sec" rid="S17">Methods 1.3.1</xref>, <xref ref-type="sec" rid="S22">Methods 1.4.1</xref>), and only their direction was affected by constraining them to one of these subspaces.</p></sec><sec id="S34"><label>1.7.3</label><title>Measures of subspace overlap</title><p id="P115">In order to measure the overlap of high dimensional neural dynamics with the subspaces we identified, we used one of two methods. First, for analysing network dynamics across two conditions chosen to correspond to ‘opposite’ stimulus cues (<xref ref-type="fig" rid="F2">Fig. 2d,j</xref>, <xref ref-type="fig" rid="F3">Fig. 3c,d,e</xref>, <xref ref-type="fig" rid="F8">Extended Data Fig. 2c,d,g,h</xref>, <xref ref-type="fig" rid="F12">Extended Data Fig. 6c,d</xref>, and <xref ref-type="fig" rid="F11">Extended Data Fig. 5</xref>), such that the coding part of the persistent subspace was one-dimensional, we simply measured the projection of neural dynamics onto the first eigenvector (i.e. the eigenvector associated with the largest real eigenvalue) of the corresponding subspace using a dot product: <disp-formula id="FD31"><label>(31)</label><mml:math id="M64"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mtext>activity</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>along</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>mode</mml:mtext><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mtext mathvariant="bold">u</mml:mtext></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> where <bold>u</bold> may correspond to the most persistent, or the most amplifying mode, or the first PC of the persistent-orthogonalized cue subspace (as defined above). We also used the same measure for visualising the quality of fit of linear neural network dynamics to experimental data (<xref ref-type="sec" rid="S24">Methods 1.4.3</xref>) with <bold>u</bold> being the first PC of the full state space of neural firings rates (<xref ref-type="fig" rid="F5">Fig. 5e</xref>). In those cases, when <bold>u</bold> had to be estimated from neural responses (<xref ref-type="fig" rid="F2">Fig. 2d,j</xref>, <xref ref-type="fig" rid="F5">Fig. 5e</xref>, <xref ref-type="fig" rid="F8">Extended Data Fig. 2c,d,g,h</xref>), we used a cross-validated approach, using different subsets of the data to determine <bold>u</bold> and <bold>x</bold>(<italic>t</italic>) (from a single split of the data). In other cases, <bold>u</bold> was determined from the truly deterministic dynamics of the system and thus there was no need for cross-validation.</p><p id="P116">Second, to measure subspace overlaps for <italic>d</italic>-dimensional neural activities across multiple conditions and time points within coarser time bins (<xref ref-type="fig" rid="F4">Fig. 4c</xref>, <xref ref-type="fig" rid="F5">Fig. 5f</xref>, <xref ref-type="fig" rid="F6">Fig. 6e</xref>, <xref ref-type="fig" rid="F13">Extended Data Fig. 7d</xref>, <xref ref-type="fig" rid="F14">Extended Data Fig. 8d–e</xref>, <xref ref-type="fig" rid="F17">Extended Data Fig. 11c</xref>, <xref ref-type="fig" rid="F18">Extended Data Fig. 12d</xref>, <xref ref-type="fig" rid="F19">Extended Data Fig. 13d</xref>, and <xref ref-type="fig" rid="F16">Extended Data Fig. 10b,c,f,g</xref>), thus corresponding to high-dimensional coding sub-spaces, we used the following properly normalized measure: <disp-formula id="FD32"><label>(32)</label><mml:math id="M65"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mtext>across-condition</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>variance</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>explained</mml:mtext><mml:mspace width="0.2em"/><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>Tr</mml:mi><mml:mspace width="0.2em"/><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mtext mathvariant="bold">U</mml:mtext></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mspace width="0.2em"/><mml:mtext mathvariant="bold">Σ</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mtext mathvariant="bold">U</mml:mtext></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>Tr</mml:mi><mml:mspace width="0.2em"/><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mtext mathvariant="bold">P</mml:mtext></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="0.2em"/><mml:mo mathvariant="bold">Σ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mtext mathvariant="bold">P</mml:mtext></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> where <bold>Σ</bold>(<italic>t</italic>) is the covariance matrix of neural activities across conditions and raw (1-ms) time points within time bin <italic>t</italic>, the columns of <bold>P</bold>(<italic>t</italic>) are the first principal components of neural activities within time bin <italic>t</italic> (i.e. the eigenvectors of <bold>Σ</bold>(<italic>t</italic>) associated with the largest eigenvalues), and <bold>U</bold>(<italic>t′</italic>) is the subspace of interest with respect to which overlaps are computed (which itself may or may not depend on time, see below). The time resolution of <italic>t</italic> and <italic>t′</italic> (i.e. the duration of time bins within which data was used to compute the corresponding terms at a given <italic>t</italic> or <italic>t</italic><sup><italic>′</italic></sup>), the choice of <bold>U</bold>(<italic>t′</italic>), and the number of vectors used for constructing <bold>U</bold>(<italic>t′</italic>) and <bold>P</bold>(<italic>t</italic>) depended on the analysis (see below).</p><p id="P117">Specifically, for measuring subspace overlap between neural activity and persistent vs. amplifying modes (<xref ref-type="fig" rid="F4">Fig. 4c</xref>, <xref ref-type="fig" rid="F5">Fig. 5f</xref>, <xref ref-type="fig" rid="F6">Fig. 6e</xref>, <xref ref-type="fig" rid="F13">Extended Data Fig. 7d</xref>, <xref ref-type="fig" rid="F14">Extended Data Fig. 8d–e</xref>, and <xref ref-type="fig" rid="F16">Extended Data Fig. 10f,g</xref>), we set <bold>U</bold>(<italic>t′)</italic> = <bold>U</bold> where the columns of <bold>U</bold> are the first <italic>d/</italic>4 eigenvectors of the most persistent or amplifying subspace (orthogonalized using a QR decomposition for the most persistent modes—this was not necessary for most amplifying modes which are orthogonal by construction), or <italic>d/</italic>4 randomly chosen orthonormal vectors as a control (shown as ‘chance’; computed analytically as 1/4 for ‘de novo’ linear networks (<xref ref-type="fig" rid="F4">Fig. 4c</xref> and <xref ref-type="fig" rid="F14">Extended Data Fig. 8d–e</xref>), and numerically for fitted linear networks, also yielding values of approximately 1/4, <xref ref-type="fig" rid="F5">Fig. 5f</xref>, <xref ref-type="fig" rid="F6">Fig. 6e</xref>, <xref ref-type="fig" rid="F13">Extended Data Fig. 7d</xref>, and <xref ref-type="fig" rid="F16">Extended Data Fig. 10f</xref>). <bold>P</bold>(<italic>t</italic>) contained the first <italic>d/</italic>4 principal components. In this case, a value of 1 for this metric implies that the <italic>d/</italic>4 directions of greatest variability in neural activity overlap exactly with the <italic>d/</italic>4-dimensional subspace spanned by <bold>U</bold>. The time resolution of <italic>t</italic> was 20 ms (for clarity, bins to be plotted were subsampled in the corresponding figures). Note that when this analysis was performed on linear networks fitted to neural data (experimentally recorded or simulated), <bold>U, P</bold>(<italic>t</italic>), and <bold>Σ</bold>(<italic>t</italic>) were all obtained from the same fitted linear network (i.e. no cross-validation). Specifically the parameters of the network were used to determine <bold>U</bold> (see <xref ref-type="sec" rid="S24">Methods 1.4.3</xref>), and the neural responses these fitted linear dynamics generated (rather than the original neural responses that were fit by the linear model) were used to determine <bold>Σ</bold>(<italic>t</italic>) and thus <bold>P</bold>(<italic>t</italic>). See <xref ref-type="sec" rid="S40">Methods 1.8</xref> for computing the significance of these overlaps (and their differences). When analysing optimized ring attractor networks (<xref ref-type="fig" rid="F9">Extended Data Fig. 3e</xref>), we used 2-dimensional subspaces (rather than <italic>d/</italic>4-dimensional subspaces) because we found empirically that the obtained ring attractors lay in a 2-dimensional subspace.</p><p id="P118">For analyzing subspace sharing between different task epochs (<xref ref-type="fig" rid="F17">Extended Data Fig. 11c</xref>, <xref ref-type="fig" rid="F18">Extended Data Fig. 12d</xref>, <xref ref-type="fig" rid="F19">Extended Data Fig. 13d</xref>, and <xref ref-type="fig" rid="F16">Extended Data Fig. 10b</xref>), <bold>U</bold>(<italic>t</italic>′) contained the top <italic>k</italic> principal components (PCs) of neural activity within the time bin indexed by <italic>t</italic>′ (we used <italic>k</italic> = 10 for the monkey data and <italic>k</italic> = 4 for our models because the models typically exhibited lower dimensional dynamics), while <bold>P</bold>(<italic>t</italic>) included all PCs within the time bin indexed by <italic>t</italic>. For these, we performed principal components analysis with dimensions corresponding to neurons and data points corresponding to time points and cue conditions. The time resolution of both <italic>t</italic> and <italic>t</italic>′ was 250 ms, such that the time periods (relative to cue onset) that we used were −500 to −250 ms (spontaneous epoch), 0 to 250 (cue epoch), 1250 to 1500 ms (delay epoch), and the first 250 ms after the go cue, i.e. <italic>t</italic><sub>go</sub> to <italic>t</italic><sub>go</sub> + 250 ms (go epoch). In this case, <bold>U</bold>(<italic>t</italic>′), <bold>P</bold>(<italic>t</italic>) and <bold>Σ</bold>(<italic>t</italic>) were obtained by fitting all the available neural data (i.e. no cross-validation). See also Ref. 64 for an ‘alignment index’ metric that is closely analogous to this use of this metric.</p><p id="P119">For showing how much variance the top 2 delay epoch PCs capture over time (<xref ref-type="fig" rid="F16">Extended Data Fig. 10c</xref>), in line with Ref. 6, we set <bold>U</bold>(<italic>t</italic>′) = <bold>U</bold> where the columns of <bold>U</bold> are the first 2 principal components of neural activities over the time period 750 to 250 ms before the go cue, i.e. <italic>t</italic><sub>go</sub> − 0.75 to <italic>t</italic><sub>go</sub> − 0.25 s, and <bold>P</bold>(<italic>t</italic>) also includes the top 2 principal components. The resolution for <italic>t</italic> was 10 ms (for clarity, bins to be plotted were subsampled in the corresponding figure). In this case, we estimated <bold>U</bold> and <bold>P</bold>(<italic>t</italic>) in a cross-validated way (as in Ref. 6)—we estimated <bold>U</bold> using training data and <bold>P</bold>(<italic>t</italic>) and <bold>Σ</bold>(<italic>t</italic>) using test data, and we show results averaged over 10 random 1:1 train:test splits of the data. See also Ref. 6 for a measure that is closely related to this use of this metric, but uses the number of neurons in the denominator instead of the total variance.</p></sec><sec id="S35"><label>1.7.4</label><title>Linear decoding</title><p id="P120">We fitted decoders using linear discriminant analysis to decode the stimulus cue identity from neural firing rates (<xref ref-type="fig" rid="F2">Fig. 2e,f,k,l</xref>, <xref ref-type="fig" rid="F4">Fig. 4a,b</xref>, <xref ref-type="fig" rid="F5">Fig. 5b,c</xref>, <xref ref-type="fig" rid="F6">Fig. 6c,d</xref>, <xref ref-type="fig" rid="F13">Extended Data Fig. 7c</xref>, <xref ref-type="fig" rid="F9">Extended Data Fig. 3d</xref>, <xref ref-type="fig" rid="F14">Extended Data Fig. 8a–c</xref>,<xref ref-type="fig" rid="F16">Extended Data Fig. 10a,h</xref>, <xref ref-type="fig" rid="F17">Extended Data Fig. 11a,b</xref>, <xref ref-type="fig" rid="F18">Extended Data Fig. 12b,c</xref>, and <xref ref-type="fig" rid="F19">Extended Data Fig. 13b,c</xref>). We constrained the decoders to be 2-dimensional (in line with previous studies<sup><xref ref-type="bibr" rid="R6">6</xref></sup>) because this was a sufficient dimensionality to decode responses. (We also trained decoders using logistic regression in the full activity space and obtained qualitatively similar results; not shown.) We primarily considered two types of decoding analyses: we either trained decoders on late delay activity and tested on all time points (‘delay-trained decoder’, e.g. <xref ref-type="fig" rid="F4">Fig. 4a</xref>), or we trained decoders separately at every time point and tested on all times (‘full cross-temporal decoding’, e.g. <xref ref-type="fig" rid="F4">Fig. 4b</xref>). In all cases, we measured decoding performance in a cross-validated way, using separate sets of neural trajectories to train and test the decoder, and we show results averaged over 10 random 1:1 train:test splits of the data. For delay-trained decoders, training data consisted of pooling neural activity over a 500 ms time interval (the time interval is shown by a horizontal black bar in all relevant figures), and tested the thus-trained decoder with data in each 1 ms time bins across the trial (for clarity, test bins to be plotted were subsampled every 10 ms in the corresponding figures). For full cross-temporal decoding, we binned neural responses into 10 ms time bins and trained and tested on all pairs of time bins (specifically, we plotted mean decoding performance across the 10 1-ms raw time bins corresponding to each 10-ms testing bin). We used a shrinkage (inverse regularisation parameter on the Euclidean norm of decoding coefficients) of 0.5 (we also tested various other values and found qualitatively similar results; not shown). Chance level decoding was defined as 1/<italic>C</italic>, where <italic>C</italic> = 2 or 6 is the number of cue conditions that need to be decoded (<xref ref-type="table" rid="T1">Tables 1</xref> and <xref ref-type="table" rid="T3">3</xref>).</p></sec><sec id="S36"><label>1.7.5</label><title>Quality of fit for linear models fitted to neural responses</title><p id="P121">When fitting linear models to neural data (experimentally recorded or simulated; <xref ref-type="sec" rid="S24">Methods 1.4.3</xref>) we used a crossvalidated approach for measuring the quality of our fits, with a random 1:1 train:test split of the data (<xref ref-type="fig" rid="F5">Fig. 5d</xref>). For this, we first fitted the model on training data (<inline-formula><mml:math id="M66"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mo>∗</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mtext>train</mml:mtext><mml:mspace width="0.2em"/></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="FD9">Eq. 9</xref>). The quality of fit was then computed on the test data, <inline-formula><mml:math id="M67"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mtext>test</mml:mtext><mml:mspace width="0.2em"/></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> as the fraction of variance of <inline-formula><mml:math id="M68"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mtext>test</mml:mtext><mml:mspace width="0.2em"/></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> explained by the simulated responses (after the appropriate projection, i.e. <bold>Cx</bold><sup>(<italic>c</italic>)</sup>(<italic>t</italic>)), across all 20 dimensions weighted by <bold>D</bold> (all parameters, including <bold>P, C</bold> and <bold>D</bold>, were set to their values obtained by fitting the training data). In other words, we computed the Pearson <italic>ℛ</italic><sup>2</sup> with respect to the identity line using the mean squared error, <italic>ε</italic><sup>2</sup> in <xref ref-type="disp-formula" rid="FD8">Eq. 8</xref>, with the momentary error in <xref ref-type="disp-formula" rid="FD9">Eq. 9</xref> computed using <inline-formula><mml:math id="M69"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mo>∗</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mtext>test</mml:mtext><mml:mspace width="0.2em"/></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula>. Once the quality of fit for this split was thus established, we conducted all further analysis involving fitted linear models with the model that was fit to the training half of this split.</p><p id="P122">As a meaningful lower bound on our quality of fit measure, we also computed the same measure (i.e. fitting a linear neural networks to training data and calculating the quality of fit using test data) for 100 different time-shuffled controls of the original train:test split of the data (<xref ref-type="sec" rid="S24">Methods 1.4.3</xref>), such that we shuffled time bins coherently between the training and the test data, across neurons and conditions (<xref ref-type="fig" rid="F5">Fig. 5d</xref>, dark gray).</p><p id="P123">To calibrate how much our fits were limited by the noisiness of the data, we also computed the quality of fit directly between <inline-formula><mml:math id="M70"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mtext>train</mml:mtext><mml:mspace width="0.2em"/></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="0.2em"/><mml:mtext>and</mml:mtext><mml:mspace width="0.2em"/><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mtext>test</mml:mtext><mml:mspace width="0.2em"/></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> (i.e. using the mean squared error, <italic>ε</italic><sup>2</sup> in <xref ref-type="disp-formula" rid="FD8">Eq. 8</xref>, with the momentary error redefined as <inline-formula><mml:math id="M71"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msup><mml:mrow><mml:mtext mathvariant="bold">e</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mtext>train</mml:mtext><mml:mspace width="0.2em"/></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mtext>test</mml:mtext><mml:mspace width="0.2em"/></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> for 100 random 1:1 train:test splits of the data (<xref ref-type="fig" rid="F5">Fig. 5d</xref>, light gray). The extent to which the <italic>ℛ</italic><sup>2</sup> computed with this control was below 1 reflected the inherent (sampling) noise of the experimental data that limited the quality of fit obtainable with any parametric model, including ours that was based on linear dynamics. Moreover, a cross-validated <italic>ℛ</italic><sup>2</sup> computed with our fits that was higher than the <italic>ℛ</italic><sup>2</sup> obtained with this control (<xref ref-type="fig" rid="F5">Fig. 5d</xref> dark and light blue vs. light gray) meant that the inherent assumption of linear dynamics in our model acted as a useful regularizer to prevent the overfitting that this overly flexible control inevitably suffered from. See more in <xref ref-type="sec" rid="S40">Methods 1.8</xref> on statistical testing for our quality of fit measure.</p><p id="P124">When fitting to simulated neural data, we obtained high quality of fits using the same measure (<italic>ℛ</italic><sup>2</sup> &gt; 0.95, not shown).</p></sec><sec id="S37"><label>1.7.6</label><title>Overlap between the coding populations during the cue and delay epochs</title><p id="P125">To test whether separate neural populations encode stimulus information during the cue and delay epochs (<xref ref-type="fig" rid="F16">Extended Data Fig. 10e</xref>), we trained (non-cross validated) decoders to decode cue identity using logistic regression on either cue-epoch activity (‘cue-trained’; the first 250 ms of activity after cue onset) or delay-epoch activity (‘delay-trained’; 1250–1500 ms after cue onset). We used an L2 regularisation penalty of 0.5 (we also tested other regularisation strengths and observed no substantial changes in our results). We took the absolute value of decoder weights as a measure of how strongly neurons contributed to decodability (either positively or negatively). We then binarized the absolute ‘cue-trained’ and ‘delay-trained’ weights using their respective median values as the binarization threshold. (This binarization reduces a potential bias effect from large or small weight values in our analysis.) Our measure of overlap between the coding populations during the cue and delay epochs, was then simply the inverse normalized Hamming distance between these two sets of binarized weights: <disp-formula id="FD33"><label>(33)</label><mml:math id="M72"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mtext>overlap</mml:mtext><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mtext>cue</mml:mtext><mml:mspace width="0.2em"/></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mtext>delay</mml:mtext><mml:mspace width="0.2em"/></mml:mrow></mml:msubsup><mml:mo>|</mml:mo></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> where <inline-formula><mml:math id="M73"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mtext>cue</mml:mtext></mml:mrow></mml:msubsup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> (‘cue trained’) and <inline-formula><mml:math id="M74"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mtext>delay</mml:mtext></mml:mrow></mml:msubsup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> (‘delay trained’) is the binarized weight of neuron <italic>n</italic> in cue condition <italic>c</italic> during the cue and delay epochs, respectively, and ⟨·⟩<sub><italic>n,c</italic></sub> denotes taking the mean across neurons and cue conditions. For completely overlapping populations, this measure takes a values of 1, for completely non-overlapping populations, it takes a values of 0, and for random overlap (shown as ‘chance’) it takes a values of 0.5.</p><p id="P126">For the shuffle controls, we randomly permuted the neuron indices of the delay-trained weights (such that using the median as a threshold thus resulted in values close to 0.5, i.e. chance level; <xref ref-type="fig" rid="F16">Extended Data Fig. 10e</xref>). We show results (for both the original analysis and shuffle control) for 10 random halves of the data (equivalent to the training halves of 10 different 1:1 train:test splits). We also tested a variety of percentile values other than the median and our results did not change substantially (choosing a threshold other than the median causes both the data and shuffle controls to have overlap values lower than those that we obtained with the median as the threshold, but it does not substantially affect the difference between them). As an additional control, we also removed neurons that did not contribute to decodability: we removed neurons that had a thresholded weight of 0 for all 6 cue conditions in both the cue and delay epochs. This resulted in removing 13.3 neurons on average for monkey K and 33.5 neurons for Monkey T (when using the median as the threshold) and our results did not change substantially (not shown).</p></sec><sec id="S38"><label>1.7.7</label><title>Finding fixed / slow points</title><p id="P127">For finding the fixed / slow points of nonlinear network dynamics (<xref ref-type="fig" rid="F2">Fig. 2d,j</xref>, <xref ref-type="fig" rid="F8">Extended Data Fig. 2b,f</xref>, <xref ref-type="fig" rid="F9">Extended Data Fig. 3a</xref>, and <xref ref-type="fig" rid="F17">Extended Data Fig. 11d</xref>), we used a slow-point analysis method<sup><xref ref-type="bibr" rid="R17">17</xref></sup> that searches for an <bold>x</bold> for which the L2 norm of the gradient determined by the autonomous dynamics of the network is below a threshold. Note that this was only possible in model neural networks as the method requires access to the equations (and parameters) defining the true (nonlinear) dynamics of a system.</p><p id="P128">Specifically, for network dynamics governed by (cf. <xref ref-type="disp-formula" rid="FD1">Eqs. 1</xref> and <xref ref-type="disp-formula" rid="FD2">2</xref>) <disp-formula id="FD34"><label>(34)</label><mml:math id="M75"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mfrac><mml:mrow><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>ψ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> for some function <bold><italic>ψ</italic></bold>, we sought to find points <bold>x</bold><sup><italic>*</italic></sup> such that ||<bold><italic>ψ</italic></bold>(<bold>x</bold><sup><italic>*</italic></sup>) ||<sub>2</sub> is small. To achieve this, we drew 1000 <bold>x</bold>’s from a spherical Gaussian distribution with mean 0 and variance 10 (the large variance helps to ensure that we cover a large part of state space) and we optimized each <bold>x</bold> to minimize ||<bold><italic>ψ</italic></bold>(<bold>x</bold>) ||<sub>2</sub> using gradient descent with gradients obtained by back-propagation with an Adam optimizer<sup><xref ref-type="bibr" rid="R85">85</xref></sup>. We used an adaptive learning rate (which we found worked substantially better than a fixed learning rate in this scenario) that started at 0.1 and halved every 1000 training iterations (we used 5000 training iterations in total). Finally, we identified the <bold>x</bold>’s obtained at the end of optimization as asymptotically stable fixed points, <bold>x</bold><sup><italic>*</italic></sup>, if ||<bold><italic>ψ</italic></bold>(<bold>x</bold>)||<sub>2</sub> &lt; 0.001 and if the largest real part in the eigenvalues of the linearization of <bold><italic>ψ</italic></bold>(<bold>x</bold>) around <bold>x</bold><sup><italic>*</italic></sup> was less than 0.</p></sec><sec id="S39"><label>1.7.8</label><title>Correlations between initial and final neural firing rates</title><p id="P129">To measure correlations between initial and final simulated activities, we used the Pearson correlation coefficient (with respect to the identity line) between initial and final mean-centered firing rates across neurons within the same simulation (i.e. no cross-validation; <xref ref-type="fig" rid="F2">Fig. 2b,h</xref>; insets). Histograms show the distribution of this correlation across 6 cue conditions (and the 10 different networks, each simulated 10 times, see above) using a kerneldensity estimate (<xref ref-type="fig" rid="F2">Fig. 2c,i</xref>, <xref ref-type="fig" rid="F8">Extended Data Fig. 2c,d,g,h</xref>, and <xref ref-type="fig" rid="F9">Extended Data Fig. 3c</xref>).</p></sec></sec><sec id="S40"><label>1.8</label><title>Statistics</title><p id="P130">We performed statistical hypothesis testing in two cases.</p><p id="P131">First, we tested whether the quality of fit of linear models to experimental data was sufficiently high using permutation tests. To construct the distribution of our test statistic (cross-validated <italic>ℛ</italic><sup>2</sup>, see also <xref ref-type="sec" rid="S36">Methods 1.7.5</xref>) under the null hypothesis, we used <italic>n</italic> = 200 different random time shuffles of the data (<xref ref-type="fig" rid="F5">Fig. 5d</xref>, dark gray), such that we shuffled time bins coherently between the training and the test data, across neurons and conditions, and for each shuffle used the same random 1:1 train:test split as for the original (unshuffled) data. For additional calibration, we also constructed the distribution of our test statistic under the alternative hypothesis that all cross-validated errors were due to sampling noise differences between the train and test data. For this, we used <italic>n</italic> = 200 random 1:1 train:test splits of the (original, unshuffled) data, and measured the quality of fit directly between the test data and the training data (rather than a model fitted to the training data, see also <xref ref-type="sec" rid="S36">Methods 1.7.5</xref>; <xref ref-type="fig" rid="F5">Fig. 5d</xref>, light gray). In both cases, we computed the two-tailed p-value of the test statistic as computed on the real data (<xref ref-type="fig" rid="F5">Fig. 5d</xref>, blue lines) with respect to the corresponding reference distribution.</p><p id="P132">Second, we also used a permutation test-based approach to test whether the experimentally observed overlaps with persistent and amplifying modes (or their differences) were significantly different from those expected by chance. For testing the significance of overlaps in a given time step, we constructed the distribution of our test statistics (the overlap measures; <xref ref-type="sec" rid="S34">Methods 1.7.3</xref>) under the null hypothesis by generating <italic>n</italic> = 200 random subspaces within the space spanned by the 20 PCs we extracted from the data (<xref ref-type="sec" rid="S24">Methods 1.4.3</xref>), dimensionality matched to the persistent and amplifying subspaces (i.e. 5 orthogonal dimensions), and computed the same subspace overlap measures for the data in the given time step with respect to these random subspaces (<xref ref-type="fig" rid="F5">Fig. 5f</xref> and <xref ref-type="fig" rid="F16">Extended Data Fig. 10f–g</xref>; gray line and shading). For testing the significance of differences between overlaps (amplifying vs. persistent at a given time step, or amplifying or persistent between two different time steps), our test statistic was this difference (i.e. a paired test), and our null distribution was constructed by measuring it for <italic>n</italic> = 200 pairs of random subspace overlaps at the appropriate time step(s). Once again, in all these cases we computed the two-tailed p-value of the test statistic as computed on the real data (<xref ref-type="fig" rid="F5">Fig. 5f</xref> and <xref ref-type="fig" rid="F16">Extended Data Fig. 10f–g</xref>, green and red lines) with respect to the corresponding reference distribution.</p><p id="P133">Note that we did not compute p-values across multiple splits of the data because this led to p-value inflation as we increased the number of splits. Instead, we repeated all relevant analyses on 10 different random 1:1 train:test splits to see if our results were robust to the choice of data split. Indeed, we obtained qualitatively and quantitatively (in terms of p-values for quality of fits, and overlaps) similar results for all these splits.</p><p id="P134">Permutation tests do not assume that the data follows any pre-defined distribution. No statistical methods were used to predetermine experimental sample sizes. Sample sizes for permutation tests (<italic>n</italic> above) were chosen so as to be able to determine p-values to a precision of 0.01 (quality of fits) or 0.01 (subspace overlaps).</p></sec></sec><sec sec-type="extended-data" id="S41"><title>Extended Data</title><fig id="F7" position="anchor"><label>Extended Data Fig. 1</label><caption><title>Dynamics of network models of working memory.</title><p id="P135"><bold>a</bold>, Neural network dynamics in a bump attractor network<sup><xref ref-type="bibr" rid="R5">5</xref></sup> performing the task shown in <xref ref-type="fig" rid="F1">Fig. 1a</xref>. Left: trajectory in neural state space in a single cue condition during the cue period (pale purple line, ending in pale purple circle) and delay period (dark purple line). Purple arrow heads indicate direction of travel along the trajectory, black cross shows attractor state. Center: time course of relative (i.e. mean-centered) firing rates of one neuron for two cue conditions (purple vs. blue, see also inset). Yellow lines indicate cue onset and offset times. Right: cross-temporal decoding of neural activity produced by the network across all 6 cue conditions. Pink rectangles indicate generalized decoding between the cue/early delay period and the late delay period and cyan square indicates generalized decoding between time points in the late delay period. The gray tick on the color bar indicates chance-level decoding. <bold>b</bold>, Same as <bold>a</bold> but for a discrete attractors model<sup><xref ref-type="bibr" rid="R5">5</xref>,<xref ref-type="bibr" rid="R31">31</xref>,<xref ref-type="bibr" rid="R69">69</xref></sup>. <bold>c</bold>, Same as <bold>a</bold> but for a linear integrator model with transient dynamics that are orthogonal to the attractor subspace<sup><xref ref-type="bibr" rid="R6">6</xref></sup>. <bold>d</bold>, Same as <bold>a</bold> but for feedforward network model<sup><xref ref-type="bibr" rid="R21">21</xref>,<xref ref-type="bibr" rid="R27">27</xref></sup>. <bold>e</bold>, Same as <bold>a</bold> but for a network whose parameters (including recurrent, input, and readout weights) were optimized to perform the task shown in <xref ref-type="fig" rid="F1">Fig. 1a</xref> (cf. <xref ref-type="fig" rid="F6">Fig. 6d</xref>, right).</p></caption><graphic xlink:href="EMS156517-f007"/></fig><fig id="F8" position="anchor"><label>Extended Data Fig. 2</label><caption><title>Attractor network dynamics with or without constraints on the initial condition of the dynamics.</title><p id="P136"><bold>a</bold>, Illustration of an attractor network with symmetric connections. <bold>b</bold>–<bold>d</bold>, Analysis of neural responses in symmetric attractor networks (such as shown in <bold>a</bold>). <bold>b</bold>, Sub-threshold activity (colored trajectories) for all 6 cue conditions (color coded as in <xref ref-type="fig" rid="F5">Fig. 5e</xref>) with initial conditions optimized within the full state space (<xref ref-type="sec" rid="S17">Methods 1.3.1</xref>). Open circles show the optimized initial conditions and crosses show stable fixed points. We show neural activity projected onto the top two principal components of the persistent subspace. <bold>c</bold>, Analysis of neural responses when initial conditions are constrained to lie within the 5-dimensional persistent subspace. Top left: distribution of Pearson correlations between initial and final meancentered neural firing rates across all 6 cue conditions and 10 networks (same as <xref ref-type="fig" rid="F2">Fig. 2c</xref>, but for persistent subspace-constrained inputs, corresponding to green line in <xref ref-type="fig" rid="F2">Fig. 2f</xref>). Top right: sub-threshold activity for 2 cue conditions in an example network (colored trajectories; same as <xref ref-type="fig" rid="F2">Fig. 2d</xref>, but for persistent subspace-constrained inputs, corresponding to green line in <xref ref-type="fig" rid="F2">Fig. 2f</xref>). Open circles (with arrows pointing to them from the origin) show the optimized initial conditions, black crosses show stable fixed points, dashed gray line is the identity line. Horizontal axis (persistent PC1) shows neural activity projected on to the 1st principal component (PC1) of network activities at the end of the delay period (across the 2 conditions shown), vertical axis (initial PC1 (orthogonalized)) shows projection to PC1 of initial neural activities orthogonalized to persistent PC1. Bottom: same as <bold>b</bold>, but for persistent subspace-constrained inputs, corresponding to green line in <xref ref-type="fig" rid="F2">Fig. 2f</xref>. <bold>d</bold>, Same as <bold>c</bold>, but for persistent nullspace-constrained inputs. Note that the distribution of Pearson correlations of neural firing rates (top left) is distinct from a delta function at 0 because we constrained the initial conditions in the space of sub-threshold activities (rather than firing rates). In the bottom panel, which shows sub-threshold activity, we see that indeed all the colored circles overlap at the origin, indicating orthogonality of the initial conditions to the persistent subspace. <bold>e</bold>–<bold>h</bold>, Same as <bold>a</bold>–<bold>d</bold> but for attractor networks without a symmetric connection constraint (i.e. panels <bold>f, g</bold>, and <bold>h</bold>, respectively correspond to the networks shown by the black, green, and red lines in <xref ref-type="fig" rid="F2">Fig. 2</xref>). Note initial conditions being near the origin in <bold>f</bold> mean that they are strongly orthogonal to the persistent subspace (as in <bold>d</bold>, but without constraining them explicitly to be in the persistent nullspace).</p></caption><graphic xlink:href="EMS156517-f008"/></fig><fig id="F9" position="anchor"><label>Extended Data Fig. 3</label><caption><title>Dynamics of optimized ring attractor networks.</title><p id="P137"><bold>a</bold>, Neural activity (colored trajectories) in a ring attractor network with unconstrained connectivity and optimized initial conditions (see <xref ref-type="sec" rid="S17">Methods 1.3.1</xref> and <xref ref-type="sec" rid="S20">1.3.4</xref>) for 6 cue conditions (color coded as in <xref ref-type="fig" rid="F5">Fig. 5e</xref>). Open circles show the optimized initial conditions and black crosses show fixed points. We show neural activity projected onto the top two principal components of the persistent subspace. Thus, all circles being near the origin means that initial conditions are strongly orthogonal to this subspace (cf. <xref ref-type="fig" rid="F8">Extended Data Fig. 2f</xref>). <bold>b</bold>, Tuning curves at <italic>t</italic> = 1 s for 6 example neurons (colored curves) whose preferred angles (colored crosses) correspond to the 6 cue conditions shown in <bold>a. c</bold>, Distribution of Pearson correlations between initial and final mean-centered neural firing rates across the 6 cue conditions and 10 networks (cf. <xref ref-type="fig" rid="F2">Fig. 2i</xref>). <bold>d</bold>, Cross-temporal decoding of neural firing rate activity (cf. <xref ref-type="fig" rid="F2">Fig. 2k</xref>). Note that only the first second of the delay period is shown on both axes because the dynamics of these networks, using a tanh nonlinearity, are faster than those shown in other figures (e.g. <xref ref-type="fig" rid="F2">Fig. 2</xref>), using a ReLu nonlinearity (but the same time constant; <xref ref-type="sec" rid="S15">Methods 1.2</xref>, and <xref ref-type="table" rid="T1">Table 1</xref>). <bold>e</bold>, Overlap (mean±1 s.d. across 10 networks) of the 2 locally most persistent (green), most amplifying (red), or random directions (black), obtained using a local linearization around the origin, with the ‘persistent subspace’ and ‘persistent nullspace’ of the original nonlinear dynamics, obtained without linearization, and the subspace spanned by the ‘optimal’ initial conditions of the original nonlinear dynamics (cf. <xref ref-type="fig" rid="F13">Extended Data Fig. 7a</xref>, bottom; see <xref ref-type="sec" rid="S23">Methods 1.4.2</xref> and <xref ref-type="sec" rid="S34">1.7.3</xref>). We used 2-dimensional subspaces from the local linearization because we found empirically that the ring attractor lay in a 2-dimensional subspace (see also <bold>a</bold>).</p></caption><graphic xlink:href="EMS156517-f009"/></fig><fig id="F10" position="anchor"><label>Extended Data Fig. 4</label><caption><title>Analysis of the total energy produced by different initial conditions in linear networks.</title><p id="P138"><bold>a</bold>, The norm of neural activity integrated over time (i.e. a measure of total energy used by the network) for each of 1000 random initial conditions (10 initial conditions for each of 100, 100-neuron networks) relative to the energy produced by the most amplifying initial condition, plotted as a function of their overlap with the persistent mode for symmetric (top) and unconstrained (bottom) linear integrator networks. A positive value on the y-axis means that the total energy produced by the given random initial condition is greater than that produced by the most amplifying initial condition. Initial conditions are scaled so that they all produce the same level of persistent activity (i.e. the same level of performance) after 2 s of simulation. <bold>b</bold>, Same as <bold>a</bold>, but initial conditions are plotted as a function of their overlap with the most amplifying mode. Note that overlap with the most amplifying mode (but not in general with the most persistent mode) is strongly predictive of total energy (with an inverse relationship between the two). <bold>c</bold>, Overlap (mean ± 1 s.d. across the 100 networks from <bold>a</bold> and <bold>b</bold>) of optimal initial conditions (Eq. S40), producing an overlap of 1 with the persistent mode after a given delay length (x-axis) while using the minimal total energy over time (Eq. S39), with either persistent (green), most amplifying (red), or random (black) directions, for symmetric (top) and unconstrained (bottom) networks. In unconstrained networks, for very short delay lengths, initial conditions must align exactly with the persistent mode, by necessity (green lines at 0 s). For longer delay lengths, initial conditions make greater use of the most amplifying direction (red lines). <bold>d</bold>, Total energy (mean across the 100 networks from <bold>a</bold> and <bold>b</bold>; we do not show error bars for visual clarity) for dynamics starting from initial conditions that produce an overlap of 1 with the persistent mode after a given delay length (x-axis) in symmetric (top) and unconstrained (bottom) networks. Initial conditions were chosen to be optimal (blue; i.e. using the least energy, cf. panel c), or aligned with the most persistent (green), most amplifying (red), or a random direction (black). In unconstrained networks, for very short delay lengths, initialising along the most persistent mode achieves near-optimal energy-efficiency (green is close to blue), but for longer delay lengths, initialising along the most amplifying mode becomes more energy efficient (red is closer to blue). (Note that for symmetric networks, top, we have offset the curves for the most amplifying, persistent, and optimal directions because these 3 directions are the same and therefore produce the same total energy.)</p></caption><graphic xlink:href="EMS156517-f010"/></fig><fig id="F11" position="anchor"><label>Extended Data Fig. 5</label><caption><title>Analysis of linear networks of different sizes.</title><p id="P139"><bold>a</bold>, Distributions of absolute overlap with the persistent mode for persistent (pale green), most amplifying (pale red), or random initial conditions (gray) across 100 randomly sampled linear symmetric (top) and unconstrained networks (bottom) consisting of either 10 (solid), 100 (dashed), or 1000 (dotted) neurons (cf. <xref ref-type="fig" rid="F3">Fig. 3d</xref>). The persistent initial conditions produced delta functions at 1 (arrows). Results for persistent and most amplifying initial conditions are identical in symmetric networks (top). <bold>b</bold>, Time course of mean (across the 100 networks from <bold>a</bold>) absolute overlap with the persistent mode when starting network dynamics from persistent (green), most amplifying (red), or random initial conditions (black) in symmetric (top) and unconstrained networks (bottom) consisting of either 10 (solid), 100 (dashed), or 1000 (dotted) neurons (cf. <xref ref-type="fig" rid="F3">Fig. 3e</xref>). Results for persistent and most amplifying initial conditions are identical in symmetric networks (top). <bold>c</bold>, Mean (across 100 networks) overlap of initial conditions that were optimized so as to generate maximal persistent activity in 100-neuron noisy symmetric (top) and unconstrained (bottom) networks with 100 orthogonal modes ordered by their persistence (green) or amplification (red) (i.e. corresponding to the rank ordered eigenvectors of the weight matrix, green, or of the observability Gramian of the dynamics, red; <xref ref-type="sec" rid="S32">Methods 1.7.1</xref>). In symmetric networks (top), the optimized initial conditions overlap only with the most amplifying mode and no other mode (note that the most persistent mode is identical to the most amplifying mode in this case). In unconstrained networks (bottom), optimized initial conditions overlap strongly with the most amplifying mode and only weakly with other modes. (The non-zero overlap with the most persistent mode is simply due to the fact that there is a non-zero overlap between the most persistent and amplifying mode in random networks, and it is at the level that would be expected based on this overlap.) <bold>d</bold>, Time course of mean (across 100 networks) absolute overlap with the persistent mode for the same 100-neuron noisy symmetric (top) and unconstrained networks (bottom) as those shown in <bold>c</bold> when the network is started from optimized initial conditions (blue), and for comparison for the most amplifying (red dashed) initial conditions (cf. <xref ref-type="fig" rid="F3">Fig. 3e</xref>). Note the close agreement between the two indicating that the most amplifying mode is indeed optimal in these networks. Horizontal black bar on x-axis shows the time period in which we applied the cost function to optimize the initial conditions (<xref ref-type="sec" rid="S34">Methods 1.7.3</xref>).</p></caption><graphic xlink:href="EMS156517-f011"/></fig><fig id="F12" position="anchor"><label>Extended Data Fig. 6</label><caption><title>Analysis of canonical nonlinear attractor systems.</title><p id="P140"><bold>a</bold>, State space of a canonical nonlinear system with two attractors and a symmetric (top) and non-symmetric Jacobian (bottom, see also <xref ref-type="sec" rid="S30">Methods 1.6</xref>, <xref ref-type="supplementary-material" rid="SD1">Supplementary Information S3</xref>; cf. <xref ref-type="fig" rid="F3">Fig. 3b</xref>). Pale blue arrows show flow field dynamics (direction and magnitude of movement in the state space as a function of the momentary state). Black crosses indicate asymptotically stable fixed points (i.e. attractor states), dashed black line shows the separatrix (the manifold separating the basins of attraction of the two attractors). Thin green and red lines indicate the locally most persistent and amplifying modes around the origin, respectively (lines are offset slightly in the top panel to aid visualisation). Pale green, red, and gray arrows with open circles at the end indicate most persistent, amplifying, and random initial conditions, respectively. Blue ellipses show the fixed initial condition norm around the origin to highlight the different axis scales. Dark green, red, and black arrows show neural dynamics starting from the corresponding initial condition. <bold>b</bold>, Time course of dynamics of the system along the persistent mode (i.e. the projection onto the green line in <bold>a</bold>) when started from the persistent (green), most amplifying (red), or random (black) initial conditions for the symmetric (top) and the unconstrained system (bottom). <bold>c</bold>, Late overlap with the locally persistent mode as a function of initial overlap with the locally most amplifying mode in the canonical nonlinear systems shown in panels <bold>a</bold>–<bold>b</bold> (solid gray line) and, for comparison, in the linear networks of <xref ref-type="fig" rid="F3">Fig. 3a–c</xref> (dashed gray line) for symmetric (top) and unconstrained systems (bottom). Late overlap is measured as the mean overlap of activity along the persistent mode (panel <bold>b</bold>, from <italic>t</italic> = 0.8 to <italic>t</italic> = 2 for the canonical nonlinear system; <xref ref-type="fig" rid="F3">Fig. 3c</xref>, from <italic>t</italic> = 0.8 s to <italic>t</italic> = 2 s for the linear networks). Open circles and squares indicate the random (gray), persistent (pale green), and most amplifying (pale red) initial conditions used respectively in panels <bold>a</bold> and <bold>b</bold> for the canonical nonlinear system, and in <xref ref-type="fig" rid="F3">Fig. 3b–c</xref> for the linear networks.</p></caption><graphic xlink:href="EMS156517-f012"/></fig><fig id="F13" position="anchor"><label>Extended Data Fig. 7</label><caption><title>Linear analyses of the nonlinear attractor networks of <xref ref-type="fig" rid="F2">Fig. 2</xref>.</title><p id="P141"><bold>a</bold>, Overlap (mean ± 1 s.d. across 10 networks) of the 5 locally most persistent (green), most amplifying (red), or random directions (black) of the symmetric (top) and unconstrained (bottom) networks from <xref ref-type="fig" rid="F2">Fig. 2</xref>, obtained using a local linearization around the origin, with the ‘persistent subspace’ and ‘persistent nullspace’ of the original nonlinear dynamics, obtained without linearization (as used in <xref ref-type="fig" rid="F2">Fig. 2f</xref> and <xref ref-type="fig" rid="F2">l</xref>, red and green), and the 5-dimensional subspace spanned by the 6 ‘optimal’ initial conditions of the original nonlinear dynamics (used in <xref ref-type="fig" rid="F2">Fig. 2b–e, h–k</xref>, and <xref ref-type="fig" rid="F2">f</xref> and <xref ref-type="fig" rid="F2">l</xref>, black). For comparison, we also show the overlap (mean ±1s.d. across 100 networks) of the single most persistent (pale green), most amplifying (pale red), and random (gray) direction with the optimal initial condition of the linear networks from <xref ref-type="fig" rid="F11">Extended Data Fig. 5c,d</xref> (‘optimal (lin. model)’). <bold>b</bold>, Time course of the overlap (mean ± 1 s.d. across 10 networks, s.d. not shown in bottom for visual clarity) of the linearized dynamics of symmetric (top) and unconstrained networks (bottom) with the subspace spanned by their most persistent modes when started from initial conditions that were optimized for the decoding accuracy of the nonlinear dynamics while constrained to be within the locally most persistent (green), most amplifying (red), or a random subspace (black). The linear dynamics, the persistent subspace wrt. which overlap is measured, and the subspaces within which initial conditions were constrained while being optimized, were all based on a local linearization of the nonlinear dynamics around the origin. Compare with <xref ref-type="fig" rid="F3">Fig. 3e</xref> for the analogous plots for linear networks. For reference, blue line shows overlap of the same linearized dynamics when started from the initial conditions directly optimized for the decoding accuracy of the nonlinear dynamics without subspace constraints (used in <xref ref-type="fig" rid="F2">Fig. 2b–e, h–k</xref>, and <xref ref-type="fig" rid="F2">f</xref> and <xref ref-type="fig" rid="F2">l</xref>, black). For consistency with <xref ref-type="fig" rid="F3">Fig. 3b–e</xref> (where initial conditions were constrained to have unit norm), we scaled activity by the norm of the initial condition (which was constrained to be 3 here; <xref ref-type="sec" rid="S23">Methods 1.4.2</xref>). <bold>c</bold>, Performance (mean 1 s.d. across 10 networks) of a delay-trained decoder (black bar indicates decoder training time period; <xref ref-type="sec" rid="S35">Methods 1.7.4</xref>) on neural activity in stochastic nonlinear symmetric (top) and unconstrained networks (bottom) over time. Colors indicate initial conditions as in <bold>b</bold>. (Blue line shows same data as black line in <xref ref-type="fig" rid="F2">Fig. 2f</xref> and <xref ref-type="fig" rid="F2">l</xref>). Gray dotted line shows chance level decoding. Green, red, and blue lines are vertically offset slightly in the top panel to aid visualization. Compare with <xref ref-type="fig" rid="F4">Fig. 4a</xref> (noise matched) for the analogous plots for linear networks (though with non-instantaneous inputs). <bold>d</bold>, Percent variance of responses explained (mean±1 s.d. across 10 networks) by the subspace spanned by either the 25% (i.e. 5) most persistent (green) or 25% (i.e. 5) most amplifying (red) modes as a function of time for 20-dimensional linear neural networks fitted to the neural responses generated by the symmetric (top) and unconstrained (bottom) nonlinear networks when started from the same (optimized) initial conditions analyzed in <bold>b</bold>–<bold>c</bold>: constrained to be within the locally most persistent (far left), most amplifying (center left), or a random subspace (center right), as determined by the local linearization of the dynamics, or without subspace constraints (far right). Gray lines show chance level overlap defined as the expected overlap with a randomly chosen subspace occupying 25% of the full space (i.e. 5 dimensions). Compare with <xref ref-type="fig" rid="F4">Fig. 4c</xref> for the analogous plots for linear networks (though with non-instantaneous inputs, and performance-matched levels of noise, see also <xref ref-type="supplementary-material" rid="SD1">Supplementary Information S4</xref>) and with <xref ref-type="fig" rid="F5">Fig. 5f</xref> and <xref ref-type="fig" rid="F16">Extended Data Fig. 10f,g</xref> for analogous plots of linear neural networks fitted to experimental data.</p></caption><graphic xlink:href="EMS156517-f013"/></fig><fig id="F14" position="anchor"><label>Extended Data Fig. 8</label><caption><title>Analysis of two variants of an integrator model and feedforward model.</title><p id="P142"><bold>a</bold>, Cross-temporal decoding of model neural activity (cf. <xref ref-type="fig" rid="F2">Fig. 2e,k</xref>, <xref ref-type="fig" rid="F4">Fig. 4b</xref>, and <xref ref-type="fig" rid="F5">Fig. 5c</xref>) for a linear integrator model<sup><xref ref-type="bibr" rid="R6">6</xref></sup> (cf. <xref ref-type="fig" rid="F7">Extended Data Fig. 1c</xref> and <xref ref-type="sec" rid="S25">Methods 1.5</xref>). Yellow lines indicate cue onset, offset, and go times. <bold>b</bold>, Same as <bold>a</bold> for the same model but for inputs aligned with purely random directions (as opposed to inputs aligned with both persistent and random directions as in the original formation of Ref.<sup><xref ref-type="bibr" rid="R6">6</xref></sup>). <bold>c</bold>, Same as <bold>a</bold> but for a linear feedforward network model<sup><xref ref-type="bibr" rid="R21">21</xref>,<xref ref-type="bibr" rid="R27">27</xref></sup> (cf. <xref ref-type="fig" rid="F7">Extended Data Fig. 1d</xref>). <bold>d</bold>, Percent variance of responses explained by the subspace spanned by either the 25% most persistent (green) or 25% most amplifying (red) modes as a function of time for the linear integrator model from <bold>a</bold> (cf. <xref ref-type="fig" rid="F4">Fig. 4c,b</xref>, <xref ref-type="fig" rid="F5">Fig. 5f</xref>, and <xref ref-type="fig" rid="F6">Fig. 6e</xref>). Yellow lines indicate cue onset, offset, and go times. Gray dotted line shows chance level overlap with a subspace spanned by 25 random orthogonal directions. <bold>e</bold>, Same as <bold>d</bold> for the same model but for inputs aligned with purely random directions. <bold>f</bold>, Same as <bold>d</bold> but for a linear feedforward network model<sup><xref ref-type="bibr" rid="R21">21</xref>,<xref ref-type="bibr" rid="R27">27</xref></sup>.</p></caption><graphic xlink:href="EMS156517-f014"/></fig><fig id="F15" position="anchor"><label>Extended Data Fig. 9</label><caption><title>Recording locations for the two monkeys.</title><p id="P143">Left: recording locations in monkey K (T1-weighted image). In order to image the interior of the chamber, we filled the chamber with cut cottons soaked in iodine. In the upper picture, the yellow arrow indicates the principal sulcus. In the bottom picture, locations of the 11 by 15 grid holes were superimposed over the MR picture. Right: recording locations in monkey T (T2-weighted image). The bottom picture shows the location for the grid of the 32 semi-chronic electrodes. Yellow dots indicate electrode penetrations and recording sites, red dots indicate non-visited sites.</p></caption><graphic xlink:href="EMS156517-f015"/></fig><fig id="F16" position="anchor"><label>Extended Data Fig. 10</label><caption><title>Supplemental analysis of experimental data and comparison to models.</title><p id="P144"><bold>a</bold>, Cross-temporal decoding analysis for monkey K (cf. <xref ref-type="fig" rid="F5">Fig. 5c</xref> for the same analysis for monkey T and for explanation of plotting scheme and annotations). <bold>b</bold>, Subspace overlap between different task epochs, measured as the percent variance explained (PVE) by projecting neural activity from one task epoch (tested) through the top 10 PCs of another task epoch (fitted). Diagonal elements show the PVE within each task epoch. We show results for monkey K (left) and monkey T (right). <bold>c</bold>, Time course of overlap with delay epoch subspace, measured as the percent variance explained by the top 2 PCs obtained from delay period activity (black bar shows time period of activity from which these PCs were obtained) on held-out test data taken in different time bins. This metric is called the alignment index<sup><xref ref-type="bibr" rid="R64">64</xref></sup> and is very similar to that used in Ref. 6 (<xref ref-type="sec" rid="S34">Methods 1.7.3</xref>). We show mean (over 10 different data splits) results for both monkeys. Yellow ticks on horizontal axis indicate cue onset, cue offset, and go times. <bold>d</bold>, Schematic of 3 different hypothetical scenarios for the relationship between cue and late delay activities (panels), illustrated in neural dynamics for 2 neurons and 2 cue conditions. Colored traces show neural trajectories, black squares indicate cue onset, open circles indicate cue offset, and filled circles show late delay activity. Left vs. right: populations encoding the cue during cue and late delay periods are overlapping vs. non-overlapping, respectively. Top vs. bottom: cue and delay activities are non-orthogonal vs. orthogonal, respectively. (Note that we are not showing dynamics for non-overlapping, non-orthogonal dynamics because no overlap necessarily implies orthogonality.) <bold>e</bold>, Relationship between cue and late delay activities in various different models and our experimental recordings (x-axis). Top: population overlap measured as the mean difference between cue and delay epoch decoder weights (left for each model and data) and, as a control, when randomly shuffling decoder weights across neurons (right for each model and data) (<xref ref-type="sec" rid="S37">Methods 1.7.6</xref>). Box plots show medians (black lines), quartiles (boxes), and 1.5 times the inter-quartile range (whiskers). Dotted gray line shows chance level overlap. Bottom: orthogonality measured as 1 minus the mean overlap between cue and delay epochs (given by the corresponding elements of the subspace overlap matrices shown in panel <bold>b</bold> and <xref ref-type="fig" rid="F17">Extended Data Fig. 11c</xref>, center right). The discrete attractors, bump attractor, and integrator models show high overlap but low orthogonality. The simple feedforward network shows high orthogonality but low overlap (note that recurrent networks with embedded feed-forward connectivity<sup><xref ref-type="bibr" rid="R21">21</xref></sup> may show high overlap). The just-in-time network shows high overlap and orthogonality, similar to the experimental data in both monkeys. <bold>f–g</bold>, Same analysis as in <xref ref-type="fig" rid="F5">Fig. 5f</xref>, but either after randomly shuffling data across time (but consistently across conditions and neurons, and applied to the same time period as in the main analysis; <bold>f</bold>, see also <xref ref-type="sec" rid="S24">Methods 1.4.3</xref>), or applied to the late delay time period (without across-time shuffling) in which we do not expect information loading dynamics (<bold>g</bold>). <bold>h</bold>, Decoding of stimulus information within the subspace spanned by either the 25% most persistent modes (green), or the 25% most amplifying modes (red) in the linear neural networks shown in <xref ref-type="fig" rid="F5">Fig. 5f</xref> relative to decoding accuracy using the full space. Comparisons use two-sided permutation tests (*, <italic>p &lt;</italic> 0.05; **, <italic>p &lt;</italic> 0.01; n.s., not significant; see <xref ref-type="sec" rid="S40">Methods 1.8</xref>) <bold>i</bold>, Top inset: original data analysis of overlaps repeated from <xref ref-type="fig" rid="F5">Fig. 5f</xref> to indicate the comparisons (colored numbers) we show in the table below (numbered columns). Bottom: table showing p-values (in each cell for experimental data, top: monkey K, bottom: monkey T) from two-sided permutation tests for each comparison of the main analysis (row 4, repeated from the main text associated with <xref ref-type="fig" rid="F5">Fig. 5f</xref>) and the control analyses shown in panels <bold>f</bold> and <bold>g</bold> of this figure (rows 5–6). Top 3 rows show predictions for the sign of each comparison under different information loading strategies in unconstrained linear networks (<xref ref-type="fig" rid="F4">Fig. 4c</xref>): using inputs aligned with random directions (1st row), persistent directions (2nd row), or the most amplifying directions (3rd row). In the column headings, pers., amp., and ch. respectively refer to overlap with most persistent, most amplifying and random subspaces (chance), <italic>t</italic><sub>0</sub> refers to the beginning of the analysis time window, i.e. cue onset (rows 1–5) or 1 s before the timing of the go cue (row 6), and <italic>t</italic><sub>1</sub> = <italic>t</italic><sub>0</sub> + 1 s refers to the end of the analysis time window. The colored numbers above each column correspond to the comparisons shown in the inset above the table. Gray indicates no significant difference between data points, red and blue indicate a significant difference for both monkeys where the first data point is respectively greater or smaller than the second data point, and pale red indicates a significant difference for one of the two monkeys (see <xref ref-type="sec" rid="S40">Methods 1.8</xref>).</p></caption><graphic xlink:href="EMS156517-f016"/></fig><fig id="F17" position="anchor"><label>Extended Data Fig. 11</label><caption><title>Cue-delay and just-in-time trained networks.</title><p id="P145"><bold>a–b</bold>, Same as <xref ref-type="fig" rid="F6">Fig. 6c</xref> green and red, and <xref ref-type="fig" rid="F6">Fig. 6d</xref> left and right, but with a regularisation strength of <inline-formula><mml:math id="M76"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mtext>nonlin</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.0005</mml:mn></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> used during training (<xref ref-type="sec" rid="S18">Methods 1.3.2</xref>). <bold>c</bold>, Subspace overlap between different task epochs, measured as the percent variance explained (PVE) by projecting neural activity from one task epoch (tested) through the top 4 PCs of another task epoch (fitted; cf. <xref ref-type="fig" rid="F18">Extended Data Fig. 12d</xref>, <xref ref-type="fig" rid="F19">Extended Data Fig. 13d</xref>, and <xref ref-type="fig" rid="F16">Extended Data Fig. 10b</xref>). Diagonal elements show the PVE within each task epoch. We show results for cue-delay (left two panels) and just-in-time trained networks (right two panels) trained with either a regularisation strength of <inline-formula><mml:math id="M77"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mtext>nonlin</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.00005</mml:mn></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> (left panel for each model, as in <xref ref-type="fig" rid="F6">Fig. 6</xref>) or <inline-formula><mml:math id="M78"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mtext>nonlin</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.0005</mml:mn></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> (right panel for each model, as in panels <bold>a</bold>–<bold>b</bold>). <bold>d</bold>, Neural activity plotted in the top two PCs of delay-epoch activity for all 6 initial conditions for cue-delay and just-in-time trained networks for each of the network-regularization combinations shown in <bold>c</bold> (cf. <xref ref-type="fig" rid="F8">Extended Data Fig. 2b–d</xref> and <xref ref-type="fig" rid="F8">f–h</xref>.) Purple traces show state-space trajectories, squares indicate cue onset, open circles indicate cue offset, and crosses indicate asymptotically stable fixed points, colors indicate cue condition as in <xref ref-type="fig" rid="F5">Fig. 5e</xref>.</p></caption><graphic xlink:href="EMS156517-f017"/></fig><fig id="F18" position="anchor"><label>Extended Data Fig. 12</label><caption><title>After-go-time trained networks.</title><p id="P146"><bold>a</bold>, Cost function for after-go-time training on the fixed delay task (<xref ref-type="sec" rid="S19">Methods 1.3.3</xref>). Cue onset, cue offset, and go cue times are indicated by the yellow vertical lines. The boxcar shows the interval over which stable decoding performance was required (i.e. the cost was only applied after the go cue). <bold>b–c</bold>, Same as <xref ref-type="fig" rid="F6">Fig. 6c</xref> orange and <xref ref-type="fig" rid="F6">Fig. 6d</xref> center, but with a regularisation strength of <inline-formula><mml:math id="M79"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mtext>nonlin</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.0005</mml:mn></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> used during training and when either a random (<bold>b</bold> orange, <bold>c</bold> left) or a fixed delay task is used (<bold>b</bold> blue, <bold>c</bold> right, <xref ref-type="sec" rid="S35">Methods 1.7.4</xref>). <bold>d</bold>, Subspace overlap between different task epochs, measured as the percent variance explained (PVE) by projecting neural activity from one task epoch (tested; cf. <xref ref-type="fig" rid="F17">Extended Data Fig. 11c</xref>, <xref ref-type="fig" rid="F19">Extended Data Fig. 13d</xref>, and <xref ref-type="fig" rid="F16">Extended Data Fig. 10b</xref>) through the top 4 PCs of another task epoch (fitted) for the networks shown in <bold>b</bold>–<bold>c</bold>. Diagonal elements show the PVE within each task epoch. <bold>e</bold>, Neural activity plotted in the top two PCs of delay-epoch activity for all 6 initial conditions for random delay (left) and fixed delay (right) trained networks (cf. <xref ref-type="fig" rid="F8">Extended Data Fig. 2b–d</xref> and <xref ref-type="fig" rid="F8">f–h</xref>; and <xref ref-type="fig" rid="F17">Extended Data Fig. 11d</xref>.) Purple traces show state-space trajectories, squares indicate cue onset, open circles indicate cue offset, and colors indicate cue conditions as in <xref ref-type="fig" rid="F5">Fig. 5e</xref>. (Note that the absence of crosses indicates the absence of asymptotically stable fixed points.)</p></caption><graphic xlink:href="EMS156517-f018"/></fig><fig id="F19" position="anchor"><label>Extended Data Fig. 13</label><caption><title>Full-delay trained networks.</title><p id="P147"><bold>a</bold>, Cost function for full-delay training on the random delay task (<xref ref-type="sec" rid="S19">Methods 1.3.3</xref>). Yellow ticks indicate cue onset and offset times, the yellow bar indicates range of go times in the variable delay task. Boxcars show intervals over which stable decoding performance was required in three example trials with different delays (<xref ref-type="sec" rid="S19">Methods 1.3.3</xref>). <bold>b–c</bold>, Same as <xref ref-type="fig" rid="F6">Fig. 6c–d</xref>, but when training with the full-delay cost with a regularisation strength of <inline-formula><mml:math id="M80"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mtext>nonlin</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.00005</mml:mn></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> (<bold>b</bold> solid, <bold>c</bold> left) or <inline-formula><mml:math id="M81"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mtext>nonlin</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.0005</mml:mn></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> (<bold>b</bold> dashed, <bold>c</bold> right, <xref ref-type="sec" rid="S35">Methods 1.7.4</xref>). <bold>d</bold>, Subspace overlap between different task epochs, measured as the percent variance explained (PVE) by projecting neural activity from one task epoch (tested; cf. <xref ref-type="fig" rid="F17">Extended Data Fig. 11c</xref>, <xref ref-type="fig" rid="F18">Extended Data Fig. 12d</xref>, and <xref ref-type="fig" rid="F16">Extended Data Fig. 10b</xref>) through the top 4 PCs of another task epoch (fitted) for the networks shown in <bold>b</bold>–<bold>c</bold>. Diagonal elements show the PVE within each task epoch.</p></caption><graphic xlink:href="EMS156517-f019"/></fig></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary information</label><media xlink:href="EMS156517-supplement-Supplementary_information.pdf" mimetype="application" mime-subtype="pdf" id="d6aAdFbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S42"><title>Acknowledgements</title><p>This work was funded by the Wellcome Trust (Investigator Award in Science 212262/Z/18/Z to M.L. and Sir Henry Wellcome Postdoctoral Fellowship 215909/Z/19/Z to J.S.), the Human Frontiers Science Programme (Research Grant RGP0044/2018 to M.L.), the Biotechnology and Biological Sciences Research Council (award BB/M010732/1 to M.G.S.), the James S. McDonnell Foundation (award 220020405 to M.G.S.), the Japan Society for the Promotion of Science (JP18K03197 and JP21K03141 to K.W., 18H05380 to T.S.), and the Japan Science and Technology Agency (CREST JPMJCR186 to T.S.). For the purpose of open access, the authors have applied a CC-BY public copyright license to any author accepted manuscript version arising from this submission. We thank Flavia Mancini, John Duncan, Guillaume Hennequin, Yashar Ahmadian, and Kris Jensen for useful feedback and detailed comments on the manuscript.</p></ack><sec id="S43" sec-type="data-availability"><title>Data availability</title><p id="P148">All experimental data will be made available in the following repository upon peerreviewed publication: <ext-link ext-link-type="uri" xlink:href="https://github.com/jakepstroud">https://github.com/jakepstroud</ext-link>.</p><sec id="S44" sec-type="data-availability"><title>Code availability</title><p id="P149">All code was custom written in Python using NumPy, SciPy, Matplotlib, Scikit-learn, and Tensorflow libraries. All code will be made available in the following repository upon peer-reviewed publication: <ext-link ext-link-type="uri" xlink:href="https://github.com/jakepstroud">https://github.com/jakepstroud</ext-link>.</p></sec></sec><fn-group><fn id="FN1" fn-type="con"><p id="P150"><bold>Author Contributions</bold></p><p id="P151">J.P.S., M.L., and M.G.S. conceived the study. K.W. performed all experimental recordings, T.S. assembled the neural recording system, and K.W. and T.S. performed data pre-processing. J.P.S. and M.L. developed the theoretical framework, performed analytical derivations, and wrote the first draft of the manuscript. J.P.S. performed all numerical simulations, analysed the data, and produced the figures. J.P.S., M.L., and M.G.S. interpreted the results. All authors revised the final manuscript.</p></fn><fn id="FN2" fn-type="conflict"><p id="P152"><bold>Competing Interests statement.</bold> The authors declare no competing interests.</p></fn><fn id="FN3"><p id="P153"><bold>Reporting Summary.</bold> Further information on research design is available in the Life Sciences Reporting Summary linked to this article.</p></fn><fn id="FN4"><p id="P154"><bold>Randomization.</bold> No new experimental data was gathered for this paper. There is no group allocation in this study. Trial types were randomly determined by a computer program.</p></fn><fn id="FN5"><p id="P155"><bold>Blinding.</bold> As data collection had been performed well before our theory of optimal information loading was developed and our corresponding analyses were performed, it was effectively blind to the purposes of our study. Data analysis was not performed blind to the conditions of the experiments.</p></fn><fn id="FN6"><p id="P156"><bold>Data exclusion.</bold> As described below (<xref ref-type="sec" rid="S14">Methods 1.1.4</xref>), 1 neuron from monkey K’s dataset was removed from all analyses because it was recorded in fewer than 10 trials for at least one stimulus cue condition.</p></fn></fn-group><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Manes</surname><given-names>F</given-names></name><etal/></person-group><article-title>Decision-making processes following damage to the prefrontal cortex</article-title><source>Brain</source><year>2002</year><volume>125</volume><fpage>624</fpage><lpage>639</lpage><pub-id pub-id-type="pmid">11872618</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baddeley</surname><given-names>A</given-names></name></person-group><article-title>Working memory: Looking back and looking forward</article-title><source>Nature Reviews Neuroscience</source><year>2003</year><volume>4</volume><fpage>829</fpage><lpage>839</lpage><pub-id pub-id-type="pmid">14523382</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldman-Rakic</surname><given-names>PS</given-names></name></person-group><article-title>Cellular basis of working memory</article-title><source>Neuron</source><year>1995</year><volume>14</volume><fpage>477</fpage><lpage>485</lpage><pub-id pub-id-type="pmid">7695894</pub-id></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Funahashi</surname><given-names>S</given-names></name><name><surname>Bruce</surname><given-names>CJ</given-names></name><name><surname>Goldman-Rakic</surname><given-names>PS</given-names></name></person-group><article-title>Mnemonic coding of visual space in the monkey’s dorsolateral prefrontal cortex</article-title><source>Journal of Neurophysiology</source><year>1989</year><volume>61</volume><fpage>331</fpage><lpage>349</lpage><pub-id pub-id-type="pmid">2918358</pub-id></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wimmer</surname><given-names>K</given-names></name><name><surname>Nykamp</surname><given-names>DQ</given-names></name><name><surname>Constantinidis</surname><given-names>C</given-names></name><name><surname>Compte</surname><given-names>A</given-names></name></person-group><article-title>Bump attractor dynamics in pre-frontal cortex explains behavioral precision in spatial working memory</article-title><source>Nature Neuroscience</source><year>2014</year><volume>17</volume><fpage>431</fpage><lpage>439</lpage><pub-id pub-id-type="pmid">24487232</pub-id></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murray</surname><given-names>JD</given-names></name><etal/></person-group><article-title>Stable population coding for working memory coexists with heterogeneous neural dynamics in prefrontal cortex</article-title><source>Proceedings of the National Academy of Sciences</source><year>2017</year><volume>114</volume><fpage>394</fpage><lpage>399</lpage><pub-id pub-id-type="pmcid">PMC5240715</pub-id><pub-id pub-id-type="pmid">28028221</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1619449114</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Compte</surname><given-names>A</given-names></name><name><surname>Brunel</surname><given-names>N</given-names></name><name><surname>Goldman-Rakic</surname><given-names>PS</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><article-title>Synaptic mechanisms and network dynamics underlying spatial working memory in a cortical network model</article-title><source>Cerebral Cortex</source><year>2000</year><volume>10</volume><fpage>910</fpage><lpage>923</lpage><pub-id pub-id-type="pmid">10982751</pub-id></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cavanagh</surname><given-names>SE</given-names></name><name><surname>Towers</surname><given-names>JP</given-names></name><name><surname>Wallis</surname><given-names>JD</given-names></name><name><surname>Hunt</surname><given-names>LT</given-names></name><name><surname>Kennerley</surname><given-names>SW</given-names></name></person-group><article-title>Reconciling persistent and dynamic hypotheses of working memory coding in prefrontal cortex</article-title><source>Nature Communications</source><year>2018</year><volume>9</volume><elocation-id>3498</elocation-id><pub-id pub-id-type="pmcid">PMC6115433</pub-id><pub-id pub-id-type="pmid">30158519</pub-id><pub-id pub-id-type="doi">10.1038/s41467-018-05873-3</pub-id></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fuster</surname><given-names>JM</given-names></name><name><surname>Alexander</surname><given-names>GE</given-names></name></person-group><article-title>Neuron activity related to short-term memory</article-title><source>Science</source><year>1971</year><volume>173</volume><fpage>652</fpage><lpage>654</lpage><pub-id pub-id-type="pmid">4998337</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spaak</surname><given-names>E</given-names></name><name><surname>Watanabe</surname><given-names>K</given-names></name><name><surname>Funahashi</surname><given-names>S</given-names></name><name><surname>Stokes</surname><given-names>MG</given-names></name></person-group><article-title>Stable and Dynamic Coding for Working Memory in Primate Prefrontal Cortex</article-title><source>The Journal of Neuroscience</source><year>2017</year><volume>37</volume><fpage>6503</fpage><lpage>6516</lpage><pub-id pub-id-type="pmcid">PMC5511881</pub-id><pub-id pub-id-type="pmid">28559375</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3364-16.2017</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stokes</surname><given-names>MG</given-names></name></person-group><article-title>‘Activity-silent’ working memory in prefrontal cortex: A dynamic coding framework</article-title><source>Trends in Cognitive Sciences</source><year>2015</year><volume>19</volume><fpage>394</fpage><lpage>405</lpage><pub-id pub-id-type="pmcid">PMC4509720</pub-id><pub-id pub-id-type="pmid">26051384</pub-id><pub-id pub-id-type="doi">10.1016/j.tics.2015.05.004</pub-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X-j</given-names></name></person-group><article-title>Synaptic reverberation underlying mnemonic persistent activity</article-title><source>Trends in Neurosciences</source><year>2001</year><volume>24</volume><fpage>455</fpage><lpage>463</lpage><pub-id pub-id-type="pmid">11476885</pub-id></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>GR</given-names></name><name><surname>Joglekar</surname><given-names>MR</given-names></name><name><surname>Song</surname><given-names>HF</given-names></name><name><surname>New-some</surname><given-names>WT</given-names></name><name><surname>Wang</surname><given-names>X-J</given-names></name></person-group><article-title>Task representations in neural networks trained to perform many cognitive tasks</article-title><source>Nature Neuroscience</source><year>2019</year><volume>22</volume><fpage>297</fpage><lpage>306</lpage><pub-id pub-id-type="pmid">30643294</pub-id></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyers</surname><given-names>EM</given-names></name><name><surname>Freedman</surname><given-names>DJ</given-names></name><name><surname>Kreiman</surname><given-names>G</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Poggio</surname><given-names>T</given-names></name></person-group><article-title>Dynamic population coding of category information in inferior temporal and prefrontal cortex</article-title><source>Journal of Neurophysiology</source><year>2008</year><volume>100</volume><fpage>1407</fpage><lpage>1419</lpage><pub-id pub-id-type="pmcid">PMC2544466</pub-id><pub-id pub-id-type="pmid">18562555</pub-id><pub-id pub-id-type="doi">10.1152/jn.90248.2008</pub-id></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stokes</surname><given-names>MG</given-names></name><etal/></person-group><article-title>Dynamic coding for cognitive control in prefrontal cortex</article-title><source>Neuron</source><year>2013</year><volume>78</volume><fpage>364</fpage><lpage>375</lpage><pub-id pub-id-type="pmcid">PMC3898895</pub-id><pub-id pub-id-type="pmid">23562541</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2013.01.039</pub-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyers</surname><given-names>EM</given-names></name></person-group><article-title>Dynamic population coding and its relationship to working memory</article-title><source>Journal of Neurophysiology</source><year>2018</year><volume>120</volume><fpage>2260</fpage><lpage>2268</lpage><pub-id pub-id-type="pmid">30207866</pub-id></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mante</surname><given-names>V</given-names></name><name><surname>Sussillo</surname><given-names>D</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><article-title>Context-dependent computation by recurrent dynamics in prefrontal cortex</article-title><source>Nature</source><year>2013</year><volume>503</volume><fpage>78</fpage><lpage>84</lpage><pub-id pub-id-type="pmcid">PMC4121670</pub-id><pub-id pub-id-type="pmid">24201281</pub-id><pub-id pub-id-type="doi">10.1038/nature12742</pub-id></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sreenivasan</surname><given-names>KK</given-names></name><name><surname>Curtis</surname><given-names>CE</given-names></name><name><surname>D’Esposito</surname><given-names>M</given-names></name></person-group><article-title>Revisiting the role of persistent neural activity during working memory</article-title><source>Trends in Cognitive Sciences</source><year>2014</year><volume>18</volume><fpage>82</fpage><lpage>89</lpage><pub-id pub-id-type="pmcid">PMC3964018</pub-id><pub-id pub-id-type="pmid">24439529</pub-id><pub-id pub-id-type="doi">10.1016/j.tics.2013.12.001</pub-id></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scott</surname><given-names>BB</given-names></name><etal/></person-group><article-title>Fronto-parietal Cortical Circuits Encode Accumulated Evidence with a Diversity of Timescales</article-title><source>Neuron</source><year>2017</year><volume>95</volume><fpage>385</fpage><lpage>398</lpage><pub-id pub-id-type="pmcid">PMC9453285</pub-id><pub-id pub-id-type="pmid">28669543</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.013</pub-id></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cueva</surname><given-names>CJ</given-names></name><etal/></person-group><article-title>Low-dimensional dynamics for working memory and time encoding</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><year>2020</year><volume>117</volume><fpage>23021</fpage><lpage>23032</lpage><pub-id pub-id-type="pmcid">PMC7502752</pub-id><pub-id pub-id-type="pmid">32859756</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1915984117</pub-id></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldman</surname><given-names>MS</given-names></name></person-group><article-title>Memory without Feedback in a Neural Network</article-title><source>Neuron</source><year>2009</year><volume>61</volume><fpage>621</fpage><lpage>634</lpage><pub-id pub-id-type="pmcid">PMC2674525</pub-id><pub-id pub-id-type="pmid">19249281</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2008.12.012</pub-id></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Machens</surname><given-names>CK</given-names></name><name><surname>Romo</surname><given-names>R</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name></person-group><article-title>Functional, but not anatomical, separation of “what” and “when” in prefrontal cortex</article-title><source>Journal of Neuro-science</source><year>2010</year><volume>30</volume><fpage>350</fpage><lpage>360</lpage><pub-id pub-id-type="pmcid">PMC2947945</pub-id><pub-id pub-id-type="pmid">20053916</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3276-09.2010</pub-id></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barak</surname><given-names>O</given-names></name><name><surname>Tsodyks</surname><given-names>M</given-names></name><name><surname>Romo</surname><given-names>R</given-names></name></person-group><article-title>Neuronal population coding of parametric working memory</article-title><source>Journal of Neuroscience</source><year>2010</year><volume>30</volume><fpage>9424</fpage><lpage>9430</lpage><pub-id pub-id-type="pmcid">PMC6632447</pub-id><pub-id pub-id-type="pmid">20631171</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1875-10.2010</pub-id></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barak</surname><given-names>O</given-names></name><name><surname>Sussillo</surname><given-names>D</given-names></name><name><surname>Romo</surname><given-names>R</given-names></name><name><surname>Tsodyks</surname><given-names>M</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name></person-group><article-title>From fixed points to chaos: Three models of delayed discrimination</article-title><source>Progress in Neurobiology</source><year>2013</year><volume>103</volume><fpage>214</fpage><lpage>222</lpage><pub-id pub-id-type="pmcid">PMC3622800</pub-id><pub-id pub-id-type="pmid">23438479</pub-id><pub-id pub-id-type="doi">10.1016/j.pneurobio.2013.02.002</pub-id></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parthasarathy</surname><given-names>A</given-names></name><etal/></person-group><article-title>Mixed selectivity morphs population codes in prefrontal cortex</article-title><source>Nature Neu-roscience</source><year>2017</year><volume>20</volume><fpage>1770</fpage><lpage>1779</lpage><pub-id pub-id-type="pmid">29184197</pub-id></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Druckmann</surname><given-names>S</given-names></name><name><surname>Chklovskii</surname><given-names>DB</given-names></name></person-group><article-title>Neuronal circuits underlying persistent representations despite time varying activity</article-title><source>Current Biology</source><year>2012</year><volume>22</volume><fpage>2095</fpage><lpage>2103</lpage><pub-id pub-id-type="pmcid">PMC3543774</pub-id><pub-id pub-id-type="pmid">23084992</pub-id><pub-id pub-id-type="doi">10.1016/j.cub.2012.08.058</pub-id></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ganguli</surname><given-names>S</given-names></name><name><surname>Huh</surname><given-names>D</given-names></name><name><surname>Sompolinsky</surname><given-names>H</given-names></name></person-group><article-title>Memory traces in dynamical systems</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><year>2008</year><volume>105</volume><fpage>18970</fpage><lpage>18975</lpage><pub-id pub-id-type="pmcid">PMC2596211</pub-id><pub-id pub-id-type="pmid">19020074</pub-id><pub-id pub-id-type="doi">10.1073/pnas.0804451105</pub-id></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Amit</surname><given-names>DJ</given-names></name></person-group><source>Modeling brain function: The world of attractor neural networks</source><publisher-name>Cambridge University Press</publisher-name><year>1992</year></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amit</surname><given-names>DJ</given-names></name><name><surname>Brunel</surname><given-names>N</given-names></name></person-group><article-title>Model of global spontaneous activity and local structured activity during delay periods in the cerebral cortex</article-title><source>Cerebral Cortex</source><year>1997</year><volume>7</volume><fpage>237</fpage><lpage>252</lpage><pub-id pub-id-type="pmid">9143444</pub-id></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Inagaki</surname><given-names>HK</given-names></name><name><surname>Fontolan</surname><given-names>L</given-names></name><name><surname>Romani</surname><given-names>S</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name></person-group><article-title>Discrete attractor dynamics underlies persistent activity in the frontal cortex</article-title><source>Nature</source><year>2019</year><volume>566</volume><fpage>212</fpage><lpage>217</lpage><pub-id pub-id-type="pmid">30728503</pub-id></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brody</surname><given-names>CD</given-names></name><name><surname>Romo</surname><given-names>R</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name></person-group><article-title>Basic mechanisms for graded persistent activity: Discrete attractors, continuous attractors, and dynamic representations</article-title><source>Current Opinion in Neurobiology</source><year>2003</year><volume>13</volume><fpage>204</fpage><lpage>211</lpage><pub-id pub-id-type="pmid">12744975</pub-id></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Machens</surname><given-names>CK</given-names></name><name><surname>Romo</surname><given-names>R</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name></person-group><article-title>Flexible control of mutual inhibition: A neural model of two-interval discrimination</article-title><source>Science</source><year>2005</year><volume>307</volume><fpage>1121</fpage><lpage>1124</lpage><pub-id pub-id-type="pmid">15718474</pub-id></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Durstewitz</surname><given-names>D</given-names></name><name><surname>Seamans</surname><given-names>JK</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><article-title>Neurocomputational Models of Working Memory</article-title><source>Nature Neuroscience</source><year>2000</year><volume>3</volume><fpage>1184</fpage><lpage>1191</lpage><pub-id pub-id-type="pmid">11127836</pub-id></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seung</surname><given-names>HS</given-names></name></person-group><article-title>How the brain keeps the eyes still</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><year>1996</year><volume>93</volume><fpage>13339</fpage><lpage>13344</lpage><pub-id pub-id-type="pmcid">PMC24094</pub-id><pub-id pub-id-type="pmid">8917592</pub-id><pub-id pub-id-type="doi">10.1073/pnas.93.23.13339</pub-id></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cannon</surname><given-names>SC</given-names></name><name><surname>Robinson</surname><given-names>DA</given-names></name><name><surname>Shamma</surname><given-names>S</given-names></name></person-group><article-title>A proposed neural network for the integrator of the oculomotor system</article-title><source>Biological Cybernetics</source><year>1983</year><volume>49</volume><fpage>127</fpage><lpage>136</lpage><pub-id pub-id-type="pmid">6661444</pub-id></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rajan</surname><given-names>K</given-names></name><etal/></person-group><article-title>Recurrent Network Models of Sequence Generation and Memory Recurrent Network Models</article-title><source>Neuron</source><year>2016</year><volume>90</volume><fpage>128</fpage><lpage>142</lpage><pub-id pub-id-type="pmcid">PMC4824643</pub-id><pub-id pub-id-type="pmid">26971945</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2016.02.009</pub-id></element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sompolinsky</surname><given-names>H</given-names></name><name><surname>Crisanti</surname><given-names>A</given-names></name><name><surname>Sommers</surname><given-names>HJ</given-names></name></person-group><article-title>Chaos in random neural networks</article-title><source>Physical Review Letters</source><year>1988</year><volume>61</volume><fpage>259</fpage><lpage>262</lpage><pub-id pub-id-type="pmid">10039285</pub-id></element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Enel</surname><given-names>P</given-names></name><name><surname>Procyk</surname><given-names>E</given-names></name><name><surname>Quilodran</surname><given-names>R</given-names></name><name><surname>Dominey</surname><given-names>PF</given-names></name></person-group><article-title>Reservoir Computing Properties of Neural Dynamics in Prefrontal Cortex</article-title><source>PLoS Computational Biology</source><year>2016</year><volume>12</volume><fpage>1</fpage><lpage>35</lpage><pub-id pub-id-type="pmcid">PMC4902312</pub-id><pub-id pub-id-type="pmid">27286251</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004967</pub-id></element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Orhan</surname><given-names>AE</given-names></name><name><surname>Ma</surname><given-names>WJ</given-names></name></person-group><article-title>A diverse range of factors affect the nature of neural representations underlying short-term memory</article-title><source>Nature Neuroscience</source><year>2019</year><volume>22</volume><fpage>275</fpage><lpage>283</lpage><pub-id pub-id-type="pmid">30664767</pub-id></element-citation></ref><ref id="R40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>HF</given-names></name><name><surname>Yang</surname><given-names>GR</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><article-title>Training Excitatory-Inhibitory Recurrent Neural Networks for Cognitive Tasks: A Simple and Flexible Framework</article-title><source>PLoS Computational Biology</source><year>2016</year><volume>12</volume><fpage>1</fpage><lpage>30</lpage><pub-id pub-id-type="pmcid">PMC4771709</pub-id><pub-id pub-id-type="pmid">26928718</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004792</pub-id></element-citation></ref><ref id="R41"><label>41</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Masse</surname><given-names>NY</given-names></name><name><surname>Yang</surname><given-names>GR</given-names></name><name><surname>Song</surname><given-names>HF</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name><name><surname>Freedman</surname><given-names>DJ</given-names></name></person-group><article-title>Circuit mechanisms for the maintenance and manipulation of information in working memory</article-title><source>Nature Neuroscience</source><year>2019</year><volume>22</volume><fpage>1159</fpage><lpage>1167</lpage><pub-id pub-id-type="pmcid">PMC7321806</pub-id><pub-id pub-id-type="pmid">31182866</pub-id><pub-id pub-id-type="doi">10.1038/s41593-019-0414-3</pub-id></element-citation></ref><ref id="R42"><label>42</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hopfield</surname><given-names>JJ</given-names></name></person-group><article-title>Neural networks and physical systems with emergent collective computational abilities</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><year>1982</year><volume>79</volume><fpage>2554</fpage><lpage>2558</lpage><pub-id pub-id-type="pmcid">PMC346238</pub-id><pub-id pub-id-type="pmid">6953413</pub-id><pub-id pub-id-type="doi">10.1073/pnas.79.8.2554</pub-id></element-citation></ref><ref id="R43"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Machens</surname><given-names>CK</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name></person-group><article-title>Design of continuous attractor networks with monotonic tuning using a symmetry principle</article-title><source>Neural Computation</source><year>2008</year><volume>20</volume><fpage>452</fpage><lpage>485</lpage><pub-id pub-id-type="pmid">18047414</pub-id></element-citation></ref><ref id="R44"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parthasarathy</surname><given-names>A</given-names></name><etal/></person-group><article-title>Time-Invariant Working Memory Representations in the Presence of Code-Morphing in the Lateral Prefrontal Cortex</article-title><source>Nature Communications</source><year>2019</year><volume>10</volume><elocation-id>4995</elocation-id><pub-id pub-id-type="pmcid">PMC6825148</pub-id><pub-id pub-id-type="pmid">31676790</pub-id><pub-id pub-id-type="doi">10.1038/s41467-019-12841-y</pub-id></element-citation></ref><ref id="R45"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barbosa</surname><given-names>J</given-names></name><etal/></person-group><article-title>Interplay between persistent activity and activity-silent dynamics in the prefrontal cortex underlies serial biases in working memory</article-title><source>Nature Neuroscience</source><year>2020</year><volume>23</volume><fpage>16</fpage><lpage>18</lpage><pub-id pub-id-type="pmcid">PMC7392810</pub-id><pub-id pub-id-type="pmid">32572236</pub-id><pub-id pub-id-type="doi">10.1038/s41593-020-0644-4</pub-id></element-citation></ref><ref id="R46"><label>46</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Abbott</surname><given-names>L</given-names></name></person-group><source>Theoretical Neuroscience: Computational and Mathematical Modeling of Neural Systems</source><publisher-name>MIT Press</publisher-name><year>2001</year></element-citation></ref><ref id="R47"><label>47</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sigala</surname><given-names>N</given-names></name><name><surname>Kusunoki</surname><given-names>M</given-names></name><name><surname>Nimmo-Smith</surname><given-names>I</given-names></name><name><surname>Gaffan</surname><given-names>D</given-names></name><name><surname>Duncan</surname><given-names>J</given-names></name></person-group><article-title>Hierarchical coding for sequential task events in the monkey prefrontal cortex</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><year>2008</year><volume>105</volume><fpage>11969</fpage><lpage>11974</lpage><pub-id pub-id-type="pmcid">PMC2504480</pub-id><pub-id pub-id-type="pmid">18689686</pub-id><pub-id pub-id-type="doi">10.1073/pnas.0802569105</pub-id></element-citation></ref><ref id="R48"><label>48</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wasmuht</surname><given-names>DF</given-names></name></person-group><source>Dynamics and dimensionality of information representation for higher cognitive function</source><publisher-name>Ph.D. thesis</publisher-name><year>2019</year></element-citation></ref><ref id="R49"><label>49</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Libby</surname><given-names>A</given-names></name><name><surname>Buschman</surname><given-names>TJ</given-names></name></person-group><article-title>Rotational dynamics reduce interference between sensory and memory representations</article-title><source>Nature Neuroscience</source><year>2021</year><volume>24</volume><fpage>715</fpage><lpage>727</lpage><pub-id pub-id-type="pmcid">PMC8102338</pub-id><pub-id pub-id-type="pmid">33821001</pub-id><pub-id pub-id-type="doi">10.1038/s41593-021-00821-9</pub-id></element-citation></ref><ref id="R50"><label>50</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>BK</given-names></name><name><surname>Miller</surname><given-names>KD</given-names></name></person-group><article-title>Balanced Amplification: A New Mechanism of Selective Amplification of Neural Activity Patterns</article-title><source>Neuron</source><year>2009</year><volume>61</volume><fpage>635</fpage><lpage>648</lpage><pub-id pub-id-type="pmcid">PMC2667957</pub-id><pub-id pub-id-type="pmid">19249282</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2009.02.005</pub-id></element-citation></ref><ref id="R51"><label>51</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wong</surname><given-names>KF</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><article-title>A recurrent network mechanism of time integration in perceptual decisions</article-title><source>Journal of Neuroscience</source><year>2006</year><volume>26</volume><fpage>1314</fpage><lpage>1328</lpage><pub-id pub-id-type="pmcid">PMC6674568</pub-id><pub-id pub-id-type="pmid">16436619</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3733-05.2006</pub-id></element-citation></ref><ref id="R52"><label>52</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ganguli</surname><given-names>S</given-names></name><etal/></person-group><article-title>One-Dimensional Dynamics of Attention and Decision Making in LIP</article-title><source>Neuron</source><year>2008</year><volume>58</volume><fpage>15</fpage><lpage>25</lpage><pub-id pub-id-type="pmcid">PMC7204626</pub-id><pub-id pub-id-type="pmid">18400159</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2008.01.038</pub-id></element-citation></ref><ref id="R53"><label>53</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hennequin</surname><given-names>G</given-names></name><name><surname>Vogels</surname><given-names>TP</given-names></name><name><surname>Gerstner</surname><given-names>W</given-names></name></person-group><article-title>Optimal control of transient dynamics in balanced networks supports generation of complex movements</article-title><source>Neuron</source><year>2014</year><volume>82</volume><fpage>1394</fpage><lpage>1406</lpage><pub-id pub-id-type="pmcid">PMC6364799</pub-id><pub-id pub-id-type="pmid">24945778</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2014.04.045</pub-id></element-citation></ref><ref id="R54"><label>54</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kao</surname><given-names>TC</given-names></name><name><surname>Hennequin</surname><given-names>G</given-names></name></person-group><article-title>Neuroscience out of control: control-theoretic perspectives on neural circuit dynamics</article-title><source>Current Opinion in Neurobiology</source><year>2019</year><volume>58</volume><fpage>122</fpage><lpage>129</lpage><pub-id pub-id-type="pmid">31563084</pub-id></element-citation></ref><ref id="R55"><label>55</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stroud</surname><given-names>JP</given-names></name><name><surname>Porter</surname><given-names>MA</given-names></name><name><surname>Hennequin</surname><given-names>G</given-names></name><name><surname>Vogels</surname><given-names>TP</given-names></name></person-group><article-title>Motor primitives in space and time via targeted gain modulation in cortical networks</article-title><source>Nature Neuroscience</source><year>2018</year><volume>21</volume><fpage>1774</fpage><lpage>1783</lpage><pub-id pub-id-type="pmcid">PMC6276991</pub-id><pub-id pub-id-type="pmid">30482949</pub-id><pub-id pub-id-type="doi">10.1038/s41593-018-0276-0</pub-id></element-citation></ref><ref id="R56"><label>56</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christodoulou</surname><given-names>G</given-names></name><name><surname>Vogels</surname><given-names>TP</given-names></name><name><surname>Agnes</surname><given-names>EJ</given-names></name></person-group><article-title>Regimes and mechanisms of transient amplification in abstract and biological neural networks</article-title><source>PLoS Computational Biology</source><year>2022</year><volume>18</volume><fpage>1</fpage><lpage>32</lpage><pub-id pub-id-type="pmcid">PMC9377633</pub-id><pub-id pub-id-type="pmid">35969604</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1010365</pub-id></element-citation></ref><ref id="R57"><label>57</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bondanelli</surname><given-names>G</given-names></name><name><surname>Ostojic</surname><given-names>S</given-names></name></person-group><article-title>Coding with transient trajectories in recurrent neural networks</article-title><source>PLoS Computational Biology</source><year>2020</year><volume>16</volume><elocation-id>1007655</elocation-id><pub-id pub-id-type="pmcid">PMC7043794</pub-id><pub-id pub-id-type="pmid">32053594</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007655</pub-id></element-citation></ref><ref id="R58"><label>58</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Trefethen</surname><given-names>LN</given-names></name></person-group><source>Spectra and Pseudospectra</source><publisher-name>Princeton University Press</publisher-name><year>1999</year></element-citation></ref><ref id="R59"><label>59</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chadwick</surname><given-names>A</given-names></name><etal/></person-group><article-title>Learning Shapes Cortical Dynamics to Enhance Integration of Relevant Sensory Input</article-title><source>bioRxiv</source><year>2021</year><elocation-id>454726</elocation-id><pub-id pub-id-type="pmid">36283408</pub-id></element-citation></ref><ref id="R60"><label>60</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hennequin</surname><given-names>G</given-names></name><name><surname>Vogels</surname><given-names>TP</given-names></name><name><surname>Gerstner</surname><given-names>W</given-names></name></person-group><article-title>Nonnormal amplification in random balanced neuronal networks</article-title><source>Physical Review E - Statistical, Nonlinear, and Soft Matter Physics</source><year>2012</year><volume>86</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="pmid">23005454</pub-id></element-citation></ref><ref id="R61"><label>61</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><article-title>An integrative theory of prefrontal cortex function</article-title><source>Annual Review of Neuroscience</source><year>2001</year><volume>24</volume><fpage>167</fpage><lpage>202</lpage><pub-id pub-id-type="pmid">11283309</pub-id></element-citation></ref><ref id="R62"><label>62</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kao</surname><given-names>TC</given-names></name><name><surname>Sadabadi</surname><given-names>MS</given-names></name><name><surname>Hennequin</surname><given-names>G</given-names></name></person-group><article-title>Optimal anticipatory control as a theory of motor preparation: A thalamo-cortical circuit model</article-title><source>Neuron</source><year>2021</year><volume>109</volume><fpage>1567</fpage><lpage>1581</lpage><pub-id pub-id-type="pmcid">PMC8111422</pub-id><pub-id pub-id-type="pmid">33789082</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2021.03.009</pub-id></element-citation></ref><ref id="R63"><label>63</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maass</surname><given-names>W</given-names></name><name><surname>Natschläger</surname><given-names>T</given-names></name><name><surname>Markram</surname><given-names>H</given-names></name></person-group><article-title>Real-time computing without stable states: A new framework for neural computation based on perturbations</article-title><source>Neural Computation</source><year>2002</year><volume>14</volume><fpage>2531</fpage><lpage>2560</lpage><pub-id pub-id-type="pmid">12433288</pub-id></element-citation></ref><ref id="R64"><label>64</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elsayed</surname><given-names>GF</given-names></name><name><surname>Lara</surname><given-names>AH</given-names></name><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Cunningham</surname><given-names>JP</given-names></name></person-group><article-title>Reorganization between preparatory and movement population responses in motor cortex</article-title><source>Nature Communications</source><year>2016</year><volume>7</volume><elocation-id>13239</elocation-id><pub-id pub-id-type="pmcid">PMC5095296</pub-id><pub-id pub-id-type="pmid">27807345</pub-id><pub-id pub-id-type="doi">10.1038/ncomms13239</pub-id></element-citation></ref><ref id="R65"><label>65</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sussillo</surname><given-names>D</given-names></name><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><article-title>A neural network that finds a naturalistic solution for the production of muscle activity</article-title><source>Nature Neuroscience</source><year>2015</year><volume>18</volume><fpage>1025</fpage><lpage>1033</lpage><pub-id pub-id-type="pmcid">PMC5113297</pub-id><pub-id pub-id-type="pmid">26075643</pub-id><pub-id pub-id-type="doi">10.1038/nn.4042</pub-id></element-citation></ref><ref id="R66"><label>66</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rolls</surname><given-names>ET</given-names></name></person-group><article-title>An attractor network in the hippocampus: Theory and neurophysiology</article-title><source>Learning and Memory</source><year>2007</year><volume>14</volume><fpage>714</fpage><lpage>731</lpage><pub-id pub-id-type="pmid">18007016</pub-id></element-citation></ref><ref id="R67"><label>67</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burak</surname><given-names>Y</given-names></name><name><surname>Fiete</surname><given-names>IR</given-names></name></person-group><article-title>Accurate path integration in continuous attractor network models of grid cells</article-title><source>PLoS Computational Biology</source><year>2009</year><volume>5</volume><elocation-id>e1000291</elocation-id><pub-id pub-id-type="pmcid">PMC2632741</pub-id><pub-id pub-id-type="pmid">19229307</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000291</pub-id></element-citation></ref><ref id="R68"><label>68</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>SS</given-names></name><name><surname>Rouault</surname><given-names>H</given-names></name><name><surname>Druckmann</surname><given-names>S</given-names></name><name><surname>Jayaraman</surname><given-names>V</given-names></name></person-group><article-title>Ring attractor dynamics in the Drosophila central brain</article-title><source>Science</source><year>2017</year><volume>356</volume><fpage>849</fpage><lpage>853</lpage><pub-id pub-id-type="pmid">28473639</pub-id></element-citation></ref><ref id="R69"><label>69</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brunel</surname><given-names>N</given-names></name></person-group><article-title>Dynamics and Plasticity of Stimulus-selective Persistent Activity in Cortical Network Models</article-title><source>Cerebral Cortex</source><year>2003</year><volume>13</volume><fpage>1151</fpage><lpage>1161</lpage><pub-id pub-id-type="pmid">14576207</pub-id></element-citation></ref><ref id="R70"><label>70</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burak</surname><given-names>Y</given-names></name><name><surname>Fiete</surname><given-names>IR</given-names></name></person-group><article-title>Fundamental limits on persistent activity in networks of noisy neurons</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><year>2012</year><volume>109</volume><fpage>17645</fpage><lpage>17650</lpage><pub-id pub-id-type="pmcid">PMC3491496</pub-id><pub-id pub-id-type="pmid">23047704</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1117386109</pub-id></element-citation></ref><ref id="R71"><label>71</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Renart</surname><given-names>A</given-names></name><name><surname>Song</surname><given-names>P</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><article-title>Robust spatial working memory through homeostatic synaptic scaling in heterogeneous cortical networks</article-title><source>Neuron</source><year>2003</year><volume>38</volume><fpage>473</fpage><lpage>485</lpage><pub-id pub-id-type="pmid">12741993</pub-id></element-citation></ref><ref id="R72"><label>72</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lundqvist</surname><given-names>M</given-names></name><name><surname>Herman</surname><given-names>P</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name></person-group><article-title>Working Memory: Delay Activity, Yes! Persistent Activity? Maybe Not</article-title><source>The Journal of Neuroscience</source><year>2018</year><volume>38</volume><fpage>7013</fpage><lpage>7019</lpage><pub-id pub-id-type="pmcid">PMC6083456</pub-id><pub-id pub-id-type="pmid">30089640</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2485-17.2018</pub-id></element-citation></ref><ref id="R73"><label>73</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brody</surname><given-names>CD</given-names></name><name><surname>Hernández</surname><given-names>A</given-names></name><name><surname>Zainos</surname><given-names>A</given-names></name><name><surname>Romo</surname><given-names>R</given-names></name></person-group><article-title>Timing and Neural Encoding of Somatosensory Parametric Working Memory in Macaque Prefrontal Cortex</article-title><source>Cerebral Cortex</source><year>2003</year><volume>13</volume><fpage>1196</fpage><lpage>1207</lpage><pub-id pub-id-type="pmid">14576211</pub-id></element-citation></ref><ref id="R74"><label>74</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>K</given-names></name></person-group><article-title>Representation of spatial orientation by the intrinsic dynamics of the head-direction cell ensemble: A theory</article-title><source>Journal of Neuroscience</source><year>1996</year><volume>16</volume><fpage>2112</fpage><lpage>2126</lpage><pub-id pub-id-type="pmcid">PMC6578512</pub-id><pub-id pub-id-type="pmid">8604055</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.16-06-02112.1996</pub-id></element-citation></ref><ref id="R75"><label>75</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Cunningham</surname><given-names>JP</given-names></name><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><article-title>Cortical Preparatory Activity: Representation of Movement or First Cog in a Dynamical Machine?</article-title><source>Neuron</source><year>2010</year><volume>68</volume><fpage>387</fpage><lpage>400</lpage><pub-id pub-id-type="pmcid">PMC2991102</pub-id><pub-id pub-id-type="pmid">21040842</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2010.09.015</pub-id></element-citation></ref><ref id="R76"><label>76</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Galgali</surname><given-names>AR</given-names></name><name><surname>Sahani</surname><given-names>M</given-names></name><name><surname>Mante</surname><given-names>V</given-names></name></person-group><article-title>Residual dynamics resolves recurrent contributions to neural computation</article-title><source>Nature Neuroscience</source><year>2023</year><elocation-id>2021.07.19.452951</elocation-id><pub-id pub-id-type="pmid">36635498</pub-id></element-citation></ref><ref id="R77"><label>77</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mongillo</surname><given-names>G</given-names></name><name><surname>Barak</surname><given-names>O</given-names></name><name><surname>Tsodyks</surname><given-names>M</given-names></name></person-group><article-title>Synaptic Theory of Working Memory</article-title><source>Science</source><year>2008</year><volume>319</volume><fpage>1543</fpage><lpage>1546</lpage><pub-id pub-id-type="pmid">18339943</pub-id></element-citation></ref><ref id="R78"><label>78</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bouchacourt</surname><given-names>F</given-names></name><name><surname>Buschman</surname><given-names>TJ</given-names></name></person-group><article-title>A Flexible Model of Working Memory</article-title><source>Neuron</source><year>2019</year><volume>103</volume><fpage>147</fpage><lpage>160</lpage><elocation-id>e8</elocation-id><pub-id pub-id-type="pmcid">PMC6613943</pub-id><pub-id pub-id-type="pmid">31103359</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2019.04.020</pub-id></element-citation></ref><ref id="R79"><label>79</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><article-title>Cortical activity in the null space: Permitting preparation without movement</article-title><source>Nature Neuroscience</source><year>2014</year><volume>17</volume><fpage>440</fpage><lpage>448</lpage><pub-id pub-id-type="pmcid">PMC3955357</pub-id><pub-id pub-id-type="pmid">24487233</pub-id><pub-id pub-id-type="doi">10.1038/nn.3643</pub-id></element-citation></ref><ref id="R80"><label>80</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watanabe</surname><given-names>K</given-names></name><name><surname>Funahashi</surname><given-names>S</given-names></name></person-group><article-title>Neural mechanisms of dual-task interference and cognitive capacity limitation in the prefrontal cortex</article-title><source>Nature Neuroscience</source><year>2014</year><volume>17</volume><fpage>601</fpage><lpage>611</lpage><pub-id pub-id-type="pmid">24584049</pub-id></element-citation></ref><ref id="R81"><label>81</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watanabe</surname><given-names>K</given-names></name><name><surname>Funahashi</surname><given-names>S</given-names></name></person-group><article-title>A dual-task paradigm for behavioral and neurobiological studies in nonhuman primates</article-title><source>Journal of Neuroscience Methods</source><year>2015</year><volume>246</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="pmid">25769271</pub-id></element-citation></ref><ref id="R82"><label>82</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drucker</surname><given-names>CB</given-names></name><name><surname>Carlson</surname><given-names>ML</given-names></name><name><surname>Toda</surname><given-names>K</given-names></name><name><surname>DeWind</surname><given-names>NK</given-names></name><name><surname>Platt</surname><given-names>ML</given-names></name></person-group><article-title>Non-invasive primate head restraint using thermoplastic masks</article-title><source>Journal of Neuroscience Methods</source><year>2015</year><volume>253</volume><fpage>90</fpage><lpage>100</lpage><pub-id pub-id-type="pmcid">PMC4560600</pub-id><pub-id pub-id-type="pmid">26112334</pub-id><pub-id pub-id-type="doi">10.1016/j.jneumeth.2015.06.013</pub-id></element-citation></ref><ref id="R83"><label>83</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ninomiya</surname><given-names>T</given-names></name><name><surname>Dougherty</surname><given-names>K</given-names></name><name><surname>Godlove</surname><given-names>DC</given-names></name><name><surname>Schall</surname><given-names>JD</given-names></name><name><surname>Maier</surname><given-names>A</given-names></name></person-group><article-title>Microcircuitry of agranular frontal cortex: contrasting laminar connectivity between occipital and frontal areas</article-title><source>Journal of Neurophysiology</source><year>2015</year><volume>113</volume><fpage>3242</fpage><lpage>3255</lpage><pub-id pub-id-type="pmcid">PMC4440241</pub-id><pub-id pub-id-type="pmid">25744881</pub-id><pub-id pub-id-type="doi">10.1152/jn.00624.2014</pub-id></element-citation></ref><ref id="R84"><label>84</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hennequin</surname><given-names>G</given-names></name><name><surname>Ahmadian</surname><given-names>Y</given-names></name><name><surname>Rubin</surname><given-names>DB</given-names></name><name><surname>Lengyel</surname><given-names>M</given-names></name><name><surname>Miller</surname><given-names>KD</given-names></name></person-group><article-title>The Dynamical Regime of Sensory Cortex: Stable Dynamics around a Single Stimulus-Tuned Attractor Account for Patterns of Noise Variability</article-title><source>Neuron</source><year>2018</year><volume>98</volume><fpage>846</fpage><lpage>860</lpage><elocation-id>e5</elocation-id><pub-id pub-id-type="pmcid">PMC5971207</pub-id><pub-id pub-id-type="pmid">29772203</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2018.04.017</pub-id></element-citation></ref><ref id="R85"><label>85</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kingma</surname><given-names>DP</given-names></name><name><surname>Ba</surname><given-names>JL</given-names></name></person-group><article-title>Adam: A method for stochastic optimization</article-title><source>arXiv</source><year>2014</year><elocation-id>1412.6980</elocation-id></element-citation></ref><ref id="R86"><label>86</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname><given-names>MM</given-names></name><etal/></person-group><article-title>Neural population dynamics during reaching</article-title><source>Nature</source><year>2012</year><volume>487</volume><fpage>51</fpage><lpage>6</lpage><pub-id pub-id-type="pmcid">PMC3393826</pub-id><pub-id pub-id-type="pmid">22722855</pub-id><pub-id pub-id-type="doi">10.1038/nature11129</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Fig. 1</label><caption><title>Neural dynamics in data and models during working memory.</title><p><bold>a</bold>, Illustration of the memory-guided saccade task. Time line of task events in a trial (bottom), with the corresponding displays (top). Top: black circle and squares show fixation ring, and the arrangement of visually cued saccade target locations, respectively (not to scale), red dots and line illustrate gaze positions during fixations and saccade, respectively. Bottom: yellow ticks show timing of stimulus cue onset and offset, yellow bar shows interval within which the go cue can occur. <bold>b</bold>, Schematic pattern of cross-temporal decoding when applied to neural recordings from the lPFC during working memory tasks<sup><xref ref-type="bibr" rid="R8">8</xref>,<xref ref-type="bibr" rid="R10">10</xref>,<xref ref-type="bibr" rid="R14">14</xref>–<xref ref-type="bibr" rid="R16">16</xref>,<xref ref-type="bibr" rid="R25">25</xref></sup>. Gray scale map shows accuracy of decoding cue identity (one out of 6) when the decoder is trained on neural activities recorded at a particular time in the trial (y-axis) and tested at another time (x-axis). Yellow lines indicate cue onset and offset times. Note poor generalization between time points inside the pink rectangle (i.e. dynamic coding), but good generalization between time points inside the cyan square (i.e. stable coding). The gray tick on the color bar indicates chance-level decoding. <bold>c</bold>, Schematic of neural network dynamics in an attractor network performing the task shown in <bold>a</bold> (see also <xref ref-type="fig" rid="F7">Extended Data Fig. 1a,b</xref>). Left: trajectory in a low-dimensional projection of neural state space in a single cue condition during the cue period (pale purple line, ending in pale purple circle) and delay period (dark purple line). Purple arrow heads indicate direction of travel along the trajectory, black cross shows attractor state, gray arrow shows overlap between cue input and late delay activity. Center: time course of firing rates (relative to across-condition mean) of a neuron aligned with dim 1 from left panel for two cue conditions (purple vs. blue, see also inset). Yellow lines indicate cue onset and offset times. Right: cross-temporal decoding of neural activity in the network (cf. <bold>b</bold>; see also <xref ref-type="fig" rid="F7">Extended Data Fig. 1a,b</xref>). <bold>d–f</bold>, Same as <bold>c</bold>, but for a linear integrator network with added transient dynamics<sup><xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R26">26</xref></sup> (<bold>d</bold>; see also <xref ref-type="fig" rid="F7">Extended Data Fig. 1c</xref>), a feedforward network that generates sequential activities<sup><xref ref-type="bibr" rid="R21">21</xref>,<xref ref-type="bibr" rid="R27">27</xref></sup> (<bold>e</bold>; see also <xref ref-type="fig" rid="F7">Extended Data Fig. 1d</xref>), and for a network optimized to perform the task shown in <bold>a</bold> (<bold>f</bold>; see also <xref ref-type="fig" rid="F7">Extended Data Fig. 1e</xref>).</p></caption><graphic xlink:href="EMS156517-f001"/></fig><fig id="F2" position="float"><label>Fig. 2</label><caption><title>Pattern completion and optimal information loading in attractor networks.</title><p><bold>a</bold>, A network with symmetric connections. Left: network schematic. Right: the recurrent weight matrix for 10 of the 50 neurons. <bold>b</bold>–<bold>f</bold>, Analysis of neural responses in symmetric attractor networks (such as shown in <bold>a</bold>) with optimized initial conditions. <bold>b</bold>, Firing rates in a representative trial. Neurons are ordered according to their rates at the end of the trial. Inset shows initial vs. final firing rates (mean-centered, i.e. relative to the time-dependent but condition-independent mean) across neurons in this trial (gray dots) and their Pearson correlation (<italic>r</italic>; <italic>p &lt;</italic> 0.001). Gray line is the identity line. <bold>c</bold>, Distribution of Pearson correlations between initial and final mean-centered neural firing rates across all 6 cue conditions and 10 networks. <bold>d</bold>, Sub-threshold activity for 2 cue conditions in an example network. Horizontal axis (persistent PC1) shows network activity projected on to the 1st principal component (PC1) of activities at the end of the delay period (across the 2 conditions shown in the inset), vertical axis (initial PC1, orthogonalized) shows projection to PC1 of initial activities orthogonalized to persistent PC1. Pale open circles (with arrows pointing to them from the origin) show the optimized initial conditions, dark traces show activity trajectories, black crosses show stable fixed points, dashed gray line is the identity line. <bold>e</bold>, Cross-temporal decoding of neural firing rate activity (cf. <xref ref-type="fig" rid="F1">Fig. 1b</xref>). The black vertical bar on the right indicates the delay-trained decoder training time period from <bold>f. f</bold>, Performance of a delay-trained decoder (black bar indicates decoding training time period) on neural firing rate activity over time starting from optimized initial conditions with full optimization (black), or restricted to the 5-dimensional subspace spanning the 6 cue-specific attractors (persistent subspace, green), or the subspace orthogonal to that (persistent nullspace, red). Solid lines and shading indicate mean 1 s.d. across all 6 cue conditions and 10 networks. Gray dotted line shows chance level decoding. Green and black lines are slightly offset vertically to aid visualization. <bold>g–l</bold>, Same as <bold>a</bold>–<bold>f</bold>, for attractor networks with unconstrained connections. The Pearson correlation in <bold>h</bold> (inset) is not significant (<italic>p &gt;</italic> 0.4).</p></caption><graphic xlink:href="EMS156517-f002"/></fig><fig id="F3" position="float"><label>Fig. 3</label><caption><title>Dynamical analysis of optimal information loading.</title><p><bold>a</bold>, Architecture of a symmetric (top) and an unconstrained network (bottom). <bold>b</bold>, Neural state space of the symmetric (top) and unconstrained network (bottom). Pale blue arrows show flow field dynamics (direction and magnitude of movement in the state space as a function of the momentary state). Thin green and red lines indicate the persistent and most amplifying modes, respectively (lines are offset slightly in the top panel to aid visualisation). Pale green, red, and gray arrows with open circles at the end indicate persistent, most amplifying, and random initial conditions, respectively. Dark green, red, and black arrows show neural dynamics starting from the corresponding initial condition. (Green arrows, and the red arrow in the top panel cannot be seen, as no movement in state space happens from those initial conditions.) Filled colored circles indicate final (persistent) neural activity. <bold>c</bold>, Time course of network activity along the persistent mode (i.e. projection onto the green line in <bold>b</bold>) when started from the persistent (green), most amplifying (red), or random initial conditions (black) for the symmetric (top) and the unconstrained model (bottom). <bold>d</bold>, Distributions of absolute overlap with the persistent mode for persistent (pale green), most amplifying (pale red), or random initial conditions (gray) across 100 randomly connected 1000-neuron symmetric (top) or unconstrained networks (bottom). The persistent (and for the symmetric models, also the equivalent most amplifying) initial conditions produce delta functions at 1 (arrows). Insets show illustration of large networks of neurons with either symmetric (top) or unconstrained (bottom) connections. <bold>e</bold>, Time course of absolute overlap with the persistent mode when starting network dynamics from persistent (green), most amplifying (red), or random initial conditions (black) for the symmetric (top) and the unconstrained network (bottom). Lines and shaded areas show mean±1 s.d. over the 100 randomly sampled 1000-neuron networks from <bold>d</bold>.</p></caption><graphic xlink:href="EMS156517-f003"/></fig><fig id="F4" position="float"><label>Fig. 4</label><caption><title>Neural signatures of optimal information loading.</title><p><bold>a</bold>, Performance of a delay-trained decoder (black bar indicates decoder training time period) on neural activity over time. Two cue conditions were used with inputs that were identical but had opposite signs. Lines show mean across 10 randomly connected 100-neuron linear unconstrained networks. Yellow ticks on horizontal axis indicate cue onset and offset times and the gray shading indicates the cue period. We show results for inputs aligned with the persistent mode (dark and pale green), the most amplifying mode (red), or a random direction (black and gray). Light colors (pale green and gray, ‘noise-matched’) correspond to networks with the same level of noise as in the reference network (red), while dark colors (dark green and black, ‘performance-matched’) correspond to networks with the same level of asymptotic decoding performance as that in the reference network (red). Gray dotted line shows chance level decoding. <bold>b</bold>, Cross-temporal decoding of neural activity for the 3 different information loading strategies (persistent, most amplifying, and random respectively in left, center, and right panels) for a representative network for the performance-matched condition from <bold>a</bold>. Yellow lines indicate cue onset and offset times. Pink rectangles indicate poor generalization between time points (i.e. dynamic coding) and cyan squares indicate examples of good generalization between time points (i.e. stable coding). The black vertical bars on the right of each plot indicate the delay-trained decoder training time period from <bold>a. c</bold>, Percent variance of responses explained by the subspace spanned by either the 25% most persistent (green) or 25% most amplifying (red) modes as a function of time in the same networks analyzed in <bold>a</bold>. Lines and error bars show mean ±1 s.d. across networks. We show results for inputs aligned with the persistent mode (left), most amplifying mode (center), or a random direction (right). Gray dotted line shows chance level overlap with a randomly chosen subspace occupying 25% of the full space.</p></caption><graphic xlink:href="EMS156517-f004"/></fig><fig id="F5" position="float"><label>Fig. 5</label><caption><title>Signatures of optimal information loading in monkey lPFC.</title><p><bold>a</bold>, Top: lPFC recording location. Bottom: neural firing rates (relative to the time-dependent but condition-independent mean) for one stimulus cue condition for 50 example neurons. See <xref ref-type="fig" rid="F1">Fig. 1a</xref> for experimental paradigm. Neurons are ordered according to their firing rate at the end of the period shown. Vertical yellow lines indicate stimulus cue onset and offset. <bold>b</bold>, Performance of a delay-trained decoder (black bar indicates decoder training time period) on neural activity over time. Yellow ticks on horizontal axis indicate stimulus cue onset, offset, and go cue times, and the gray shading indicates the stimulus cue period. Data is aligned to either stimulus cue onset (first 1.5 s) or to the go cue (final 1.5 s). Gray dotted lines show chance level decoding. <bold>c</bold>, Cross-temporal decoding of neural activity for monkey T (see <xref ref-type="fig" rid="F16">Extended Data Fig. 10a</xref> for Monkey K). Yellow lines indicate stimulus cue onset, offset, and go cue times. Pink rectangles indicate poor generalization between time points (i.e. dynamic coding) and the cyan square indicates examples of good generalization between time points (i.e. stable coding). The orange arrow indicates good same-time decoding during the cue period. The black vertical bar on the right indicates the delay-trained decoder training time period from <bold>b. d</bold>, Cross-validated quality of fits when fitting 20-dimensional linear neural networks to neural activity (blue) and time shuffled controls (dark gray). We also show quality of fits of the data against itself (‘train vs. test’; light gray). <bold>e</bold>, Neural activity for each of the 6 cue conditions projected onto the top PC (solid lines) for monkey K (left) and monkey T (right). Solid lines show held-out test data, dashed lines show predictions of fitted model dynamics. The inset for monkey T shows which color corresponds to each cue condition. <bold>f</bold>, Percent variance of responses explained by the subspace spanned by either the 25% most persistent (green) or 25% most amplifying (red) modes as a function of time for the 20-dimensional linear neural networks fitted to data from monkey K (top) and monkey T (bottom). Gray lines show chance level overlap defined as the expected overlap with a randomly chosen subspace occupying 25% of the full space (median and 95% C.I. across 200 random subspaces). Comparisons shown in <bold>d</bold> and <bold>f</bold> use two-sided permutation tests (*, <italic>p &lt;</italic> 0.05; **, <italic>p &lt;</italic> 0.01; n.s., not significant).</p></caption><graphic xlink:href="EMS156517-f005"/></fig><fig id="F6" position="float"><label>Fig. 6</label><caption><title>Information loading in task-optimized nonlinear networks.</title><p><bold>a</bold>, Illustration of a recurrent neural network model with unconstrained connectivity (middle). During the cue period, networks received input from one of six input channels on any given trial depending on the cue condition (left). Network activity was decoded into one of six possible behavioural responses via six readout channels (right). All recurrent weights in the network (50 neurons), as well as weights associated with the input and readout channels, were optimized. <bold>b</bold>, Illustration of cost functions used for training. Yellow ticks indicate cue onset and offset times, yellow bars indicate range of go times in the variable delay task. Boxcars show intervals over which stable decoding performance was required in three example trials with different delays for each of the cost functions considered: cue-delay (left), after-go-time (center), or just-in-time (right). <bold>c</bold>, Performance of a delay-trained decoder (black bar indicates decoder training time period on model neural activity over time in trials with a 1.75 s delay. Yellow ticks show stimulus cue onset, offset, and go times, and the gray shading indicates the cue period. Neural activities were generated by networks optimized for the cue-delay (green), after-go-time (orange), or just-in-time (red) costs. Solid colored lines and shading indicate mean±1 s.d. across 10 networks. Gray dotted line shows chance level decoding. <bold>d</bold>, Cross-temporal decoding of model neural activity for cue-delay (left), after-go-time (center), and just-in-time (right) trained models. Yellow lines indicate stimulus cue onset, offset, and go times. The black vertical bars on the right of each plot indicate the delay-trained decoder training time period from <bold>c. e</bold>, Percent variance of responses explained by the subspace spanned by either the 25% most persistent (green) or 25% most amplifying (red) modes as a function of time for 20-dimensional linear neural networks fitted to the model neural activities of nonlinear networks optimized for the cue-delay (left), after-go-time (center), or just-in-time cost (right). Gray lines show chance level overlap defined as the expected overlap with a randomly chosen subspace occupying 25% of the full space. Lines and error bars show mean±1 s.d. over 10 networks.</p></caption><graphic xlink:href="EMS156517-f006"/></fig><table-wrap id="T1" position="float" orientation="portrait"><label>Table 1</label><caption><title>Parameters used in the simulations of our models.</title></caption><table frame="hsides" rules="cols"><thead><tr><th align="left" valign="top">Symbol</th><th align="left" valign="top"><xref ref-type="fig" rid="F2">Fig. 2</xref></th><th align="left" valign="top"><xref ref-type="fig" rid="F3">Fig. 3 a-c</xref></th><th align="left" valign="top"><xref ref-type="fig" rid="F3">Fig. 3d-d</xref></th><th align="left" valign="top"><xref ref-type="fig" rid="F4">Fig. 4</xref></th><th align="left" valign="top">Units</th><th align="left" valign="top">Description</th></tr></thead><tbody><tr><td align="left" valign="top"><italic>N</italic></td><td align="left" valign="top">50</td><td align="left" valign="top">2</td><td align="left" valign="top">1000</td><td align="left" valign="top">100</td><td align="left" valign="top">-</td><td align="left" valign="top">number of neurons</td></tr><tr><td align="left" valign="top"><italic>t</italic><sub>0</sub></td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">-0.5</td><td align="left" valign="top">s</td><td align="left" valign="top">simulation start time</td></tr><tr><td align="left" valign="top"><italic>t</italic><sub>go</sub></td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">s</td><td align="left" valign="top">go cue time</td></tr><tr><td align="left" valign="top"><italic>t</italic><sub>max</sub></td><td align="left" valign="top">2</td><td align="left" valign="top">2</td><td align="left" valign="top">2</td><td align="left" valign="top">2.5</td><td align="left" valign="top">s</td><td align="left" valign="top">simulation end time</td></tr><tr><td align="left" valign="top"><italic>τ</italic></td><td align="left" valign="top">0.05</td><td align="left" valign="top">0.05</td><td align="left" valign="top">0.05</td><td align="left" valign="top">0.2</td><td align="left" valign="top">s</td><td align="left" valign="top">effective time constant</td></tr><tr><td align="left" valign="top"><bold>x</bold><sup>(<italic>c</italic>)</sup>(<italic>t</italic><sub>0</sub>)</td><td align="left" valign="top"><bold>h</bold><sup>(<italic>c</italic>)</sup></td><td align="left" valign="top"><bold>h</bold><sup>(<italic>c</italic>)</sup></td><td align="left" valign="top"><bold>h</bold><sup>(<italic>c</italic>)</sup></td><td align="left" valign="top"><bold>0</bold></td><td align="left" valign="top">-</td><td align="left" valign="top">initial condition</td></tr><tr><td align="left" valign="top"><bold>f</bold>(·)</td><td align="left" valign="top">nonlinear<sup><xref ref-type="table-fn" rid="TFN1">a</xref></sup></td><td align="left" valign="top">linear<sup><xref ref-type="table-fn" rid="TFN1">a</xref></sup></td><td align="left" valign="top">linear<sup><xref ref-type="table-fn" rid="TFN1">a</xref></sup></td><td align="left" valign="top">linear<sup><xref ref-type="table-fn" rid="TFN1">a</xref></sup></td><td align="left" valign="top">Hz</td><td align="left" valign="top">neural activation function</td></tr><tr><td align="left" valign="top"><bold>W</bold></td><td align="left" valign="top">optimized<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">set<sup><xref ref-type="table-fn" rid="TFN4">d</xref></sup></td><td align="left" valign="top"><inline-formula><mml:math id="M82"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mover><mml:mrow><mml:mo>∼</mml:mo></mml:mrow><mml:mrow><mml:mtext>iid.</mml:mtext></mml:mrow></mml:mover></mml:mrow><mml:mspace width="0.2em"/><mml:mrow><mml:mi>𝒩</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>e</mml:mi></mml:msup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula></td><td align="left" valign="top"><inline-formula><mml:math id="M83"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mover><mml:mrow><mml:mo>∼</mml:mo></mml:mrow><mml:mrow><mml:mtext>iid.</mml:mtext></mml:mrow></mml:mover></mml:mrow><mml:mspace width="0.2em"/><mml:mrow><mml:mi>𝒩</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>e</mml:mi></mml:msup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula></td><td align="left" valign="top">s</td><td align="left" valign="top">weight matrix</td></tr><tr><td align="left" valign="top"><italic>C</italic></td><td align="left" valign="top">6</td><td align="left" valign="top">1</td><td align="left" valign="top">1</td><td align="left" valign="top">2</td><td align="left" valign="top">-</td><td align="left" valign="top">number of stimuli</td></tr><tr><td align="left" valign="top"><bold>h</bold><sup>(<italic>c</italic>)</sup></td><td align="left" valign="top">optimized<sup><italic>c</italic><sub>1</sub></sup></td><td align="left" valign="top">set<sup><xref ref-type="table-fn" rid="TFN6">f</xref></sup></td><td align="left" valign="top">set<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">set<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">-</td><td align="left" valign="top">stimulus input</td></tr><tr><td align="left" valign="top"><bold>g</bold></td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">go cue</td></tr><tr><td align="left" valign="top"><italic>m</italic><sub>h</sub>(<italic>t</italic>)</td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top"><italic>K</italic>(0,0.25)<sup><xref ref-type="table-fn" rid="TFN7">g</xref></sup></td><td align="left" valign="top">-</td><td align="left" valign="top">stimulus masking kernel</td></tr><tr><td align="left" valign="top"><italic>m</italic><sub>g</sub>(<italic>t</italic>)</td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">-</td><td align="left" valign="top">go cue masking kernel</td></tr><tr><td align="left" valign="top"><bold>b</bold></td><td align="left" valign="top">optimized<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top"><bold>0</bold></td><td align="left" valign="top"><bold>0</bold></td><td align="left" valign="top"><bold>0</bold></td><td align="left" valign="top">-</td><td align="left" valign="top">cue-independent bias</td></tr><tr><td align="left" valign="top"><italic>σ</italic></td><td align="left" valign="top">0.05</td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">variable<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">-</td><td align="left" valign="top">noise standard deviation</td></tr><tr style="border-top: double"><td align="left" valign="top">Symbol</td><td align="left" valign="top"><xref ref-type="fig" rid="F5">Fig. 5 e-f</xref></td><td align="left" valign="top"><xref ref-type="fig" rid="F6">Fig. 6a-d</xref> and <xref ref-type="fig" rid="F7">Extended Data Fig. 1e</xref></td><td align="left" valign="top"><xref ref-type="fig" rid="F6">Fig. 6e</xref></td><td align="left" valign="top"><xref ref-type="fig" rid="F8">Extended Data Fig. 2</xref></td><td align="left" valign="top">Units</td><td align="left" valign="top">Description</td></tr><tr style="border-top: solid thin"><td align="left" valign="top"><italic>N</italic></td><td align="left" valign="top">20</td><td align="left" valign="top">50</td><td align="left" valign="top">20</td><td align="left" valign="top">50</td><td align="left" valign="top">-</td><td align="left" valign="top">number of neurons</td></tr><tr><td align="left" valign="top"><italic>t</italic><sub>0</sub></td><td align="left" valign="top">0</td><td align="left" valign="top">-0.5</td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">s</td><td align="left" valign="top">simulation start time</td></tr><tr><td align="left" valign="top"><italic>t</italic><sub>go</sub></td><td align="left" valign="top">-</td><td align="left" valign="top">2</td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">s</td><td align="left" valign="top">go cue time</td></tr><tr><td align="left" valign="top"><italic>t</italic><sub>max</sub></td><td align="left" valign="top">1</td><td align="left" valign="top">3</td><td align="left" valign="top">1</td><td align="left" valign="top">2</td><td align="left" valign="top">s</td><td align="left" valign="top">simulation end time</td></tr><tr><td align="left" valign="top"><italic>τ</italic></td><td align="left" valign="top">0.05</td><td align="left" valign="top">0.05</td><td align="left" valign="top">0.05</td><td align="left" valign="top">0.05</td><td align="left" valign="top">s</td><td align="left" valign="top">effective time constant</td></tr><tr><td align="left" valign="top"><bold>x</bold><sup>(<italic>c</italic>)</sup>(<italic>t</italic><sub>0</sub>)</td><td align="left" valign="top"><bold>0</bold></td><td align="left" valign="top"><bold>0</bold></td><td align="left" valign="top"><bold>0</bold></td><td align="left" valign="top"><bold>h</bold><sup>(<italic>c</italic>)</sup></td><td align="left" valign="top">-</td><td align="left" valign="top">initial condition</td></tr><tr><td align="left" valign="top"><bold>f</bold>(·)</td><td align="left" valign="top">linear<sup><xref ref-type="table-fn" rid="TFN1">a</xref></sup></td><td align="left" valign="top">nonlinear<sup><xref ref-type="table-fn" rid="TFN1">a</xref></sup></td><td align="left" valign="top">linear<sup><xref ref-type="table-fn" rid="TFN1">a</xref></sup></td><td align="left" valign="top">nonlinear<sup><xref ref-type="table-fn" rid="TFN1">a</xref></sup></td><td align="left" valign="top">Hz</td><td align="left" valign="top">neural activation function</td></tr><tr><td align="left" valign="top"><bold>W</bold></td><td align="left" valign="top">fit<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">optimized<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">fit<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">optimized<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">s</td><td align="left" valign="top">weight matrix</td></tr><tr><td align="left" valign="top"><italic>C</italic></td><td align="left" valign="top">6</td><td align="left" valign="top">6</td><td align="left" valign="top">6</td><td align="left" valign="top">6</td><td align="left" valign="top">-</td><td align="left" valign="top">number of stimuli</td></tr><tr><td align="left" valign="top"><bold>h</bold><sup>(<italic>c</italic>)</sup></td><td align="left" valign="top">fit<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">optimized<sup><italic>c</italic><sub>2</sub></sup></td><td align="left" valign="top">fit<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">optimized<sup><italic>c</italic><sub>1</sub></sup></td><td align="left" valign="top">-</td><td align="left" valign="top">stimulus input</td></tr><tr><td align="left" valign="top"><bold>g</bold></td><td align="left" valign="top">-</td><td align="left" valign="top">∑<sub><italic>c</italic></sub> <bold>h</bold><sup>(<italic>c</italic>)</sup></td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">go cue</td></tr><tr><td align="left" valign="top"><italic>m</italic><sub>h</sub>(<italic>t</italic>)</td><td align="left" valign="top"><italic>K</italic>(0,0.25)<sup><xref ref-type="table-fn" rid="TFN7">g</xref></sup></td><td align="left" valign="top"><italic>K</italic>(0, 0.25)<sup><xref ref-type="table-fn" rid="TFN7">g</xref></sup></td><td align="left" valign="top"><italic>K</italic>(0,0.25)<sup><xref ref-type="table-fn" rid="TFN7">g</xref></sup></td><td align="left" valign="top">0</td><td align="left" valign="top">-</td><td align="left" valign="top">stimulus masking kernel</td></tr><tr><td align="left" valign="top"><italic>m</italic><sub>g</sub>(<italic>t</italic>)</td><td align="left" valign="top">0</td><td align="left" valign="top"><italic>K</italic>(<italic>t</italic><sub>go</sub>, <italic>t</italic><sub>go</sub> + 0.5)<sup><xref ref-type="table-fn" rid="TFN7">g</xref></sup></td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">-</td><td align="left" valign="top">go cue masking kernel</td></tr><tr><td align="left" valign="top"><bold>b</bold></td><td align="left" valign="top">fit<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">optimized<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">fit<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">optimized<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">-</td><td align="left" valign="top">cue-independent bias</td></tr><tr><td align="left" valign="top"><italic>σ</italic></td><td align="left" valign="top">0</td><td align="left" valign="top">0.05</td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">-</td><td align="left" valign="top">noise standard deviation</td></tr><tr style="border-top: double"><td align="left" valign="top">Symbol</td><td align="left" valign="top"><xref ref-type="fig" rid="F9">Extended Data Fig. 3</xref></td><td align="left" valign="top"><xref ref-type="fig" rid="F13">Extended Data Fig. 7b</xref></td><td align="left" valign="top"><xref ref-type="fig" rid="F13">Extended Data Fig. 7c</xref></td><td align="left" valign="top"><xref ref-type="fig" rid="F13">Extended Data Fig. 7d</xref></td><td align="left" valign="top">Units</td><td align="left" valign="top">Description</td></tr><tr style="border-top: solid thin"><td align="left" valign="top"><italic>N</italic></td><td align="left" valign="top">50</td><td align="left" valign="top">50</td><td align="left" valign="top">50</td><td align="left" valign="top">20</td><td align="left" valign="top">-</td><td align="left" valign="top">number of neurons</td></tr><tr><td align="left" valign="top"><italic>t</italic><sub>0</sub></td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">s</td><td align="left" valign="top">simulation start time</td></tr><tr><td align="left" valign="top"><italic>t</italic><sub>go</sub></td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">s</td><td align="left" valign="top">go cue time</td></tr><tr><td align="left" valign="top"><italic>t</italic><sub>max</sub></td><td align="left" valign="top">2</td><td align="left" valign="top">2</td><td align="left" valign="top">2</td><td align="left" valign="top">2</td><td align="left" valign="top">s</td><td align="left" valign="top">simulation end time</td></tr><tr><td align="left" valign="top"><italic>τ</italic></td><td align="left" valign="top">0.05</td><td align="left" valign="top">0.05</td><td align="left" valign="top">0.05</td><td align="left" valign="top">0.05</td><td align="left" valign="top">s</td><td align="left" valign="top">effective time constant</td></tr><tr><td align="left" valign="top"><bold>x</bold><sup>(<italic>c</italic>)</sup>(<italic>t</italic><sub>0</sub>)</td><td align="left" valign="top"><bold>h</bold><sup>(<italic>c</italic>)</sup></td><td align="left" valign="top"><bold>h</bold><sup>(<italic>c</italic>)</sup></td><td align="left" valign="top"><bold>h</bold><sup>(<italic>c</italic>)</sup></td><td align="left" valign="top"><bold>h</bold><sup>(<italic>c</italic>)</sup></td><td align="left" valign="top">-</td><td align="left" valign="top">initial condition</td></tr><tr><td align="left" valign="top"><bold>f</bold>(·)</td><td align="left" valign="top">nonlinear<sup><xref ref-type="table-fn" rid="TFN1">a</xref></sup></td><td align="left" valign="top">linear<sup><xref ref-type="table-fn" rid="TFN1">a</xref></sup></td><td align="left" valign="top">nonlinear<sup><xref ref-type="table-fn" rid="TFN1">a</xref></sup></td><td align="left" valign="top">linear<sup><xref ref-type="table-fn" rid="TFN1">a</xref></sup></td><td align="left" valign="top">Hz</td><td align="left" valign="top">neural activation function</td></tr><tr><td align="left" valign="top"><bold>W</bold></td><td align="left" valign="top">optimized<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">optimized<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">optimized<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">fit<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">s</td><td align="left" valign="top">weight matrix</td></tr><tr><td align="left" valign="top"><italic>C</italic></td><td align="left" valign="top">36 (6)<sup><xref ref-type="table-fn" rid="TFN8">h</xref></sup></td><td align="left" valign="top">6</td><td align="left" valign="top">6</td><td align="left" valign="top">6</td><td align="left" valign="top">-</td><td align="left" valign="top">number of stimuli</td></tr><tr><td align="left" valign="top"><bold>h</bold><sup>(<italic>c</italic>)</sup></td><td align="left" valign="top">optimized<sup><italic>c</italic><sub>2</sub></sup></td><td align="left" valign="top">optimized<sup><italic>c</italic><sub>1</sub></sup></td><td align="left" valign="top">optimized<sup><italic>c</italic><sub>1</sub></sup></td><td align="left" valign="top">fit<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">-</td><td align="left" valign="top">stimulus input</td></tr><tr><td align="left" valign="top"><bold>g</bold></td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">go cue</td></tr><tr><td align="left" valign="top"><italic>m</italic><sub>h</sub>(<italic>t</italic>)</td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">-</td><td align="left" valign="top">stimulus masking kernel</td></tr><tr><td align="left" valign="top"><italic>m</italic><sub>g</sub>(<italic>t</italic>)</td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">-</td><td align="left" valign="top">go cue masking kernel</td></tr><tr><td align="left" valign="top"><bold>b</bold></td><td align="left" valign="top">optimized<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">optimized<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">optimized<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">fit<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">-</td><td align="left" valign="top">cue-independent bias</td></tr><tr><td align="left" valign="top"><italic>σ</italic></td><td align="left" valign="top">0.05</td><td align="left" valign="top">0</td><td align="left" valign="top">0.05</td><td align="left" valign="top">0</td><td align="left" valign="top">-</td><td align="left" valign="top">noise standard deviation</td></tr><tr style="border-top: double"><td align="left" valign="top">Symbol</td><td align="left" valign="top"><xref ref-type="fig" rid="F10">Extended Data Fig. 4a,b</xref></td><td align="left" valign="top"><xref ref-type="fig" rid="F10">Extended Data Fig. 4c,d</xref></td><td align="left" valign="top"><xref ref-type="fig" rid="F11">Extended Data Fig. 5a,b</xref></td><td align="left" valign="top">Units</td><td align="left" valign="top">Description</td></tr><tr style="border-top: solid thin"><td align="left" valign="top"><italic>N</italic></td><td align="left" valign="top">100</td><td align="left" valign="top">100</td><td align="left" valign="top">10, 100, 1000</td><td align="left" valign="top">-</td><td align="left" valign="top">number of neurons</td></tr><tr><td align="left" valign="top"><italic>t</italic><sub>0</sub></td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">s</td><td align="left" valign="top">simulation start time</td></tr><tr><td align="left" valign="top"><italic>t</italic><sub>go</sub></td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">s</td><td align="left" valign="top">go cue time</td></tr><tr><td align="left" valign="top"><italic>t</italic><sub>max</sub></td><td align="left" valign="top">2</td><td align="left" valign="top">2</td><td align="left" valign="top">2</td><td align="left" valign="top">s</td><td align="left" valign="top">simulation end time</td></tr><tr><td align="left" valign="top"><italic>τ</italic></td><td align="left" valign="top">0.05</td><td align="left" valign="top">0.05</td><td align="left" valign="top">0.05</td><td align="left" valign="top">s</td><td align="left" valign="top">effective time constant</td></tr><tr><td align="left" valign="top"><bold>x</bold><sup>(<italic>c</italic>)</sup>(<italic>t</italic><sub>0</sub>)</td><td align="left" valign="top"><bold>h</bold><sup>(<italic>c</italic>)</sup></td><td align="left" valign="top"><bold>h</bold><sup>(<italic>c</italic>)</sup></td><td align="left" valign="top"><bold>h</bold><sup>(<italic>c</italic>)</sup></td><td align="left" valign="top">-</td><td align="left" valign="top">initial condition</td></tr><tr><td align="left" valign="top"><bold>f</bold>(·)</td><td align="left" valign="top">linear<sup><xref ref-type="table-fn" rid="TFN1">a</xref></sup></td><td align="left" valign="top">linear<sup><xref ref-type="table-fn" rid="TFN1">a</xref></sup></td><td align="left" valign="top">linear<sup><xref ref-type="table-fn" rid="TFN1">a</xref></sup></td><td align="left" valign="top">Hz</td><td align="left" valign="top">neural activation function</td></tr><tr><td align="left" valign="top"><bold>W</bold></td><td align="left" valign="top"><inline-formula><mml:math id="M84"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mover><mml:mrow><mml:mo>∼</mml:mo></mml:mrow><mml:mrow><mml:mtext>iid.</mml:mtext></mml:mrow></mml:mover></mml:mrow><mml:mspace width="0.2em"/><mml:mrow><mml:mi>𝒩</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>e</mml:mi></mml:msup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula></td><td align="left" valign="top"><inline-formula><mml:math id="M85"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mover><mml:mrow><mml:mo>∼</mml:mo></mml:mrow><mml:mrow><mml:mtext>iid.</mml:mtext></mml:mrow></mml:mover></mml:mrow><mml:mspace width="0.2em"/><mml:mrow><mml:mi>𝒩</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>e</mml:mi></mml:msup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula></td><td align="left" valign="top"><inline-formula><mml:math id="M86"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mover><mml:mrow><mml:mo>∼</mml:mo></mml:mrow><mml:mrow><mml:mtext>iid.</mml:mtext></mml:mrow></mml:mover></mml:mrow><mml:mspace width="0.2em"/><mml:mrow><mml:mi>𝒩</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>e</mml:mi></mml:msup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula></td><td align="left" valign="top">s</td><td align="left" valign="top">weight matrix</td></tr><tr><td align="left" valign="top"><italic>C</italic></td><td align="left" valign="top">1</td><td align="left" valign="top">1</td><td align="left" valign="top">1</td><td align="left" valign="top">-</td><td align="left" valign="top">number of stimuli</td></tr><tr><td align="left" valign="top"><bold>h</bold><sup>(<italic>c</italic>)</sup></td><td align="left" valign="top"><inline-formula><mml:math id="M87"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mover><mml:mrow><mml:mo>∼</mml:mo></mml:mrow><mml:mrow><mml:mtext>iid.</mml:mtext></mml:mrow></mml:mover></mml:mrow><mml:mspace width="0.2em"/><mml:mrow><mml:mi>𝒩</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula></td><td align="left" valign="top">optimized<sup><italic>c</italic><sub>4</sub></sup></td><td align="left" valign="top">set<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">-</td><td align="left" valign="top">stimulus input</td></tr><tr><td align="left" valign="top"><bold>g</bold></td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">go cue</td></tr><tr><td align="left" valign="top"><italic>m</italic><sub>h</sub>(<italic>t</italic>)</td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">-</td><td align="left" valign="top">stimulus masking kernel</td></tr><tr><td align="left" valign="top"><italic>m</italic><sub>g</sub>(<italic>t</italic>)</td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">-</td><td align="left" valign="top">go cue masking kernel</td></tr><tr><td align="left" valign="top"><bold>b</bold></td><td align="left" valign="top"><bold>0</bold></td><td align="left" valign="top"><bold>0</bold></td><td align="left" valign="top"><bold>0</bold></td><td align="left" valign="top">-</td><td align="left" valign="top">cue-independent bias</td></tr><tr><td align="left" valign="top"><italic>σ</italic></td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">-</td><td align="left" valign="top">noise standard deviation</td></tr><tr style="border-top: double"><td align="left" valign="top">Symbol</td><td align="left" valign="top"><xref ref-type="fig" rid="F11">Extended Data Fig. 5c,d</xref></td><td align="left" valign="top"><xref ref-type="fig" rid="F16">Extended Data Fig. 10f</xref></td><td align="left" valign="top"><xref ref-type="fig" rid="F16">Extended Data Fig. 10g</xref></td><td align="left" valign="top"><xref ref-type="fig" rid="F17">Extended Data Figs. 11</xref>–<xref ref-type="fig" rid="F19">13</xref></td><td align="left" valign="top">Units</td><td align="left" valign="top">Description</td></tr><tr style="border-top: solid thin"><td align="left" valign="top"><italic>N</italic></td><td align="left" valign="top">100</td><td align="left" valign="top">20</td><td align="left" valign="top">20</td><td align="left" valign="top">50</td><td align="left" valign="top">-</td><td align="left" valign="top">number of neurons</td></tr><tr><td align="left" valign="top"><italic>t</italic><sub>0</sub></td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top"><italic>t</italic><sub>go</sub> – 1</td><td align="left" valign="top">-0.5</td><td align="left" valign="top">s</td><td align="left" valign="top">simulation start time</td></tr><tr><td align="left" valign="top"><italic>t</italic><sub>go</sub></td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">1</td><td align="left" valign="top">2</td><td align="left" valign="top">s</td><td align="left" valign="top">go cue time</td></tr><tr><td align="left" valign="top"><italic>t</italic><sub>max</sub></td><td align="left" valign="top">2</td><td align="left" valign="top">1</td><td align="left" valign="top">1</td><td align="left" valign="top">3</td><td align="left" valign="top">s</td><td align="left" valign="top">simulation end time</td></tr><tr><td align="left" valign="top"><italic>τ</italic></td><td align="left" valign="top">0.05</td><td align="left" valign="top">0.05</td><td align="left" valign="top">0.05</td><td align="left" valign="top">0.05</td><td align="left" valign="top">s</td><td align="left" valign="top">effective time constant</td></tr><tr><td align="left" valign="top"><bold>x</bold><sup>(<italic>c</italic>)</sup>(<italic>t</italic><sub>0</sub>)</td><td align="left" valign="top"><bold>h</bold><sup>(<italic>c</italic>)</sup></td><td align="left" valign="top"><bold>0</bold></td><td align="left" valign="top">set<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top"><bold>0</bold></td><td align="left" valign="top">-</td><td align="left" valign="top">initial condition</td></tr><tr><td align="left" valign="top"><bold>f</bold>(·)</td><td align="left" valign="top">linear<sup><xref ref-type="table-fn" rid="TFN1">a</xref></sup></td><td align="left" valign="top">linear<sup><xref ref-type="table-fn" rid="TFN1">a</xref></sup></td><td align="left" valign="top">linear<sup><xref ref-type="table-fn" rid="TFN1">a</xref></sup></td><td align="left" valign="top">nonlinear<sup><xref ref-type="table-fn" rid="TFN1">a</xref></sup></td><td align="left" valign="top">Hz</td><td align="left" valign="top">neural activation function</td></tr><tr><td align="left" valign="top"><bold>W</bold></td><td align="left" valign="top"><inline-formula><mml:math id="M88"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mover><mml:mrow><mml:mo>∼</mml:mo></mml:mrow><mml:mrow><mml:mtext>iid.</mml:mtext></mml:mrow></mml:mover></mml:mrow><mml:mspace width="0.2em"/><mml:mrow><mml:mi>𝒩</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>e</mml:mi></mml:msup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula></td><td align="left" valign="top">fit<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">fit<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">optimized<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">s</td><td align="left" valign="top">weight matrix</td></tr><tr><td align="left" valign="top"><italic>C</italic></td><td align="left" valign="top">1</td><td align="left" valign="top">6</td><td align="left" valign="top">6</td><td align="left" valign="top">6</td><td align="left" valign="top">-</td><td align="left" valign="top">number of stimuli</td></tr><tr><td align="left" valign="top"><bold>h</bold><sup>(<italic>c</italic>)</sup></td><td align="left" valign="top">optimized<sup><italic>c</italic><sub>3</sub></sup></td><td align="left" valign="top">fit<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">-</td><td align="left" valign="top">optimized<sup><italic>c</italic><sub>2</sub></sup></td><td align="left" valign="top">-</td><td align="left" valign="top">stimulus input</td></tr><tr><td align="left" valign="top"><bold>g</bold></td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">∑<sub><italic>c</italic></sub> <bold>h</bold><sup>(<italic>c</italic>)</sup></td><td align="left" valign="top">-</td><td align="left" valign="top">go cue</td></tr><tr><td align="left" valign="top"><italic>m</italic><sub>h</sub>(<italic>t</italic>)</td><td align="left" valign="top">0</td><td align="left" valign="top"><italic>K</italic>(0,0.25)<sup><xref ref-type="table-fn" rid="TFN7">g</xref></sup></td><td align="left" valign="top">0</td><td align="left" valign="top"><italic>K</italic>(0,0.25)<sup><xref ref-type="table-fn" rid="TFN7">g</xref></sup></td><td align="left" valign="top">-</td><td align="left" valign="top">stimulus masking kernel</td></tr><tr><td align="left" valign="top"><italic>m</italic><sub>g</sub>(<italic>t</italic>)</td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top"><italic>K</italic>(<italic>t</italic><sub>go</sub>, <italic>t</italic><sub>go</sub> + 0.5)<sup><xref ref-type="table-fn" rid="TFN7">g</xref></sup></td><td align="left" valign="top">-</td><td align="left" valign="top">go cue masking kernel</td></tr><tr><td align="left" valign="top"><bold>b</bold></td><td align="left" valign="top"><bold>0</bold></td><td align="left" valign="top">fit<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">fit<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">optimized<sup><xref ref-type="table-fn" rid="TFN2">b</xref></sup></td><td align="left" valign="top">-</td><td align="left" valign="top">cue-independent bias</td></tr><tr><td align="left" valign="top"><italic>σ</italic></td><td align="left" valign="top">0.05</td><td align="left" valign="top">0</td><td align="left" valign="top">0</td><td align="left" valign="top">0.05</td><td align="left" valign="top">-</td><td align="left" valign="top">noise standard deviation</td></tr></tbody></table><table-wrap-foot><fn id="TFN1"><label>a</label><p id="P157">For nonlinear networks, <italic>f</italic><sub><italic>i</italic></sub>(<bold>x</bold>) = [<italic>x</italic><sub><italic>i</italic></sub>]<sub>+</sub> was the rectified linear (ReLU) activation function. For linear networks <italic>f</italic><sub><italic>i</italic></sub>(<bold>x</bold>) = <italic>x</italic><sub><italic>i</italic></sub>. The only exception to this was when we created ring attractor networks (<xref ref-type="fig" rid="F9">Extended Data Fig. 3</xref>) in which we used a tanh nonlinearity <italic>f</italic><sub><italic>i</italic></sub>(<bold>x</bold>) = tanh(<italic>x</italic><sub><italic>i</italic></sub>). See also text.</p></fn><fn id="TFN2"><label>b</label><p id="P158">See text for details.</p></fn><fn id="TFN3"><label>c</label><p id="P159">Inputs were optimized either with both a norm constraint and an overall energy constraint (<italic>c</italic><sub>1</sub>); only an overall energy constraint (<italic>c</italic><sub>2</sub>); only a norm constraint (<italic>c</italic><sub>3</sub>); or so that the dynamics produced the mathematically minimal overall energy (<italic>c</italic><sub>4</sub>, see <xref ref-type="supplementary-material" rid="SD1">Supplementary Information S2</xref>). See text for more details.</p></fn><fn id="TFN4"><label>d</label><p id="P160">For the symmetric network, we used <inline-formula><mml:math id="M89"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mn>0.375</mml:mn></mml:mtd><mml:mtd><mml:mn>0.625</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0.625</mml:mn></mml:mtd><mml:mtd><mml:mn>0.375</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>;</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> for the unconstrained network, we used <inline-formula><mml:math id="M90"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mtext mathvariant="bold">R</mml:mtext></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnalign="center center"><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>50</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mo>−</mml:mo><mml:mn>11.5</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mtext mathvariant="bold">R</mml:mtext></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> where <bold>R</bold> is the rotation matrix <inline-formula><mml:math id="M91"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mtext mathvariant="bold">R</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnalign="center center"><mml:mtr><mml:mtd><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mo>−</mml:mo><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> with <italic>θ</italic> = 0.1.</p></fn><fn id="TFN5"><label>e</label><p id="P161">For the symmetric networks, we enforced <inline-formula><mml:math id="M92"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mo stretchy="false">←</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mspace width="0.2em"/><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> For all networks we also shifted the obtained weight matrix by the identity matrix multiplied by a constant so that the largest real part in the eigenvalues of <bold>W</bold> is exactly 1 (i.e., the largest eigenvalue of the associated Jacobian would therefore be 0 due to the leak term), and we rejected any <bold>W</bold>’s for which the top eigenvalue (the eigenvalue with largest real part) had an imaginary component. For <xref ref-type="fig" rid="F4">Fig. 4</xref>, to provide a slightly better agreement between the model dynamics and the experimental recordings, we rejected any <bold>W</bold>’s for which the inner product between the most amplifying mode and persistent mode was greater than 0.2 (i.e. we only kept <bold>W</bold>’s that were relatively mathematically non-normal).</p></fn><fn id="TFN6"><label>f</label><p id="P162">We used 3 possible input directions (which all had a Euclidean norm of 1): inputs either aligned with the most persistent mode (<bold>x</bold><sup>p</sup>), the most amplifying mode (<bold>x</bold><sup>a</sup>), or a random direction (<bold>x</bold><sup>r</sup>). For the symmetric model, <bold>x</bold><sup>p</sup> = <bold>x</bold><sup>a</sup> = [0.707, 0.707]<sup>⊤</sup> and we used <bold>x</bold><sup>r</sup> = [0.98, 0.18]<sup>⊤</sup>. For the unconstrained model, <bold>x</bold><sup>p</sup> = [0.995, 0.0998]<sup>⊤</sup>, <bold>x</bold><sup>a</sup> = [0.1537, 0.9881]<sup>⊤</sup> and we used <bold>x</bold><sup>r</sup> = [0.8453, 0.5343]<sup>⊤</sup>.</p></fn><fn id="TFN7"><label>g</label><p id="P163"><inline-formula><mml:math id="M93"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left"><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mtext>if</mml:mtext><mml:mspace width="0.2em"/><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>≤</mml:mo><mml:mi>t</mml:mi><mml:mo>≤</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mspace width="0.2em"/><mml:mtext mathvariant="bold">s</mml:mtext></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mtext>otherwise</mml:mtext></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula>. In the table, <italic>t</italic><sub>go</sub> refers to the timing of the go cue (see text).</p></fn><fn id="TFN8"><label>h</label><p id="P164">For training, we used <italic>C</italic> = 36 cue conditions. For our subsequent analyses (<xref ref-type="fig" rid="F9">Extended Data Fig. 3</xref>), we used <italic>C</italic> = 6 cue conditions to be consistent with the other models.</p></fn></table-wrap-foot></table-wrap><table-wrap id="T2" position="float" orientation="portrait"><label>Table 2</label><caption><title>Parameters for nonlinear network optimization.</title><p>Times <italic>T</italic><sub>1</sub> and <italic>T</italic><sub>2</sub> are relative to stimulus onset at <italic>t</italic> = 0. Units are shown in parentheses after the name of the corresponding parameter.</p></caption><table frame="box" rules="all"><thead><tr><th align="left" valign="middle">Cost function</th><th align="left" valign="middle"><italic>T</italic><sub>1</sub> (s)</th><th align="left" valign="middle"><italic>T</italic><sub>2</sub> (s)</th><th align="left" valign="middle"><inline-formula><mml:math id="M94"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mtext>nonlin</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mrow><mml:mtext>s</mml:mtext></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula></th><th align="left" valign="middle"><inline-formula><mml:math id="M95"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mtext>nonlin</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula></th><th align="left" valign="middle">Figures</th></tr></thead><tbody><tr><td align="left" valign="middle" rowspan="2" style="border-bottom: solid thin">cue-delay</td><td align="left" valign="middle" rowspan="2" style="border-bottom: solid thin">0</td><td align="left" valign="middle" rowspan="2" style="border-bottom: solid thin"><italic>t</italic><sub>go</sub></td><td align="left" valign="middle" rowspan="2" style="border-bottom: solid thin">20</td><td align="left" valign="middle">0.00005</td><td align="left" valign="middle"><xref ref-type="fig" rid="F6">Fig. 6</xref> and <xref ref-type="fig" rid="F17">Extended Data Fig. 11</xref></td></tr><tr><td align="left" valign="middle" style="border-bottom: solid thin">0.0005</td><td align="left" valign="middle" style="border-bottom: solid thin"><xref ref-type="fig" rid="F17">Extended Data Fig. 11</xref></td></tr><tr><td align="left" valign="middle" rowspan="2" style="border-bottom: solid thin">full-delay</td><td align="left" valign="middle" rowspan="2" style="border-bottom: solid thin">0.25</td><td align="left" valign="middle" rowspan="2" style="border-bottom: solid thin"><italic>t</italic><sub>go</sub></td><td align="left" valign="middle" rowspan="2" style="border-bottom: solid thin">20</td><td align="left" valign="middle">0.00005</td><td align="left" valign="middle"><xref ref-type="fig" rid="F19">Extended Data Fig. 13</xref></td></tr><tr><td align="left" valign="middle" style="border-bottom: solid thin">0.0005</td><td align="left" valign="middle" style="border-bottom: solid thin"><xref ref-type="fig" rid="F19">Extended Data Fig. 13</xref></td></tr><tr><td align="left" valign="middle" rowspan="5" style="border-bottom: solid thin">just-in-time</td><td align="left" valign="middle">0.5</td><td align="left" valign="middle"><italic>t</italic><sub>max</sub></td><td align="left" valign="middle">33</td><td align="left" valign="middle">0.00005</td><td align="left" valign="middle"><xref ref-type="fig" rid="F2">Fig. 2</xref> and <xref ref-type="fig" rid="F8">Extended Data Fig. 2</xref></td></tr><tr><td align="left" valign="middle" rowspan="2">0.75</td><td align="left" valign="middle" rowspan="2"><italic>t</italic><sub>go</sub></td><td align="left" valign="middle" rowspan="2">33</td><td align="left" valign="middle">0.00005</td><td align="left" valign="middle"><xref ref-type="fig" rid="F6">Fig. 6</xref> and <xref ref-type="fig" rid="F17">Extended Data Fig. 11</xref> and Extended Data</td></tr><tr><td align="left" valign="middle"/><td align="left" valign="middle"><xref ref-type="fig" rid="F1">Fig. 1e</xref></td></tr><tr><td align="left" valign="middle"/><td align="left" valign="middle"/><td align="left" valign="middle"/><td align="left" valign="middle">0.0005</td><td align="left" valign="middle"><xref ref-type="fig" rid="F17">Extended Data Fig. 11</xref></td></tr><tr><td align="left" valign="middle" style="border-bottom: solid thin">0.5</td><td align="left" valign="middle" style="border-bottom: solid thin"><italic>t</italic><sub>max</sub></td><td align="left" valign="middle" style="border-bottom: solid thin">33</td><td align="left" valign="middle" style="border-bottom: solid thin">0.05</td><td align="left" valign="middle" style="border-bottom: solid thin"><xref ref-type="fig" rid="F9">Extended Data Fig. 3</xref></td></tr><tr><td align="left" valign="middle" rowspan="2">after-go</td><td align="left" valign="middle" rowspan="2"><italic>t</italic><sub>go</sub></td><td align="left" valign="middle" rowspan="2"><italic>t</italic><sub>go</sub> + 0.5</td><td align="left" valign="middle" rowspan="2">10</td><td align="left" valign="middle">0.00005</td><td align="left" valign="middle"><xref ref-type="fig" rid="F6">Fig. 6</xref></td></tr><tr><td align="left" valign="middle">0.0005</td><td align="left" valign="middle"><xref ref-type="fig" rid="F18">Extended Data Fig. 12</xref></td></tr></tbody></table></table-wrap><table-wrap id="T3" position="float" orientation="portrait"><label>Table 3</label><caption><title>Parameters used in previous models.</title></caption><table frame="box" rules="groups"><thead><tr><th align="left" valign="top" colspan="7" style="border-bottom: solid thin">Parameters used in network simulations of previous models</th></tr><tr><th align="left" valign="top">Symbol</th><th align="left" valign="top"><xref ref-type="fig" rid="F7">Extended Data Fig. 1a</xref></th><th align="left" valign="top"><xref ref-type="fig" rid="F7">Extended Data Fig. 1b</xref></th><th align="left" valign="top"><xref ref-type="fig" rid="F7">Extended Data Fig. 1c</xref> and <xref ref-type="fig" rid="F14">Extended Data Fig. 8a,b,d,e</xref></th><th align="left" valign="top"><xref ref-type="fig" rid="F7">Extended Data Fig. 1d</xref> and <xref ref-type="fig" rid="F14">Extended Data Fig. 8c,f</xref></th><th align="left" valign="top">Units</th><th align="left" valign="top">Description</th></tr></thead><tbody><tr><td align="left" valign="top"><italic>N</italic></td><td align="left" valign="top">100</td><td align="left" valign="top">108</td><td align="left" valign="top">100</td><td align="left" valign="top">100</td><td align="left" valign="top">-</td><td align="left" valign="top">number of neurons</td></tr><tr><td align="left" valign="top"><italic>t</italic><sub>0</sub></td><td align="left" valign="top">-0.5</td><td align="left" valign="top">-0.5</td><td align="left" valign="top">-0.5</td><td align="left" valign="top">-0.5</td><td align="left" valign="top">s</td><td align="left" valign="top">simulation start time</td></tr><tr><td align="left" valign="top"><italic>t</italic><sub>go</sub></td><td align="left" valign="top">2</td><td align="left" valign="top">2</td><td align="left" valign="top">2</td><td align="left" valign="top">2</td><td align="left" valign="top">s</td><td align="left" valign="top">go cue time</td></tr><tr><td align="left" valign="top"><italic>t</italic><sub>max</sub></td><td align="left" valign="top">3</td><td align="left" valign="top">3</td><td align="left" valign="top">3</td><td align="left" valign="top">3</td><td align="left" valign="top">s</td><td align="left" valign="top">simulation end time</td></tr><tr><td align="left" valign="top"><italic>τ</italic></td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">0.05</td><td align="left" valign="top">0.01</td><td align="left" valign="top">s</td><td align="left" valign="top">effective time constant</td></tr><tr><td align="left" valign="top"><inline-formula><mml:math id="M96"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow><mml:mrow><mml:mtext>r</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mtext>E</mml:mtext></mml:mrow></mml:mrow></mml:msubsup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula></td><td align="left" valign="top">0.02</td><td align="left" valign="top">0.02</td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">s</td><td align="left" valign="top">effective time constant (E neurons)</td></tr><tr><td align="left" valign="top"><inline-formula><mml:math id="M97"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow><mml:mrow><mml:mtext>r</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow></mml:mrow></mml:msubsup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula></td><td align="left" valign="top">0.01</td><td align="left" valign="top">0.01</td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">s</td><td align="left" valign="top">effective time constant (I neurons)</td></tr><tr><td align="left" valign="top"><bold>r</bold><sup>(<italic>c</italic>)</sup>(<italic>t</italic><sub>0</sub>)</td><td align="left" valign="top"><bold>0</bold></td><td align="left" valign="top"><bold>0</bold></td><td align="left" valign="top"><bold>0</bold></td><td align="left" valign="top"><bold>0</bold></td><td align="left" valign="top">Hz</td><td align="left" valign="top">initial condition</td></tr><tr><td align="left" valign="top"><bold>f</bold>(·)</td><td align="left" valign="top">nonlinear<sup><xref ref-type="table-fn" rid="TFN9">a</xref></sup></td><td align="left" valign="top">nonlinear<sup><xref ref-type="table-fn" rid="TFN9">a</xref></sup></td><td align="left" valign="top">linear<sup><xref ref-type="table-fn" rid="TFN9">a</xref></sup></td><td align="left" valign="top">linear<sup><xref ref-type="table-fn" rid="TFN9">a</xref></sup></td><td align="left" valign="top">Hz</td><td align="left" valign="top">neural activation function</td></tr><tr><td align="left" valign="top"><bold>W</bold></td><td align="left" valign="top">set<sup><xref ref-type="table-fn" rid="TFN10">b</xref></sup></td><td align="left" valign="top">set<sup><xref ref-type="table-fn" rid="TFN10">b</xref></sup></td><td align="left" valign="top">set<sup><xref ref-type="table-fn" rid="TFN10">b</xref></sup></td><td align="left" valign="top">set<sup><xref ref-type="table-fn" rid="TFN10">b</xref></sup></td><td align="left" valign="top">s</td><td align="left" valign="top">weight matrix</td></tr><tr><td align="left" valign="top"><italic>C</italic></td><td align="left" valign="top">6</td><td align="left" valign="top">6</td><td align="left" valign="top">6</td><td align="left" valign="top">6</td><td align="left" valign="top">-</td><td align="left" valign="top">number of stimuli</td></tr><tr><td align="left" valign="top"><bold>h</bold><sup>(<italic>c</italic>)</sup></td><td align="left" valign="top">set<sup><xref ref-type="table-fn" rid="TFN10">b</xref></sup></td><td align="left" valign="top">set<sup><xref ref-type="table-fn" rid="TFN10">b</xref></sup></td><td align="left" valign="top">set<sup><xref ref-type="table-fn" rid="TFN10">b</xref></sup></td><td align="left" valign="top">set<sup><xref ref-type="table-fn" rid="TFN10">b</xref></sup></td><td align="left" valign="top">-</td><td align="left" valign="top">stimulus input</td></tr><tr><td align="left" valign="top"><bold>g</bold></td><td align="left" valign="top">∑<sub><italic>c</italic></sub> <bold>h</bold><sup>(<italic>c</italic>)</sup></td><td align="left" valign="top">∑<sub><italic>c</italic></sub> <bold>h</bold><sup>(<italic>c</italic>)</sup></td><td align="left" valign="top">∑<sub><italic>c</italic></sub> <bold>h</bold><sup>(<italic>c</italic>)</sup></td><td align="left" valign="top">∑<sub><italic>c</italic></sub> <bold>h</bold><sup>(<italic>c</italic>)</sup></td><td align="left" valign="top">-</td><td align="left" valign="top">go cue</td></tr><tr><td align="left" valign="top"><italic>m</italic><sub>h</sub>(<italic>t</italic>)</td><td align="left" valign="top"><italic>K</italic>(0,0.25)<sup><xref ref-type="table-fn" rid="TFN11">c</xref></sup></td><td align="left" valign="top"><italic>K</italic>(0,0.25)<sup><xref ref-type="table-fn" rid="TFN11">c</xref></sup></td><td align="left" valign="top"><italic>K</italic>(0,0.25)<sup><xref ref-type="table-fn" rid="TFN11">c</xref></sup></td><td align="left" valign="top">K (0,0.25)<sup><xref ref-type="table-fn" rid="TFN11">c</xref></sup></td><td align="left" valign="top">-</td><td align="left" valign="top">stimulus masking kernel</td></tr><tr><td align="left" valign="top"><italic>m</italic><sub>g</sub>(<italic>t</italic>)</td><td align="left" valign="top"><italic>K</italic>(<italic>t</italic><sub>go</sub>, <italic>t</italic><sub>go</sub> + 0.5)<sup><xref ref-type="table-fn" rid="TFN11">c</xref></sup></td><td align="left" valign="top"><italic>K</italic>(<italic>t</italic><sub>go</sub>, <italic>t</italic><sub>go</sub> + 0.5)<sup><xref ref-type="table-fn" rid="TFN11">c</xref></sup></td><td align="left" valign="top"><italic>K</italic>(<italic>t</italic><sub>go</sub>, <italic>t</italic><sub>go</sub> + 0.5)<sup><xref ref-type="table-fn" rid="TFN11">c</xref></sup></td><td align="left" valign="top"><italic>K</italic>(<italic>t</italic><sub>go</sub>, <italic>t</italic><sub>go</sub> + 0.5)<sup><xref ref-type="table-fn" rid="TFN11">c</xref></sup></td><td align="left" valign="top">-</td><td align="left" valign="top">go cue masking kernel</td></tr><tr><td align="left" valign="top"><bold>b</bold><sub><italic>r</italic></sub></td><td align="left" valign="top"><inline-formula><mml:math id="M98"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>b</mml:mi><mml:mrow><mml:mrow><mml:mtext>r</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mtext>E</mml:mtext></mml:mrow></mml:mrow></mml:msubsup><mml:mspace width="0.2em"/><mml:mspace width="0.2em"/><mml:mspace width="0.2em"/><mml:mspace width="0.2em"/><mml:mo>=</mml:mo><mml:mspace width="0.2em"/><mml:mspace width="0.2em"/><mml:mspace width="0.2em"/><mml:mspace width="0.2em"/><mml:mn>0.2</mml:mn><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>b</mml:mi><mml:mrow><mml:mrow><mml:mtext>r</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula></td><td align="left" valign="top"><inline-formula><mml:math id="M99"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>b</mml:mi><mml:mrow><mml:mrow><mml:mtext>r</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mtext>E</mml:mtext></mml:mrow></mml:mrow></mml:msubsup><mml:mspace width="0.2em"/><mml:mspace width="0.2em"/><mml:mspace width="0.2em"/><mml:mspace width="0.2em"/><mml:mo>=</mml:mo><mml:mspace width="0.2em"/><mml:mspace width="0.2em"/><mml:mspace width="0.2em"/><mml:mspace width="0.2em"/><mml:mo>−</mml:mo><mml:mn>1.2</mml:mn><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>b</mml:mi><mml:mrow><mml:mrow><mml:mtext>r</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.28</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula></td><td align="left" valign="top"><bold>0</bold></td><td align="left" valign="top"><bold>0</bold></td><td align="left" valign="top">Hz</td><td align="left" valign="top">cue-independent bias</td></tr><tr><td align="left" valign="top"><italic>σ</italic><sub>r</sub></td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">0.02</td><td align="left" valign="top">0.02</td><td align="left" valign="top">Hz</td><td align="left" valign="top">noise standard deviation</td></tr><tr><td align="left" valign="top"><inline-formula><mml:math id="M100"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mrow><mml:mtext>r</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mtext>E</mml:mtext></mml:mrow></mml:mrow></mml:msubsup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula></td><td align="left" valign="top">1</td><td align="left" valign="top">2</td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">Hz</td><td align="left" valign="top">noise standard deviation (E neurons)</td></tr><tr><td align="left" valign="top"><inline-formula><mml:math id="M101"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mrow><mml:mtext>r</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow></mml:mrow></mml:msubsup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula></td><td align="left" valign="top">3</td><td align="left" valign="top">1</td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">Hz</td><td align="left" valign="top">noise standard deviation (I neurons)</td></tr></tbody></table><table-wrap-foot><fn id="TFN9"><label>a</label><p id="P165">For nonlinear networks, <inline-formula><mml:math id="M102"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left"><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mspace width="0.2em"/><mml:mo>if</mml:mo><mml:mspace width="0.2em"/><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>≤</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msqrt><mml:mn>4</mml:mn><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:msqrt></mml:mtd><mml:mtd><mml:mtext>otherwise</mml:mtext></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula> For linear networks <italic>f<sub>i</sub></italic>(<bold>x</bold>) = <italic>x<sub>i</sub></italic>.</p></fn><fn id="TFN10"><label>b</label><p id="P166">See text for details.</p></fn><fn id="TFN11"><label>c</label><p id="P167"><inline-formula><mml:math id="M103"><mml:mtable><mml:mtr><mml:mtd><mml:mstyle displaystyle="true"><mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mtext>if</mml:mtext><mml:mspace width="0.2em"/><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>≤</mml:mo><mml:mi>t</mml:mi><mml:mo>≤</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mspace width="0.2em"/><mml:mtext>s</mml:mtext></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mtext>otherwise</mml:mtext><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula></p></fn></table-wrap-foot></table-wrap></floats-group></article>