<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS151844</article-id><article-id pub-id-type="doi">10.1101/2021.11.02.466729</article-id><article-id pub-id-type="archive">PPR415997</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">4</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Feedback information sharing in the human brain reflects bistable perception in the absence of report</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Canales-Johnson</surname><given-names>Andres</given-names></name><xref ref-type="aff" rid="A1">a</xref><xref ref-type="aff" rid="A2">b</xref><xref ref-type="aff" rid="A3">c</xref><xref ref-type="aff" rid="A4">d</xref><xref ref-type="aff" rid="A8">h</xref><xref ref-type="corresp" rid="CR1">i</xref></contrib><contrib contrib-type="author"><name><surname>Beerendonk</surname><given-names>Lola</given-names></name><xref ref-type="aff" rid="A1">a</xref><xref ref-type="aff" rid="A2">b</xref><xref ref-type="aff" rid="A8">h</xref></contrib><contrib contrib-type="author"><name><surname>Chennu</surname><given-names>Srivas</given-names></name><xref ref-type="aff" rid="A5">e</xref></contrib><contrib contrib-type="author"><name><surname>Davidson</surname><given-names>Matthew J.</given-names></name><xref ref-type="aff" rid="A6">f</xref></contrib><contrib contrib-type="author"><name><surname>Ince</surname><given-names>Robin A.A.</given-names></name><xref ref-type="aff" rid="A7">g</xref></contrib><contrib contrib-type="author"><name><surname>Gaal</surname><given-names>Simon van</given-names></name><xref ref-type="aff" rid="A1">a</xref><xref ref-type="aff" rid="A2">b</xref><xref ref-type="corresp" rid="CR1">i</xref></contrib></contrib-group><aff id="A1"><label>a</label>Conscious Brain Lab, Department of Psychology, University of Amsterdam, Nieuwe Achtergracht 129-B, 1018 WT, Amsterdam, The Netherlands</aff><aff id="A2"><label>b</label>Amsterdam Brain Cognition, University of Amsterdam, Nieuwe Achtergracht 129-B, 1018 WT Amsterdam, The Netherlands</aff><aff id="A3"><label>c</label>Cambridge Consciousness and Cognition Lab, Department of Psychology, University of Cambridge, Downing Street, CB2 3EB Cambridge, United Kingdom</aff><aff id="A4"><label>d</label>Neuropsychology and Cognitive Neurosciences Research Center, Faculty of Health Sciences, Universidad Cato’lica del Maule, 3460000 Talca, Chile</aff><aff id="A5"><label>e</label>School of Computing, University of Kent, Canterbury CT2 7NF, United Kingdom</aff><aff id="A6"><label>f</label>School of Psychology, University of Sydney, Sydney, Australia</aff><aff id="A7"><label>g</label>Institute of Neuroscience and Psychology, University of Glasgow, Scotland G12 8QB, United Kingdom</aff><aff id="A8"><label>h</label>Equal contribution</aff><author-notes><corresp id="CR1"><label>i</label>Correspondence to: Andres Canales-Johnson (<email>afc37@cam.ac.uk</email>), Simon van Gaal (<email>s.vangaal@uva.nl</email>))</corresp></author-notes><pub-date pub-type="nihms-submitted"><day>30</day><month>07</month><year>2022</year></pub-date><pub-date pub-type="preprint"><day>29</day><month>07</month><year>2022</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">In the search for the neural basis of conscious experience, perception and the cognitive processes associated with reporting perception are typically confounded as neural activity is recorded while participants explicitly report what they experience. Here we present a novel way to disentangle perception from report using eye-movement analysis techniques based on convolutional neural networks and neurodynamical analyses based on information theory. We use a bistable visual stimulus that instantiates two well-known properties of conscious perception: integration and differentiation. At any given moment, observers either perceive the stimulus as one integrated unitary object or as two differentiated objects that are clearly distinct from each other. Using electroencephalography, we show that measures of integration and differentiation based on information theory closely follow participants’ perceptual experience of those contents when switches were reported. We observed increased information integration between anterior to posterior electrodes (front to back) prior to a switch to the integrated percept, and higher information differentiation of anterior signals leading up to reporting the differentiated percept. Crucially, information integration was closely linked to perception and even observed in a no-report condition when perceptual transitions were inferred from eye movements alone. In contrast, the link between neural differentiation and perception was observed solely in the active report condition. Our results, therefore, suggest that perception and the processes associated with report require distinct amounts of anterior-posterior network communication and anterior information differentiation. While front-to-back directed information is associated with changes in the content of perception when viewing bistable visual stimuli, regardless of report, frontal information differentiation was absent in the no-report condition and therefore is not directly linked to perception <italic>per se</italic>.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">Consciousness is subjective experience, the ‘what it is likeness’ of our experience, for example, when we perceive a certain scene or endure pain. Having such experiences may be the main reason why life matters to us, and it may set us apart from other smart but non-living “things”, such as your phone or the internet (<xref ref-type="bibr" rid="R1">1</xref>). Conscious experience is a truly subjective and private phenomenon and it cannot be observed directly from the outside. To objectively study and understand it, we have to get access to the inner subjective experience of others, for instance via self-report tasks or via behavioral tasks that we believe can capture conscious content (<xref ref-type="bibr" rid="R2">2</xref>). In this way, when combined with neuroimaging tools, the neural correlates of consciousness (NCCs) are sought (<xref ref-type="bibr" rid="R3">3</xref>). However, while doing so, what we observe in measures of brain activity may not be as pure as we hoped for. Our measurements of ‘consciousness’ may be cofounded with several cognitive factors, e.g., the act of reporting, attention, surprise, or decision-making, arising after conscious experience has emerged. This severely complicates our attempt to isolate the neural basis of conscious experience (<xref ref-type="bibr" rid="R4">4</xref>; <xref ref-type="bibr" rid="R5">5</xref>; <xref ref-type="bibr" rid="R6">6</xref>; <xref ref-type="bibr" rid="R7">7</xref>; <xref ref-type="bibr" rid="R8">8</xref>; <xref ref-type="bibr" rid="R9">9</xref>). Here we address this complication, by assessing the influence of report and no-report task instructions on neural measures reflecting perceptual transitions in situations in which sensory input is ambiguous.</p><p id="P3">Perceptual ambiguity is a key phenomenon to study the brain mechanisms of conscious perception (<xref ref-type="bibr" rid="R10">10</xref>), often experimentally elicited by using ‘multistable stimuli’ (<xref ref-type="bibr" rid="R11">11</xref>). Multistability can be induced in several ways or using several ambiguous stimuli, for instance using binocular rivalry, structure from motion, the Necker cube, and motion-induced blindness. The common feature of such paradigms is that an ambiguous stimulus can be interpreted in two, or multiple ways, without changing the sensory input that reaches the senses. Confronted with this ambiguity, observers experience spontaneous fluctuations between interpretations of the stimulus.</p><p id="P4">Experimental evidence has varied regarding whether changes in perception when viewing multistable stimuli correlate with changes in early sensory or higher-order cortical activity. In support of higher loci, single-cell recordings in monkeys have revealed that the strongest perceptual modulations of neuronal firing occur in higher association cortices, including inferotemporal cortex (ITC) and dorsolateral prefrontal cortex (DLPFC) (<xref ref-type="bibr" rid="R12">12</xref>; <xref ref-type="bibr" rid="R13">13</xref>; <xref ref-type="bibr" rid="R14">14</xref>; <xref ref-type="bibr" rid="R15">15</xref>). However, previous human fMRI studies have associated both early and higher sensory regions with perceptual transitions (<xref ref-type="bibr" rid="R16">16</xref>). For example, when face and house stimuli compete for perceptual dominance, category-specific regions in ITC activate more strongly for the dominant percept, even before observers indicate a perceptual switch via button press. Another common observation in human fMRI studies is the association of a large network of parietal and frontal brain areas, traditionally associated with attentional and cognitive functions, during the report of perceptual transitions (for an overview see (<xref ref-type="bibr" rid="R11">11</xref>)). One central and unresolved issue in consciousness science in general (<xref ref-type="bibr" rid="R8">8</xref>)), and multistable perception in particular, is what processes these large clusters of activations in the frontoparietal cortex reflect. The feedback account states that frontal regions actively exert a top-down influence on sensory brain regions to resolve perceptual ambiguity. Evidence in favor of this account shows that targeting specific nodes in this network using transcranial magnetic stimulation (TMS) can shape the rate of perceptual transitions, suggesting their causal influence in resolving, or even driving, perceptual ambiguity (<xref ref-type="bibr" rid="R11">11</xref>; <xref ref-type="bibr" rid="R17">17</xref>; <xref ref-type="bibr" rid="R18">18</xref>). The opposite feedforward account links frontal activity to processing of the consequences of perceiving, and thus processes occurring after perceptual ambiguity was resolved by posterior brain regions (<xref ref-type="bibr" rid="R19">19</xref>; <xref ref-type="bibr" rid="R20">20</xref>; <xref ref-type="bibr" rid="R18">18</xref>). Here, we contribute to this debate by assessing the extent to which feedforward and feedback processes correlate with changes in multistable perception, in the presence and absence of explicit report about the dominant percept.</p><p id="P5">By studying conscious contents in the presence and absence of explicit report during visual bistable perception, we here investigate the neural mechanisms underlying perceptual transitions, while dissociating perception from report, or other related factors. The bistable stimulus we use consists of two overlapping gratings, known as ambiguous plaids or moving plaids (<xref ref-type="bibr" rid="R21">21</xref>; <xref ref-type="bibr" rid="R22">22</xref>). This ambiguous stimulus can be perceived as one plaid moving coherently in a vertical direction, or two plaids sliding across one another horizontally. The plaid stimulus was thus perceived as perceptually integrated (one object) or perceptually differentiated (two objects), respectively. Due to the unique direction of motion associated with these stimuli, this stimulus allows us to track perception in the absence of report by capitalizing on the occurrence of optokinetic nystagmus (OKN) (<xref ref-type="bibr" rid="R23">23</xref>; <xref ref-type="bibr" rid="R24">24</xref>; <xref ref-type="bibr" rid="R25">25</xref>; <xref ref-type="bibr" rid="R26">26</xref>). OKN is a visually induced reflex, comprised of a combination of slow-phase and fast-phase eye movements that allow the eyes to follow objects in motion, for instance when looking at the trees alongside the road whilst moving past them in a car. Importantly, OKN follows perception when viewing bistable visual stimuli, which makes it useful for assessing perception in the absence of reports (<xref ref-type="bibr" rid="R23">23</xref>; <xref ref-type="bibr" rid="R25">25</xref>; <xref ref-type="bibr" rid="R26">26</xref>).</p><p id="P6">We focused on neural metrics inspired by information theory (<xref ref-type="bibr" rid="R27">27</xref>), to assess the neural underpinnings of awareness in report and no report conditions while viewing this integrated or differentiated percept. In a recent report-based study on perceptual ambiguity, it was shown that frontoparietal information integration, computed as the amount of information sharing between frontal and parietal EEG/ECoG signals, increased when participants reported an ambiguous auditory stimulus as perceptually integrated compared to when it was reported as perceptually differentiated. On the contrary, information differentiation, computed as the amount of information diversity within frontal or parietal EEG/ECoG signals separately, showed the opposite pattern within the same frontoparietal electrodes: it increased when participants reported the bistable stimulus as perceptually differentiated compared to perceptually integrated. This suggests that information integration and information differentiation go hand in hand with observers’ phenomenology of an integrated or differentiated percept of an ambiguous stimulus, a hypothesis that we explore in the visual modality here. One crucial open question so far, however, is whether the observed changes in neural integration and differentiation are dependent upon reporting or not because, in this previous study, observers had to explicitly report the perceptual switches by pressing buttons. We address this issue here by specifically relating neural metrics of integration and differentiation to changing percepts in both report and no-report conditions (<xref ref-type="bibr" rid="R5">5</xref>; <xref ref-type="bibr" rid="R9">9</xref>). Further, we here also specify the directionality of neural information flow to relate feedforward and feedback activity to changes in perceptual experience, independent of the necessity to report.</p></sec><sec id="S2" sec-type="results"><title>Results</title><sec id="S3"><title>Oculomotor signals</title><p id="P7">There were two experimental conditions that were performed in alternating runs. During the report runs (<xref ref-type="fig" rid="F1">Figure 1A</xref>), observers pressed one button when the percept changed from vertical movement to horizontal movement and another button to indicate changes from horizontal movement to vertical movement (buttons were counterbalanced across blocks). During the no-report runs (<xref ref-type="fig" rid="F1">Figure 1B</xref>), observers were instructed to remain central fixation and just passively view the stimulus, and therefore perceptual transitions were rendered task-irrelevant. Participants were not informed about the relationship between perception and oculomotor signals and not about our goal to infer perception from their eye signals.</p><p id="P8">We first characterized changes in oculomotor signals in both directions of perceptual change (vertical/horizontal) in the report condition time-locked to the button response. We computed the slow phase of the OKN (see Methods) as it distinguishes between visual percepts during binocular rivalry (<xref ref-type="bibr" rid="R25">25</xref>; <xref ref-type="bibr" rid="R28">28</xref>; <xref ref-type="bibr" rid="R29">29</xref>; <xref ref-type="bibr" rid="R9">9</xref>; <xref ref-type="bibr" rid="R30">30</xref>). OKN is particularly useful as positive and negative zero-crossings tend to precede the perceptual changes indicated by button presses. We observed OKN zero crossing going from positive to negative before the visual stimulus was reported as integrated, and zero crossing going from negative to positive, when the stimulus was reported as differentiated (<xref ref-type="fig" rid="F1">Figure 1C</xref>). In the left panel of <xref ref-type="fig" rid="F1">Figure 1C</xref> (Report: BP) we depicted the raw OKN time series time-locked to the button press (-200 to 500 ms) in microvolts. Next, for both the report (Report: OKN; <xref ref-type="fig" rid="F1">Figure 1C</xref>) and no-report (No report: OKN; <xref ref-type="fig" rid="F1">Figure 1C</xref>) conditions, after computing the OKN crossings in the continuous oculomotor signal, we labeled the data with their corresponding button press labels, and created epochs locked to the OKN crossings, which as expected, revealed a clear moment for the perceptual transitions (<xref ref-type="fig" rid="F1">Figure 1C</xref>). In the middle and right panels of <xref ref-type="fig" rid="F1">Figure 1C</xref> we plotted the slow phase of the OKN signal locked to zero-crossing in arbitrary units, which was computed as described in the Methods. It is important to note the similarity of OKN data in both report and no-report conditions, demonstrating its potential to capture the contents of perception in both cases.</p><p id="P9">To quantify the predictive value of the OKN crossings for identifying perceptual contents, we performed a decoding analysis using a convolutional neural network (CNN). To measure the generalization performance of the CNN, we split the OKN epochs and their corresponding button press labels into 3 parts: training, validation, and testing. 70% of the entire dataset was allocated to the training set. The remaining 30% were further split equally to create validation and test datasets, each containing 15% of the original data and labels (see <xref ref-type="sec" rid="S11">Methods</xref> for details).</p><p id="P10">First, we trained a CNN to decode the button presses from the oculomotor signal using a cross-classification procedure in the report condition. We obtained a classification accuracy of 85% (<xref ref-type="fig" rid="F1">Figure 1D</xref>). Next, in the same report condition, a second CNN was trained to decode the labels based on the OKN crossings, reaching a classification accuracy of 79%, indicating that OKN changes could reliably decode changes in perception. We finally estimated OKN crossings in the no-report data, labeled each crossing accordingly, and trained a third CNN to decode the labels, obtaining a classification accuracy of 80% (<xref ref-type="fig" rid="F1">Figure 1D</xref>). Finally, another indication that our CNN accurately marks the occurrence of perceptual switches is that the number of switches in the report condition strongly correlates when based on button presses versus CNN performance (across subject Pearson’s r=0.88; p&lt;0.001, see (<xref ref-type="bibr" rid="R23">23</xref>), for a similar analysis).</p></sec><sec id="S4"><title>Histograms</title><p id="P11">We next characterized the distributions of perceptual switches in the report and no-report condition, locked to button presses and OKN crossings (<xref ref-type="fig" rid="F1">Figure 1E</xref>). All distributions were approximated well with a gamma distribution (p&lt;0.001), a common observation in report-based rivalry paradigms (<xref ref-type="bibr" rid="R31">31</xref>). That the no-report dominance durations are well approximated by a typical gamma function further indicates that the variability (and phenomenology) in perceptual switches during the passive viewing condition is similar to active report conditions (see also (<xref ref-type="bibr" rid="R23">23</xref>; <xref ref-type="bibr" rid="R31">31</xref>).</p><p id="P12">To investigate whether perceptual ambiguity is resolved differently when the stimulus is reported as integrated or differentiated, we computed the time delay between OKN crossings and button presses in the report condition. We observed a longer delay between OKN crossing and the button press when the stimulus was reported as integrated versus differentiated (t<sub>1,39</sub>=2.23; p= 0.032; Cohen’s d=0.352, (<xref ref-type="fig" rid="F1">Figure 1F</xref>). This increase in reaction time after a change in percept has occurred (as confirmed via OKN) suggests an increase in cognitive demand when reporting an integrated percept (transitioning from two objects to one) than when reporting a differentiated percept (going from one to two objects). We return to these features in the time-frequency characteristics of perceptual switches.</p><p id="P13">Overall, it is important to note the similarity of OKN data in both report and no-report conditions, demonstrating its ability to capture the content of perception in both cases. We observed the classic gamma functions for the distribution of percepts in each case. As a result, comparing our measures of integration and differentiation when time-locked to OKN crossings presents a powerful opportunity to assess the impact of reportbased paradigms on the neural correlates of perception.</p></sec><sec id="S5"><title>Report condition locked to button presses</title><p id="P14">We first investigated the neural dynamics of information integration when participants reported perceptual switches by pressing buttons. Here, information integration refers to the transformation of inputs into outputs through recurrent neural dynamics. These nonlinear transformations are essential for pattern extraction in neural networks and may lead to signal amplification and broadcasting (<xref ref-type="bibr" rid="R32">32</xref>). To this end, we computed a metric of information integration known as Directed Information (dir-INFO) which quantifies directional connectivity between neural signals (<xref ref-type="bibr" rid="R33">33</xref>; <xref ref-type="bibr" rid="R34">34</xref>). Compared to traditional causality detection methods based on linear models (e.g., Granger causality), dir-INFO is a model-free measure and can detect both linear and nonlinear functional relationships between brain signals. We took advantage of previous work that made this measure statistically robust when applied to neural data (<xref ref-type="bibr" rid="R35">35</xref>; <xref ref-type="bibr" rid="R36">36</xref>; <xref ref-type="bibr" rid="R33">33</xref>; <xref ref-type="bibr" rid="R37">37</xref>). dir-INFO quantifies functional connectivity by measuring the degree to which the past of a “sender signal” <italic>X</italic> (e.g., EEG traces of anterior electrodes) predicts the future of another “receiver signal” <italic>Y</italic> (e.g., EEG traces of posterior electrodes), conditional on the past of the receiver signal <italic>Y</italic>. Thus, if there is significant dir-INFO between EEG signal <italic>X</italic> at one time, and EEG signal <italic>Y</italic> at a later time, this shows that signal <italic>X</italic> contains information about the future signal <italic>Y</italic>. Conditioning out the past of signal <italic>Y</italic> ensures the delayed interaction is providing new information over and above that available in the past of signal <italic>Y</italic>. For all dir-INFO analyses, we tested multiple delays from 0 ms to 500 ms (in steps of 4 ms) between the sender and receiver signal, which allows us to investigate the characteristic time delay of directed information transfer during perceptual switches between anterior and posterior signals. For all analyses reported here, we lock data to perceptual switches (either marked by a button press or eye-movement analysis) and inspect the EEG dynamics leading up to this perceptual switch. We have excluded all trials in which the previous perceptual switch occurred less than 2 seconds before the switch of interest (at time 0).</p><p id="P15">In the case of the report condition, (<xref ref-type="fig" rid="F2">Figure 2A</xref>) shows dir-INFO between frontal and parietal signals, in both directions, so in the feedback direction (anterior to posterior electrodes) and in the feedforward direction (posterior to anterior electrodes, <xref ref-type="supplementary-material" rid="SD1">Figure S1A</xref> for electrode location). We plot feedforward and feedback-directed information as a function of signal delay between the two electrode sets, both when the moving plaids are reported as integrated (to INT; red color) as well as differentiated (to DIF; blue color). Signal delays are plotted on the y-axis, and testing time before the button press is plotted on the x-axis. A cluster-based permutation test performed on the difference between dir-INFO leading up to the integrated percept versus differentiated percept shows two significant clusters (cluster p&lt;0.01). One cluster was observed indicating an increase in dir-INFO for the switch to integrated condition compared to the differentiated condition, at ∼50 ms delay between the time-period 1050 to 900 ms prior to the button press. A second cluster indicated an increase in dir-INFO prior to a switch to the integrated condition ∼250 ms delay of approximately 1200 to 500 ms before the button press (<xref ref-type="fig" rid="F2">Figure 2</xref>). Importantly, these significant clusters were observed in the feedback direction only. Note that there are no button presses in the time window of interest, due to our trial exclusion procedure.</p><p id="P16">Next, we tested for an interaction between the direction of perceptual change (to integrated, to differentiated) and information direction (front to back, back to front). We performed a cluster-based permutation test on the difference between the perceptual switch (to INT minus to DIFF trials) and information direction (feedback minus feedforward). We observed two significant clusters (cluster p&lt;0.01) showing stronger dir-INFO when perception switched to integrated as compared to differentiated in the front-to-back direction, but not in the back-to-front direction (<xref ref-type="fig" rid="F2">Figure 2C</xref>). Finally, to test for the spatial specificity of the dir-INFO effect (i.e., the anterior-posterior direction), we computed dir-INFO in the right-left direction using temporal electrodes (<xref ref-type="supplementary-material" rid="SD1">Figure S1B</xref>). No dir-INFO differences between perceptual switches were observed in the right-to-left direction, nor in the left-to-right direction (<xref ref-type="supplementary-material" rid="SD1">Figure S2</xref>).</p><p id="P17">We next analyzed the dynamics of information differentiation (K-complexity) within frontal and parietal signals separately. Neural differentiation metrics quantify the diversity of information patterns within brain signals and it has been useful for distinguishing between conscious states (<xref ref-type="bibr" rid="R38">38</xref>; <xref ref-type="bibr" rid="R39">39</xref>; <xref ref-type="bibr" rid="R40">40</xref>) and conscious contents previously (<xref ref-type="bibr" rid="R27">27</xref>). We performed cluster-based permutation testing on the difference between the Information Differentiation (ID) time series leading up to the integrated percept versus the differentiated percept for the same set of anterior (front) and posterior (back) electrodes. As expected, significantly increased diff-INFO was observed before the bistable stimulus was reported as differentiated as compared to when was reported as integrated. This effect was observed at approximately -1300 to 250 ms around the button press indicating the upcoming perceptual switch (<xref ref-type="fig" rid="F2">Figure 2E</xref>), note that in the 2000 ms before the perceptual switch indicated by the response no previous switches are incorporated). Importantly, no such effect was observed for the posterior electrodes (<xref ref-type="fig" rid="F2">Figure 2D</xref>).</p><p id="P18">We next tested for an interaction between the direction of perceptual change and information differentiation by subtracting between to DIF and to INT trials within frontal and back ROIs (<xref ref-type="fig" rid="F2">Figure 2E</xref>). As predicted, a cluster-based permutation test revealed an interaction between perceptual change, perceptual direction, and ROI based on information differentiation (p&lt;0.01), showing higher diff-INFO in the anterior region prior to a change to seeing the differentiated percept, without changes to diff-INFO in the posterior regions (<xref ref-type="fig" rid="F2">Figure 2E</xref>). Finally, we computed diff-INFO in the right and left ROI using the temporal electrodes. No diff-INFO differences between perceptual switches were observed in the right nor left ROI (<xref ref-type="supplementary-material" rid="SD1">Figure S3</xref>).</p><p id="P19">Taken together, and consistent with previously reported effects in the auditory domain (<xref ref-type="bibr" rid="R41">41</xref>), these results show that having an integrated versus a differentiated percept, goes hand in hand with front-to-back neural directed information integration and frontal differentiation brain measures. Next, we aim to establish to what extent these effects depend on the necessity for reporting perceptual transitions (task relevance of switches) and we further specify the timing of these effects by locking our analyses more closely to the perceptual transitions based on OKN crossings.</p></sec><sec id="S6"><title>Report condition locked to OKN crossings</title><p id="P20">The dir-INFO analyses were performed in the same way as in the report condition but this time locked to OKN crossings instead of button presses. We observed significant clusters of increased dir-INFO when the visual stimulus was perceived as integrated as compared to differentiated, again only in the feedback direction (<xref ref-type="fig" rid="F3">Figure 3A</xref>).</p><p id="P21">Significant clusters spanned delays between 50 to 450 ms and occurred roughly -1600 to 100 ms around the moment OKN crossed. Interestingly, significant time points were observed much closer in time to the perceptual switches when time-locked to OKN crossings, than when locked to responses (<xref ref-type="fig" rid="F2">Figure 2A</xref>). Similar interaction analysis between switch direction and integration direction (feedback vs feedforward) was performed. The difference in directed information between integrated and differentiated percepts was stronger for the feedback direction than the feedforward direction (interaction cluster p&lt;0.01; <xref ref-type="fig" rid="F3">Figure 3C</xref>).</p><p id="P22">For information differentiation however, locked to the OKN crossings in the report condition, no robust clusters were observed (<xref ref-type="fig" rid="F3">Figure 3D</xref>), neither for the front (left panel) nor the back (right panel) ROIs. As a strong diff-INFO effect was observed in this same data when aligned to button-press (<xref ref-type="fig" rid="F2">Figure 2D</xref>), we note that this measure may capture processes involved in (manual) report, rather than in the experience of a perceptual state. We return to this nuance in our Discussion.</p></sec><sec id="S7"><title>No report condition</title><p id="P23">After establishing the dynamics of information integration and differentiation in the report condition, and finding that differentiation measures, but not integration measures, were dependent on report, we next analyzed both during the no-report condition (i.e., locked to the OKN crossings). Similar to the report condition, a cluster-based permutation test revealed significant clusters of increased dir-INFO when the visual stimulus was perceived as integrated as compared to differentiated, but uniquely in the feedback direction (<xref ref-type="fig" rid="F4">Figure 4A</xref>). The observed clusters showed a similar range of delays (around 50 to 400 ms) and they were observed in similar time windows (-600 to 0 ms around the OKN crossings) as in the report condition when time-locked to the OKN (<xref ref-type="fig" rid="F3">Figure 3</xref>). We also observed significant clusters showing an interaction between perceptual switch and information direction (p&lt;0.01), showing stronger integration when the percept switched to integrated as compared to differentiated, and more so in the feedback than feedforward direction (<xref ref-type="fig" rid="F4">Figure 4C</xref>).</p><p id="P24">Finally, we analyzed the dynamics of information differentiation during the no-report condition. Again, no robust diff-INFO temporal clusters were observed when testing the entire time window -2000 to 500 ms around the OKN crossing between perceptual switches neither in the front nor in the back ROIs (<xref ref-type="fig" rid="F4">Figure 4D</xref>). Taken together, these results indicate that directed information distinguishes visual contents even in the absence of explicit report, while information differentiation in anterior locations is dependent upon report.</p></sec><sec id="S8"><title>Eye movements cannot explain the observed neural effects</title><p id="P25">We would like to note that the observed EEG effects are unlikely to be the result of differences in eye-movement signals between conditions for several reasons. First, measures of neural differentiation were specific to the report-locked analyses, although similar eye-movement patterns were present in all conditions. Second, the difference in the directionality of the dir-INFO effects (presence of a dir-INFO effect in the feedback but not feedforward direction, no effects for temporal electrodes) indicates that general eye-movement confounds are also not likely. Third, OKN signals gradually change over time over a period of 2 seconds leading up to the perceptual switch, with highly similar time courses for both types of percepts (see <xref ref-type="fig" rid="F1">Figure 1C</xref>)). The neural effects we observed do not reflect such a gradual build-up and differ based on the perceived content which differs from what one would expect based on the pattern of the OKN signals. Fourth, it is also unlikely that eye-related signals (e.g. muscle activity) get somehow embedded in the EEG recordings and drive our anterior-to-posterior effects. The idea would be that if this signal is first measured on frontal and then on posterior electrodes, transfer entropy or source conduction would increase measures of directed information flow. This interpretation is unlikely given that we did not observe any differences in OKN signals when comparing to INT and to DIFF periods in the time window 1200 to 500 ms before the button press, where we observed the differences in our neural measures in the report condition (<xref ref-type="fig" rid="F1">Figure 1C</xref>; dependent-samples t-test (to INT, to DIF): t<sub>1,39</sub>=0.093; p=0.926; BF<sub>01</sub>=5.77). Fifth, when the eyes change their direction maximally, that is at the zero crossings where the derivative of the slope is largest (<xref ref-type="fig" rid="F1">Figure 1C</xref>), or when the eyes most strongly indicate a certain perceptual state (at the peak of the OKN signal in <xref ref-type="fig" rid="F1">Figure 1C</xref>), dir-INFO in the feedback direction was not maximal. If the eyes drive the neural effects, a peak in dir-INFO would be expected. Finally, and most importantly, we have re-analyzed a previously published dataset in which we used an auditory bistable stimulus in combination with EEG measurements (<xref ref-type="bibr" rid="R27">27</xref>). In that study, participants listened to a sequence of tones and indicated with a button press whether they experienced either a single stream (perceptual integration) or two parallel streams (perceptual differentiation) of sounds. In that dataset, there were no systematic associations between eye movements and perceptual switches due to the auditory nature of the task. In <xref ref-type="supplementary-material" rid="SD1">Figure S4</xref> we report the dir-INFO analysis showing a highly similar pattern of results as reported here for bistable visual stimuli. Again, we observed increased dir-INFO leading up to integrated percepts, and uniquely in the feedback direction (see <xref ref-type="supplementary-material" rid="SD1">Figure S4</xref> for details). Together, these considerations and additional results from auditory bistability indicate that the results observed here are unlikely to be caused by incidental differences in eyemovement patterns between conditions or perceptual states.</p></sec><sec id="S9"><title>Time-frequency characteristics of perceptual switches</title><p id="P26">To compare the integration and differentiation results with more traditional electrophysiological features of multistable perception, we computed the time-frequency profile of perceptual switches to the differentiated and integrated percepts in <xref ref-type="fig" rid="F5">Figure 5</xref> (using cluster-based corrections for multiple comparisons). We observed increased oscillatory power in a broad frequency band from 1 to 18 Hz at frontal electrode sites, preceding a perceptual transition to an integrated compared to a differentiated percept. This was only observed in the button press locked analyses of the report condition, not in any of the other conditions. Interestingly, the same pattern of results was observed in the frontal complexity measure (diff-INFO) (<xref ref-type="fig" rid="F2">Figure 2D,E</xref>). Complexity measures have been linked to changes in frequency dynamics (<xref ref-type="bibr" rid="R42">42</xref>), and in particular, an increase in low-frequency power can increase the redundancy in neural signals, decreasing information complexity (<xref ref-type="bibr" rid="R43">43</xref>; <xref ref-type="bibr" rid="R44">44</xref>; <xref ref-type="bibr" rid="R45">45</xref>). Accordingly, we observed that in the time window that overlaps both measures (from -1050 ms before the response onset), the decrease in complexity negatively correlated with time-frequency power (Pearson’s r=-0.39; p=0.013). We return to this result in our Discussion.</p></sec></sec><sec id="S10" sec-type="discussion"><title>Discussion</title><p id="P27">Perceptual rivalry is the phenomenon that the perceptual interpretation of a bistable visual stimulus alternates over time in the absence of physical changes in the presented sensory input. The use of perceptual rivalry, as a tool, has provided fundamental insight into what neural processes may reflect the content of our conscious experience. However, although great progress has been made in unraveling neural processes underlying the competition between neural representations and the perceptual change between alternative percepts, it has proven notoriously difficult to separate neural correlates of perceptual switches, from processes that have another origin and are associated, for instance, with report, attention, surprise or commitment to a decision (<xref ref-type="bibr" rid="R8">8</xref>; <xref ref-type="bibr" rid="R9">9</xref>). Here we aimed to tackle this issue using an experimental set-up that contained four crucial ingredients. First, we experimentally introduced conditions in which perceptual switches were task-relevant and had to be reported about, versus conditions in which perceptual transitions were irrelevant and bistable stimuli just had to be viewed passively (<xref ref-type="bibr" rid="R23">23</xref>; <xref ref-type="bibr" rid="R25">25</xref>; <xref ref-type="bibr" rid="R46">46</xref>). Second, we relied on neural measures with millisecond temporal resolution, allowing us to pinpoint the relevant neural processes as they evolve over time. Third, we capitalized on novel information-based measures that have been shown to reflect the phenomenology of conscious perception (<xref ref-type="bibr" rid="R33">33</xref>; <xref ref-type="bibr" rid="R27">27</xref>), allowing us to track specific perceptual content over time, while it naturally alternates. Fourth and finally, we introduced a novel way to analyze eye-tracking data to be able to pinpoint when precisely in time perceptual interpretations alternate, allowing us to time-lock our analysis to focus on processing leading up to the perceptual change (times prior to OKN crossing), from processing involved in translating perception into action, as well as other cognitive confounds arising after the perceptual switch (times after OKN, prior to button-press). This effort has led to several novel results and conclusions, which are summarized below.</p><p id="P28">We showed that perceptual switches can systematically be inferred from eye-movement measurements during passive viewing of a bistable visual stimulus by capitalizing on OKN measures in combination with deep neural network modeling. This confirms previous work that has shown that OKN and pupil measures can act as reliable indicators of the dynamics of perceptual and binocular rivalry (<xref ref-type="bibr" rid="R25">25</xref>; <xref ref-type="bibr" rid="R28">28</xref>; <xref ref-type="bibr" rid="R26">26</xref>). In fact, percept durations varied commonly during experimental blocks in which perceptual switches had to be reported, and were therefore taskrelevant, and blocks in which observers passively viewed the bistable stimulus (perceptual switches are task-irrelevant). In both conditions, the observer’s percept durations followed a right-skewed gamma distribution as has been observed previously across a wide range of bistability paradigms (<xref ref-type="bibr" rid="R31">31</xref>), suggesting that the phenomenology of perception was similar during active report and passive viewing. Next, we showed that when the perception of a bistable stimulus was explicitly reported, directed information from anterior to posterior signals was increased before the observers reported perceiving the integrated stimulus (one plaid moving upwards) compared to when the differentiated percept was reported. Note that although the posterior signals were not the source but the receiver of the information flow, posterior signals were still involved in the processing of the percept as the feedback pattern only emerged due to the statistical relationship between anterior and posterior signals. A different situation was observed when signals were analyzed in isolation using the information differentiation metric. Thus, before the percept was reported as differentiated (two stimuli, each moving sideways in a different direction), we observed higher information differentiation of anterior signals, as compared to integrated percepts, before the perceptual switch indicated by the button press. This effect was not observed on posterior sensors. These results indicate that our informationbased measures derived from electrophysiological activity capture and track the phenomenology of the percept during perceptual ambiguity. These results are in agreement with our previous report-based study on auditory bistable perception showing a correspondence between perceptual integration and differentiation and neural metrics of information integration and differentiation (<xref ref-type="bibr" rid="R27">27</xref>). During report, when dir-INFO is high an integrated percept is likely to be perceived, whereas when diff-INFO is high, a differentiated percept is more likely to be perceived.</p><p id="P29">When perceptual changes were inferred from eye movements during passive viewing, we observed that our directed integration measure still tracked the perceptual state of the observer, but uniquely so in the feedback direction (from anterior to posterior signals). However, information differentiation measures no longer tracked the evolving percept, suggesting that our differentiation measures may reflect other processes not directly linked to perception, such as differences in task set or for example differences in attention due to the necessity to report. In sum, the relative strength of directed information in the feedback direction indicated which percept likely dominated during passive viewing, whereas neural differentiation does not. We would like to note that this means that directed information is thus a “symmetrical measure” in the sense that when it is high it reflects that an integrated percept is likely to be dominant, whereas when it is low, a differentiated stimulus is likely dominating perception.</p><p id="P30">During ambiguous perception (e.g. bistability, rivalry), feedback connections are thought to be critical for the comparison of internally generated predictions of sensory input with actual inputs (<xref ref-type="bibr" rid="R20">20</xref>; <xref ref-type="bibr" rid="R18">18</xref>). Based on the neurobiology of feedback connections, they are vastly more numerous and divergent than feedforward ones, i.e. fewer neurons project in a feedforward manner, compared to a feedback one (<xref ref-type="bibr" rid="R47">47</xref>). We believe this dominance of feedback signals may account for the increase in directed information we observed prior to perceiving the integrated (vertical) motion percept (<xref ref-type="fig" rid="F2">Figure 2A</xref>, <xref ref-type="fig" rid="F3">3A</xref>, <xref ref-type="fig" rid="F4">4A</xref>). More specifically, for our bidirectional plaid stimulus, perceiving an integrated percept of unified vertical motion required the holistic combination of local signals across the visual field. Thus, for perceptual integration, local signals from low-level areas may have required enhanced feedback modulations from higher areas to integrate visual information across space (<xref ref-type="bibr" rid="R48">48</xref>). This integration can be seen as hypothesis testing in which the high-level interpretation can inform the low-level features where feedback projections are considered to enhance neural activity (<xref ref-type="bibr" rid="R49">49</xref>; <xref ref-type="bibr" rid="R50">50</xref>; <xref ref-type="bibr" rid="R51">51</xref>). Supporting this view, recent studies on binocular rivalry have shown that PFC neurons increase their firing rate before the occurrence of perceptual switches both in monkeys (<xref ref-type="bibr" rid="R29">29</xref>) and humans (<xref ref-type="bibr" rid="R52">52</xref>). In the case of multiunit activity (MUA) recordings in humans, increased frontal activation precedes the activity of lower areas such as MT, suggesting that the frontal cortex biases sensory information in the lower areas towards one of the two perceptual contents in a top-down feedback manner (<xref ref-type="bibr" rid="R52">52</xref>). Thus, our results are in agreement with this prior research, as stronger top-down modulation preceded the integrated interpretation of our bistable plaid stimulus.</p><p id="P31">It is important to stress that we used information-specific EEG measures, which allowed us to track the contents of rivalrous states while quantifying the directionality of integration for our observers. This approach is similar to previous binocular rivalry studies using for instance alternating face/house stimuli and isolating (the competition between) neural activity in feature or category-selective brain regions, either using electrophysiology (<xref ref-type="bibr" rid="R20">20</xref>) or fMRI (<xref ref-type="bibr" rid="R16">16</xref>; <xref ref-type="bibr" rid="R53">53</xref>). The use of these EEG information-based measures enabled us to track the neural signatures of the content of perception with high temporal precision before perception alternated, similar to influential electrophysiological studies using feature-specific neural responses (<xref ref-type="bibr" rid="R12">12</xref>; <xref ref-type="bibr" rid="R54">54</xref>; <xref ref-type="bibr" rid="R29">29</xref>; <xref ref-type="bibr" rid="R52">52</xref>). Due to the low temporal resolution of the BOLD signal, to be able to isolate the neural cause of perceptual switches during rivalry, previous fMRI studies have often included a replay condition with yoked switches that are simulated using video replay. These replay trials mimic perceptual switches but have no neural cause as they are not driven by fluctuations in brain activity. fMRI studies have shown that the dorsolateral prefrontal cortex (dlPFC) activates stronger for perceptual switches during rivalry (as compared to baseline), and often also activates stronger during rivalry than during replay (<xref ref-type="bibr" rid="R31">31</xref>; <xref ref-type="bibr" rid="R25">25</xref>; <xref ref-type="bibr" rid="R7">7</xref>; <xref ref-type="bibr" rid="R46">46</xref>; <xref ref-type="bibr" rid="R55">55</xref>). Frässle and colleagues showed that when comparing rivalry to replay conditions, there was an increase in dlPFC activity when actively reporting on perceptual changes. However, the difference between rivalry and replay diminished in pre-frontal areas during passive viewing (<xref ref-type="bibr" rid="R25">25</xref>), suggesting that actively reporting on rivalry recruits additional prefrontal resources compared to reporting on replay, which is not required for passively experiencing a change in percept (see also e.g. (<xref ref-type="bibr" rid="R16">16</xref>)). Similarly, Brascamp and colleagues (<xref ref-type="bibr" rid="R31">31</xref>) have shown that prefrontal activation in fMRI (or in their words “responses in executive brain areas” in general) may be driven by the fact that perceptual switches often draw attention (possibly because they are surprising and relevant) and require report, but are not related to perceptual transitions per se. They have shown this by designing a task in which switches in perception between two stimuli (dots moving in different directions in the two eyes) could go unnoticed by observers, as if these switches were preconscious (potentially accessible but not actually accessed) (<xref ref-type="bibr" rid="R56">56</xref>). Although these switches remained unnoticed to the participants, sensory brain regions still showed neural activity patterns associated with those switches, whereas switch-related modulations in executive areas were minimized (although still numerically higher than baseline). Based on such results it has been argued that PFC involvement during rivalry may potentially be related to report, or other consequences of perceptual switches, but that the PFC does not drive those switches (<xref ref-type="bibr" rid="R25">25</xref>). Interestingly, our information differentiation (diff-INFO) results also suggest that frontal information differentiation may reflect processing associated with report rather than perception per se. In the report condition, we found that reporting the stimulus as integrated took longer than reporting it as differentiated, indicative of a task-dependent increase in the cognitive demand of disambiguating the stimulus identity. It may be that these differences can explain the frontal information differentiation effect observed during the report of perceptual switches, compared to the absence of this effect during the passive viewing condition. Knapen and colleagues (<xref ref-type="bibr" rid="R7">7</xref>) showed that large parts of the prefrontal network, again especially dorsolateral PFC, activate stronger perceptual transitions with longer durations, so when the system takes longer to settle in a particular perceptual state (the transition phase between interpretations is longer) than when the transition phase is shorter. Finally, a recent study (<xref ref-type="bibr" rid="R18">18</xref>) has shown that transcranial stimulation of the right inferior frontal cortex (IFC) reduced the occurrence of perceptual changes for bistable stimuli when they had to be actively reported (see also (<xref ref-type="bibr" rid="R57">57</xref>) for similar results while stimulating the DLPFC). The authors argued that the IFC may register perceptual conflicts (or the mismatch/prediction error signal) between two possible perceptual interpretations, gradually building up towards the perceptual switch. Therefore, the IFC may be influencing the competition between pools of neurons coding for the different percepts in the visual cortex, thereby “steering” or “co-determining” conscious perception (<xref ref-type="bibr" rid="R19">19</xref>). Our front-to-back dir-INFO results are more in line with this latter finding, suggesting that even during no report conditions, subtle influences from frontal signals co-determine perceptual switches during visual bistability (and report-based auditory bistability (<xref ref-type="supplementary-material" rid="SD1">Figure S4</xref>), but see (<xref ref-type="bibr" rid="R57">57</xref>)).</p><p id="P32">The experiment designed here can be regarded as a so-called “no-report paradigm” and not the stricter “no-cognition paradigm”, because in principle when one eliminates any type of explicit report, this does not necessarily remove all possible processes prior to reporting that could happen throughout the experiment (<xref ref-type="bibr" rid="R5">5</xref>). Observers may still reason, think or reflect about the presented bistable stimulus and perceptual alternations. This issue is similar to previous attempts to minimalize cognitive processes during perceptual rivalry (<xref ref-type="bibr" rid="R23">23</xref>; <xref ref-type="bibr" rid="R25">25</xref>; <xref ref-type="bibr" rid="R46">46</xref>). In our experiment, the crucial aspect is that perceptual switches were task-irrelevant during the passive viewing condition and task-relevant during the report condition (<xref ref-type="bibr" rid="R58">58</xref>). We cannot and did not control what observers were doing during passive viewing and therefore do not know whether and how observers were reasoning about the perceived stimulus or the occurrence of perceptual switches. Therefore, we only intended to arbitrate between task/report-related and perception-related information-based measures of perceptual transitions. Interestingly, using a similar set-up, combining OKN measures with manipulation of task-relevance of perceptual switches, it has recently been shown that also in the pupil response, task/report and perception-related dilations and constrictions can be separated (<xref ref-type="bibr" rid="R23">23</xref>). Finally, a cautionary note on the experimental design is that it is possible that participants were preparing an overt response in both conditions, but just withheld their response in the no-report condition. This may be a consequence of alternating blocks, in which we chose to equate the conditions as much as possible (e.g. match rates of perceptual learning, fatigue, and drowsiness over time between conditions). It is possible that perceptual changes were attended to in the no-report blocks, although they were not task-relevant.</p><p id="P33">We note, however, that we also observed frontal theta-band power increases uniquely in manual report conditions – supporting the separation between report and no-report states in our design. Frontal-central theta power has often been related to the processing of conflict, both at the level of stimuli as well as for conflicting stimulus-response mappings (<xref ref-type="bibr" rid="R59">59</xref>; <xref ref-type="bibr" rid="R60">60</xref>). In the time-frequency response-locked analyses we observed increased theta-band power leading up to the integrated compared to differentiated percept, as well as longer reaction times between OKN crossings and report. This pattern of results was in agreement with the analysis of information differentiation in the report condition (<xref ref-type="fig" rid="F2">Figure 2D</xref>), which was also only observed in the response-locked analyses. Combined, these results suggest that there may be additional differences between reporting an integrated and differentiated percept, that are contingent on subjective conflict, an exciting possibility for future research that may unify mechanisms of perceptual and cognitive decision-making (<xref ref-type="bibr" rid="R61">61</xref>).</p><p id="P34">Despite much debate in the field, influential theories of consciousness (<xref ref-type="bibr" rid="R62">62</xref>), such as Global Neuronal Workspace theory, Recurrent Processing theory, and Integrated Information Theory, agree that the common property of conscious experience relates to the brain’s capacity to integrate information through recurrent processing (the combination of lateral and feedback interactions), enhancing cortico-cortical interactions at a local scale (between nearby regions) or global scale (between distant regions) (<xref ref-type="bibr" rid="R63">63</xref>; <xref ref-type="bibr" rid="R64">64</xref>; <xref ref-type="bibr" rid="R65">65</xref>). Note that such consciousness theories are mostly concerned with explaining which neural processes can be observed when sensory information “crosses the threshold” from subliminal (unconscious) to phenomenal or access consciousness, and thus aim to isolate the necessary ingredients constituent to conscious experience. Instead, we focus here on which neural processes influence the competition between alternative interpretations of ambiguous visual input (see (<xref ref-type="bibr" rid="R19">19</xref>)) for a short review of this difference). In light of that latter debate, we show that the amount of directed information flow between anterior to posterior electrodes reflects the likelihood of perceiving the integrated version of an ambiguous stimulus during perceptual ambiguity, even in a context where report is not required. The low spatial resolution of our EEG measurements, however, precludes any claims about the specific origins of these observed feedback signals and future studies are needed to obtain more spatial specificity as well as a more mechanistic explanation of the neural processes the directed information measure reflects.</p><p id="P35">In conclusion, our results suggest that the relevant dynamical mechanism for perceiving different contents during visual bistability, controlling for many factors associated with reporting perception, is the directed information between frontal and posterior signals, rather than the isolated information differentiation contained within the front or the back of the brain.</p></sec><sec id="S11" sec-type="methods"><title>Methods</title><sec id="S12" sec-type="subjects"><title>Participants</title><p id="P36">Forty-two participants (31 females, 2 left-handed) aged between 18 and 35 (M = 20 years, SD = 3.73), recruited from the University of Amsterdam (Amsterdam, the Netherlands) participated in this study for monetary compensation. All participants had a normal or corrected-to-normal vision. The study was approved by the institutional review board (IRB) of the Psychology department of the University of Amsterdam (project ID: BC-8686), and written informed consent was obtained from all participants after the explanation of the experimental protocol. One participant was excluded during data collection for not following the task instructions. Another participant was excluded during the analyses because of very strong artifacts in the EEG data.</p></sec><sec id="S13"><title>Stimulus</title><p id="P37">The stimulus consisted of two overlapping semi-transparent half-wave gratings, known as ambiguous plaids or moving plaids (<xref ref-type="bibr" rid="R66">66</xref>; <xref ref-type="bibr" rid="R67">67</xref>; <xref ref-type="bibr" rid="R22">22</xref>). Each grating was a sinusoid (0.33 cycles per degree of visual angle), clipped to include only positive contrast luminance, positioned at the center of an aperture (diameter = 36.03). Peak contrast was set to 0.025 relative to the uniform grey background. The encoding gamma was set to 2. The orientation of each grating was 15° and -15°. Motion was created by changing the phase of the grating on each frame (6 Hz motion).</p><p id="P38">We selected this specific stimulus for three reasons. Firstly, the stimulus is ambiguous, meaning that perception alternates whilst the sensory input remains constant. This approach is considered to be one of the most powerful methodologies to study the neural underpinnings of phenomenal consciousness (<xref ref-type="bibr" rid="R9">9</xref>). Secondly, the stimulus can be perceived as one grating moving coherently or two gratings sliding across one another. In other words, gratings are either perceptually integrated or perceptually differentiated, respectively. Note that the ambiguous plaids stimulus is considered to be tristable (rather than bistable) because it has one integrated percept (the gratings moving together as a single pattern) and two differentiated percepts (the gratings sliding across one another) with alternating depth order (which grating is perceived as foreground and which as background) (<xref ref-type="bibr" rid="R66">66</xref>). However, we treat the stimulus as if it were bistable because we instruct participants to respond to changes from the integrated percept to the differentiated percept and vice versa. The last reason for using this stimulus is that it allows us to track perception in the absence of responses by exploiting the occurrence of optokinetic nystagmus (OKN) (<xref ref-type="bibr" rid="R68">68</xref>; <xref ref-type="bibr" rid="R25">25</xref>; <xref ref-type="bibr" rid="R26">26</xref>).</p></sec><sec id="S14"><title>Experimental design and procedure</title><p id="P39">There were two experimental conditions (i.e. report and no-report) that were performed in alternating runs of four minutes each (<xref ref-type="fig" rid="F1">Figure 1A</xref>). Participants performed twenty runs in total, split up into five blocks consisting of two runs of each condition. The order within the blocks was always the same and started with a no-report run (i.e. no-report, report, no-report, report). Note that the same stimulus was used for both conditions and that the stimulus was constant throughout each run. Only the direction of motion of the stimulus (i.e. upwards or downwards) was changed every two runs in order to exclude the direction of the stimulus as a confounding factor (<xref ref-type="fig" rid="F1">Figure 1A</xref>). During the report runs, participants were instructed to press one button when the percept changed from vertical movement to horizontal movement and another button to indicate changes from horizontal movement to vertical movement (<xref ref-type="fig" rid="F1">Figure 1B,C</xref>) (i.e. 2AFC). The buttons were operated with the index fingers of both hands and the contingencies of the buttons were counterbalanced across participants. During the no-report runs, participants were instructed to remain focused on the stimulus at all times and to relax their hands on the desk in front of them (i.e. passive viewing of the stimulus). Throughout the experiment, participants remained unaware of the relationship between perception and eye movements, and they were not informed about the influence of OKN on their perceptual state.</p><p id="P40">The experiment was programmed and executed using the Psychophysics Toolbox (version 3.0.14; Brainard, 1997) and Eyelink Toolbox extensions (Cornelissen, Peters, and Palmer, 2002) for MATLAB (R2016a, MathWorks, Inc., Natick, MA, US). Stimuli were presented on an Asus VG236H LCD monitor (23” diagonal, 1920 x 1080 pixel resolution; 120 Hz refresh rate) at a viewing distance of 50 cm.</p></sec><sec id="S15"><title>Electroencephalography (EEG) recording and preprocessing</title><p id="P41">EEG signals were acquired through a 64-channel Biosemi ActiveTwo system (Biosemi, Amsterdam, the Netherlands) with two online references (CMS and DRL) placed according to the international 10-20 system. Two external electrodes were placed on the earlobes for possible use as offline references. Four additional external electrodes were used to record vertical and horizontal eye movements, adding up to 72 channels in total. Data were sampled at 512 Hz. Preprocessing was done by means of custom-made MATLAB (R2016a, The MathWorks, Inc.) scripts supported by EEGLAB (<xref ref-type="bibr" rid="R69">69</xref>). Continuous EEG data were first down-sampled to 250 Hz and filtered between 1-100 Hz. Data from the 64 channels over the scalp surface (i.e. reference electrodes and external electrodes excluded) were retained for further analyses. All twenty runs were extracted and subsequently appended in order to eliminate the time periods between runs in which no stimulus was present. Channels with a variance smaller than -2 or larger than 2 standard deviations (SD) of the mean activity of all channels were rejected and a notch filter of 50 Hz was applied to remove the line noise.</p><p id="P42">Independent Component Analysis (ICA) (<xref ref-type="bibr" rid="R69">69</xref>) was performed over all remaining channels. Independent components representing eye blinks, eye movements, muscle artifacts, and other types of noise were removed from the EEG signal after which the signals from the previously rejected channels were replaced with the weighted average activity in all remaining channels by spherical spline interpolation. Subsequently, the data were separated into separate datasets containing the report and no-report runs for each participant. The report dataset was segmented into epochs from -2000 to 500 ms around responses. Epochs with response repetitions and epochs that contained more than one response were rejected (22.30% of epochs on average). Finally, epochs were rejected if they exceeded certain thresholds for amplitude (&lt;-150 <italic>μV</italic> or &gt;150 <italic>μV</italic>) or slope (&gt;60 <italic>μV</italic>/epoch), and the data were referenced to the average activity in all channels.</p></sec><sec id="S16"><title>Eye-tracking recording</title><p id="P43">Eye movements were recorded at 500 Hz with an EyeLink 1000 (SR Research) infrared eye tracker, calibrated using a 6-point calibration procedure at the start of every block (i.e. five times throughout data collection). During the blocks, participants’ heads were positioned on a chin rest in order to minimize head movements.</p></sec><sec id="S17"><title>Optokinetic nystagmus (OKN) signal analysis</title><p id="P44">OKN is a combination of slow-phase and fast-phase eye movements that allows the eyes to follow objects in motion when the head remains stationary, for instance when looking at the trees alongside the road whilst moving past them in a car. The slow-phase movements try to match the stimulus speed to keep the retinal image stable and are interrupted by fast eye movements that reset the eye in orbit. Thus, the velocity of slow-phase OKN provides a continuous and robust estimate of conscious perception rather than the actual visual input, which makes it useful for assessing perception in the absence of reports (<xref ref-type="bibr" rid="R70">70</xref>; <xref ref-type="bibr" rid="R25">25</xref>; <xref ref-type="bibr" rid="R28">28</xref>; <xref ref-type="bibr" rid="R71">71</xref>; <xref ref-type="bibr" rid="R26">26</xref>). From the eye movement data, we obtained mean slow-phase OKN velocity and classification accuracy of percepts based on this signal. We performed the following pre-processing steps to obtain the velocity of slow-phase OKN.</p><p id="P45">First, periods of blinks and saccades were detected using the manufacturer’s standard algorithms with default settings. The subsequent data analyses were performed using custom-made Python software. The following steps were applied to each pupil recording: (i) linear interpolation of values measured just before and after each identified blink (interpolation time window, from 150 ms before until 150 ms after blink), (ii) temporal filtering (third-order Butterworth, low-pass: 10 Hz), (iii) removal of pupil responses to blinks and to saccades, by first estimating these responses by means of deconvolution, and then removing them from the pupil time series by means of multiple linear regression (<xref ref-type="bibr" rid="R7">7</xref>), and (iv) conversion to units of modulation (percent signal change) around the mean of the pupil time series from each block.</p><p id="P46">Second, we smoothed the integrated OKN with a 100 ms Gaussian kernel. We then computed the instantaneous velocity of integrated OKN as the difference between neighboring two-time points (2 ms difference). To obtain the velocity of the slow-phase OKN, we further smoothed the instantaneous velocity with the 100 ms Gaussian kernel. Finally, we segmented the time course of the velocity of slow-phase OKN from 1 s before to 2 s after the onset of stimuli. We did not include the first trial of each block in the analysis as we did not record the fixation position before the first trial.</p></sec><sec id="S18"><title>Convolutional Neural Network (CNN) classification on button press and OKN</title><p id="P47">First, to quantify the discriminability of perceptual report in OKN and button press in the report condition, we employed a convolutional neural network (CNN) with the instantaneous velocity of slow-phase OKN as a feature (Figure ??C,D). The CNN consisted of the following layers in sequence:</p><p id="P48">A 1D input layer of dimension 1 X 625 units, matching the shape of an epoch of smoothed OKN sampled at 500 Hz.</p><p id="P49">A convolutional layer consisting of 8 convolutional filters, each with the shape 1 x 25. Units in this layer used ReLU activation functions. The stride step size of the convolution over the inputs was set to 1.</p><p id="P50">A max pooling layer with the shape 1 x 5, and a stride step size of 2.</p><p id="P51">A second convolutional layer with 16 convolutional filters, each with the shape 2 x 50. Units used ReLU activation functions and the stride step size of the convolution over the inputs was set to 1.</p><p id="P52">Another max pooling layer with the shape 1 x 5 and stride step size of 2.</p><p id="P53">A third (and final) convolutional layer with 32 convolutional filters, each with the shape 2 x 75. Units used ReLU activation functions and the stride step size of the convolution over the inputs was set to 1.</p><p id="P54">A fully connected dense layer of shape 1 x 2, consisting of units with softmax activation functions.</p><p id="P55">To prevent overfitting and measure the generalisation performance of the CNN, we first split the OKN data epochs, and their corresponding button press labels into 3 parts: training, validation and testing. 70% of the entire dataset consisting of 13,406 epochs was allocated to the training set. The remaining 30% were further split equally to create validation and test datasets, each containing 15% of the original data and labels. We used stratified sampling when creating these splits, to ensure that the relative proportion of samples of each class was the same in each split.</p><p id="P56">The CNN was then trained using the training set, with a minibatch size of 128, over 30 epochs. We randomly shuffled the training dataset at the beginning of each epoch and evaluated the CNN’s performance on the validation dataset once every 10 mini-batches. The stochastic gradient descent algorithm with a momentum of 0.9 was used to learn the weights that minimised the cross-entropy loss over the training dataset. At the end of the training procedure, we recorded the accuracy with which the trained CNN classified OKN epochs in the held-out test dataset.</p><p id="P57">The above procedure – including CNN training, validation, and testing— was repeated, after defining epoch labels based on the OKN crossings in the report condition. Finally, we retrained and evaluated the CNN by defining epoch labels based on the OKN crossings in the no-report condition (<xref ref-type="fig" rid="F1">Figure 1</xref>).</p></sec><sec id="S19"><title>Directed Information (dir-INFO)</title><p id="P58">In order to quantify the directed functional connectivity between different EEG signals, we used Directed Information (dir-INFO), also known as Transfer Entropy, an information theoretic measure of Wiener-Granger causality (<xref ref-type="bibr" rid="R72">72</xref>; <xref ref-type="bibr" rid="R73">73</xref>; <xref ref-type="bibr" rid="R74">74</xref>). Compared to traditional causality detection methods based on linear models (e.g. Granger causality), dir-INFO is a model-free measure and can detect both linear and nonlinear functional relationships between brain signals. We took advantage of previous work that made this measure statistically robust when applied to neural data (<xref ref-type="bibr" rid="R75">75</xref>; <xref ref-type="bibr" rid="R36">36</xref>; <xref ref-type="bibr" rid="R33">33</xref>; <xref ref-type="bibr" rid="R37">37</xref>).</p><p id="P59">Thus, dir-INFO quantifies functional connectivity by measuring the degree to which the past of a signal <italic>X</italic> predicts the future of another signal <italic>Y</italic>, conditional on the past of <italic>Y</italic>, defined at a specific lag or delay τ: dir-INFO = <italic>I</italic>(<italic>Y<sub>t</sub></italic>; <italic>X<sub>t-τ</sub></italic>|<italic>Y<sub>t-τ</sub></italic>). Thus, if there is significant dir-INFO between EEG signal <italic>X</italic> at one time, and EEG signal <italic>Y</italic> at a later time, this shows that signal <italic>X</italic> contains information about the future signal <italic>Y</italic>. Conditioning out the past of signal <italic>Y</italic> ensures the delayed interaction is providing new information over and above that available in the past of signal <italic>X</italic>. For all dir-INFO analyses, we tested delays from 0 ms to 500 ms in steps of 4 ms.</p></sec><sec id="S20"><title>Information Differentiation (diff-INFO)</title><p id="P60">We computed Kolmogorov-Chaitin complexity (K complexity) as a metric of information differentiation (<xref ref-type="bibr" rid="R76">76</xref>; <xref ref-type="bibr" rid="R77">77</xref>). K complexity quantifies the algorithmic complexity (i.e. the diversity of information patterns) of an EEG signal by measuring its degree of redundancy: from a highly redundant signal (i.e. less differentiated signal) to a slightly redundant one (i.e. highly differentiated signal) (<xref ref-type="bibr" rid="R27">27</xref>; <xref ref-type="bibr" rid="R38">38</xref>; <xref ref-type="bibr" rid="R39">39</xref>; <xref ref-type="bibr" rid="R40">40</xref>). Algorithmic complexity of a given EEG sequence can be described as the length of the shortest computer program that can generate it. A short program corresponds to a less complex sequence. K complexity was estimated by quantifying the compression size of the EEG using the Lempel-Ziv zip algorithm (<xref ref-type="bibr" rid="R78">78</xref>).</p><p id="P61">Algorithmic information theory has been introduced by Andrï Kolmogorov and Gregory Chaitin as an area of interaction between computer science and information theory. The concept of algorithmic complexity or Kolmogorov-Chaitin complexity (K complexity) is defined as the shortest description of a string (or in our case a signal <italic>X</italic>). That is to say, K complexity is the size of the smallest algorithm (or computer program) that can produce that particular time series. However, it can be demonstrated by reductio ad absurdum that there is no possible algorithm that can measure K complexity (<xref ref-type="bibr" rid="R79">79</xref>). To sidestep this issue, we can estimate an upper-bound value of K complexity(<italic>X</italic>). This can be concretely accomplished by applying a lossless compression of the time series and quantifying the compression size. Capitalizing on the vast signal compression literature, we heuristically used a classical open-source compressor gzip (<xref ref-type="bibr" rid="R80">80</xref>) to estimate K complexity (<italic>X</italic>). It is important to standardize the method of representation of the signal before compression in order to avoid irrelevant differences in complexity. Specifically, to compute K complexity(<italic>X</italic>):</p><p id="P62">First, the signals were transformed into sequences of symbols. Each symbol represents, with identical complexity, the amplitude of the corresponding channel for each time point. The number of symbols was set to 32 and each one corresponds to dividing the amplitude range of that given channel into 32 equivalent bins. Similar results have been obtained with binning ranging from 8 to 128 bins (<xref ref-type="bibr" rid="R40">40</xref>). Next, time series were compressed using the compressLib library for Matlab, this library implements the gzip algorithm to compress Matlab variables.</p><p id="P63">Finally, K complexity(<italic>X</italic>) was calculated as the size of the compressed variable with time series divided by the size of the original variable before compression. Our premise is that the bigger the size of the compressed string, the more complex the structure of the time series, thus indexing the complexity of the electrical activity recorded at an electrode. For each trial and ROI, K complexity was estimated using a 100 ms sliding window with a 4 ms time step.</p></sec><sec id="S21"><title>EEG time-frequency analysis</title><p id="P64">Epochs were grouped based on conditions: report, report (OKN), and no report (OKN). Then, EEG traces were decomposed into time-frequency charts from 2 Hz to 26 Hz in 13 linearly spaced steps (2 Hz per bin). The power spectrum of the EEG signal (as obtained by the fast Fourier transform) was multiplied by the power spectra of complex Morlet wavelets (<italic>e<sup>i2wtf</sup></italic> <italic>e</italic><sup>(−<italic>t</italic><sup>2</sup>/(2<italic>ζ</italic><sup>2</sup>)</sup>) with logarithmically spaced cycle sizes ranging from 3 to 12. The inverse Fourier transform was then used to acquire the complex signal, which was converted to frequency-band specific power by squaring the result of the convolution of the complex and real parts of the signal (<italic>real</italic>[<italic>z</italic>(<italic>t</italic>)]<sup>2</sup> + <italic>imag</italic>[<italic>z</italic>(<italic>t</italic>)]<sup>2</sup>). The resulting time-frequency data were then averaged per subject and trial type. Finally, timefrequency traces were transformed to decibels (dB) and normalized to the length of the entire trial (baseline: -2000ms to 500 ms) according to: <italic>dB</italic> = 10 ⋆ log<sub>10</sub>(power/baseline)</p></sec><sec id="S22"><title>EEG electrode selection (ROI)</title><p id="P65">Canonical bilateral frontal (n = 6), parietal (n = 6), as well as right temporal (n = 6) and left temporal (n = 6) electrode clusters were selected for dir-INFO and diff-INFO analyses (<xref ref-type="supplementary-material" rid="SD1">Figure S1</xref>). Values within each region of interest (ROI) were averaged before computing dir-INFO and diff-INFO metrics and subsequently averaged per condition and participant.</p></sec><sec id="S23"><title>Statistical analysis</title><p id="P66">To test for significant time-delay dir-INFO (<xref ref-type="fig" rid="F2">Figure 2</xref> and <xref ref-type="fig" rid="F3">3</xref>), and time-frequency spectral power (<xref ref-type="fig" rid="F5">Figure 5</xref>) a cluster-based nonparametric statistical test implemented in FieldTrip (Maris and Oostenveld 2007) was used. In brief, time-delay dir-INFO charts (-2000 to 500 ms) were compared in pairs of experimental conditions (perceptual switches: to INT vs. to DIFF). For each such pairwise comparison, epochs in each condition were averaged subject-wise. These averages were passed to the analysis procedure of FieldTrip, the details of which are described elsewhere (<xref ref-type="bibr" rid="R81">81</xref>). In short, this procedure compared corresponding temporal points in the subject-wise averages using dependent samples t-tests for within-subject comparisons. Although this step was parametric, FieldTrip uses a nonparametric clustering method to address the multiple comparisons problem. t values of adjacent temporal points whose p values were lower than 0.01 were clustered together by summating their t values, and the largest such cluster was retained. This whole procedure, i.e., calculation of t values at each temporal point followed by clustering of adjacent t values, was then repeated 1000 times, with recombination and randomized resampling of the subject-wise averages before each repetition. This Monte Carlo method generated a non-parametric estimate of the p-value representing the statistical significance of the originally identified cluster. The cluster-level t value was calculated as the sum of the individual t values at the points within the cluster.</p><p id="P67">In the case of dir-INFO (<xref ref-type="fig" rid="F2">Figure 2</xref> and <xref ref-type="fig" rid="F3">3</xref>, in order to test a possible interaction effect between information direction and perceptual switch, a separate cluster-based permutation test was calculated as the difference between perceptual switch (to INT, to DIFF) and direction of change (front-to-back, back-to-front).</p><p id="P68">Similarly, for diff-INFO analysis, we performed a cluster-based permutation test across the diff-INFO time series (-2000 to 500 ms) between perceptual switches for the front and back ROIs separately. Next, in order to test for an interaction between perceptual switch and direction of change, we performed another cluster-based permutation test on the difference between perceptual switch (to INT, to DIFF) and ROI (front, back).</p><p id="P69">In case of null findings, we performed a Bayesian RANOVA with identical parameters and settings on the same data, to test if there was actual support of the null hypothesis. When reported, BF01 refers to the Bayes Factor in favor of the null hypothesis. Statistical analyses were performed using MATLAB (2019a), Jamovi (Version 0.8.1.6) [Computer Software] (Retrieved from <ext-link ext-link-type="uri" xlink:href="https://www.jamovi.org/">https://www.jamovi.org</ext-link>) (open source), and JASP Team (2018; JASP; version 0.8.4 software) statistical software.</p></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary Figures</label><media xlink:href="EMS151844-supplement-Supplementary_Figures.pdf" mimetype="application" mime-subtype="pdf" id="d12aAdEbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S24"><title>Acknowledgements</title><p>We thank Dr. William J. Harrison, Dr. Maartje de Jong, Dr. William Gilpin, Dr. Martin Vinck, and Dr. Tomas Knapen for contributing to valuable discussions and insights and proofreading the manuscript. This manuscript is dedicated to the memory of Prof. Walter J. Freeman (1927 - 2016) whose pioneering work on Neurodynamics has inspired and ignited countless meaningful insights during the execution of this project.</p><sec id="S25"><title>Funding</title><p>This research was supported by an ABC Talent Grant of the University of Amsterdam (ACJ, SVG), a grant from the H2020 European Research Council (ERC STG 715605, SVG), and a BIAL Foundation Grant 2020/2021 (ID: A-29477, SVG, ACJ).</p></sec></ack><fn-group><fn id="FN1" fn-type="con"><p id="P70">Authorship contributions</p><p id="P71">Conceived and designed the experiments: ACJ, SVG. Performed the experiments: ACJ, LB. Analyzed the data: ACJ, MD. Contributed reagents/materials/analysis tools: RI, SC. Wrote the paper: ACJ, LB, SC, RI, MD, SVG.</p></fn><fn id="FN2" fn-type="conflict"><p id="P72">Conflict of Interest</p><p id="P73">None declared.</p></fn></fn-group><ref-list><ref id="R1"><label>[1]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Lau</surname><given-names>H</given-names></name><name><surname>Kouider</surname><given-names>S</given-names></name></person-group><article-title>What is consciousness, and could machines have it?</article-title><source>Science</source><year>2017</year><month>Oct</month><volume>358</volume><issue>6362</issue><fpage>486</fpage><lpage>92</lpage><pub-id pub-id-type="pmid">29074769</pub-id></element-citation></ref><ref id="R2"><label>[2]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Francken</surname><given-names>JC</given-names></name><name><surname>Beerendonk</surname><given-names>L</given-names></name><name><surname>Molenaar</surname><given-names>D</given-names></name><name><surname>Fahrenfort</surname><given-names>JJ</given-names></name><name><surname>Kiverstein</surname><given-names>JD</given-names></name><name><surname>Seth</surname><given-names>AK</given-names></name><etal/></person-group><article-title>An academic survey on theoretical foundations, common assumptions and the current state of consciousness science</article-title><source>Neurosci Conscious</source><year>2022</year><month>Aug</month><volume>2022</volume><issue>1</issue><elocation-id>niac011</elocation-id><pub-id pub-id-type="pmcid">PMC9374479</pub-id><pub-id pub-id-type="pmid">35975240</pub-id><pub-id pub-id-type="doi">10.1093/nc/niac011</pub-id></element-citation></ref><ref id="R3"><label>[3]</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Crick</surname><given-names>F</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name></person-group><chapter-title>Towards a neurobiological theory of consciousness</chapter-title><source>Seminars in the Neurosciences</source><publisher-name>Saunders Scientific Publications</publisher-name><year>1990</year><volume>2</volume><fpage>263</fpage><lpage>75</lpage></element-citation></ref><ref id="R4"><label>[4]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aru</surname><given-names>J</given-names></name><name><surname>Bachmann</surname><given-names>T</given-names></name><name><surname>Singer</surname><given-names>W</given-names></name><name><surname>Melloni</surname><given-names>L</given-names></name></person-group><article-title>Distilling the neural correlates of consciousness</article-title><source>Neurosci Biobehav Rev</source><year>2012</year><month>Feb</month><volume>36</volume><issue>2</issue><fpage>737</fpage><lpage>46</lpage><pub-id pub-id-type="pmid">22192881</pub-id></element-citation></ref><ref id="R5"><label>[5]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Block</surname><given-names>N</given-names></name></person-group><article-title>What is wrong with the no-report paradigm and how to fix it</article-title><source>Trends Cogn Sci</source><year>2019</year><month>Dec</month><volume>23</volume><issue>12</issue><fpage>1003</fpage><lpage>13</lpage><pub-id pub-id-type="pmid">31676213</pub-id></element-citation></ref><ref id="R6"><label>[6]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Storm</surname><given-names>JF</given-names></name><name><surname>Boly</surname><given-names>M</given-names></name><name><surname>Casali</surname><given-names>AG</given-names></name><name><surname>Massimini</surname><given-names>M</given-names></name><name><surname>Olcese</surname><given-names>U</given-names></name><name><surname>Pennartz</surname><given-names>CMA</given-names></name><etal/></person-group><article-title>Consciousness regained: Disentangling mechanisms, brain systems, and behavioral responses</article-title><source>J Neurosci</source><year>2017</year><month>Nov</month><volume>37</volume><issue>45</issue><fpage>10882</fpage><lpage>93</lpage><pub-id pub-id-type="pmcid">PMC5678021</pub-id><pub-id pub-id-type="pmid">29118218</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1838-17.2017</pub-id></element-citation></ref><ref id="R7"><label>[7]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knapen</surname><given-names>T</given-names></name><name><surname>Brascamp</surname><given-names>J</given-names></name><name><surname>Pearson</surname><given-names>J</given-names></name><name><surname>van Ee</surname><given-names>R</given-names></name><name><surname>Blake</surname><given-names>R</given-names></name></person-group><article-title>The role of frontal and parietal brain areas in bistable perception</article-title><source>J Neurosci</source><year>2011</year><month>Jul</month><volume>31</volume><issue>28</issue><fpage>10293</fpage><lpage>301</lpage><pub-id pub-id-type="pmcid">PMC3146344</pub-id><pub-id pub-id-type="pmid">21753006</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1727-11.2011</pub-id></element-citation></ref><ref id="R8"><label>[8]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Massimini</surname><given-names>M</given-names></name><name><surname>Boly</surname><given-names>M</given-names></name><name><surname>Tononi</surname><given-names>G</given-names></name></person-group><article-title>Neural correlates of consciousness: progress and problems</article-title><source>Nat Rev Neurosci</source><year>2016</year><month>May</month><volume>17</volume><issue>5</issue><fpage>307</fpage><lpage>21</lpage><pub-id pub-id-type="pmid">27094080</pub-id></element-citation></ref><ref id="R9"><label>[9]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsuchiya</surname><given-names>N</given-names></name><name><surname>Wilke</surname><given-names>M</given-names></name><name><surname>Frässle</surname><given-names>S</given-names></name><name><surname>Lamme</surname><given-names>VAF</given-names></name></person-group><article-title>No-report paradigms: Extracting the true neural correlates of consciousness</article-title><source>Trends Cogn Sci</source><year>2015</year><month>Dec</month><volume>19</volume><issue>12</issue><fpage>757</fpage><lpage>70</lpage><pub-id pub-id-type="pmid">26585549</pub-id></element-citation></ref><ref id="R10"><label>[10]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sterzer</surname><given-names>P</given-names></name><name><surname>Kleinschmidt</surname><given-names>A</given-names></name><name><surname>Rees</surname><given-names>G</given-names></name></person-group><article-title>The neural bases of multistable perception</article-title><source>Trends Cogn Sci</source><year>2009</year><month>Jul</month><volume>13</volume><issue>7</issue><fpage>310</fpage><lpage>8</lpage><pub-id pub-id-type="pmid">19540794</pub-id></element-citation></ref><ref id="R11"><label>[11]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brascamp</surname><given-names>J</given-names></name><name><surname>Sterzer</surname><given-names>P</given-names></name><name><surname>Blake</surname><given-names>R</given-names></name><name><surname>Knapen</surname><given-names>T</given-names></name></person-group><article-title>Multistable perception and the role of the frontoparietal cortex in perceptual inference</article-title><source>Annu Rev Psychol</source><year>2018</year><month>Jan</month><volume>69</volume><fpage>77</fpage><lpage>103</lpage><pub-id pub-id-type="pmid">28854000</pub-id></element-citation></ref><ref id="R12"><label>[12]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leopold</surname><given-names>DA</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name></person-group><article-title>Activity changes in early visual cortex reflect monkeys’ percepts during binocular rivalry</article-title><source>Nature</source><year>1996</year><month>Feb</month><volume>379</volume><issue>6565</issue><fpage>549</fpage><lpage>53</lpage><pub-id pub-id-type="pmid">8596635</pub-id></element-citation></ref><ref id="R13"><label>[13]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Panagiotaropoulos</surname><given-names>TI</given-names></name><name><surname>Deco</surname><given-names>G</given-names></name><name><surname>Kapoor</surname><given-names>V</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name></person-group><article-title>Neuronal discharges and gamma oscillations explicitly reflect visual consciousness in the lateral prefrontal cortex</article-title><source>Neuron</source><year>2012</year><month>Jun</month><volume>74</volume><issue>5</issue><fpage>924</fpage><lpage>35</lpage><pub-id pub-id-type="pmid">22681695</pub-id></element-citation></ref><ref id="R14"><label>[14]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheinberg</surname><given-names>DL</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name></person-group><article-title>The role of temporal cortical areas in perceptual organization</article-title><source>Proc Natl Acad Sci U S A</source><year>1997</year><month>Apr</month><volume>94</volume><issue>7</issue><fpage>3408</fpage><lpage>13</lpage><pub-id pub-id-type="pmcid">PMC20383</pub-id><pub-id pub-id-type="pmid">9096407</pub-id><pub-id pub-id-type="doi">10.1073/pnas.94.7.3408</pub-id></element-citation></ref><ref id="R15"><label>[15]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tong</surname><given-names>F</given-names></name></person-group><article-title>Primary visual cortex and visual awareness</article-title><source>Nat Rev Neurosci</source><year>2003</year><month>Mar</month><volume>4</volume><issue>3</issue><fpage>219</fpage><lpage>29</lpage><pub-id pub-id-type="pmid">12612634</pub-id></element-citation></ref><ref id="R16"><label>[16]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tong</surname><given-names>F</given-names></name><name><surname>Nakayama</surname><given-names>K</given-names></name><name><surname>Vaughan</surname><given-names>JT</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name></person-group><article-title>Binocular rivalry and visual awareness in human extrastriate cortex</article-title><source>Neuron</source><year>1998</year><month>Oct</month><volume>21</volume><issue>4</issue><fpage>753</fpage><lpage>9</lpage><pub-id pub-id-type="pmid">9808462</pub-id></element-citation></ref><ref id="R17"><label>[17]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carmel</surname><given-names>D</given-names></name><name><surname>Walsh</surname><given-names>V</given-names></name><name><surname>Lavie</surname><given-names>N</given-names></name><name><surname>Rees</surname><given-names>G</given-names></name></person-group><article-title>Right parietal TMS shortens dominance durations in binocular rivalry</article-title><source>Curr Biol</source><year>2010</year><month>Sep</month><volume>20</volume><issue>18</issue><fpage>R799</fpage><lpage>800</lpage><pub-id pub-id-type="pmid">20869603</pub-id></element-citation></ref><ref id="R18"><label>[18]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weilnhammer</surname><given-names>V</given-names></name><name><surname>Fritsch</surname><given-names>M</given-names></name><name><surname>Chikermane</surname><given-names>M</given-names></name><name><surname>Eckert</surname><given-names>AL</given-names></name><name><surname>Kanthak</surname><given-names>K</given-names></name><name><surname>Stuke</surname><given-names>H</given-names></name><etal/></person-group><article-title>An active role of inferior frontal cortex in conscious experience</article-title><source>Curr Biol</source><year>2021</year><month>Jul</month><volume>31</volume><issue>13</issue><fpage>2868</fpage><lpage>80</lpage><elocation-id>e8</elocation-id><pub-id pub-id-type="pmid">33989530</pub-id></element-citation></ref><ref id="R19"><label>[19]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bartels</surname><given-names>A</given-names></name></person-group><article-title>Consciousness: What is the role of prefrontal cortex?</article-title><source>Curr Biol</source><year>2021</year><month>Jul</month><volume>31</volume><issue>13</issue><fpage>R853</fpage><lpage>6</lpage><pub-id pub-id-type="pmid">34256919</pub-id></element-citation></ref><ref id="R20"><label>[20]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Jong</surname><given-names>MC</given-names></name><name><surname>Vansteensel</surname><given-names>MJ</given-names></name><name><surname>van Ee</surname><given-names>R</given-names></name><name><surname>Leijten</surname><given-names>FSS</given-names></name><name><surname>Ramsey</surname><given-names>NF</given-names></name><name><surname>Dijk-erman</surname><given-names>HC</given-names></name><etal/></person-group><article-title>Intracranial recordings reveal unique shape and timing of responses in human visual cortex during illusory visual events</article-title><source>Curr Biol</source><year>2020</year><month>Aug</month><volume>30</volume><issue>16</issue><fpage>3089</fpage><lpage>100</lpage><elocation-id>e4</elocation-id><pub-id pub-id-type="pmid">32619489</pub-id></element-citation></ref><ref id="R21"><label>[21]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hupe’</surname><given-names>JM</given-names></name><name><surname>Rubin</surname><given-names>N</given-names></name></person-group><article-title>The dynamics of bi-stable alternation in ambiguous motion displays: a fresh look at plaids</article-title><source>Vision Res</source><year>2003</year><month>Mar</month><volume>43</volume><issue>5</issue><fpage>531</fpage><lpage>48</lpage><pub-id pub-id-type="pmid">12594999</pub-id></element-citation></ref><ref id="R22"><label>[22]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hupe’</surname><given-names>JM</given-names></name><name><surname>Lamirel</surname><given-names>C</given-names></name><name><surname>Lorenceau</surname><given-names>J</given-names></name></person-group><article-title>Pupil dynamics during bistable motion perception</article-title><source>J Vis</source><year>2009</year><month>Jul</month><volume>9</volume><issue>7</issue><fpage>10</fpage><pub-id pub-id-type="pmid">19761325</pub-id></element-citation></ref><ref id="R23"><label>[23]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brascamp</surname><given-names>JW</given-names></name><name><surname>de Hollander</surname><given-names>G</given-names></name><name><surname>Wertheimer</surname><given-names>MD</given-names></name><name><surname>DePew</surname><given-names>AN</given-names></name><name><surname>Knapen</surname><given-names>T</given-names></name></person-group><article-title>Separable pupillary signatures of perception and action during perceptual multistability</article-title><source>Elife</source><year>2021</year><month>Aug</month><volume>10</volume><pub-id pub-id-type="pmcid">PMC8378849</pub-id><pub-id pub-id-type="pmid">34378532</pub-id><pub-id pub-id-type="doi">10.7554/eLife.66161</pub-id></element-citation></ref><ref id="R24"><label>[24]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>B</given-names></name><name><surname>Matsuo</surname><given-names>V</given-names></name><name><surname>Raphan</surname><given-names>T</given-names></name></person-group><article-title>Quantitative analysis of the velocity characteristics of optokinetic nystagmus and optokinetic after-nystagmus</article-title><source>J Physiol</source><year>1977</year><month>Sep</month><volume>270</volume><issue>2</issue><fpage>321</fpage><lpage>44</lpage><pub-id pub-id-type="pmcid">PMC1353516</pub-id><pub-id pub-id-type="pmid">409838</pub-id><pub-id pub-id-type="doi">10.1113/jphysiol.1977.sp011955</pub-id></element-citation></ref><ref id="R25"><label>[25]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frässle</surname><given-names>S</given-names></name><name><surname>Sommer</surname><given-names>J</given-names></name><name><surname>Jansen</surname><given-names>A</given-names></name><name><surname>Naber</surname><given-names>M</given-names></name><name><surname>Einhäuser</surname><given-names>W</given-names></name></person-group><article-title>Binocular rivalry: frontal activity relates to introspection and action but not to perception</article-title><source>J Neurosci</source><year>2014</year><month>Jan</month><volume>34</volume><issue>5</issue><fpage>1738</fpage><lpage>47</lpage><pub-id pub-id-type="pmcid">PMC6827584</pub-id><pub-id pub-id-type="pmid">24478356</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4403-13.2014</pub-id></element-citation></ref><ref id="R26"><label>[26]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Naber</surname><given-names>M</given-names></name><name><surname>Frässle</surname><given-names>S</given-names></name><name><surname>Einhäuser</surname><given-names>W</given-names></name></person-group><article-title>Perceptual rivalry: reflexes reveal the gradual nature of visual awareness</article-title><source>PLoS One</source><year>2011</year><month>Jun</month><volume>6</volume><issue>6</issue><elocation-id>e20910</elocation-id><pub-id pub-id-type="pmcid">PMC3109001</pub-id><pub-id pub-id-type="pmid">21677786</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0020910</pub-id></element-citation></ref><ref id="R27"><label>[27]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Canales-Johnson</surname><given-names>A</given-names></name><name><surname>Billig</surname><given-names>AJ</given-names></name><name><surname>Olivares</surname><given-names>F</given-names></name><name><surname>Gonzalez</surname><given-names>A</given-names></name><name><surname>Garcia</surname><given-names>MDC</given-names></name><name><surname>Silva</surname><given-names>W</given-names></name><etal/></person-group><article-title>Dissociable neural information dynamics of perceptual integration and differentiation during bistable perception</article-title><source>Cereb Cortex</source><year>2020</year><month>Jun</month><volume>30</volume><issue>8</issue><fpage>4563</fpage><lpage>80</lpage><pub-id pub-id-type="pmcid">PMC7325715</pub-id><pub-id pub-id-type="pmid">32219312</pub-id><pub-id pub-id-type="doi">10.1093/cercor/bhaa058</pub-id></element-citation></ref><ref id="R28"><label>[28]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fujiwara</surname><given-names>M</given-names></name><name><surname>Ding</surname><given-names>C</given-names></name><name><surname>Kaunitz</surname><given-names>L</given-names></name><name><surname>Stout</surname><given-names>JC</given-names></name><name><surname>Thyagarajan</surname><given-names>D</given-names></name><name><surname>Tsuchiya</surname><given-names>N</given-names></name></person-group><article-title>Optokinetic nystagmus reflects perceptual directions in the onset binocular rivalry in Parkinson’s disease</article-title><source>PLoS One</source><year>2017</year><month>Mar</month><volume>12</volume><issue>3</issue><elocation-id>e0173707</elocation-id><pub-id pub-id-type="pmcid">PMC5348009</pub-id><pub-id pub-id-type="pmid">28288201</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0173707</pub-id></element-citation></ref><ref id="R29"><label>[29]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kapoor</surname><given-names>V</given-names></name><name><surname>Dwarakanath</surname><given-names>A</given-names></name><name><surname>Safavi</surname><given-names>S</given-names></name><name><surname>Werner</surname><given-names>J</given-names></name><name><surname>Besserve</surname><given-names>M</given-names></name><name><surname>Panagio-taropoulos</surname><given-names>TI</given-names></name><etal/></person-group><article-title>Decoding the contents of consciousness from prefrontal ensembles</article-title><year>2020</year></element-citation></ref><ref id="R30"><label>[30]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilbertz</surname><given-names>G</given-names></name><name><surname>Ketkar</surname><given-names>M</given-names></name><name><surname>Guggenmos</surname><given-names>M</given-names></name><name><surname>Sterzer</surname><given-names>P</given-names></name></person-group><article-title>Combined fMRI-and eye movement-based decoding of bistable plaid motion perception</article-title><source>Neuroimage</source><year>2018</year><month>May</month><volume>171</volume><fpage>190</fpage><lpage>8</lpage><pub-id pub-id-type="pmid">29294388</pub-id></element-citation></ref><ref id="R31"><label>[31]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brascamp</surname><given-names>JW</given-names></name><name><surname>Klink</surname><given-names>PC</given-names></name><name><surname>Levelt</surname><given-names>WJM</given-names></name></person-group><article-title>The ‘laws’ of binocular rivalry: 50 years of Levelt’s propositions</article-title><source>Vision Res</source><year>2015</year><month>Apr</month><volume>109</volume><issue>Pt A</issue><fpage>20</fpage><lpage>37</lpage><pub-id pub-id-type="pmid">25749677</pub-id></element-citation></ref><ref id="R32"><label>[32]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vinck</surname><given-names>M</given-names></name><name><surname>Uran</surname><given-names>C</given-names></name><name><surname>Spyropoulos</surname><given-names>G</given-names></name><name><surname>Onorato</surname><given-names>I</given-names></name><name><surname>Broggini</surname><given-names>AC</given-names></name><name><surname>Schneider</surname><given-names>M</given-names></name><etal/></person-group><article-title>Principles of large-scale neural interactions</article-title><source>Neuron</source><year>2023</year><volume>111</volume><issue>7</issue><fpage>987</fpage><lpage>1002</lpage><pub-id pub-id-type="pmid">37023720</pub-id></element-citation></ref><ref id="R33"><label>[33]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ince</surname><given-names>RAA</given-names></name><name><surname>Giordano</surname><given-names>BL</given-names></name><name><surname>Kayser</surname><given-names>C</given-names></name><name><surname>Rousselet</surname><given-names>GA</given-names></name><name><surname>Gross</surname><given-names>J</given-names></name><name><surname>Schyns</surname><given-names>PG</given-names></name></person-group><article-title>A statistical framework for neuroimaging data analysis based on mutual information estimated via a gaussian copula</article-title><source>Human Brain Mapping</source><year>2017</year><volume>38</volume><issue>3</issue><fpage>1541</fpage><lpage>73</lpage><pub-id pub-id-type="pmcid">PMC5324576</pub-id><pub-id pub-id-type="pmid">27860095</pub-id><pub-id pub-id-type="doi">10.1002/hbm.23471</pub-id></element-citation></ref><ref id="R34"><label>[34]</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ince</surname><given-names>RAA</given-names></name><name><surname>Panzeri</surname><given-names>S</given-names></name><name><surname>Schultz</surname><given-names>SR</given-names></name></person-group><chapter-title>Summary of information theoretic quantities</chapter-title><source>Encyclopedia of Computational Neuroscience</source><publisher-loc>New York, NY</publisher-loc><publisher-name>Springer</publisher-name><year>2014</year><fpage>1</fpage><lpage>6</lpage></element-citation></ref><ref id="R35"><label>[35]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Besserve</surname><given-names>M</given-names></name><name><surname>Lowe</surname><given-names>SC</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name><name><surname>Schölkopf</surname><given-names>B</given-names></name><name><surname>Panzeri</surname><given-names>S</given-names></name></person-group><article-title>Shifts of gamma phase across primary visual cortical sites reflect dynamic stimulus-modulated information transfer</article-title><source>PLoS Biol</source><year>2015</year><month>Sep</month><volume>13</volume><issue>9</issue><elocation-id>e1002257</elocation-id><pub-id pub-id-type="pmcid">PMC4579086</pub-id><pub-id pub-id-type="pmid">26394205</pub-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1002257</pub-id></element-citation></ref><ref id="R36"><label>[36]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giordano</surname><given-names>BL</given-names></name><name><surname>Ince</surname><given-names>RAA</given-names></name><name><surname>Gross</surname><given-names>J</given-names></name><name><surname>Schyns</surname><given-names>PG</given-names></name><name><surname>Panzeri</surname><given-names>S</given-names></name><name><surname>Kayser</surname><given-names>C</given-names></name></person-group><article-title>Contributions of local speech encoding and functional connectivity to audiovisual speech perception</article-title><source>Elife</source><year>2017</year><month>Jun</month><volume>6</volume><pub-id pub-id-type="pmcid">PMC5462535</pub-id><pub-id pub-id-type="pmid">28590903</pub-id><pub-id pub-id-type="doi">10.7554/eLife.24763</pub-id></element-citation></ref><ref id="R37"><label>[37]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>H</given-names></name><name><surname>Ince</surname><given-names>RAA</given-names></name><name><surname>Schyns</surname><given-names>PG</given-names></name><name><surname>Thut</surname><given-names>G</given-names></name><name><surname>Gross</surname><given-names>J</given-names></name></person-group><article-title>Representational interactions during audiovisual speech entrainment: Redundancy in left posterior superior temporal gyrus and synergy in left motor cortex</article-title><source>PLoS Biol</source><year>2018</year><month>Aug</month><volume>16</volume><issue>8</issue><elocation-id>e2006558</elocation-id><pub-id pub-id-type="pmcid">PMC6095613</pub-id><pub-id pub-id-type="pmid">30080855</pub-id><pub-id pub-id-type="doi">10.1371/journal.pbio.2006558</pub-id></element-citation></ref><ref id="R38"><label>[38]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schartner</surname><given-names>M</given-names></name><name><surname>Seth</surname><given-names>A</given-names></name><name><surname>Noirhomme</surname><given-names>Q</given-names></name><name><surname>Boly</surname><given-names>M</given-names></name><name><surname>Bruno</surname><given-names>MA</given-names></name><name><surname>Laureys</surname><given-names>S</given-names></name><etal/></person-group><article-title>Complexity of multi-dimensional spontaneous EEG decreases during propofol induced general anaesthesia</article-title><source>PLoS One</source><year>2015</year><month>Aug</month><volume>10</volume><issue>8</issue><elocation-id>e0133532</elocation-id><pub-id pub-id-type="pmcid">PMC4529106</pub-id><pub-id pub-id-type="pmid">26252378</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0133532</pub-id></element-citation></ref><ref id="R39"><label>[39]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schartner</surname><given-names>MM</given-names></name><name><surname>Carhart-Harris</surname><given-names>RL</given-names></name><name><surname>Barrett</surname><given-names>AB</given-names></name><name><surname>Seth</surname><given-names>AK</given-names></name><name><surname>Muthuku-maraswamy</surname><given-names>SD</given-names></name></person-group><article-title>Increased spontaneous MEG signal diversity for psychoactive doses of ketamine, LSD and psilocybin</article-title><source>Sci Rep</source><year>2017</year><month>Apr</month><volume>7</volume><issue>1</issue><elocation-id>46421</elocation-id><pub-id pub-id-type="pmcid">PMC5396066</pub-id><pub-id pub-id-type="pmid">28422113</pub-id><pub-id pub-id-type="doi">10.1038/srep46421</pub-id></element-citation></ref><ref id="R40"><label>[40]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sitt</surname><given-names>JD</given-names></name><name><surname>King</surname><given-names>JR</given-names></name><name><surname>El Karoui</surname><given-names>I</given-names></name><name><surname>Rohaut</surname><given-names>B</given-names></name><name><surname>Faugeras</surname><given-names>F</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name><etal/></person-group><article-title>Large scale screening of neural signatures of consciousness in patients in a vegetative or minimally conscious state</article-title><source>Brain</source><year>2014</year><month>Aug</month><volume>137</volume><issue>Pt 8</issue><fpage>2258</fpage><lpage>70</lpage><pub-id pub-id-type="pmcid">PMC4610185</pub-id><pub-id pub-id-type="pmid">24919971</pub-id><pub-id pub-id-type="doi">10.1093/brain/awu141</pub-id></element-citation></ref><ref id="R41"><label>[41]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Canales-Johnson</surname><given-names>A</given-names></name><name><surname>Teixeira Borges</surname><given-names>AF</given-names></name><name><surname>Komatsu</surname><given-names>M</given-names></name><name><surname>Fujii</surname><given-names>N</given-names></name><name><surname>Fahren-fort</surname><given-names>JJ</given-names></name><name><surname>Miller</surname><given-names>KJ</given-names></name><etal/></person-group><article-title>Broadband Dynamics Rather than Frequency Specific Rhythms Underlie Prediction Error in the Primate Auditory Cortex</article-title><year>2021</year><volume>41</volume><issue>45</issue><fpage>9374</fpage><lpage>91</lpage><pub-id pub-id-type="pmcid">PMC8580146</pub-id><pub-id pub-id-type="pmid">34645605</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0367-21.2021</pub-id></element-citation></ref><ref id="R42"><label>[42]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mediano</surname><given-names>PAM</given-names></name><name><surname>Rosas</surname><given-names>FE</given-names></name><name><surname>Barrett</surname><given-names>AB</given-names></name><name><surname>Bor</surname><given-names>D</given-names></name></person-group><article-title>Decomposing spectral and phasic differences in nonlinear features between datasets</article-title><source>Phys Rev Lett</source><year>2021</year><month>Sep</month><volume>127</volume><issue>12</issue><elocation-id>124101</elocation-id><pub-id pub-id-type="pmid">34597101</pub-id></element-citation></ref><ref id="R43"><label>[43]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aba’solo</surname><given-names>D</given-names></name><name><surname>Simons</surname><given-names>S</given-names></name><name><surname>Morgado da Silva</surname><given-names>R</given-names></name><name><surname>Tononi</surname><given-names>G</given-names></name><name><surname>Vyazovskiy</surname><given-names>VV</given-names></name></person-group><article-title>Lempel-Ziv complexity of cortical activity during sleep and waking in rats</article-title><source>J Neurophysiol</source><year>2015</year><month>Apr</month><volume>113</volume><issue>7</issue><fpage>2742</fpage><lpage>52</lpage><pub-id pub-id-type="pmcid">PMC4416627</pub-id><pub-id pub-id-type="pmid">25717159</pub-id><pub-id pub-id-type="doi">10.1152/jn.00575.2014</pub-id></element-citation></ref><ref id="R44"><label>[44]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aftanas</surname><given-names>LI</given-names></name><name><surname>Golocheikine</surname><given-names>SA</given-names></name></person-group><article-title>Non-linear dynamic complexity of the human EEG during meditation</article-title><source>Neurosci Lett</source><year>2002</year><month>Sep</month><volume>330</volume><issue>2</issue><fpage>143</fpage><lpage>6</lpage><pub-id pub-id-type="pmid">12231432</pub-id></element-citation></ref><ref id="R45"><label>[45]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pal</surname><given-names>D</given-names></name><name><surname>Li</surname><given-names>D</given-names></name><name><surname>Dean</surname><given-names>JG</given-names></name><name><surname>Brito</surname><given-names>MA</given-names></name><name><surname>Liu</surname><given-names>T</given-names></name><name><surname>Fryzel</surname><given-names>AM</given-names></name><etal/></person-group><article-title>Level of consciousness is dissociable from electroencephalographic measures of cortical connectivity, slow oscillations, and complexity</article-title><source>J Neurosci</source><year>2020</year><month>Jan</month><volume>40</volume><issue>3</issue><fpage>605</fpage><lpage>18</lpage><pub-id pub-id-type="pmcid">PMC6961988</pub-id><pub-id pub-id-type="pmid">31776211</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1910-19.2019</pub-id></element-citation></ref><ref id="R46"><label>[46]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lumer</surname><given-names>ED</given-names></name><name><surname>Rees</surname><given-names>G</given-names></name></person-group><article-title>Covariation of activity in visual and prefrontal cortex associated with subjective visual perception</article-title><source>Proc Natl Acad Sci U S A</source><year>1999</year><month>Feb</month><volume>96</volume><issue>4</issue><fpage>1669</fpage><lpage>73</lpage><pub-id pub-id-type="pmcid">PMC15554</pub-id><pub-id pub-id-type="pmid">9990082</pub-id><pub-id pub-id-type="doi">10.1073/pnas.96.4.1669</pub-id></element-citation></ref><ref id="R47"><label>[47]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markov</surname><given-names>NT</given-names></name><name><surname>Ercsey-Ravasz</surname><given-names>MM</given-names></name><name><surname>Ribeiro Gomes</surname><given-names>AR</given-names></name><name><surname>Lamy</surname><given-names>C</given-names></name><name><surname>Magrou</surname><given-names>L</given-names></name><name><surname>Vezoli</surname><given-names>J</given-names></name><etal/></person-group><article-title>A weighted and directed interareal connectivity matrix for macaque cerebral cortex</article-title><source>Cereb Cortex</source><year>2014</year><month>Jan</month><volume>24</volume><issue>1</issue><fpage>17</fpage><lpage>36</lpage><pub-id pub-id-type="pmcid">PMC3862262</pub-id><pub-id pub-id-type="pmid">23010748</pub-id><pub-id pub-id-type="doi">10.1093/cercor/bhs270</pub-id></element-citation></ref><ref id="R48"><label>[48]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Angelucci</surname><given-names>A</given-names></name><name><surname>Levitt</surname><given-names>JB</given-names></name><name><surname>Walton</surname><given-names>EJS</given-names></name><name><surname>Hupe</surname><given-names>JM</given-names></name><name><surname>Bullier</surname><given-names>J</given-names></name><name><surname>Lund</surname><given-names>JS</given-names></name></person-group><article-title>Circuits for local and global signal integration in primary visual cortex</article-title><source>J Neurosci</source><year>2002</year><month>Oct</month><volume>22</volume><issue>19</issue><fpage>8633</fpage><lpage>46</lpage><pub-id pub-id-type="pmcid">PMC6757772</pub-id><pub-id pub-id-type="pmid">12351737</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.22-19-08633.2002</pub-id></element-citation></ref><ref id="R49"><label>[49]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rao</surname><given-names>RP</given-names></name><name><surname>Ballard</surname><given-names>DH</given-names></name></person-group><article-title>Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects</article-title><source>Nat Neu-rosci</source><year>1999</year><month>Jan</month><volume>2</volume><issue>1</issue><fpage>79</fpage><lpage>87</lpage><pub-id pub-id-type="pmid">10195184</pub-id></element-citation></ref><ref id="R50"><label>[50]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vezoli</surname><given-names>J</given-names></name><name><surname>Magrou</surname><given-names>L</given-names></name><name><surname>Goebel</surname><given-names>R</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name><name><surname>Knoblauch</surname><given-names>K</given-names></name><name><surname>Vinck</surname><given-names>M</given-names></name><etal/></person-group><article-title>Cortical hierarchy, dual counterstream architecture and the importance of top-down generative networks</article-title><source>Neuroimage</source><year>2021</year><month>Jan</month><volume>225</volume><elocation-id>117479</elocation-id><pub-id pub-id-type="pmcid">PMC8244994</pub-id><pub-id pub-id-type="pmid">33099005</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117479</pub-id></element-citation></ref><ref id="R51"><label>[51]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keller</surname><given-names>GB</given-names></name><name><surname>Mrsic-Flogel</surname><given-names>TD</given-names></name></person-group><article-title>Predictive processing: A canonical cortical computation</article-title><source>Neuron</source><year>2018</year><month>Oct</month><volume>100</volume><issue>2</issue><fpage>424</fpage><lpage>35</lpage><pub-id pub-id-type="pmcid">PMC6400266</pub-id><pub-id pub-id-type="pmid">30359606</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2018.10.003</pub-id></element-citation></ref><ref id="R52"><label>[52]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gelbard-Sagiv</surname><given-names>H</given-names></name><name><surname>Mudrik</surname><given-names>L</given-names></name><name><surname>Hill</surname><given-names>MR</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Fried</surname><given-names>I</given-names></name></person-group><article-title>Human single neuron activity precedes emergence of conscious perception</article-title><source>Nat Commun</source><year>2018</year><month>May</month><volume>9</volume><issue>1</issue><elocation-id>2057</elocation-id><pub-id pub-id-type="pmcid">PMC5970215</pub-id><pub-id pub-id-type="pmid">29802308</pub-id><pub-id pub-id-type="doi">10.1038/s41467-018-03749-0</pub-id></element-citation></ref><ref id="R53"><label>[53]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tong</surname><given-names>F</given-names></name><name><surname>Meng</surname><given-names>M</given-names></name><name><surname>Blake</surname><given-names>R</given-names></name></person-group><article-title>Neural bases of binocular rivalry</article-title><source>Trends Cogn Sci</source><year>2006</year><month>Nov</month><volume>10</volume><issue>11</issue><fpage>502</fpage><lpage>11</lpage><pub-id pub-id-type="pmid">16997612</pub-id></element-citation></ref><ref id="R54"><label>[54]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Logothetis</surname><given-names>NK</given-names></name><name><surname>Schall</surname><given-names>JD</given-names></name></person-group><article-title>Neuronal correlates of subjective visual perception</article-title><source>Science</source><year>1989</year><month>Aug</month><volume>245</volume><issue>4919</issue><fpage>761</fpage><lpage>3</lpage><pub-id pub-id-type="pmid">2772635</pub-id></element-citation></ref><ref id="R55"><label>[55]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sterzer</surname><given-names>P</given-names></name><name><surname>Kleinschmidt</surname><given-names>A</given-names></name></person-group><article-title>A neural basis for inference in perceptual ambiguity</article-title><source>Proc Natl Acad Sci U S A</source><year>2007</year><month>Jan</month><volume>104</volume><issue>1</issue><fpage>323</fpage><lpage>8</lpage><pub-id pub-id-type="pmcid">PMC1765459</pub-id><pub-id pub-id-type="pmid">17190824</pub-id><pub-id pub-id-type="doi">10.1073/pnas.0609006104</pub-id></element-citation></ref><ref id="R56"><label>[56]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Changeux</surname><given-names>JP</given-names></name></person-group><article-title>Experimental and theoretical approaches to conscious processing</article-title><source>Neuron</source><year>2011</year><month>Apr</month><volume>70</volume><issue>2</issue><fpage>200</fpage><lpage>27</lpage><pub-id pub-id-type="pmid">21521609</pub-id></element-citation></ref><ref id="R57"><label>[57]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Graaf</surname><given-names>TA</given-names></name><name><surname>de Jong</surname><given-names>MC</given-names></name><name><surname>Goebel</surname><given-names>R</given-names></name><name><surname>van Ee</surname><given-names>R</given-names></name><name><surname>Sack</surname><given-names>AT</given-names></name></person-group><article-title>On the functional relevance of frontal cortex for passive and voluntarily controlled bistable vision</article-title><source>Cereb Cortex</source><year>2011</year><month>Oct</month><volume>21</volume><issue>10</issue><fpage>2322</fpage><lpage>31</lpage><pub-id pub-id-type="pmid">21385836</pub-id></element-citation></ref><ref id="R58"><label>[58]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>MA</given-names></name><name><surname>Ortego</surname><given-names>K</given-names></name><name><surname>Kyroudis</surname><given-names>A</given-names></name><name><surname>Pitts</surname><given-names>M</given-names></name></person-group><article-title>Distinguishing the neural correlates of perceptual awareness and postperceptual processing</article-title><source>J Neu-rosci</source><year>2020</year><month>Jun</month><volume>40</volume><issue>25</issue><fpage>4925</fpage><lpage>35</lpage><pub-id pub-id-type="pmcid">PMC7326348</pub-id><pub-id pub-id-type="pmid">32409620</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0120-20.2020</pub-id></element-citation></ref><ref id="R59"><label>[59]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>MX</given-names></name><name><surname>van Gaal</surname><given-names>S</given-names></name></person-group><article-title>Subthreshold muscle twitches dissociate oscillatory neural signatures of conflicts from errors</article-title><source>Neuroimage</source><year>2014</year><month>Feb</month><volume>86</volume><fpage>503</fpage><lpage>13</lpage><pub-id pub-id-type="pmid">24185026</pub-id></element-citation></ref><ref id="R60"><label>[60]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>Q</given-names></name><name><surname>van Gaal</surname><given-names>S</given-names></name></person-group><article-title>Conflict awareness dissociates theta-band neural dynamics of the medial frontal and lateral frontal cortex during trial-by-trial cognitive control</article-title><source>Neuroimage</source><year>2015</year><month>Aug</month><volume>116</volume><fpage>102</fpage><lpage>11</lpage><pub-id pub-id-type="pmid">25957992</pub-id></element-citation></ref><ref id="R61"><label>[61]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Safavi</surname><given-names>S</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><article-title>Multistability, perceptual value, and internal foraging</article-title><source>Neuron</source><year>2022</year><month>Oct</month><volume>110</volume><issue>19</issue><fpage>3076</fpage><lpage>90</lpage><pub-id pub-id-type="pmid">36041434</pub-id></element-citation></ref><ref id="R62"><label>[62]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seth</surname><given-names>AK</given-names></name><name><surname>Bayne</surname><given-names>T</given-names></name></person-group><article-title>Theories of consciousness</article-title><source>Nat Rev Neurosci</source><year>2022</year><month>Jul</month><volume>23</volume><issue>7</issue><fpage>439</fpage><lpage>52</lpage><pub-id pub-id-type="pmid">35505255</pub-id></element-citation></ref><ref id="R63"><label>[63]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lamme</surname><given-names>VAF</given-names></name></person-group><article-title>Towards a true neural stance on consciousness</article-title><source>Trends Cogn Sci</source><year>2006</year><month>Nov</month><volume>10</volume><issue>11</issue><fpage>494</fpage><lpage>501</lpage><pub-id pub-id-type="pmid">16997611</pub-id></element-citation></ref><ref id="R64"><label>[64]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mashour</surname><given-names>GA</given-names></name><name><surname>Roelfsema</surname><given-names>P</given-names></name><name><surname>Changeux</surname><given-names>JP</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><article-title>Conscious processing and the global neuronal workspace hypothesis</article-title><source>Neuron</source><year>2020</year><month>Mar</month><volume>105</volume><issue>5</issue><fpage>776</fpage><lpage>98</lpage><pub-id pub-id-type="pmcid">PMC8770991</pub-id><pub-id pub-id-type="pmid">32135090</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2020.01.026</pub-id></element-citation></ref><ref id="R65"><label>[65]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tononi</surname><given-names>G</given-names></name><name><surname>Boly</surname><given-names>M</given-names></name><name><surname>Massimini</surname><given-names>M</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name></person-group><article-title>Integrated information theory: from consciousness to its physical substrate</article-title><source>Nat Rev Neurosci</source><year>2016</year><month>Jul</month><volume>17</volume><issue>7</issue><fpage>450</fpage><lpage>61</lpage><pub-id pub-id-type="pmid">27225071</pub-id></element-citation></ref><ref id="R66"><label>[66]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huguet</surname><given-names>G</given-names></name><name><surname>Rinzel</surname><given-names>J</given-names></name><name><surname>Hupe’</surname><given-names>JM</given-names></name></person-group><article-title>Noise and adaptation in multistable perception: noise drives when to switch, adaptation determines percept choice</article-title><source>J Vis</source><year>2014</year><month>Mar</month><volume>14</volume><issue>3</issue><fpage>19</fpage><pub-id pub-id-type="pmid">24627459</pub-id></element-citation></ref><ref id="R67"><label>[67]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hupe’</surname><given-names>JM</given-names></name><name><surname>Rubin</surname><given-names>N</given-names></name></person-group><article-title>The dynamics of bi-stable alternation in ambiguous motion displays: a fresh look at plaids</article-title><source>Vision Res</source><year>2003</year><month>Mar</month><volume>43</volume><issue>5</issue><fpage>531</fpage><lpage>48</lpage></element-citation></ref><ref id="R68"><label>[68]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>B</given-names></name><name><surname>Matsuo</surname><given-names>V</given-names></name><name><surname>Raphan</surname><given-names>T</given-names></name></person-group><article-title>Quantitative analysis of the velocity characteristics of optokinetic nystagmus and optokinetic after-nystagmus</article-title><source>J Physiol</source><year>1977</year><month>Sep</month><volume>270</volume><issue>2</issue><fpage>321</fpage><lpage>44</lpage></element-citation></ref><ref id="R69"><label>[69]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delorme</surname><given-names>A</given-names></name><name><surname>Makeig</surname><given-names>S</given-names></name></person-group><article-title>EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis</article-title><source>J Neurosci Methods</source><year>2004</year><month>Mar</month><volume>134</volume><issue>1</issue><fpage>9</fpage><lpage>21</lpage><pub-id pub-id-type="pmid">15102499</pub-id></element-citation></ref><ref id="R70"><label>[70]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Enoksson</surname><given-names>P</given-names></name></person-group><article-title>Binocular rivalry and monocular dominance studied with optokinetic nystagmus</article-title><source>Acta Ophthalmol</source><year>2009</year><month>May</month><volume>42</volume><issue>2</issue><fpage>495</fpage><lpage>5</lpage><pub-id pub-id-type="pmid">14059924</pub-id></element-citation></ref><ref id="R71"><label>[71]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leopold</surname><given-names>D</given-names></name><name><surname>Fitzgibbons</surname><given-names>J</given-names></name><name><surname>Logothetis</surname><given-names>N</given-names></name></person-group><article-title>The Role of Attention in Binocular Rivalry as Revealed through Optokinetic Nystagmus</article-title><source>MASSACHUSETTS INST OF TECH CAMBRIDGE ARTIFICIAL INTELLIGENCE LAB</source><year>1995</year></element-citation></ref><ref id="R72"><label>[72]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Massey</surname><given-names>J</given-names></name><etal/></person-group><article-title>Causality, feedback and directed information</article-title><source>In: Proc Int Symp Inf Theory Applic(ISITA-90)</source><year>1990</year><fpage>303</fpage><lpage>5</lpage></element-citation></ref><ref id="R73"><label>[73]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vicente</surname><given-names>R</given-names></name><name><surname>Wibral</surname><given-names>M</given-names></name><name><surname>Lindner</surname><given-names>M</given-names></name><name><surname>Pipa</surname><given-names>G</given-names></name></person-group><article-title>Transfer entropy–a model-free measure of effective connectivity for the neurosciences</article-title><source>J Comput Neurosci</source><year>2011</year><month>Feb</month><volume>30</volume><issue>1</issue><fpage>45</fpage><lpage>67</lpage><pub-id pub-id-type="pmcid">PMC3040354</pub-id><pub-id pub-id-type="pmid">20706781</pub-id><pub-id pub-id-type="doi">10.1007/s10827-010-0262-3</pub-id></element-citation></ref><ref id="R74"><label>[74]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wibral</surname><given-names>M</given-names></name><name><surname>Rahm</surname><given-names>B</given-names></name><name><surname>Rieder</surname><given-names>M</given-names></name><name><surname>Lindner</surname><given-names>M</given-names></name><name><surname>Vicente</surname><given-names>R</given-names></name><name><surname>Kaiser</surname><given-names>J</given-names></name></person-group><article-title>Transfer entropy in magnetoencephalographic data: quantifying information flow in cortical and cerebellar networks</article-title><source>Prog Biophys Mol Biol</source><year>2011</year><month>Mar</month><volume>105</volume><issue>1-2</issue><fpage>80</fpage><lpage>97</lpage><pub-id pub-id-type="pmid">21115029</pub-id></element-citation></ref><ref id="R75"><label>[75]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Besserve</surname><given-names>M</given-names></name><name><surname>Lowe</surname><given-names>SC</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name><name><surname>Schölkopf</surname><given-names>B</given-names></name><name><surname>Panzeri</surname><given-names>S</given-names></name></person-group><article-title>Shifts of gamma phase across primary visual cortical sites reflect dynamic stimulus-modulated information transfer</article-title><source>PLoS Biol</source><year>2015</year><month>Sep</month><volume>13</volume><issue>9</issue><elocation-id>e1002257</elocation-id></element-citation></ref><ref id="R76"><label>[76]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chaitin</surname><given-names>G</given-names></name></person-group><article-title>Information-theoretic computation complexity</article-title><source>IEEE Trans Inf Theory</source><year>1974</year><month>Jan</month><volume>20</volume><issue>1</issue><fpage>10</fpage><lpage>5</lpage></element-citation></ref><ref id="R77"><label>[77]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kolmogorov</surname><given-names>AN</given-names></name></person-group><article-title>Three approaches to the quantitative definition of information</article-title><source>Int J Comput Math</source><year>1968</year><month>Jan</month><volume>2</volume><issue>1-4</issue><fpage>157</fpage><lpage>68</lpage></element-citation></ref><ref id="R78"><label>[78]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lempel</surname><given-names>A</given-names></name><name><surname>Ziv</surname><given-names>J</given-names></name></person-group><article-title>On the complexity of finite sequences</article-title><source>IEEE Trans Inf Theory</source><year>1976</year><month>Jan</month><volume>22</volume><issue>1</issue><fpage>75</fpage><lpage>81</lpage></element-citation></ref><ref id="R79"><label>[79]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chaitin</surname><given-names>GJ</given-names></name></person-group><article-title>The berry paradox</article-title><source>Complexity</source><year>1995</year><month>Sep</month><volume>1</volume><issue>1</issue><fpage>26</fpage><lpage>30</lpage></element-citation></ref><ref id="R80"><label>[80]</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Salomon</surname><given-names>D</given-names></name></person-group><source>Data compression</source><publisher-loc>London, England</publisher-loc><publisher-name>Springer</publisher-name><edition>4th</edition><year>2007</year></element-citation></ref><ref id="R81"><label>[81]</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maris</surname><given-names>E</given-names></name><name><surname>Oostenveld</surname><given-names>R</given-names></name></person-group><article-title>Nonparametric statistical testing of EEG-and MEG-data</article-title><source>J Neurosci Methods</source><year>2007</year><month>Aug</month><volume>164</volume><issue>1</issue><fpage>177</fpage><lpage>90</lpage><pub-id pub-id-type="pmid">17517438</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><p>Experimental design, oculomotor decoding, and behavior. (A) Phenomenology during visual bistability in the report condition. Participants observed an ambiguous stimulus (moving plaids) that are experienced either as one plaid moving vertically (integrated percept; red arrow) or as two plaids moving horizontally (differentiated percept; blue arrows). Perceptual transitions occur either in integrated to differentiated direction (to DIF; blue) or in the differentiated to integrated direction (to INT; red). Middle row: Behavioral responses during the task. Participants pressed one button when perceiving that the integrated percept had fully changed into the differentiated percept (red button) and another button when perceiving that the differentiated percept had fully changed into the integrated percept (blue button). Bottom row: Dynamical analyses for EEG and oculomotor (eye tracking) signals. From the oculomotor response, we estimated the speed of the slow phase of the OKN (grey line) to infer participant’s perceptual content around OKN zero-crossings (to INT: red eye; to DIFF: blue eye) which coincides with their reports indexed by button presses (to INT: red button; to DIFF: blue button). (B) In the no-report condition observers passively viewed the bistable stimulus (no button presses) and perceptual alternations were inferred from oculomotor signals (to INT: red eye; to DIFF: blue eye). EEG y-axis represents voltage (microvolts) and x-axis time (milliseconds); OKN y-axis represents velocity (arbitrary units) and x-axis time (milliseconds). (C) Left panel: Raw oculomotor signal (in microvolts) locked to the button press (Report BP). Middle and Right panels: slow phase of the OKN (in arbitrary units) extracted from the oculomotor signal and locked to the OKN zero crossings (Report: OKN; No report: OKN). The slow phase of the OKN was obtained by computing the instantaneous velocity of the oculomotor signal smoothed over time (see Methods). Decoding accuracies (D) and histograms (E) for perceptual switches in the report condition locked to the button response, in the report condition locked to the OKN crossings, and in the no-report condition locked to the OKN crossings. (F) Delay between OKN crossings and button responses in the report condition (left panel: single-subject distributions; right panel: group-level analysis). Data is available at <ext-link ext-link-type="uri" xlink:href="https://osf.io/a2f3v/">https://osf.io/a2f3v/</ext-link>.</p></caption><graphic xlink:href="EMS151844-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><p>Information dynamics of the report condition locked to button responses. A Group-level dir-INFO between front and back ROIs (upper row) and between back and front ROIs (lower row) when moving plaids are reported as integrated (to INT; red color), reported as differentiated (to DIF; blue color), and the cluster-based permutation tests between the two. B Distribution of single-participant dir-INFO values for the frontal to the parietal direction (upper row) and for the parietal to the frontal direction (lower row). Values were extracted based on the significant clusters obtained in the frontal-to-parietal contrast (purple blobs). C Group-level dir-INFO statistical interaction effect computed as the difference between to INT and to DIFF trials between front and back ROIs (i.e., a double-subtraction). D Group-level diff-INFO within the frontal ROI and the corresponding single-subject diff-INFO values (left panel) when moving plaids are reported as differentiated and reported as integrated, and the same for the parietal ROI (right panel). E Group-level diff-INFO statistical interaction effect computed as the difference between to DIF and to INT trials between front (yellow color) and back (black color) ROIs. Data is available at <ext-link ext-link-type="uri" xlink:href="https://osf.io/a2f3v/">https://osf.io/a2f3v/</ext-link>.</p></caption><graphic xlink:href="EMS151844-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><p>Information dynamics of the report condition locked to OKN crossings. Specifics between A-D are identical to <xref ref-type="fig" rid="F2">Figure 2</xref>. E Single participant diff-INFO values were extracted using as a reference the significant time window observed in <xref ref-type="fig" rid="F2">Figure 2D</xref>. Data is available at <ext-link ext-link-type="uri" xlink:href="https://osf.io/a2f3v/">https://osf.io/a2f3v/</ext-link>.</p></caption><graphic xlink:href="EMS151844-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><p>Information dynamics of the no-report condition locked to OKN crossings. Specifics between A-D are identical to <xref ref-type="fig" rid="F2">Figure 2</xref>. E Single participant diff-INFO values were extracted using as a reference the significant time window observed in <xref ref-type="fig" rid="F2">Figure 2D</xref>. Data is available at <ext-link ext-link-type="uri" xlink:href="https://osf.io/a2f3v/">https://osf.io/a2f3v/</ext-link>.</p></caption><graphic xlink:href="EMS151844-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><p>Spectral power in the report and no report conditions. A Group-level spectral power in the front ROI for the report condition (upper row), report condition locked to OKN crossings (middle row), and no report condition (lower row), when moving plaids are reported as integrated (to INT; red color), reported as differentiated (to DIF; blue color), and the cluster-based permutation tests between the two. B Same as A but for the back ROI. Data is available at <ext-link ext-link-type="uri" xlink:href="https://osf.io/a2f3v/">https://osf.io/a2f3v/</ext-link>.</p></caption><graphic xlink:href="EMS151844-f005"/></fig></floats-group></article>