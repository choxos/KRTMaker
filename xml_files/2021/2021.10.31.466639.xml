<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS145923</article-id><article-id pub-id-type="doi">10.1101/2021.10.31.466639</article-id><article-id pub-id-type="archive">PPR415100</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Multiple and Dissociable Effects of Sensory History on Working-Memory Performance</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orchid">https://orcid.org/0000-0002-0812-6842</contrib-id><name><surname>Hajonides</surname><given-names>Jasper E.</given-names></name><aff id="A1">Oxford Centre for Human Brain Activity, University of Oxford, UK Department of Experimental Psychology, University of Oxford, UK</aff></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orchid">https://orcid.org/0000-0002-7434-1751</contrib-id><name><surname>van Ede</surname><given-names>Freek</given-names></name><aff id="A2">Department of Applied and Experimental Psychology, Vrije Universiteit, NL</aff></contrib><contrib contrib-type="author"><name><surname>Stokes</surname><given-names>Mark G.</given-names></name><aff id="A3">Department of Experimental Psychology, University of Oxford, UK</aff></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orchid">https://orcid.org/0000-0001-5762-2802</contrib-id><name><surname>Nobre</surname><given-names>Anna C.</given-names></name><aff id="A4">Oxford Centre for Human Brain Activity, University of Oxford, UK Department of Experimental Psychology, University of Oxford, UK</aff></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orchid">https://orcid.org/0000-0001-5599-3044</contrib-id><name><surname>Myers</surname><given-names>Nicholas E.</given-names></name><xref ref-type="corresp" rid="CR1">*</xref><aff id="A5">School of Psychology University of Nottingham, UK Department of Experimental Psychology, University of Oxford, UK</aff></contrib></contrib-group><author-notes><corresp id="CR1">
<label>*</label>Corresponding author. <email>Nick.Myers@nottingham.ac.uk</email></corresp></author-notes><pub-date pub-type="nihms-submitted"><day>14</day><month>06</month><year>2022</year></pub-date><pub-date pub-type="preprint"><day>09</day><month>06</month><year>2022</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nd/4.0/">CC BY-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Behavioural reports of sensory information are biased by stimulus history. The nature and direction of such serial-dependence biases can differ between experimental settings – both attractive and repulsive biases towards previous stimuli have been observed. How and when these biases arise in the human brain remains largely unexplored. They could occur either via a change in sensory processing itself and/or during post-perceptual processes such as maintenance or decision-making. To address this, we analysed behavioural and magnetoencephalographic data from a working-memory task in which participants were sequentially presented with two randomly oriented gratings, one of which was cued for recall at the end of the trial. Behavioural responses showed evidence for two distinct biases: 1) a within-trial repulsive bias away from the previously encoded orientation on the same trial, and 2) a between-trial attractive bias towards the task-relevant orientation on the previous trial. Multivariate classification of stimulus orientation revealed that neural representations during stimulus encoding were biased away from the previous grating orientation, regardless of whether we considered the within- or between-trial prior orientation – despite opposite effects on behaviour. These results suggest that repulsive biases occur at the level of sensory processing and can be overridden at post-perceptual stages to result in attractive biases in behaviour.</p></abstract><kwd-group><kwd>Working Memory</kwd><kwd>Attention</kwd><kwd>Serial Dependence</kwd><kwd>Neural Representations</kwd><kwd>Supervised Learning</kwd><kwd>Perceptual Bias</kwd></kwd-group></article-meta></front><body><sec id="S1" sec-type="intro"><label>1</label><title>Introduction</title><p id="P2">Stimulus history modulates performance guided by sensory input. Reliance on temporal correlations is deeply engrained in the visual system (<xref ref-type="bibr" rid="R46">Simoncelli &amp; Olshausen, 2001</xref>) and can be beneficial to guide perception within a world that is largely stable over short time scales (<xref ref-type="bibr" rid="R17">Dong &amp; Atick, 1995</xref>). Past sensory evidence can be an effective prior for extracting signals from the noisy sensory stream and to help maintain a stable representation to bridge blinks, eye movements, or visual occlusions. Recent studies have also revealed robust short-term influences of prior stimulation in delayed-response and working-memory tasks (<xref ref-type="bibr" rid="R1">Bae &amp; Luck, 2017</xref>; <xref ref-type="bibr" rid="R10">Cicchini, Anobile, &amp; Burr, 2014</xref>; <xref ref-type="bibr" rid="R12">Cicchini, Mikellidou, &amp; Burr, 2018</xref>; <xref ref-type="bibr" rid="R14">Czoschke, Fischer, Beitner, Kaiser, &amp; Bledowski, 2019</xref>; <xref ref-type="bibr" rid="R19">Fischer &amp; Whitney, 2014</xref>; <xref ref-type="bibr" rid="R24">Fritsche, Mostert, &amp; de Lange, 2017</xref>; <xref ref-type="bibr" rid="R29">Huang &amp; Sekuler, 2010</xref>). More specifically, remembered items are often reported as more similar to the task-relevant stimulus in a previous trial. This attractive bias, sometimes referred to as the serial-dependency bias, is suggested to increase temporal stability by acting as a prior (<xref ref-type="bibr" rid="R10">Cicchini, Anobile, &amp; Burr, 2014</xref>; <xref ref-type="bibr" rid="R18">Fischer, Czoschke, et al., 2020</xref>; <xref ref-type="bibr" rid="R19">Fischer &amp; Whitney, 2014</xref>; <xref ref-type="bibr" rid="R34">Kiyonaga, Scimeca, Bliss, &amp; Whitney, 2017</xref>). Conversely, features of items sequentially presented within trials are often judged as more dissimilar to each other (<xref ref-type="bibr" rid="R7">Born &amp; Tootell, 1992</xref>; <xref ref-type="bibr" rid="R24">Fritsche, Mostert, &amp; de Lange, 2017</xref>; <xref ref-type="bibr" rid="R50">Störmer &amp; Alvarez, 2014</xref>). This repulsive bias could result from efficient coding of temporally autocorrelated signals (<xref ref-type="bibr" rid="R12">Cicchini, Mikellidou, &amp; Burr, 2018</xref>). The amplification of subtle differences between stimuli could additionally serve to optimise perceptual decision-making (<xref ref-type="bibr" rid="R12">Cicchini, Mikellidou, &amp; Burr, 2018</xref>; <xref ref-type="bibr" rid="R34">Kiyonaga, Scimeca, Bliss, &amp; Whitney, 2017</xref>; <xref ref-type="bibr" rid="R54">van Bergen &amp; Jehee, 2019</xref>). Despite their opposite directions, attractive and repulsive performance biases have been shown to jointly influence task processing (<xref ref-type="bibr" rid="R14">Czoschke, Fischer, Beitner, Kaiser, &amp; Bledowski, 2019</xref>; <xref ref-type="bibr" rid="R24">Fritsche, Mostert, &amp; de Lange, 2017</xref>; <xref ref-type="bibr" rid="R25">Fritsche, Spaak, &amp; de Lange, 2020</xref>; <xref ref-type="bibr" rid="R43">Sadil, Cowell, &amp; Huber, 2021</xref>), albeit at different time scales (<xref ref-type="bibr" rid="R26">Gekas, McDermott, &amp; Mamassian, 2019</xref>; <xref ref-type="bibr" rid="R45">Sheehan &amp; Serences, 2021</xref>). While the current literature has largely focused on behaviour, relatively less work has examined whether these opposing biases share a neural mechanism, and in particular whether both biases may arise at early or late sensory processing stages. A number of studies have shown evidence for between-trial biases arising in early visual cortex (<xref ref-type="bibr" rid="R45">Sheehan &amp; Serences, 2021</xref>; <xref ref-type="bibr" rid="R48">St. John-Saaltink, Kok, Lau, &amp; De Lange, 2016</xref>), but with insufficient temporal resolution to isolate early processing stages, or they have measured activity only in frontal cortex but not sensory cortex (<xref ref-type="bibr" rid="R40">Papadimitriou, White, &amp; Snyder, 2017</xref>).</p><p id="P3">The current study combined behavioural reports in a working-memory task and continuous magne- toencephalographic (MEG) recordings to assess within- and between-trial biases induced by sensory history with high temporal resolution. We devised a task in which participants were sequentially presented with two orientations and used a continuous, precision response to reproduce one of them at the end of a trial. Additionally, we included a cue that indicated which of the two orientations had to be reported in the trial to test for possible differential susceptibility of biases to the task-relevance of stimuli (as per <xref ref-type="bibr" rid="R3">Bae &amp; Luck, 2020</xref>; <xref ref-type="bibr" rid="R18">Fischer, Czoschke, et al., 2020</xref>). We compared systematic biases induced by the first orientation on the second (within-trial bias) as well as biases from the previous trial on the current trial (between-trial bias). Critically, we tested whether we could find neural signatures for such biases using a decoding approach that leveraged the high temporal resolution of MEG. We set out to decode the presented orientation and expected to find the within-and between-trial biases in the neural data that mirrored the behavioural biases.</p><p id="P4">Previewing the results, we confirmed that behavioural responses were systematically pushed away from previous orientations on the same trial and pulled toward the orientations recalled on the previous trial. Mirroring the behavioural repulsion results, the sensory neural representation of stimulus orientation was shifted away from the preceding orientation presented on a given trial. However, we found no neural evidence for an attractive between-trial sensory bias during orientation encoding, despite such a bias observed in behaviour. Instead, we always observed a repulsive neural bias, regardless whether we considered orientations from the same or previous trial as a source of the bias.</p></sec><sec id="S2" sec-type="methods"><label>2</label><title>Methods</title><sec id="S3" sec-type="subjects"><label>2.1</label><title>Participants</title><p id="P5">Twenty healthy volunteers with normal or corrected-to-normal vision participated in the study. All participants were between 20 and 36 years old (mean 25.4 years old; eleven females). Prior to taking part in the study, volunteers provided their informed consent according to the procedures approved by the Central University Research Ethics Committee of the University of Oxford. Participants received £15 per hour compensation for taking part in this study.</p></sec><sec id="S4"><label>2.2</label><title>Experimental set-up</title><p id="P6">Participants sat in the MEG scanner, which was situated in a dimly lit, sound-proof, and magnetically shielded room. A projection screen was placed at a viewing distance of 90 cm. Visual stimuli were projected at the back of the screen at a spatial resolution of 1024 × 768 pixels using a refresh rate of 60 Hz using a Panasonic DLP projector (PT-D7700E).</p><p id="P7">The task was programmed and presented using Matlab (Mathworks, Nantick, WA) in conjunction with the Psychophysics Toolbox (<xref ref-type="bibr" rid="R8">Brainard, 1997</xref>). Participants indicated their responses on an optic-fibre response box.</p></sec><sec id="S5"><label>2.3</label><title>Task</title><p id="P8">Participants performed a precision working-memory task in which they reproduced the orientation of one of two grating stimuli presented sequentially with independent orientations (<xref ref-type="fig" rid="F1">Figure 1</xref>). Simultaneously with the presentation of the second grating, participants were cued as to which grating orientation to report when probed at the end of the trial. In half of the trials, only the first or second grating was presented and used for reporting.</p><p id="P9">Each trial started with a central fixation dot (0.2° visual angle) on screen for 800 ms with a grey background (RGB: 127, 127, 127; <xref ref-type="fig" rid="F1">Figure 1</xref>). Subsequently, a sinusoidal Gabor stimulus at a random angle was centrally presented on the visual display for 200 ms (diameter of 6° visual angle, 2 cycles per degree of visual angle, 50% contrast, tapered by a Gaussian envelope with a 1.5 ° standard deviation). On trials in which the first grating was not presented the fixation dot changed colour from black to grey (RGB: 192, 192, 192) to signal the omission. After a delay of 1700 – 1900 ms, the second grating was presented. This second grating had the same properties as the first grating except for the angle, which was randomly drawn independently from that of the first grating orientation. At the centre of the grating, the fixation dot changed colour (orange: (255, 161, 0); cyan: (0, 236, 255)). The colour signalled if the first orientation (report 1st trial) or the second orientation (report 2nd trial) would be probed. Cue-colour contingencies of the experiment were counterbalanced across participants and changed halfway through the experiment. After the colour contingencies switched, participants practised the new contingencies over the course of one block before continuing with the second half of the session. The colour cue was always valid in indicating which grating orientation was relevant for the reporting stage at the end of the trial. On trials in which the second grating was absent the cue would therefore always indicate the first orientation.</p><p id="P10">After another delay of 1700 – 1900 ms, a probe grating appeared. Participants had to adjust its orientation to match the cued grating in memory. Adjustments were made by pressing buttons with the right hand to rotate the grating either clockwise (middle finger) or anticlockwise (index finger). Responses were confirmed by pressing a button with the left index finger. A 200-ms fixation period followed, after which participants were presented with 50 ms of feedback in the form of a grating indicating the correct orientation.</p><p id="P11">In total, participants completed 400 trials. In half of the trials, two items were presented in 200 trials (100 trials with report 1st cue and 100 with report 2nd cue). Only one item was presented in the remaining 200 trials (100 with only grating 1 and 100 only grating 2). The resulting factorial design (relevant grating, number of gratings presented) included four conditions: report 1st with two items presented, report 1st with one item presented, report 2nd with two items presented, and report 2nd with one item presented. Trial types were randomly mixed and presented in blocks of 50 trials, with each block lasting approximately 10 minutes.</p></sec><sec id="S6"><label>2.4</label><title>Behavioural Analysis</title><p id="P12">Response error was quantified by calculating the circular distance between the recalled orientation and the cued orientation. All responses were mapped onto a -90° to 90° space to compute circular error. In all between-trial analyses, we excluded the first trial of each block.</p></sec><sec id="S7"><label>2.5</label><title>Mixture Modelling</title><p id="P13">We fit a classical mixture model frequently used in the working memory literature to investigate the relative rate of responses to targets, guesses, and erroneous responses to the wrong target (‘swap errors’ <xref ref-type="bibr" rid="R4">Bays, Catalao, &amp; Husain, 2009</xref>; <xref ref-type="bibr" rid="R44">Schneegans &amp; Bays, 2017</xref>). The model was fit separately for each condition (report 1st in 2-item trials; report 1st in 1-item control; report 2nd in 2-item trials; report 2nd in 1-item control). The mixture model estimated the precision of the von Mises distribution, target response rate, guess rate, and swap rate to the item that was presented on the same trial but not cued (only 2-item trials). After fitting the data to the entire dataset, the model provided single-trial weights for target response rate, guess rate, and swap rate.</p></sec><sec id="S8"><label>2.6</label><title>Performance Bias Calculation</title><p id="P14">We calculated the performance bias (the signed circular difference between the response and the target orientation) as a function of the circular difference between the target orientation and the orientation that induced the bias (the target orientation in the preceding trial or the task-irrelevant orientation in the same trial). We computed the difference between the target orientation and inducer through subtraction, with all angular differences mapped between -90° and 90°. These distances were binned into 64 equally sized, overlapping bins, with each bin containing 25% of trials. We computed the average signed error (bias) across all trials within each bin. Edge artefacts were avoided by wrapping the angular differences around, to ensure the average was computed over a constant number of trials and centred on the midpoint of the bin. Subsequently, we sign-flipped the performance bias in bins with a negative distance and averaged over negative (-90° to 0°) and positive distances (0° to 90°) between target orientation and inducing orientation, resulting in 32 bins. The summed bias over absolute distances (0° to 90°) calculated over the 32 bins for each condition and participant served as a measure of bias.</p></sec><sec id="S9"><label>2.7</label><title>MEG Acquisition</title><p id="P15">Participants were seated in the MEG scanner after being instructed about the task specifics. They completed one practice block while seated in the scanner prior to MEG recording onset. Participants were instructed to maintain their gaze at the central fixation dot and to minimise blinking throughout the trial.</p><p id="P16">Neuromagnetic data were acquired using a whole-head VectorView system including 204 planar gradiometers and 102 magnetometers (Elekta Neuromag Oy, Helsinki, Finland) in a magnetically shielded room. Throughout the experiment, participants’ head position was monitored continuously using index coils placed at four points on the head. Magnetic field strength was sampled at a rate of 1000 Hz and band-pass filtered on-line between 0.03 Hz and 300 Hz. In addition, vertical and horizontal electro-oculograms were measured using electrodes placed above, below, and adjacent to the eyes. Eye movements were monitored using an EyeLink 1000 (SR Research) eye tracker at a frequency of 1000 Hz.</p></sec><sec id="S10"><label>2.8</label><title>MEG Data Preprocessing</title><p id="P17">The data were pre-processed offline using Fieldtrip (<xref ref-type="bibr" rid="R39">Oostenveld, Fries, Maris, &amp; Schoffelen, 2011</xref>), OHBA software library (OSL) drawing on SPM8 (<ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm">http://www.fil.ion.ucl.ac.uk/spm</ext-link>), and Elekta software. Prior to any preprocessing, the MEG data were visually inspected to remove and interpolate any sensors that displayed excessive levels of noise and were subsequently de-noised and motion corrected using Maxfilter Signal Space Separation (<xref ref-type="bibr" rid="R51">Taulu, Kajola, &amp; Simola, 2004</xref>) before removing independent components related to cardiac and eye-blink artefacts. Data were epoched around the first grating and second grating (from 400 ms prior to grating onset to 900 ms after onset) and downsampled to 200 Hz. Trials with high variance in either gradiometers or magnetometers were identified and excluded using a generalised ESD (extreme studentised deviate; <xref ref-type="bibr" rid="R42">Rosner, 1983</xref>) test at a 0.05 significance threshold. This resulted in 7.49% ± 11.55% (mean ± standard deviation) being excluded during preprocessing.</p></sec><sec id="S11"><label>2.9</label><title>LDA Classification</title><p id="P18">Data were further pre-processed. Magnitudes of magnetometers were approximately matched to gradiometers by multiplication (factor 20) and subjected to spatio-temporal decoding as described in (<xref ref-type="bibr" rid="R28">Hajonides, Nobre, van Ede, &amp; Stokes, 2021</xref>; <xref ref-type="bibr" rid="R60">Wolff, Jochim, Akyürek, Buschman, &amp; Stokes, 2020</xref>; <xref ref-type="bibr" rid="R61">Wolff, Jochim, Akyürek, &amp; Stokes, 2017</xref>). Data from all 306 MEG sensors across a sliding window of 30 time points (150 ms) were concatenated into a vector. Pre-stimulus baselining was not applied to maintain stable information from previously presented stimuli. Dimensionality was reduced for each time point through a principal component analysis, maintaining 90% of the variance (between 250 to 600 ms this was around 209 ± 39 components, mean ± std.). To train an LDA classifier, the data were split into training and testing sets using 10-fold stratified cross-validation. Grating angles were binned into 10 equally spaced orientation bins (0° to 18°, 18° to 36°, 36° degree to 126°, 126° to 144°, 144° to 162°, 162° to 180°). For each trial and time point, we thus obtained 10 LDA distances estimating the likelihood for each of the bins. Representational similarity curves were constructed by aligning evidence across trials around the same category bin. In cross-decoding analyses, LDA classifiers were trained on orientation bins of one event (e.g., presented grating) but classifier evidence aligned around bins of another orientation (e.g., target orientation on the previous trial). The resulting representational similarity curves were convolved with a cosine.</p><p id="P19">To test which sensors most significantly contributed to the classifier likelihoods observed in our multivariate methods, we also ran a searchlight decoding analysis (<xref ref-type="bibr" rid="R36">Kriegeskorte, Goebel, &amp; Bandettini, 2006</xref>). In this analysis, we iteratively considered a small group of sensors and were thereby able to map the approximate locus of the observed effect. More specifically, we selected data from each sensor plus its 47 most closely adjacent neighbours (magnetometers and gradiometers included) and ran the same classification analysis as described above.</p></sec><sec id="S12"><label>2.10</label><title>Calculation of the Neural Asymmetry Score as a measure of Neural Bias</title><p id="P20">For within-trial biases, we assessed processing of the second grating and only considered 2-item trials. The classifier was trained on all presentations of the second grating and bin likelihoods were generated for each trial. For between-trial analyses, we analysed orientation processing of both the first and second grating in the current trial. For this reason, we trained the classifier on all trials and generated bin predictions for all trials.</p><p id="P21">Subsequently, based on the results from the performance-bias analyses, we selected trials in which the angular distance between the inducer and the grating orientation on the display led to a significant behavioural bias at the group level. In the case of the within-trial repulsive bias, the inducer was the orientation of the first grating on the same trial. For the between-trial analyses, the inducer was the target orientation reported on the previous trial (except for control analyses, where the unreported orientation was used as the target). As a dependent variable, we considered likelihood estimations for each orientation bin, where we expect the highest likelihood for the angular bin that has zero offset to the presented orientation and decreasing likelihoods for bins with larger angular distances to the presented orientation. We separately assessed likelihood estimations for trials in which the inducer orientation was clockwise (CW) vs counterclockwise (CCW) with respect to the current orientation. For both CW and CCW trials, we separately averaged the evidence from the orientation bins CW (-72° to -18°) and evidence from the CCW bins (18° to 72°). Asymmetry scores were computed by obtaining the difference between the two groups of angular bins (CW minus CCW). Finally, we calculated an overall neural bias score by subtracting asymmetry scores on trials with CW vs. CCW inducers. Attractive neural biases resulted in a positive score (i.e., trials with CW angular distances resulted in more CW evidence, CCW angular distances resulted in more CCW evidence), whereas repulsive neural biases resulted in a negative score (i.e., CW angular distances resulted in less CW evidence than CCW trials, and vice versa).</p></sec><sec id="S13"><label>2.11</label><title>Statistical Testing</title><p id="P22">Statistical tests were computed using both JASP (<xref ref-type="bibr" rid="R53">Team, 2020</xref>) and Scipy (<xref ref-type="bibr" rid="R55">Virtanen et al., 2020</xref>). We tested the time series of cosine-convolved classifier evidence against zero using a cluster-based permutation test, which addresses the multiple comparison problem (using MNE; <xref ref-type="bibr" rid="R27">Gramfort et al., 2013</xref>). We ran 100,000 iterations. The clusters with groups of time points significantly different from zero are indicated in the relevant figures using horizontal lines. Cluster-based permutation testing was also applied to performance bias across angular distance between the presented orientation and the inducer orientation.</p><p id="P23">The time period of interest for the neural bias analyses included all timepoints in which cosine- convolved classifier evidence for the presented grating orientation was significantly above zero in our comparison analyses (in all reported time averages, time points between 250 and 600 ms were used).</p><p id="P24">All tests were two-sided unless stated otherwise.</p></sec></sec><sec id="S14" sec-type="results"><label>3</label><title>Results</title><sec id="S15"><label>3.1</label><title>Error Rates</title><p id="P25">Participants were accurate in reproducing the target orientation (mean response error 11.73° ± 0.70° SEM; mean standard deviation 17.61° ± 1.07° S.E.M., see <xref ref-type="table" rid="T1">Table 1</xref> for condition-wise performance). A 2-by-2 repeated-measures ANOVA on response error showed main effects of cue type (F<sub>1,19</sub> = 16.49, <italic>p</italic> &lt; .001, <italic>η</italic><sup>2</sup> = 0.374) and number of stimuli presented (F<sub>1,19</sub> = 29.78, <italic>p</italic> &lt; .001, <italic>η</italic><sup>2</sup> = 0.075). Cue type was significant for both 1- or 2-item trials, with absolute error higher on report 1st than on report 2nd trials for both 2-item trials (<italic>t</italic><sub>19</sub> = 3.972, <italic>p</italic> &lt; .001, <italic>d</italic> = 0.888; see <xref ref-type="table" rid="T1">Table 1</xref>) and 1-item trials (<italic>t</italic><sub>19</sub> = 3.948, Bonferroni-corrected <italic>p</italic> &lt; .001, <italic>d</italic> = 0.883). By contrast, number of items presented primarily affected the report 1st conditions. Error was higher on report 1st 2-item than on report 1st 1-item trials (<italic>t</italic><sub>19</sub> = 5.665, <italic>p</italic> &lt; .001, <italic>d</italic> = 1.267) but did not significantly differ between report 2nd 2-item and report 2nd 1-item trials (<italic>t</italic><sub>19</sub> = 1.885, <italic>p</italic> = .075, <italic>d</italic> = 0.421), leading to a significant interaction between the two factors (F<sub>1,19</sub> = 10.90, <italic>p</italic> = .004, <italic>η</italic><sup>2</sup> = 0.026). Analyses using mixture modelling (<xref ref-type="bibr" rid="R4">Bays, Catalao, &amp; Husain, 2009</xref>) confirmed that errors originating from responses to the non-cued grating orientation were rare (swap rate of .033 ± .01 on two-item trials; see also <xref ref-type="bibr" rid="R30">Huang, 2020</xref>).</p></sec><sec id="S16"><label>3.2</label><title>Repulsive performance biases within trials</title><p id="P26">We analysed within-trial biases in behavioural performance by assessing whether the reported orientation was systematically reported as closer to or further away from the non-target orientation on the same trial (see <xref ref-type="sec" rid="S2">Methods</xref>). We restricted the analyses to 2-item trials. <xref ref-type="fig" rid="F2">Figure 2A</xref> shows the performance bias for all absolute angular distances between the first and second grating orientation for report 1st and report 2nd trials. In trials with report 1st cues, there was no significant bias towards or away from the interfering second grating orientation that was not relevant to the task at hand (<italic>t</italic><sub>19</sub> = 0.74, <italic>p</italic> = .467). In contrast, trials with report 2nd cues revealed significant biases away from the initially encoded first grating orientation (<italic>t</italic><sub>19</sub> = −2.33, <italic>p</italic> = .031; illustrated in <xref ref-type="fig" rid="F2">Figure 2B</xref>). The repulsive bias in report 2nd trials was confirmed using a cluster-based permutation test, showing a significant cluster (p = .012) when the angular distance between the two orientations was between 10° and 49° (<xref ref-type="fig" rid="F2">Figure 2A</xref>).</p></sec><sec id="S17"><label>3.3</label><title>Attractive Performance Bias Between Trials</title><p id="P27">We next evaluated the between-trial bias on responses in the current trial towards the orientation that was cued on the previous trial (<xref ref-type="fig" rid="F3">Figure 3</xref>). We assessed the performance bias as a function of angular differences between the target grating on the current and on the previous trial. The analysis also considered the position of the target grating in the current trial (1<sup>st</sup> or 2<sup>nd</sup>) and the number of items on the current trial (1- or 2-items). For consistency, we term all trials where participants report the first grating orientation report 1st trials and trials where participants report the second orientation report 2nd trials, regardless of the number of gratings presented. Again, we calculated the sum of the bias across angular distances between targets in the current and previous trial <xref ref-type="fig" rid="F3">Figure 3A, B</xref>. In contrast to the repulsive bias described in the previous section, we found that all conditions showed an attractive performance bias (all <italic>p</italic> &lt; .05 in two-sided statistical tests). The attractive serial bias was most pronounced for small to intermediate angular distances between the inducer and current orientation (0 - 60°). A repeated-measures ANOVA on the sum of biases across angular distances indicated an effect of cue type, with larger biases occurring in report 1st trials (F<sub>1,19</sub> = 5.706, <italic>p</italic> = .027, <italic>η</italic><sup>2</sup> = .172), but not of the number of gratings presented in a trial (F<sub>1,19</sub> = .980, <italic>p</italic> = .335, <italic>η</italic><sup>2</sup> = .007). The two factors did not interact (<italic>F</italic><sub>1,19</sub> = .377, <italic>p</italic> = .547, <italic>η</italic><sup>2</sup> = .002). This shows that the bias was stronger when recalling the first item, which was encoded closer in time to the previous trial.</p></sec><sec id="S18"><label>3.4</label><title>Task Dependence of Attractive Performance Bias Between Trials</title><p id="P28">Next, we repeated the same between-trial analyses but investigated the role of task relevance and cue type in the previous trial. This allowed us to test for and compare behavioural biases elicited by the probed (and reported) orientation and by the unreported orientation in the previous trial. We also tested whether the cue type on the previous trial affected bias in the current trial. We only looked at trials in which two orientations were presented on the previous trial.</p><p id="P29">A repeated-measures ANOVA on the sum of angular distances of the performance bias for task relevance and cue type confirmed an effect of task relevance (F<sub>1,19</sub> = 14.684, <italic>p</italic> = .001; <xref ref-type="fig" rid="F3">Figure 3D</xref>) but showed no effect of cue type (F<sub>1,19</sub> = 1.423, <italic>p</italic> = .248) or interaction(F<sub>1,19</sub> = 1.633, <italic>p</italic> = .216). Task-relevant orientations in trials of either cue type resulted in a significant bias (previous trial was report 1st and contained 2 items: <italic>t</italic><sub>19</sub> = 3.524, <italic>p</italic> = .002; previous trial was report 2nd and contained 2-items: <italic>t</italic><sub>19</sub> = 4.476, <italic>p</italic> &lt; .001). Unprobed orientations did not lead to a significant bias (both <italic>p</italic> &gt; .2). No reliable difference was observed between the strength of the bias between report 2nd 2-items or report 1st 2-items conditions in previous trials (<italic>t</italic><sub>19</sub> = 1.691, <italic>p</italic> = .107). Following up, we assessed the performance bias as a function of the angular distance between the current target orientation and previously presented orientations. Cluster-based permutation testing showed an attractive bias towards the task-relevant orientation on the previous trial when a report 1st cue (p = .001; 7° – 58°; <xref ref-type="fig" rid="F3">Figure 3C</xref>) or a report 2nd cue (p &lt; .001; 4° – 77°) was presented in the previous trial. For unreported orientations, no bias was observed (no candidate clusters for report 1st or report 2nd cue). Together, this pattern of results is showing an attractive between-trial bias, but only with regard to items that were relevant in the previous trial.</p></sec><sec id="S19"><label>3.5</label><title>Neural Classification of Presented Orientations</title><p id="P30">For our classification analysis, grating orientations were binned into 10 equally spaced bins. We applied Linear Discriminant Analysis (LDA) on spatial and temporal features from all 306 MEG sensors ranging from 400 ms prior to stimulus onset up to 900 ms post stimulus onset (see <xref ref-type="sec" rid="S2">Methods</xref>). If orientation information was present, LDA likelihood estimations gave rise to representational similarity curves centred on the presented orientation that could be convolved with a cosine function to result in a single evidence estimation per time point. LDA classification reflected significant evidence for the presented orientation after the visual onset of the grating (<xref ref-type="fig" rid="F4">Figure 4</xref>). This revealed significant decoding of both the first grating orientation (100 – 615 ms; <italic>p</italic> &lt; .001) and the second grating orientation (95 – 590 ms; <italic>p</italic> &lt; .001). A non-significant trend was observed for the evidence of the first grating orientation following the presentation of the second grating (250 – 600 ms; <italic>t</italic><sub>19</sub>= 1.971; <italic>p</italic> = .063; see also cross-decoding analyses below). There was no difference in classifier evidence after a report 1st or report 2nd cue (250 – 600 ms; <italic>t</italic><sub>19</sub>= 0.798; <italic>p</italic> = .435).</p></sec><sec id="S20"><label>3.6</label><title>Within-trial Classification Bias Away From Previous Stimulus</title><p id="P31">Representational similarity curves were used to estimate the direction and magnitude of neural biases in orientation representation. By training the classifier on all stimuli, orientation history biases should cancel out, allowing testing on trials with specific prior orientations (clockwise vs. counterclockwise to current stimulus) to reveal any neural biases. To investigate how information from the second grating was modulated by information from the first grating, we separately assessed trials with report 1st and report 2nd cues. Doing so, we evaluated the classification evidence in the MEG data in the epoch following the presentation of the second grating. For these analyses, we again only selected trials with both gratings were presented. We separated trials in which the first grating was clockwise vs. counterclockwise relative to the second grating (angular distance of 10° - 50°, based on behavioural results, see <xref ref-type="fig" rid="F2">Figure 2A, B</xref>). We considered the average of time points between 250 – 600 ms for all future analyses, since in this time window stimulus orientation could be decoded with reliable accuracy in this time window (see <xref ref-type="fig" rid="F4">Figure 4</xref> and grey-shaded area in <xref ref-type="fig" rid="F5">Figure 5</xref>). Echoing the performance biases, no significant bias occurred on report 1st trials (<xref ref-type="fig" rid="F5">Figure 5A, B</xref>; <italic>t</italic><sub>19</sub>= –0.723; <italic>p</italic> = .478). However, on report 2nd trials, we observed a repulsive effect, away from the previously encoded grating orientation (<xref ref-type="fig" rid="F5">Figure 5C, D</xref>; <italic>t</italic><sub>19</sub>= –3.52; <italic>p</italic> = .002).</p><p id="P32">There was no correlation, across participants, between the magnitude of the bias in the behavioural and neural data on report 1st trials (<italic>r</italic> = .010; <italic>p</italic> = .968) or report 2nd trials (<italic>r</italic> = −.328; <italic>p</italic> = .158).</p></sec><sec id="S21"><label>3.7</label><title>Repulsive Neural Biases Between Trials Away From Sensory History</title><p id="P33">To probe for neural between-trial biases, we used the same approach as for within-trial neural biases. We tested the LDA evidence derived during the stimulus encoding period for systematic deviations in likelihood estimations as a function of the angular distance between the current orientation and the probed orientation on the previous trial. If the behavioural between-trial bias reflects neural modulation during encoding of sensory features, we would expect to see an increase in likelihood for orientations presented in the previous trial, in line with the attractive performance bias. We trained the classifier on data following presentation of both the first and second grating orientation combined and included all cue types and number of items presented. Informed by our behavioural analyses on between-trial performance biases, for the test set we selected trials where the previous probe angle had a relative difference of 0° – 60° (<xref ref-type="fig" rid="F3">Figure 3A, B</xref>; derived from significant angular differences) positive or negative from the presented grating orientation. The results were qualitatively the same and remained significant when other angular ranges were selected.</p><p id="P34">Contrary to our expectations, classifier evidence was significantly shifted away from the target orientation on the previous trial (250 – 600 ms post grating onset; <italic>t</italic><sub>19</sub>= –2.83, <italic>p</italic> = .011; <xref ref-type="fig" rid="F6">Figure 6A - D</xref>) rather than mirroring the attractive behavioural bias. In practice, this would mean that if the cued orientation on the previous trial was CW, classifier evidence for CCW bins increased, and vice versa. The repulsive bias away from the target on the previous trial trended towards significance for the first (<italic>t</italic><sub>19</sub> = –1.78, <italic>p</italic> = .090) and was significant for the second grating (<italic>t</italic><sub>19</sub> = −2.43, <italic>p</italic> = .025) in the current trial when considered separately (<xref ref-type="fig" rid="F6">Figure 6C</xref>). The between-trial repulsive bias during stimulus-two processing was present if no orientation was presented in the first interval (<italic>t</italic><sub>19</sub> = −2.69, <italic>p</italic> = .014) but not when the first grating was also presented (<italic>t</italic><sub>19</sub> = −1.68, <italic>p</italic> = .110). Interestingly, topographies in <xref ref-type="fig" rid="F6">Figure 6D</xref> and <xref ref-type="fig" rid="F6">Figure 6G</xref> were highly similar (<italic>r</italic> = .563; <italic>p</italic> &lt; .001) and both topographies correlated negatively with the stimulus-decoding topography (<xref ref-type="fig" rid="F6">Figure 6D</xref>, <italic>r</italic> = .558, <italic>p</italic> &lt; .001; <xref ref-type="fig" rid="F6">Figure 6G</xref>, <italic>r</italic> = .763, <italic>p</italic> &lt; .001). Next, we tested whether this repulsive neural bias was affected by the task relevance of the grating and by the cueing condition of the previous trial. We quantified this bias for task-relevant and task-irrelevant grating orientations in the previous trial. Only trials where the previous trial contained two items were included in this analysis. When averaging the neural bias over 250 – 600 ms, the task-relevant orientation showed a repulsive neural bias (<italic>t</italic><sub>19</sub> = -2.78, <italic>p</italic> = .012), but we found no neural bias for task-irrelevant orientations (<italic>t</italic><sub>19</sub> = −0.33, <italic>p</italic> = .743), though this difference did not reach significance (<italic>t</italic><sub>19</sub> = 1.80, <italic>p</italic> = .088). Yet, cluster-based permutation testing indicated a significant cluster indicating that task-relevant orientations exerted a significantly stronger repulsive bias than task-irrelevant orientations (500 – 550 ms; <italic>p</italic> = .039).</p></sec><sec id="S22"><label>3.8</label><title>Cross-Decoding Evidence for Previously Presented Stimuli</title><p id="P35">If information about the previously presented orientation is still partially present in the visual system during and after the presentation of the current grating orientation, it could interact with encoding, possibly leading to the observed repulsive bias. One possibility is that the lingering representation is in an orthogonal representational format, which is different from sensory coding of features (<xref ref-type="bibr" rid="R37">Libby &amp; Buschman, 2021</xref>). In this case there would be little to no overlap between the activation pattern elicited during sensory input and the pattern related to the lingering representation of that past grating orientation. A classifier trained to separate perceptual information would therefore not cross-generalise if tested on the memory code. Alternatively, the lingering code could be present in a stable representation that shares similarity with the representation of incoming sensory information. If this were the case, a classifier, trained on the data from the current grating orientation, would cross-generalise and identify information about the past grating (or suppression of information expressed in negative evidence).</p><p id="P36">We adapted cross-decoding to detect lingering orientation-selective activity from the previous trial (also see <xref ref-type="bibr" rid="R57">Wan, Cai, Samaha, &amp; Postle, 2020</xref>). After training the classifier for the presented orientation and testing for evidence of the previous trial’s target orientation, we observed significant negative classifier evidence in the period of 250 – 600 after grating onset (<xref ref-type="fig" rid="F6">Figure 6F</xref>; concatenating over grating one and grating two: <italic>t</italic><sub>19</sub>= −2.820, <italic>p</italic> = .011; grating one alone, <italic>t</italic><sub>19</sub>= −1.376, <italic>p</italic> = .185; grating two, <italic>t</italic><sub>19</sub>= −2.951, <italic>p</italic> = .008).</p><p id="P37">Negative classifier evidence indicates that, while information is still present about the previous orientation, orientation-selective patterns may be sign-reversed relative to stimulus encoding. This suppression of evidence for the previous trial’s orientation could have been the cause of the apparent repulsive bias in the decoding of the current trial’s orientation. If this was the case, we would expect the two measures to be positively correlated: stronger suppression of the previous orientation (negative classifier evidence) should lead to a more negative bias for the current orientation. We tested this using Pearson correlations across participants and found a significant correlation when assessing all grating presentations together (<xref ref-type="fig" rid="F6">Figure 6E</xref>; <italic>r</italic> = .832, <italic>p</italic> &lt; .001; grating one alone, <italic>r</italic> = .685, <italic>p</italic> &lt; .001; grating two alone, <italic>r</italic> = .751, <italic>p</italic> &lt; .001).</p><p id="P38">No correlation was observed between the attractive behavioural performance bias and the magnitude of the negative shift in the neural data (<italic>r</italic> = .186, <italic>p</italic> = .432) nor with the magnitude of negative decoding (<italic>r</italic> = .144, <italic>p</italic> = .544).</p></sec></sec><sec id="S23" sec-type="discussion"><label>4</label><title>Discussion</title><p id="P39">The present study investigated biases from previously perceived and memorised information on neural coding and behavioural responses. We observed both neural and behavioural biases that demonstrate interactions between past and present sensory processing. Orientations presented on the <italic>same</italic> trial exerted repulsive performance biases on currently perceived orientations. In contrast, task-relevant orientations on the <italic>previous</italic> trial exerted an opposite, attractive performance bias, altogether providing evidence for two counteracting biasing processes acting in tandem. Interestingly, multivariate decoding of neural data indicated that both stimuli from the same and previous trial generate a repulsive neural bias, suggesting that the two types of performance biases may arise from modulations acting on different stages of stimulus processing. While repulsive biases could reflect mechanisms akin to visual adaptation that promote visual discriminability, the attractive performance bias observed across trials had no equivalent attractive modulation at the level of the sensory representation. Since a neural repulsive bias occurred instead, we suggest that post-perceptual modulatory mechanisms may override any early repulsive sensory modulation and lead to attractive performance biases.</p><p id="P40">The present behavioural results provide evidence of two types of performance biases: a repulsive within-trial and an attractive between-trial performance bias (c.f., <xref ref-type="bibr" rid="R3">Bae &amp; Luck, 2020</xref>; <xref ref-type="bibr" rid="R18">Fischer, Czoschke, et al., 2020</xref>). Both biases were modulated by the task relevance of the inducing stimulus. Firstly, we identified a repulsive performance bias away from the first orientation in a trial, but no significant retrospective repulsive bias from the second orientation, even though the second grating was presented closer in time to the probe. We speculate that this may have happened because the relevance cue appeared together with this second stimulus, indicating its irrelevance in probe-first trials. Similarly, participants’ responses in the current trial were biased only towards task-relevant orientations in the previous trial. At the neural level, biases were also dependent on task relevance. A repulsive neural bias was only present when the presented orientation was cued as task-relevant and therefore encoded into working memory. By contrast, task-irrelevant gratings that were not encoded into working memory could be decoded with similar precision but did not exhibit a significant bias. Gratings from previous trials that were associated with an attractive performance bias also led to repulsive neural biases during working-memory encoding. Only task-relevant orientations led to a repulsive bias.</p><p id="P41">Adaptation could partly explain the repulsive neural bias observed here. Visual adaptation has been proposed as the cause of repulsive neural biases (<xref ref-type="bibr" rid="R31">Jazayeri &amp; Movshon, 2006</xref>, <xref ref-type="bibr" rid="R32">2007</xref>; <xref ref-type="bibr" rid="R35">Kohn, 2007</xref>; <xref ref-type="bibr" rid="R49">Stocker &amp; Simoncelli, 2008</xref>; <xref ref-type="bibr" rid="R58">Webster, 2015</xref>). Since adaptation reduces firing in recently active neurons (Clifford, Wenderoth, &amp; Spehar, 2000; <xref ref-type="bibr" rid="R56">Wainwright, 1999</xref>), it is an efficient use of finite neural resources (<xref ref-type="bibr" rid="R49">Stocker &amp; Simoncelli, 2008</xref>; <xref ref-type="bibr" rid="R58">Webster, 2015</xref>) when the environment is autocorrelated because neurons can code for a larger range of stimuli when their responses are not saturated. Curiously, we observed a repulsive neural bias only on report 2nd trials, when the presented orientation was task-relevant and encoded into working memory. The interaction with task relevance suggests that stimulus processing is only biased when it is primed for later use in upcoming behaviour.</p><p id="P42">This task-dependent modulation was unlikely the result of reduced processing of task-irrelevant stimuli, as overall orientation decoding was not affected by task relevance. In line with recent studies, it is possible that a context-sensitive repulsive bias, possibly occurring at a post-perceptual stage (<xref ref-type="bibr" rid="R23">Fritsche &amp; de Lange, 2019</xref>; <xref ref-type="bibr" rid="R62">Zamboni, Ledgeway, McGraw, &amp; Schluppeck, 2016</xref>), exists alongside an early perceptual bias based on visual adaptation (<xref ref-type="bibr" rid="R24">Fritsche, Mostert, &amp; de Lange, 2017</xref>). The task-dependency of the neural bias could be the basis of recently observed repulsive biases in behaviour (<xref ref-type="bibr" rid="R1">Bae &amp; Luck, 2017</xref>; <xref ref-type="bibr" rid="R9">Chunharas, Rademaker, Brady, &amp; Serences, 2019</xref>; <xref ref-type="bibr" rid="R14">Czoschke, Fischer, Beitner, Kaiser, &amp; Bledowski, 2019</xref>; <xref ref-type="bibr" rid="R15">Czoschke, Peters, Rahm, Kaiser, &amp; Bledowski, 2020</xref>), which may help individuate concurrently maintained stimuli (e.g. <xref ref-type="bibr" rid="R59">Wei, Wang, &amp; Wang, 2012</xref>). Under this explanation, only attended and encoded features would be subject to interactions with previous features.</p><p id="P43">The bias imposed by the orientation from the previous trial was attractive in behaviour but repulsive in the neural data at early processing stages. This contrast is ostensibly at odds with previous behavioural studies that have assigned an early perceptual origin to attractive between-trial biases (e.g., <xref ref-type="bibr" rid="R11">Cicchini, Mikellidou, &amp; Burr, 2017</xref>; <xref ref-type="bibr" rid="R12">Cicchini, Mikellidou, &amp; Burr, 2018</xref>; <xref ref-type="bibr" rid="R19">Fischer &amp; Whitney, 2014</xref>). There is still little direct neural evidence confirming this. EEG studies have shown that previous trial information can be decoded during the encoding phase of the current trial (<xref ref-type="bibr" rid="R2">Bae &amp; Luck, 2019</xref>) or immediately prior to the current trial (Barbosa et al., 2020), and visually evoked neural responses in numerosity judgement tasks are modulated by stimulus history (<xref ref-type="bibr" rid="R20">Fornaciai &amp; Park, 2018</xref>, <xref ref-type="bibr" rid="R21">2019</xref>). However, the mere presence of prior stimulus information does not imply an attractive bias on the current stimulus. One study observed an attractive behavioural bias and a neural bias in early visual areas using fMRI (<xref ref-type="bibr" rid="R47">St John-Saaltink, Kok, Lau, &amp; de Lange, 2016</xref>). However, this study used only two stimulus orientations (45° and 135°) with an offset too large to produce a reliable behavioural bias, meaning that our findings may reflect a different biasing phenomenon.</p><p id="P44">Contradicting the early sensory origin of serial attractive bias, a recent fMRI study (<xref ref-type="bibr" rid="R45">Sheehan &amp; Serences, 2021</xref>) found evidence consistent with the present results. Sheehan et al. observed repulsive neural biases relative to the orientation on the previous trial across in visual cortex, in spite of an attractive behavioural bias, and found that models incorporating early visual adaptation and a post-perceptual origin of attractive biases could explain both effects. These results are in line with the present findings. Together, the observations make a case that prior stimuli lead to repulsion at the encoding stage and that attractive performance biases may arise elsewhere. Our findings further indicate that the link between neural adaptation and behaviour should be context-dependent, since we observed repulsive neural biases together with both repulsive and attractive behavioural biases. Therefore, future models linking visual adaptation to behaviour may need to incorporate context-dependence. Additionally, the high temporal resolution of MEG allowed us to show that neural biases arise within 500 ms of stimulus onset, have a posterior origin, and that they occur simultaneously relative to multiple prior stimuli (from the same trial and the previous trial).</p><p id="P45">While Sheehan and colleagues argued that past stimuli were stored in a non-sensory code, they did not directly examine whether the representation of past stimuli occurred in a shared neural subspace with the representation of current stimuli. Here, we addressed this issue by showing that neural suppression of recently active neural populations could account for the observed repulsive bias. We tested this using cross-decoding analyses, training a classifier on the presented orientation and predicting previous orientations. Consistent with the suppression of recent stimulus-specific activity, cross-decoding yielded below-chance decoding of the previous orientation. In turn, this may have shifted the neural tuning curve for the current orientation away from the previous orientation, generating a repulsive bias. This relationship was confirmed by the robust correlation between cross-decoding and repulsive bias magnitude.</p><p id="P46">Another recent study observed a repulsive neural bias in single-unit recordings from frontal eye fields (FEF) paired with an attractive behavioural bias in a delayed-saccade task (<xref ref-type="bibr" rid="R40">Papadimitriou, White, &amp; Snyder, 2017</xref>). The authors suggested that lingering attention to the previous target location could warp the representation of current target locations (<xref ref-type="bibr" rid="R64">Zirnsak, Steinmetz, Noudoost, Xu, &amp; Moore, 2014</xref>). Since we observed neural biases primarily in posterior sensors, our results are more in line with a sensory origin of the repulsive bias, but this may interact with attentional biases originating in frontal cortex (<xref ref-type="bibr" rid="R38">Moore &amp; Armstrong, 2003</xref>; <xref ref-type="bibr" rid="R52">Taylor, Nobre, &amp; Rushworth, 2007</xref>). Attentional modulation could be one explanation for the context-dependency of biases observed here.</p><p id="P47">Altogether, we demonstrate a consistent repulsive shift in neural evidence during working-memory encoding. Our results imply that perceptual adaptation, along with context-sensitive factors, contributes to feature-selective downweighting to exert a repulsive bias away from recent stimulus features. Interestingly, no evidence of an attractive neural bias acting directly on sensory aspects of encoding was observed. Neural data thereby provide indirect evidence for the post-perceptual account of attractive between-trial biases, rather than modulating encoding stages (<xref ref-type="bibr" rid="R3">Bae &amp; Luck, 2020</xref>; <xref ref-type="bibr" rid="R5">Bliss, Sun, &amp; D’Esposito, 2017</xref>; <xref ref-type="bibr" rid="R24">Fritsche, Mostert, &amp; de Lange, 2017</xref>; <xref ref-type="bibr" rid="R33">Kim, Burr, Cicchini, &amp; Alais, 2020</xref>; <xref ref-type="bibr" rid="R41">Pascucci et al., 2019</xref>). We speculate that the attractive between-trial bias instead arises through post-perceptual processing stages involving memory (<xref ref-type="bibr" rid="R5">Bliss, Sun, &amp; D’Esposito, 2017</xref>; <xref ref-type="bibr" rid="R24">Fritsche, Mostert, &amp; de Lange, 2017</xref>), perceptual decision-making, or motor planning (<xref ref-type="bibr" rid="R6">Boettcher, Gresch, Nobre, &amp; van Ede, 2021</xref>; <xref ref-type="bibr" rid="R16">de Azevedo Neto &amp; Bartels, 2021</xref>; <xref ref-type="bibr" rid="R43">Sadil, Cowell, &amp; Huber, 2021</xref>). The source of the attractive between-trial bias, whatever its neural mechanism, may be strong enough to override the repulsive bias during the perceptual/encoding stage. Together, these co-existing biases may help guide efficient coding for nuanced perceptual discriminations and visual stability across our environment.</p></sec></body><back><ack id="S24"><title>Acknowledgements</title><p>This research was funded by an ESRC Grand Union studentship and the Scatcherd European Scholarship awarded to <bold>J.E.H.,</bold> an ERC Starting Grant from the European Research Council (MEMTICIPATION, 850636) to <bold>F.v.E.,</bold> was supported by a James S. McDonnell Foundation Scholar Award (220020405) and an ESRC grant (ES/S015477/1) to <bold>M.G.S.,</bold> a James S. McDonnell Foundation Understanding Human Cognition Collaborative Award (number 220020448) and a Wellcome Trust Senior Investigator Award (104571/Z/14/Z) to <bold>A.C.N.,</bold> as well as a Wellcome Trust award (201409/Z/16/Z) and with support from University College Oxford to <bold>N.E.M.</bold> The work was enabled by the NIHR Oxford Health Biomedical Research Centre and the Wellcome Centre for Integrative Neuroimaging is supported by core funding from the Wellcome Trust (203139/Z/16/Z). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. For the purpose of Open Access, the author has applied a CC BY public copyright licence to any Author Accepted Manuscript version arising from this submission.</p></ack><sec id="S25" sec-type="data-availability"><title>Data Availability</title><p id="P48">Data and analysis scripts can be accessed via <ext-link ext-link-type="uri" xlink:href="https://osf.io/98ujm/">https://osf.io/98ujm/</ext-link>.</p></sec><fn-group><fn id="FN1" fn-type="conflict"><p id="P49"><bold>Conflict of interest</bold></p><p id="P50">The authors declare no conflict of interest.</p></fn></fn-group><ref-list><ref id="R1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bae</surname><given-names>GY</given-names></name><name><surname>Luck</surname><given-names>SJ</given-names></name></person-group><article-title>Interactions between visual working memory representations</article-title><source>Attention, Perception, and Psychophysics</source><year>2017</year><volume>79</volume><issue>8</issue><fpage>2376</fpage><lpage>2395</lpage><pub-id pub-id-type="doi">10.3758/s13414-017-1404-8</pub-id></element-citation></ref><ref id="R2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bae</surname><given-names>GY</given-names></name><name><surname>Luck</surname><given-names>SJ</given-names></name></person-group><article-title>Reactivation of Previous Experiences in a Working Memory Task</article-title><source>Psychological Science</source><year>2019</year><volume>30</volume><issue>4</issue><fpage>587</fpage><lpage>595</lpage><pub-id pub-id-type="doi">10.1177/0956797619830398</pub-id></element-citation></ref><ref id="R3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bae</surname><given-names>GY</given-names></name><name><surname>Luck</surname><given-names>SJ</given-names></name></person-group><article-title>Serial dependence in vision: Merely encoding the previous-trial target is not enough</article-title><source>Psychonomic Bulletin and Review</source><year>2020</year><volume>27</volume><issue>2</issue><fpage>293</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.3758/s13423-019-01678-7</pub-id></element-citation></ref><ref id="R4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bays</surname><given-names>PM</given-names></name><name><surname>Catalao</surname><given-names>RFG</given-names></name><name><surname>Husain</surname><given-names>M</given-names></name></person-group><article-title>The precision of visual working memory is set by allocation of a shared resource</article-title><source>Journal of vision</source><year>2009</year><volume>9</volume><issue>10</issue><fpage>7.1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1167/9.10.7</pub-id></element-citation></ref><ref id="R5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bliss</surname><given-names>DP</given-names></name><name><surname>Sun</surname><given-names>JJ</given-names></name><name><surname>D’Esposito</surname><given-names>M</given-names></name></person-group><article-title>Serial dependence is absent at the time of perception but increases in visual working memory</article-title><source>Scientific Reports</source><year>2017</year><volume>7</volume><issue>1</issue><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1038/s41598-017-15199-7</pub-id></element-citation></ref><ref id="R6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boettcher</surname><given-names>SE</given-names></name><name><surname>Gresch</surname><given-names>D</given-names></name><name><surname>Nobre</surname><given-names>AC</given-names></name><name><surname>van Ede</surname><given-names>F</given-names></name></person-group><article-title>Output planning at the input stage in visual working memory</article-title><source>Science Advances</source><year>2021</year><volume>7</volume><issue>13</issue><fpage>1</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1126/sciadv.abe8212</pub-id></element-citation></ref><ref id="R7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Born</surname><given-names>RT</given-names></name><name><surname>Tootell</surname><given-names>RBH</given-names></name></person-group><article-title>Middle temporal visual area</article-title><source>Nature</source><year>1992</year><volume>357</volume><month>June</month><fpage>497</fpage><lpage>499</lpage></element-citation></ref><ref id="R8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname><given-names>DH</given-names></name></person-group><article-title>The Psychophysics Toolbox</article-title><source>Spatial Vision</source><year>1997</year><volume>10</volume><fpage>433</fpage><lpage>436</lpage><pub-id pub-id-type="doi">10.1163/156856897X00357</pub-id></element-citation></ref><ref id="R9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chunharas</surname><given-names>C</given-names></name><name><surname>Rademaker</surname><given-names>R</given-names></name><name><surname>Brady</surname><given-names>T</given-names></name><name><surname>Serences</surname><given-names>J</given-names></name></person-group><source>Adaptive memory distortion in visual working memory</source><year>2019</year><pub-id pub-id-type="doi">10.31234/osf.io/e3m5a</pub-id><comment>743941</comment></element-citation></ref><ref id="R10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cicchini</surname><given-names>GM</given-names></name><name><surname>Anobile</surname><given-names>G</given-names></name><name><surname>Burr</surname><given-names>DC</given-names></name></person-group><article-title>Compressive mapping of number to space reflects dynamic encoding mechanisms, not static logarithmic transform</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><year>2014</year><volume>111</volume><issue>21</issue><fpage>7867</fpage><lpage>7872</lpage><pub-id pub-id-type="doi">10.1073/pnas.1402785111</pub-id></element-citation></ref><ref id="R11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cicchini</surname><given-names>GM</given-names></name><name><surname>Mikellidou</surname><given-names>K</given-names></name><name><surname>Burr</surname><given-names>D</given-names></name></person-group><article-title>Serial dependencies act directly on perception</article-title><source>Journal of Vision</source><year>2017</year><volume>17</volume><issue>14</issue><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1167/17.14.6</pub-id></element-citation></ref><ref id="R12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cicchini</surname><given-names>GM</given-names></name><name><surname>Mikellidou</surname><given-names>K</given-names></name><name><surname>Burr</surname><given-names>DC</given-names></name></person-group><article-title>The functional role of serial dependence</article-title><source>Proceedings of the Royal Society B: Biological Sciences</source><year>2018</year><volume>285</volume><issue>1890</issue><pub-id pub-id-type="doi">10.1098/rspb.2018.1722</pub-id></element-citation></ref><ref id="R13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clifford</surname><given-names>CW</given-names></name><name><surname>Wenderoth</surname><given-names>P</given-names></name><name><surname>Spehar</surname><given-names>B</given-names></name></person-group><article-title>A functional angle on some after-effects in cortical vision</article-title><source>Proceedings of the Royal Society B: Biological Sciences</source><year>2000</year><volume>267</volume><issue>1454</issue><fpage>1705</fpage><lpage>1710</lpage><pub-id pub-id-type="doi">10.1098/rspb.2000.1198</pub-id></element-citation></ref><ref id="R14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Czoschke</surname><given-names>S</given-names></name><name><surname>Fischer</surname><given-names>C</given-names></name><name><surname>Beitner</surname><given-names>J</given-names></name><name><surname>Kaiser</surname><given-names>J</given-names></name><name><surname>Bledowski</surname><given-names>C</given-names></name></person-group><article-title>Two types of serial dependence in visual working memory</article-title><source>British Journal of Psychology</source><year>2019</year><volume>110</volume><issue>2</issue><fpage>256</fpage><lpage>267</lpage><pub-id pub-id-type="doi">10.1111/bjop.12349</pub-id></element-citation></ref><ref id="R15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Czoschke</surname><given-names>S</given-names></name><name><surname>Peters</surname><given-names>B</given-names></name><name><surname>Rahm</surname><given-names>B</given-names></name><name><surname>Kaiser</surname><given-names>J</given-names></name><name><surname>Bledowski</surname><given-names>C</given-names></name></person-group><article-title>Visual objects interact differently during encoding and memory maintenance</article-title><source>Attention, Perception, and Psychophysics</source><year>2020</year><volume>82</volume><issue>3</issue><fpage>1241</fpage><lpage>1257</lpage><pub-id pub-id-type="doi">10.3758/s13414-019-01861-x</pub-id></element-citation></ref><ref id="R16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Azevedo Neto</surname><given-names>RM</given-names></name><name><surname>Bartels</surname><given-names>A</given-names></name></person-group><article-title>Disrupting short-term memory maintenance in premotor cortex affects serial dependence in visuomotor integration</article-title><source>Journal of Neuroscience</source><year>2021</year><volume>41</volume><issue>45</issue><fpage>9392</fpage><lpage>9402</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0380-21.2021</pub-id></element-citation></ref><ref id="R17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dong</surname><given-names>D</given-names></name><name><surname>Atick</surname><given-names>J</given-names></name></person-group><article-title>Statistics of natural time-varying images</article-title><source>Network: Computation in Neural Systems</source><year>1995</year><volume>6</volume><issue>3</issue><fpage>345</fpage><lpage>358</lpage><pub-id pub-id-type="doi">10.1088/0954-898X/6/3/003</pub-id></element-citation></ref><ref id="R18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischer</surname><given-names>C</given-names></name><name><surname>Czoschke</surname><given-names>S</given-names></name><name><surname>Peters</surname><given-names>B</given-names></name><name><surname>Rahm</surname><given-names>B</given-names></name><name><surname>Kaiser</surname><given-names>J</given-names></name><name><surname>Bledowski</surname><given-names>C</given-names></name></person-group><article-title>Context information supports serial dependence of multiple visual objects across memory episodes</article-title><source>Nature Communications</source><year>2020</year><volume>11</volume><issue>1</issue><pub-id pub-id-type="doi">10.1038/s41467-020-15874-w</pub-id></element-citation></ref><ref id="R19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischer</surname><given-names>J</given-names></name><name><surname>Whitney</surname><given-names>D</given-names></name></person-group><article-title>Serial dependence in visual perception</article-title><source>Current Biology</source><year>2014</year><volume>16</volume><issue>5</issue><fpage>738</fpage><lpage>743</lpage><pub-id pub-id-type="doi">10.1038/nn.3689</pub-id></element-citation></ref><ref id="R20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fornaciai</surname><given-names>M</given-names></name><name><surname>Park</surname><given-names>J</given-names></name></person-group><article-title>Attractive Serial Dependence in the Absence of an Explicit Task</article-title><source>Psychological Science</source><year>2018</year><volume>29</volume><issue>3</issue><fpage>437</fpage><lpage>446</lpage><pub-id pub-id-type="doi">10.1177/0956797617737385</pub-id></element-citation></ref><ref id="R21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fornaciai</surname><given-names>M</given-names></name><name><surname>Park</surname><given-names>J</given-names></name></person-group><article-title>Neural dynamics of serial dependence in numerosity perception</article-title><source>Journal of Cognitive Neuroscience</source><year>2019</year><volume>32</volume><issue>1</issue><fpage>141</fpage><lpage>154</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01474</pub-id></element-citation></ref><ref id="R22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freyd</surname><given-names>JJ</given-names></name><name><surname>Finke</surname><given-names>RA</given-names></name></person-group><article-title>Representational Motion</article-title><source>Journal of Experimental Psychology</source><year>1984</year><volume>10</volume><issue>1</issue><fpage>126</fpage><lpage>132</lpage></element-citation></ref><ref id="R23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fritsche</surname><given-names>M</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><article-title>Reference repulsion is not a perceptual illusion</article-title><source>Cognition</source><year>2019</year><volume>184</volume><issue>January</issue><fpage>107</fpage><lpage>118</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2018.12.010</pub-id></element-citation></ref><ref id="R24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fritsche</surname><given-names>M</given-names></name><name><surname>Mostert</surname><given-names>P</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><article-title>Opposite Effects of Recent History on Perception and Decision</article-title><source>Current Biology</source><year>2017</year><volume>27</volume><issue>4</issue><fpage>590</fpage><lpage>595</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.01.006</pub-id></element-citation></ref><ref id="R25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fritsche</surname><given-names>M</given-names></name><name><surname>Spaak</surname><given-names>E</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><article-title>A bayesian and efficient observer model explains concurrent attractive and repulsive history biases in visual perception</article-title><source>eLife</source><year>2020</year><volume>9</volume><fpage>1</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.7554/eLife.55389</pub-id></element-citation></ref><ref id="R26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gekas</surname><given-names>N</given-names></name><name><surname>McDermott</surname><given-names>KC</given-names></name><name><surname>Mamassian</surname><given-names>P</given-names></name></person-group><article-title>Disambiguating serial effects of multiple timescales</article-title><source>Journal of Vision</source><year>2019</year><volume>19</volume><issue>6</issue><fpage>1</fpage><lpage>14</lpage><pub-id pub-id-type="doi">10.1167/19.6.24</pub-id></element-citation></ref><ref id="R27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Luessi</surname><given-names>M</given-names></name><name><surname>Larson</surname><given-names>E</given-names></name><name><surname>Engemann</surname><given-names>DA</given-names></name><name><surname>Strohmeier</surname><given-names>D</given-names></name><name><surname>Brodbeck</surname><given-names>C</given-names></name><name><surname>Goj</surname><given-names>R</given-names></name><name><surname>Jas</surname><given-names>M</given-names></name><name><surname>Brooks</surname><given-names>T</given-names></name><name><surname>Parkkonen</surname><given-names>L</given-names></name><name><surname>Hämäläinen</surname><given-names>M</given-names></name></person-group><article-title>MEG and EEG data analysis with MNE-Python</article-title><source>Frontiers in Neuroscience</source><year>2013</year><volume>7</volume><issue>267</issue><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.3389/fnins.2013.00267</pub-id></element-citation></ref><ref id="R28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hajonides</surname><given-names>JE</given-names></name><name><surname>Nobre</surname><given-names>AC</given-names></name><name><surname>van Ede</surname><given-names>F</given-names></name><name><surname>Stokes</surname><given-names>MG</given-names></name></person-group><article-title>Decoding visual colour from scalp electroencephalography measurements</article-title><source>NeuroImage</source><year>2021</year><month>April</month><volume>237</volume><elocation-id>118030</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2021.118030</pub-id></element-citation></ref><ref id="R29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>J</given-names></name><name><surname>Sekuler</surname><given-names>R</given-names></name></person-group><article-title>Distortions in recall from visual memory: Two classes of attractors at work</article-title><source>Journal of Vision</source><year>2010</year><volume>10</volume><issue>2</issue><fpage>1</fpage><lpage>27</lpage><pub-id pub-id-type="doi">10.1167/10.2.24</pub-id></element-citation></ref><ref id="R30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>L</given-names></name></person-group><article-title>Distinguishing target biases and strategic guesses in visual working memory</article-title><source>Attention, Perception, and Psychophysics</source><year>2020</year><volume>82</volume><issue>3</issue><fpage>1258</fpage><lpage>1270</lpage><pub-id pub-id-type="doi">10.3758/s13414-019-01913-2</pub-id></element-citation></ref><ref id="R31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jazayeri</surname><given-names>M</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><article-title>Optimal representation of sensory information by neural populations</article-title><source>Nature Neuroscience</source><year>2006</year><volume>9</volume><issue>5</issue><fpage>690</fpage><lpage>696</lpage><pub-id pub-id-type="doi">10.1038/nn1691</pub-id></element-citation></ref><ref id="R32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jazayeri</surname><given-names>M</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><article-title>A new perceptual illusion reveals mechanisms of sensory decoding</article-title><source>Nature</source><year>2007</year><volume>446</volume><issue>7138</issue><fpage>912</fpage><lpage>915</lpage><pub-id pub-id-type="doi">10.1038/nature05739</pub-id></element-citation></ref><ref id="R33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>S</given-names></name><name><surname>Burr</surname><given-names>D</given-names></name><name><surname>Cicchini</surname><given-names>GM</given-names></name><name><surname>Alais</surname><given-names>D</given-names></name></person-group><article-title>Serial dependence in perception requires conscious awareness</article-title><source>Current Biology</source><year>2020</year><volume>30</volume><issue>6</issue><fpage>R257</fpage><lpage>R258</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2020.02.008</pub-id></element-citation></ref><ref id="R34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiyonaga</surname><given-names>A</given-names></name><name><surname>Scimeca</surname><given-names>JM</given-names></name><name><surname>Bliss</surname><given-names>DP</given-names></name><name><surname>Whitney</surname><given-names>D</given-names></name></person-group><source>Serial Dependence across Perception, Attention, and Memory</source><year>2017</year><pub-id pub-id-type="doi">10.1016/j.tics.2017.04.011</pub-id></element-citation></ref><ref id="R35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kohn</surname><given-names>A</given-names></name></person-group><article-title>Visual adaptation: Physiology, mechanisms, and functional benefits</article-title><source>Journal of Neurophysiology</source><year>2007</year><volume>97</volume><issue>5</issue><fpage>3155</fpage><lpage>3164</lpage><pub-id pub-id-type="doi">10.1152/jn.00086.2007</pub-id></element-citation></ref><ref id="R36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name><name><surname>Goebel</surname><given-names>R</given-names></name><name><surname>Bandettini</surname><given-names>P</given-names></name></person-group><article-title>Information-based functional brain mapping</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><year>2006</year><volume>103</volume><issue>10</issue><fpage>3863</fpage><lpage>3868</lpage><pub-id pub-id-type="doi">10.1073/pnas.0600244103</pub-id></element-citation></ref><ref id="R37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Libby</surname><given-names>A</given-names></name><name><surname>Buschman</surname><given-names>TJ</given-names></name></person-group><article-title>Rotational dynamics reduce interference between sensory and memoryrepresentations</article-title><source>Nature Neuroscience</source><year>2021</year><volume>24</volume><issue>5</issue><fpage>715</fpage><lpage>726</lpage><pub-id pub-id-type="doi">10.1038/s41593-021-00821-9</pub-id></element-citation></ref><ref id="R38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moore</surname><given-names>T</given-names></name><name><surname>Armstrong</surname><given-names>KM</given-names></name></person-group><article-title>Selective gating of visual signals by microstimulation of frontal cortex</article-title><source>Nature</source><year>2003</year><volume>421</volume><issue>6921</issue><fpage>370</fpage><lpage>373</lpage></element-citation></ref><ref id="R39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oostenveld</surname><given-names>R</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name><name><surname>Maris</surname><given-names>E</given-names></name><name><surname>Schoffelen</surname><given-names>JM</given-names></name></person-group><article-title>FieldTrip: Open source software for advanced analysis of MEG, EEG, and invasive electrophysiological data</article-title><source>Computational Intelligence and Neuroscience</source><year>2011</year><volume>2011</volume><pub-id pub-id-type="doi">10.1155/2011/156869</pub-id></element-citation></ref><ref id="R40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Papadimitriou</surname><given-names>C</given-names></name><name><surname>White</surname><given-names>RL</given-names></name><name><surname>Snyder</surname><given-names>LH</given-names></name></person-group><article-title>Ghosts in the Machine II: Neural correlates of memory interferencefrom the previous trial</article-title><source>Cerebral Cortex</source><year>2017</year><volume>27</volume><issue>4</issue><fpage>2513</fpage><lpage>2527</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhw106</pub-id></element-citation></ref><ref id="R41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pascucci</surname><given-names>D</given-names></name><name><surname>Mancuso</surname><given-names>G</given-names></name><name><surname>Santandrea</surname><given-names>E</given-names></name><name><surname>Libera</surname><given-names>CD</given-names></name><name><surname>Plomp</surname><given-names>G</given-names></name><name><surname>Chelazzi</surname><given-names>L</given-names></name></person-group><source>Laws of concatenated perception: Vision goes for novelty, decisions for perseverance</source><year>2019</year><volume>17</volume><pub-id pub-id-type="doi">10.1371/journal.pbio.3000144</pub-id></element-citation></ref><ref id="R42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosner</surname><given-names>B</given-names></name></person-group><article-title>Percentage Outlier Points for Generalized ESD Many-Procedure</article-title><source>Technometrics</source><year>1983</year><volume>25</volume><issue>2</issue><fpage>165</fpage><lpage>172</lpage></element-citation></ref><ref id="R43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sadil</surname><given-names>P</given-names></name><name><surname>Cowell</surname><given-names>RA</given-names></name><name><surname>Huber</surname><given-names>DE</given-names></name></person-group><article-title>The yin-yang of serial dependence effects: every response is both an attraction to the prior response and a repulsion from the prior stimulus</article-title><source>PsyArXiv</source><year>2021</year></element-citation></ref><ref id="R44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneegans</surname><given-names>S</given-names></name><name><surname>Bays</surname><given-names>PM</given-names></name></person-group><article-title>Neural Architecture for Feature Binding in Visual Working Memory</article-title><source>The Journal of Neuroscience</source><year>2017</year><volume>37</volume><issue>14</issue><fpage>3913</fpage><lpage>3925</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3493-16.2017</pub-id></element-citation></ref><ref id="R45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheehan</surname><given-names>TC</given-names></name><name><surname>Serences</surname><given-names>JT</given-names></name></person-group><article-title>Sensory readout accounts for adaptation</article-title><source>bioRxiv</source><year>2021</year><elocation-id>2021.04.06.438664</elocation-id><pub-id pub-id-type="doi">10.1101/2021.04.06.438664</pub-id></element-citation></ref><ref id="R46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simoncelli</surname><given-names>EP</given-names></name><name><surname>Olshausen</surname><given-names>BA</given-names></name></person-group><article-title>Natural image statistics and neural representation</article-title><source>Annual Review of Neuroscience</source><year>2001</year><volume>24</volume><fpage>1193</fpage><lpage>1216</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.24.1.1193</pub-id></element-citation></ref><ref id="R47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>John-Saaltink</surname><given-names>E</given-names><suffix>St</suffix></name><name><surname>Kok</surname><given-names>P</given-names></name><name><surname>Lau</surname><given-names>HC</given-names></name><name><surname>De Lange</surname><given-names>FP</given-names></name></person-group><article-title>Serial dependence in perceptual decisions is reflected in activitypatterns in primary visual cortex</article-title><source>Journal of Neuroscience</source><year>2016</year><volume>36</volume><issue>23</issue><fpage>6186</fpage><lpage>6192</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4390-15.2016</pub-id></element-citation></ref><ref id="R48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>John-Saaltink</surname><given-names>E</given-names><suffix>St</suffix></name><name><surname>Kok</surname><given-names>P</given-names></name><name><surname>Lau</surname><given-names>HC</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><article-title>Serial Dependence in Perceptual Decisions Is Reflected in ActivityPatterns in Primary Visual Cortex</article-title><source>The Journal of neuroscience : the official journal of the Society for Neuroscience</source><year>2016</year><volume>36</volume><issue>23</issue><fpage>6186</fpage><lpage>92</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4390-15.2016</pub-id></element-citation></ref><ref id="R49"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Stocker</surname><given-names>AA</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group><source>A Bayesian model of conditioned perception</source><conf-name>Advances in Neural Information Processing Systems 20 - Proceedings of the 2007 Conference</conf-name><year>2008</year><volume>20</volume><fpage>1409</fpage><lpage>1416</lpage></element-citation></ref><ref id="R50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Störmer</surname><given-names>VS</given-names></name><name><surname>Alvarez</surname><given-names>GA</given-names></name></person-group><article-title>Feature-based attention elicits surround suppression in feature space</article-title><source>Current Biology</source><year>2014</year><volume>24</volume><issue>17</issue><fpage>1985</fpage><lpage>1988</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2014.07.030</pub-id></element-citation></ref><ref id="R51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taulu</surname><given-names>S</given-names></name><name><surname>Kajola</surname><given-names>M</given-names></name><name><surname>Simola</surname><given-names>J</given-names></name></person-group><article-title>Suppression of interference and artifacts by the signal space separation method</article-title><source>Brain Topography</source><year>2004</year><volume>16</volume><issue>4</issue><fpage>269</fpage><lpage>275</lpage><pub-id pub-id-type="doi">10.1023/B:BRAT.0000032864.93890.f9</pub-id></element-citation></ref><ref id="R52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taylor</surname><given-names>PC</given-names></name><name><surname>Nobre</surname><given-names>AC</given-names></name><name><surname>Rushworth</surname><given-names>MF</given-names></name></person-group><article-title>FEF TMS affects visual cortical activity</article-title><source>Cerebral Cortex</source><year>2007</year><volume>17</volume><issue>2</issue><fpage>391</fpage><lpage>399</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhj156</pub-id></element-citation></ref><ref id="R53"><element-citation publication-type="other"><collab>Team J</collab><source>JASP (Version 0.14.1)[Computer software]</source><year>2020</year></element-citation></ref><ref id="R54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Bergen</surname><given-names>RS</given-names></name><name><surname>Jehee</surname><given-names>JF</given-names></name></person-group><article-title>Probabilistic Representation in Human Visual Cortex Reflects Uncertainty in Serial Decisions</article-title><source>Journal of Neuroscience</source><year>2019</year><volume>39</volume><issue>41</issue><fpage>8164</fpage><lpage>8176</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3212-18.2019</pub-id></element-citation></ref><ref id="R55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Virtanen</surname><given-names>P</given-names></name><name><surname>Gommers</surname><given-names>R</given-names></name><name><surname>Oliphant</surname><given-names>TE</given-names></name><name><surname>Haberland</surname><given-names>M</given-names></name><name><surname>Reddy</surname><given-names>T</given-names></name><name><surname>Cournapeau</surname><given-names>D</given-names></name><name><surname>Burovski</surname><given-names>E</given-names></name><name><surname>Peterson</surname><given-names>P</given-names></name><name><surname>Weckesser</surname><given-names>W</given-names></name><name><surname>Bright</surname><given-names>J</given-names></name><name><surname>van der Walt</surname><given-names>SJ</given-names></name><etal/></person-group><article-title>SciPy 1.0: fundamental algorithms for scientific computing in Python</article-title><source>Nature Methods</source><year>2020</year><volume>17</volume><issue>3</issue><fpage>261</fpage><lpage>272</lpage><pub-id pub-id-type="doi">10.1038/s41592-019-0686-2</pub-id></element-citation></ref><ref id="R56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wainwright</surname><given-names>MJ</given-names></name></person-group><article-title>Visual adaptation as optimal information transmission</article-title><source>Vision Research</source><year>1999</year><volume>39</volume><issue>23</issue><fpage>3960</fpage><lpage>3974</lpage><pub-id pub-id-type="doi">10.1016/S0042-6989(99)00101-7</pub-id></element-citation></ref><ref id="R57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wan</surname><given-names>Q</given-names></name><name><surname>Cai</surname><given-names>Y</given-names></name><name><surname>Samaha</surname><given-names>J</given-names></name><name><surname>Postle</surname><given-names>BR</given-names></name></person-group><article-title>Tracking stimulus representation across a 2-back visual working memory task: Tracking 2-back representation</article-title><source>Royal Society Open Science</source><year>2020</year><volume>7</volume><issue>8</issue><pub-id pub-id-type="doi">10.1098/rsos.190228rsos190228</pub-id></element-citation></ref><ref id="R58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Webster</surname><given-names>MA</given-names></name></person-group><article-title>Visual Adaptation</article-title><source>Annual Review of Vision Science</source><year>2015</year><volume>1</volume><fpage>547</fpage><lpage>567</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-082114-035509</pub-id></element-citation></ref><ref id="R59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname><given-names>Z</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name><name><surname>Wang</surname><given-names>DH</given-names></name></person-group><article-title>From distributed resources to limited slots in multiple-item working memory: A spiking network model with normalization</article-title><source>Journal of Neuroscience</source><year>2012</year><volume>32</volume><issue>33</issue><fpage>11228</fpage><lpage>11240</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0735-12.2012</pub-id></element-citation></ref><ref id="R60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolff</surname><given-names>MJ</given-names></name><name><surname>Jochim</surname><given-names>J</given-names></name><name><surname>Akyürek</surname><given-names>EG</given-names></name><name><surname>Buschman</surname><given-names>TJ</given-names></name><name><surname>Stokes</surname><given-names>MG</given-names></name></person-group><article-title>Drifting codes within a stable coding scheme for working memory</article-title><source>PLoS biology</source><year>2020</year><volume>18</volume><issue>3</issue><elocation-id>e3000625</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.3000625</pub-id></element-citation></ref><ref id="R61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolff</surname><given-names>MJ</given-names></name><name><surname>Jochim</surname><given-names>J</given-names></name><name><surname>Akyürek</surname><given-names>EG</given-names></name><name><surname>Stokes</surname><given-names>MG</given-names></name></person-group><article-title>Dynamic hidden states underlying working-memory-guided behavior</article-title><source>Nature Neuroscience</source><year>2017</year><volume>20</volume><issue>6</issue><fpage>864</fpage><lpage>871</lpage><pub-id pub-id-type="doi">10.1038/nn.4546</pub-id></element-citation></ref><ref id="R62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zamboni</surname><given-names>E</given-names></name><name><surname>Ledgeway</surname><given-names>T</given-names></name><name><surname>McGraw</surname><given-names>PV</given-names></name><name><surname>Schluppeck</surname><given-names>D</given-names></name></person-group><article-title>Do perceptual biases emerge early or late in visual processing? Decision-biases in motion perception</article-title><source>Proceedings of the Royal Society B: Biological Sciences</source><year>2016</year><volume>283</volume><issue>1833</issue><pub-id pub-id-type="doi">10.1098/rspb.2016.0263</pub-id></element-citation></ref><ref id="R63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>W</given-names></name><name><surname>Luck</surname><given-names>SJ</given-names></name></person-group><article-title>Discrete fixed-resolution representations in visual working memory</article-title><source>Nature</source><year>2008</year><volume>453</volume><issue>7192</issue><fpage>233</fpage><lpage>5</lpage><pub-id pub-id-type="doi">10.1038/nature06860</pub-id></element-citation></ref><ref id="R64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zirnsak</surname><given-names>M</given-names></name><name><surname>Steinmetz</surname><given-names>NA</given-names></name><name><surname>Noudoost</surname><given-names>B</given-names></name><name><surname>Xu</surname><given-names>KZ</given-names></name><name><surname>Moore</surname><given-names>T</given-names></name></person-group><article-title>Visual space is compressed in prefrontal cortex before eye movements</article-title><source>Nature</source><year>2014</year><volume>507</volume><issue>7493</issue><fpage>504</fpage><lpage>507</lpage><pub-id pub-id-type="doi">10.1038/nature13149</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><p>Experimental task design. Participants were presented with two arrays that contained an oriented bar grating or a place holder fixation dot. An oriented grating was presented either in the first (25% of trials), second (25%), or both (50%) arrays. A colour cue presented on array 2 indicated the relevant stimulus for recall. The cue size in array-2 is enlarged for visualisation purposes. The colour cued either the first array or the second array. On trials with only one orientation presented, the cue was redundant but still presented. Mappings between colour and cue meaning were counterbalanced. After matching the orientation in the probe display to the orientation in memory, participants were presented with feedback in the form of a grating with the correct orientation. Timings in parentheses are in milliseconds.</p></caption><graphic xlink:href="EMS145923-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Within-trial repulsive performance biases.</title><p>A) Within-trial bias as a function of the absolute angular distance between the two presented orientations. Trials were split for report 1st and report 2nd cues on 2-item trials. Shading indicates standard error of the mean. The horizontal line indicates a cluster of significant performance biases for a range of angular difference. The right panel shows the sum of bias across angular distances per subject. Error bars show 95% confidence intervals. R1 = report 1st; R2 = report 2nd. B) Schematic of the within-trial performance bias. A repulsive performance bias is observed for report 2nd trials only.</p></caption><graphic xlink:href="EMS145923-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Attractive behavioural biases towards the relevant target orientation in the previous trial.</title><p>A) Line plots for the attractive between-trial bias as a function of the absolute angular distance between the target orientation on the previous trial and the presented grating. Shading indicates the standard error of the mean. Horizontal lines indicate clusters of significant performance biases for a range of angular differences. B) Bar plots indicate the average sum of biases across angular distances per subject and per condition as seen in panel 3A. C) Line plots show the attractive between-trial bias as a function of the absolute angular distance between the probed angle on the previous trial (green) or the presented but not probed angle in the previous trial (orange). The horizontal lines indicate cluster-corrected angular distances for which the bias is significant. R1 = report 1st orientation on the previous trial; R2 = report 2nd orientation on the previous trial. D) Sum of the response data shown in panel 3C. Positive values indicate an attractive bias. All error bars indicate 95% confidence intervals.</p></caption><graphic xlink:href="EMS145923-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Orientation decoding of presented grating.</title><p>Training an independent classifier to decode the first or second grating orientation in either the first- or second-time interval - left and right side respectively. The MEG topographies show which sensors most strongly contribute to the overall evidence. The left topography shows decoding of the first orientation in the first interval between 250 - 600 ms. The right topography shows decoding of the second orientation at the same latency. Error bars indicate the standard error of the mean. Horizontal lines indicate periods of significant grating orientation decoding after cluster-based permutation tests against zero, <italic>p</italic> = .05.</p></caption><graphic xlink:href="EMS145923-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>Shift in representational similarity curve relative to previous grating orientation.</title><p>A) Asymmetry scores following the presentation of the second grating on report 1st 2-item trials. The first grating orientation had a positive (purple) or negative (green) angular distance relative to the current grating orientation. The shaded area indicates the time interval (250 - 600 ms) used for statistical analysis and to generate the representational similarity curves in the right panel. Smoothing (thicker lines in darker colours) was applied for visualisation purposes. B) shows the representational similarity curves with evidence for the presented grating orientation for trials with positive or negative angular distances relative to the first rating. For visualisation purposes, data points were interpolated (from 10 to 50 data points) and fitted using a Savitzky-Golay filter (with a window length of 9 data points and polynomial of order 1). C) Asymmetry scores for report 2nd 2-item trials, where participants encoded the grating orientation on screen into working memory with a neural bias away from the grating orientation that was presented earlier on the same trial. Shading indicates standard error of the mean. D) shows data from the grey-shaded region in panel 5C. Horizontal lines indicate periods of significant bias on unsmoothed data after cluster-based permutation tests against <italic>p</italic> = .05.</p></caption><graphic xlink:href="EMS145923-f005"/></fig><fig id="F6" position="float"><label>Figure 6</label><caption><title>Bias on encoding imposed by previous trial.</title><p>A) Asymmetry index for trials with a CW or CCW angular distance (0° – 60°) between the cued item on the previous trial and the presented grating (collapsed across the first and second grating). Asymmetry index time course is shown relative to the onset of grating presentation. A one-dimensional Gaussian filter with a kernel of 15 ms was applied to the data for visualisation purposes. The grey shaded area indicates which time points (250-600 ms) are used for analyses described in the text and in panels 6B-D and F-H. B) Average LDA orientation-likelihoods for trials with CW (green) and CCW (purple) angular distances with respect to the previous trial. Evidence is lower for CW orientation bins when in the previous trial a CW orientation was cued, and vice versa for CCW orientations. The same interpolation was applied as described in <xref ref-type="fig" rid="F5">Figure 5</xref>. C) Average bias relative to the previously cued orientation across all stimuli and for the first and second orientation separately. D) MEG topography based on searchlight results, illustrating in which sensors the evidence shift from panels 6A-C is most prominent. E) Cross-decoding evidence for the previously cued orientation (classifier trained on current orientation), locked to grating presentation. Same conventions as in panel 6A. F) Correlations between asymmetry index panel 6A and cross-decoding evidence from panel 6E for grating orientation processing of all stimuli combined (black), first grating (light grey) and second grating (dark grey). A least-squares linear regression model was applied for each of the conditions, with shaded 95% confidence intervals estimated using bootstrapping. G) Cross-decoding evidence from panel 6D summarised for all stimuli and separately for the first and second grating. H) MEG topography based on searchlight results, showing cross-decoding evidence for each sensor. *: <italic>p</italic> &lt; .05, **: <italic>p</italic> &lt; .01. Plotted with 95% confidence intervals.</p></caption><graphic xlink:href="EMS145923-f006"/></fig><table-wrap id="T1" orientation="portrait" position="float"><label>Table 1</label><caption><title>Descriptive statistics of error for all experimental conditions.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="top"/><th align="center" valign="top">Report 1st trials</th><th align="center" valign="top">Report 2nd trials</th></tr></thead><tbody><tr><td align="center" valign="top">1 item</td><td align="center" valign="top">11.91° (±4.61°)</td><td align="center" valign="top">8.96° (±2.52°)</td></tr><tr><td align="center" valign="top">2 items</td><td align="center" valign="top">14.69°(±5.38°)</td><td align="center" valign="top">9.79°(±2.89°)</td></tr></tbody></table><table-wrap-foot><fn id="TFN1"><p id="P51"><italic>Note</italic>. Mean Absolute Error (± Std. Dev.). All units are in degrees.</p></fn></table-wrap-foot></table-wrap></floats-group></article>