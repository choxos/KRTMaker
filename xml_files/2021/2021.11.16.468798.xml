<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS151736</article-id><article-id pub-id-type="doi">10.1101/2021.11.16.468798</article-id><article-id pub-id-type="archive">PPR422772</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Reversible inactivation of ferret auditory cortex impairs spatial and non-spatial hearing</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Town</surname><given-names>Stephen M.</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><contrib contrib-type="author"><name><surname>Poole</surname><given-names>Katarina C.</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Wood</surname><given-names>Katherine C.</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Bizley</surname><given-names>Jennifer K.</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib></contrib-group><aff id="A1"><label>1</label>Ear Institute, University College London, London, UK</aff><aff id="A2"><label>2</label>Department of Otorhinolaryngology: HNS, Department of Neuroscience, University of Pennsylvania, Philadelphia, PA</aff><author-notes><corresp id="CR1"><bold>Corresponding Authors:</bold> Stephen Town (<email>s.town@ucl.ac.uk</email>), UCL Ear Institute, 332 Gray’s Inn Road, London, UK; Jennifer Bizley (<email>j.bizley@ucl.ac.uk</email>), UCL Ear Institute, 332 Gray’s Inn Road, London, UK</corresp></author-notes><pub-date pub-type="nihms-submitted"><day>27</day><month>07</month><year>2022</year></pub-date><pub-date pub-type="preprint"><day>26</day><month>07</month><year>2022</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">A key question in auditory neuroscience is to what extent are brain regions functionally specialized for processing specific sound features such as sound location and identity. In auditory cortex, correlations between neural activity and sounds support both the specialization of distinct cortical subfields, and encoding of multiple sound features within individual cortical areas. However, few studies have tested the contribution of auditory cortex to hearing in multiple contexts. Here we determined the role of ferret primary auditory cortex in both spatial and non-spatial hearing by reversibly inactivating the middle ectosylvian gyrus during behavior using cooling (n=2) or optogenetics (n=1). In optogenetic experiments, we utilized the mDLx promoter to express Channelrhodopsin 2 in GABAergic interneurons and confirmed both viral expression (n=2) and light-driven suppression of spiking activity in auditory cortex, recorded using Neuropixels under anesthesia (n=465 units from 2 additional untrained ferrets). Cortical inactivation impaired vowel discrimination in co-located noise, but not in clean conditions, or when the temporally coincident vowel and noise were spatially separated by 180°. Testing the ferrets implanted with cooling loops in a sound localization task confirmed that deficits in spatial hearing arose from inactivation of the same region of auditory cortex that was implicated in vowel discrimination in noise. Our results are consistent with single unit recordings in primary auditory cortex showing mixed selectivity for spatial and non-spatial features of sound and suggest a contribution of this region to multiple forms of hearing necessary for auditory scene analysis.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">A central question in neuroscience is to what extent the brain is functionally organized into specialized units versus distributed networks of interacting regions (<xref ref-type="bibr" rid="R29">Földiák, 2009</xref>; <xref ref-type="bibr" rid="R13">Bowers, 2017</xref>). In sensory systems, separate cortical fields are thought to process distinct stimulus features such as visual motion, color and identity (<xref ref-type="bibr" rid="R53">Nassi and Callaway, 2009</xref>) or sound location and identity (<xref ref-type="bibr" rid="R59">Rauschecker and Scott, 2009</xref>).</p><p id="P3">Primary auditory cortex plays a critical role in many aspects of hearing. Neurons in this area show tuning to multiple features of sounds such as location and level (<xref ref-type="bibr" rid="R14">Brugge et al., 1996</xref>; <xref ref-type="bibr" rid="R73">Zhang et al., 2004</xref>), location and identity (<xref ref-type="bibr" rid="R3">Amaro et al., 2021</xref>) or vowel timbre, pitch and voicing (<xref ref-type="bibr" rid="R11">Bizley et al., 2009</xref>; <xref ref-type="bibr" rid="R67">Town et al., 2018</xref>). This sensitivity to multiple features can give rise to complex spectrotemporal tuning (<xref ref-type="bibr" rid="R4">Atencio et al., 2008</xref>; <xref ref-type="bibr" rid="R34">Harper et al., 2016</xref>) that can also be modulated by ongoing behavior (<xref ref-type="bibr" rid="R30">Fritz et al., 2003</xref>; <xref ref-type="bibr" rid="R20">David et al., 2012</xref>).</p><p id="P4">The mixed selectivity observed in responses of auditory cortical neurons is matched by a diverse range of behavioral deficits following auditory cortical lesions or inactivation (<xref ref-type="bibr" rid="R63">Slonina et al., 2022</xref>). Affected behaviors include discrimination of natural sounds such as vocalizations (<xref ref-type="bibr" rid="R36">Heffner and Heffner, 1986</xref>; <xref ref-type="bibr" rid="R35">Harrington et al., 2001</xref>), as well as sound modulation (<xref ref-type="bibr" rid="R56">Ohl et al., 1999</xref>; <xref ref-type="bibr" rid="R16">Ceballo et al., 2019</xref>) and sound localization (<xref ref-type="bibr" rid="R36">Heffner and Heffner, 1986</xref>; <xref ref-type="bibr" rid="R46">Malhotra et al., 2008</xref>). Most cortical inactivation studies focus on performance in a single task, or on a small range of related behaviors and thus our inferences on common functions must draw on data from different subjects, species and techniques.</p><p id="P5">Ideally, we would complement such inferences with direct comparisons of the effects of inactivation on distinct tasks performed by the same subjects and using the same methods of perturbation. Tests of distinct behaviors during auditory cortical inactivation are rare, but have yielded valuable insight into the functional specialization of non-primary auditory cortex (<xref ref-type="bibr" rid="R1">Adriani et al., 2003</xref>; <xref ref-type="bibr" rid="R44">Lomber and Malhotra, 2008</xref>; <xref ref-type="bibr" rid="R2">Ahveninen et al., 2013</xref>).</p><p id="P6">Here, we define distinct behaviors as those requiring subjects to act on the basis of orthogonal stimulus features, where orthogonality indicates that one feature can be varied while another remains constant (e.g. <xref ref-type="bibr" rid="R28">Flesch et al., 2018</xref>). The sparsity of inactivation data across distinct behaviors reflects the technical limitations on suppressing neural activity in humans and the difficulty in training individual animals to perform multiple tasks with contrasting demands.</p><p id="P7">We leveraged ferrets’ capacity to learn multiple psychoacoustic tasks to test the role of auditory cortex in distinct behaviors involving vowel discrimination in multiple contexts (clean conditions, or with co-located or spatially separated noise) and approach-to-target sound localization. During testing, we reversibly inactivated a large portion of primary auditory cortex by cooling the mid-to-low frequency area of the middle ectosylvian gyrus (MEG). Inactivation produced a pattern of deficits that confirms a common role for this brain region in both spatial and non-spatial hearing. Further experiments with optogenetics confirmed the role for MEG in vowel discrimination in noise and demonstrated the efficacy of light-driven suppression of sound evoked responses in ferret auditory cortex.</p></sec><sec id="S2" sec-type="methods"><title>Methods</title><sec id="S3"><title>Animals</title><p id="P8">Subjects were ten pigmented ferrets (<italic>Mustela putorius</italic>, female, between 0.5 and 5 years old). Animals were maintained in groups of two or more ferrets in enriched housing conditions, with regular otoscopic examinations to ensure the cleanliness and health of ears.</p><p id="P9">Seven animals were trained in behavioral tasks in which access to water was regulated (<xref ref-type="table" rid="T1">Table 1</xref>). During water regulation, each ferret was water-restricted prior to testing and received a minimum of 60ml/kg of water per day, either during task performance or supplemented as a wet mash made from water and ground high-protein pellets. Subjects were tested in morning and afternoon sessions on each day for up to five days in a week, while their weight and water consumption was measured throughout the experiment.</p><p id="P10">All experimental procedures were approved by local ethical review committees (Animal Welfare and Ethical Review Board) at University College London and The Royal Veterinary College, University of London and performed under license from the UK Home Office (Project License 70/7267) and in accordance with the Animals (Scientific Procedures) Act 1986.</p></sec><sec id="S4"><title>Stimuli</title><sec id="S5"><title>Vowel discrimination</title><p id="P11">Vowels were synthesized in MATLAB (MathWorks, USA) using an algorithm adapted from Malcolm Slaney’s Auditory Toolbox (<ext-link ext-link-type="uri" xlink:href="https://engineering.purdue.edu/~malcolm/interval/1998-010/">https://engineering.purdue.edu/~malcolm/interval/1998-010/</ext-link>) that simulates vowels by passing a click train through a biquad filter with appropriate numerators such that formants are introduced in parallel. In the current study, four formants (F1-4) were modeled: /u/ (F1-4: 460, 1105, 2857, 4205 Hz), /ε/ (730, 2058, 2857, 4205 Hz), /a/ (936, 1551, 2975, 4263 Hz) and /i/ (437, 2761, 2975, 4263 Hz). Ferrets were only trained to discriminate between a pair of vowels: either /ε/ and /u/ (F1201, F1203, F1217, F1509 and F1706), or /a/ and /i/ (F1216 and F1311). All vowels were generated with a 200 Hz fundamental frequency.</p><p id="P12">Vowels were presented in clean conditions as two repeated tokens, each of 250 ms duration and of the same identity, separated with a silent interval of 250 ms (<xref ref-type="fig" rid="F1">Fig. 1A</xref>). Here, two vowel tokens were used for consistency with previous work (<xref ref-type="bibr" rid="R9">Bizley et al., 2013a</xref>; <xref ref-type="bibr" rid="R65">Town et al., 2015</xref>). Sounds were presented through loudspeakers (Visaton FRS 8) positioned on the left and right sides of the head at equal distance and approximate head height. These speakers produced a smooth response (±2 dB) from 200 to 20000 Hz, with a 20 dB drop-off from 200 to 20 Hz when measured in an anechoic environment using a microphone positioned at a height and distance equivalent to that of the ferrets in the testing chamber. All vowel sounds were passed through an inverse filter generated from calibration of speakers to Golay codes (<xref ref-type="bibr" rid="R74">Zhou et al., 1992</xref>). Clean conditions were defined as the background sound level measured within the sound-attenuating chamber in which the task was performed in the absence of stimulus presentation (22 dB SPL).</p><p id="P13">Vowels were also presented with additive broadband noise fixed at 70 dB SPL and restricted in time to the period of stimulus presentation (0 to 750 ms after onset of the first vowel token). Noise was generated afresh on each trial. Onsets of both vowels and noise were ramped using a 5 ms cosine function. During initial experiments on vowel discrimination in noise, vowels and noise were played from both left and right speakers (<xref ref-type="fig" rid="F1">Fig. 1A</xref>); however when investigating spatial release from energetic masking, vowels were presented from either left or right speaker but not both. Noise was also presented from one speaker and thus the noise levels in such experiments were 67 dB SPL; noise was presented either from the same speaker as vowels, the opposite speaker or not at all (<xref ref-type="fig" rid="F1">Fig. 1B</xref>).</p></sec><sec id="S6"><title>Sound localization</title><p id="P14">Auditory stimuli were broadband noise bursts of differing durations (F1509: 700 ms; F1311: 250 ms or 100 ms) cosine ramped with 5-ms duration at the onset and offset and low-pass filtered below 22 kHz (finite impulse response filter &lt;22 kHz, 70 dB attenuation at 22.2 kHz). Noise bursts were generated afresh on each trial in MATLAB at a sampling frequency of 48828.125 Hz and presented from one of seven speakers (Visaton FRS SC 5.9) positioned at 30° intervals (<xref ref-type="fig" rid="F1">Fig. 1C</xref>). Note that one ferret (F1509) was not tested with sounds from the central speaker (0°). Across trials, stimuli were presented at one of three pseudo-randomly selected intensities (57, 61.5 and 66 dB SPL).</p><p id="P15">Speakers were calibrated to produce a flat response from 200 Hz to 25 kHz using Golay codes, presented in an anechoic environment, to construct inverse filters (<xref ref-type="bibr" rid="R74">Zhou et al., 1992</xref>). All the speakers were matched for level using a microphone positioned upright at the level of the ferret’s head in the center of the semi-circle. Calibrations were performed with a condenser microphone (Model 4191, Brüel and Kjær) and/or a Brüel and Kjær 3110–003 measuring amplifier.</p></sec></sec><sec id="S7"><title>Task design</title><p id="P16">Behavioral tasks, data acquisition, and stimulus generation were all automated using custom software running on personal computers, which communicated with TDT real-time signal processors (Vowel discrimination: RZ6, Sound localization: RX8).</p><sec id="S8"><title>Vowel discrimination</title><p id="P17">Ferrets were trained to discriminate the synthetic vowel sounds within a custom-built double-walled sound attenuating chamber (IAC Acoustics Ltd.) lined with acoustic foam. The chamber contained a wire-frame pet-cage with three response ports housing infra-red sensors that detected the ferret’s presence. On each trial, the ferret was required to approach the center port and hold head position for a variable period (between 0 and 500 ms) before stimulus presentation. Animals were required to maintain contact with the center port until 250 ms after the presentation of the first token, at which point they could respond at left or right response ports. Correct responses were rewarded with water while incorrect responses led to a brief time-out (between 3 and 8 s) indicated by presentation of a 100 ms broadband noise burst and in which the center port was disabled so that animals could not initiate a new trial. Following a time-out, the animal was presented with a correction trial in which the same stimulus and trial parameters (e.g. hold time) were used. To suppress any bias the animal might have to respond at a particular port, we continued to present timeouts and correction trials until a correct response was made. Once a correct response was made on correction trials, a new vowel sound and trial parameters were selected for the next trial. To encourage animals to maintain a steady head position at the center port during sound presentation, a water reward was also given at trial onset on a small proportion (10%) of randomly chosen trials.</p></sec><sec id="S9"><title>Sound localization</title><p id="P18">Ferrets were trained and tested in a second behavioral chamber that consisted of a custom-built D-shaped box surrounded by an array of seven speakers at 30° intervals. Each speaker had a response port located in front (8.5 cm in front of the speaker; 15.5 cm from the center of the box) at which animals could report sound location and obtain water rewards. A further port was also placed at the center of the arena to initiate stimulus presentation. This port was offset from the center by 3 cm to ensure the animal’s head was aligned at the center of the speaker ring, with the interaural axis in line with the -90° and +90° speakers. The distance between the head and speakers during sound presentation was 24 cm. Outside the training box, an LED (15 cm from the floor) was used to indicate trial availability. The test arena was housed in a custom built sound attenuating chamber (90 cm high x 90 cm wide x 75 cm deep, Zephyr Products Ltd, UK) lined with 45 mm acoustic foam.</p></sec></sec><sec id="S10"><title>Behavioral training</title><sec id="S11"><title>Vowel discrimination</title><p id="P19">Subjects were trained to discriminate a pair of vowels through a series of stages of increasing difficulty. When first introduced to the training apparatus, animals were rewarded with water if they visited any port. Once subjects had associated the ports with water, a contingency was introduced in which the subject was required to hold the head at the central port for a short time (501–1001 ms) before receiving a reward. The central port activation initiated a trial period in which a nose-poke at either peripheral port was rewarded.</p><p id="P20">Following acquisition of the basic task structure (typically two to three sessions), sounds were introduced. On each trial, two repeats of a single vowel sound (each 250 ms in duration with a 250 ms interval) were played after the animal first contacted the port with a variable delay (between 0 and 500 ms). A trial was initiated if the subject’s head remained at the port for the required hold time, plus an additional 500 ms in which the first token of the sound and subsequent interval were played. Following trial initiation, vowel sounds were looped (i.e. played repeatedly) until the ferret completed the trial by visiting the “correct” peripheral port to receive a reward. Nose-pokes at the “incorrect” peripheral port were not rewarded or punished at this stage and incorrect responses did not terminate trials. If the animal failed to visit the correct port within a specified period after initiating a trial (between 25 and 60 s), that trial was aborted and the animal could begin the next trial.</p><p id="P21">Once animals were completing trials frequently, the consequences of incorrect responses were altered so that incorrect responses terminated the current trial. Subjects were then required to return to the center port to initiate a correction trial in which the same stimulus was presented. Correction trials were included to prevent animals from biasing their responses to only one port and were repeated until the animal made a correct response. After a minimum of two sessions in which errors terminated trials, a time-out (between 5 and 15 s) punishment was added to incorrect responses. Time-outs were signaled by a burst of broadband noise (100 ms), and the center port was disabled for the duration of the time out, preventing initiation of further trials.</p><p id="P22">Once subjects could discriminate repeated sounds on consecutive sessions with a performance of 80%, looping of sounds was removed so that subjects were presented with only two vowel sounds during the initiation of the trial at the center port. When ferrets correctly identified 80% of vowels in two consecutive sessions, the animal was considered to be ready for testing in noise. Note that beyond experience through testing, ferrets did not receive specific training to discriminate vowels in noise.</p></sec><sec id="S12"><title>Sound localization</title><p id="P23">In contrast to vowel discrimination, training in sound localization took place after animals were implanted with cooling loops, and following completion of all testing in vowel discrimination. Ferrets (F1311 and F1509) were first trained to hold at the port in the center of the localization arena to initiate presentation of a series of repeating 1000 ms noise bursts (500 ms interval) from one speaker. The animal was allowed to leave the central port after the first burst, after which the stimulus repeated until a correct response was made at the peripheral port nearest the presenting speaker. Responses at other ports had no effect at this stage, but premature departures from the center triggered a short (1 sec) timeout.</p><p id="P24">Once ferrets were accustomed to the task (identified by regularly returning to the start port after receiving water from target locations), error detection was introduced so that trials were terminated when animals reported at the wrong peripheral port. The ferret was then required to initiate a new trial, on which the same stimulus was presented (correction trial) until a correct response was made. Time-outs were then introduced for incorrect responses and were increased from 1 to between 5 and 7 seconds. During this training phase, we also increased the hold time required at the central port before stimulus presentation, initially up to 500 ms during training and then 1000 ms during testing.</p><p id="P25">Once ferrets reached ≥ 60% correct, the stimulus was reduced to a single noise burst and subsequently the stimulus duration was reduced. Ferrets were ready for testing at these durations once their performance stabilized (approximately 3 to 4 weeks); for one ferret (F1311) we could reduce sound duration to between 250 and 100 ms with stable performance, however time constraints on the lifetime of the cooling implant required that we use a longer duration (700 ms) for the second animal (F1509). In all cases, animals were required to hold head position at the central port for the full duration of the sound and thus could not make head movements during stimulus presentation.</p></sec></sec><sec id="S13"><title>Cortical inactivation using cooling</title><sec id="S14"><title>Loop implantation</title><p id="P26">Cortical inactivation experiments were performed using an approach developed by <xref ref-type="bibr" rid="R70">Wood et al. (2017)</xref>: Two ferrets (F1311 &amp; F1509) were successfully implanted with cooling loops made from 23 gauge stainless steel tubing bent to form a loop shape approximately the size of primary auditory cortex. (A third ferret, F1216, was also implanted but the loops were persistently blocked and thus non-functional). At the base of the loop, a micro-thermocouple made from twisting together PFA insulated copper (30 AWG; 0.254 mm) and constantan wire (Omega Engineering Limited, UK), was soldered and secured with araldite. Thermocouple wires were soldered to a miniature thermocouple connector (RS components Ltd, UK) and secured with epoxy resin prior to implantation.</p><p id="P27">Loops were surgically implanted over the middle ectosylvian gyrus, specifically targeting the mid-to-low frequency regions of primary auditory cortex (A1 and Anterior Auditory Field, AAF) that border the non-primary fields of the posterior Ectosylvian gyrus (<xref ref-type="fig" rid="F2">Fig. 2A</xref>). Loops targeted this region as it is known to contain neurons sensitive to both sound timbre and location (<xref ref-type="bibr" rid="R11">Bizley et al., 2009</xref>; <xref ref-type="bibr" rid="R67">Town et al., 2018</xref>). Consistent with previous studies (<xref ref-type="bibr" rid="R70">Wood et al., 2017</xref>), we did not map the boundaries of auditory cortical subfields prior to loop placement. Cortical mapping may damage brain tissue, potentially triggering compensatory mechanisms that might mask a role in task performance. Placement of cooling loops was therefore based on our extensive experience targeting this area for electrode placements using anatomical landmarks (<xref ref-type="bibr" rid="R11">Bizley et al., 2009</xref>, <xref ref-type="bibr" rid="R10">2013b</xref>; <xref ref-type="bibr" rid="R67">Town et al., 2018</xref>).</p><p id="P28">Surgery was performed in sterile conditions under general anesthesia, induced by a single intramuscular injection of diazepam (0.4 ml/kg, 5 mg/ml; Hameln) and ketamine (Ketaset; 0.25 ml/kg, 100 mg/ml; Fort Dodge Animal Health, Kent, UK). Animals were intubated and ventilated, and anesthesia was then maintained with between 1 and 3% isoflurane in oxygen throughout the surgery. Animals were provided with subcutaneous injections of atropine (0.09 ml/kg, 600 μl/ml) and dexamethasone (0.25 ml/kg), as well as surgical saline intravenously, while vital signs (body temperature, end-tidal CO<sub>2</sub>, Oxygen saturation and electrocardiogram) were monitored throughout surgery.</p><p id="P29">General anesthesia was supplemented with local analgesics (Marcaine, 2 mg/kg, AstraZeneca) injected at the point of midline incision. Under anesthesia, the temporal muscle overlying the skull was retracted and largely removed, and a craniotomy was made over the ectosylvian gyrus. The dura over the gyrus was then opened to allow placement of the cooling loop on the surface of the brain. The loop was shaped during surgery to best fit the curvature of the cortical surface prior to placement, and was then embedded within silicone elastomer (Kwik-Sil, World Precision Instruments) around the craniotomy, and dental cement (Palacos R+G, Heraeus) on the head. Bone screws (stainless steel, 19010-100, Interfocus) were also placed along the midline and rear of the skull (two per hemisphere) to anchor the implant. Implant anchorage was also facilitated by cleaning the skull with citric acid (0.1 g in 10 ml distilled water) and application of dental adhesive (Supra-Bond C&amp;B, Sun Medical). Some skin was then removed in order to close the remaining muscle and skin smoothly around the edges of the implant.</p><p id="P30">Pre-operative, peri-operative and post-operative analgesia and anti-inflammatory drugs were provided to animals under veterinary advice. Animals were allowed to recover for at least one month before resuming behavioral testing and beginning cortical inactivation experiments.</p></sec><sec id="S15"><title>Cooling during behavior</title><p id="P31">To reduce the temperature of the cortical tissue surrounding the loop, cooled ethanol (100%) was passed through the tube using an FMI QV drive pump (Fluid Metering, Inc., NY, USA) controlled by a variable speed controller (V300, Fluid Metering, Inc., NY, USA). Ethanol was carried to and from the loop on the animal’s head via FEP and PTFE tubing (Adtech Polymer Engineering Ltd, UK) insulated with silicon tubing and, where necessary, bridged using two-way connectors (Diba Fluid Intelligence, Cambridge, UK). Ethanol was cooled by passage through a 1 meter coil of PTFE tubing held within a Dewar flask (Nalgene, NY, USA) containing dry ice and ethanol. After passing through the loop to cool the brain, ethanol was returned to a reservoir that was open to atmospheric pressure.</p><p id="P32">For a cooling session, the apparatus was first ‘pre-cooled’ before connecting an animal by pumping ethanol through spare cooling loops (i.e. loops that were not implanted in an animal) until loop temperatures fell below 0°C. The animal was then connected to the system, using the implanted thermocouples to monitor loop temperature at the cortical surface. The temperature was monitored online using a wireless transfer system (UWTC-1, Omega Engineering Ltd., UK) or wired thermometer, and pump flow rates adjusted to control loop temperature. Loops over both left and right auditory cortex were connected during bilateral cooling (all tasks), whereas only the left or right loop was connected during unilateral cooling (sound localization only).</p><p id="P33">For F1311, the animal was connected to the system and cooling began before the behavioral session, with the subject held by the experimenter and rewarded with animal treats (Nutriplus gel, Virbac, UK) while cooling pumps were turned on and loop temperatures reduced over five to ten minutes. When loop temperatures reached ≤ 12°C, the animal was placed in the behavioral arena and testing began. In contrast, F1509 would not perform tasks after being rewarded by the experimenter and so behavioral sessions were started and cortical temperature slowly reduced during task performance. Trials performed before the loops reached ≤ 20°C were excluded from analysis. Across animals, we considered bilateral cooling to be successful on any trial on which the average temperature across left and right loops was ≤ 20°C, while successful unilateral cooling required that one loop remained uncooled (≥ 35°C) while the other was ≤ 20°C (<xref ref-type="fig" rid="F2">Fig. 2B</xref>). Cooling to these temperatures should suppress spiking activity within the immediate vicinity of the loop without spreading beyond the ectosylvian gyrus (<xref ref-type="bibr" rid="R45">Lomber et al., 1999</xref>; <xref ref-type="bibr" rid="R19">Coomber et al., 2011</xref>; <xref ref-type="bibr" rid="R70">Wood et al., 2017</xref>).</p><p id="P34">For both animals, cooling took place while the animals were free to move without interaction with the experimenter and within the same apparatus used for previous behavioral testing. The behavioral tasks during cooling were unchanged from those already described; i.e. the same ranges of sound levels were used, correction trials were included and the same reward contingencies were used. For each trial in the task, the time of stimulus onset was recorded and cross-referenced with temperature records so that any trials in which cortical temperature was above threshold during a cooling session could be removed from the analysis. During control testing, animals were connected to the cooling system using the same thermocouple sensors, but cooling loops were not connected to FEP tubing in order to avoid blockages and maximize the functional lifespan of loops.</p></sec></sec><sec id="S16"><title>Data analysis: Behavior</title><p id="P35">All analyses excluded responses on correction trials, or trials where ferrets failed to respond within the required time (60 s). For all tests of vowel discrimination, we also required a minimum number of trials (n=10) and sessions (n=3) in both cooled and control conditions to include a sound level or SNR value in the analysis. Note that the requirement for a minimum number of trials introduced slight differences in the range of levels or SNRs tested between vowel discrimination experiments using vowel presentation both from left and right speakers and spatial release from energetic masking.</p><p id="P36">Temperature measurements were obtained on each trial for loops over left and right auditory cortex, and the animal was considered to be cooled if the average loop temperature was ≤ 20°C (bilateral cooling). In unilateral cooling, cooling was considered to be achieved if the relevant loop was ≤ 20°C. The threshold for cooling was based on previous work demonstrating the suppression of neural activity below this temperature (<xref ref-type="bibr" rid="R37">Jasper et al., 1970</xref>; <xref ref-type="bibr" rid="R45">Lomber et al., 1999</xref>).</p><p id="P37">Statistical analysis of effects of stimulus manipulation (e.g. presence of noise) and cooling used generalized linear mixed models (GLMMs) fitted using <italic>lme4</italic> (<xref ref-type="bibr" rid="R5">Bates et al., 2015</xref>) in R (version 4.2.1). The details of each model are outlined alongside the relevant results; however, in general, analysis of behavioral performance (correct vs. incorrect responses) was based on logistic regression in which the GLMM used binomial distribution and logit link function settings. For each model, we used ferret as a random factor and reported the magnitude of coefficients (β) of fixed effects of interest (e.g. effect of cooling) and probability (p) that the coefficient was drawn from a distribution centered about zero. To check model fit, we used the <italic>DHARMa</italic> package to assess the randomized quantile residuals (<xref ref-type="bibr" rid="R26">Dunn and Smyth, 1996</xref>) and reported both the marginal and conditional R<sup>2</sup> values (<xref ref-type="bibr" rid="R52">Nakagawa and Schielzeth, 2013</xref>).</p><sec id="S17"><title>Vowel Discrimination</title><p id="P38">To analyze the effects of cooling, we compared behavioral performance of each animal across multiple sessions: The effects of cooling were measured on paired testing sessions performed on the same day (F1509) or unpaired sessions collected over the same time period (F1311). For F1509, we excluded trials when the animal was tested with sound levels below 50 dB SPL, for which no other subject was tested.</p><p id="P39">To summarize performance of each subject in a particular stimulus condition (clean conditions, co-located noise etc.), we randomly resampled (bootstrapped) data with equal numbers of each vowel and sound level or SNR (when showing data across level or SNR). Bootstrapping was performed 10<sup>3</sup> times, with samples drawn with replacement on each iteration. For each bootstrap iteration, the number of samples drawn for each sound level or SNR was defined by taking the median of the number of trials sampled at each level or SNR. (For example, if we originally collected 10, 20 and 30 trials at 50, 60 and 70 db SPL, we randomly drew 20 trials with replacement for each sound level). Where vowels varied in sound location, we also resampled with equal numbers of trials with vowels from left and right speakers.</p></sec><sec id="S18"><title>Sound Localization</title><p id="P40">Performance localizing sounds was analyzed using the percentage of trials on which animals correctly reported the target stimulus position. For F1311, we included responses to sounds of 100 ms and 250 ms duration, and sampled a random subset of data to ensure equal numbers of trials with each sound duration were included for each cooling condition. For each animal, we considered control data from all sessions after training was complete, and all trials obtained during cooling. When bootstrap resampling, we randomly drew equal numbers of trials when sounds were presented at each location (F1311: 69 trials at each of seven locations; F1509: 27 trials at each of six locations).</p></sec></sec><sec id="S19"><title>Optogenetics</title><sec id="S20"><title>Injections in Auditory Cortex</title><p id="P41">Four ferrets (F1706, F1801, F1807 and F1814) were injected bilaterally in auditory cortex with an Adeno-associated Virus (AAV) to induce expression of Channelrhodopsin 2 (ChR2) in GABAergic interneurons using the mDlx promotor (AAV2.mDlx.ChR2-mCherry-Fishell3.WPRE.SV40, Addgene83898, UPenn Vector Core)(<xref ref-type="bibr" rid="R24">Dimidschstein et al., 2016</xref>). For each auditory cortex (i.e. left and right), injections were placed at two sites in the same area of MEG in which cooling loops were placed, under general anesthesia using the same sterile surgical protocol as described above. Within each site, injections were made at two depths (500 and 800 μm below the cortical surface) so that a total of four injections were made, with 1 μl injected each time.</p></sec><sec id="S21"><title>Optogenetic testing during behavior (F1706)</title><p id="P42">Following viral delivery, we implanted an optrode (Neuronexus, Ann Arbor, MI, USA) in each auditory cortex to deliver light in F1706. During testing, light was delivered from a 463 nm DPSS laser (Shanghai Laser &amp; Optics Century Ltd. China) with a steady-state power of 40 mW, measured at fiber termination before the optrode using an S140C integrating sphere photodiode sensor (ThorLabs, Germany). Although the optrode implanted included recording sites for monitoring neural activity during testing, we were unable to eliminate grounding issues that made recordings from this animal unusable and we therefore elected to train the animal in the vowel discrimination task and look for behavioral effects of silencing auditory cortex. The optrode was housed within an opaque plastic tower (25 mm tall) embedded in dental cement.</p><p id="P43">Retraining and testing of this animal after viral injection and optrode implantation was delayed due to the Covid-19 pandemic and behavioral testing took place 20 months after injection. At this point, we were only able to test the effect of light delivery on vowel discrimination in noise and a subsequent failure in the implant precluded testing of vowel discrimination in clean conditions, or with stimuli used to study spatial release from energetic masking or sound localization. The implant failure also prevented us from perfusing the brain of this animal in order to detect viral expression (although see below for successful confirmation of viral expression in other animals).</p><p id="P44">All data during vowel discrimination in noise was collected when the animal was attached to the optical fiber system, with opaque black tape used to secure the attachment and ensure that laser light was not visible to the ferret. In behavioral testing, light was delivered on 50% of test trials (with the exception of the first test session in which the laser was presented on all test trials); however, all correction trials took place without light delivery. On each trial that light was presented, we used short pulses (10 ms duration, presented at 10 Hz) that began 100 ms before sound onset, and continued until 100 ms after sound offset.</p><p id="P45">Data analysis for performance discriminating vowels in noise followed the same procedure as for analysis of behavior in animals with cooling. However, optogenetics provided more refined temporal control than cooling, allowing us to compare performance on trials within the same test session, with and without light delivery.</p></sec><sec id="S22"><title>Optogenetic suppression of cortical activity (F1801 and F1807)</title><p id="P46">Photostimulation in visual cortex of ferrets expressing ChR2 in GABAergic interneurons suppresses cortical activity (<xref ref-type="bibr" rid="R69">Wilson et al., 2018</xref>). To determine if stimulation of ChR2 in GABAergic neurons was also sufficient to suppress sound-driven responses in auditory cortex, we recorded the activity of auditory cortical neurons while presenting stimuli with and without laser stimulation to ferrets under anesthesia.</p><p id="P47">Anesthesia was induced by a single dose of ketamine (Ketaset; 5 mg/kg/h; Fort Dodge Animal Health) and medetomidine (Domitor; 0.022 mg/ kg/h; Pfizer). The left radial vein was cannulated and anesthesia was maintained throughout the experiment by continuous infusion (ketamine: 5 mg/kg/hr; medetomidine: 0.022 mg/kg/hr; atropine sulfate: 0.06 mg/kg/hr and dexamethasone: 0.5 mg/kg/hr in Hartmann’s solution with 5% glucose). The ferret was intubated, placed on a ventilator (Harvard Model 683 small animal ventilator; Harvard Apparatus) and supplemented with oxygen. Body temperature (38°C), electrocardiogram and end-tidal CO<sub>2</sub> were monitored throughout the experiment (~48 hours).</p><p id="P48">Animals were then placed in a stereotaxic frame and the site of viral injection over both left and right auditory cortex was exposed. A metal bar was attached to the midline of the skull, holding the head without further need of a stereotaxic frame. The animal was then transferred to a small table in a soundproof chamber (Industrial Acoustics, Winchester, UK) for stimulus presentation and neural recording. During recordings, the craniotomy was covered with 3% agar, replaced at regular intervals.</p><p id="P49">Neural activity was recorded in SpikeGLX (v 3.0., billkarsh.github.io/SpikeGLX) using Neuropixels Probes (IMEC, v1.0) inserted orthogonal to the cortical surface, and connected via headstages to an IMEC PXIe data acquisition module within PCI eXtensions for Instrumentation (PXI) hardware (PXIe-1071 chassis and PXI-6132 I/O module, National Instruments) that sampled neural signals at 30 kHz. Candidate action potentials were then extracted and sorted in Kilosort (v3.0., <ext-link ext-link-type="uri" xlink:href="http://github.com/MouseLand/Kilosort">github.com/MouseLand/Kilosort</ext-link>), and manually curated to identify single (n = 174) or multi-unit (n = 291) activity. Spike clusters were merged based on assessment of waveform similarity and classed as a single unit using waveform size, consistency and inter-spike interval distribution (all single units had ≤2% of spikes within 2ms). Spike clusters without negative deflections in the waveform, which were primarily laser artifacts (identified as sharp peaks in the waveforms) were discarded from the analysis.</p><p id="P50">During recording, we presented broadband noise bursts of varying levels (40 to 70 dB SPL) and durations (50, 100 and 250 ms), either alone or with laser on. Stimuli were repeated 20 times, with a pseudo-random interval (0.5 to 0.7 seconds) between trials. Laser stimulation was provided by the same 463 nm DPSS laser used in behavioral experiments with F1706, attached to a custom made optic-fiber (1.5 mm diameter, Thorlabs FP1500URT) that was designed to maximize the area over which light was delivered, and could provide up to 300 mW at the fiber tip. Here, we report effects of pulsed light, delivered with a target power of 50 mW and frequency of 1 or 10 Hz. Pulses had a square-wave design with 50% duty cycle, beginning 100 ms before sound onset and ending 100 ms after sound offset. In addition to laser testing with sound presentation, we also tested the effect of the laser on spontaneous activity without sound. The effects of laser light delivery were measured at several sites over auditory cortex by placing the optic fiber and Neuropixel probe in various configurations over MEG and close to the viral injection sites of auditory cortex in each animal.Due to the COVID-19 pandemic, recordings were delayed until 21 months (F1801) and 18 months (F1807) after viral injection.</p><p id="P51">After recordings were completed, each animal was transcardially perfused with 0.9% saline and 4% paraformaldehyde (PFA) under anesthesia. The brain was then removed for storage in PFA, before sinking in 30% sucrose for 5 days prior to cryosectioning. Due to unavailability of a functioning cryostat (also delayed by the pandemic), brains were stored in PFA for six months, potentially limiting the quality of fluorescent signals. Coronal sections (50 μm) were taken through the full extent of the ectosylvian gyrus in order to confirm viral expression via visualization of mCherry. To better judge the quality of viral expression on a shorter timescale, we also transcardially perfused a further animal (F1814) within 12 weeks of viral injection, sectioned it immediately and measured mCherry and cell body (DAPI) labeling. Slices were imaged using a Zeiss Axio Imager 2.0 and Zeiss Confocal, and processed on Zen Blue.</p></sec></sec><sec id="S23"><title>Data analysis: Optogenetic modulation of neural activity</title><p id="P52">To contrast the effects of laser light delivery on sound-driven activity, we first calculated the mean firing rate of each unit during auditory evoked activity, taking a window from sound onset to sound offset (50, 100 or 250 ms in length). For each unit, we compared the mean firing rate during this window calculated over all conditions in which the laser was present with the mean firing rate when the laser was absent (change in firing rate = laser OFF - laser ON). To contrast the effects of laser light delivery on spontaneous activity of each unit, we performed the same calculation on mean firing rates during the 100ms window before sound onset, on trials with and without the laser.</p><p id="P53">Inspection of neural activity with, and without laser suggested that light delivery had distinct effects on subgroups of neurons. To test if units could be distinguished by their modulation to laser delivery and to determine the number of separable groups of units using an unsupervised approach, we applied K-means clustering to the firing rates of each unit with and without laser. Clustering was based on the cosine distance between units (rather than Euclidean distance) in order to isolate the change in spike rate with laser stimulation across units with widely varying baseline firing rates. We identified the appropriate number of clusters within the data by comparing the sum of point-to-centroid distances for K = 1 to 10 and finding the knee-point using vector bisection (Dmitry Kaplan 2022. Knee Point, MATLAB Central File Exchange. <ext-link ext-link-type="uri" xlink:href="http://www.mathworks.com/matlabcentral/fileexchange/35094-knee-point">www.mathworks.com/matlabcentral/fileexchange/35094-knee-point</ext-link>).</p><p id="P54">To map the extent of sound-evoked activity across the length of the probe, we compared mean spike rates during sound presentation and a time window preceding sound onset of matched duration (Wilcoxon signed-rank test). This analysis was performed on each unit to each sound duration by sound level condition, with Bonferroni correction for multiple comparisons. Units that showed a significant response in any of the conditions were classed as an auditory evoked unit (n = 72). We then contrasted the effects of laser light delivery on the firing rates of units recorded at different cortical depths during sound presentation, where depth refers to the distance on the probe from the most superficial channel on which spiking activity was observed.</p><p id="P55">We also investigated the temporal dynamics of the optogenetic stimulation to control for heating effects from laser delivery (<xref ref-type="bibr" rid="R57">Owen et al., 2019</xref>). To identify the latency at which light delivery induced a significant change in firing, we performed nonparametric cluster statistical analysis, which controls for multiple comparisons that would occur from calculating a test-statistic over each timepoint, by calculating a test-statistic from clusters of adjacent time samples of the PSTH in which firing rate with laser was greater than without laser (or vice versa)(<xref ref-type="bibr" rid="R47">Maris and Oostenveld, 2007</xref>). This statistic was calculated during the 100 ms after laser onset for each condition and the minimum time bin labeled as significant by the cluster statistic was averaged across conditions to calculate the latency for each unit.</p></sec></sec><sec id="S24" sec-type="results"><title>Results</title><sec id="S25"><title>Optogenetic inactivation of sound-driven responses in auditory cortex</title><p id="P56">We used an AAV vector with an mDlx promoter to target expression of ChR2 to GABAergic interneurons in ferret auditory cortex. Post-mortem histology confirmed viral expression in two of three animals perfused (F1807 and F1814, but not F1801, in whom terminal recordings had severely compromised brain quality). Widefield imaging demonstrated viral expression in MEG, with labeled cells observed up to between 1 and 2 mm from injection sites (<xref ref-type="fig" rid="F3">Fig. 3A</xref>). Confocal imaging revealed colocalization of mCherry with cell bodies (labeled by DAPI), with the opsin localized around the cell body (F1814).</p><p id="P57">We then examined the electrophysiological efficacy of cortical inactivation through optogenetics using Neuropixels probes to record the activity of 465 units (n = 174 single units, 291 multi-units) in auditory cortex under ketamine-medetomidine anesthesia. Multiple optic fiber and recording sites were tested over auditory cortex, and at each site, we presented broadband noise with half of the trials having a laser delivery simultaneously presented (from 100 ms before, to 100 ms after sound onset/offset; <xref ref-type="fig" rid="F3">Fig. 3B-C</xref>). Light delivery affected neural responses in a variety of ways, including suppressing responses to sound, suppressing baseline spontaneous firing and, in some cases, driving firing (<xref ref-type="fig" rid="F3">Fig. 3D</xref>).</p><p id="P58">When comparing the mean firing rates of units with and without laser light, we saw that the activity of most units were suppressed by light, but that a small number showed no change in firing, or increases in firing. While these patterns were most evident when examining firing in the time window around sound presentation (<xref ref-type="fig" rid="F4">Fig. 4A</xref>), the same pattern was also evident in spontaneous activity (<xref ref-type="fig" rid="F4">Fig. 4B</xref>). During spontaneous activity the lower firing rates of units gave less scope to observe modulation and thus the effects of inactivation were weaker.</p><p id="P59">To capture the distinct effects of light delivery on the neural population, we used K-means clustering to classify units into separate groups based on their responses to sounds with and without laser light. Assessing cluster performance with K between 1 and 10 (see Methods) indicated that two clusters captured the majority of variance between units, with the two groups being distinguished by their sensitivity to photostimulation both when considering auditory evoked activity (<xref ref-type="fig" rid="F4">Fig. 4C</xref>) and spontaneous activity (<xref ref-type="fig" rid="F4">Fig. 4D</xref>).</p><p id="P60">When comparing the effects of laser light on sound evoked firing, Cluster 1 showed a significant decrease with photostimulation (n = 272 units, median change of -1.296 spikes/s, Wilcoxon signed rank test with Bonferroni correction, p &lt; 0.001, Z = -14.3), whilst Cluster 2 showed a small but significant increase in firing with light delivery (n = 193 units, median change of 0.0667 spikes/s, p &lt; 0.001, Z = 5.09). In periods of spontaneous activity, Cluster 1 showed a significant decrease in firing with light delivery (median change of -0.4167 spikes/s, Wilcoxon signed rank test with Bonferroni correction, p &lt; 0.001, Z = -8.18), whilst Cluster 2 showed a similar increase in firing in the spontaneous condition as in the evoked condition (median change of 0.0667 spikes/s, p &lt; 0.001, Z = 4.22).</p><p id="P61">For each unit within a cluster, we also asked if the mean sound-evoked firing rate (windowed between 50 to 150 ms from laser onset, which included 50 ms of baseline activity and the first 50 ms of sound evoked activity) differed between laser presentation and absence (two-tailed sided Wilcoxon signed rank test, p &lt; 0.05). The majority of units in Cluster 1 (60.3 %) showed significant decreases in activity with light delivery, while only a minority of units (25.9%) in Cluster 2 were affected by light delivery. The pattern of results was similar, regardless of whether activity was recorded from single units or multi-units (<xref ref-type="table" rid="T2">Table 2</xref>).</p></sec><sec id="S26"><title>Spatial and temporal organization of optogenetic inactivation</title><p id="P62">The extent and speed of inactivation are major considerations when manipulating neural activity during behavior. To understand how far and how fast it was possible to suppress neurons using ChR2 expressed via the mDlx promoter, we mapped the effects of laser light with cortical depth and time (<xref ref-type="fig" rid="F5">Fig. 5</xref>). In our analysis of depth, we defined the limits of auditory cortex on the basis of sound-evoked responses, of which 95% were observed within 2.62 mm of the top of the probe (<xref ref-type="fig" rid="F5">Fig. 5A-B</xref>). Such functional estimates are comparable with the thickness of ferret auditory cortex observed histologically (with correction for tissue shrinkage during fixation, <xref ref-type="fig" rid="F3">Fig. 3A</xref>).</p><p id="P63">Across the depth profile of auditory cortex, laser-driven suppression of neural activity was stronger in more superficial units and diminished with distance from the cortical surface (<xref ref-type="fig" rid="F5">Fig. 5C</xref>). The effect of depth was evident in the median position of units in clusters 1 and 2 (identified through K-means clustering in the previous section), with light-suppressed units grouped in cluster 1 occurring significantly closer to the cortical surface (rank-sum test, p &lt; 0.001).</p><p id="P64">Modeling the laser-related change in single trial spike counts of individual units as a function of distance from the cortical surface confirmed a significant interaction between depth and light delivery (Poisson mixed-model regression with distance and light as fixed effects, ferret, unit and sound duration as random effects, p &lt; 0.001). However, the fall-off in suppression captured by the model took place across several millimeters, with 90% of all significantly inactivated units (<xref ref-type="table" rid="T2">Table 2</xref>) being located within 1.598 mm of the cortical surface. This prolonged fall-off over several millimeters contrasts with the rapid attenuation of blue light in tissue over hundreds of micrometers (<xref ref-type="bibr" rid="R43">Li et al., 2019</xref>), making it unlikely that light-based artifacts account for the spatial extent of inactivation observed.</p><p id="P65">The temporal profile of inactivation also indicated that the effects we observed were not a trivial result of cortical heating, as light delivery suppressed cortical activity rapidly (<xref ref-type="fig" rid="F5">Fig. 5D</xref>).</p><p id="P66">Nonparametric cluster statistics revealed a median latency for significant change in firing at 2.5 ms. Such rapid changes in firing rate show that the mDlx-induced expression of ChR2 in auditory cortex provided a fast method for cortical inactivation, and are unlikely to be driven by changes in temperature of tissue that have been reported over longer time-scales, on the order of hundreds of milliseconds or seconds (<xref ref-type="bibr" rid="R57">Owen et al., 2019</xref>).</p></sec><sec id="S27"><title>Optogenetic inactivation primarily affects broad-spiking neurons</title><p id="P67">Analysis of light-driven suppression of sound driven responses indicated that optogenetic inactivation affected a specific subgroup of neurons; that is units in cluster 1 but not cluster 2, identified through K-means clustering. It is possible that cells within each cluster may be drawn from distinct populations of neurons suppressed by light-driven local network inhibition (cluster 1), and GABAergic interneurons driven by light (cluster 2). Pyramidal neurons and interneurons are often distinguished by their spike waveform as broad and narrow spiking cells respectively (<xref ref-type="bibr" rid="R54">Niell and Stryker, 2008</xref>; <xref ref-type="bibr" rid="R51">Moore and Wehr, 2013</xref>) and so we asked if the clusters identified from firing rate data might have distinct spike shapes that correspond to these cell types.</p><p id="P68">To compare spike shapes, we measured the trough-to-peak latencies of average spike waveforms from well-isolated single units in cluster 1 (n = 80) and cluster 2 (n = 20) recorded within 1.598 mm from the cortical surface (i.e. the depth range within which 90% of significantly inactivated units were identified). We found that the trough to peak latencies of single units in cluster 1 (i.e. those that were suppressed by the laser) were indeed longer than those in cluster 2, indicating a broader waveform (<xref ref-type="fig" rid="F5">Fig. 5E</xref>).</p><p id="P69">To determine whether differences in trough-to-peak latency observed between clusters might arise spuriously, we compared the difference we observed in our data with results when randomly shuffling cluster labels (<xref ref-type="fig" rid="F5">Fig. 5F</xref>). Permutation testing confirmed that the difference in spike widths between clusters was significant (p = 0.01, n = 1000 iterations). Thus our results are consistent with the suggestion that neurons suppressed by the laser were primarily broad-spiking excitatory/pyramidal neurons, while the remaining cells were more likely to be narrow-spiking inhibitory interneurons. Note however that because the mDlx promotor is specific only to GABAergic neurons, light is likely to drive multiple subclasses of inhibitory interneurons including, but not restricted to, fast spiking PV neurons.</p></sec><sec id="S28"><title>Auditory cortex is required for vowel discrimination in co-located noise but not clean conditions</title><p id="P70">We examined the role of primary auditory cortex in behavior using cortical inactivation via cooling in two ferrets (F1311 and F1509) or stimulation of inhibitory interneurons using optogenetics in one ferret (F1706). Ferrets were trained to report the identity of vowel sounds (F1311: /a/ and /i/, F1509, F1706: /u/ and /εe/) of varying sound level in clean conditions (<xref ref-type="fig" rid="F1">Fig. 1A</xref>),, and then tested with vowels in additive broadband noise in control conditions and with cooling or laser light delivery.</p><p id="P71">Auditory cortical inactivation impaired vowel discrimination in noise in each animal (<xref ref-type="fig" rid="F6">Fig. 6</xref>). Across SNRs, performance discriminating sounds in noise was worse during cooling than control sessions (change in performance [cooled-control]: F1311 = -11.1%, F1509 = -9.72%) and worse on trials when light was delivered ([Light: On - Off]: F1706 = -12.5%). In contrast, cooling did not impair vowel discrimination in clean conditions in either animal tested (F1311 = +5.39%, F1509 = +1.85%, F1706 not tested with laser light delivery in clean conditions).</p><p id="P72">To assess changes in vowel discrimination with cortical inactivation across ferrets, we compared single trial performance using a mixed-effects logistic regression with ferret as a random effect, and in which background noise (clean vs. noise), experimental treatment (test [cooled or light-on] vs. control [warm or light-off]) and the interaction between treatment and noise were contrasted as fixed effects. We also included whether the subject was rewarded at the center spout and the sound level of vowels as covariates, as well as the interaction between sound level and noise condition. Using the Akaike Information Criterion, this model was selected over other alternatives that either omitted interactions, or included three-way interactions between noise, treatment and sound level.</p><p id="P73">The impairment in vowel discrimination in noise with cortical inactivation was reflected in the fitted model as a significant interaction between noise condition and experimental treatment (<xref ref-type="table" rid="T3">Table 3</xref>, p = 0.002). There was also a significant main effect of noise (p &lt; 0.001) that captured the general impairment of performance caused by degrading sounds. There was no main effect of treatment alone (p = 0.374), illustrating that the general ability to perform a two choice task was not affected by cooling/light delivery.</p></sec><sec id="S29"><title>Spatial separation of vowel and noise</title><p id="P74">In the initial vowel discrimination task, vowels and noise were presented together from two speakers; one on the left and right of the head. We also tested a variant of the task in which vowel and noise were presented either together at a single speaker, or spatially separated from left and right speakers (<xref ref-type="fig" rid="F1">Fig. 1B</xref>). In initial behavioral testing, we measured the extent of spatial release from energetic masking in six animals: two ferrets implanted with cooling loops (F1311 and F1509) as well as four additional ferrets that were not used for cortical inactivation (F1201, F1203, F1216 and F1217).</p><p id="P75">Spatial separation of vowel and noise improved the ability of each ferret to discriminate vowel identity compared to colocated vowel and noise (<xref ref-type="fig" rid="F7">Fig. 7A</xref>). In terms of percent correct, the benefit of spatial separation was consistent but small for each subject (mean across bootstrap resamples, separated - colocalized; F1311: +1.35%, F1509: +2.85%, F1201: +1.73%, F1203: +2.68%, F1216: 1.94%, F1217 = +2.19%). To relate these results to the maximum unmasking possible, we also measured the effect of removing noise entirely by presenting vowels from a single speaker in clean conditions. Removing noise improved performance (mean across bootstrap resamples, clean - colocalized; F1311: 5.78%, F1509: 15.1%, F1201: 26.6%, F1203: 16.7%, F1216: 11.9%, F1217: 20.2%), but no animal performed perfectly in clean conditions (<xref ref-type="fig" rid="F7">Fig. 7B</xref>). Thus, although the absolute changes in performance with spatial separation of noise and vowel were small, they could represent a substantial fraction (up to one fifth) of the behavioral benefit observed when removing noise entirely.</p><p id="P76">Spatial separation also improved vowel discrimination in noise during auditory cortical inactivation. In two animals tested with bilateral cooling, performance was better in spatially separated than co-located noise (<xref ref-type="fig" rid="F7">Fig. 7C</xref>, separated - colocalized, F1311: +12.7%, F1509: +5.87%). The benefit of spatial separation was larger during cooling than control conditions (F1311: +1.35%, F1509: +2.85%), primarily because cooling impaired vowel discrimination in co-located noise, and the effect of cooling was ameliorated by spatially separating the vowel and noise. The performance benefit of removing noise completely was also evident during cooling (<xref ref-type="fig" rid="F7">Fig. 7D</xref><bold>)</bold> and more pronounced than in control conditions ([clean - colocalized], cooled vs. control: F1311: 17.5% vs. 5.78%, F1509: 18.1% vs 15.1%).</p><p id="P77">To model the effects of spatial separation of vowel and noise on task performance, we fitted a mixed-effects logistic regression to response counts from all animals, with ferret as a random effect and with noise condition (separated vs. co-located), treatment (cooled vs. control), sound level and vowel location (left vs. right) as fixed effects. To account for the possibility that cortical inactivation modulated the effect of spatial separation, we also included an interaction term between treatment and noise condition. Model fitting confirmed the importance of spatial separation (p = 0.009) and the effect of cooling on vowel discrimination in noise (p = 0.011; <xref ref-type="table" rid="T4">Table 4</xref>), as well as the relationship between task performance and sound level (p &lt; 0.001, <xref ref-type="fig" rid="F7">Fig. 7E</xref>). There was no significant interaction between cooling and separation, indicating that, at least for the animals tested, cortical inactivation did not affect the performance gained by separating vowel and noise.</p></sec><sec id="S30"><title>A shared role for auditory cortex in sound localization and vowel discrimination in noise</title><p id="P78">To determine whether the region of auditory cortex that we inactivated was also involved in spatial hearing, we retrained the two ferrets implanted with cooling loops in an approach-to-target sound localization task (<xref ref-type="fig" rid="F1">Fig. 1C</xref>). Sound localization was then tested in control conditions and when cooling auditory cortex bilaterally or unilaterally, with cooling of the left or right auditory cortex only.</p><p id="P79">Bilateral cooling impaired sound localization in both ferrets (<xref ref-type="fig" rid="F8">Fig. 8A-B</xref>), with performance (percent correct) being significantly lower during cooling than in control testing (change in performance [cooled-control]: F1311 = -14.8%, F1509 = -12.9%).</p><p id="P80">We modeled the effects of bilateral cooling on single trial performance using mixed-effects logistic regression, with treatment [cooled/control] as a fixed effect, and with sound level and center reward as additional covariates in the fixed model. In the random model, we included ferret and speaker location; speaker location was included in the random rather than fixed model to avoid the non-linear dependence of performance on sound location (<xref ref-type="fig" rid="F8">Fig. 8C</xref>). The resulting model fit confirmed a significant main effect of cooling, as well as sound level and center reward (p &lt; 0.001, <xref ref-type="table" rid="T5">Table 5</xref>).</p><p id="P81">Unilateral cooling impaired localization of sounds in the contralateral hemifield of space to a greater extent than sounds in the ipsilateral hemifield (<xref ref-type="fig" rid="F9">Fig. 9A-B</xref>). Cooling left auditory cortex resulted in larger impairments when localizing sounds in the right side of space, compared to the left (mean change in performance across bootstrap iterations, right vs left speakers, F1311: -19.1 vs + 0.4%, F1509: -32.5 vs -15.6%). Cooling the right auditory cortex had a less detrimental effect, but again resulted in larger deficits in contralateral localization; here, performance was more strongly impaired when localizing sounds in the left than right side of space for one ferret (change in performance, left vs. right speakers, F1509: -22.9 vs. -6.4%). The same pattern of results was observed in the other ferret, but the difference in performance between speaker locations was much smaller (F1311: -8.3 vs -7.5%). In comparison, the effects of bilateral cooling were similar when localizing sounds in both left and right hemifields (F1311: -14.5 vs. -16.6%, F1509: -15.6% vs. -13.4%).</p><p id="P82">To model performance during unilateral cooling, we used a mixed-effects logistic regression with ferret as a random effect, and fixed effects for cooled hemisphere (left or right auditory cortex), speaker hemifield (left or right side of space) and distance from each speaker to the midline (30°, 60° or 90°). Comparison of nested models demonstrated that interactions between each parameter, up to the level of the three-way interaction significantly improved model fit (analysis of deviance, p &lt; 0.001) and so we included all interactions between these terms. We also included sound level, the occurrence of a center reward and performance on control trials without cortical cooling (expressed as proportion of trials correct when all other variables were held constant) as covariates.</p><p id="P83">The model captured the larger effect of unilateral cooling on sound localization in the contralateral hemisphere described above as a significant interaction between cooled hemisphere and speaker hemifield (p = 0.008, <xref ref-type="table" rid="T6">Table 6</xref>). The interaction between cooled hemisphere, speaker hemifield and angular distance of speaker from the midline (p &lt; 0.001) also emphasized how the effects of unilateral cooling were increasingly pronounced at peripheral sound locations (<xref ref-type="fig" rid="F9">Fig. 9C</xref>).</p></sec></sec><sec id="S31" sec-type="discussion"><title>Discussion</title><p id="P84">Our results, summarized in <xref ref-type="table" rid="T7">Table 7</xref>, demonstrate that both vowel discrimination in noise and sound localization depend on a common region of ferret auditory cortex, and that cortical inactivation via cooling leads to behavioral deficits in both tasks, while leaving intact other forms of hearing such as vowel discrimination in clean conditions.</p><sec id="S32"><title>Selection of cortical region for inactivation</title><p id="P85">We implanted cooling loops (or optic fibers) over the MEG, specifically targeting the mid-to-low frequency regions of primary auditory cortex (that border the non-primary fields of posterior ectosylvian gyrus; <xref ref-type="fig" rid="F2">Fig. 2A</xref>). We targeted this area as it contains neurons that are predominantly tuned to low sound frequencies (Bizley et al., 2005), often vowel responsive and/or spatially tuned (<xref ref-type="bibr" rid="R11">Bizley et al., 2009</xref>; <xref ref-type="bibr" rid="R66">Town et al., 2017</xref>, <xref ref-type="bibr" rid="R67">2018</xref>) and may play an important role in encoding interaural timing cues supporting sound localization (<xref ref-type="bibr" rid="R71">Wood et al., 2019</xref>). It is thus perhaps unsurprising that a region implicated in processing of spatial and non-spatial sound features should contribute to multiple forms of hearing.</p><p id="P86">The extent of inactivation is a critical consideration in any perturbation study (<xref ref-type="bibr" rid="R63">Slonina et al., 2022</xref>); the size of cooling loops used here reflected a compromise between the need to inactivate sufficient numbers of neurons to observe behavioral deficits, and avoid unintended spread of cooling to subcortical structures (<xref ref-type="bibr" rid="R19">Coomber et al., 2011</xref>). Previous data from our lab has shown that the cooling loops we used induce spatially-restricted heat loss that limits the reduction in spiking activity to the cortical layers surrounding the loop (<xref ref-type="bibr" rid="R70">Wood et al., 2017</xref>). In the current study, ferrets could discriminate vowels in clean conditions during bilateral cooling, while in the same sessions, vowel discrimination in noise was impaired. The ability of animals to discriminate vowels in clean conditions demonstrates that the cooling protocol we used did not affect ferrets’ general hearing, motor ability or capacity to engage in behavioral tasks.</p><p id="P87">A critical outstanding question is to what extent non-primary regions of auditory cortex beyond MEG contribute to sound localization and vowel discrimination in noise. Earlier cooling studies have used multiple loops to identify distinct contributions of non-primary areas of cat auditory cortex to spatial and non-spatial hearing (<xref ref-type="bibr" rid="R44">Lomber and Malhotra, 2008</xref>). If such distinctions also exist in ferrets, then one would predict that inactivation of distinct fields of non-primary auditory cortex may disrupt specific tasks. Testing this will be an important issue for future investigations, which will benefit from the optogenetic techniques that we have confirmed here are effective in rapidly suppressing auditory cortical processing of sounds and disrupting psychoacoustic task performance.</p></sec><sec id="S33"><title>What is auditory cortex doing?</title><p id="P88">Our results confirm the widely observed role of auditory cortex in sound localization in carnivores (<xref ref-type="bibr" rid="R41">Kavanagh and Kelly, 1987</xref>; <xref ref-type="bibr" rid="R64">Smith et al., 2004</xref>; <xref ref-type="bibr" rid="R46">Malhotra et al., 2008</xref>), while the ability of ferrets to discriminate vowels in clean conditions is consistent with similar behavior in cats with lesions of primary and secondary auditory cortex (<xref ref-type="bibr" rid="R21">Dewson, 1964</xref>). Thus, although auditory cortical neurons are strongly modulated by vowel timbre (<xref ref-type="bibr" rid="R11">Bizley et al., 2009</xref>), there may be redundant encoding of spectral timbre across multiple cortical fields, or this activity may not be required for the simple two-choice timbre discrimination employed here.</p><p id="P89">A role for auditory cortex in vowel discrimination became evident when we added noise to vowels. An open question from our work is whether the same role for auditory cortex would be observed in clean conditions if vowels were presented closer to ferret’s psychophysical thresholds. If so, then our current results might indicate a role for auditory cortex in difficult listening conditions that is consistent with deficits in fine spectrotemporal discriminations following auditory cortical lesions in cats and non-human primates that otherwise have limited effects on easier tasks requiring coarser resolution (<xref ref-type="bibr" rid="R27">Evarts, 1952</xref>; <xref ref-type="bibr" rid="R33">Goldberg and Neff, 1961</xref>; <xref ref-type="bibr" rid="R23">Diamond et al., 1962</xref>; <xref ref-type="bibr" rid="R48">Massopust et al., 1965</xref>; <xref ref-type="bibr" rid="R22">Dewson et al., 1969</xref>; <xref ref-type="bibr" rid="R36">Heffner and Heffner, 1986</xref>). Interpreting lesion studies requires caution, due to the potential for recovery of function; however our results were obtained using reversible methods for which there was minimal opportunity for recovery during cooling, and particularly during rapid optogenetic inactivation.</p><p id="P90">The benefit of spatial separation of vowel and noise to vowel discrimination observed during cooling, coupled with impaired sound localization is consistent with separate mechanisms for spatial stream segregation and discrimination of sound location (<xref ref-type="bibr" rid="R50">Middlebrooks and Onsan, 2012</xref>). That spatial separation of target vowels and noise maskers benefits vowel discrimination during cortical cooling suggests that subcortical structures can parse the noise and vowel into separate streams. In stark contrast, substantial performance deficits were observed for co-located vowel and noise, emphasizing the importance of auditory cortex in segregating competing co-located sound sources (<xref ref-type="bibr" rid="R49">Mesgarani and Chang, 2012</xref>; <xref ref-type="bibr" rid="R7">Bizley and Cohen, 2013</xref>). In our results, the spatial separation of target and masker into opposing hemifields may result in the representation of the vowel being comparable to that in clean conditions in the hemisphere contralateral to the vowel, and help animals to compensate for the lack of cortical scene analysis that is critical for resolving co-located sound sources.</p></sec><sec id="S34"><title>Spatial release from energetic masking</title><p id="P91">The effects of release from energetic masking that we observed were small, relative to the benefit of removing masking entirely. This is not surprising given the limited effectiveness of spatial release from energetic masking relative to release from informational masking that have been widely reported (<xref ref-type="bibr" rid="R15">Brungart, 2001</xref>; <xref ref-type="bibr" rid="R39">Jones and Litovsky, 2011</xref>). It is likely that the benefit animals received from spatial separation of vowel and masker can be accounted for by the better-ear effect, in which spatial separation elevates the signal-to-noise ratio at one ear (while decreasing the SNR at the opposite ear), and listeners are then able to select information available from the better ear. Such effects may arise by the level of the inferior colliculus (IC)(<xref ref-type="bibr" rid="R42">Lane and Delgutte, 2005</xref>), which would, at least in part, explain how ferrets retained a benefit of spatial separation during cortical cooling. One would therefore predict that IC inactivation might result in more effective disruption, particularly when inactivating IC contralateral to the better ear. While cooling such deep-lying structures within the ferret brain would likely affect surrounding brain regions, the potential anatomical specificity of optogenetics makes such experiments feasible in the future.</p></sec><sec id="S35"><title>Auditory decision making</title><p id="P92">A notable feature of our results, along with the general pattern in the literature on hearing impairments following auditory cortical inactivation, is the preserved ability of animals to perform some sound-based tasks (e.g. vowel discrimination in clean conditions). These findings suggest that substantial redundancy in the auditory system allows alternative pathways to support task performance. The most obvious candidates for this are the ascending pathways from medial geniculate thalamus to secondary auditory cortex that bypass primary fields of the MEG (<xref ref-type="bibr" rid="R6">Bizley et al., 2015</xref>).</p><p id="P93">It is also possible that information at earlier stages of the auditory system, in this case about vowel identity (<xref ref-type="bibr" rid="R12">Blackburn and Sachs, 1990</xref>; <xref ref-type="bibr" rid="R62">Schebesch et al., 2010</xref>), can access brain areas that coordinate behavior and is sufficient for discriminations that have already been learnt (<xref ref-type="bibr" rid="R58">Ponvert and Jaramillo, 2019</xref>). Our use of reversible inactivation via cooling, which operates on the timescale of minutes / individual test sessions, suggests that any redundant pathways must come into use rapidly, integrate seamlessly with normal decision-making processes and occur with minimal need for learning.</p><p id="P94">Understanding how signals in auditory cortex are integrated into behavior is also critical for determining how deficits in spatial and non-spatial hearing arise, as the impairments observed in vowel discrimination in noise and sound localization may not have arisen through the same mechanisms. Cooling suppresses the activity of neurons, and so we might infer that the absence of spiking degrades cell assemblies that downstream neurons rely on for informed auditory decision making. Such downstream centers may be located in areas such as the prefrontal cortex (<xref ref-type="bibr" rid="R61">Romanski et al., 1999</xref>; <xref ref-type="bibr" rid="R40">Kaas and Hackett, 2000</xref>) or the striatum (<xref ref-type="bibr" rid="R75">Znamenskiy and Zador, 2013</xref>). To ascertain the underlying causes of the deficits we have observed, it will be necessary to combine auditory cortical inactivation with neural recording in such downstream areas, or to perform targeted manipulations of specific neural pathways.</p></sec><sec id="S36"><title>A role for areas showing mixed selectivity in perception?</title><p id="P95">We targeted inactivation to the area of auditory cortex in which neurons have previously shown mixed selectivity for sound location and vowel identity (<xref ref-type="bibr" rid="R11">Bizley et al., 2009</xref>; <xref ref-type="bibr" rid="R68">Walker et al., 2011</xref>; <xref ref-type="bibr" rid="R67">Town et al., 2018</xref>). Such mixed selectivity has been observed widely, including across the auditory system (<xref ref-type="bibr" rid="R18">Cohen et al., 2004</xref>; <xref ref-type="bibr" rid="R55">O’Connor et al., 2010</xref>; <xref ref-type="bibr" rid="R17">Chambers et al., 2014</xref>; <xref ref-type="bibr" rid="R25">Downer et al., 2017</xref>; <xref ref-type="bibr" rid="R72">Yi et al., 2019</xref>; <xref ref-type="bibr" rid="R3">Amaro et al., 2021</xref>) and may reflect a general process through which neural systems meet the demands of complex and flexible behaviors (<xref ref-type="bibr" rid="R60">Rigotti et al., 2013</xref>; <xref ref-type="bibr" rid="R38">Jazayeri and Afraz, 2017</xref>). Our results show that an area of the brain tuned to multiple sound features makes a contribution to multiple forms of hearing, and are consistent with broader predictions about the involvement of mixed selectivity in behavior (<xref ref-type="bibr" rid="R31">Fusi et al., 2016</xref>).</p><p id="P96">Mixed selectivity expands the range of dimensions across which groups of neurons can represent sounds, and so it may be possible to recover detailed information about diverse stimulus sets from population activity in auditory cortex. However, our ability to observe the use of such information in animal behavior is still limited, as most behavioral tasks are low-dimensional (i.e. they have only one or two independent variables along which subjects act)(<xref ref-type="bibr" rid="R32">Gao and Ganguli, 2015</xref>). By testing the effects of cortical inactivation on both spatial and non-spatial hearing in the same subjects, we have taken some of the first steps towards expanding the study of auditory behavior to higher dimensions that may be necessary to understand the role of mixed selectivity in everyday hearing.</p></sec></sec></body><back><ack id="S37"><title>Acknowledgements</title><p>We would like to thank Dr Tara Etherington for assistance with data collection during cortical cooling and Dr Joseph Sollini for assistance in developing the optogenetic approach. We are also grateful to Dr Erwin Alles for constructing the fiber optic implants used with F1801 and F1807 and Linda Ford for logistical support.</p><p>Data associated with sound localization of one subject (F1311) has been previously reported in (<xref ref-type="bibr" rid="R70">Wood et al., 2017</xref>)</p><p>This research was funded in whole, or in part, by the Wellcome Trust [a Wellcome Trust / Royal Society Sir Henry Dale Fellowship to JKB, Grant number 098418/Z/12/A], a Royal Society Dorothy Hodgkin Fellowship to JKB, the BBSRC (BB/H016813/1) and the European Research Council (SOUNDSCENE). For the purpose of open access, the author has applied a CC BY public copyright license to any Author Accepted Manuscript version arising from this submission.</p></ack><sec id="S38" sec-type="data-availability"><title>Data Availability</title><p id="P97">All code and data associated with the project is available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/stephentown42/cooling_auditory_cortex">https://github.com/stephentown42/cooling_auditory_cortex</ext-link></p></sec><fn-group><fn id="FN1" fn-type="conflict"><p id="P98"><bold>Competing Interests</bold></p><p id="P99">No competing interests declared.</p></fn></fn-group><ref-list><ref id="R1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adriani</surname><given-names>M</given-names></name><name><surname>Maeder</surname><given-names>P</given-names></name><name><surname>Meuli</surname><given-names>R</given-names></name><name><surname>Thiran</surname><given-names>AB</given-names></name><name><surname>Frischknecht</surname><given-names>R</given-names></name><name><surname>Villemure</surname><given-names>J-G</given-names></name><name><surname>Mayer</surname><given-names>J</given-names></name><name><surname>Annoni</surname><given-names>J-M</given-names></name><name><surname>Bogousslavsky</surname><given-names>J</given-names></name><name><surname>Fornari</surname><given-names>E</given-names></name><name><surname>Thiran</surname><given-names>J-P</given-names></name><etal/></person-group><article-title>Sound recognition and localization in man: specialized cortical networks and effects of acute circumscribed lesions</article-title><source>Exp Brain Res</source><year>2003</year><volume>153</volume><fpage>591</fpage><lpage>604</lpage></element-citation></ref><ref id="R2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahveninen</surname><given-names>J</given-names></name><name><surname>Huang</surname><given-names>S</given-names></name><name><surname>Nummenmaa</surname><given-names>A</given-names></name><name><surname>Belliveau</surname><given-names>JW</given-names></name><name><surname>Hung</surname><given-names>A-Y</given-names></name><name><surname>Jääskeläinen</surname><given-names>IP</given-names></name><name><surname>Rauschecker</surname><given-names>JP</given-names></name><name><surname>Rossi</surname><given-names>S</given-names></name><name><surname>Tiitinen</surname><given-names>H</given-names></name><name><surname>Raij</surname><given-names>T</given-names></name></person-group><article-title>Evidence for distinct human auditory cortex regions for sound location versus identity processing</article-title><source>Nat Commun</source><year>2013</year><volume>4</volume><fpage>1</fpage><lpage>8</lpage></element-citation></ref><ref id="R3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amaro</surname><given-names>D</given-names></name><name><surname>Ferreiro</surname><given-names>DN</given-names></name><name><surname>Grothe</surname><given-names>B</given-names></name><name><surname>Pecka</surname><given-names>M</given-names></name></person-group><article-title>Source identity shapes spatial preference in primary auditory cortex during active navigation</article-title><source>Curr Biol</source><year>2021</year><volume>31</volume><fpage>3875</fpage><lpage>3883</lpage><elocation-id>e5</elocation-id></element-citation></ref><ref id="R4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Atencio</surname><given-names>CA</given-names></name><name><surname>Sharpee</surname><given-names>TO</given-names></name><name><surname>Schreiner</surname><given-names>CE</given-names></name></person-group><article-title>Cooperative Nonlinearities in Auditory Cortical Neurons</article-title><source>Neuron</source><year>2008</year><volume>58</volume><fpage>956</fpage><lpage>966</lpage></element-citation></ref><ref id="R5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bates</surname><given-names>D</given-names></name><name><surname>Mächler</surname><given-names>M</given-names></name><name><surname>Bolker</surname><given-names>B</given-names></name><name><surname>Walker</surname><given-names>S</given-names></name></person-group><article-title>Fitting Linear Mixed-Effects Models Using <bold>lme4</bold></article-title><source>J Stat Softw</source><year>2015</year><volume>67</volume><date-in-citation>Accessed July 30, 2021</date-in-citation><comment>Available at: <ext-link ext-link-type="uri" xlink:href="http://www.jstatsoft.org/v67/i01/">http://www.jstatsoft.org/v67/i01/</ext-link></comment></element-citation></ref><ref id="R6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bizley</surname><given-names>JK</given-names></name><name><surname>Bajo</surname><given-names>VM</given-names></name><name><surname>Nodal</surname><given-names>FR</given-names></name><name><surname>King</surname><given-names>AJ</given-names></name></person-group><article-title>Cortico-Cortical Connectivity Within Ferret Auditory Cortex</article-title><source>J Comp Neurol</source><year>2015</year><volume>523</volume><fpage>2187</fpage><lpage>2210</lpage></element-citation></ref><ref id="R7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bizley</surname><given-names>JK</given-names></name><name><surname>Cohen</surname><given-names>YE</given-names></name></person-group><article-title>The what, where and how of auditory-object perception</article-title><source>Nat Rev Neurosci</source><year>2013</year><volume>14</volume><fpage>693</fpage><lpage>707</lpage></element-citation></ref><ref id="R8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bizley</surname><given-names>JK</given-names></name><name><surname>Nodal</surname><given-names>FR</given-names></name><name><surname>Nelken</surname><given-names>I</given-names></name><name><surname>King</surname><given-names>AJ</given-names></name></person-group><article-title>Functional organization of ferret auditory cortex</article-title><source>Cereb Cortex N Y N</source><year>2005</year><volume>15</volume><fpage>1637</fpage><lpage>1653</lpage><comment>1991</comment></element-citation></ref><ref id="R9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bizley</surname><given-names>JK</given-names></name><name><surname>Walker</surname><given-names>KMM</given-names></name><name><surname>King</surname><given-names>AJ</given-names></name><name><surname>Schnupp</surname><given-names>JWH</given-names></name></person-group><article-title>Spectral timbre perception in ferrets: discrimination of artificial vowels under different listening conditions</article-title><source>J Acoust Soc Am</source><year>2013a</year><volume>133</volume><fpage>365</fpage><lpage>376</lpage></element-citation></ref><ref id="R10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bizley</surname><given-names>JK</given-names></name><name><surname>Walker</surname><given-names>KMM</given-names></name><name><surname>Nodal</surname><given-names>FR</given-names></name><name><surname>King</surname><given-names>AJ</given-names></name><name><surname>Schnupp</surname><given-names>JWH</given-names></name></person-group><article-title>Auditory cortex represents both pitch judgments and the corresponding acoustic cues</article-title><source>Curr Biol CB</source><year>2013b</year><volume>23</volume><fpage>620</fpage><lpage>625</lpage></element-citation></ref><ref id="R11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bizley</surname><given-names>JK</given-names></name><name><surname>Walker</surname><given-names>KMM</given-names></name><name><surname>Silverman</surname><given-names>BW</given-names></name><name><surname>King</surname><given-names>AJ</given-names></name><name><surname>Schnupp</surname><given-names>JWH</given-names></name></person-group><article-title>Interdependent encoding of pitch, timbre, and spatial location in auditory cortex</article-title><source>J Neurosci Off J Soc Neurosci</source><year>2009</year><volume>29</volume><fpage>2064</fpage><lpage>2075</lpage></element-citation></ref><ref id="R12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blackburn</surname><given-names>CC</given-names></name><name><surname>Sachs</surname><given-names>MB</given-names></name></person-group><article-title>The representations of the steady-state vowel sound /e/ in the discharge patterns of cat anteroventral cochlear nucleus neurons</article-title><source>J Neurophysiol</source><year>1990</year><volume>63</volume><fpage>1191</fpage><lpage>1212</lpage></element-citation></ref><ref id="R13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bowers</surname><given-names>JS</given-names></name></person-group><article-title>Grandmother cells and localist representations: a review of current thinking</article-title><source>Lang Cogn Neurosci</source><year>2017</year><volume>32</volume><fpage>257</fpage><lpage>273</lpage></element-citation></ref><ref id="R14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brugge</surname><given-names>JF</given-names></name><name><surname>Reale</surname><given-names>RA</given-names></name><name><surname>Hind</surname><given-names>JE</given-names></name></person-group><article-title>The structure of spatial receptive fields of neurons in primary auditory cortex of the cat</article-title><source>J Neurosci Off J Soc Neurosci</source><year>1996</year><volume>16</volume><fpage>4420</fpage><lpage>4437</lpage></element-citation></ref><ref id="R15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brungart</surname><given-names>DS</given-names></name></person-group><article-title>Informational and energetic masking effects in the perception of two simultaneous talkers</article-title><source>J Acoust Soc Am</source><year>2001</year><volume>109</volume><fpage>1101</fpage><lpage>1109</lpage></element-citation></ref><ref id="R16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ceballo</surname><given-names>S</given-names></name><name><surname>Piwkowska</surname><given-names>Z</given-names></name><name><surname>Bourg</surname><given-names>J</given-names></name><name><surname>Daret</surname><given-names>A</given-names></name><name><surname>Bathellier</surname><given-names>B</given-names></name></person-group><article-title>Targeted Cortical Manipulation of Auditory Perception</article-title><source>Neuron</source><year>2019</year><volume>104</volume><fpage>1168</fpage><lpage>1179</lpage><elocation-id>e5</elocation-id></element-citation></ref><ref id="R17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chambers</surname><given-names>AR</given-names></name><name><surname>Hancock</surname><given-names>KE</given-names></name><name><surname>Sen</surname><given-names>K</given-names></name><name><surname>Polley</surname><given-names>DB</given-names></name></person-group><article-title>Online Stimulus Optimization Rapidly Reveals Multidimensional Selectivity in Auditory Cortical Neurons</article-title><source>J Neurosci</source><year>2014</year><volume>34</volume><fpage>8963</fpage><lpage>8975</lpage></element-citation></ref><ref id="R18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>YE</given-names></name><name><surname>Russ</surname><given-names>BE</given-names></name><name><surname>Gifford</surname><given-names>GW</given-names></name><name><surname>Kiringoda</surname><given-names>R</given-names></name><name><surname>MacLean</surname><given-names>KA</given-names></name></person-group><article-title>Selectivity for the Spatial and Nonspatial Attributes of Auditory Stimuli in the Ventrolateral Prefrontal Cortex</article-title><source>J Neurosci</source><year>2004</year><volume>24</volume><fpage>11307</fpage><lpage>11316</lpage></element-citation></ref><ref id="R19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coomber</surname><given-names>B</given-names></name><name><surname>Edwards</surname><given-names>D</given-names></name><name><surname>Jones</surname><given-names>SJ</given-names></name><name><surname>Shackleton</surname><given-names>TM</given-names></name><name><surname>Goldschmidt</surname><given-names>J</given-names></name><name><surname>Wallace</surname><given-names>MN</given-names></name><name><surname>Palmer</surname><given-names>AR</given-names></name></person-group><article-title>Cortical inactivation by cooling in small animals</article-title><source>Front Syst Neurosci</source><year>2011</year><volume>5</volume><fpage>53</fpage></element-citation></ref><ref id="R20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>David</surname><given-names>SV</given-names></name><name><surname>Fritz</surname><given-names>JB</given-names></name><name><surname>Shamma</surname><given-names>SA</given-names></name></person-group><article-title>Task reward structure shapes rapid receptive field plasticity in auditory cortex</article-title><source>Proc Natl Acad Sci U S A</source><year>2012</year><volume>109</volume><fpage>2144</fpage><lpage>2149</lpage></element-citation></ref><ref id="R21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dewson</surname><given-names>JH</given-names></name></person-group><article-title>Speech Sound Discrimination by Cats</article-title><source>Science</source><year>1964</year><volume>144</volume><fpage>555</fpage><lpage>556</lpage></element-citation></ref><ref id="R22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dewson</surname><given-names>JH</given-names></name><name><surname>Pribram</surname><given-names>KH</given-names></name><name><surname>Lynch</surname><given-names>JC</given-names></name></person-group><article-title>Effects of ablations of temporal cortex upon speech sound discrimination in the monkey</article-title><source>Exp Neurol</source><year>1969</year><volume>24</volume><fpage>579</fpage><lpage>591</lpage></element-citation></ref><ref id="R23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diamond</surname><given-names>IT</given-names></name><name><surname>Goldberg</surname><given-names>JM</given-names></name><name><surname>Neff</surname><given-names>WD</given-names></name></person-group><article-title>Tonal discrimination after ablation of auditory cortex</article-title><source>J Neurophysiol</source><year>1962</year><volume>25</volume><fpage>223</fpage><lpage>235</lpage></element-citation></ref><ref id="R24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dimidschstein</surname><given-names>J</given-names></name><etal/></person-group><article-title>A viral strategy for targeting and manipulating interneurons across vertebrate species</article-title><source>Nat Neurosci</source><year>2016</year><volume>19</volume><fpage>1743</fpage><lpage>1749</lpage></element-citation></ref><ref id="R25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Downer</surname><given-names>JD</given-names></name><name><surname>Rapone</surname><given-names>B</given-names></name><name><surname>Verhein</surname><given-names>J</given-names></name><name><surname>O’Connor</surname><given-names>KN</given-names></name><name><surname>Sutter</surname><given-names>ML</given-names></name></person-group><article-title>Feature-Selective Attention Adaptively Shifts Noise Correlations in Primary Auditory Cortex</article-title><source>J Neurosci Off J Soc Neurosci</source><year>2017</year><volume>37</volume><fpage>5378</fpage><lpage>5392</lpage></element-citation></ref><ref id="R26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dunn</surname><given-names>PK</given-names></name><name><surname>Smyth</surname><given-names>GK</given-names></name></person-group><article-title>Randomized Quantile Residuals</article-title><source>J Comput Graph Stat</source><year>1996</year><volume>5</volume><fpage>236</fpage><lpage>244</lpage></element-citation></ref><ref id="R27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Evarts</surname><given-names>EV</given-names></name></person-group><article-title>Effect of auditory cortex ablation on frequency discrimination in monkey</article-title><source>J Neurophysiol</source><year>1952</year><volume>15</volume><fpage>443</fpage><lpage>448</lpage></element-citation></ref><ref id="R28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flesch</surname><given-names>T</given-names></name><name><surname>Balaguer</surname><given-names>J</given-names></name><name><surname>Dekker</surname><given-names>R</given-names></name><name><surname>Nili</surname><given-names>H</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name></person-group><article-title>Comparing continual task learning in minds and machines</article-title><source>Proc Natl Acad Sci U S A</source><year>2018</year><volume>115</volume><elocation-id>E10313-E10322</elocation-id></element-citation></ref><ref id="R29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Földiák</surname><given-names>P</given-names></name></person-group><article-title>Neural Coding: Non-Local but Explicit and Conceptual</article-title><source>Curr Biol</source><year>2009</year><volume>19</volume><fpage>R904</fpage><lpage>R906</lpage></element-citation></ref><ref id="R30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fritz</surname><given-names>J</given-names></name><name><surname>Shamma</surname><given-names>S</given-names></name><name><surname>Elhilali</surname><given-names>M</given-names></name><name><surname>Klein</surname><given-names>D</given-names></name></person-group><article-title>Rapid task-related plasticity of spectrotemporal receptive fields in primary auditory cortex</article-title><source>Nat Neurosci</source><year>2003</year><volume>6</volume><fpage>1216</fpage><lpage>1223</lpage></element-citation></ref><ref id="R31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fusi</surname><given-names>S</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Rigotti</surname><given-names>M</given-names></name></person-group><article-title>Why neurons mix: high dimensionality for higher cognition</article-title><source>Curr Opin Neurobiol</source><year>2016</year><volume>37</volume><fpage>66</fpage><lpage>74</lpage></element-citation></ref><ref id="R32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname><given-names>P</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name></person-group><article-title>On simplicity and complexity in the brave new world of large-scale neuroscience</article-title><source>Curr Opin Neurobiol</source><year>2015</year><volume>32</volume><fpage>148</fpage><lpage>155</lpage></element-citation></ref><ref id="R33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldberg</surname><given-names>JM</given-names></name><name><surname>Neff</surname><given-names>WD</given-names></name></person-group><article-title>Frequency discrimination after bilateral ablation of cortical auditory areas</article-title><source>J Neurophysiol</source><year>1961</year><volume>24</volume><fpage>119</fpage><lpage>128</lpage></element-citation></ref><ref id="R34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harper</surname><given-names>NS</given-names></name><name><surname>Schoppe</surname><given-names>O</given-names></name><name><surname>Willmore</surname><given-names>BDB</given-names></name><name><surname>Cui</surname><given-names>Z</given-names></name><name><surname>Schnupp</surname><given-names>JWH</given-names></name><name><surname>King</surname><given-names>AJ</given-names></name></person-group><article-title>Network Receptive Field Modeling Reveals Extensive Integration and Multi-feature Selectivity in Auditory Cortical Neurons</article-title><source>PLOS Comput Biol</source><year>2016</year><volume>12</volume><elocation-id>e1005113</elocation-id></element-citation></ref><ref id="R35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harrington</surname><given-names>IA</given-names></name><name><surname>Heffner</surname><given-names>RS</given-names></name><name><surname>Heffner</surname><given-names>HE</given-names></name></person-group><article-title>An investigation of sensory deficits underlying the aphasia-like behavior of macaques with auditory cortex lesions</article-title><source>Neuroreport</source><year>2001</year><volume>12</volume><fpage>1217</fpage><lpage>1221</lpage></element-citation></ref><ref id="R36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heffner</surname><given-names>HE</given-names></name><name><surname>Heffner</surname><given-names>RS</given-names></name></person-group><article-title>Effect of unilateral and bilateral auditory cortex lesions on the discrimination of vocalizations by Japanese macaques</article-title><source>J Neurophysiol</source><year>1986</year><volume>56</volume><fpage>683</fpage><lpage>701</lpage></element-citation></ref><ref id="R37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jasper</surname><given-names>HH</given-names></name><name><surname>Shacter</surname><given-names>DG</given-names></name><name><surname>Montplaisir</surname><given-names>J</given-names></name></person-group><article-title>The effect of local cooling upon spontaneous and evoked electrical activity of cerebral cortex</article-title><source>Can J Physiol Pharmacol</source><year>1970</year><volume>48</volume><fpage>640</fpage><lpage>652</lpage></element-citation></ref><ref id="R38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jazayeri</surname><given-names>M</given-names></name><name><surname>Afraz</surname><given-names>A</given-names></name></person-group><article-title>Navigating the Neural Space in Search of the Neural Code</article-title><source>Neuron</source><year>2017</year><volume>93</volume><fpage>1003</fpage><lpage>1014</lpage></element-citation></ref><ref id="R39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>GL</given-names></name><name><surname>Litovsky</surname><given-names>RY</given-names></name></person-group><article-title>A cocktail party model of spatial release from masking by both noise and speech interferers</article-title><source>J Acoust Soc Am</source><year>2011</year><volume>130</volume><fpage>1463</fpage><lpage>1474</lpage></element-citation></ref><ref id="R40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaas</surname><given-names>JH</given-names></name><name><surname>Hackett</surname><given-names>TA</given-names></name></person-group><article-title>Subdivisions of auditory cortex and processing streams in primates</article-title><source>Proc Natl Acad Sci</source><year>2000</year><volume>97</volume><fpage>11793</fpage><lpage>11799</lpage></element-citation></ref><ref id="R41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kavanagh</surname><given-names>GL</given-names></name><name><surname>Kelly</surname><given-names>JB</given-names></name></person-group><article-title>Contribution of auditory cortex to sound localization by the ferret (Mustela putorius)</article-title><source>J Neurophysiol</source><year>1987</year><volume>57</volume><fpage>1746</fpage><lpage>1766</lpage></element-citation></ref><ref id="R42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lane</surname><given-names>CC</given-names></name><name><surname>Delgutte</surname><given-names>B</given-names></name></person-group><article-title>Neural Correlates and Mechanisms of Spatial Release From Masking: Single-Unit and Population Responses in the Inferior Colliculus</article-title><source>J Neurophysiol</source><year>2005</year><volume>94</volume><fpage>1180</fpage><lpage>1198</lpage></element-citation></ref><ref id="R43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>N</given-names></name><name><surname>Chen</surname><given-names>S</given-names></name><name><surname>Guo</surname><given-names>ZV</given-names></name><name><surname>Chen</surname><given-names>H</given-names></name><name><surname>Huo</surname><given-names>Y</given-names></name><name><surname>Inagaki</surname><given-names>HK</given-names></name><name><surname>Chen</surname><given-names>G</given-names></name><name><surname>Davis</surname><given-names>C</given-names></name><name><surname>Hansel</surname><given-names>D</given-names></name><name><surname>Guo</surname><given-names>C</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Huguenard</surname><given-names>J</given-names></name><name><surname>Marder</surname><given-names>E</given-names></name><name><surname>Petersen</surname><given-names>CC</given-names></name></person-group><article-title>Spatiotemporal constraints on optogenetic inactivation in cortical circuits</article-title><source>eLife</source><year>2019</year><volume>8</volume><comment>eds</comment><elocation-id>e48622</elocation-id></element-citation></ref><ref id="R44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lomber</surname><given-names>SG</given-names></name><name><surname>Malhotra</surname><given-names>S</given-names></name></person-group><article-title>Double dissociation of “what” and “where” processing in auditory cortex</article-title><source>Nat Neurosci</source><year>2008</year><volume>11</volume><fpage>609</fpage><lpage>616</lpage></element-citation></ref><ref id="R45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lomber</surname><given-names>SG</given-names></name><name><surname>Payne</surname><given-names>BR</given-names></name><name><surname>Horel</surname><given-names>JA</given-names></name></person-group><article-title>The cryoloop: an adaptable reversible cooling deactivation method for behavioral or electrophysiological assessment of neural function</article-title><source>J Neurosci Methods</source><year>1999</year><volume>86</volume><fpage>179</fpage><lpage>194</lpage></element-citation></ref><ref id="R46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Malhotra</surname><given-names>S</given-names></name><name><surname>Stecker</surname><given-names>GC</given-names></name><name><surname>Middlebrooks</surname><given-names>JC</given-names></name><name><surname>Lomber</surname><given-names>SG</given-names></name></person-group><article-title>Sound Localization Deficits During Reversible Deactivation of Primary Auditory Cortex and/or the Dorsal Zone</article-title><source>J Neurophysiol</source><year>2008</year><volume>99</volume><fpage>1628</fpage><lpage>1642</lpage></element-citation></ref><ref id="R47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maris</surname><given-names>E</given-names></name><name><surname>Oostenveld</surname><given-names>R</given-names></name></person-group><article-title>Nonparametric statistical testing of EEG- and MEG-data</article-title><source>J Neurosci Methods</source><year>2007</year><volume>164</volume><fpage>177</fpage><lpage>190</lpage></element-citation></ref><ref id="R48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Massopust</surname><given-names>LC</given-names></name><name><surname>Barnes</surname><given-names>HW</given-names></name><name><surname>Verdura</surname><given-names>J</given-names></name></person-group><article-title>Auditory frequency discrimination in cortically ablated monkeys</article-title><source>J Aud Res</source><year>1965</year><volume>5</volume><fpage>85</fpage><lpage>93</lpage></element-citation></ref><ref id="R49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mesgarani</surname><given-names>N</given-names></name><name><surname>Chang</surname><given-names>EF</given-names></name></person-group><article-title>Selective cortical representation of attended speaker in multi-talker speech perception</article-title><source>Nature</source><year>2012</year><volume>485</volume><pub-id pub-id-type="doi">10.1038/nature11020</pub-id></element-citation></ref><ref id="R50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Middlebrooks</surname><given-names>JC</given-names></name><name><surname>Onsan</surname><given-names>ZA</given-names></name></person-group><article-title>Stream segregation with high spatial acuity</article-title><source>J Acoust Soc Am</source><year>2012</year><volume>132</volume><fpage>3896</fpage><lpage>3911</lpage></element-citation></ref><ref id="R51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moore</surname><given-names>AK</given-names></name><name><surname>Wehr</surname><given-names>M</given-names></name></person-group><article-title>Parvalbumin-Expressing Inhibitory Interneurons in Auditory Cortex Are Well-Tuned for Frequency</article-title><source>J Neurosci</source><year>2013</year><volume>33</volume><fpage>13713</fpage><lpage>13723</lpage></element-citation></ref><ref id="R52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nakagawa</surname><given-names>S</given-names></name><name><surname>Schielzeth</surname><given-names>H</given-names></name></person-group><article-title>A general and simple method for obtaining R2 from generalized linear mixed-effects models</article-title><source>Methods Ecol Evol</source><year>2013</year><volume>4</volume><fpage>133</fpage><lpage>142</lpage></element-citation></ref><ref id="R53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassi</surname><given-names>JJ</given-names></name><name><surname>Callaway</surname><given-names>EM</given-names></name></person-group><article-title>Parallel Processing Strategies of the Primate Visual System</article-title><source>Nat Rev Neurosci</source><year>2009</year><volume>10</volume><fpage>360</fpage><lpage>372</lpage></element-citation></ref><ref id="R54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niell</surname><given-names>CM</given-names></name><name><surname>Stryker</surname><given-names>MP</given-names></name></person-group><article-title>Highly Selective Receptive Fields in Mouse Visual Cortex</article-title><source>J Neurosci</source><year>2008</year><volume>28</volume><fpage>7520</fpage><lpage>7536</lpage></element-citation></ref><ref id="R55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Connor</surname><given-names>K</given-names></name><name><surname>Yin</surname><given-names>P</given-names></name><name><surname>Petkov</surname><given-names>C</given-names></name><name><surname>Sutter</surname><given-names>M</given-names></name></person-group><article-title>Complex Spectral Interactions Encoded by Auditory Cortical Neurons: Relationship Between Bandwidth and Pattern</article-title><source>Front Syst Neurosci</source><year>2010</year><volume>4</volume><fpage>145</fpage></element-citation></ref><ref id="R56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ohl</surname><given-names>FW</given-names></name><name><surname>Wetzel</surname><given-names>W</given-names></name><name><surname>Wagner</surname><given-names>T</given-names></name><name><surname>Rech</surname><given-names>A</given-names></name><name><surname>Scheich</surname><given-names>H</given-names></name></person-group><article-title>Bilateral Ablation of Auditory Cortex in Mongolian Gerbil Affects Discrimination of Frequency Modulated Tones but not of Pure Tones</article-title><source>Learn Mem</source><year>1999</year><volume>6</volume><fpage>347</fpage><lpage>362</lpage></element-citation></ref><ref id="R57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Owen</surname><given-names>SF</given-names></name><name><surname>Liu</surname><given-names>MH</given-names></name><name><surname>Kreitzer</surname><given-names>AC</given-names></name></person-group><article-title>Thermal constraints on in vivo optogenetic manipulations</article-title><source>Nat Neurosci</source><year>2019</year><volume>22</volume><fpage>1061</fpage><lpage>1065</lpage></element-citation></ref><ref id="R58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ponvert</surname><given-names>ND</given-names></name><name><surname>Jaramillo</surname><given-names>S</given-names></name></person-group><article-title>Auditory Thalamostriatal and Corticostriatal Pathways Convey Complementary Information about Sound Features</article-title><source>J Neurosci</source><year>2019</year><volume>39</volume><fpage>271</fpage><lpage>280</lpage></element-citation></ref><ref id="R59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rauschecker</surname><given-names>JP</given-names></name><name><surname>Scott</surname><given-names>SK</given-names></name></person-group><article-title>Maps and streams in the auditory cortex: nonhuman primates illuminate human speech processing</article-title><source>Nat Neurosci</source><year>2009</year><volume>12</volume><fpage>718</fpage><lpage>724</lpage></element-citation></ref><ref id="R60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rigotti</surname><given-names>M</given-names></name><name><surname>Barak</surname><given-names>O</given-names></name><name><surname>Warden</surname><given-names>MR</given-names></name><name><surname>Wang</surname><given-names>X-J</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name></person-group><article-title>The importance of mixed selectivity in complex cognitive tasks</article-title><source>Nature</source><year>2013</year><volume>497</volume><fpage>585</fpage><lpage>590</lpage></element-citation></ref><ref id="R61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Romanski</surname><given-names>LM</given-names></name><name><surname>Tian</surname><given-names>B</given-names></name><name><surname>Fritz</surname><given-names>J</given-names></name><name><surname>Mishkin</surname><given-names>M</given-names></name><name><surname>Goldman-Rakic</surname><given-names>PS</given-names></name><name><surname>Rauschecker</surname><given-names>JP</given-names></name></person-group><article-title>Dual streams of auditory afferents target multiple domains in the primate prefrontal cortex</article-title><source>Nat Neurosci</source><year>1999</year><volume>2</volume><fpage>1131</fpage><lpage>1136</lpage></element-citation></ref><ref id="R62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schebesch</surname><given-names>G</given-names></name><name><surname>Lingner</surname><given-names>A</given-names></name><name><surname>Firzlaff</surname><given-names>U</given-names></name><name><surname>Wiegrebe</surname><given-names>L</given-names></name><name><surname>Grothe</surname><given-names>B</given-names></name></person-group><article-title>Perception and neural representation of size-variant human vowels in the Mongolian gerbil (Meriones unguiculatus)</article-title><source>Hear Res</source><year>2010</year><volume>261</volume><fpage>1</fpage><lpage>8</lpage></element-citation></ref><ref id="R63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Slonina</surname><given-names>ZA</given-names></name><name><surname>Poole</surname><given-names>KC</given-names></name><name><surname>Bizley</surname><given-names>JK</given-names></name></person-group><article-title>What can we learn from inactivation studies? Lessons from auditory cortex</article-title><source>Trends Neurosci</source><year>2022</year><volume>45</volume><fpage>64</fpage><lpage>77</lpage></element-citation></ref><ref id="R64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>AL</given-names></name><name><surname>Parsons</surname><given-names>CH</given-names></name><name><surname>Lanyon</surname><given-names>RG</given-names></name><name><surname>Bizley</surname><given-names>JK</given-names></name><name><surname>Akerman</surname><given-names>CJ</given-names></name><name><surname>Baker</surname><given-names>GE</given-names></name><name><surname>Dempster</surname><given-names>AC</given-names></name><name><surname>Thompson</surname><given-names>ID</given-names></name><name><surname>King</surname><given-names>AJ</given-names></name></person-group><article-title>An investigation of the role of auditory cortex in sound localization using muscimol-releasing Elvax</article-title><source>Eur J Neurosci</source><year>2004</year><volume>19</volume><fpage>3059</fpage><lpage>3072</lpage></element-citation></ref><ref id="R65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Town</surname><given-names>SM</given-names></name><name><surname>Atilgan</surname><given-names>H</given-names></name><name><surname>Wood</surname><given-names>KC</given-names></name><name><surname>Bizley</surname><given-names>JK</given-names></name></person-group><article-title>The role of spectral cues in timbre discrimination by ferrets and humans</article-title><source>J Acoust Soc Am</source><year>2015</year><volume>137</volume><fpage>2870</fpage><lpage>2883</lpage></element-citation></ref><ref id="R66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Town</surname><given-names>SM</given-names></name><name><surname>Brimijoin</surname><given-names>WO</given-names></name><name><surname>Bizley</surname><given-names>JK</given-names></name></person-group><article-title>Egocentric and allocentric representations in auditory cortex</article-title><source>PLOS Biol</source><year>2017</year><volume>15</volume><elocation-id>e2001878</elocation-id></element-citation></ref><ref id="R67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Town</surname><given-names>SM</given-names></name><name><surname>Wood</surname><given-names>KC</given-names></name><name><surname>Bizley</surname><given-names>JK</given-names></name></person-group><article-title>Sound identity is represented robustly in auditory cortex during perceptual constancy</article-title><source>Nat Commun</source><year>2018</year><volume>9</volume><fpage>1</fpage><lpage>15</lpage></element-citation></ref><ref id="R68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walker</surname><given-names>KMM</given-names></name><name><surname>Bizley</surname><given-names>JK</given-names></name><name><surname>King</surname><given-names>AJ</given-names></name><name><surname>Schnupp</surname><given-names>JWH</given-names></name></person-group><article-title>Multiplexed and robust representations of sound features in auditory cortex</article-title><source>J Neurosci Off J Soc Neurosci</source><year>2011</year><volume>31</volume><fpage>14565</fpage><lpage>14576</lpage></element-citation></ref><ref id="R69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>DE</given-names></name><name><surname>Scholl</surname><given-names>B</given-names></name><name><surname>Fitzpatrick</surname><given-names>D</given-names></name></person-group><article-title>Differential tuning of excitation and inhibition shapes direction selectivity in ferret visual cortex</article-title><source>Nature</source><year>2018</year><volume>560</volume><fpage>97</fpage><lpage>101</lpage></element-citation></ref><ref id="R70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wood</surname><given-names>KC</given-names></name><name><surname>Town</surname><given-names>SM</given-names></name><name><surname>Atilgan</surname><given-names>H</given-names></name><name><surname>Jones</surname><given-names>GP</given-names></name><name><surname>Bizley</surname><given-names>JK</given-names></name></person-group><article-title>Acute Inactivation of Primary Auditory Cortex Causes a Sound Localisation Deficit in Ferrets</article-title><source>PLOS ONE</source><year>2017</year><volume>12</volume><elocation-id>e0170264</elocation-id></element-citation></ref><ref id="R71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wood</surname><given-names>KC</given-names></name><name><surname>Town</surname><given-names>SM</given-names></name><name><surname>Bizley</surname><given-names>JK</given-names></name></person-group><article-title>Neurons in primary auditory cortex represent sound source location in a cue-invariant manner</article-title><source>Nat Commun</source><year>2019</year><volume>10</volume><fpage>1</fpage><lpage>15</lpage></element-citation></ref><ref id="R72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yi</surname><given-names>HG</given-names></name><name><surname>Leonard</surname><given-names>MK</given-names></name><name><surname>Chang</surname><given-names>EF</given-names></name></person-group><article-title>The Encoding of Speech Sounds in the Superior Temporal Gyrus</article-title><source>Neuron</source><year>2019</year><volume>102</volume><fpage>1096</fpage><lpage>1110</lpage></element-citation></ref><ref id="R73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Nakamoto</surname><given-names>KT</given-names></name><name><surname>Kitzes</surname><given-names>LM</given-names></name></person-group><article-title>Binaural Interaction Revisited in the Cat Primary Auditory Cortex</article-title><source>J Neurophysiol</source><year>2004</year><volume>91</volume><fpage>101</fpage><lpage>117</lpage></element-citation></ref><ref id="R74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>B</given-names></name><name><surname>Green</surname><given-names>DM</given-names></name><name><surname>Middlebrooks</surname><given-names>JC</given-names></name></person-group><article-title>Characterization of external ear impulse responses using Golay codes</article-title><source>J Acoust Soc Am</source><year>1992</year><volume>92</volume><fpage>1169</fpage><lpage>1171</lpage></element-citation></ref><ref id="R75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Znamenskiy</surname><given-names>P</given-names></name><name><surname>Zador</surname><given-names>AM</given-names></name></person-group><article-title>Corticostriatal neurons in auditory cortex drive decisions during auditory discrimination</article-title><source>Nature</source><year>2013</year><volume>497</volume><fpage>482</fpage><lpage>485</lpage></element-citation></ref></ref-list></back><floats-group><boxed-text id="BX1" position="float" orientation="portrait"><caption><title>Significance Statement</title></caption><p>Neurons in primary auditory cortex are often sensitive to the location and identity of sounds. Here we inactivated auditory cortex during spatial and non- spatial listening tasks using cooling, or optogenetics. Auditory cortical inactivation impaired multiple behaviors, demonstrating a role in both the analysis of sound location and identity and confirming a functional contribution of mixed selectivity observed in neural activity. Parallel optogenetic experiments in two additional untrained ferrets linked behavior to physiology by demonstrating that expression of Channelrhodopsin 2 permitted rapid light-driven suppression of auditory cortical activity recorded under anesthesia.</p></boxed-text><fig id="F1" position="float"><label>Figure 1</label><caption><title>Behavioral task designs.</title><p><bold>(A)</bold> Vowel discrimination in noise and in clean conditions. Both vowel and noise were presented from speakers to the left (S<sub>L</sub>) and right (S<sub>R</sub>) of the head as the animal held at a center lick port (C). The animal then reported vowel identity by visiting either left (L) or right (R) response ports. Spectrograms show vowels (e.g. two 250 ms tokens of /u/, separated by 250 ms interval) alone or with additive broadband noise. Vowel identity was always the same for both tokens, and the animal was required to respond left or right based on that identity (i.e. there was no requirement to compare the two tokens). <bold>(B)</bold> Vowel discrimination task when vowels were presented from a single speaker in clean conditions, or with noise from the same speaker (colocalized) or the alternative speaker (spatially separated). Spectrograms and behavioral task arena as shown in A. <bold>(C)</bold> Sound localization task in which ferrets reported the location of broadband noise from one of several speakers in frontal space by approaching a water spout located at each speaker.</p></caption><graphic xlink:href="EMS151736-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Cortical inactivation in behavioral tasks.</title><p><bold>(A)</bold> Anatomical location of ferret auditory cortex and positions of cooling loops (blue) implanted in F1311 &amp; F1509 and viral injection in F1706 over the Middle Ectosylvian Gyrus. (Acronyms, A1: Primary auditory cortex, AAF: Anterior Auditory Field, AEG: Anterior Ectosylvian Gyrus, AVF: Anterior Ventral Field, ADF: Anterior Dorsal Field, PEG: Posterior Ectosylvian Gyrus, PPF: Posterior Pseudosylvian Field, PSF: Posterior Suprasylvian Field, VP: Ventral Posterior Auditory Field). <bold>(B)</bold> Distribution of cortical temperatures during bilateral cooling (all tasks) and unilateral cooling of left or right auditory cortex (sound localization only). Scatterplots show temperatures on individual trials measured at the base of each cooling loop, where contact was made with the cortical surface.</p></caption><graphic xlink:href="EMS151736-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Targeting of optogenetic inactivation and neural responses.</title><p>(<bold>A</bold>) Imaging viral expression in ferret auditory cortex. Top: Widefield imaging of coronal sections through the ectosylvian gyrus with the cell bodies labeled with DAPI (blue) and ChR2 labeled with mCherry (red). Middle / Bottom: Confocal imaging of the injection site showing colocalization of cell bodies and mCherry expression (outlined). (<bold>B</bold>) Experimental schematic showing stimulus and light delivery protocols. (<bold>C</bold>) Configurations of probe and optic fiber over injection sites within MEG in each ferret (F1807 and F1801). (<bold>D</bold>) Peri-stimulus time histogram and raster plots showing responses of four example units recorded from auditory cortex with and without light delivery in a single laser pulse (columns 1-3) and a 10 Hz laser pulse (column 4).</p></caption><graphic xlink:href="EMS151736-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Optogenetic inactivation of auditory cortical activity.</title><p>(<bold>A-B</bold>) Scatterplots of firing rate with and without laser and (<bold>C-D</bold>) cumulative histograms of change in firing rate with laser light delivery. Plots show firing rate measured during (<bold>A, C</bold>) or before (<bold>B, D</bold>) sound presentation for each unit, coloured by cluster and filled if the change in firing rate between laser conditions was significant (Wilcoxon signed-rank, p &lt; 0.05). Green lines / labels on cumulative histograms mark the proportion of units (across all clusters) in which laser presentation suppressed spiking activity.</p></caption><graphic xlink:href="EMS151736-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>Depth-dependent suppression.</title><p>(<bold>A</bold>) Schematic of probe displaying approximate anatomical locations in reference to surface calculated by the most superficial depth at which spiking was observed. (<bold>B</bold>) The location of auditory evoked units (n = 72) as a function of cortical depth from surface with boxplot showing quartiles with whiskers showing the 95th percentiles. (<bold>C</bold>) Change in firing rate with light delivery as a function of cortical depth from surface. Inset shows magnified gray region with dotted line showing predictions from fitted Poisson mixed-model. (<bold>D</bold>) Latency of significant change in firing rate with light delivery as a function of depth. Marker color and shape in C-D indicates cluster grouping identified via K-means clustering, as in <xref ref-type="fig" rid="F4">Figure 4</xref>. (<bold>E</bold>) Average spike shapes of well-isolated single-units of cluster 1 (blue, n = 80 SUs) and cluster 2 (red, n = 20 SUs) recorded within 1.598 mm of the surface (error: std.). (<bold>F</bold>) Difference in trough to peak latency of each mean waveform (cluster 1 - cluster 2) for observed data (red dashed line, difference = 0.0648 ms) or when randomly shuffling clusters labels (histogram, n = 1000 iterations) during permutation testing (97.5th percentile, black line).</p></caption><graphic xlink:href="EMS151736-f005"/></fig><fig id="F6" position="float"><label>Figure 6</label><caption><title>Cortical inactivation impairs vowel discrimination in noise, but not clean conditions.</title><p>(<bold>A</bold>) Performance discriminating vowels in noise (n = 3 ferrets) or clean conditions (n = 2 ferrets, F1706 not tested) during cooling or optogenetic inactivation and in control testing. Scatter plots show performance across all SNRs or sound levels for each bootstrap (n = 1000 iterations), with means shown as markers. (<bold>B</bold>) Model fit to data (lines) from each ferret discriminating vowels in clean and noise conditions, with cooling (F1311 and F1509) or optogenetics (F1706, noise only). Scatter plots show observed data, with marker size showing trial numbers.</p></caption><graphic xlink:href="EMS151736-f006"/></fig><fig id="F7" position="float"><label>Figure 7</label><caption><title>Spatial separation improves vowel discrimination in noise.</title><p>(<bold>A</bold>) Performance of each ferret (n = 6) in spatially separated or co-located noise in control conditions across SNR. Scatter plots indicate performance across bootstrap resampling (n = 1000 iterations) with mean performance shown by markers. (<bold>B</bold>) Control performance discriminating vowels in clean conditions (i.e. without noise) vs. co-located noise. (<bold>C</bold>) Performance of two ferrets during cooling, when discriminating vowels in spatially separated or co-located noise. (<bold>D</bold>) Performance during cooling when discriminating vowels in clean conditions vs. co-located noise. (<bold>E</bold>) Mixed-effect model fit (lines) and observed performance (markers) vs. SNR discriminating vowels in co-located and spatially separated noise.</p></caption><graphic xlink:href="EMS151736-f007"/></fig><fig id="F8" position="float"><label>Figure 8</label><caption><title>Effects of bilateral cooling on sound localization.</title><p>(<bold>A</bold>) Performance of ferrets (n=2) tested with bilateral cooling during sound localization. Scatter plots show performance on each bootstrap sample (n = 1000) with means indicated by markers. (<bold>B</bold>) Confusion matrices showing behavioral responses for each speaker and response location in control conditions (unfilled black: F1311 = 1690 trials, F1509 = 1220 trials), and during bilateral cooling (blue: F1311 = 294 trials, F1509 = 115 trials). (<bold>C</bold>) Performance as a function of sound location predicted by mixed-effects logistic regression (lines) and observed during behavior (markers) in cooled and control conditions.</p></caption><graphic xlink:href="EMS151736-f008"/></fig><fig id="F9" position="float"><label>Figure 9</label><caption><title>Effects of unilateral cooling on sound localization.</title><p>(<bold>A</bold>) Performance of ferrets (n=2) localizing sounds in the left and right side of space during unilateral cooling of left or right auditory cortex, control conditions and bilateral cooling. Scatter plots show performance on each bootstrap sample (n = 1000) with means indicated by markers. (<bold>B</bold>) Bubble plots showing the joint distribution of behavioral responses for each speaker and response location during unilateral cooling (filled blue/yellow) and control conditions (unfilled black) for F1311 (top row) and F1509 (bottom row). Sample sizes in control conditions (F1311 = 1690 trials, F1509 = 1220 trials), and during cooling left (F1311 = 476 trials, F1509 = 97 trials) or right auditory cortex (F1311 = 536 trials, F1509 = 294 trials). (<bold>C</bold>) Observed behavior (markers) and model prediction (lines) of performance localizing sounds in left and right sides of space during unilateral cooling.</p></caption><graphic xlink:href="EMS151736-f009"/></fig><table-wrap id="T1" orientation="portrait" position="float"><label>Table 1</label><caption><title>Metadata for each subject.</title><p>Vowel discrimination was tested in clean conditions, with co-located (CL) noise, or spatially separated (SS) noise. Cooling loops implanted in F1216 (asterisk) were persistently blocked and could not be used reliably to achieve bilateral cooling (1 of 14 attempts). Animals implanted with microelectrodes provided single unit recordings for another study (<xref ref-type="bibr" rid="R67">Town et al., 2018</xref>).</p></caption><table frame="void" rules="none"><thead><tr style="background-color: #D9D9D9;"><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="center" valign="bottom" colspan="3">Vowel Discrimination</th><th align="center" valign="bottom" rowspan="2">Sound Localization</th></tr><tr style="background-color: #D9D9D9;"><th align="left" valign="bottom">Ferret</th><th align="left" valign="bottom">Implant Type</th><th align="left" valign="bottom">Clean</th><th align="left" valign="bottom">CL Noise</th><th align="left" valign="bottom">SS noise</th></tr></thead><tbody><tr style="background-color: #EFEFEF;"><td align="left" valign="top" style="color: #0B5394;"><bold>F1311</bold></td><td align="center" valign="middle" rowspan="2" style="color: #0B5394;">Cooling Loops</td><td align="center" valign="top" style="color: #0B5394;"><bold><italic>Yes</italic></bold></td><td align="center" valign="top" style="color: #0B5394;"><bold><italic>Yes</italic></bold></td><td align="center" valign="top" style="color: #0B5394;"><bold><italic>Yes</italic></bold></td><td align="center" valign="top" style="color: #0B5394;"><bold><italic>Yes</italic></bold></td></tr><tr style="background-color: #EFEFEF;"><td align="left" valign="top" style="color: #0B5394;"><bold>F1509</bold></td><td align="center" valign="top" style="color: #0B5394;"><bold><italic>Yes</italic></bold></td><td align="center" valign="top" style="color: #0B5394;"><bold><italic>Yes</italic></bold></td><td align="center" valign="top" style="color: #0B5394;"><bold><italic>Yes</italic></bold></td><td align="center" valign="top" style="color: #0B5394;"><bold><italic>Yes</italic></bold></td></tr><tr style="background-color: #EFEFEF;"><td align="left" valign="top" style="color: #434343;"><bold>F1201</bold></td><td align="center" valign="middle" rowspan="3" style="color: #434343;">Microelectrode Arrays</td><td align="center" valign="top" style="color: #434343;"><italic>No</italic></td><td align="center" valign="top" style="color: #434343;"><italic>No</italic></td><td align="center" valign="top" style="color: #434343;"><italic>Control only</italic></td><td align="center" valign="top" style="color: #434343;"><italic>No</italic></td></tr><tr style="background-color: #EFEFEF;"><td align="left" valign="top" style="color: #434343;"><bold>F1203</bold></td><td align="center" valign="top" style="color: #434343;"><italic>No</italic></td><td align="center" valign="top" style="color: #434343;"><italic>No</italic></td><td align="center" valign="top" style="color: #434343;"><italic>Control only</italic></td><td align="center" valign="top" style="color: #434343;"><italic>No</italic></td></tr><tr style="background-color: #EFEFEF;"><td align="left" valign="top" style="color: #434343;"><bold>F1217</bold></td><td align="center" valign="top" style="color: #434343;"><italic>No</italic></td><td align="center" valign="top" style="color: #434343;"><italic>No</italic></td><td align="center" valign="top" style="color: #434343;"><italic>Control only</italic></td><td align="center" valign="top" style="color: #434343;"><italic>No</italic></td></tr><tr style="background-color: #EFEFEF;"><td align="left" valign="top" style="color: #434343;"><bold>F1216</bold></td><td align="center" valign="top" style="color: #434343;"><italic>Cooling Loops*</italic></td><td align="center" valign="top" style="color: #434343;"><italic>No</italic></td><td align="center" valign="top" style="color: #434343;"><italic>No</italic></td><td align="center" valign="top" style="color: #434343;"><italic>Control only</italic></td><td align="center" valign="top" style="color: #434343;"><italic>No</italic></td></tr><tr style="background-color: #EFEFEF;"><td align="left" valign="top" style="color: #A5290C;"><bold>F1706</bold></td><td align="center" valign="top" style="color: #A5290C;">Optic Fibers</td><td align="center" valign="top" style="color: #A5290C;"><italic>No</italic></td><td align="center" valign="top" style="color: #A5290C;"><bold><italic>Yes</italic></bold></td><td align="center" valign="top" style="color: #A5290C;"><italic>No</italic></td><td align="center" valign="top" style="color: #A5290C;"><italic>No</italic></td></tr><tr style="background-color: #EFEFEF;"><td align="left" valign="top" style="color: #783F04;"><bold>F1801</bold></td><td align="center" valign="middle" rowspan="2" style="color: #783F04;">Anesthetized Recording</td><td align="center" valign="top" style="color: #783F04;"><italic>No</italic></td><td align="center" valign="top" style="color: #783F04;"><italic>No</italic></td><td align="center" valign="top" style="color: #783F04;"><italic>No</italic></td><td align="center" valign="top" style="color: #783F04;"><italic>No</italic></td></tr><tr style="background-color: #EFEFEF;"><td align="left" valign="top" style="color: #783F04;"><bold>F1807</bold></td><td align="center" valign="top" style="color: #783F04;"><italic>No</italic></td><td align="center" valign="top" style="color: #783F04;"><italic>No</italic></td><td align="center" valign="top" style="color: #783F04;"><italic>No</italic></td><td align="center" valign="top" style="color: #783F04;"><italic>No</italic></td></tr><tr style="background-color: #EFEFEF;"><td align="left" valign="top" style="color: #783F04;"><bold>F1814</bold></td><td align="center" valign="top" style="color: #783F04;">Histology</td><td align="center" valign="top" style="color: #783F04;"><italic>No</italic></td><td align="center" valign="top" style="color: #783F04;"><italic>No</italic></td><td align="center" valign="top" style="color: #783F04;"><italic>No</italic></td><td align="center" valign="top" style="color: #783F04;"><italic>No</italic></td></tr></tbody></table></table-wrap><table-wrap id="T2" orientation="portrait" position="float"><label>Table 2</label><caption><title>Proportion of single and multi-units in each cluster that showed a significant change in firing rate with laser light delivery in 50 to 150 ms window after laser onset (Wilcoxon signed rank test, p &lt; 0.05).</title></caption><table frame="void" rules="none"><thead><tr><th align="left" valign="top"/><th align="center" valign="top" style="background-color: #D9D9D9;">Single Unit</th><th align="center" valign="top" style="background-color: #D9D9D9;">Multi-unit</th><th align="center" valign="top" style="background-color: #D9D9D9;">Total</th></tr></thead><tbody><tr style="background-color: #EFEFEF;"><td align="center" valign="top" style="color: #6FB0CD;"><bold>Cluster 1</bold></td><td align="center" valign="top" style="color: #6FB0CD;">58 / 103 (56.3%)</td><td align="center" valign="top" style="color: #6FB0CD;">106 / 169 (62.7%)</td><td align="center" valign="top" style="color: #6FB0CD;">164 / 272 (60.3%)</td></tr><tr style="background-color: #EFEFEF;"><td align="center" valign="top" style="color: #E07E6B;"><bold>Cluster 2</bold></td><td align="center" valign="top" style="color: #E07E6B;">16 / 71 (22.5%)</td><td align="center" valign="top" style="color: #E07E6B;">34 / 122 (27.9%)</td><td align="center" valign="top" style="color: #E07E6B;">50 / 193 (25.9%)</td></tr><tr style="background-color: #EFEFEF;"><td align="center" valign="top" style="color: #434343;"><bold>Total</bold></td><td align="center" valign="top" style="color: #434343;">74 / 174 (42.5%)</td><td align="center" valign="top" style="color: #434343;">140 / 291 (48.1%)</td><td align="center" valign="top" style="color: #434343;">214 / 465 (46.0%)</td></tr></tbody></table></table-wrap><table-wrap id="T3" orientation="portrait" position="float"><label>Table 3</label><caption><p>Model output for mixed-effect model logistic regression (n = 3 ferrets) showing coefficient estimates and standard error for fixed effects. Sample sizes: F1311 = 1914 trials, F1509 = 603 trials, F1706 = 352 trials. Model fit: Marginal R<sup>2</sup> = 0.076, Conditional R<sup>2</sup> = 0.090.</p></caption><table frame="box" rules="all"><thead><tr style="background-color: #980000; color:#FFFFFF;"><th align="left" valign="top">Fixed Effects</th><th align="center" valign="top">Estimate</th><th align="center" valign="top">Std. Error</th><th align="center" valign="top">Z</th><th align="center" valign="top">P(&gt; z)</th></tr></thead><tbody><tr style="background-color: #D9D9D9;"><td align="left" valign="top">Intercept</td><td align="center" valign="top">1.473</td><td align="center" valign="top">0.266</td><td align="center" valign="top">5.538</td><td align="center" valign="top"><bold>&lt; 0.001</bold></td></tr><tr><td align="left" valign="top">Treatment</td><td align="center" valign="top">0.151</td><td align="center" valign="top">0.170</td><td align="center" valign="top">0.888</td><td align="center" valign="top">0.374</td></tr><tr style="background-color: #D9D9D9;"><td align="left" valign="top"><bold>Noise condition</bold></td><td align="center" valign="top">-0.951</td><td align="center" valign="top">0.263</td><td align="center" valign="top">-3.614</td><td align="center" valign="top"><bold>&lt; 0.001</bold></td></tr><tr><td align="left" valign="top">Vowel sound level</td><td align="center" valign="top">0.112</td><td align="center" valign="top">0.325</td><td align="center" valign="top">0.344</td><td align="center" valign="top">0.730</td></tr><tr style="background-color: #D9D9D9;"><td align="left" valign="top">Center Reward</td><td align="center" valign="top">-0.080</td><td align="center" valign="top">0.104</td><td align="center" valign="top">-0.766</td><td align="center" valign="top">0.443</td></tr><tr><td align="left" valign="top"><bold>Treatment * Noise</bold></td><td align="center" valign="top">-0.603</td><td align="center" valign="top">0.199</td><td align="center" valign="top">-3.029</td><td align="center" valign="top"><bold>0.002</bold></td></tr><tr style="background-color: #D9D9D9;"><td align="left" valign="top"><bold>Noise * Level</bold></td><td align="center" valign="top">0.612</td><td align="center" valign="top">0.344</td><td align="center" valign="top">1.78</td><td align="center" valign="top">0.075</td></tr></tbody></table></table-wrap><table-wrap id="T4" orientation="portrait" position="float"><label>Table 4</label><caption><p>Coefficients for mixed effects logistic regression model comparing vowel discrimination in co-located or spatially separated noise, with cortical cooling (2 ferrets) and in control conditions (6 ferrets). Trial counts: F1201= 3112 trials, F1203 = 2501 trials, F1216 = 2821 trials, F1217 = 2335 trials, F1311 = 2744 trials, F1509 = 1430 trials. Model fit: marginal R<sup>2</sup> = 0.022, conditional R<sup>2</sup> = 0.029.</p></caption><table frame="box" rules="all"><thead><tr style="background-color: #E69138; color: #FFFFFF;"><th align="left" valign="top">Fixed Effects</th><th align="center" valign="top">Estimate</th><th align="center" valign="top">Std. Error</th><th align="center" valign="top">Z</th><th align="center" valign="top">P(&gt; z)</th></tr></thead><tbody><tr style="background-color: #D9D9D9;"><td align="left" valign="top">Intercept</td><td align="center" valign="top">0.173</td><td align="center" valign="top">0.087</td><td align="center" valign="top">1.98</td><td align="center" valign="top">0.047</td></tr><tr><td align="left" valign="top">Noise separation</td><td align="center" valign="top">0.114</td><td align="center" valign="top">0.044</td><td align="center" valign="top">2.62</td><td align="center" valign="top"><bold>0.009</bold></td></tr><tr style="background-color: #D9D9D9;"><td align="left" valign="top">Cooling</td><td align="center" valign="top">-0.322</td><td align="center" valign="top">0.126</td><td align="center" valign="top">-2.55</td><td align="center" valign="top"><bold>0.011</bold></td></tr><tr><td align="left" valign="top">Vowel sound level</td><td align="center" valign="top">0.740</td><td align="center" valign="top">0.078</td><td align="center" valign="top">9.46</td><td align="center" valign="top"><bold>&lt; 0.001</bold></td></tr><tr style="background-color: #D9D9D9;"><td align="left" valign="top">Vowel Location</td><td align="center" valign="top">-0.031</td><td align="center" valign="top">0.042</td><td align="center" valign="top">-0.747</td><td align="center" valign="top">0.455</td></tr><tr><td align="left" valign="top">Cooling * Separation</td><td align="center" valign="top">0.260</td><td align="center" valign="top">0.167</td><td align="center" valign="top">1.55</td><td align="center" valign="top">0.120</td></tr></tbody></table></table-wrap><table-wrap id="T5" orientation="portrait" position="float"><label>Table 5</label><caption><title>Model results for comparison of performance localizing sounds during cooling and control conditions (n = 2 ferrets). Sample sizes, control conditions: F1311 = 1690 trials, F1509 = 1220 trials, bilateral cooling: F1311 = 294 trials, F1509 = 115 trials. Model fit: marginal R<sup>2</sup> = 0.039, conditional R<sup>2</sup> = 0.120.</title></caption><table frame="box" rules="all"><thead><tr style="background-color: #1B8583; color: #FFFFFF;"><th align="left" valign="top">Fixed Effects</th><th align="center" valign="top">Estimate</th><th align="center" valign="top">Std. Error</th><th align="center" valign="top">Z</th><th align="center" valign="top">P(&gt; z)</th></tr></thead><tbody><tr style="background-color: #D9D9D9;"><td align="left" valign="top">Intercept</td><td align="center" valign="top">-0.385</td><td align="center" valign="top">0.285</td><td align="center" valign="top">-1.352</td><td align="center" valign="top">0.176</td></tr><tr><td align="left" valign="top">Cooling</td><td align="center" valign="top">0.625</td><td align="center" valign="top">0.111</td><td align="center" valign="top">5.635</td><td align="center" valign="top"><bold>&lt; 0.001</bold></td></tr><tr style="background-color: #D9D9D9;"><td align="left" valign="top">Sound level</td><td align="center" valign="top">0.036</td><td align="center" valign="top">0.010</td><td align="center" valign="top">3.668</td><td align="center" valign="top"><bold>&lt; 0.001</bold></td></tr><tr><td align="left" valign="top">Center reward</td><td align="center" valign="top">-0.512</td><td align="center" valign="top">0.150</td><td align="center" valign="top">-3.413</td><td align="center" valign="top"><bold>&lt; 0.001</bold></td></tr></tbody></table></table-wrap><table-wrap id="T6" orientation="portrait" position="float"><label>Table 6</label><caption><p>Model results for comparison of performance localizing sounds during unilateral cooling of left and right auditory cortex (n = 2 ferrets). Sample sizes during cooling left (F1311 = 476 trials, F1509 = 97 trials) or right auditory cortex (F1311 = 536 trials, F1509 = 294 trials). Model fit: Marginal R<sup>2</sup> = 0.185, Conditional R<sup>2</sup> = 0.208.</p></caption><table frame="box" rules="all"><thead><tr style="background-color: #F1C232; color: #FFFFFF;"><th align="left" valign="top">Fixed Effects</th><th align="center" valign="top">Estimate</th><th align="center" valign="top">Std. Error</th><th align="center" valign="top">Z</th><th align="center" valign="top">P(&gt; z)</th></tr></thead><tbody><tr style="background-color: #D9D9D9;"><td align="left" valign="top">Intercept</td><td align="center" valign="top">-3.215</td><td align="center" valign="top">0.496</td><td align="center" valign="top">-6.487</td><td align="center" valign="top"><bold>&lt; 0.001</bold></td></tr><tr><td align="left" valign="top">Cooled Hemisphere</td><td align="center" valign="top">0.617</td><td align="center" valign="top">0.492</td><td align="center" valign="top">-1.255</td><td align="center" valign="top">0.210</td></tr><tr style="background-color: #D9D9D9;"><td align="left" valign="top">Speaker Hemifield</td><td align="center" valign="top">2.636</td><td align="center" valign="top">0.531</td><td align="center" valign="top">4.968</td><td align="center" valign="top"><bold>&lt; 0.001</bold></td></tr><tr><td align="left" valign="top">Angle to midline</td><td align="center" valign="top">2.06</td><td align="center" valign="top">0.390</td><td align="center" valign="top">5.281</td><td align="center" valign="top"><bold>&lt; 0.001</bold></td></tr><tr style="background-color: #D9D9D9;"><td align="left" valign="top">Sound level</td><td align="center" valign="top">0.011</td><td align="center" valign="top">0.017</td><td align="center" valign="top">0.637</td><td align="center" valign="top">0.524</td></tr><tr><td align="left" valign="top">Center Reward</td><td align="center" valign="top">-0.082</td><td align="center" valign="top">0.296</td><td align="center" valign="top">-0.276</td><td align="center" valign="top">0.782</td></tr><tr style="background-color: #D9D9D9;"><td align="left" valign="top">Control Performance</td><td align="center" valign="top">2.362</td><td align="center" valign="top">0.419</td><td align="center" valign="top">5.636</td><td align="center" valign="top"><bold>&lt; 0.001</bold></td></tr><tr><td align="left" valign="top">Hemisphere * Hemifield</td><td align="center" valign="top">-1.769</td><td align="center" valign="top">0.669</td><td align="center" valign="top">-2.642</td><td align="center" valign="top"><bold>0.008</bold></td></tr><tr style="background-color: #D9D9D9;"><td align="left" valign="top">Hemisphere * Angle</td><td align="center" valign="top">-1.138</td><td align="center" valign="top">0.470</td><td align="center" valign="top">-2.419</td><td align="center" valign="top"><bold>0.016</bold></td></tr><tr><td align="left" valign="top">Hemifield * Angle</td><td align="center" valign="top">-3.581</td><td align="center" valign="top">0.516</td><td align="center" valign="top">-6.937</td><td align="center" valign="top"><bold>&lt; 0.001</bold></td></tr><tr style="background-color: #D9D9D9;"><td align="left" valign="top">Hemifield * Angle * Hemisphere</td><td align="center" valign="top">2.965</td><td align="center" valign="top">0.632</td><td align="center" valign="top">4.694</td><td align="center" valign="top"><bold>&lt; 0.001</bold></td></tr></tbody></table></table-wrap><table-wrap id="T7" orientation="portrait" position="float"><label>Table 7</label><caption><title>Summary of results during auditory cortical cooling.</title></caption><table frame="box" rules="all" style="border-color: #B7B7B7;"><thead><tr><th align="left" valign="top"/><th align="center" valign="top" colspan="3">Vowel Discrimination</th><th align="left" valign="top"/></tr><tr><th align="center" valign="top">Ferret</th><th align="center" valign="top" style="background-color: #D9D9D9;">Clean</th><th align="center" valign="top" style="background-color: #D9D9D9;">CL Noise</th><th align="center" valign="top" style="background-color: #D9D9D9;">SS noise</th><th align="center" valign="top">Sound Localization</th></tr></thead><tbody><tr><td align="center" valign="top">F1311</td><td align="center" valign="top" style="color: #38761D;">Present</td><td align="center" valign="top" style="color: #980000;">Present</td><td align="center" valign="top" style="color: #38761D;">Present</td><td align="center" valign="top" style="color: #980000;">Impaired</td></tr><tr><td align="center" valign="top">F1509</td><td align="center" valign="top" style="color: #38761D;">Present</td><td align="center" valign="top" style="color: #980000;">Impaired</td><td align="center" valign="top" style="color: #38761D;">Present</td><td align="center" valign="top" style="color: #980000;">Impaired</td></tr><tr><td align="center" valign="top">F1706</td><td align="center" valign="top" style="background-color: #D9D9D9; color: #FFFFFF;">Not tested</td><td align="center" valign="top" style="color: #980000;">Impaired</td><td align="center" valign="top" style="background-color: #D9D9D9; color: #FFFFFF;">Not tested</td><td align="center" valign="top" style="background-color: #D9D9D9; color: #FFFFFF;">Not tested</td></tr></tbody></table></table-wrap></floats-group></article>