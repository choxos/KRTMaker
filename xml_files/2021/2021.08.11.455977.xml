<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS150780</article-id><article-id pub-id-type="doi">10.1101/2021.08.11.455977</article-id><article-id pub-id-type="archive">PPR382021</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Hippocampal and medial prefrontal cortices encode structural task representations following progressive and interleaved training schedules</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Berens</surname><given-names>Sam C.</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><contrib contrib-type="author"><name><surname>Bird</surname><given-names>Chris M.</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib></contrib-group><aff id="A1"><label>1</label>School of Psychology, University of Sussex, UK</aff><author-notes><corresp id="CR1"><label>*</label>Correspondence: <email>s.berens@sussex.ac.uk</email> (S.C.B.)</corresp></author-notes><pub-date pub-type="nihms-submitted"><day>15</day><month>07</month><year>2022</year></pub-date><pub-date pub-type="preprint"><day>13</day><month>07</month><year>2022</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Memory generalisations may be underpinned by either encoding- or retrieval-based generalisation mechanisms and different training schedules may bias some learners to favour one of these mechanisms over the other. We used a transitive inference task to investigate whether generalisation is influenced by progressive vs randomly interleaved training, and overnight consolidation. On consecutive days, participants learnt pairwise discriminations from two transitive hierarchies before being tested during fMRI. Inference performance was consistently better following progressive training, and for pairs further apart in the transitive hierarchy. BOLD pattern similarity correlated with hierarchical distances in the left hippocampus (HIP) and medial prefrontal cortex (MPFC) following both training schedules. These results are consistent with the use of structural representations that directly encode hierarchical relationships between task features. However, such effects were only observed in the MPFC for recently learnt relationships. Furthermore, the MPFC appeared to maintain structural representations in participants who performed at chance on the inference task. We conclude that humans preferentially employ encoding-based mechanisms to store map-like relational codes that can be used for memory generalisation. These codes are expressed in the HIP and MPFC following both progressive and interleaved training but are not sufficient for accurate inference.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">Humans are readily able to generalise information learnt in one situation and apply it in another. For example, if we are told that Abuja is generally hotter than Beirut (A&gt;B), and Beirut is hotter than Carlisle (B&gt;C), then we can infer that Abuja is hotter than Carlisle (A&gt;C), despite never having been given that information directly. This particular type of generalisation is known as transitive inference.</p><p id="P3">The hippocampal system and medial prefrontal cortices (MPFC) have long been implicated in generalising recently learned information for use in new situations. Broadly speaking, contemporary models propose that these generalisations may be supported in two different ways: <italic>1)</italic> retrieval-based models, and <italic>2)</italic> encoding-based models. Despite these opposing views being present in the literature for many decades [<xref ref-type="bibr" rid="R1">1</xref>,<xref ref-type="bibr" rid="R2">2</xref>], it is unclear which mechanisms are used to support memory generalisation or, indeed, whether one is favoured over the other in particular situations.</p><p id="P4">Retrieval-based models suggest that the hippocampus encodes pattern separated representations that express specific relationships between co-presented items [<xref ref-type="bibr" rid="R3">3</xref>]. These models argue that generalisation is supported by a recursive neural mechanism that rapidly integrates distinct memories on-the-fly. As such, they predict that the brain only needs to store the originally presented information, since generalisation occurs as and when it is necessary via the retrieval of directly learnt information. Retrieval-based models have received support from both fMRI [<xref ref-type="bibr" rid="R4">4</xref>] and behavioural studies [<xref ref-type="bibr" rid="R5">5</xref>].</p><p id="P5">In contrast, encoding-based models suggest that the hippocampal and MPFC systems learn unified representations that directly express inferred structured relationships between task features [<xref ref-type="bibr" rid="R6">6</xref>–<xref ref-type="bibr" rid="R9">9</xref>]. These ‘structural representations’ are therefore sufficient to support inference without the need for a specialised inference mechanism. As such, the hallmark of encoding-based models is that the relationships between events have been abstracted and stored, enabling generalisation to occur without the need for online integration. Of course, these knowledge structures may not be created strictly at the point of encoding – it is possible that they emerge after a period of consolidation or after the same information has been experienced several times [<xref ref-type="bibr" rid="R10">10</xref>–<xref ref-type="bibr" rid="R12">12</xref>].</p><p id="P6">Consistent with encoding-based models, the hippocampus, entorhinal cortex, and medial prefrontal cortex have been found to encode generalised relationships that were not explicitly trained [<xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R13">13</xref>–<xref ref-type="bibr" rid="R18">18</xref>]. Additionally, the entorhinal cortex and MPFC are known to represent distinct sets of stimuli in similar ways provided that there are common relationships between the stimuli within each set [<xref ref-type="bibr" rid="R19">19</xref>–<xref ref-type="bibr" rid="R21">21</xref>]. These generalised representations are thought to facilitate inference and knowledge transfer across related tasks, although their relationship to generalisation performance is ambiguous.</p><p id="P7">Retrieval-based models predict that generalisation performance decreases when inferences require integrating information over more independent memory traces (so-called, negative transitive slopes; see [<xref ref-type="bibr" rid="R3">3</xref>]). However, encoding-based models often predict the opposite relationship, e.g., generalisations are easier when comparing stimuli that are separated by larger distances in an inferred hierarchy (positive transitive slopes). This is because the information required to discriminate stimuli based on their relative positions in an abstract task space becomes increasing salient with larger distances [<xref ref-type="bibr" rid="R22">22</xref>]. In support of retrieval-based mechanisms, there is clear evidence of negative transitive slopes when inferences involving distinct episodic memories [<xref ref-type="bibr" rid="R5">5</xref>]. Nonetheless, most studies have reported positive transitive slopes consistent with encoding-based mechanisms, particularly in transitive inference paradigms [<xref ref-type="bibr" rid="R9">9</xref>,<xref ref-type="bibr" rid="R23">23</xref>–<xref ref-type="bibr" rid="R26">26</xref>].</p><p id="P8">Aside from retrieval- and encoding-based models, it has been suggested that above chance performance on transitive inference tasks can result from stimulus-reward associative learning simply because, during some training procedures, stimuli at the top of the hierarchy tend to be selected more often and so are more commonly associated with reward [<xref ref-type="bibr" rid="R27">27</xref>–<xref ref-type="bibr" rid="R30">30</xref>]. However, more recent research has shown that these simple associative mechanisms are unable to account for all transitive inference behaviours [<xref ref-type="bibr" rid="R9">9</xref>,<xref ref-type="bibr" rid="R23">23</xref>,<xref ref-type="bibr" rid="R25">25</xref>,<xref ref-type="bibr" rid="R26">26</xref>,<xref ref-type="bibr" rid="R31">31</xref>–<xref ref-type="bibr" rid="R35">35</xref>]. Moreover, participants in the current study were able to perform inferences despite a receiving a pattern of reinforcement that was entirely incompatible with stimulus-reward association learning (see <ext-link ext-link-type="uri" xlink:href="https://osf.io/cteg9">https://osf.io/cteg9</ext-link>). As such, we do not consider these models any further in the current study.</p><p id="P9">Certain training conditions can have a large impact on how information is retained [<xref ref-type="bibr" rid="R36">36</xref>] and generalises to new situations [<xref ref-type="bibr" rid="R37">37</xref>]. For example, categorisation of previously unseen objects is sometimes improved if exemplars from different categories are presented in an interleaved order, rather than in category-specific blocks, e.g., [<xref ref-type="bibr" rid="R38">38</xref>–<xref ref-type="bibr" rid="R40">40</xref>]. However, other studies have shown advantages for blocked training schedules, especially when category differences are clearly verbalizable, e.g., [<xref ref-type="bibr" rid="R41">41</xref>–<xref ref-type="bibr" rid="R43">43</xref>]. Potentially resolving this conflict, interleaving has been shown to aid category generalisation when exemplars are highly similar to one another (both within- and between-categories), whereas blocking may be best when exemplars are relatively distinct [<xref ref-type="bibr" rid="R44">44</xref>]. As such, it has been suggested that interleaving emphasises between-category differences, whereas blocking emphasises commonalities amongst exemplars [<xref ref-type="bibr" rid="R37">37</xref>,<xref ref-type="bibr" rid="R44">44</xref>].</p><p id="P10">Despite this, it remains unclear whether and how interleaved vs blocked training influences the structure of learnt memory representations, or the generalisation mechanisms that are preferentially employed. Behavioural evidence suggests that blocked training enables the learning of low-dimensional (compressed) stimulus representations that linearly encode task-relevant features [<xref ref-type="bibr" rid="R42">42</xref>]. Additionally, recent research shows that training overlapping discriminations in an ordered sequence (e.g., A&gt;B followed by B&gt;C and then C&gt;D, so-called ‘chaining’) may improve transitive inference by allowing learners to integrate the discriminations into a unified mental model [<xref ref-type="bibr" rid="R45">45</xref>,<xref ref-type="bibr" rid="R46">46</xref>]. Nevertheless, when this integration takes place, and whether it depends on encoding- or retrieval-based mechanisms has yet to be tested.</p><p id="P11">We hypothesised that interleaved training would promote the learning of the specific, pattern separated, pairings and consequently bias the use of retrieval-based inference judgements. This follows the proposal that interleaved training highlights the differences between items. Furthermore, it is consistent with the finding that hippocampal pattern separation prevents interference between overlapping relationships learnt in an interleaved order [<xref ref-type="bibr" rid="R47">47</xref>]. In contrast, we hypothesised that presenting related pieces of information in ordered blocks (hereafter referred to as ‘progressive training’), should facilitate the use of encoding-based inference mechanisms. Specifically, progressive training may enable pattern completion between pairs thereby allowing participants to encode inferred relationships during training [<xref ref-type="bibr" rid="R48">48</xref>].</p><p id="P12">This hypothesis is partly informed by a supplementary analysis demonstrating that that, relative to interleaving, progressive training can bias some artificial neural networks to learn task representations that directly encode generalised relationships (see <xref ref-type="supplementary-material" rid="SD3">S1 Text</xref>). We trained a variety of multilayer perceptions (MLPs) on a transitive inference task. When the MLPs were constrained to learn low-dimensional (compressed) representations of the discriminations, they tended to encode the relative value of stimuli (i.e., A&gt;B&gt;C). This aided inference performance because the MLPs were not equipped with a retrieval-based generalisation mechanism. Given this result, we predicted that progressive training would facilitate encoding-based inference in humans and speculated that it may confer a similar performance advantage.</p><p id="P13">As mentioned, many studies have rereported positive transitive slopes that are indicative of encoding-based generalisations. However, it is noteworthy that most of these studies have either employed progressive training schedules [<xref ref-type="bibr" rid="R23">23</xref>,<xref ref-type="bibr" rid="R26">26</xref>], or provided explicit feedback to inferred discriminations which can confound distance effects with differences in how often stimuli are rewarded [<xref ref-type="bibr" rid="R22">22</xref>,<xref ref-type="bibr" rid="R24">24</xref>,<xref ref-type="bibr" rid="R25">25</xref>]. Here, we directly tested the predictions of retrieval-/encoding-based generalisation mechanisms following both interleaved and progressive training schedules, in a feedback-free inference test.</p><p id="P14">In addition to the training schedule, we also manipulated whether participants experienced an overnight period of consolidation before being tested on their ability to generalise. Sleep-dependent consolidation has long been implicated in abstracting statistical regularities across separate memories, possibly because it allows distinct event representations to be replayed out-of-order [<xref ref-type="bibr" rid="R49">49</xref>,<xref ref-type="bibr" rid="R50">50</xref>]. In support of this, many studies have shown that memory generalisation improves following a period of sleep, or even wakeful rest [<xref ref-type="bibr" rid="R51">51</xref>–<xref ref-type="bibr" rid="R55">55</xref>]. We hypothesised that overnight consolidation would allow pattern separated memories of task contingencies to be re-encoded as structural memory representations, see [<xref ref-type="bibr" rid="R56">56</xref>,<xref ref-type="bibr" rid="R57">57</xref>]. We therefore predicted that inferences made on items learnt the previous day would depend more on encoding-based mechanisms than inferences on items learnt immediately prior to scanning.</p><p id="P15">To test these hypotheses, we analysed the effect of training schedule and overnight consolidation on behavioural and fMRI data collected while human participants performed transitive inferences. We trained a series of ‘premise’ discriminations via either progressive or interleaved presentations within a reinforcement learning task (see <xref ref-type="fig" rid="F1">Figure 1</xref>). Across consecutive days, 34 participants learnt 2 independent sets of premise discriminations (one set per day), each of which entailed a 1-dimensional transitive hierarchy over 7 visual features (A&gt;B&gt;C&gt;D&gt;E&gt;F&gt;G). Shortly after training on the second day, participants recalled all the premise discriminations, and made inferences whilst being scanned. As such, we were able to investigate progressive/interleaved training, and inferences based on recent/remote memories in a full factorial design.</p><p id="P16">We found that progressive training had a large benefit on inference performance in humans. Computational models that captured broad predictions of retrieval- and encoding-based models revealed that our behavioural data are better accounted for by encoding-based mechanisms. Surprisingly, this did not depend on the experimental factors of interest, namely, training schedule and overnight consolidation. Next, we tested neurocognitive predictions of encoding- and retrieval-based models using univariate and multivariate analyses of the imaging data. Retrieval-based models predict the occurrence of BOLD activations that are uniquely associated with on-the-fly generalisation performance. However, we did not observe any effects consistent with this prediction. In contrast, a representational similarity analysis (RSA) supported encoding-based models. Specifically, consistent with multiple encoding-based accounts, we identified RSA effects in the hippocampus and MPFC suggestive of structural representations that expressed inferred relationships across the whole transitive hierarchy. In the MPFC, these effects we only evident for recently learnt contingencies, perhaps suggesting a time-dependent role of this region. We also found that structural representations in the hippocampus and MPFC were associated with different patterns of behavioural performance, perhaps suggestive of different generalisation processes.</p></sec><sec id="S2" sec-type="results"><title>Results</title><sec id="S3"><title>Inference performance</title><p id="P17">Over two consecutive days, we trained participants to make binary discriminations in a reinforcement learning task (see <xref ref-type="fig" rid="F1">Figure 1A</xref>). Trials presented two buildings that differed in only one respect; the wall textures rendered onto the outside of each building. One building contained a pile of virtual gold (reinforcement) and participants were tasked with learning which wall texture predicted the gold in order to gain as much reinforcement as possible. We explicitly trained 2 sets of discriminations with 6 premise pairs in each; ‘A&gt;B’, ‘B&gt;C’ … ‘F&gt;G’ (correct responses indicated to the left of the greater-than sign). As such, the contingencies predicting reward implied 2 independent transitive hierarchies (A&gt;B&gt;C&gt;D&gt;E&gt;F&gt;G, <xref ref-type="fig" rid="F1">Figure 1B</xref>).</p><p id="P18">One set of premise discriminations was trained on each day and training sessions were separated by approximately 24 hours. Prior to the first session, participants were randomly assigned to either an interleaved or progressive training condition which determined the type of training they received on both days. Interleaved training involved presenting all 6 discriminations in a pseudorandom order such that there was a uniform probability (1/6) of encountering any one on a particular trial (see <xref ref-type="fig" rid="F1">Figure 1C</xref>). In contrast, progressive training involved 6 epochs of different lengths that gradually introduced discriminations and ensured that, once introduced, they were presented in all subsequent epochs.</p><p id="P19">After training on the second day, participants underwent fMRI scanning while recalling all the premise discriminations (from both days) as well as 2 sets of inferred discriminations. As such, the experiment involved 3 main experimental factors: <italic>1)</italic> training method (interleaved vs progressive), <italic>2)</italic> session (recent vs remote), <italic>3)</italic> discrimination type (premise vs inferred). Here, we only report contrasts relating to our a priori hypotheses but a full list of results is available on the Open Science Framework (OSF, <ext-link ext-link-type="uri" xlink:href="https://osf.io/tvk43/">https://osf.io/tvk43/</ext-link>).</p><p id="P20"><xref ref-type="fig" rid="F2">Figure 2A</xref> depicts estimates of performance for the in-scanner task in terms of the probability of a correct response. A mixed-effects logistic regression highlighted similar levels of accuracy for the premise discriminations regardless of training method, session, or their interaction; largest effect: t(804) = 0.765, p = .445. However, there was a large effect of training method on inference performance with progressive learners outperforming interleaved learners; t(804) = 5.54, p &lt; .001. This effect was also evident as a main effect of training method (averaged across both premise and inferred trials), t(804) = 3.83, p &lt; .001, and as an interaction between method and discrimination type; t(804) = 7.39, p &lt; .001. No main effect of session or a session by method/discrimination type interaction was detected; largest effect: t(804) = 1.44, p = .149.</p><p id="P21">The logistic regression also examined the effect of ‘transitive distance’, that is, accuracy differences corresponding to larger or smaller separations between wall textures along the transitive hierarchy (e.g., B&gt;D has a distance of 2, whereas B&gt;F has a distance of 4). We found an overall effect of transitive distance, t(804) = 2.11, p = .035, indicating that, in general, as the separation between wall textures increased, behavioural accuracy also increased. Additionally, there was a significant 3-way interaction between training method, session and transitive distance, t(804) = 3.18, p = .002. This suggested that transitive distance was most predictive of performance in the progressive-remote condition, t(804) = 3.07, p = .002, relative to all other conditions which yielded similar distance effects (t-values = 1.99, 1.08, &amp; 1.55, for the interleaved-recent, interleaved-remote &amp; progressive-recent conditions respectively, see <xref ref-type="fig" rid="F2">Figure 2B</xref>). However, this interaction does not reflect larger performance increases in the progressive-remote condition as the estimated probability of a correct response was uniformly close to ceiling (only increasing from .921 to .996). Instead, it mainly reflects performance becoming more consistently accurate (i.e., lower variances in the binomial probability estimate) with larger distances.</p><p id="P22">A generalised linear model of response times (correct responses only) produced a complementary pattern of results (see <xref ref-type="fig" rid="F2">Figure 2C</xref>). Specifically, we detected main effects of training method and discrimination type indicating shorter response times from progressive learners and longer response times to inferred discriminations; t(5301) = 2.01, p = .045, and t(5301) = 2.31, p = .021, respectively. These effects were superseded by a training by discrimination type interaction highlighting that longer response times to inferred trials were more pronounced for interleaved learners; t(5301) = 5.17, p &lt; .001. Unlike the accuracy data, this analysis showed a main effect of session indicative of quicker responses to all remote discriminations; t(5301) = 3.26, p = .001. No other significant main effects or interactions were detected.</p></sec><sec id="S4"><title>Computational models</title><p id="P23">We predicted that the use of retrieval- and encoding-based generalisation mechanisms would vary by experiment condition. To test this directly, we created two descriptive models based on general principles of retrieval- and encoding-based accounts. Under similar assumptions, each model attempted to predict participants’ inference performance from their responses to premise trials. The goodness-of-fit for each model was determined by how well it accounted for the pattern of correct and incorrect responses.</p><p id="P24">The retrieval-based AND model assumes that correctly inferring a non-trained discrimination (e.g., B&gt;E) involves retrieving all the directly trained response contingencies required to reconstruct the relevant section of the transitive hierarchy (e.g., B&gt;C <italic>and</italic> C&gt;D <italic>and</italic> D&gt;E; so-called mediating contingencies). As such, the AND model captures a general prediction of retrieval-based mechanisms; that inference performance decreases as a function of transitive distance due to the reliance on more independent memory traces [<xref ref-type="bibr" rid="R3">3</xref>–<xref ref-type="bibr" rid="R5">5</xref>].</p><p id="P25">In contrast, the encoding-based OR model assumes that participants can access a unified structural representation describing the associative distances between all stimuli. Nonetheless, in order to make a successful inference, knowledge of this associative structure must be evaluated alongside the reward contingencies indicating which of the presented stimuli is higher in the reward hierarchy. When making an inference (e.g., B&gt;E), it is therefore sufficient to recall only one of the contingencies indicating which stimulus should be preferred (e.g., B&gt;C), or which stimulus should be avoided (e.g., D&gt;E).</p><p id="P26">The AND and OR models predict different levels of performance across inference trials (see Methods). We measured the fit of these models against participants’ performance data using a cross-entropy cost function and analysed these goodness-of-fit statistics using a generalised linear mixed-effects regression with 3 experimental factors: 1) model type (AND vs OR), 2) training method (interleaved vs progressive), and 3) session (recent vs remote). <xref ref-type="fig" rid="F3">Figure 3</xref> plots the cross-entropy statistics by all conditions. The mixed-effects regression highlighted main effects of model type, t(128) = 8.45, p &lt; .001, and training method, t(128) = 5.53, p &lt; .001, both of which were qualified by a model type by training method interaction: t(128) = 5.84, p &lt; .001. No other model terms were significant.</p><p id="P27">These results indicated that, relative to the AND model, the OR model provided a better fit to the inference data in general, although it was less predictive in interleaved learners. Nonetheless, the OR model was still preferred over the AND model in interleaved learners, t(128) = 2.63, p = .009. This was also evident when we used Spearman rank correlations to compare the number of correct responses to each inferred discrimination with the number of correct responses that would be expected under each model. Specifically, the correspondence between model predictions and the observed data tended to be higher across participants for the OR model in both the progressive and interleaved conditions; t(14) = 7.31, p &lt; .001, and t(16) = 5.38, p &lt; .001 (respectively, statistics derived from bootstrapped paired-samples t-tests, see <xref ref-type="supplementary-material" rid="SD2">S1 Table</xref>). Contrary to our predictions, these results indicate that inference performance is best accounted for by encoding-based mechanisms in all experimental conditions.</p></sec><sec id="S5"><title>Univariate BOLD effects</title><p id="P28">Retrieval-based models of generalisation hold that inferences depend on an online mechanism that retrieves multiple premise contingencies from memory and integrates information between them. As such, we used a set of linear mixed-effects models to test whether BOLD responses were larger on inferred trials than on premise trials and whether this effect was modulated by 5 factors of interest: <italic>1)</italic> transitive distance, <italic>2)</italic> training method (interleaved vs progressive), <italic>3)</italic> training session (recent vs remote), <italic>4)</italic> inference accuracy, and <italic>5)</italic> the slope relating transitive distance to inference performance (hereafter referred to as the ‘transitive slope’). The rationale for this latter factor follows from considering that encoding- and retrieval-based models predict different transitive slopes (being positive and negative, respectively). Given this, the magnitude of the slope can be used to indicate whether BOLD responses more closely adhere to the predictions of one model or the other.</p><p id="P29">In comparison to the trained discriminations, inference trials evoked lower levels of BOLD in the right hippocampus (specifically, more deactivation relative to the implicit baseline); t(787) = 2.79, p = .005 (<xref ref-type="supplementary-material" rid="SD1">S1 Figure</xref>). However, this effect was not modulated by training method, t(787) = 0.31, p = .753, or inference accuracy, t(787) = 0.04, p = .965, and so cannot account for variation in inference performance. In contrast, BOLD estimates in the superior MPFC did reflect differences in inference performance. In the left superior MPFC we saw a significant effect of trial type, again indicating more deactivation on inference trials, t(787) = 3.25, p = .001. This was qualified by a 3-way interaction between trial type, training method, and inference accuracy, t(787) = 2.93, p = .003 (<xref ref-type="fig" rid="F4">Figures 4A and 4B</xref>). Similarly, the right superior MPFC produced a significant interaction between trial type and training method t(787) = 2.76, p = .006, (<xref ref-type="fig" rid="F4">Figures 4C and 4D</xref>). Overall, these results indicate that the MPFC produced greater levels of BOLD activity whenever response accuracy was high, regardless of whether participants were responding to premise or inferred discriminations.</p><p id="P30">In sum, we found no univariate BOLD effects consistent with the use of retrieval-based generalisation mechanisms. While activity in the superior MPFC was associated with behavioural performance, this association was not specific to, or enhanced by novel inferences as would be expected under retrieval-based accounts, see [<xref ref-type="bibr" rid="R58">58</xref>,<xref ref-type="bibr" rid="R59">59</xref>]. A full list of statistical outputs relating to each ROI is available on the OSF (<ext-link ext-link-type="uri" xlink:href="https://osf.io/sdtyk">https://osf.io/sdtyk</ext-link>).</p></sec><sec id="S6"><title>Representational similarity analyses</title><p id="P31">We predicted that the training method and the length of the study-test interval would affect how response contingencies were encoded by medial temporal and prefrontal systems. Specifically, we expected that progressive training and longer retention intervals would result in structural representations of the transitive hierarchy and that this would correspond to better inference. To test this, we constructed a series of linear mixed-effects models (LMMs) that aimed to <italic>a)</italic> identify neural signatures of structural memory representations, and <italic>b)</italic> reveal whether they are modulated by each experimental factor (and their interactions).</p><p id="P32">BOLD responses to each discrimination were first used to estimate representations of individual wall-textures via an ordinary least-squares decomposition (see Methods and <xref ref-type="fig" rid="F5">Figure 5A</xref>). The correlational similarity between wall-texture representations was then analysed in the LMMs to identify ‘distance effects’ within each hierarchy, i.e., where the similarity between wall-textures from the same transitive chain (i.e., trained on the same day) scaled with transitive distance (e.g., corr[B,C] &gt; corr[B,D] &gt; corr[B,E]). Moreover, the LMMs tested whether such distance effects were modulated by 4 factors of interest: <italic>1)</italic> training method (interleaved vs progressive), <italic>2)</italic> training session (recent vs remote), <italic>3)</italic> inference accuracy, and <italic>4)</italic> transitive slope (as above).</p><p id="P33">Importantly, the LMMs excluded correlations involving wall textures ‘A’ and ‘G’ at the extreme ends of each hierarchy. This is because these stimuli were only presented in premise trials and so their estimated voxel representations may differ from all other representations for trivial reasons. Additionally, each LMM included an extensive set of fixed- and random-effect predictors that controlled for nuisance correlations between co-presented wall textures and correlations resulting from the least-squares decomposition (see Methods).</p><p id="P34">Here, we only report main effects and interactions involving the transitive distance predictor since our hypotheses only concerned these terms. Nonetheless, for completeness, we report all other significant effects in a supplement (<xref ref-type="supplementary-material" rid="SD5">S2 Text</xref>) and provide a full list of statistical outputs on the OSF (<ext-link ext-link-type="uri" xlink:href="https://osf.io/29x3q">https://osf.io/29x3q</ext-link>). The supplement also includes an analysis of hierarchical representations that generalised across the transitive chains learnt on each day of training (i.e., across recent and remote conditions). While no significant ‘across-hierarchy distance effects’ were identified, we detail all other main effects and interactions revealed by this analysis.</p><p id="P35">In the left hippocampus, we saw a main effect of distance that did not survive our correction for multiple comparisons; t(652) = 2.61, p = .009. While not reaching our strict criterion for statistical significance, 27 of the 34 participants exhibited the predicted distance effect in this region which is significantly more than would be expected by chance alone (p &lt; .001, binomial test). As such, this effect is consistent with our prediction that representational similarity between wall textures should be inversely related to their hierarchical distance (see <xref ref-type="fig" rid="F5">Figure 5B</xref>). The left hippocampus also produced a distance by transitive slope interaction, t(652) = 3.31, p = .001. Contrary to predictions, this indicated that distance effects were most strongly expressed in participants who had a relatively low (or negative) transitive slope (see <xref ref-type="fig" rid="F6">Figure 6A</xref>). As such, the left hippocampus appears to encode structural task representations most strongly when behavioural performance is less typical of encoding-based generalisation.</p><p id="P36">In the left superior MPFC, transitive distance was negatively correlated with representational similarity in the recent, but not the remote, conditions; t(650) = 3.59, p &lt; .001, and t(650) = 0.113, p = .910 (respectively). This resulted in a significant interaction between transitive distance and training session suggesting the presence of structural representations for recently learnt stimuli alone, t(650) = 3.00, p = .003 (see <xref ref-type="fig" rid="F5">Figure 5C</xref>). On top of this effect, we saw a 3-way interaction between distance, session and inferential accuracy, t(650) = 4.24, p &lt; .001 (see <xref ref-type="fig" rid="F6">Figure 6B</xref>). This indicated that the strength of structural representations was greatest for participants who did not achieve high levels of inference performance (although note that the distance effect was still significant for the majority of performance scores).</p><p id="P37">In the right superior MPFC, we also saw a 3-way interaction between distance, session, and accuracy, t(652) = 2.90, p = .004. Again, this was suggestive of structural representations in recent condition, but only when generalisation performance was relatively low, and only for learners in the interleaved training condition. Furthermore, the right superior MPFC produced a distance by transitive slope interaction that was superseded by a 3-way interaction between distance, session, and transitive slope, t(652) = 2.79, p =.006, and t(652) = 2.96, p = .003 (respectively, see <xref ref-type="fig" rid="F6">Figure 6C</xref>). This highlighted that the expected distance effects were only expressed in the remote condition when participants’ behavioural data was heavily indicative of encoding-based generalisations. Importantly, this contrasts with the distance effects identified in the left hippocampus which were strongest when participants’ behavioural data were <italic>less</italic> indicative of encoding-based generalisation.</p><p id="P38">Finally, we report a significant 3-way interaction between distance, session, and training method in the left inferior MPFC, t(648) = 2.99, p = .003. This was mainly driven by distance effects in the progressive training condition. Specifically, we observed the predicted negative correlation between distance and pattern similarity in the recent condition (t = 1.95), but the opposing (positive) relationship for progressive learners in the remote condition (t = 2.40). Post-hoc tests indicated that the positive distance effect was principally attributable to high levels of similarity between responses to wall textures ‘B’ and ‘F’ (i.e., those with the largest transitive distance in the analysis). While such an effect may reflect how the stimuli were being encoded, this pattern of data was not predicted and so we do not draw any inferences based on this result.</p><p id="P39">To validate the distance effects reported above, we ran a series of follow-up tests to examine whether they could be attributed to higher levels of BOLD similarity exclusively for stimuli that were shown within the same premise pair (i.e., driven by Δ1 pairs alone). First, we contrasted similarity estimates between different levels of the distance factor in a random effects analysis. Consistent with our a priori predictions, this invariably revealed significant differences (at uncorrected thresholds) between levels of the distance predictor that did not include Δ1 pairs. We also re-ran each LMM, but excluded similarity estimates between Δ1 pairs. With the exception of the main effect of distance in the hippocampus, all left lateralised effects reported above survived our correction for multiple comparisons, t(382) &gt; 2.92.</p><p id="P40">Taken together, these findings suggest that the hippocampus contributes to memory generalisations by representing structural memory codes following both interleaved and progressive training. The superior MPFC appears to maintain similar representations, but only for recently learnt material.</p></sec></sec><sec id="S7" sec-type="discussion"><title>Discussion</title><p id="P41">We sought to determine whether the use of encoding- and retrieval-based generalisation mechanisms are influenced by two factors: 1) the order in which task contingencies are learnt (i.e., interleaved vs progressive training), and 2) whether there has been a period of overnight consolidation.</p><p id="P42">Our behavioural analyses demonstrate that progressive training substantially increases generalisation performance compared with randomly interleaving contingencies. This happens despite comparable accuracy in remembering the directly trained (premise) contingencies that generalisations were based upon. However, contrary to our hypotheses, model-based analyses of the behavioural data revealed that encoding-based mechanisms were preferentially used across all experimental conditions. Representational similarity analyses of the fMRI data were also suggestive of the use of encoding-based mechanisms. Here, BOLD pattern similarity in the hippocampal and medial prefrontal cortices correlated with hierarchical distances between stimuli. This implies the presence of map-like structural representations that directly express inferred relationships in an abstract task space. Importantly, these effects were evident following both interleaved and progressive training. It therefore appears that humans have a robust means of learning hierarchical structures regardless of the training method.</p><p id="P43">In contrast to our results, previous studies have shown that some generalisations are enhanced by interleaved training when compared to blocked schedules. Zhou et al [<xref ref-type="bibr" rid="R60">60</xref>] report that both humans and connectionist model of the hippocampal system show elevated levels of memory integration and property generalisation following interleaved training. However, it is notable that our progressive training procedure represent a middle ground between blocking and interleaving. Progressive epochs gradually introduce new discriminations while concurrently testing those that had been shown previously. Unlike fully blocked schedules, this protects against ‘catastrophic interference’ [<xref ref-type="bibr" rid="R42">42</xref>,<xref ref-type="bibr" rid="R61">61</xref>], where new learning results in the forgetting of previously acquired knowledge. It is therefore possible that progressive training offers the best of all worlds – enhanced generalisation across different contexts whilst protecting against catastrophic interference.</p><p id="P44">To date, state-of-the-art machine learning applications have avoided catastrophic interference by relying on interleaved training [<xref ref-type="bibr" rid="R62">62</xref>]. Recently, Kirkpatrick et al [<xref ref-type="bibr" rid="R46">46</xref>] introduced an updated loss function for gradient decent that protects previously acquired expertise from catastrophic interference. This cost function incorporates a Fisher information matrix describing how critical each parameter is to maintaining performance on previously trained objectives. It is possible that such protections against interference may allow artificial networks to learn task representations that better support generalisation.</p><p id="P45">Although progressive training improved inference performance our study, it appeared to have very little effect on the mechanisms used to make inferential judgements. Analyses of both the behavioural and fMRI data suggested that participants principally used encoding-based mechanisms in all experimental conditions. Moreover, the results of our univariate fMRI analyses did not meet the predictions of retrieval-based mechanisms. The preference for encoding-based strategies that we observed may be due to how well the premise pairs were learnt. Retrieval-based mechanisms are known to explain inference performance when memories have been acquired in a single episode (i.e., one-shot learning; [<xref ref-type="bibr" rid="R5">5</xref>]). Given this, our findings are consistent with proposals that encoding-based generalisation mechanisms directly encode abstractions whenever information is frequently rehearsed [<xref ref-type="bibr" rid="R49">49</xref>].</p><p id="P46">As noted, we found evidence that transitive hierarchies were represented in the hippocampus and MPFC in the form of map-like structural codes. This supports various models of memory generalisation that posit representations of physical space can be applied to make inferences in abstract, non-spatial tasks [<xref ref-type="bibr" rid="R7">7</xref>,<xref ref-type="bibr" rid="R63">63</xref>,<xref ref-type="bibr" rid="R64">64</xref>]. Interesting however, the MPFC only appeared to represent structural codes for recently learnt stimuli. Furthermore, while we identified MPFC representations in the majority of participants, they tended to be most strongly expressed in participants who did not achieve high levels of inferential performance. Both of these effects may be attributable to the ease with which structural representations could be accessed and manipulated. It is possible that such operations were more difficult in the recent condition (note the slower response times in this condition), and when participants found inferences more difficult, they tended to activate MPFC representations for longer and/or less efficiently.</p><p id="P47">Relatedly, BOLD patterns in the MPFC exhibited structural representations even when participants performed at chance level on the inference task (see <xref ref-type="fig" rid="F6">Figure 6B</xref>). It therefore appears that merely having structural representations is not sufficient for good inference performance. Furthermore, while progressive training aided inference performance, we did not detect overall group differences in the strength of structural representations between training conditions. Given this, we speculate that progressive exposure may facilitate the <italic>use</italic> of structural representations during novel inference, rather than the acquisition of structural representations per se. This may explain why some types of generalisation benefit from blocked/progressive exposure, while other forms of generalisation (not dependent on structural codes), do not, e.g., [<xref ref-type="bibr" rid="R38">38</xref>–<xref ref-type="bibr" rid="R40">40</xref>,<xref ref-type="bibr" rid="R60">60</xref>].</p><p id="P48">Our finding of structural representations in the absence of above-chance inference performance is incompatible with models that propose knowing the relative value of stimuli is all that is needed to build a hierarchical task representation and make novel inferences (e.g., [<xref ref-type="bibr" rid="R6">6</xref>], and the MLPs reported in the supplement). Nevertheless, other models can account for this observation. Neural codes postulated by both the Tolman-Eichenbaum Machine (TEM) and the successor representation (SR) model dissociate the learned values of stimuli from structural relationships between them [<xref ref-type="bibr" rid="R7">7</xref>,<xref ref-type="bibr" rid="R63">63</xref>,<xref ref-type="bibr" rid="R64">64</xref>]. In the TEM, structural information derived from previous experience is bound to sensory codes in the hippocampus via a fast Hebbian learning rule. However, the ability to use these representations for transitive inference depends on additional path-integration steps that may bottleneck performance. Similarly, SRs can encode the distance between all stimuli in a transitive hierarchy based on knowledge of which stimuli were presented in the same premise pairs. However, in order to support transitive inference, SRs must be combined with a representation encoding the average reward returned by each stimulus.</p><p id="P49">We also tested whether individual differences in transitive slopes covaried with the strength of structural representations in each ROI. We predicted that participants who produced large, positive transitive slopes (suggestive of encoding-based mechanisms) would most strongly express structural representations in each ROI. This was indeed the case in the right superior MPFC. However, the left hippocampus showed an opposing relationship; a significant distance effect that was strongest for participants who produced negative transitive slopes (see <xref ref-type="fig" rid="F6">Figure 6</xref>). We are unable to fully interpret these results as they were not predicted a priori and because the association between transitive slope and the MPFC distance effect was not consistent across conditions (only being evident in the interleaved, remote condition). However, it is unlikely that there is a simple relationship between the sign and magnitude of each participant’s transitive slope, and their use of different generalisation mechanisms.</p><p id="P50">Aside from a slight decrease in response latencies on both premise and inferred trials, we did not observe any benefit of overnight consolidation on inference performance (in either training condition). This finding is in contrast to a similar test by Ellenbogen et al [<xref ref-type="bibr" rid="R54">54</xref>] who found that inference performance increased after a period of sleep. We also did not support our hypothesis that consolidation would bias the use of encoding-based inference mechanisms. Indeed, contrary to this, we found that structural representations in the superior MPFC became less evident for transitive hierarchies that were learnt 24 hours before testing. While it is possible that this effect reflects consolidation of structural representations outside of the MPFC, or more efficient processing within the region, additional research will be needed to clarify the role of consolidation in memory generalisations.</p><p id="P51">In summary, we show that progressive training dramatically improves transitive inference and that humans tend to use encoding-based mechanisms to inform inferential judgements based on well-learnt contingencies. Both the hippocampus and MPFC encode structural representations of transitive hierarchies, yet the presence of these representations appears to be insufficient for successful inference. Taken together, these findings provide strong support for encoding-based models that predict map-like structural representations underpin spatial and non-spatial generalisations.</p></sec><sec id="S8" sec-type="methods"><title>Methods</title><sec id="S9" sec-type="subjects"><title>Participants</title><p id="P52">Right-handed participants were recruited from the University of Sussex, UK. All gave written informed consent and were reimbursed for their time. Participants had either normal or corrected-to-normal vision and reported no history of neurological or psychiatric illness. During the study, they were randomly assigned to one of the two between-subject conditions (i.e., the interleaved or progressive training conditions) such that there were an equal number of useable datasets in each. Data from 5 participants could not be included in the final sample because of problems with fMRI data acquisition (one participant), excess of motion-related artifacts in the imaging data (three participants), and a failure to respond during the in-scanner task (one participant). After these exclusions, the final sample included 34 participants (16 females) with a mean age of 25.9 years (<italic>SD</italic> = 4.60 years). The study was approved by the Brighton and Sussex Medical School’s Research Governance and Ethics Committee.</p></sec><sec id="S10"><title>Behavioural tasks</title><sec id="S11"><title>Pre-scanner training</title><p id="P53">We developed a reinforcement learning task designed to train participants on pairwise discriminations before scanning. Two different versions of the task were produced so that each participant could be trained on two occasions; once immediately prior to scanning (recent condition), and once 24 hours before scanning (remote condition).</p><p id="P54">Unreal Development Kit (Epic Games) was used to generate a number of unique scenes within a first-person virtual environment (see <xref ref-type="fig" rid="F1">Figure 1A</xref> for examples). On each trial, a scene depicted two buildings positioned equidistantly from a start location. One building concealed a pile of virtual gold (reinforcement), yet the only features that predicted the rewarded location were the wall textures rendered onto the towers of each building. Participants were tasked with learning which wall-textures predicted reward in each scene and selecting them in order to gain as much reward as possible.</p><p id="P55">In total, seven unique wall textures were used in each version of the task. During training, these were combined to generate 6 binary discriminations (e.g., A&gt;B, B&gt;C, etc.) that implied a 1-dimensional transitive hierarchy (A&gt;B&gt;C&gt;D&gt;E&gt;F&gt;G, where each letter denotes a unique wall texture; see <xref ref-type="fig" rid="F1">Figure 1B</xref>). As such, every wall texture could be assigned a scalar value representing its utility in predicting reward. Importantly, each wall texture was rendered onto the left and right buildings an equal number of times to ensure that non-target strategies (e.g., always selecting the building on the left) would not result in above chance performance.</p><p id="P56"><xref ref-type="fig" rid="F1">Figure 1</xref> presents a schematic of the training schedule for participants in either the interleaved or progressive learning conditions. All trials initially depicted the participant at the start location, in front of two buildings, for up to 3 seconds. During this time participants were required to select the building they believed contained the gold via a left/right button press (decision period). Immediately following a response, a 4-second animation was played showing the participant approaching their chosen building and opening its central door to reveal whether or not it contained gold (feedback period). If no response was made within the 3-second response window, a 4-second red fixation cross was shown in place of the feedback video.</p><p id="P57">For participants in the interleaved learning condition, all discriminations were presented in a pseudorandom order such that there was a uniform probability (1/6) of encountering any one discrimination on any particular trial (see <xref ref-type="fig" rid="F1">Figure 1C</xref>). Given that ‘chaining’ overlapping trails in an ordered sequence (e.g., ‘B&gt;C’ followed by ‘C&gt;D’) may facilitate encoding-based generalisations [<xref ref-type="bibr" rid="R45">45</xref>,<xref ref-type="bibr" rid="R46">46</xref>], it is noteworthy that our interleaved training schedule presented participants is relatively few chained sequences. Specifically, out of 360 training trails, there were an average of 75.12 chains with a length of two, 10.23 chains with a length of three, and a negligible number of chains (1.51) with a length of four or more discriminations.</p><p id="P58">For participants in the progressive learning condition, the task was composed of 6 sequentially presented epochs of different lengths which gradually introduced each discrimination one-by-one. The first epoch exclusively trained the discrimination at the top of the transitive hierarchy (A&gt;B) across 17 trials. The second epoch involved an additional 14 trials of the A&gt;B discrimination but also introduced the next-highest discrimination (B&gt;C) across 20 trial (~59%). This pattern continued down the hierarchy such that, after a discrimination had been introduced, the number of times it was tested in subsequent epochs linearly decreased but remained above zero so that all discriminations were tested in the final epoch (see <xref ref-type="fig" rid="F1">Figure 1D</xref>). Full details of this training procedure are provided on the OSF (<ext-link ext-link-type="uri" xlink:href="https://osf.io/uzyb7/">https://osf.io/uzyb7/</ext-link>).</p><p id="P59">Regardless of the training condition that participants were assigned to, all pairwise discriminations were tested 60 times each by the end of the training procedure (i.e., 360 trials in total, ~37 minutes). Before the first training session, participants were briefed on the experimental procedure and told that the wall textures were the only features that predicted reward. These instructions specified that each wall texture should be considered as a single separate ‘pattern’, and that may either conceal the reward or not, depending on the other wall texture presented within the scene. They were not given any other details regarding the number or type of discriminations.</p></sec><sec id="S12"><title>In-scanner task</title><p id="P60">Following the second training session, participants were tested on the 6 directly trained (premise) discriminations, and a set of 6 transitive inferences (e.g., B&gt;D), whilst being scanned (see <xref ref-type="fig" rid="F1">Figure 1B</xref>). This tapped knowledge acquired during both of the preceding training sessions. Note that the inferred discriminations did not involve wall-texture stimuli from the ends of each hierarchy (i.e., A and G). This is because discriminations involving these terminal stimuli may be made by applying simple feature-based response policies (i.e., “Always select A”, “Always avoid G”), without the need to use a generalised value function.</p><p id="P61">Similar to the training task, all in-scanner trials initially depicted the participant at a start location in front of two buildings. Participants were instructed to select the building that they believed contained virtual gold based on what they had learned during training. Guesses were strongly encouraged if the participant was not confident. Unlike the previous training sessions, the image of the start location persisted on-screen throughout the 3-second response window regardless of when/whether a response was made. Importantly, no feedback videos were shown during the in-scanner task meaning that participants could not (re-)learn the contingencies via external feedback. Following the response window, a fixation cross was displayed centrally for 3.5 seconds before the next trial commenced.</p><p id="P62">The in-scanner task tested each premise/inferred discrimination 8 times (the higher value wall-texture appeared on the left-hand building in exactly 50% of trials). As such, the task involved a total of 192 trials: 2 trial types (premise vs inferred) x 2 training sessions (recent vs remote) x 6 unique discriminations x 8 repetitions. Additionally, we included 16 null events (lasting 6.5 seconds each) in order to facilitate the estimation of a resting baseline. All trials were presented in a single run and progressed in a pseudorandom order that was determined by an optimization procedure to enable maximally efficient decoding of trial-specific BOLD responses (<ext-link ext-link-type="uri" xlink:href="https://osf.io/eczif/">https://osf.io/eczif/</ext-link>).</p></sec><sec id="S13"><title>Refresher task</title><p id="P63">As noted, participants were trained on 2 independent sets of premise discriminations in pre-scanner training sessions that occurred approximately 24 hours apart. The wall-textures used in each session were counterbalanced across participants. Just before entering the scanner, participants practised each of the directly trained discriminations in a short refresher task. This ran identically to the training tasks but only included 12 trails of each discrimination (lasting approximately 15 minutes). The refresher was not intended to act as an additional training phase but served to remind participants of the appearance of all wall textures so that they were easily identifiable.</p></sec></sec><sec id="S14"><title>Analysis of in-scanner performance</title><p id="P64">We used a generalised-linear mixed-effects model (GLMM) to characterise the pattern of correct vs incorrect responses during the in-scanner task. Specifically, this tested the relationship between response accuracy and 3 binary-coded fixed-effect predictors: <italic>1)</italic> trial type (premise vs inferred), <italic>2)</italic> training method (interleaved vs progressive), and <italic>3)</italic> training session (recent vs remote). Additionally, a continuous (mean-centered) fixed-effect predictor accounted for the effect of transitive distance on inference trials. All possible interactions between these variables were included meaning that the model consisted of 12 fixed-effects coefficients in total (including the intercept term). We also included random intercepts and slopes for each within-subject variable (grouped by participant), and random intercepts for each unique wall-texture discrimination (to account for any stimulus specific effects). Covariance components between random effects were fully estimated from the data.</p><p id="P65">The outcome variable was the number of correct responses to the 8 repeated trials for each in-scanner discrimination. This outcome was modelled as a binomial process such that parameter estimates encoded the probability of a correct response on a single trial, <italic>Pr</italic>(<italic>correct</italic>). To avoid any biases resulting from failures to respond (1.81% of trials on average), we resampled missing responses as random guesses with a 50% probability of success. The model used a logit link-function and was estimated via maximum pseudo-likelihood using the Statistics and Machine Learning toolbox in MATLAB R2020a (The MathWorks Inc.).</p><p id="P66">In addition to the model of response accuracy, we estimated a similar GLMM that characterised behavioural patterns in response latencies (correct trials only). This GLMM used exactly the same fixed- and random-effect predictors as above. Response times were modelled using a log link-function and the distribution of observations was parameterised by the gamma distribution. As before, the model was fit via maximum pseudo-likelihood in MATLAB.</p></sec><sec id="S15"><title>Computational models of inference performance</title><p id="P67">We predicted that inference performance would vary by experimental condition due to differences in the way inferences were made, but not because of any differences in performance for the directly trained discriminations. To test this, we produced two competing models of the behavioural data referred to as the AND and OR models. Both of these attempted to predict participants’ inference performance given responses to the directly trained discriminations alone.</p><p id="P68">The AND model assumes that correctly inferring a non-trained discrimination (e.g., ‘B&gt;E’) involves retrieving all the directly learnt response contingencies required to reconstruct the relevant transitive hierarchy (e.g., ‘B&gt;C’ and ‘C&gt;D’ and ‘D&gt;E’). We refer to these directly trained discriminations as “mediating contingencies”. As such, this model captures a common assumption of retrieval-based models of generalisation.</p><p id="P69">In contrast, the OR model assumes that participants have access to a unified structural representation describing the associative distances between all stimuli. Nonetheless, in order to make a successful inference, knowledge of this associative structure must be evaluated alongside the reward contingencies indicating which of the presented stimuli is higher in the reward hierarchy. When making an inference (e.g., B&gt;E), it is therefore sufficient to recall only one of the contingencies indicating which stimulus should be preferred (e.g., B&gt;C), or which stimulus should be avoided (e.g., D&gt;E).</p><p id="P70">Note, these models are not intended to be process model that describe how humans solve the task at the algorithmic level. They are merely intended to describe the data and test whether the behaviour in each condition better accord with general predictions of encoding and retrieval models.</p><p id="P71">To formalise both models, we first computed a likelihood function describing plausible values for the probability of correctly retrieving each premise discrimination (<italic>r<sub>p</sub></italic>, where the index <italic>p</italic> denotes a specific premise discrimination). To do this we assume the probability of observing <italic>k<sub>p</sub></italic> correct responses, to the <italic>n</italic> = 8 test trials, depends on a joint binomial process involving <italic>r<sub>p</sub></italic> and, if retrieval is not successful, a random guess that yields a correct response with a probability of 0.5: <disp-formula id="FD1"><label>Eq. 1</label><mml:math id="M1"><mml:mrow><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mi>∑</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:mfrac><mml:mrow><mml:mi>n</mml:mi><mml:mo>!</mml:mo></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>!</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>!</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>!</mml:mo></mml:mrow></mml:mfrac><mml:msub><mml:mi>r</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:msup><mml:mrow><mml:mspace width="0.2em"/></mml:mrow><mml:mi>m</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p id="P72">From this, the likelihood function for the parameter <italic>r<sub>p</sub></italic> (denoted <italic>L</italic>(<italic>r<sub>p</sub></italic>|<italic>k<sub>p</sub>,n</italic>)) is given by dividing out a normalising constant, <italic>c</italic>(<italic>k<sub>p</sub></italic>|<italic>n</italic>), computed by numerical integration: <disp-formula id="FD2"><label>Eq. 2</label><mml:math id="M2"><mml:mrow><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula> Where: <disp-formula id="FD3"><label>Eq. 3</label><mml:math id="M3"><mml:mrow><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mn>1</mml:mn></mml:msubsup><mml:mrow><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mspace width="0.2em"/><mml:mi>r</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula> <xref ref-type="supplementary-material" rid="SD4">S2 Figure</xref> A displays the likelihood function for <italic>r<sub>p</sub></italic> under different values of <italic>k<sub>p</sub></italic>. Based on these likelihoods, we then sampled random values of <italic>r<sub>p</sub></italic> for each premise discrimination that mediated the generalisation trails. To do this, we used an inverse transform sampling method where a value of <italic>r<sub>p</sub></italic> was selected such that the cumulative likelihood up to that value (i.e., <inline-formula><mml:math id="M4"><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:msubsup><mml:mrow><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></inline-formula>) was equal to a unique, uniformly distributed random number in the range [0,1] (see <xref ref-type="supplementary-material" rid="SD4">S2 Figure B</xref>).</p><p id="P73">As noted, the AND model assumes that a non-trained discrimination depends on successfully retrieving all the reward contingencies that span the transitive hierarchy between presented stimuli. We denote the set of sampled <italic>r<sub>p</sub></italic> values related to these mediating contingencies <italic>A<sub>i</sub></italic>, where the index <italic>i</italic> denotes a specific non-trained discrimination, and the number of elements in <italic>A<sub>i</sub></italic> is equal to the transitive distance. Given the sampled values in <italic>A<sub>i</sub></italic>, we therefore computed the probability this for each non-trained discrimination (denoted <inline-formula><mml:math id="M5"><mml:mrow><mml:msubsup><mml:mi>g</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>): <disp-formula id="FD4"><label>Eq. 4</label><mml:math id="M6"><mml:mrow><mml:msubsup><mml:mi>g</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>κ</mml:mi><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∏</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p id="P74">The constant term κ is a scalar value in the range [0,1] that determines the probability of engaging in memory-guided generalisations rather than simply guessing. This parameter was fit to the inference data by a bounded nonlinear optimiser (“fmincon”, MATLAB Optimization Toolbox, R2020a). Specifically, given the sampled values in <italic>A<sub>i</sub></italic>, the optimiser was tasked with finding a single value of κ across all inference trials from a particular participant/condition that minimised a cross-entropy term (<italic>H</italic>) relating model predictions to the observed inference data (see <ext-link ext-link-type="uri" xlink:href="https://osf.io/a6w9t">https://osf.io/a6w9t</ext-link>). <italic>H</italic> was based on <xref ref-type="disp-formula" rid="FD7">equation 7</xref> and describes the mean log-probability of observing <italic>k<sub>i</sub></italic> correct responses to all inference trials.</p><p id="P75">The OR model assumes that performance on the non-trained discriminations depend on successfully retrieving either of the reward contingencies indicating which stimulus should be preferred or avoided. We denote the set of sampled <italic>r<sub>p</sub></italic> values related to these two contingencies <italic>O<sub>i</sub></italic>, and computed the probability of successful inference under the OR model (<inline-formula><mml:math id="M7"><mml:mrow><mml:msubsup><mml:mi>g</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>) as follows: <disp-formula id="FD5"><label>Eq. 5</label><mml:math id="M8"><mml:mrow><mml:msubsup><mml:mi>g</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>κ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∏</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p id="P76">Note that the value of κ was estimated as above, but independently for each model. We then computed model-derived probabilities for the number of correct inference responses <italic>k<sub>i</sub></italic> to the <italic>n</italic> = 8 inference trials (similar to <xref ref-type="disp-formula" rid="FD1"><italic>Eq. 1</italic></xref>): <disp-formula id="FD6"><label>Eq. 6</label><mml:math id="M9"><mml:mrow><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mi>∑</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:mfrac><mml:mrow><mml:mi>n</mml:mi><mml:mo>!</mml:mo></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>!</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>!</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>!</mml:mo></mml:mrow></mml:mfrac><mml:msubsup><mml:mi>g</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p id="P77">In order to estimate the expected distribution of <italic>Pr</italic> (<italic>k<sub>i</sub></italic>|<italic>n, g<sub>i</sub></italic>) for each type of inference, we repeatedly sampled sets of <italic>R<sub>i</sub></italic> over 10000 iterations using the aforementioned likelihood functions (<xref ref-type="disp-formula" rid="FD2"><italic>Eq. 2</italic></xref>). The cross entropy <italic>H</italic> of each model was then taken as the mean negative log probability over all <italic>I</italic> inferences in a particular condition, from a particular participant: <disp-formula id="FD7"><label>Eq. 7</label><mml:math id="M10"><mml:mrow><mml:mi>H</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>I</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munderover><mml:mi>∑</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>I</mml:mi></mml:munderover><mml:mrow><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p id="P78">To analyse condition-dependent differences in the cross-entropy statistics, we entered them into a GLMM with 3 binary-coded fixed effect predictors: <italic>1)</italic> inference model (AND vs OR), <italic>2)</italic> training method (interleaved vs progressive), and <italic>3)</italic> training session (recent vs remote). All possible interactions between these predictors were also included. The GLMM further contained random intercepts and slopes of each fixed effect (grouped by participant), with a covariance pattern that was fully estimated form the data. Cross-entropy was modelled using a log link-function and the distribution of observations was parameterised by the gamma distribution. The model was fitted via maximum pseudo-likelihood in MATLAB.</p><p id="P79">Although the gradient of transitive slopes may also be used to differentiate encoding vs retrieval-based mechanisms [<xref ref-type="bibr" rid="R5">5</xref>,<xref ref-type="bibr" rid="R26">26</xref>], the approach outlined above explicitly accounts for differences in premise trial performance that can otherwise confound the analysis. For instance, discriminations between stimuli separated by a larger transitive distance are more likely to involve reward contingencies that can be remembered either better or worse than most others. This may have non-linear effects on inferential accuracy thereby obscuring, or even reversing, the direction of transitive slopes. Our computational models overcome this problem by explicitly accounting for the profile of premise trial performance.</p></sec><sec id="S16"><title>MRI acquisition</title><p id="P80">All functional and structural volumes were acquired on a 1.5 Tesla Siemens Avanto scanner equipped with a 32-channel phased-array head coil. T2*-weighted scans were acquired with echo-planar imaging (EPI), 34 axial slices (approximately 30° to AC-PC line; interleaved) and the following parameters: repetition time = 2520 ms, echo time = 43 ms, flip angle = 90°, slice thickness = 3 mm, inter-slice gap = 0.6 mm, in-plane resolution = 3 × 3 mm. The number of volumes acquired during the in-scanner task was 537. To allow for T1 equilibrium, the first 3 EPI volumes were acquired prior to the task starting and then discarded. Subsequently, a field map was captured to allow the correction of geometric distortions caused by field inhomogeneity (see the MRI pre-processing section below). Finally, for purposes of co-registration and image normalization, a whole-brain T1-weighted structural scan was acquired with a 1mm<sup>3</sup> resolution using a magnetization-prepared rapid gradient echo pulse sequence.</p></sec><sec id="S17"><title>MRI pre-processing</title><p id="P81">Image pre-processing was performed in SPM12 (<ext-link ext-link-type="uri" xlink:href="https://www.fil.ion.ucl.ac.uk/spm">www.fil.ion.ucl.ac.uk/spm</ext-link>). This involved spatially realigning all EPI volumes to the first image in the time series. At the same time, images were corrected for geometric distortions caused by field inhomogeneities (as well as the interaction between motion and such distortions) using the Realign and Unwarp algorithms in SPM [<xref ref-type="bibr" rid="R65">65</xref>,<xref ref-type="bibr" rid="R66">66</xref>]. All BOLD effects of interest were derived from a set of first-level general linear models (GLM) of the unsmoothed EPI data in native space. Here, we estimated univariate responses to the 24 discriminations (i.e., 6 premise + 6 inferred, from each day) using the least-squares-separate method [<xref ref-type="bibr" rid="R67">67</xref>]. To do this, a unique GLM was constructed for each discrimination such that one event regressor modelled the effect of that discrimination while a second regressor accounted for all other discriminations. As such, one beta estimate from each model encoded the BOLD response for a particular discrimination. These models also included the following nuisance regressors: 6 affine motion parameters, their first-order derivatives, squared values of the motion parameters and derivatives, and a Fourier basis set implementing a 1/128 Hz high-pass filter.</p><p id="P82">For the analysis of univariate BOLD activity, the 24 beta estimates related to each discrimination were averaged within regions of interest and entered into a linear mixed-effects regression model (see ‘Analysis of univariate BOLD’ below). For the RSA, these beta estimates were linearly decomposed into voxel-wise representations of each wall texture in the reinforcement learning task (n=7 per transitive chain). This decomposition involved multiplying the 24 beta values from a given voxel with a 15*24 transformation matrix that encoded the occurrence of each wall texture across discriminations (see <xref ref-type="fig" rid="F5">Figure 5A</xref>). The first 7 outputs of this transformation related to the recently learnt wall textures, the second 7 outputs related to remotely learnt wall textures, and the final output encoded overall BOLD differences between premise and inferred trials (a nuisance term that was not included in any further analysis). Importantly, BOLD representations for wall textures ‘A’ and ‘G’ may have trivially differed from all other patterns since these stimuli were only presented in premise trails and so were only shown alongside one other wall texture (‘B’ and ‘F’, respectively). As such, similarity scores involving the ‘A’ and ‘G’ patterns were excluded from the RSA leaving only scores related to ‘B’, ‘C’, ‘D’, ‘E’, and ‘F’.</p></sec><sec id="S18"><title>Regions of interest</title><p id="P83">Numerous studies have implicated the hippocampus, entorhinal cortex, and medial prefrontal cortices in memory generalisations [<xref ref-type="bibr" rid="R4">4</xref>,<xref ref-type="bibr" rid="R7">7</xref>,<xref ref-type="bibr" rid="R19">19</xref>,<xref ref-type="bibr" rid="R10">10</xref>–<xref ref-type="bibr" rid="R17">17</xref>]. As such, our a priori ROIs comprised 8 binary masks that covered all of area in native space (separately in each hemisphere). This was done by transforming group-level masks in MNI space using the inverse warp utility in SPM12. For the hippocampus, we used an MNI mask provided by Ritchey et al [<xref ref-type="bibr" rid="R68">68</xref>]. The entorhinal masks were derived from the maximum probability tissue labels provided by Neuromorphometrics Inc. Finally, 4 separate masks corresponding to the left and right inferior and superior MPFC were defined from a parcellation that divided the cortex into 100 clusters based on 17 resting-state networks identified by Schaefer et al [<xref ref-type="bibr" rid="R69">69</xref>]. Normalised group averages of each ROI used in our main analyses are shown in <xref ref-type="supplementary-material" rid="SD6">S3 Figure</xref> and are available at <ext-link ext-link-type="uri" xlink:href="https://osf.io/tvk43/">https://osf.io/tvk43/</ext-link>.</p><p id="P84">Notably, the MPFC ROIs that we selected for a priori analyses were relatively large compared to the hippocampal and entorhinal ROIs. As such, we provide supplementary analyses of the MPFC based on a finer, 400 cluster, parcellation of the Schaefer et al networks (see <xref ref-type="supplementary-material" rid="SD7">S3 Text</xref>).</p></sec><sec id="S19"><title>Analysis of univariate BOLD</title><p id="P85">Univariate BOLD effects were investigated within a set of linear mixed-effects models (LMMs). These characterised condition-dependent differences in ROI-averaged beta estimates that derived from a first level GLM of the in-scanner task (see ‘MRI pre-processing’ above). The LMMs included 3 binary-coded fixed-effect predictor variables: <italic>1)</italic> trial type (premise vs inferred), <italic>2)</italic> training method (interleaved vs progressive), and <italic>3)</italic> training session (recent vs remote). Additionally, 3 mean-centred continuous fixed-effects were included: <italic>i)</italic> inference accuracy (averaged across discriminations, per participant, per session), <italic>ii)</italic> ‘transitive slope’ (the simple correlation between transitive distance and accuracy, per participant, per session), and <italic>iii)</italic> transitive distance per se (applied to inference trials only). All interactions between these variables were also included (excluding interactions between the continuous predictors) meaning that the model consisted of 28 fixed-effects coefficients in total (including the intercept term). We also included random intercepts and slopes for each within-subject fixed-effect (group by participant), as well as random intercepts for each unique wall-texture discrimination (both grouped and ungrouped by participant). Covariance components between random effects were fully estimated from the data. The model used an identity link-function and was estimated via maximum likelihood in MATLAB.</p></sec><sec id="S20"><title>Representational similarity analysis</title><p id="P86">Condition-dependent differences in the similarity between wall-texture representations were also investigated using LMMs. To generate these models, we first estimated BOLD similarity in each ROI by producing a pattern-by-pattern correlation matrix from the decomposed wall-texture representations (including wall textures ‘B’ to ‘F’ only, see ‘MRI pre-processing’). The resulting correlation coefficients were then Fisher-transformed before being entered into each LMM as an outcome variable. These models were structured to predict the Fisher-transformed similarity scores as a function of various predictors of interest. As above, covariance components between random effects were fully estimated from the data. The models used an identity link-function and were estimated via maximum likelihood in MATLAB.</p><p id="P87">Critically, the temporal structure of the in-scanner task and least-squared decomposition procedure introduced nuisance correlations between wall texture representations. To account for these, we derived two predictor variables of no-interest and used them to model nuisance effects in each LMM described below. The first predictor accounted for trivial correlations resulting from shared sources of noise across co-presented wall textures. This was taken as the Fisher-transformed correlation between binary vectors encoding whether each pair of wall textures were presented in same the in-scanner trails. Across analyses, this predictor invariably accounted for a significant amount of variance in the similarity scores, <italic>r</italic> ∈ [0.105, 0.277].</p><p id="P88">The second predictor of no-interest modelled nuisance correlations attributable to the temporal proximity of trials during the in-scanner task and the pattern decomposition procedure itself. To estimate these correlations, we simulated independent, normally distributed voxel patterns for all wall textures across a large number of iterations, mixed them together in accordance with the trial timings for each subject, and re-estimated the voxel patterns using the least-squares-separate decomposition procedure outlined above. The predictor of no-interest was then taken as the mean Fisher-transformed correlation between simulated wall-textures across iterations. Using this procedure, we aimed to model the effect of fMRI repetition suppression by parametrically modulating the simulated BOLD responses such that repeated presentations evoked an attenuated response. This adjustment was based on Fritsche et al [<xref ref-type="bibr" rid="R70">70</xref>] who report that repetition suppression effects in the parahippocampal cortex yield a BOLD attenuation of approximately 23% following a 100ms delay, and 10% following a 1 second delay. Given this, we applied repetition suppression effects assuming an exponential recovery from adaptation over time. Our simulations showed that the presence of such effects did not notably bias BOLD pattern recovery. Furthermore, the temporal signal-to-noise ratio of the fMRI signal had little effect on the correlational structure of the recovered BOLD patterns. Nonetheless, the simulations did reveal some minor nuisance correlations that tended to account for a significant amount of variance in the pattern similarity scores, <italic>r</italic> ∈ [0.001, 0.183].</p><sec id="S21"><title>Within-hierarchy RSA</title><p id="P89">The first set of similarity analyses tested for differences between wall-texture representations from the same transitive hierarchy. Similar to the models described previously, these LMMs included 5 fixed-effect predictors of interest: <italic>1)</italic> training method, <italic>2)</italic> training session, <italic>3)</italic> transitive distance, <italic>4)</italic> inference accuracy, and <italic>5)</italic> transitive slope. All interactions between these variables were also included (excluding interactions between inference accuracy and transitive slope). The LMMs also included random intercepts and slopes for each effect derived from a repeated measure variable. Finally, the models comprised an extensive set of random intercepts and slopes (grouped by participant) that accounted for all dependencies between pattern correlations (see <ext-link ext-link-type="uri" xlink:href="https://osf.io/jwaek">https://osf.io/jwaek</ext-link>).</p></sec><sec id="S22"><title>Across-hierarchy RSA</title><p id="P90">The second set of similarity analyses tested for differences between wall-texture representations from different transitive hierarchies (i.e., those learnt in different training sessions). These LMMs included 4 fixed-effect predictors of interest: <italic>1)</italic> training method, <italic>2)</italic> transitive distance, <italic>3)</italic> inference accuracy, and <italic>4)</italic> transitive slope. Note that the effect of training session was not included as did not apply when examining the similarity between representations learnt in different sessions. As before, the effect of transitive distance accounted for comparisons between wall-textures at different levels of the hierarchy. However, in this set of models, the distance predictor included an additional level (Δ0), corresponding to comparisons between wall-textures at the same hierarchical level. The across-hierarchy LMMs included the same nuisance variables and random-effects as in the within-hierarchy RSA (<ext-link ext-link-type="uri" xlink:href="https://osf.io/cjv7h">https://osf.io/cjv7h</ext-link>).</p></sec></sec><sec id="S23"><title>Statistical validation and inference</title><p id="P91">To ensure that each linear mixed-effects regression model was not unduly influenced by outlying data points, we systematically excluded observations that produced unexpectedly large residual values above or below model estimates. The threshold for excluding data points was based on the number of observations in each model rather than a fixed threshold heuristic. We chose to do this because the expected range of normally distributed residual values depends on the sample size which varied between models. Across all linear models, we excluded data points that produced an absolute standardised residual larger than the following cut-off threshold (<italic>z</italic>): <disp-formula id="FD8"><label>Eq. 8</label><mml:math id="M11"><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>Φ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mn>2</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> Where, Φ<sup>–1</sup>is the Probit function, and <italic>n</italic> is the sample size. This threshold was chosen as it represents the bounds of a standard normal distribution that will contain all <italic>n</italic> normally distributed data points of a random sample, 50% of the time. The value of <italic>z</italic> is approximately 2.7 when <italic>n</italic> = 100 and 3.4 when <italic>n</italic> = 1000. After excluding outliers, Kolmogorov-Smirnov tests indicated that the residuals were normally distributed across all the linear mixed-effects models (across analyses, the proportion of excluded outliers ranged between 0 and 0.941%; see <ext-link ext-link-type="uri" xlink:href="https://osf.io/cvm3r">https://osf.io/cvm3r</ext-link>). Additionally, visual inspection of scatter plots showing residual versus predicted scores indicated no evidence of heteroscedasticity, non-linearity or overly influential datapoints (see <ext-link ext-link-type="uri" xlink:href="https://osf.io/zpumq">https://osf.io/zpumq</ext-link>).</p><p id="P92">All <italic>p</italic>-values are reported as two-tailed statistics. Unless otherwise stated, we only report significant effects from the fMRI analyses that survive a Bonferroni correction for multiple comparisons across our 8 regions of interest.</p></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>S1 Figure</label><media xlink:href="EMS150780-supplement-S1_Figure.tif" mimetype="image" mime-subtype="tiff" id="d21aAdEbB" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD2"><label>S1 Table</label><media xlink:href="EMS150780-supplement-S1_Table.pdf" mimetype="application" mime-subtype="pdf" id="d21aAdEcB" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD3"><label>S1 Text</label><media xlink:href="EMS150780-supplement-S1_Text.pdf" mimetype="application" mime-subtype="pdf" id="d21aAdEdB" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD4"><label>S2 Figure</label><media xlink:href="EMS150780-supplement-S2_Figure.tif" mimetype="image" mime-subtype="tiff" id="d21aAdEeB" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD5"><label>S2 Text</label><media xlink:href="EMS150780-supplement-S2_Text.pdf" mimetype="application" mime-subtype="pdf" id="d21aAdEfB" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD6"><label>S3 Figure</label><media xlink:href="EMS150780-supplement-S3_Figure.tif" mimetype="image" mime-subtype="tiff" id="d21aAdEgB" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD7"><label>S3 Text</label><media xlink:href="EMS150780-supplement-S3_Text.pdf" mimetype="application" mime-subtype="pdf" id="d21aAdEhB" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD8"><label>Legends for supplementary information</label><media xlink:href="EMS150780-supplement-Legends_for_supplementary_information.pdf" mimetype="application" mime-subtype="pdf" id="d21aAdEiB" position="anchor"/></supplementary-material></sec></body><back><ack id="S24"><title>Acknowledgments</title><p>This work was supported by a European Research Council Consolidator Grant awarded to C.M.B. (Project: EVENTS). We are grateful to Prof Neil Burgess and Prof Anil Seth for feedback on early drafts of the article manuscript.</p></ack><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Potts</surname><given-names>GR</given-names></name></person-group><article-title>Information processing strategies used in the encoding of linear orderings</article-title><source>J Verbal Learning Verbal Behav</source><year>1972</year><volume>11</volume><fpage>727</fpage><lpage>740</lpage><pub-id pub-id-type="doi">10.1016/S0022-5371(72)80007-0</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Potts</surname><given-names>GR</given-names></name></person-group><article-title>Storing and retrieving information about ordered relationships</article-title><source>J Exp Psychol</source><year>1974</year><volume>103</volume><fpage>431</fpage><lpage>439</lpage><pub-id pub-id-type="doi">10.1037/h0037408</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumaran</surname><given-names>D</given-names></name><name><surname>McClelland</surname><given-names>JL</given-names></name></person-group><article-title>Generalization through the recurrent interaction of episodic memories: A model of the hippocampal system</article-title><source>Psychol Rev</source><year>2012</year><volume>119</volume><fpage>573</fpage><lpage>616</lpage><pub-id pub-id-type="doi">10.1037/a0028681</pub-id></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koster</surname><given-names>R</given-names></name><name><surname>Chadwick</surname><given-names>MJ</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Berron</surname><given-names>D</given-names></name><name><surname>Banino</surname><given-names>A</given-names></name><name><surname>Düzel</surname><given-names>E</given-names></name><etal/></person-group><article-title>Big-Loop Recurrence within the Hippocampal System Supports Integration of Information across Episodes</article-title><source>Neuron</source><year>2018</year><volume>99</volume><fpage>1342</fpage><lpage>1354</lpage><elocation-id>e6</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuron.2018.08.009</pub-id></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Banino</surname><given-names>A</given-names></name><name><surname>Koster</surname><given-names>R</given-names></name><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Kumaran</surname><given-names>D</given-names></name></person-group><article-title>Retrieval-Based Model Accounts for Striking Profile of Episodic Memory and Generalization</article-title><source>Sci Rep</source><year>2016</year><volume>6</volume><fpage>1</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1038/srep31330</pub-id></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumaran</surname><given-names>D</given-names></name><name><surname>Banino</surname><given-names>A</given-names></name><name><surname>Blundell</surname><given-names>C</given-names></name><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><article-title>Computations Underlying Social Hierarchy Learning: Distinct Neural Mechanisms for Updating and Representing Self-Relevant Information</article-title><source>Neuron</source><year>2016</year><volume>92</volume><fpage>1135</fpage><lpage>1147</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.10.052</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whittington</surname><given-names>JCR</given-names></name><name><surname>Muller</surname><given-names>TH</given-names></name><name><surname>Mark</surname><given-names>S</given-names></name><name><surname>Chen</surname><given-names>G</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name><etal/></person-group><article-title>The Tolman-Eichenbaum Machine: Unifying Space and Relational Memory through Generalization in the Hippocampal Formation</article-title><source>Cell</source><year>2020</year><volume>183</volume><fpage>1249</fpage><lpage>1263</lpage><elocation-id>e23</elocation-id><pub-id pub-id-type="doi">10.1016/j.cell.2020.10.024</pub-id></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ciranka</surname><given-names>S</given-names></name><name><surname>Linde-Domingo</surname><given-names>J</given-names></name><name><surname>Padezhki</surname><given-names>I</given-names></name><name><surname>Wicharz</surname><given-names>C</given-names></name><name><surname>Wu</surname><given-names>CM</given-names></name><name><surname>Spitzer</surname><given-names>B</given-names></name></person-group><article-title>Asymmetric reinforcement learning facilitates human inference of transitive relations</article-title><source>Nat Hum Behav</source><year>2022</year><fpage>1</fpage><lpage>36</lpage><pub-id pub-id-type="doi">10.1038/s41562-021-01263-w</pub-id></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jensen</surname><given-names>G</given-names></name><name><surname>Muñoz</surname><given-names>F</given-names></name><name><surname>Alkan</surname><given-names>Y</given-names></name><name><surname>Ferrera</surname><given-names>VP</given-names></name><name><surname>Terrace</surname><given-names>HS</given-names></name></person-group><article-title>Implicit Value Updating Explains Transitive Inference Performance: The Betasort Model</article-title><source>PLoS Comput Biol</source><year>2015</year><volume>11</volume><fpage>1</fpage><lpage>27</lpage><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004523</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeithamova</surname><given-names>D</given-names></name><name><surname>Dominick</surname><given-names>A</given-names></name><name><surname>Preston</surname><given-names>AR</given-names></name></person-group><article-title>Hippocampal and Ventral Medial Prefrontal Activation during Retrieval-Mediated Learning Supports Novel Inference</article-title><year>2012</year><volume>75</volume><fpage>168</fpage><lpage>179</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.05.010</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><article-title>Complementary learning systems within the hippocampus: A neural network modelling approach to reconciling episodic memory with statistical learning</article-title><source>Philos Trans R Soc B Biol Sci</source><year>2017</year><volume>372</volume><pub-id pub-id-type="doi">10.1098/rstb.2016.0049</pub-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferreira</surname><given-names>CS</given-names></name><name><surname>Charest</surname><given-names>I</given-names></name><name><surname>Wimber</surname><given-names>M</given-names></name></person-group><article-title>Retrieval aids the creation of a generalised memory trace and strengthens episode-unique information</article-title><source>Neuroimage</source><year>2019</year><volume>201</volume><elocation-id>115996</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.07.009</pub-id></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morton</surname><given-names>NW</given-names></name><name><surname>Schlichting</surname><given-names>ML</given-names></name><name><surname>Preston</surname><given-names>AR</given-names></name></person-group><article-title>Representations of common event structure in medial temporal lobe and frontoparietal cortex support efficient inference</article-title><source>Proc Natl Acad Sci U S A</source><year>2020</year><volume>117</volume><fpage>29338</fpage><lpage>29345</lpage><pub-id pub-id-type="doi">10.1073/pnas.1912338117</pub-id></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaplan</surname><given-names>R</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><article-title>Hippocampal-entorhinal transformations in abstract frames of reference</article-title><source>Entorhinal Transform Abstr Fram Ref</source><year>2018</year><elocation-id>414524</elocation-id><pub-id pub-id-type="doi">10.1101/414524</pub-id></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tavares</surname><given-names>RM</given-names></name><name><surname>Mendelsohn</surname><given-names>A</given-names></name><name><surname>Grossman</surname><given-names>Y</given-names></name><name><surname>Williams</surname><given-names>CH</given-names></name><name><surname>Shapiro</surname><given-names>M</given-names></name><name><surname>Trope</surname><given-names>Y</given-names></name><etal/></person-group><article-title>A Map for Social Navigation in the Human Brain</article-title><source>Neuron</source><year>2015</year><volume>87</volume><fpage>231</fpage><lpage>243</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.06.011</pub-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumaran</surname><given-names>D</given-names></name><name><surname>Melo</surname><given-names>HL</given-names></name><name><surname>Duzel</surname><given-names>E</given-names></name></person-group><article-title>The Emergence and Representation of Knowledge about Social and Nonsocial Hierarchies</article-title><source>Neuron</source><year>2012</year><volume>76</volume><fpage>653</fpage><lpage>666</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.09.035</pub-id></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>J</given-names></name><name><surname>Gardner</surname><given-names>MPH</given-names></name><name><surname>Stalnaker</surname><given-names>TA</given-names></name><name><surname>Ramus</surname><given-names>SJ</given-names></name><name><surname>Wikenheiser</surname><given-names>AM</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Rat Orbitofrontal Ensemble Activity Contains Multiplexed but Dissociable Representations of Value and Task Structure in an Odor Sequence Task</article-title><source>Curr Biol</source><year>2019</year><volume>29</volume><fpage>897</fpage><lpage>907</lpage><elocation-id>e3</elocation-id><pub-id pub-id-type="doi">10.1016/j.cub.2019.01.048</pub-id></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaefer</surname><given-names>K</given-names></name><name><surname>Nardin</surname><given-names>M</given-names></name><name><surname>Blahna</surname><given-names>K</given-names></name><name><surname>Csicsvari</surname><given-names>J</given-names></name></person-group><article-title>Replay of Behavioral Sequences in the Medial Prefrontal Cortex during Rule Switching</article-title><source>Neuron</source><year>2020</year><volume>106</volume><fpage>154</fpage><lpage>165</lpage><elocation-id>e6</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuron.2020.01.015</pub-id></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baram</surname><given-names>AB</given-names></name><name><surname>Muller</surname><given-names>TH</given-names></name><name><surname>Nili</surname><given-names>H</given-names></name><name><surname>Garvert</surname><given-names>MM</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name></person-group><article-title>Entorhinal and ventromedial prefrontal cortices abstract and generalize the structure of reinforcement learning problems</article-title><source>Neuron</source><year>2021</year><volume>109</volume><fpage>713</fpage><lpage>723</lpage><elocation-id>e7</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuron.2020.11.024</pub-id></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>SA</given-names></name><name><surname>Miller</surname><given-names>DS</given-names></name><name><surname>Nili</surname><given-names>H</given-names></name><name><surname>Ranganath</surname><given-names>C</given-names></name><name><surname>Boorman</surname><given-names>ED</given-names></name></person-group><article-title>Map Making: Constructing, Combining, and Inferring on Abstract Cognitive Maps</article-title><source>Neuron</source><year>2020</year><volume>107</volume><fpage>1226</fpage><lpage>1238</lpage><elocation-id>e8</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuron.2020.06.030</pub-id></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luyckx</surname><given-names>F</given-names></name><name><surname>Nili</surname><given-names>H</given-names></name><name><surname>Spitzer</surname><given-names>B</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name></person-group><article-title>Neural structure mapping in human probabilistic reward learning</article-title><source>Elife</source><year>2019</year><volume>8</volume><fpage>1</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.7554/eLife.42816</pub-id></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>D’Amato</surname><given-names>MR</given-names></name><name><surname>Colombo</surname><given-names>M</given-names></name></person-group><article-title>The symbolic distance effect in monkeys (Cebus apella)</article-title><source>Anim Learn Behav</source><year>1990</year><volume>18</volume><fpage>133</fpage><lpage>140</lpage><pub-id pub-id-type="doi">10.3758/BF03205250</pub-id></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gazes</surname><given-names>RP</given-names></name><name><surname>Chee</surname><given-names>NW</given-names></name><name><surname>Hampton</surname><given-names>RR</given-names></name></person-group><article-title>Cognitive mechanisms for transitive inference performance in rhesus monkeys: Measuring the influence of associative strength and inferred order</article-title><source>J Exp Psychol Anim Behav Process</source><year>2012</year><volume>38</volume><fpage>331</fpage><lpage>345</lpage></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jensen</surname><given-names>G</given-names></name><name><surname>Altschul</surname><given-names>D</given-names></name><name><surname>Danly</surname><given-names>E</given-names></name><name><surname>Terrace</surname><given-names>H</given-names></name></person-group><article-title>Transfer of a Serial Representation between Two Distinct Tasks by Rhesus Macaques</article-title><source>PLoS One</source><year>2013</year><volume>8</volume><pub-id pub-id-type="doi">10.1371/journal.pone.0070285</pub-id></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jensen</surname><given-names>G</given-names></name><name><surname>Alkan</surname><given-names>Y</given-names></name><name><surname>Ferrera</surname><given-names>VP</given-names></name><name><surname>Terrace</surname><given-names>HS</given-names></name></person-group><article-title>Reward associations do not explain transitive inference performance in monkeys</article-title><source>Sci Adv</source><year>2019</year><volume>5</volume><pub-id pub-id-type="doi">10.1126/sciadv.aaw2089</pub-id></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lazareva</surname><given-names>OF</given-names></name><name><surname>Paxton Gazes</surname><given-names>R</given-names></name><name><surname>Elkins</surname><given-names>Z</given-names></name><name><surname>Hampton</surname><given-names>R</given-names></name></person-group><article-title>Associative models fail to characterize transitive inference performance in rhesus monkeys (Macaca mulatta)</article-title><source>Learn Behav</source><year>2020</year><volume>48</volume><fpage>135</fpage><lpage>148</lpage><pub-id pub-id-type="doi">10.3758/s13420-020-00417-6</pub-id></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vasconcelos</surname><given-names>M</given-names></name></person-group><article-title>Transitive inference in non-human animals: An empirical and theoretical analysis</article-title><source>Behav Processes</source><year>2008</year><volume>78</volume><fpage>313</fpage><lpage>334</lpage><pub-id pub-id-type="doi">10.1016/j.beproc.2008.02.017</pub-id></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Couvillon</surname><given-names>PA</given-names></name><name><surname>Bitterman</surname><given-names>ME</given-names></name></person-group><article-title>A Conventional Conditioning Analysis of “Transitive Inference” in Pigeons</article-title><source>J Exp Psychol Anim Behav Process</source><year>1992</year><volume>18</volume><fpage>308</fpage><lpage>310</lpage><pub-id pub-id-type="doi">10.1037/0097-7403.18.3.308</pub-id></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>von Fersen</surname><given-names>L</given-names></name><name><surname>Wynne</surname><given-names>CDL</given-names></name><name><surname>Delius</surname><given-names>JD</given-names></name><name><surname>Staddon</surname><given-names>JER</given-names></name></person-group><article-title>Transitive Inference Formation in Pigeons</article-title><source>J Exp Psychol Anim Behav Process</source><year>1991</year><volume>17</volume><fpage>334</fpage><lpage>341</lpage><pub-id pub-id-type="doi">10.1037/0097-7403.17.3.334</pub-id></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Siemann</surname><given-names>M</given-names></name><name><surname>Delius</surname><given-names>JD</given-names></name></person-group><article-title>Algebraic Learning and Neural Network Models for Transitive and Non-transitive Responding</article-title><source>Eur J Cogn Psychol</source><year>1998</year><volume>10</volume><fpage>307</fpage><lpage>334</lpage><pub-id pub-id-type="doi">10.1080/713752279</pub-id></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jensen</surname><given-names>G</given-names></name><name><surname>Alkan</surname><given-names>Y</given-names></name><name><surname>Muñoz</surname><given-names>F</given-names></name><name><surname>Ferrera</surname><given-names>VP</given-names></name><name><surname>Terrace</surname><given-names>HS</given-names></name></person-group><article-title>Transitive inference in humans (Homo sapiens) and rhesus macaques (Macaca mulatta) after massed training of the last two list items</article-title><source>J Comp Psychol</source><year>2017</year><volume>131</volume><fpage>231</fpage><lpage>245</lpage><pub-id pub-id-type="doi">10.1037/com0000065</pub-id></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lazareva</surname><given-names>OF</given-names></name><name><surname>Smirnova</surname><given-names>AA</given-names></name><name><surname>Bagozkaja</surname><given-names>MS</given-names></name><name><surname>Zorina</surname><given-names>ZA</given-names></name><name><surname>Rayevsky</surname><given-names>VV</given-names></name><name><surname>Wasserman</surname><given-names>EA</given-names></name></person-group><article-title>Transitive Responding in Hooded Crows Requires Linearly Ordered Stimuli</article-title><source>J Exp Anal Behav</source><year>2004</year><volume>82</volume><fpage>1</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.1901/jeab.2004.82-1</pub-id></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lazareva</surname><given-names>OF</given-names></name><name><surname>Wasserman</surname><given-names>EA</given-names></name></person-group><article-title>Effect of stimulus orderability and reinforcement history on transitive responding in pigeons</article-title><source>Behav Processes</source><year>2006</year><volume>72</volume><fpage>161</fpage><lpage>172</lpage><pub-id pub-id-type="doi">10.1016/j.beproc.2006.01.008</pub-id></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lazareva</surname><given-names>OF</given-names></name><name><surname>Wasserman</surname><given-names>EA</given-names></name></person-group><article-title>Transitive inference in pigeons: Measuring the associative values of Stimuli B and D</article-title><source>Behav Processes</source><year>2012</year><volume>89</volume><fpage>244</fpage><lpage>255</lpage><pub-id pub-id-type="doi">10.1016/j.beproc.2011.12.001</pub-id></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weaver</surname><given-names>JE</given-names></name><name><surname>Steirn</surname><given-names>JN</given-names></name><name><surname>Zentall</surname><given-names>TR</given-names></name></person-group><article-title>Transitive inference in pigeons: Control for differential value transfer</article-title><source>Psychon Bull Rev</source><year>1997</year><volume>4</volume><fpage>113</fpage><lpage>117</lpage><pub-id pub-id-type="doi">10.3758/BF03210782</pub-id></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roediger</surname><given-names>HL</given-names></name><name><surname>Karpicke</surname><given-names>JD</given-names></name></person-group><article-title>Test-enhanced learning: Taking memory tests improves long-term retention</article-title><source>Psychol Sci</source><year>2006</year><volume>17</volume><fpage>249</fpage><lpage>255</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9280.2006.01693.x</pub-id></element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Birnbaum</surname><given-names>MS</given-names></name><name><surname>Kornell</surname><given-names>N</given-names></name><name><surname>Bjork</surname><given-names>EL</given-names></name><name><surname>Bjork</surname><given-names>RA</given-names></name></person-group><article-title>Why interleaving enhances inductive learning: The roles of discrimination and retrieval</article-title><source>Mem Cogn</source><year>2013</year><volume>41</volume><fpage>392</fpage><lpage>402</lpage><pub-id pub-id-type="doi">10.3758/s13421-012-0272-7</pub-id></element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kornell</surname><given-names>N</given-names></name><name><surname>Bjork</surname><given-names>RA</given-names></name></person-group><article-title>Learning concepts and categories: Is spacing the “enemy of induction”?</article-title><source>Psychol Sci</source><year>2008</year><volume>19</volume><fpage>585</fpage><lpage>592</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9280.2008.02127.x</pub-id></element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kang</surname><given-names>SHK</given-names></name><name><surname>Pashler</surname><given-names>H</given-names></name></person-group><article-title>Learning Painting Styles: Spacing is Advantageous when it Promotes Discriminative Contrast</article-title><source>Appl Cogn Psychol</source><year>2012</year><volume>26</volume><fpage>97</fpage><lpage>103</lpage><pub-id pub-id-type="doi">10.1002/acp.1801</pub-id></element-citation></ref><ref id="R40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carvalho</surname><given-names>PF</given-names></name><name><surname>Goldstone</surname><given-names>RL</given-names></name></person-group><article-title>The benefits of interleaved and blocked study: Different tasks benefit from different schedules of study</article-title><source>Psychon Bull Rev</source><year>2014</year><volume>22</volume><fpage>281</fpage><lpage>288</lpage><pub-id pub-id-type="doi">10.3758/s13423-014-0676-4</pub-id></element-citation></ref><ref id="R41"><label>41</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Noh</surname><given-names>SM</given-names></name><name><surname>Yan</surname><given-names>VX</given-names></name><name><surname>Bjork</surname><given-names>RA</given-names></name><name><surname>Maddox</surname><given-names>WT</given-names></name></person-group><article-title>Optimal sequencing during category learning: Testing a dual-learning systems perspective</article-title><source>Cognition</source><year>2016</year><volume>155</volume><fpage>23</fpage><lpage>29</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2016.06.007</pub-id></element-citation></ref><ref id="R42"><label>42</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flesch</surname><given-names>T</given-names></name><name><surname>Balaguer</surname><given-names>J</given-names></name><name><surname>Dekker</surname><given-names>R</given-names></name><name><surname>Nili</surname><given-names>H</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name></person-group><article-title>Comparing continual task learning in minds and machines</article-title><source>Proc Natl Acad Sci U S A</source><year>2018</year><volume>115</volume><fpage>E10313</fpage><lpage>E10322</lpage><pub-id pub-id-type="doi">10.1073/pnas.1800755115</pub-id></element-citation></ref><ref id="R43"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heffernan</surname><given-names>EM</given-names></name><name><surname>Schlichting</surname><given-names>ML</given-names></name><name><surname>Mack</surname><given-names>ML</given-names></name></person-group><article-title>Learning exceptions to the rule in human and model via hippocampal encoding</article-title><source>Sci Rep</source><year>2021</year><volume>11</volume><fpage>1</fpage><lpage>14</lpage><pub-id pub-id-type="doi">10.1038/s41598-021-00864-9</pub-id></element-citation></ref><ref id="R44"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carvalho</surname><given-names>PF</given-names></name><name><surname>Goldstone</surname><given-names>RL</given-names></name></person-group><article-title>Putting category learning in order: Category structure and temporal arrangement affect the benefit of interleaved over blocked study</article-title><source>Mem Cogn</source><year>2013</year><volume>42</volume><fpage>481</fpage><lpage>495</lpage><pub-id pub-id-type="doi">10.3758/s13421-013-0371-0</pub-id></element-citation></ref><ref id="R45"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markant</surname><given-names>DB</given-names></name></person-group><article-title>Active transitive inference: When learner control facilitates integrative encoding</article-title><source>Cognition</source><year>2020</year><volume>200</volume><elocation-id>104188</elocation-id><pub-id pub-id-type="doi">10.1016/j.cognition.2020.104188</pub-id></element-citation></ref><ref id="R46"><label>46</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markant</surname><given-names>DB</given-names></name></person-group><article-title>Chained study and the discovery of relational structure</article-title><source>Mem Cogn</source><year>2021</year><volume>50</volume><fpage>95</fpage><lpage>111</lpage><pub-id pub-id-type="doi">10.3758/s13421-021-01201-1</pub-id></element-citation></ref><ref id="R47"><label>47</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Favila</surname><given-names>SE</given-names></name><name><surname>Chanales</surname><given-names>AJH</given-names></name><name><surname>Kuhl</surname><given-names>BA</given-names></name></person-group><article-title>Experience-dependent hippocampal pattern differentiation prevents interference during subsequent learning</article-title><source>Nat Commun</source><year>2016</year><volume>7</volume><pub-id pub-id-type="doi">10.1038/ncomms11066</pub-id></element-citation></ref><ref id="R48"><label>48</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schlichting</surname><given-names>ML</given-names></name><name><surname>Mumford</surname><given-names>JA</given-names></name><name><surname>Preston</surname><given-names>AR</given-names></name></person-group><article-title>Learning-related representational changes reveal dissociable integration and separation signatures in the hippocampus and prefrontal cortex</article-title><source>Nat Commun</source><year>2015</year><volume>6</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1038/ncomms9151</pub-id></element-citation></ref><ref id="R49"><label>49</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumaran</surname><given-names>D</given-names></name><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>McClelland</surname><given-names>JL</given-names></name></person-group><article-title>What Learning Systems do Intelligent Agents Need? Complementary Learning Systems Theory Updated</article-title><source>Trends Cogn Sci</source><year>2016</year><volume>20</volume><fpage>512</fpage><lpage>534</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2016.05.004</pub-id></element-citation></ref><ref id="R50"><label>50</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mcclelland</surname><given-names>JL</given-names></name><name><surname>Mcnaughton</surname><given-names>BL</given-names></name><name><surname>Reilly</surname><given-names>RCO</given-names></name></person-group><article-title>Why There Are Complementary Learning Systems in the Hippocampus and Neocortex: Insights From the Successes and Failures of Connectionist Models of Learning and Memory</article-title><source>Psychol Rev</source><year>1995</year><volume>102</volume><fpage>419</fpage><lpage>457</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.102.3.419</pub-id></element-citation></ref><ref id="R51"><label>51</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Javadi</surname><given-names>AH</given-names></name><name><surname>Tolat</surname><given-names>A</given-names></name><name><surname>Spiers</surname><given-names>HJ</given-names></name></person-group><article-title>Sleep enhances a spatially mediated generalization of learned values</article-title><source>Learn Mem</source><year>2015</year><volume>22</volume><fpage>532</fpage><lpage>536</lpage><pub-id pub-id-type="doi">10.1101/lm.038828.115</pub-id></element-citation></ref><ref id="R52"><label>52</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Richards</surname><given-names>BA</given-names></name><name><surname>Xia</surname><given-names>F</given-names></name><name><surname>Santoro</surname><given-names>A</given-names></name><name><surname>Husse</surname><given-names>J</given-names></name><name><surname>Woodin</surname><given-names>MA</given-names></name><name><surname>Josselyn</surname><given-names>SA</given-names></name><etal/></person-group><article-title>Patterns across multiple memories are identified over time</article-title><source>Nat Neurosci</source><year>2014</year><volume>17</volume><fpage>981</fpage><lpage>986</lpage><pub-id pub-id-type="doi">10.1038/nn.3736</pub-id></element-citation></ref><ref id="R53"><label>53</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schlichtinga</surname><given-names>ML</given-names></name><name><surname>Preston</surname><given-names>AR</given-names></name></person-group><article-title>Memory reactivation during rest supports upcoming earning of related content</article-title><source>Proc Natl Acad Sci U S A</source><year>2014</year><volume>111</volume><fpage>15845</fpage><lpage>15850</lpage><pub-id pub-id-type="doi">10.1073/pnas.1404396111</pub-id></element-citation></ref><ref id="R54"><label>54</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ellenbogen</surname><given-names>JM</given-names></name><name><surname>Hu</surname><given-names>PT</given-names></name><name><surname>Payne</surname><given-names>JD</given-names></name><name><surname>Titone</surname><given-names>D</given-names></name><name><surname>Walker</surname><given-names>MP</given-names></name></person-group><article-title>Human relational memory requires time and sleep</article-title><source>Proc Natl Acad Sci U S A</source><year>2007</year><volume>104</volume><fpage>7723</fpage><lpage>7728</lpage><pub-id pub-id-type="doi">10.1073/pnas.0700094104</pub-id></element-citation></ref><ref id="R55"><label>55</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dumay</surname><given-names>N</given-names></name><name><surname>Gaskell</surname><given-names>MG</given-names></name></person-group><article-title>Sleep-associated changes in the mental representation of spoken words: Research report</article-title><source>Psychol Sci</source><year>2007</year><volume>18</volume><fpage>35</fpage><lpage>39</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9280.2007.01845.x</pub-id></element-citation></ref><ref id="R56"><label>56</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewis</surname><given-names>PA</given-names></name><name><surname>Durrant</surname><given-names>SJ</given-names></name></person-group><article-title>Overlapping memory replay during sleep builds cognitive schemata</article-title><source>Trends Cogn Sci</source><year>2011</year><volume>15</volume><fpage>343</fpage><lpage>351</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2011.06.004</pub-id></element-citation></ref><ref id="R57"><label>57</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name></person-group><article-title>Human Replay Spontaneously Reorganizes Experience</article-title><source>Cell</source><year>2019</year><volume>178</volume><fpage>640</fpage><lpage>652</lpage><elocation-id>e14</elocation-id><pub-id pub-id-type="doi">10.1016/j.cell.2019.06.012</pub-id></element-citation></ref><ref id="R58"><label>58</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Preston</surname><given-names>AR</given-names></name><name><surname>Shrager</surname><given-names>Y</given-names></name><name><surname>Dudukovic</surname><given-names>NM</given-names></name><name><surname>Gabrieli</surname><given-names>JDE</given-names></name></person-group><article-title>Hippocampal contribution to the novel use of relational information in declarative memory</article-title><source>Hippocampus</source><year>2004</year><volume>14</volume><fpage>148</fpage><lpage>152</lpage><pub-id pub-id-type="doi">10.1002/hipo.20009</pub-id></element-citation></ref><ref id="R59"><label>59</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zalesak</surname><given-names>M</given-names></name><name><surname>Heckers</surname><given-names>S</given-names></name></person-group><article-title>The role of the hippocampus in transitive inference</article-title><source>Psychiatry Res - Neuroimaging</source><year>2009</year><volume>172</volume><fpage>24</fpage><lpage>30</lpage><pub-id pub-id-type="doi">10.1016/j.pscychresns.2008.09.008</pub-id></element-citation></ref><ref id="R60"><label>60</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>Z</given-names></name><name><surname>Singh</surname><given-names>D</given-names></name><name><surname>Tandoc</surname><given-names>MC</given-names></name><name><surname>Schapiro</surname><given-names>AC</given-names></name></person-group><article-title>Distributed representations for human inference</article-title><source>bioRxiv</source><year>2021</year></element-citation></ref><ref id="R61"><label>61</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McCloskey</surname><given-names>M</given-names></name><name><surname>Cohen</surname><given-names>N</given-names></name></person-group><article-title>Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem</article-title><source>Psychol Learn Motiv</source><year>1989</year><volume>24</volume><fpage>109</fpage><lpage>165</lpage></element-citation></ref><ref id="R62"><label>62</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kirkpatrick</surname><given-names>J</given-names></name><name><surname>Pascanu</surname><given-names>R</given-names></name><name><surname>Rabinowitz</surname><given-names>N</given-names></name><name><surname>Veness</surname><given-names>J</given-names></name><name><surname>Desjardins</surname><given-names>G</given-names></name><name><surname>Rusu</surname><given-names>AA</given-names></name><etal/></person-group><article-title>Overcoming catastrophic forgetting in neural networks</article-title><source>Proc Natl Acad Sci U S A</source><year>2017</year><volume>114</volume><fpage>3521</fpage><lpage>3526</lpage><pub-id pub-id-type="doi">10.1073/pnas.1611835114</pub-id></element-citation></ref><ref id="R63"><label>63</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Momennejad</surname><given-names>I</given-names></name></person-group><article-title>Learning Structures: Predictive Representations, Replay, and Generalization</article-title><source>Curr Opin Behav Sci</source><year>2020</year><volume>32</volume><fpage>155</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2020.02.017</pub-id></element-citation></ref><ref id="R64"><label>64</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stachenfeld</surname><given-names>KL</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name></person-group><article-title>The hippocampus as a predictive map</article-title><source>Nat Neurosci</source><year>2017</year><volume>20</volume><fpage>1643</fpage><lpage>1653</lpage><pub-id pub-id-type="doi">10.1038/nn.4650</pub-id></element-citation></ref><ref id="R65"><label>65</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andersson</surname><given-names>JLR</given-names></name><name><surname>Hutton</surname><given-names>C</given-names></name><name><surname>Ashburner</surname><given-names>J</given-names></name><name><surname>Turner</surname><given-names>R</given-names></name><name><surname>Friston</surname><given-names>K</given-names></name></person-group><article-title>Modeling geometric deformations in EPI time series</article-title><source>Neuroimage</source><year>2001</year><volume>13</volume><fpage>903</fpage><lpage>919</lpage><pub-id pub-id-type="doi">10.1006/nimg.2001.0746</pub-id></element-citation></ref><ref id="R66"><label>66</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hutton</surname><given-names>C</given-names></name><name><surname>Bork</surname><given-names>A</given-names></name><name><surname>Josephs</surname><given-names>O</given-names></name><name><surname>Deichmann</surname><given-names>R</given-names></name><name><surname>Ashburner</surname><given-names>J</given-names></name><name><surname>Turner</surname><given-names>R</given-names></name></person-group><article-title>Image distortion correction in fMRI: A quantitative evaluation</article-title><source>Neuroimage</source><year>2002</year><volume>16</volume><fpage>217</fpage><lpage>240</lpage><pub-id pub-id-type="doi">10.1006/nimg.2001.1054</pub-id></element-citation></ref><ref id="R67"><label>67</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mumford</surname><given-names>JA</given-names></name><name><surname>Turner</surname><given-names>BO</given-names></name><name><surname>Ashby</surname><given-names>FG</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name></person-group><article-title>Deconvolving BOLD activation in event-related designs for multivoxel pattern classification analyses</article-title><source>Neuroimage</source><year>2012</year><volume>59</volume><fpage>2636</fpage><lpage>2643</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.08.076</pub-id></element-citation></ref><ref id="R68"><label>68</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ritchey</surname><given-names>M</given-names></name><name><surname>Montchal</surname><given-names>ME</given-names></name><name><surname>Yonelinas</surname><given-names>AP</given-names></name><name><surname>Ranganath</surname><given-names>C</given-names></name></person-group><article-title>Delay-dependent contributions of medial temporal lobe regions to episodic memory retrieval</article-title><source>Elife</source><year>2015</year><volume>2015</volume><fpage>1</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.7554/eLife.05025</pub-id></element-citation></ref><ref id="R69"><label>69</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schaefer</surname><given-names>A</given-names></name><name><surname>Kong</surname><given-names>R</given-names></name><name><surname>Gordon</surname><given-names>EM</given-names></name><name><surname>Laumann</surname><given-names>TO</given-names></name><name><surname>Zuo</surname><given-names>X-N</given-names></name><name><surname>Holmes</surname><given-names>AJ</given-names></name><etal/></person-group><article-title>Local-Global Parcellation of the Human Cerebral Cortex from Intrinsic Functional Connectivity MRI</article-title><source>Cereb Cortex</source><year>2018</year><volume>28</volume><fpage>3095</fpage><lpage>3114</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhx179</pub-id></element-citation></ref><ref id="R70"><label>70</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fritsche</surname><given-names>M</given-names></name><name><surname>Lawrence</surname><given-names>SJD</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><article-title>Temporal tuning of repetition suppression across the visual cortex</article-title><source>J Neurophysiol</source><year>2020</year><volume>123</volume><fpage>224</fpage><lpage>233</lpage><pub-id pub-id-type="doi">10.1152/jn.00582.2019</pub-id></element-citation></ref></ref-list></back><floats-group><boxed-text id="BX1" position="float" orientation="portrait"><caption><title>Author summary</title></caption><p>Integrating information across distinct situations allows both humans and non-human animals to solve novel problems. For instance, by observing that topaz is hard enough to scratch quartz, and that quartz is hard enough to scratch gypsum, one can infer that topaz must be harder than gypsum - even if these materials have never been seen together. This type of generalisation (transitive inference) can be achieved by combing different pieces of information either, 1) when an inference is actually needed (retrieval-based generalisation), or 2) when new information is first encountered (encoding-based generalisation). We predicted that the use of these generalisation mechanisms depends on the order in which information is presented and whether that information was learnt before an overnight rest. Contrary to our predictions, behavioural and neuroimaging analyses of a transitive inference task in humans showed convergent evidence for encoding-based generalisations in all conditions. While these conditions had a large impact on inferential ability, we found that brain regions involved in memory invariably learnt inferred relationships between items that had not been seen together. Strikingly, this appeared to be the case even when participants where unbale to make accurate inferences.</p></boxed-text><fig id="F1" position="float"><label>Figure 1</label><caption><title>Illustration of the pre-scanner training and in-scanner behavioural tasks.</title><p>A) Both before and during fMRI, participants saw computer generated images of two buildings with different wall-textures rendered onto their exterior surfaces. One building concealed a pile of virtual gold (reinforcement) and the location of this reward was perfectly determined by the combination of wall-textures shown. In the pre-scanner training phase, participants were tasked with learning the reward contingencies via trial-and-error. A left/right button press was required within 3 seconds of the start of each trail. Following this, a feedback animation was shown indicating whether the response was correct or not. During the in-scanner task, participants were required to respond to still images of the two buildings, yet no feedback was provided. B) A schematic illustration of the reward contingencies trained before scanning (i.e., the premise discriminations, red solid lines) and inferred inside the scanner (i.e., inferred discriminations, dashed lines). Letters denote unique wall textures and the greater than signs indicate the rewarded wall-texture in each premise discrimination. Taken together the 6 premise discriminations implied a 1-dimensional transitive hierarchy. Inferred discriminations did not involve the ends of the hierarchy (i.e., A and G) since such challenges can be solved by retrieving an explicitly trained (featural) contingency (e.g., recalling that A is always rewarded). As such, the set of inferred discriminations included three trials with a ‘transitive distance’ of Δ2, two trials with a transitive distance of Δ3, and one trial with a transitive distance of Δ4. Note that participants were trained on two independent transitive hierarchies on two separate days: one 24 hours before scanning, one immediately before scanning. While equivalent in structure, the contingencies learnt on each day involved entirely different wall-texture stimuli (counterbalanced across participants) which were never presented in the same trial. C) and D) One each day of training, premise trials were ordered in one of two ways: interleaved training involved presented all 6 premise discriminations in pseudorandom order such that there was a uniform probability (1/6) of encountering any one discrimination on a particular trial (panel C). In contrast, progressive training involved 6 epochs of different lengths that gradually introduced the discriminations whilst ensuring that, once a discrimination had been introduced, it was presented in all subsequent epochs (panel D).</p></caption><graphic xlink:href="EMS150780-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Humans shows better generalisation following progressive training.</title><p>A) Estimates of the probability of a correct response, <italic>Pr</italic> (<italic>correct</italic>), split by trial type (premise vs inferred) and experimental condition (training method and session). While participants showed comparable levels of performance on the premise discriminations across conditions (red bars), inference performance varied by training method with progressive learners showing much higher levels of accuracy (blue bars). B) On inference trials, behavioural performance was positively related to “transitive distance” (the degree of separation between discriminable features along the transitive hierarchy, see <xref ref-type="fig" rid="F1">Figure 1B</xref>). While the correlation between transitive distance and performance was positive in all conditions, the association was most consistent for remote discriminations in the progressive training condition. C) Estimates of the mean response time (in seconds, correct responses only) split by trial type and experimental condition (as in panel A). Response times closely mirrored the probability of a correct response but showed an additional effect indicating that participants were faster at responding to remote contingencies (overall). D) Response times to inference trails by transitive distance. While not significant, in general, response times decreased as transitive distance increased. Individual data points reflect response times across all trials and participants, and error bars/lines represent 95% confidence intervals.</p></caption><graphic xlink:href="EMS150780-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Behavioural performance is suggestive of encoding-based generalisation mechanisms.</title><p>Figure shows goodness-of-fit statistics per participant and condition for two models of inference performance (lower values indicate a better model fit). The AND model implements a general assumption of retrieval-based generalisation mechanisms - that inference requires retrieving multiple independent response contingencies in order to evaluate transitive relationships. In contrast, the OR model realises a general assumption of encoding-based generalisation; specifically, that inferences require the retrieval of a unified structural representation. In all conditions, average goodness-of-fit statistics were lowest for the OR model indicating that it was a better fit to the behavioural data (result qualified by a generalised linear mixed-effects model - see text).</p></caption><graphic xlink:href="EMS150780-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Inference performance within- and across-experimental conditions is associated with univariate BOLD activity in the superior MPFC.</title><p>Panels A and B show activity in the left superior MPFC. Panels C and D show activity in the right superior MPFC. Bar charts display mean response amplitudes to all in-scanner discriminations split by trial type (premise vs inferred) and experimental condition (training method and session). Scatter plots display mean response amplitudes to all inference trials (both recent and remote) as a function of inference performance, split by training method (interleaved vs progressive). In the left superior MPFC, a main effect of trial type indicated lower levels of BOLD activity on inference trails (panel A). This was superseded by a significant 3-way interaction indicating larger BOLD responses to inference trials in progressive learners who achieved high levels of inference performance (panel B). The right superior MPFC showed a significant 2-way interaction between trial type and training method. This indicated that BOLD responses in interleaved learners were lower on inference trails (relative to premise trials), but comparable to premise trials in progressive learners (panels C and D). Overall, these data indicate that the MPFC produced greater levels of BOLD activity whenever response accuracy is high. Individual data points indicate discrimination-specific BOLD estimates for each participant and error-bars indicate 95% confidence intervals.</p></caption><graphic xlink:href="EMS150780-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>Methods and results for the RSA.</title><p>A) BOLD responses across voxels (v1, v2, etc.) for each in-scanner discrimination (A&gt;B, B&gt;D, etc.) were estimated in a set of 1<sup>st</sup> level models. These were linearly transformed into representations of specific wall-texture stimuli (A, B, C, etc.) via a least-squares decomposition procedure. Subsequently, BOLD similarity between wall-textures was estimated, Fisher-transformed, and entered into a mixed-effects model that implemented the RSA. Nuisance covariates accounted for trivial correlations between co-presented wall-textures and correlations resulting from the decomposition procedure. Effects of interest modelled the influence of condition, behavioural performance, and transitive distance. B) In the left hippocampus, transitive distance (i.e., the separation between wall-textures) was negatively correlated with BOLD similarity across all conditions. As such, this region appears to encode a structural representation of the transitive hierarchy that is not modulated by training method (i.e., interleaved vs progressive) or session (recent vs remote). C) The left superior MPFC exhibited a distance by session interaction suggesting that structural representations were only expressed for recently learnt contingencies. Individual datapoints indicate pairwise similarity estimates from all participants and shaded error-bars indicate 95% confidence intervals.</p></caption><graphic xlink:href="EMS150780-f005"/></fig><fig id="F6" position="float"><label>Figure 6</label><caption><title>Associations between measures of behavioural performance and the magnitude of distance effects in the RSA.</title><p>Solid trend lines depict the fitted fixed-effect relationship, while shaded error-bars indicate 95% confidence intervals. Note that negative distance effects (plotted above the dashed horizontal) represent the predicted association between transitive distance and BOLD pattern similarity. Individual datapoints depict participant-specific random slopes for each association. A) Distance effects in the left hippocampus were strongest when participants produced relatively low transitive slopes (less indicative of encoding-based generalisation). B) Distance effects in the left superior MPFC were only significant in the recent condition and were strongest when participants did not achieve high levels of inference performance. C) In contrast to the left hippocampus, distance effects in the right superior MPFC were most evident when participants produced relatively large transitive slopes (most indicative of encoding-based generalisation), yet this association was limited to the remote condition. Individual datapoints indicate estimated distance effects per participant and shaded error-bars indicate 95% confidence intervals.</p></caption><graphic xlink:href="EMS150780-f006"/></fig></floats-group></article>