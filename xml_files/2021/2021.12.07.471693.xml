<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS146591</article-id><article-id pub-id-type="doi">10.1101/2021.12.07.471693</article-id><article-id pub-id-type="archive">PPR430361</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group><subj-group subj-group-type="europepmc-category"><subject>Covid-19</subject></subj-group></article-categories><title-group><article-title>Interpretable and Generalizable Attention-Based Model for Predicting Drug-Target Interaction Using 3D Structure of Protein Binding Sites: SARS-CoV-2 Case Study and in-Lab Validation</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><name><surname>Yazdani-Jahromi</surname><given-names>Mehdi</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Yousefi</surname><given-names>Niloofar</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Tayebi</surname><given-names>Aida</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Garibay</surname><given-names>Ozlem Ozmen</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="corresp" rid="CR1">†</xref></contrib><contrib contrib-type="author"><name><surname>Seal</surname><given-names>Sudipta</given-names></name><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Kolanthai</surname><given-names>Elayaraja</given-names></name><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Neal</surname><given-names>Craig J.</given-names></name><xref ref-type="aff" rid="A2">2</xref></contrib></contrib-group><aff id="A1"><label>1</label>Industrial Engineering and Management Systems, University of Central Florida, Street, 32816, 4000 Central Florida Blvd. Orlando, USA</aff><aff id="A2"><label>2</label>College of Medicine, Bionix Cluster, University of Central Florida, 4000 Central Florida Blvd. Orlando, 32816, Florida, USA</aff><aff id="A3"><label>3</label>Advanced Materials Processing and Analysis Center, Dept. of Materials Science and Engineering, University of Central Florida, 4000 Central Florida Blvd. Orlando, 32816, Florida, USA</aff><author-notes><corresp id="CR1">
<label>†</label>Ozlem Ozmen Garibay. <email>ozlem@ucf.edu</email></corresp></author-notes><pub-date pub-type="nihms-submitted"><day>01</day><month>07</month><year>2022</year></pub-date><pub-date pub-type="preprint"><day>18</day><month>02</month><year>2022</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">In this study, we introduce and implement an interpretable graph-based deep learning prediction model, which utilizes protein binding sites along with self-attention to learn which protein binding sites interact with a given ligand. Our proposed model enables interpretability by identifying the protein binding sites that contribute the most towards the Drug-Target Interaction. Results on three benchmark datasets show improved performance compared to previous graph-based models. More significantly, unlike previous studies our model performance remains close to the optimal performance when tested with new proteins (ie., high generalizablity). Through multidisciplinary collaboration, we further experimentally evaluate the practical potential of our proposed approach. To achieve this, we first computationally predict binding interaction of some candidate compounds with a target protein, then experimentally validate the binding interactions for these pairs in the laboratory. The high agreement between the computationally-predicted and experimentally-observed (measured) DTIs illustrates the potential of our method as an effective pre-screening tool in drug re-purposing applications.</p></abstract><kwd-group><kwd>Deep learning</kwd><kwd>Self-Attention</kwd><kwd>Binding Sites</kwd><kwd>Machine learning</kwd><kwd>drug-target interaction</kwd><kwd>SARS-CoV-2</kwd><kwd>DTI software</kwd><kwd>DTI database</kwd></kwd-group></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">Drug-target interaction characterizes the binding between a drug and its target, which is critical to discovery of novel drug species, and/or repurposing of existing drugs. High-Throughput Screening remains the most reliable approach to examine the affinity of a drug toward its targets. However, the experimental characterization of every possible compound–protein pair quickly becomes impractical, due to the immense space of chemical compounds, targets and mixtures. This motivates the use of computational approaches for DTI prediction tasks.</p><p id="P3">Molecular simulation and molecular docking are among earlier computational approaches, which typically require 3D structures of the target proteins to assess the drug-target interaction. The application of these structure-based methods is limited, as there are many proteins with unknown 3D structures, beside that they involve an expensive process. Artificial Intelligence (AI)-based approaches, including Deep Learning (DL) and Machine Learning (ML) algorithms have then emerged to overcome some of these challenges in the process of drug design and discovery. Traditional shallow ML-based models, such as KronRLS <xref ref-type="bibr" rid="R21">Pahikkala et al. [2015]</xref> and <xref ref-type="bibr" rid="R9">SimBoost He et al. [2017]</xref>, require hand-crafted features, which highly affect the performance of the models. Deep Learning has advanced these traditional models due to their ability in automatically capturing useful latent features, leading to highly flexible models with extensive power in identifying, processing and extrapolating complex patterns in molecular data.</p><p id="P4">Deep Learning models for DTI can be mainly categorized into two classes. One class is designed to work with sequence-based representation input data. Examples of this type include Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) that are incapable of capturing structural information of the molecules, leading to degraded predictive power of these models. This motivates the use of a more natural representation of the molecules and the convention of second class of Deep Learning models, namely Graph Neural Networks (GNNs) that use graph descriptions of the molecules, where atoms and chemical bonds correspond to nodes and edges, respectively. Graph Convolutional Neural Network (GCNN) and Graph Attention Network (GAT) are the two widely used GNN-based models in computer-aided drug design and discovery <xref ref-type="bibr" rid="R27">Torng and Altman [2019]</xref>, <xref ref-type="bibr" rid="R16">Lim et al. [2019]</xref>, <xref ref-type="bibr" rid="R25">Son and Kim [2021]</xref>. All these graph-based models use amino acid sequence representations for proteins, which cannot capture the 3D structural features that are key factors in the prediction of drug-target interactions. On the other hand, obtaining the high-resolution 3D structure of the proteins is a challenging task, beside the fact that proteins contain a large number of atoms requiring a large scale 3D (sparse) matrix to capture the whole structure. To alleviate this issue, an alternative strategy has been adopted wherein the proteins are represented by a 2D contact (or distance) map that shows the interaction of proteins’ residue pairs in the form of a matrix <xref ref-type="bibr" rid="R10">Jiang et al. [2020]</xref>, <xref ref-type="bibr" rid="R37">Zheng et al. [2020]</xref>. It is worth mentioning that a contact (or distance) map is typically the output of protein structure prediction, which is based on heuristics and provides only an approximation abstraction of the real structure of protein, generally, different from the one determined experimentally via X-ray crystallography or by nucleic magnetic resonance spectroscopy (NMR) <xref ref-type="bibr" rid="R28">Tradigo [2013]</xref>. Taken all together, and considering the fact that the binding of a protein to many molecules occurs at different binding pockets rather than the whole protein, in this paper, we represent protein pockets as graphs where the key protein residues correspond to the nodes that are connected based on residue proximity. Our model is inspired by the ones developed for text classification in the field of Natural Language Processing (NLP), and is highly explainable due to its self attention mechanism.</p><sec id="S2"><title>Contribution</title><p id="P5">Our contribution can be summarized in three parts. First, we use graph representation of protein pockets as the input for target protein. Given the fact that intermolecular interactions between protein and ligand occur in pocket-like regions of the protein, prediction models that utilize the binding sites (pockets) of the proteins are expected to have better generalizability, compared to those relying on certain patterns present in drug molecules or protein sequences. Second, we devise a self-attention mechanism to make the model learn which parts of the protein interact with the ligand, thus complement the black-box nature of deep learning-based methods and enables interpretability, while achieving better DTI prediction performance. Third, we build an end-to-end Graph Convolutional Neural Network (GCNN)-based model, which (1) automatically learns useful embeddings from the graphs of raw molecules and protein pockets, that is, the embeddings are not fixed, but they change according to the context (i.e., sentence) in which they appear and (2) use the learned embeddings similar to the word embeddings, by treating the drug-target complex as a sentence with relational meaning between its biochemical entities a.k.a. protein pockets and drug molecule. This consideration is motivated by the fact that the structure of drug-target complex can be very similar to the structure of a natural language sentence in that the structural and relational information of the entities are keys in understanding the most important information of the sentence. In this regard, each protein pocket or drug is analogous to a word, and each drug-target pair is analogous to a sentence. More specifically, we hypothesize that self-attention bidirectional Long Short-Term Memory (LSTM) mechanism can be used to capture any relationship between binding sites of a given protein and the drug in a sequence, and thus provide a better understanding of their binding relationships. Finally, we conduct in-lab experimental investigations to test the practical potential of our model in prediction and evaluation of compound-target binding interactions in a real world application. Visualization of the aforementioned method can be found in <xref ref-type="fig" rid="F1">Figure 1</xref>. To the best of our knowledge, we are the first to use attention-based bidirectional LSTM networks to perform a relation classification to capture the most important contextual semantic or relational information in a biochemical sequence (i.e. sentence). Each part of our contribution will be described in Section 2.</p></sec><sec id="S3"><title>Related works</title><p id="P6">Deep learning based approaches have been successfully deployed to address DTI prediction. The main difference between deep learning approaches are in their architecture as well as the representation of the input data. As previously mentioned, small molecules of the drugs can be easily and effectively represented in one-dimensional space, but proteins are much bigger molecules with complex interaction and 1D representations can be insufficient. Although the datasets containing 3D structure of the protein are limited, some recent deep learning based literature have used them in their study. For example, AtomNet <xref ref-type="bibr" rid="R33">Wallach et al. [2015]</xref> is the first study that used the 3D structure of protein as input to a 3D convolutional neural network to predict the binding of drug-target pairs using a binary classifier. <xref ref-type="bibr" rid="R23">Ragoza et al. [2017]</xref> proposed a CNN scoring function that took the 3D representation of the protein-ligand complex and learned the features critical in binding prediction. This model outperformed AutoDock Vina score in terms of discriminating and ranking the binding poses. Pafnucy <xref ref-type="bibr" rid="R26">Stepniewska-Dziubinska et al. [2018]</xref> proposed 3D convolutional neural networks that predicted the binding affinity values for the drug-target pairs. This study represented the input with 3D grid and considers both proteins and ligands atoms similar. Using a regularization technique, their designed network focused on capturing the general properties of interactions between proteins and ligands.</p><p id="P7">There are limitations associated with all these studies. For example, it is a highly challenging task to experimentally obtain high-quality 3D structure of proteins, which explains why the number of datasets with 3D structure information is very limited <xref ref-type="bibr" rid="R37">Zheng et al. [2020]</xref>. Most studies that use 3D structural information utilize convolutional neural networks, which are sensitive to different orientations of the 3D structure, beside the fact that these approaches are computationally expensive.</p><p id="P8">To overcome these limitations, recent studies have proposed graph convolutional network approaches such as <xref ref-type="bibr" rid="R8">Gomes et al. [2017]</xref>, <xref ref-type="bibr" rid="R11">Karimi et al. [2019]</xref>, <xref ref-type="bibr" rid="R20">Nguyen et al. [2021]</xref>, which take 3D structure of proteins as input for DTI prediction task. There are other studies that applied GCNN to the 3D structure of the protein-ligand complex. Among these studies, GraphBAR <xref ref-type="bibr" rid="R25">Son and Kim [2021]</xref>, is the first 3D graph convolutional neural network that used a regression approach to predicts drug-target binding affinities. They used graphs to represent the complex of protein-ligand instead of 3D voxelized grid cube. These graphs were in the form of multiple adjacency matrices in which the entries were calculated based on distance and feature matrices of molecular properties of the atoms. Also, they used a docking simulation method to augment additional data to their model. Lim et. al. <xref ref-type="bibr" rid="R16">Lim et al. [2019]</xref> proposed a graph convolutional network model along with a distance-aware graph attention mechanism to extract features of the interactions binding pose, directly from 3D structure of drug-target complexes from docking softwares. Their model improved over docking and several deep learning-based models in terms of virtual screening and pose prediction task. However, their approach had limitations such as less explainability as well as addition docking errors added to the deep learning model. Pocket Feature is an unsupervised autoencoder model, which was proposed by Torng et. al. <xref ref-type="bibr" rid="R27">Torng and Altman [2019]</xref>, to learn representations from binding sites of the target proteins. The model used 3D graph representations for protein pockets along with 2D graph representations for drugs. They trained a GCNN model to extract features from the graphs of protein pockets and drugs’ SMILEs. Their model outperformed 3DCNN<xref ref-type="bibr" rid="R23">Ragoza et al. [2017]</xref> and docking simlutation models such as AutoDock <xref ref-type="bibr" rid="R29">VinaTrott and Olson [2010]</xref>, RF-Score<xref ref-type="bibr" rid="R17">Liu et al. [2015a]</xref>, and NNScore<xref ref-type="bibr" rid="R17">Liu et al. [2015a]</xref>. Zheng et al <xref ref-type="bibr" rid="R37">Zheng et al. [2020]</xref> pointed out the low efficiency of using direct input of three-dimensional structure and utilized a 2D distance map to represent the proteins. They further converted the problem of drug-target interaction prediction into a classical visual question and answering (VQA) problem, wherein, given a distance map of a protein, the question was whether or not a given drug interacts with the target protein. Although their model outperformed several state-of-the-art models, their VQA system is able to solve a classification task only, where it predicts if there is an interaction between drug-target pairs.</p></sec></sec><sec id="S4" sec-type="materials | methods"><title>Materials and Methods</title><sec id="S5"><title>Preprocessing</title><p id="P9">We use 3D structure of the proteins that are extracted from Protein Data Bank (PDB) files of proteins. PDB data are collections of submitted experimental values (e.g. from NMR, x-ray diffraction, cryo-electron microscopy) for proteins. We use the algorithm proposed by Saberi Fathi et. al <xref ref-type="bibr" rid="R24">Saberi Fathi and Tuszynski [2014]</xref> to find binding pockets of proteins. <xref ref-type="fig" rid="F2">Figure 2</xref> provides a visualization of a protein’s binding sites. This algorithm computes bounding box coordination for each binding site of a protein. These coordinations were then used to reduce complete protein structures into a subset of peptide fragments. These fragments can be represented as a graph wherein each atom is a node and the connection between atoms are edges in the graph. For each atom, a vector was constructed to represent the atom’s features. Also, one-hot encoding of atom type, atom degree, total number of hydrogen atoms and implicit valence of the atom were used to compute feature vector of each atom. This approach yields vector with a size of 1 × 31 for each node. A bidirectional graph is constructed for each ligand, which is represented in Simplified molecular-input line-entry system(SMILE) format in drug-target interaction data sets. In this study, hydrogen atoms are not explicitly represented as nodes in the graph. Also, a vector was constructed to represent atom’s features in the graph. Similarly, one-hot encoding of atom type, atom degree, formal charge of the atom, number of radical electrons of the atom, the atom’s hybridization, atom’s aromaticity, and the number of total hydrogens of the atom were used to construct the features of the atoms in a ligand. This approach yields vector with a size of 1 × 74 for each node. Generated graphs for proteins and ligands are then fed into a graph convolutional neural network to learn embeddings.</p></sec><sec id="S6"><title>Topology Adaptive Graph Convolutional Networks</title><p id="P10">We use a Topology Adaptive Graph CNN (TAGCN) <xref ref-type="bibr" rid="R3">Du et al. [2018]</xref>, which is a variant of graph convolutional and it works by simultaneously sliding a set of fixed-size learnable filters on a given graph. This produces a weighted sum of the filter’s outputs, representing both strength correlation between graph vertices and the vertex features themselves <xref ref-type="bibr" rid="R3">Du et al. [2018]</xref>. The graph convolutional layer for TAGCN is defined as <disp-formula id="FD1"><label>(1)</label><mml:math id="M1"><mml:msup><mml:mi>H</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:munderover><mml:mi>∑</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">(</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>A</mml:mi><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mi>X</mml:mi><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula> where <italic>A</italic> denotes the adjacency matrix, <italic>D<sub>ii</sub></italic> = Σ<sub><italic>j</italic>=0</sub> <italic>A<sub>ij</sub></italic> is its corresponding diagonal degree matrix, Θ<sub><italic>k</italic></sub> is the linear weights that accumulates the results of different hops together, with <italic>K</italic> being the number of hops, indicating the length of a path from a given node.</p></sec><sec id="S7"><title>Pooling Mechanism</title><p id="P11">Once the constructed graphs for proteins and drugs are fed into a series of graph convolutional layers, we then utilize the method proposed by Li et. al. <xref ref-type="bibr" rid="R14">Li et al. [2017]</xref> to extract embedding from the corresponding graphs. For the graph level representation, they define a vector as <disp-formula id="FD2"><label>(2)</label><mml:math id="M2"><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">G</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>tanh</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msub><mml:mi>∑</mml:mi><mml:mrow><mml:mi>ν</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">V</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>ν</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>ν</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>⊙</mml:mo><mml:mi>tanh</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>ν</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>ν</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula> where, <italic>i</italic> and <italic>j</italic> are neural networks, <inline-formula><mml:math id="M3"><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>ν</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> and <italic>x<sub>ν</sub></italic> are input and outputs real-valued vectors, and <inline-formula><mml:math id="M4"><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>ν</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>ν</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:math></inline-formula> is a soft attention mechanism <xref ref-type="bibr" rid="R14">Li et al. [2017]</xref>.</p></sec><sec id="S8"><title>Sequence Handling</title><p id="P12">Following the extraction of embeddings, we then treat the problem as a text classification problem, which can be defined as follows:</p><p id="P13">Let <italic>d</italic> ∈ 𝕏 denote a protein-ligand complex, where 𝕏 is space of embeddings for protein pockets and ligands. Also, define the fixed set of classification labels as ℂ = {0, 1}, with 0 for non-active and 1 for active interactions for a given drug-target pair. Let 𝔻 denote the labeled training set of protein-ligand complexes ⟨<italic>d</italic>, <italic>c</italic>⟩, where ⟨<italic>d</italic>, <italic>c</italic>⟩ ∈ 𝕏 × ℂ, and it is defined as <xref ref-type="disp-formula" rid="FD5">Eq. (3)</xref>. <disp-formula id="FD3"><label>(3)</label><mml:math id="M5"><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mtext>sequence</mml:mtext><mml:mspace width="0.2em"/><mml:mo>(</mml:mo><mml:mspace width="0.2em"/><mml:mtext>protein</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>pockets</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>embeddings</mml:mtext><mml:mspace width="0.2em"/><mml:mo>,</mml:mo><mml:mspace width="0.2em"/><mml:mtext>ligand</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>embedding</mml:mtext><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>.</mml:mo></mml:math></disp-formula></p><p id="P14">Following the approach proposed by Zhou et. al. <xref ref-type="bibr" rid="R38">Zhou et al. [2016]</xref>, the goal is to learn a classifier <italic>γ</italic> that maps created sequences to {0, 1}. <disp-formula id="FD4"><label>(4)</label><mml:math id="M6"><mml:mi>γ</mml:mi><mml:mo>:</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">X</mml:mi></mml:mrow><mml:mo stretchy="false">→</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mo>.</mml:mo></mml:math></disp-formula></p></sec><sec id="S9"><title>Self-Attention</title><p id="P15">Attention mechanism is a method for selectively concentrating on most relevant part of the input vector. It accomplishes this task by mapping a query and a set of key-value pairs to a weighted sum of the values, computed by the relationship of the query and the corresponding key <xref ref-type="bibr" rid="R31">Vaswani et al. [2017]</xref>. Vaswani et al. <xref ref-type="bibr" rid="R31">Vaswani et al. [2017]</xref> describes a particular attention called “Scaled Dot-Product Attention”, where the input is composed of queries, keys and values. Instead of computing a dot product between the inputs and the query, this attention mechanism contains learnable parameters through adopting three trainable weight matrices. More specifically, as shown in <xref ref-type="disp-formula" rid="FD7">Eq. 5</xref>, the queries, keys, and values are packed into matrices Q, K, and V, respectively. Also, the output matrix is computed by calculating the dot product of the query with all the keys, divided by the square root of the dimension of the keys. The division of the square root of the dimension of the keys serves as a scaling factor to avoid pushing the softmax function into small gradient regions <xref ref-type="bibr" rid="R31">Vaswani et al. [2017]</xref>. <disp-formula id="FD5"><label>(5)</label><mml:math id="M7"><mml:mi>Attention</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>Q</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>Softmax</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mi>Q</mml:mi><mml:msup><mml:mi>K</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:msqrt><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:msqrt></mml:mfrac><mml:mo stretchy="false">)</mml:mo><mml:mi>V</mml:mi><mml:mo>.</mml:mo></mml:math></disp-formula></p><p id="P16">This self-attention mechanism uses sequence of embeddings as input, and extracts query, key and value from each embedding. The attention output is then computed using <xref ref-type="disp-formula" rid="FD7">Eq. 5</xref>.</p></sec><sec id="S10"><title>BiLSTM</title><p id="P17">Long Short Term Memory (LSTM) is a variation of recurrent neural networks with three gates in its architecture: the input gate, forget gate, and output gate. The cells in an LSTM remember the information in the sequence for an arbitrary index, and the gates regulate the flow of information to and out of each cell. The forget gate, then, decides which information should be forgotten and which information should persist through the next cell. Zhou et al. <xref ref-type="bibr" rid="R38">Zhou et al. [2016]</xref> developed a BiLSTM network with two subnetworks for the forward and backward sequence context, respectively. Using an element-wise sum, the outputs of the forward and backward passes are then combined, as shown below: <disp-formula id="FD6"><label>(6)</label><mml:math id="M8"><mml:msub><mml:mrow><mml:mover><mml:mi>h</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>LSTM</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>h</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula> <disp-formula id="FD7"><label>(7)</label><mml:math id="M9"><mml:msub><mml:mrow><mml:mover><mml:mi>h</mml:mi><mml:mo accent="false">←</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>LSTM</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover><mml:mi>h</mml:mi><mml:mo accent="false">←</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula> <disp-formula id="FD8"><label>(8)</label><mml:math id="M10"><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>h</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⊕</mml:mo><mml:msub><mml:mover><mml:mi>h</mml:mi><mml:mo accent="false">←</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:math></disp-formula></p></sec><sec id="S11"><title>Classifier</title><p id="P18">The new values previously computed are then concatenated to a 1D vector <italic>I</italic>, and are passed to the classification layers. In this study, 2 fully connected layers are used to classify concatenated vector to either an active or inactive interaction. <xref ref-type="disp-formula" rid="FD11">Eqs. 9</xref> and <xref ref-type="disp-formula" rid="FD12">10</xref> represent the two input and output layers of the classifier network, respectively: <disp-formula id="FD9"><label>(9)</label><mml:math id="M11"><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>RELU</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mtext>input</mml:mtext></mml:mrow></mml:msub><mml:mi>I</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mtext>input</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:math></disp-formula> <disp-formula id="FD10"><label>(10)</label><mml:math id="M12"><mml:mi>O</mml:mi><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mtext>output</mml:mtext></mml:mrow></mml:msub><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mtext>output</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:math></disp-formula></p><p id="P19">Sigmoid function is then used in the final layer 10 to predict the output in the form of a probability. Moreover, the following cross entropy loss function is used to train the model: <disp-formula id="FD11"><label>(11)</label><mml:math id="M13"><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mi>∑</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>.</mml:mo></mml:math></disp-formula></p></sec></sec><sec id="S12"><title>Experiments</title><sec id="S13"><title>Datasets</title><p id="P20">We compare our AttentionSiteDTI with several state-of-the-art methods, using three benchmark datasets: DUD-E dataset, Human dataset and the customized BindingDB dataset. We use the simplest docking-based method to find the binding sites of proteins <xref ref-type="bibr" rid="R24">Saberi Fathi and Tuszynski [2014]</xref>. We expect a boost in the performance of our model with incorporation of more complex (ML-based) binding site prediction algorithms, and/or higher-level computational physics approaches (e.g. molecular dynamics, density functional theory).</p><sec id="S14"><title>DUD-E</title><p id="P21">This dataset <xref ref-type="bibr" rid="R19">Mysinger et al. [2012]</xref> consists of 102 targets from 8 protein families. Each target has around 224 active compounds and more than 10,000 decoys, which were computationally generated in a way that their physical attributes are similar to active compounds but topologically dissimilar. We used three fold cross validation for our experiment, each fold was splitted based on the target, similar targets were kept in the same fold. We used random under sampling on the decoys to make the dataset balanced for training and used unbalanced dataset for evaluation.</p></sec><sec id="S15"><title>Human</title><p id="P22">This dataset <xref ref-type="bibr" rid="R18">Liu et al. [2015b]</xref> was built using a systematic screening framework to create credible and reliable negative sample pairs. the dataset consists of 5,423 interactions. We used the same split used in the DrugVQA <xref ref-type="bibr" rid="R37">Zheng et al. [2020]</xref> (80%,10%,10% random split for training,validation and test set) for a head-to-head comparison.</p></sec><sec id="S16"><title>BindingDB</title><p id="P23">This dataset <xref ref-type="bibr" rid="R7">Gilson et al. [2016]</xref> contains experimentally based assays of the interactions between small molecules and proteins. Following the work in DrugVQA <xref ref-type="bibr" rid="R37">Zheng et al. [2020]</xref>, we used a small subset of the dataset, which consists of 39,747 positive and 31,218 negative samples. Further, in order to validate the generalization ability of the proposed model, the testing set was split into two groups of the proteins; those that are seen in the time of training vs those that are not being seen by the model.</p></sec></sec><sec id="S17"><title>Implementation and evaluation strategy</title><sec id="S18"><title>Experimentation strategies</title><p id="P24">We used Pytorch 1.8.2 (long time support version) for our implementations. We train the models for 30 epochs and used Adam optimizer for training the network with learning rate of 0.001. We used batch size of 100 for better generalization of the network along with a dropout with probability 0.3 after each fully connected layer. The GPU used for the experimentation was (Nvidia RTX 3090) with 24 GB of memory. We used 4 as number of hops in TAGCN for proteins and 2 for ligands. Size of the hidden state for BiLSTM layer in our model was set to 31, which was the output of the graph convolution layer (TAGCN). We used padding of zero to reshape each matrix to the maximum number of binding pockets in the datasets. Also, in order to prevent the attention layer to focus on relationship between different pockets of the protein, the corresponding values for inner protein relationships were set to zero. All other hyperparameters were tuned to yield the best result for each data set, which can be seen in <xref ref-type="table" rid="T1">Table 1</xref>. <italic>Evaluation metrics</italic>. We evaluated our models in terms of several metrics, including Area Under the receiver operating characteristic Curve (AUC). We additionally report precision and recall for human dataset, accuracy for BindingDB dataset and ROC enrichment metric(RE)for DUD-E dataset, which is defined as <disp-formula id="FD12"><label>(12)</label><mml:math id="M14"><mml:mi>R</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mi>R</mml:mi></mml:mrow></mml:mfrac><mml:mspace width="0.0em"/><mml:mtext>at</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>a</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>given</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>FPR</mml:mtext><mml:mspace width="0.2em"/><mml:mtext>threshold</mml:mtext><mml:mo>.</mml:mo></mml:math></disp-formula></p></sec><sec id="S19"><title>Ablation study</title><p id="P25">Our ablation study illustrates the effectiveness of several text classification methods in AttentionSiteDTI framework. We report AUC of all experiments, which is widely used in the literature. The results of this study can be found in <xref ref-type="table" rid="T2">Table 2</xref> showing that the attention mechanism is the most effective method in text classification, and it is particularly advantageous due to its power in explainability. Although, the attention mechanism is showing superior performance compared to Bi-LSTM, it is noteworthy that, for more challenging datasets, attention mechanism cannot capture the relationship between binding sites and ligands. Therefore, for instance in DUD-E dataset, which is intentionally generated in the way that the negative interactions are extremely close to positive ones, attention mechanism with Bi-LSTM architecture gives better results compared to only self-attention mechanism. The Bi-LSTM architecture cannot focus solely on interactions between ligand and binding sites; therefore, it has inferior results compared to other proposed architectures.</p><p id="P26">Finally, the TAGCN architecture for calculating graph embeddings has a better performance compared to GAT <xref ref-type="bibr" rid="R32">Veličković et al. [2018]</xref> and GCN <xref ref-type="bibr" rid="R12">Kipf and Welling [2017]</xref> architectures, but the performance on other graph convolutional layers is yet to be explored.</p></sec><sec id="S20"><title>Comparison on the DUD-E dataset</title><p id="P27">On DUD-E dataset, we compared our proposed model with several state-of-the-art models that can be divided into 4 categories: (1) machine learning-based methods such as NN-score<xref ref-type="bibr" rid="R4">Durrant and McCammon [2011]</xref>, and Random Forest-score (RF-score)<xref ref-type="bibr" rid="R1">Ballester and Mitchell [2010]</xref>; (2) open source molecular docking programs including AutoDock <xref ref-type="bibr" rid="R29">VinaTrott and Olson [2010]</xref> and Smina<xref ref-type="bibr" rid="R13">Koes et al. [2013]</xref>; (3) deep learning-based models such as AtomNet<xref ref-type="bibr" rid="R33">Wallach et al. [2015]</xref>, 3D-CNN<xref ref-type="bibr" rid="R23">Ragoza et al. [2017]</xref>, which use neural networks to extract features from 3D structural information; and (4) graph-based models like PocketGCN<xref ref-type="bibr" rid="R27">Torng and Altman [2019]</xref>, GNN<xref ref-type="bibr" rid="R30">Tsubaki et al. [2018]</xref>, DrugVQA<xref ref-type="bibr" rid="R37">Zheng et al. [2020]</xref>, which are all based on graph representations. PocketGCN utilizes two Graph-CNNs that automatically extract features from the graph of protein pockets and ligands to capture protein-ligand binding interactions. CPI-GNN<xref ref-type="bibr" rid="R34">Wang et al. [2020]</xref> is a prediction model that combines a graph neural network (GNN) for compounds and a convolutional neural network (CNN) for targets. DrugVQA utilizes a 2D distance map to represent proteins in a Visual Question Answering system, where the images are the distance maps of the proteins, the questions are the SMILES of the drugs, and the answers are whether the drug-target pair will interact. Note that the scores of these models are derived form Zheng et. al.<xref ref-type="bibr" rid="R37">Zheng et al. [2020]</xref>. Also, following Zheng et al.’s work, we perform 3-fold cross-validation on this dataset, and report the average evaluation metrics. Also, we employ F1 score and ROC enrichment (RE) at thresholds 0.5%, 1%, 2%, and 5% . The results in <xref ref-type="table" rid="T3">Table 3</xref> indicate that our model achieves state-of-the-art performance in DTI prediction on all metrics with significant improvement at 0.5% RE. Also, we hypothesize that the poor performance of AtomNet and 3D-CNN may be due to the sparsity of 3D space, as they use the whole 3D structure of the proteins.</p></sec><sec id="S21"><title>Comparison on the human dataset</title><p id="P28">On Human dataset, we compared our model against several traditional ML models such as K-Nearest Neighbors (KNN), Random Forest (RF), L2-logistic (L2)(these results were gathered from <xref ref-type="bibr" rid="R17">Liu et al. [2015a]</xref>); and some recently developed graph-based approaches including Graph CNNs(GCNs)<xref ref-type="bibr" rid="R12">Kipf and Welling [2017]</xref> , CPI–GNN<xref ref-type="bibr" rid="R34">Wang et al. [2020]</xref>, DrugVQA<xref ref-type="bibr" rid="R37">Zheng et al. [2020]</xref>, TransformerCPI<xref ref-type="bibr" rid="R2">Chen et al. [2020]</xref> as well as GraphDTA<xref ref-type="bibr" rid="R20">Nguyen et al. [2021]</xref> that was originally designed for regression task, and was tailored to binary classification task by <xref ref-type="bibr" rid="R36">Wu et al. [2021]</xref>. For a head-to-head comparison with other models, we followed the same experimental setting as in <xref ref-type="bibr" rid="R15">Lim et al. [2016]</xref>, <xref ref-type="bibr" rid="R30">Tsubaki et al. [2018]</xref>. Also, we repeated our experiments with three different random seeds, similar to DrugVQA<xref ref-type="bibr" rid="R37">Zheng et al. [2020]</xref>. The performances of the aforementioned models were obtained from <xref ref-type="bibr" rid="R36">Wu et al. [2021]</xref>, and are summarized in <xref ref-type="table" rid="T4">Table 4</xref>. It can be observed that the prediction accuracy of our proposed model is superior than all ML- and GNN-based models; and it achieves competitive performance with DrugVQA in terms of precision and recall. The relatively low performance of ML-based models is indeed in line with our expectation, and is due to their use of low-quality features, unable of capturing complex non-linear relationships in drug-drug interaction. The deep learning models, on the other hand, are very powerful in extracting important features governing the complex interactions in a drug-target pair. On this basis, our model further improves on the accuracy, indicating that the quality of learned information in drug-target interactions is guaranteed by the back propagation of the end-to-end learning of our AttentionSiteDTI.</p></sec><sec id="S22"><title>Comparison on the BindingDB dataset</title><p id="P29">On BindingDB dataset, we further compared our model against Tiresias<xref ref-type="bibr" rid="R5">Fokoue et al. [2016]</xref>, DBN<xref ref-type="bibr" rid="R35">Wen et al. [2017]</xref>, CPI-GNN <xref ref-type="bibr" rid="R34">Wang et al. [2020]</xref>, E2E<xref ref-type="bibr" rid="R6">Gao et al. [2018]</xref>, DrugVQA<xref ref-type="bibr" rid="R37">Zheng et al. [2020]</xref> and Bridge-DPI<xref ref-type="bibr" rid="R36">Wu et al. [2021]</xref> as baselines. Tiresias uses similarity measures of drug and target pairs. DBN uses stacked restricted Boltzmann machines with the inputs in the form of extended connectivity fingerprints. As mentioned earlier, CPI-GNN combines a graph neural network (GNN) for compounds and a convolutional neural network (CNN) for targets to capture drug-target interactions. E2E is a GNN-based model that uses LSTM to learn drug-target pair information with Gene Ontology annotations. DrugVQA, as previously mentioned, is a Visual Question Answering system, where the images are the distance maps of the proteins, the questions are the SMILES of the drugs, and the answers are whether the drug-target pair will interact. Finally, BridgeDPI uses convolutional neural networks to obtain embeddings for drugs and proteins, as well as a GNN to learn the associations between proteins/drugs using some hyper-nodes that are connections between proteins/drugs. Note that the scores for all these models are derived from <xref ref-type="bibr" rid="R36">Wu et al. [2021]</xref>. Also, following suggestions from previous works, we report the prediction results in terms of AUC and Accuracy (ACC) on the test set, which is divided into a set of unseen protein (the proteins that are not observed in training set) and a set of seen protein (the proteins that are observed in training set). This, indeed, makes the customized BindingDB dataset suitable to assess models’ generalization ability to unknown proteins, which should be the focus in prediction problems (i.e., cold-start problem), as there are a large number of unknown proteins in nature.</p><p id="P30">As experimental results indicate in <xref ref-type="fig" rid="F3">Figure 3</xref>, all models generally perform well on seen proteins with AUC above 0.9, and ACC exceeding 0.85. However, these models show different and much worse performance on unseen proteins, which reflects the complexity of this more realistic learning scenario. Tiresias is a similarity-based model that uses a set of expert designed similarity measures as the features for proteins and drugs. The poor performance of Tiresias on the unseen proteins is perhaps due to the fact that these handcrafted features are not sufficient in capturing interactions between drug-target pairs, thus resulting in the accuracy even less than 0.5 on unseen proteins. On the other hand, the good performance of deep learning-based models including DBN, CPI-GNN, E2E, DrugVQA, BridgeDPI as well as our AttentionSiteDTI shows the effectiveness of these models in capturing relevant features that are critical in DTI prediction problem. As the results show, our model achieves the best performance with AUC of 0.97 and 0.94 on seen and unseen proteins, respectively. Also, in terms of accuracy, our AttentionSiteDTI outperforms all other models with accuracy reaching 0.89 in unseen proteins. This is an indication that our attention-based bidirectional LSTM network is, indeed, effective in relation classification of drug-target (protein pocket) pairs by learning the deeper interaction rules, governing the relationship between proteins’ binding sites (pockets) and drugs. Also, the seemingly good performance of baselines on seen proteins can be an indication of over-fitting.</p></sec><sec id="S23"><title>Model Explainability</title><p id="P31">Ligands bind to certain parts (active sites) of proteins either blocking the binding of other ligands or inducing a change in the protein structure, which produces a therapeutic effect. Binding at other sites that provide no therapeutic value are “non-active,” and generally do not cause a direct biological effect. Ligands binding to active sites and inducing a change in protein structure (conformation) are less likely in our system of study, and are probably not as helpful for building models (usually these ligands/therapeutic agents are employed/considered when a patient has an ailment, which causes natural biochemicals to be produced in insufficient quantities).</p><p id="P32">In this work the attention mechanism enables the model to predict which protein binding sites are more probable to bind with a given ligand. This probability is the attention matrix computed in the model. The attention visualization can be found in <xref ref-type="fig" rid="F4">Figure 4</xref> as the heat map of the protein for the complex of SARS-CoV2 Spike protein and human, host cell-expressing ACE2 in the interaction with the drug named Darunavir. The projection of the heat map on the protein is depicted in this figure, as well.</p></sec></sec></sec><sec id="S24"><title>SARS-CoV-2 Case study and In Lab Validation</title><p id="P33">To further evaluate the practical potential of our proposed model, we experimentally tested and validated the binding interactions between spike (or ACE2) protein and seven candidate compounds including N-acetyl-neuraminic acid, 3<italic>α</italic>, 6<italic>α</italic>Mannopentaose, N-glycolylneuraminic acid, 2-Keto-3-deoxyoctonate ammonium salt, cytidine5-monophospho-N-acetylneuraminic acid sodium salt and Darunavir as inhibitor molecules to bind to the spike protein, or the ACE2 receptor protein, which has been shown to be the primary host factor recognized and targeted by SARS-CoV-2 Spike protein. The primary goal in our experimental investigations is to determine the ability of those seven compounds to disrupt the important interaction between spike protein and ACE2, which, in turn, leads to inability of SARS-CoV-2 virus to infect host cells. As the results show in <xref ref-type="table" rid="T5">Table 5</xref>, we observe high agreement (five out of seven matched results) between the predicted and experimentally-measured drug-target interactions, which illustrates the potential of our AttentionSiteDTI as an effective complementary pre-screening tool to accelerate the exploration, and recommendation of lead compounds with desired interaction properties toward their targets. In our experiment, we set the activity threshold to 15 nm to only capture highly active compounds; thereby, limiting the influence of interactions at neighboring sites and weak interactions with poor coordination to the binding site center.</p></sec><sec id="S25" sec-type="conclusions"><title>Conclusion</title><p id="P34">In this work, we proposed an end-to-end Graph Convolutional Neural Network(GCNN)-based model, built on self-attention bidirectional Long Short-Term Memory mechanism, which captures any relationship between binding sites of a given protein and the drug in a sequence analogous to a sentence with relational meaning between its biochemical entities a.k.a. protein pockets and drug molecule. Our proposed framework enables learning which binding sites of a protein interact with a given ligand, thus allows interpretability and better generalizability, while outperforms state-of-the-art methods in prediction of drug-target interaction. We experimentally validate the predicted binding interactions between seven candidate compounds and spike (or ACE2) protein. The results of our in-lab validation showed high agreement between the computationally-predicted and experimentally-observed binding interactions. Our model exhibit state-of-the-art performance, is highly generalizable, provide interpretable outputs and performs well when validated against in-lab experiments. As a result, we expect it to be an effective virtual screening tool for drug discovery.</p></sec></body><back><ack id="S26"><title>Acknowledgments</title><p>We thank Ms.Katalina Biondi for discussions and her valuable feedback and comments on earlier versions of the manuscript.</p></ack><bio id="B1"><title>Biographical Note</title><p id="P35"><bold>Mehdi Yazdan-Jahromi</bold> is a second year PhD student at University of Central Florida. His current research interests include Graph Neural Networks, Algorithmic Fairness.</p></bio><bio id="B2"><p id="P36"><bold>Niloofar Yousefi</bold> PhD (University of Central Florida) is a Postdoctoral Research Associate with the emphasize on Computer Science, Machine Learning and Agent-based Modeling at UCF’s Complex Adaptive Systems (CAS) laboratory in the collage of Engineering and Computer Science. <bold>Aida Tayebi</bold> is a second year PhD student at University of Central Florida. Her current research interests include Algorithmic Fairness, and bias mitigation techniques in DTI. <bold>Ozlem Ozmen Garibay</bold> is an Assistant Professor of Industrial Engineering and Management System at the University of Central Florida where she directs the Human-Centered Artificial Intelligence Research Lab (Human-CAIR Lab). Prior to that, she served as the Director of Research Technology. Her areas of research are big data, social media analysis, social cybersecurity, artificial social intelligence, human-machine teams, social and economic networks, network science, STEM education analytics, higher education economic impact and engagement, artificial intelligence, evolutionary computation, and complex systems.</p></bio><bio id="B3"><p id="P37"><bold>Sudipta Seal</bold> is currently the chair of the Department of Materials Science and Engineering at University of Central Florida, as well as a Pegasus Professor and a University Distinguished Professor. He joined the Advanced Materials Processing and Analysis Center and UCF in 1997. He has been consistently productive in research, instruction and service to UCF since 1998. He has served as the Nano Initiative coordinator for the vice president of research and commercialization. He served as the director of AMPAC and the NanoScience Technology Center from 2009 to 2017.</p></bio><bio id="B4"><p id="P38"><bold>Elayaraja Kolanthai</bold> Ph.D. (Anna University) is a Postdoctoral Research Associate at UCF’s Materials Science and Engineering. His current research interests include Development of nanoparticles, layer-by-layer antimicrobial/antiviral nanoparticle coating, polymer composites for tissue engineering, and gene/drug delivery application.</p></bio><bio id="B5"><p id="P39"><bold>Craig J. Neal</bold>PhD (University of Central Florida) is a Postdoctoral Research Associate at UCF’s Materials Science and Engineering. His current research interests include Wet chemical synthesis and surface engineering of nanoparticles for biomedical applications and electrochemical devices. Electroanalysis of nanomaterials and bio-nano interactions.</p></bio><sec sec-type="data-availability" id="S27"><title>Data and Code availability</title><p>All datasets are publicly available. DUD-E dataset is available at <ext-link ext-link-type="uri" xlink:href="http://dude.docking.org/">http://dude.docking.org</ext-link>, Human dataset is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/IBMInterpretableDTIP">https://github.com/IBMInterpretableDTIP</ext-link> and finally the customized BindingDB-IBM dataset can be found at <ext-link ext-link-type="uri" xlink:href="https://github.com/masashitsubaki/CPI_prediction/tree/master/">https://github.com/masashitsubaki/CPI_prediction/tree/master/</ext-link>. We used 3D structures of proteins in Human dataset from <ext-link ext-link-type="uri" xlink:href="https://github.com/prokia/drugVQA">https://github.com/prokia/drugVQA</ext-link>. Also, all instructions and codes for our experiments are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/yazdanimehdi/AttentionSiteDTI">https://github.com/yazdanimehdi/AttentionSiteDTI</ext-link></p></sec><fn-group><fn id="FN1" fn-type="conflict"><p id="P40">Competing interests</p><p id="P41">There is NO Competing Interest.</p></fn></fn-group><ref-list><ref id="R1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ballester</surname><given-names>PJ</given-names></name><name><surname>Mitchell</surname><given-names>JBO</given-names></name></person-group><article-title>A machine learning approach to predicting protein–ligand binding affinity with applications to molecular docking</article-title><source>Bioinformatics</source><year>2010</year><volume>26</volume><issue>9</issue><fpage>1169</fpage><lpage>1175</lpage><comment>ISSN 1367-4803</comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btq112</pub-id></element-citation></ref><ref id="R2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>L</given-names></name><name><surname>Tan</surname><given-names>X</given-names></name><name><surname>Wang</surname><given-names>D</given-names></name><name><surname>Zhong</surname><given-names>F</given-names></name><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Yang</surname><given-names>T</given-names></name><name><surname>Luo</surname><given-names>X</given-names></name><name><surname>Chen</surname><given-names>K</given-names></name><name><surname>Jiang</surname><given-names>H</given-names></name><name><surname>Zheng</surname><given-names>M</given-names></name></person-group><article-title>Transformercpi: improving compound–protein interaction prediction by sequence-based deep learning with self-attention mechanism and label reversal experiments</article-title><source>Bioinformatics</source><year>2020</year><volume>36</volume><issue>16</issue><fpage>4406</fpage><lpage>4414</lpage></element-citation></ref><ref id="R3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Du</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>S</given-names></name><name><surname>Wu</surname><given-names>G</given-names></name><name><surname>Moura</surname><given-names>JMF</given-names></name><name><surname>Kar</surname><given-names>S</given-names></name></person-group><source>Topology adaptive graph convolutional networks</source><year>2018</year></element-citation></ref><ref id="R4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Durrant</surname><given-names>JD</given-names></name><name><surname>McCammon</surname><given-names>JA</given-names></name></person-group><article-title>NNScore 2.0: A Neural-Network Receptor–Ligand Scoring Function</article-title><source>Journal of Chemical Information and Modeling</source><year>2011</year><volume>51</volume><issue>11</issue><fpage>2897</fpage><lpage>2903</lpage><comment>ISSN 1549-9596</comment><pub-id pub-id-type="doi">10.1021/ci2003889</pub-id></element-citation></ref><ref id="R5"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Fokoue</surname><given-names>A</given-names></name><name><surname>Sadoghi</surname><given-names>M</given-names></name><name><surname>Hassanzadeh</surname><given-names>O</given-names></name><name><surname>Zhang</surname><given-names>P</given-names></name></person-group><source>Predicting drug-drug interactions through large-scale similarity-based link prediction</source><conf-name>European Semantic Web Conference</conf-name><publisher-name>Springer</publisher-name><year>2016</year><fpage>774</fpage><lpage>789</lpage></element-citation></ref><ref id="R6"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Gao</surname><given-names>KY</given-names></name><name><surname>Fokoue</surname><given-names>A</given-names></name><name><surname>Luo</surname><given-names>H</given-names></name><name><surname>Iyengar</surname><given-names>A</given-names></name><name><surname>Dey</surname><given-names>S</given-names></name><name><surname>Zhang</surname><given-names>P</given-names></name></person-group><source>Interpretable drug target prediction using deep neural representation</source><conf-name>IJCAI</conf-name><year>2018</year><volume>2018</volume><fpage>3371</fpage><lpage>3377</lpage></element-citation></ref><ref id="R7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilson</surname><given-names>MK</given-names></name><name><surname>Liu</surname><given-names>T</given-names></name><name><surname>Baitaluk</surname><given-names>M</given-names></name><name><surname>Nicola</surname><given-names>G</given-names></name><name><surname>Hwang</surname><given-names>L</given-names></name><name><surname>Chong</surname><given-names>J</given-names></name></person-group><article-title>Bindingdb in 2015: a public database for medicinal chemistry, computational chemistry and systems pharmacology</article-title><source>Nucleic acids research</source><year>2016</year><volume>44</volume><issue>D1</issue><fpage>D1045</fpage><lpage>D1053</lpage></element-citation></ref><ref id="R8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gomes</surname><given-names>J</given-names></name><name><surname>Ramsundar</surname><given-names>B</given-names></name><name><surname>Feinberg</surname><given-names>EN</given-names></name><name><surname>Pande</surname><given-names>VS</given-names></name></person-group><article-title>Atomic convolutional networks for predicting protein-ligand binding affinity</article-title><source>arXiv preprint</source><year>2017</year><elocation-id>arxiv:1703.10603</elocation-id></element-citation></ref><ref id="R9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>T</given-names></name><name><surname>Heidemeyer</surname><given-names>M</given-names></name><name><surname>Ban</surname><given-names>F</given-names></name><name><surname>Cherkasov</surname><given-names>A</given-names></name><name><surname>Ester</surname><given-names>M</given-names></name></person-group><article-title>Simboost: a read-across approach for predicting drug–target binding affinities using gradient boosting machines</article-title><source>Journal of cheminformatics</source><year>2017</year><volume>9</volume><issue>1</issue><fpage>1</fpage><lpage>14</lpage></element-citation></ref><ref id="R10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>M</given-names></name><name><surname>Li</surname><given-names>Z</given-names></name><name><surname>Zhang</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Yuan</surname><given-names>Q</given-names></name><name><surname>Wei</surname><given-names>Z</given-names></name></person-group><article-title>Drug–target affinity prediction using graph neural network and contact maps</article-title><source>RSC Advances</source><year>2020</year><volume>10</volume><issue>35</issue><fpage>20701</fpage><lpage>20712</lpage></element-citation></ref><ref id="R11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karimi</surname><given-names>M</given-names></name><name><surname>Wu</surname><given-names>D</given-names></name><name><surname>Wang</surname><given-names>Z</given-names></name><name><surname>Shen</surname><given-names>Y</given-names></name></person-group><article-title>Deepaffinity: interpretable deep learning of compound–protein affinity through unified recurrent and convolutional neural networks</article-title><source>Bioinformatics</source><year>2019</year><volume>35</volume><issue>18</issue><fpage>3329</fpage><lpage>3338</lpage></element-citation></ref><ref id="R12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kipf</surname><given-names>TN</given-names></name><name><surname>Welling</surname><given-names>M</given-names></name></person-group><source>Semi-supervised classification with graph convolutional networks</source><year>2017</year></element-citation></ref><ref id="R13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koes</surname><given-names>DR</given-names></name><name><surname>Baumgartner</surname><given-names>MP</given-names></name><name><surname>Camacho</surname><given-names>CJ</given-names></name></person-group><article-title>Lessons Learned in Empirical Scoring with smina from the CSAR 2011 Benchmarking Exercise</article-title><source>Journal of Chemical Information and Modeling</source><year>2013</year><volume>53</volume><issue>8</issue><fpage>1893</fpage><lpage>1904</lpage><comment>ISSN 1549-9596</comment><pub-id pub-id-type="doi">10.1021/ci300604z</pub-id></element-citation></ref><ref id="R14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Tarlow</surname><given-names>D</given-names></name><name><surname>Brockschmidt</surname><given-names>M</given-names></name><name><surname>Zemel</surname><given-names>R</given-names></name></person-group><source>Gated graph sequence neural networks</source><year>2017</year></element-citation></ref><ref id="R15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lim</surname><given-names>H</given-names></name><name><surname>Gray</surname><given-names>P</given-names></name><name><surname>Xie</surname><given-names>L</given-names></name><name><surname>Poleksic</surname><given-names>A</given-names></name></person-group><article-title>Improved genome-scale multi-target virtual screening via a novel collaborative filtering approach to cold-start problem</article-title><source>Scientific reports</source><year>2016</year><volume>6</volume><issue>1</issue><fpage>1</fpage><lpage>11</lpage></element-citation></ref><ref id="R16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lim</surname><given-names>J</given-names></name><name><surname>Ryu</surname><given-names>S</given-names></name><name><surname>Park</surname><given-names>K</given-names></name><name><surname>Choe</surname><given-names>YJ</given-names></name><name><surname>Ham</surname><given-names>J</given-names></name><name><surname>Kim</surname><given-names>WY</given-names></name></person-group><article-title>Predicting drug–target interaction using a novel graph neural network with 3d structure-embedded graph representation</article-title><source>Journal of chemical information and modeling</source><year>2019</year><volume>59</volume><issue>9</issue><fpage>3981</fpage><lpage>3988</lpage></element-citation></ref><ref id="R17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>H</given-names></name><name><surname>Sun</surname><given-names>J</given-names></name><name><surname>Guan</surname><given-names>J</given-names></name><name><surname>Zheng</surname><given-names>J</given-names></name><name><surname>Zhou</surname><given-names>S</given-names></name></person-group><article-title>Improving compound–protein interaction prediction by building up highly credible negative samples</article-title><source>Bioinformatics</source><year>2015a</year><volume>31</volume><issue>12</issue><fpage>i221</fpage><lpage>i229</lpage><comment>ISSN 1367-4803</comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btv256</pub-id></element-citation></ref><ref id="R18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>H</given-names></name><name><surname>Sun</surname><given-names>J</given-names></name><name><surname>Guan</surname><given-names>J</given-names></name><name><surname>Zheng</surname><given-names>J</given-names></name><name><surname>Zhou</surname><given-names>S</given-names></name></person-group><article-title>Improving compound–protein interaction prediction by building up highly credible negative samples</article-title><source>Bioinformatics</source><year>2015b</year><volume>31</volume><issue>12</issue><fpage>i221</fpage><lpage>i229</lpage></element-citation></ref><ref id="R19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mysinger</surname><given-names>MM</given-names></name><name><surname>Carchia</surname><given-names>M</given-names></name><name><surname>Irwin</surname><given-names>JJ</given-names></name><name><surname>Shoichet</surname><given-names>BK</given-names></name></person-group><article-title>Directory of useful decoys, enhanced (dud-e): better ligands and decoys for better benchmarking</article-title><source>Journal of medicinal chemistry</source><year>2012</year><volume>55</volume><issue>14</issue><fpage>6582</fpage><lpage>6594</lpage></element-citation></ref><ref id="R20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nguyen</surname><given-names>T</given-names></name><name><surname>Le</surname><given-names>H</given-names></name><name><surname>Quinn</surname><given-names>TP</given-names></name><name><surname>Nguyen</surname><given-names>T</given-names></name><name><surname>Le</surname><given-names>TD</given-names></name><name><surname>Venkatesh</surname><given-names>S</given-names></name></person-group><article-title>Graphdta: Predicting drug–target binding affinity with graph neural networks</article-title><source>Bioinformatics</source><year>2021</year><volume>37</volume><issue>8</issue><fpage>1140</fpage><lpage>1147</lpage></element-citation></ref><ref id="R21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pahikkala</surname><given-names>T</given-names></name><name><surname>Airola</surname><given-names>A</given-names></name><name><surname>Pietilä</surname><given-names>S</given-names></name><name><surname>Shakyawar</surname><given-names>S</given-names></name><name><surname>Szwajda</surname><given-names>A</given-names></name><name><surname>Tang</surname><given-names>J</given-names></name><name><surname>Aittokallio</surname><given-names>T</given-names></name></person-group><article-title>Toward more realistic drug–target interaction predictions</article-title><source>Briefings in bioinformatics</source><year>2015</year><volume>16</volume><issue>2</issue><fpage>325</fpage><lpage>337</lpage></element-citation></ref><ref id="R22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pettersen</surname><given-names>EF</given-names></name><name><surname>Goddard</surname><given-names>TD</given-names></name><name><surname>Huang</surname><given-names>CC</given-names></name><name><surname>Couch</surname><given-names>GS</given-names></name><name><surname>Greenblatt</surname><given-names>DM</given-names></name><name><surname>Meng</surname><given-names>EC</given-names></name><name><surname>Ferrin</surname><given-names>TE</given-names></name></person-group><article-title>Ucsf chimera—a visualization system for exploratory research and analysis</article-title><source>Journal of computational chemistry</source><year>2004</year><volume>25</volume><issue>13</issue><fpage>1605</fpage><lpage>1612</lpage></element-citation></ref><ref id="R23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ragoza</surname><given-names>M</given-names></name><name><surname>Hochuli</surname><given-names>J</given-names></name><name><surname>Idrobo</surname><given-names>E</given-names></name><name><surname>Sunseri</surname><given-names>J</given-names></name><name><surname>Koes</surname><given-names>DR</given-names></name></person-group><article-title>Protein–ligand scoring with convolutional neural networks</article-title><source>Journal of chemical information and modeling</source><year>2017</year><volume>57</volume><issue>4</issue><fpage>942</fpage><lpage>957</lpage></element-citation></ref><ref id="R24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saberi Fathi</surname><given-names>SM</given-names></name><name><surname>Tuszynski</surname><given-names>JA</given-names></name></person-group><article-title>A simple method for finding a protein’s ligand-binding pockets</article-title><source>BMC Structural Biology</source><year>2014</year><volume>14</volume><issue>1</issue><fpage>18</fpage><comment>URL <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1186/1472-6807-14-18">https://doi.org/10.1186/1472-6807-14-18</ext-link></comment><pub-id pub-id-type="doi">10.1186/1472-6807-14-18</pub-id></element-citation></ref><ref id="R25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Son</surname><given-names>J</given-names></name><name><surname>Kim</surname><given-names>D</given-names></name></person-group><article-title>Development of a graph convolutional neural network model for efficient prediction of protein-ligand binding affinities</article-title><source>PloS one</source><year>2021</year><volume>16</volume><issue>4</issue><elocation-id>e0249404</elocation-id></element-citation></ref><ref id="R26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stepniewska-Dziubinska</surname><given-names>MM</given-names></name><name><surname>Zielenkiewicz</surname><given-names>P</given-names></name><name><surname>Siedlecki</surname><given-names>P</given-names></name></person-group><article-title>Development and evaluation of a deep learning model for protein–ligand binding affinity prediction</article-title><source>Bioinformatics</source><year>2018</year><volume>34</volume><issue>21</issue><fpage>3666</fpage><lpage>3674</lpage></element-citation></ref><ref id="R27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Torng</surname><given-names>W</given-names></name><name><surname>Altman</surname><given-names>RB</given-names></name></person-group><article-title>Graph Convolutional Neural Networks for Predicting Drug-Target Interactions</article-title><source>Journal of Chemical Information and Modeling</source><year>2019</year><volume>59</volume><issue>10</issue><fpage>4131</fpage><lpage>4149</lpage><comment>ISSN 1549-9596</comment><pub-id pub-id-type="doi">10.1021/acs.jcim.9b00628</pub-id></element-citation></ref><ref id="R28"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Tradigo</surname><given-names>G</given-names></name></person-group><source>Protein Contact Maps</source><publisher-name>Springer</publisher-name><publisher-loc>New York, New York, NY</publisher-loc><year>2013</year><fpage>1771</fpage><lpage>1773</lpage><comment>ISBN 978-1-4419-9863-7. URL <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/978-1-4419-9863-7_980">https://doi.org/10.1007/978-1-4419-9863-7_980</ext-link></comment><pub-id pub-id-type="doi">10.1007/978-1-4419-9863-7_980</pub-id></element-citation></ref><ref id="R29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Trott</surname><given-names>O</given-names></name><name><surname>Olson</surname><given-names>AJ</given-names></name></person-group><article-title>Autodock vina: improving the speed and accuracy of docking with a new scoring function, efficient optimization, and multithreading</article-title><source>Journal of computational chemistry</source><year>2010</year><volume>31</volume><issue>2</issue><fpage>455</fpage><lpage>461</lpage></element-citation></ref><ref id="R30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsubaki</surname><given-names>M</given-names></name><name><surname>Tomii</surname><given-names>K</given-names></name><name><surname>Sese</surname><given-names>J</given-names></name></person-group><article-title>Compound–protein interaction prediction with end-to-end learning of neural networks for graphs and sequences</article-title><source>Bioinformatics</source><year>2018</year><volume>35</volume><issue>2</issue><fpage>309</fpage><lpage>318</lpage><comment>ISSN 1367-4803</comment><pub-id pub-id-type="doi">10.1093/bioinformatics/bty535</pub-id></element-citation></ref><ref id="R31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vaswani</surname><given-names>A</given-names></name><name><surname>Shazeer</surname><given-names>N</given-names></name><name><surname>Parmar</surname><given-names>N</given-names></name><name><surname>Uszkoreit</surname><given-names>J</given-names></name><name><surname>Jones</surname><given-names>L</given-names></name><name><surname>Gomez</surname><given-names>AN</given-names></name><name><surname>Kaiser</surname><given-names>L</given-names></name><name><surname>Polosukhin</surname><given-names>I</given-names></name></person-group><source>Attention is all you need</source><year>2017</year></element-citation></ref><ref id="R32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Veličković</surname><given-names>P</given-names></name><name><surname>Cucurull</surname><given-names>G</given-names></name><name><surname>Casanova</surname><given-names>A</given-names></name><name><surname>Romero</surname><given-names>A</given-names></name><name><surname>Liò</surname><given-names>P</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name></person-group><source>Graph attention networks</source><year>2018</year></element-citation></ref><ref id="R33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wallach</surname><given-names>I</given-names></name><name><surname>Dzamba</surname><given-names>M</given-names></name><name><surname>Heifets</surname><given-names>A</given-names></name></person-group><article-title>Atomnet: a deep convolutional neural network for bioactivity prediction in structure-based drug discovery</article-title><source>arXiv preprint</source><year>2015</year><elocation-id>arxiv:1510.02855</elocation-id></element-citation></ref><ref id="R34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>E</given-names></name><name><surname>Wang</surname><given-names>F</given-names></name><name><surname>Yang</surname><given-names>Z</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Lin</surname><given-names>H</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name></person-group><article-title>A Graph Convolutional Network–Based Method for Chemical-Protein Interaction Extraction: Algorithm Development</article-title><source>JMIR Medical Informatics</source><year>2020</year><volume>8</volume><issue>5</issue><elocation-id>e17643</elocation-id><comment>ISSN 2291-9694</comment><pub-id pub-id-type="doi">10.2196/17643</pub-id></element-citation></ref><ref id="R35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wen</surname><given-names>M</given-names></name><name><surname>Zhang</surname><given-names>Z</given-names></name><name><surname>Niu</surname><given-names>S</given-names></name><name><surname>Sha</surname><given-names>H</given-names></name><name><surname>Yang</surname><given-names>R</given-names></name><name><surname>Yun</surname><given-names>Y</given-names></name><name><surname>Lu</surname><given-names>H</given-names></name></person-group><article-title>Deep-learning-based drug–target interaction prediction</article-title><source>Journal of proteome research</source><year>2017</year><volume>16</volume><issue>4</issue><fpage>1401</fpage><lpage>1409</lpage></element-citation></ref><ref id="R36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>Y</given-names></name><name><surname>Gao</surname><given-names>M</given-names></name><name><surname>Zeng</surname><given-names>M</given-names></name><name><surname>Chen</surname><given-names>F</given-names></name><name><surname>Li</surname><given-names>M</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name></person-group><article-title>BridgeDPI: A Novel Graph Neural Network for Predicting Drug-Protein Interactions</article-title><source>arXiv</source><year>2021</year></element-citation></ref><ref id="R37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>S</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Chen</surname><given-names>S</given-names></name><name><surname>Xu</surname><given-names>J</given-names></name><name><surname>Yang</surname><given-names>Y</given-names></name></person-group><article-title>Predicting drug–protein interaction using quasi-visual question answering system</article-title><source>Nature Machine Intelligence</source><year>2020</year><volume>2</volume><issue>2</issue><fpage>134</fpage><lpage>140</lpage></element-citation></ref><ref id="R38"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>P</given-names></name><name><surname>Shi</surname><given-names>W</given-names></name><name><surname>Tian</surname><given-names>J</given-names></name><name><surname>Qi</surname><given-names>Z</given-names></name><name><surname>Li</surname><given-names>B</given-names></name><name><surname>Hao</surname><given-names>H</given-names></name><name><surname>Xu</surname><given-names>B</given-names></name></person-group><source>Attention-based bidirectional long short-term memory networks for relation classification</source><conf-name>Proceedings of the 54th annual meeting of the association for computational linguistics (volume 2: Short papers)</conf-name><year>2016</year><fpage>207</fpage><lpage>212</lpage></element-citation></ref></ref-list></back><floats-group><boxed-text id="BX1" position="float" orientation="portrait"><caption><title>Key Points</title></caption><list list-type="bullet" id="L1"><list-item><p>We build an end-to-end Graph Convolutional Neural Network (GCNN)-based model for predicting drug-target interactions.</p></list-item><list-item><p>Self-attention mechanism enables the model to predict the most active binding site of the protein in drug-target interaction which translates to interpretablity of the deep-learning model in this branch of problem.</p></list-item><list-item><p>The proposed model showed the best generalizability among all other drug-target interaction prediction models.</p></list-item><list-item><p>We validated our predictions by experimentally testing the candidate compounds.</p></list-item></list></boxed-text><fig id="F1" position="float"><label>Fig. 1</label><caption><title>Our proposed framework includes 5 main modules</title><p>(1) Preprocessing module that consists of finding the binding sites of proteins; (2) AttentionSiteDTI deep learning module, where we construct graph representations of ligands’ SMILE and proteins’ binding sites, and we create a graph convolutional neural network armed with an attention pooling mechanism to extract learnable embeddings from graphs, as well as a self-attention mechanism to learn relationship between ligands and proteins’ binding sites; (3) Prediction module to predict unknown interaction in a drug-target pair, which can address both classification and regression tasks; (4) Interpretation module to provide a deeper understanding of which binding sites of a target protein are more probable to bind with a given ligand. (5) In-lab validations, where we compare our computationally-predicted results with experimentally-observed (measured) drug-target interactions in laboratory to test and validate the practical potential of our proposed model.</p></caption><graphic xlink:href="EMS146591-f001"/></fig><fig id="F2" position="float"><label>Fig. 2</label><caption><p>Depiction of COVID spike protein and ACE2 complex with PDB-ID of 6M0J; Color of the surface represents the binding sites computed through Saberi Fathi et. al algorithm which yields the binding site of the proteins. All protein visualization was produced with UCSF Chimera software <xref ref-type="bibr" rid="R22">Pettersen et al. [2004]</xref></p></caption><graphic xlink:href="EMS146591-f002"/></fig><fig id="F3" position="float"><label>Fig. 3</label><caption><title>Comparison of AttentionSiteDTI with six baselines</title><p>(left) shows Area Under the Curve (AUC) for seen proteins and unseen proteins in the test; (right) shows Accuracy for seen proteins and unseen proteins in the test. Note that the accuracy scores of Tiresias do not show in unseen case, because it is lower than the lower bound of the y-axis (0.5). Note that for a head-to-head comparison with all models including ours, we implemented the BridgeDPI model with our experimental setting. Our model outperforms all other methods in unseen proteins which means our model is better in generalization over other models. In the seen protein scenario our model is comparable to other models and high AUC and accuracy in seen scenario indicates over-fitting of the model.</p></caption><graphic xlink:href="EMS146591-f003"/></fig><fig id="F4" position="float"><label>Fig. 4</label><caption><p>(Left) shows Heatmap and line plot of self-attention mechanism weights for each binding site in the proposed method with input of Darunavir as ligand and complex of COVID spike protein and ACE2 as protein, which translates to probability of each calculated binding sites of the protein being active for that specific ligand.(Right) shows projected heatmap of self-attention weights on the complex of COVID spike protein and ACE2. This figure shows the interpretablity of our model which can give us the binding site that have the most probability of binding to the ligand.</p></caption><graphic xlink:href="EMS146591-f004"/></fig><table-wrap id="T1" position="float" orientation="portrait"><label>Table 1</label><caption><p>Dataset’s Training Hyperparameters (FC is representing number of fully connected layers, L-GCN and P-GCN are number of Graph convolutional layers for extracting ligands and protein binding sites embedding respectively)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top">Datasets</th><th align="left" valign="top">FC</th><th align="left" valign="top">L-GCN</th><th align="left" valign="top">P-GCN</th></tr></thead><tbody><tr><td align="left" valign="top">DUD-E</td><td align="left" valign="top">2</td><td align="left" valign="top">18</td><td align="left" valign="top">16</td></tr><tr><td align="left" valign="top">Human</td><td align="left" valign="top">6</td><td align="left" valign="top">4</td><td align="left" valign="top">3</td></tr><tr><td align="left" valign="top">Bindingdb</td><td align="left" valign="top">6</td><td align="left" valign="top">4</td><td align="left" valign="top">3</td></tr></tbody></table></table-wrap><table-wrap id="T2" position="float" orientation="portrait"><label>Table 2</label><caption><title>Ablation Study Results</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top">Ablation tests</th><th align="center" valign="top">BindingDB</th><th align="center" valign="top">Human</th><th align="center" valign="top">DUD-E</th></tr></thead><tbody><tr><td align="left" valign="top">Bi-LSTM</td><td align="center" valign="top">0.863</td><td align="center" valign="top">0.976</td><td align="center" valign="top">0.954</td></tr><tr><td align="left" valign="top">Self-Attention</td><td align="center" valign="top"><bold>0.940</bold></td><td align="center" valign="top"><bold>0.991</bold></td><td align="center" valign="top">0.961</td></tr><tr><td align="left" valign="top">Bi-LSTM + Self-Attention</td><td align="center" valign="top">0.925</td><td align="center" valign="top">0.984</td><td align="center" valign="top"><bold>0.971</bold></td></tr></tbody></table></table-wrap><table-wrap id="T3" position="float" orientation="portrait"><label>Table 3</label><caption><title>DUD-E Dataset Comparision</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top"/><th align="center" valign="top">AUC</th><th align="center" valign="top">0.5% RE</th><th align="center" valign="top">1.0% RE</th><th align="center" valign="top">2.0% RE</th><th align="center" valign="top">5.0% RE</th></tr></thead><tbody><tr><td align="left" valign="top">NN Score</td><td align="center" valign="top">0.584</td><td align="center" valign="top">4.166</td><td align="center" valign="top">2.980</td><td align="center" valign="top">2.460</td><td align="center" valign="top">1.891</td></tr><tr><td align="left" valign="top">RF-score</td><td align="center" valign="top">0.622</td><td align="center" valign="top">5.628</td><td align="center" valign="top">4.274</td><td align="center" valign="top">3.499</td><td align="center" valign="top">2.678</td></tr><tr><td align="left" valign="top">Vina</td><td align="center" valign="top">0.716</td><td align="center" valign="top">9.139</td><td align="center" valign="top">7.321</td><td align="center" valign="top">5.811</td><td align="center" valign="top">4.444</td></tr><tr><td align="left" valign="top">Smina</td><td align="center" valign="top">0.696</td><td align="center" valign="top">-</td><td align="center" valign="top">-</td><td align="center" valign="top">-</td><td align="center" valign="top">-</td></tr><tr><td align="left" valign="top">3D-CNN</td><td align="center" valign="top">0.868</td><td align="center" valign="top">42.559</td><td align="center" valign="top">26.655</td><td align="center" valign="top">19.363</td><td align="center" valign="top">10.710</td></tr><tr><td align="left" valign="top">AtomNet</td><td align="center" valign="top">0.895</td><td align="center" valign="top">-</td><td align="center" valign="top">-</td><td align="center" valign="top">-</td><td align="center" valign="top">-</td></tr><tr><td align="left" valign="top">PocketGCN</td><td align="center" valign="top">0.886</td><td align="center" valign="top">44.406</td><td align="center" valign="top">29.748</td><td align="center" valign="top">19.408</td><td align="center" valign="top">10.735</td></tr><tr><td align="left" valign="top">GNN</td><td align="center" valign="top">0.940</td><td align="center" valign="top">-</td><td align="center" valign="top">-</td><td align="center" valign="top">-</td><td align="center" valign="top">-</td></tr><tr><td align="left" valign="top">DrugVQA</td><td align="center" valign="top"><bold>0.972</bold></td><td align="center" valign="top">88.17</td><td align="center" valign="top">58.71</td><td align="center" valign="top">35.06</td><td align="center" valign="top"><bold>17.39</bold></td></tr><tr><td align="left" valign="top">AttentionSiteDTI</td><td align="center" valign="top">0.971</td><td align="center" valign="top"><bold>101.74</bold></td><td align="center" valign="top"><bold>59.92</bold></td><td align="center" valign="top"><bold>35.07</bold></td><td align="center" valign="top">16.74</td></tr></tbody></table></table-wrap><table-wrap id="T4" position="float" orientation="portrait"><label>Table 4</label><caption><title>Human Dataset Comparision</title></caption><table frame="hsides" rules="groups"><thead><tr style="border-top: hidden"><th align="left" valign="top"/><th align="center" valign="top">AUROC</th><th align="center" valign="top">Precision</th><th align="center" valign="top">Recall</th><th align="center" valign="top">F1 Score</th></tr></thead><tbody><tr><td align="left" valign="top">K-NN</td><td align="center" valign="top">0.86</td><td align="center" valign="top">0.798</td><td align="center" valign="top">0.927</td><td align="center" valign="top">0.858</td></tr><tr><td align="left" valign="top">RF</td><td align="center" valign="top">0.940</td><td align="center" valign="top">0.861</td><td align="center" valign="top">0.897</td><td align="center" valign="top">0.879</td></tr><tr><td align="left" valign="top">L2</td><td align="center" valign="top">0.911</td><td align="center" valign="top">0.861</td><td align="center" valign="top">0.913</td><td align="center" valign="top">0.902</td></tr><tr><td align="left" valign="top">SVM</td><td align="center" valign="top">0.910</td><td align="center" valign="top"><bold>0.966</bold></td><td align="center" valign="top">0.950</td><td align="center" valign="top">0.958</td></tr><tr><td align="left" valign="top">GraphDTA</td><td align="center" valign="top">0.960</td><td align="center" valign="top">0.882</td><td align="center" valign="top">0.912</td><td align="center" valign="top">-</td></tr><tr><td align="left" valign="top">GCN</td><td align="center" valign="top">0.956</td><td align="center" valign="top">0.862</td><td align="center" valign="top">0.928</td><td align="center" valign="top">-</td></tr><tr><td align="left" valign="top">CPI-GNN</td><td align="center" valign="top">0.970</td><td align="center" valign="top">0.923</td><td align="center" valign="top">0.918</td><td align="center" valign="top">0.920</td></tr><tr><td align="left" valign="top">E2E/GO</td><td align="center" valign="top">0.970</td><td align="center" valign="top">0.893</td><td align="center" valign="top">0.914</td><td align="center" valign="top">0.903</td></tr><tr><td align="left" valign="top">DrugVQA</td><td align="center" valign="top">0.979</td><td align="center" valign="top">0.954</td><td align="center" valign="top">0.961</td><td align="center" valign="top">0.957</td></tr><tr><td align="left" valign="top">BridgeDPI</td><td align="center" valign="top">0.990</td><td align="center" valign="top">0.963</td><td align="center" valign="top">0.949</td><td align="center" valign="top">0.956</td></tr><tr><td align="left" valign="top">AttentionSiteDTI</td><td align="center" valign="top"><bold>0.991</bold></td><td align="center" valign="top">0.951</td><td align="center" valign="top"><bold>0.975</bold></td><td align="center" valign="top"><bold>0.963</bold></td></tr></tbody></table></table-wrap><table-wrap id="T5" position="float" orientation="portrait"><label>Table 5</label><caption><title>In-lab Validation of AttentionSiteDTI in the case study of Covid-19</title></caption><table frame="hsides" rules="groups"><thead><tr style="border-top: hidden"><th align="left" valign="top">Compound</th><th align="center" valign="top">AttentionSiteDTI</th><th align="center" valign="top">Lab Results</th></tr></thead><tbody><tr><td align="left" valign="top">2-keto-3-deoxynononic acid</td><td align="center" valign="top">Non-interacting</td><td align="center" valign="top">Interacting</td></tr><tr><td align="left" valign="top">N-Glycolylneuraminic acid</td><td align="center" valign="top">Non-interacting</td><td align="center" valign="top">Interacting</td></tr><tr><td align="left" valign="top">Cytidine-5-monophospho-N-acetylneuraminic acid sodium salt</td><td align="center" valign="top"><bold>Interacting</bold></td><td align="center" valign="top"><bold>Interacting</bold></td></tr><tr><td align="left" valign="top">Darunavir</td><td align="center" valign="top"><bold>Interacting</bold></td><td align="center" valign="top"><bold>Interacting</bold></td></tr><tr><td align="left" valign="top">N-acetyl-neuraminic acid</td><td align="center" valign="top"><bold>Non-interacting</bold></td><td align="center" valign="top"><bold>Non-interacting</bold></td></tr><tr><td align="left" valign="top">N-Acetyllactosamine</td><td align="center" valign="top"><bold>Non-interacting</bold></td><td align="center" valign="top"><bold>Non-interacting</bold></td></tr><tr><td align="left" valign="top">3,6-Mannopentaose</td><td align="center" valign="top"><bold>Non-interacting</bold></td><td align="center" valign="top"><bold>Non-interacting</bold></td></tr></tbody></table></table-wrap></floats-group></article>