<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="ppub"/></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS145667</article-id><article-id pub-id-type="doi">10.1101/2021.08.08.455583</article-id><article-id pub-id-type="archive">PPR380945</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>The Normative Modeling Framework for Computational Psychiatry</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Rutherford</surname><given-names>Saige</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Kia</surname><given-names>Seyed Mostafa</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A4">4</xref></contrib><contrib contrib-type="author"><name><surname>Wolfers</surname><given-names>Thomas</given-names></name><xref ref-type="aff" rid="A5">5</xref><xref ref-type="aff" rid="A6">6</xref></contrib><contrib contrib-type="author"><name><surname>Fraza</surname><given-names>Charlotte</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Zabihi</surname><given-names>Mariam</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Dinga</surname><given-names>Richard</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Berthet</surname><given-names>Pierre</given-names></name><xref ref-type="aff" rid="A5">5</xref><xref ref-type="aff" rid="A6">6</xref></contrib><contrib contrib-type="author"><name><surname>Worker</surname><given-names>Amanda</given-names></name><xref ref-type="aff" rid="A7">7</xref></contrib><contrib contrib-type="author"><name><surname>Verdi</surname><given-names>Serena</given-names></name><xref ref-type="aff" rid="A8">8</xref><xref ref-type="aff" rid="A9">9</xref></contrib><contrib contrib-type="author"><name><surname>Ruhe</surname><given-names>Henricus G.</given-names></name><xref ref-type="aff" rid="A10">10</xref><xref ref-type="fn" rid="FN1">*</xref></contrib><contrib contrib-type="author"><name><surname>Beckmann</surname><given-names>Christian F.</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A11">11</xref><xref ref-type="fn" rid="FN1">*</xref></contrib><contrib contrib-type="author"><name><surname>Marquand</surname><given-names>Andre F.</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A7">7</xref><xref ref-type="fn" rid="FN1">*</xref></contrib></contrib-group><aff id="A1"><label>1</label>Donders Institute for Brain, Cognition, and Behavior, Radboud University, Nijmegen, the Netherlands</aff><aff id="A2"><label>2</label>Department of Cognitive Neuroscience, Radboud University Medical Center, Nijmegen, the Netherlands</aff><aff id="A3"><label>3</label>Department of Psychiatry, University of Michigan, Ann Arbor, MI, United States</aff><aff id="A4"><label>4</label>Department of Psychiatry, Utrecht University Medical Center, Utrecht, the Netherlands</aff><aff id="A5"><label>5</label>Department of Psychology, University of Oslo, Oslo, Norway</aff><aff id="A6"><label>6</label>Norwegian Center for Mental Disorders Research, University of Oslo, Oslo, Norway</aff><aff id="A7"><label>7</label>Department of Psychological Medicine, Institute of Psychiatry, Psychology and Neuroscience, King’s College London, London, United Kingdom</aff><aff id="A8"><label>8</label>Centre for Medical Image Computing, Medical Physics and Biomedical Engineering, University College London, London, UK</aff><aff id="A9"><label>9</label>Dementia Research Centre, UCL Queen Square Institute of Neurology, London, United Kingdom</aff><aff id="A10"><label>10</label>Department of Psychiatry, Radboud University Medical Center, Nijmegen, the Netherlands</aff><aff id="A11"><label>11</label>Centre for Functional MRI of the Brain, University of Oxford, Oxford, United Kingdom</aff><author-notes><corresp id="CR1">Corresponding author: Saige Rutherford <email>saige.rutherford@donders.ru.nl</email></corresp><fn id="FN1" fn-type="equal"><label>*</label><p id="P1">Contributed equally to senior author</p></fn><fn id="FN2"><p id="P2"><bold>Tweet</bold></p><p id="P3">New protocol by @being_saige for normative modeling analysis using the Predictive Clinical Neuroscience toolkit (PCNtoolkit) - an emerging and innovative framework for mapping individual differences at the level of a single subject or observation in relation to a reference model, moving computational psychiatry analyses away from noisy case-control comparisons.</p></fn></author-notes><pub-date pub-type="nihms-submitted"><day>08</day><month>06</month><year>2022</year></pub-date><pub-date pub-type="preprint"><day>01</day><month>06</month><year>2022</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P4">Normative modeling is an emerging and innovative framework for mapping individual differences at the level of a single subject or observation in relation to a reference model. It involves charting centiles of variation across a population in terms of mappings between biology and behavior which can then be used to make statistical inferences at the level of the individual. The fields of computational psychiatry and clinical neuroscience have been slow to transition away from patient versus “healthy” control analytic approaches, likely due to a lack of tools designed to properly model biological heterogeneity of mental disorders. Normative modeling provides a solution to address this issue and moves analysis away from case-control comparisons that rely on potentially noisy clinical labels. In this article, we define a standardized protocol to guide users through, from start to finish, normative modeling analysis using the Predictive Clinical Neuroscience toolkit (PCNtoolkit). We describe the input data selection process, provide intuition behind the various modeling choices, and conclude by demonstrating several examples of down-stream analyses the normative model results may facilitate, such as stratification of high-risk individuals, subtyping, and behavioral predictive modeling. The protocol takes approximately 1-3 hours to complete.</p></abstract><kwd-group><kwd>normative modeling</kwd><kwd>computational psychiatry</kwd><kwd>individual differences</kwd><kwd>precision medicine</kwd><kwd>software tutorial</kwd><kwd>lifespan neuroscience</kwd><kwd>brain growth charting</kwd></kwd-group></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P5">Clinical neuroscientists have recently acknowledged two realities that have disrupted the way research is conducted: first, that to understand individual differences it is necessary to move away from group average statistics <sup><xref ref-type="bibr" rid="R1">1</xref>–<xref ref-type="bibr" rid="R7">7</xref></sup> and, second, that the classical diagnostic labels of psychiatric disorders are not clearly represented in the underlying biology<sup><xref ref-type="bibr" rid="R8">8</xref>–<xref ref-type="bibr" rid="R11">11</xref></sup>. Initiatives such as RDoC<sup><xref ref-type="bibr" rid="R9">9</xref>,<xref ref-type="bibr" rid="R12">12</xref>,<xref ref-type="bibr" rid="R13">13</xref></sup>, HiTOP<sup><xref ref-type="bibr" rid="R10">10</xref>,<xref ref-type="bibr" rid="R14">14</xref>,<xref ref-type="bibr" rid="R15">15</xref></sup>, and ROAMER<sup><xref ref-type="bibr" rid="R16">16</xref>,<xref ref-type="bibr" rid="R17">17</xref></sup> were established in response and seek to refine the nosology of mental disorders by mapping biobehavioral dimensions that cut across heterogeneous disorder categories. Despite this awareness and an increasing interest in quantifying individual differences, the field has still been slow to transition away from casecontrol comparisons that aim to contrast patient versus healthy control groups and assume that clinical groups are distinct and homogenous. A key barrier that has impeded progress is a lack of alternative analysis methods, designed to model variation across individuals, also known as heterogeneity<sup><xref ref-type="bibr" rid="R18">18</xref></sup>. Nearly all existing techniques for connecting the brain to behavior operate at the group-level and provide no path to individual-level inference<sup><xref ref-type="bibr" rid="R19">19</xref>–<xref ref-type="bibr" rid="R21">21</xref></sup>. Normative modeling is a framework for understanding differences at the level of a single subject or observation while mapping these differences in relation to a reference model (<xref ref-type="fig" rid="F1">Figure 1</xref>). It involves charting centiles of variation across a population in terms of mappings between biology and behavior, which can then be used to make statistical inferences at the level of the individual, akin to the use of growth charts in pediatric medicine (<xref ref-type="fig" rid="F1">Figure 1A</xref>). The practice of normative modeling in clinical neuroscience was developed to provide additional information beyond what can be learned from case-control modeling approaches (see ‘Development of the Protocol’ section below for further information). Case-control thinking assumes that the mean is representative of the population, when it may not be (e.g., if the clinical population is diffuse or comprised of multiple sub-populations). Therefore, normative modeling has become a leading tool for precision medicine research programs and has been used in many clinical contexts<sup><xref ref-type="bibr" rid="R22">22</xref></sup> (see ‘Applications’ section below for further examples).</p><p id="P6">Neuroscience has historically brought together scientists from diverse educations, for example, some from a clinical background and others having a mathematics background. The interdisciplinary nature introduces a challenge in bridging the gap between technical and clinical perspectives. This is a key challenge that aligns with the aims of the open-science movement and brain-hack community<sup><xref ref-type="bibr" rid="R23">23</xref></sup>, in other words, to distill the essential components of the analytic workflow into a consistent and widely applicable protocol. This helps to avoid ‘research debt’, i.e., a lack of ideas being digested<sup><xref ref-type="bibr" rid="R24">24</xref></sup>. This distiller mindset is crucial for confronting research debt and embracing paradigm shifts in thinking, such as moving from case-control comparisons to the normative modeling framework.</p><p id="P7">The purpose of this work is to distill the methods of normative modeling, an advanced analysis technique, into an actionable protocol that addresses these challenges in that it is accessible to researchers within the diverse field of clinical neuroscience. We distill the essential components of a normative modeling analysis and provide a demonstrative analysis from start to finish using the Predictive Clinical Neuroscience Toolkit <underline><styled-content style="color:#087adc">software</styled-content></underline>. We describe the input data selection process, give an overview of the various modeling choices, and conclude by demonstrating several examples of downstream analyses the normative model results may facilitate, such as stratification of high-risk individuals, subtyping, and behavioral predictive modeling.</p></sec><sec id="S2"><title>Development of the protocol</title><p id="P8">Normative modeling has a long history that relates to statistics and measurement theory and has many applications from medicine to economics to neuroscience. Familiar use cases of normative modeling include growth charting in pediatrics, neurocognitive tests, and interpreting graduate school test score percentiles (i.e., scoring 90<sup>th</sup> percentile on the MCAT). The mathematical and computational development of normative modeling has been fine-tuned<sup><xref ref-type="bibr" rid="R25">25</xref>–<xref ref-type="bibr" rid="R28">28</xref></sup> and currently exists as an open-source software python package, the Predictive Clinical</p><p id="P9">Neuroscience toolkit (PCNtoolkit), which we focus on in this manuscript. This toolkit implements many commonly used algorithms for normative modelling and supports multiple industry standard data formats (e.g., NIFTI, CIFTI, text formats). Extensive documentation has been written to accompany this protocol and is available online through <underline><styled-content style="color:#087adc">read the docs</styled-content></underline>. This includes tutorials with sample data for all algorithm implementations, a glossary to help new users understand the jargon associated with the software, and a frequently asked questions page. An online <underline><styled-content style="color:#087adc">forum</styled-content></underline> for communicating questions, bugs, feature requests, <italic>etc</italic>. to the core team of PCNtoolkit developers is also available. We have developed these open-source resources to promote and encourage individual differences research in computational psychiatry using normative modeling.</p></sec><sec id="S3"><title>Applications and comparison with other methods</title><p id="P10">Normative modeling has been applied to many research questions in computational psychiatry and other fields, including in autism spectrum disorder<sup><xref ref-type="bibr" rid="R29">29</xref>–<xref ref-type="bibr" rid="R31">31</xref></sup>, attention deficit hyperactive disorder<sup><xref ref-type="bibr" rid="R32">32</xref>,<xref ref-type="bibr" rid="R33">33</xref></sup>, Alzheimer’s disease<sup><xref ref-type="bibr" rid="R34">34</xref></sup>, bipolar disorder, and schizophrenia<sup><xref ref-type="bibr" rid="R35">35</xref>–<xref ref-type="bibr" rid="R37">37</xref></sup>. Crucially, these applications have shown that normative modelling can detect individual differences both in the presence of strong case-control differences (observed in schizophrenia)<sup><xref ref-type="bibr" rid="R36">36</xref></sup> and in their absence (observed in autism spectrum disorder)<sup><xref ref-type="bibr" rid="R30">30</xref></sup>. This highlights the value and complementary nature of understanding individual variation relative to group means. These applications have primarily focused on predicting regional structural or functional neuroimaging data (i.e., biological response variables) from phenotypic variables (i.e., clinically relevant covariates) such as age and sex. Age creates a natural, time-varying dimension for mapping normative trajectories and is well suited to applications in which deviations of an individual manifest from a typical trajectory of brain development or ageing. However, other phenotypes that have been used in neuroimaging predictive modeling studies such as general cognitive ability<sup><xref ref-type="bibr" rid="R38">38</xref>,<xref ref-type="bibr" rid="R39">39</xref></sup>, social cognition, or sustained attention<sup><xref ref-type="bibr" rid="R40">40</xref>,<xref ref-type="bibr" rid="R41">41</xref></sup> are also attractive possibilities to use as covariates, thereby defining axes for observing deviation patterns. Normative modeling has also been used to learn mappings between reward sensitivity and reward related brain activity<sup><xref ref-type="bibr" rid="R42">42</xref></sup>.</p><p id="P11">It is important to emphasize that normative modeling is a general regression framework for mapping sources of heterogeneity, refocusing attention on individual predictions rather than group means (e.g., diagnostic labels), and detecting individuals who deviate from the norm. Therefore, it is not limited to a specific algorithm or mathematical model, although we recommend certain algorithms based on the research question and available input data. The algorithms in the PCNtoolkit tend to favor Bayesian over frequentist statistics, as there are certain features of Bayesian approaches that facilitate better normative modeling estimation. For example, having a posterior distribution over the parameters help to better separate different sources of uncertainty, e.g., separating variation (‘aleatoric uncertainty’ – cannot be reduced by adding more data) from modeling (or ‘epistemic’) uncertainty which can be reduced by adding more data. These different use cases of normative modeling (algorithm selection, predicting brain from behavior or behavior from the brain) are explained in-depth in the ‘Experimental Design’ section, below.</p><p id="P12">There is a long history of using regression methods to learn mappings between brain and behavior<sup><xref ref-type="bibr" rid="R43">43</xref>,<xref ref-type="bibr" rid="R44">44</xref></sup>. Principle Component Regression (PCR)<sup><xref ref-type="bibr" rid="R20">20</xref>,<xref ref-type="bibr" rid="R45">45</xref>,<xref ref-type="bibr" rid="R46">46</xref></sup>, Connectome predictive modeling (CPM)<sup><xref ref-type="bibr" rid="R19">19</xref>,<xref ref-type="bibr" rid="R47">47</xref></sup>, and canonical correlation analysis (CCA)<sup><xref ref-type="bibr" rid="R48">48</xref>,<xref ref-type="bibr" rid="R49">49</xref></sup> have become mainstream methods for linking brain and behavior. These methods have demonstrated the feasibility of brain-behavior mapping and laid the foundation for individual differences research to thrive. While these approaches have generated much curiosity and excitement, they are limited in their ability to provide inference at the level of the individual, providing only point estimates (i.e., without associated centiles of variation). Most papers using these tools only report the mean predictive model performance, collapsing information across hundreds or thousands of people into a single number (e.g. model accuracy or regression performance)<sup><xref ref-type="bibr" rid="R46">46</xref>,<xref ref-type="bibr" rid="R47">47</xref>,<xref ref-type="bibr" rid="R50">50</xref>,<xref ref-type="bibr" rid="R51">51</xref></sup>. The normative modeling framework takes these ideas a step further to quantify and describe how individuals differ statistically, with respect to an expected pattern. In this way, normative modelling breaks the symmetry inherent in the case control paradigm. In more detail, PCR and CPM differ from normative modeling in terms of how the prediction model is formulated. PCR and CPM setup the regression model such that, Y, a n_subjects x 1 vector (i.e., age or fluid intelligence), is predicted from X, a matrix with n_subjects x n_brain dimensions, where n_brain is typically a reduced feature space selected via a regularization step. This setup makes interpretating which brain features are related to the behavior very challenging. Studies using PCR or CPM attempt to interpret the brain feature weights, but as these methods typically use fMRI connectomic data, consisting of connections and nodes, interpretation often yields a complex whole-brain visualization that is not very informative. The individual-level output of these models is a single point estimate, a predicted behavior score for each subject. These individual point estimates are then summarized by correlating the predicted and true behavior scores, reporting explained variance (R<sup>2</sup>), and calculating accuracy (mean squared error). Compared to PCR and CPM, normative modeling inverts the regression setup around to predict brain region Y, a n_subjects x 1 vector from X, a matrix with n_subjects x n_covariates (i.e., age, sex, fluid intelligence, site, data quality metric). There is a separate regression model for each brain region. The individual-level outputs of normative modeling are the predicted brain score, the predictive variance (separated into modeling and noise components), a deviation score (Z-score, how much each subject deviate from the normative range). The overall performance is evaluated by correlating predicted and true values, calculating explained variance, standardized mean squared error, and mean standardized log loss. In contrast, CCA estimates a doubly multivariate relationship in that both X and Y are matrices (X is n_subjects x n_brain matrix and Y is n_subjects x n_behavior). Whilst CCA is well suited to detecting that a mapping exists, this still leads to difficult interpretation of feature importance and, moreover, CCA is highly prone to overfitting and requires careful assessment of out of sample metrics with respect to an appropriate null distribution, which is not always done in practice. Like PCR and CPM, CCA also does not provide individual measure of uncertainty or deviation scores.</p><p id="P13">Case-control inference (e.g., mass univariate group t-testing and classification of patient vs. control) examples are perhaps the most interesting comparison to the normative modeling framework. Case-control methods typically require there to be a homogeneous within-group spatial signature and their success relies on obtaining statistical significance (p-value &lt; 0.05). We clarify this point with an example of the assumptions of case-control inference. To detect a group difference in amygdala activation between a control group and a group of individuals with post-traumatic stress disorder during a fMRI task, all individuals in the control group need a similar value of amygdala activation and all individuals in the PTSD group need a similar value of amygdala activation. Then, the mean amygdala activation signal of the control group must be statistically different from the mean amygdala activation signal of the PTSD group after stringent multiple comparison testing correction. These assumptions ignore the fact that different biological processes (i.e., some people have increased activation and others decreased) can lead to similar external behavior. Normative models reveal a different side of the data -- that the classical diagnostic labels of psychiatric disorders are not clearly represented in the underlying biology, meaning patient groups are not well defined by a unifying neurosignature -- and provide clear evidence for the limitations of case-control paradigms. Brain age models are also in the same family as normative models but generally have a narrower focus on interpreting accelerated/decelerated aging<sup><xref ref-type="bibr" rid="R52">52</xref>,<xref ref-type="bibr" rid="R53">53</xref></sup> or improving prediction accuracy<sup><xref ref-type="bibr" rid="R54">54</xref></sup>. Brain age models only allow for interpreting centiles of variation in terms of age, which is limited and does not have a clear interpretation in terms of biological variation across individuals.</p><p id="P14">“All models are wrong, but some are useful” -- George E.P. Box.</p><p id="P15">There is not one ‘best’ modeling approach and many of the methods presented in this section can be complimentary in that they investigate different questions. Before embarking on a computational modeling journey, it is always important to ask questions such as: What are the assumptions made by this model? What type of inference do you want to make (group-level, individual-level)? What aspect of the predictive model is most important (accuracy, quantifying uncertainty, statistical significance)? Allow your research question to guide the answers and model selection.</p></sec><sec id="S4"><title>Expertise needed to implement the protocol</title><p id="P16">We aimed to make this protocol user-friendly to the diverse community of neuroscience, including those with a non-technical background. The fundamental objective of this protocol is to learn how to implement the normative modeling framework via the PCNtoolkit software without being an expert in statistics and machine learning. You will be given enough knowledge to set up training and test sets, understand what data should be going into the model, interpret results, and make inferences based on the results. Prerequisites of this protocol are basic familiarity with the Python programming language and a computer with a stable internet connection. Complete code, example data, and extensive documentation accompany this protocol; thus, writing code from scratch is unnecessary. Of course, it is our intention for readers to be inspired by this protocol and to use the normative modeling framework in more ways than presented here. If you wish to use the framework presented in this protocol beyond the provided code, familiarity with the Linux command line, bash scripting, setting up virtual environments, and submitting jobs to high-performance clusters would also be helpful.</p></sec><sec id="S5"><title>Limitations</title><sec id="S6"><title>Big data requires automated QC</title><p id="P17">As datasets grow to meet the requirements of becoming population-level or big data, there is typically a need to rely on automated quality control metrics<sup><xref ref-type="bibr" rid="R55">55</xref></sup>. This means there is potential to unintentionally include poor quality data, which could, in turn, affect the results. The training and test dataset used in this protocol has been manually quality checked by visualizing every subject’s raw T1w volume with their corresponding Freesurfer brain-mask as an overlay using an online (JavaScript-based) image viewer. Quality checking code and further instructions for use is made available on GitHub. These images were inspected for obvious quality issues, such as excess field-of-view cut-off, motion artifacts, or signal drop-out. Subjects that were flagged as having quality issues were excluded from the sample. Users should consider manually quality checking their own data if they wish to add on additional samples to the dataset.</p></sec><sec id="S7"><title>Multi-site confounds and data availability</title><p id="P18">Pooling data from multiple sites is often a necessary step to create diverse datasets and reach sufficient sample sizes for machine learning analyses. When combining data from different studies, several challenges arise. First, there are often different MRI scanners at each site that also have different acquisition parameters. These MRI hardware and software divergences give rise to substantial nuisance variance that must be properly accounted for when modeling the data. Second, there may be sampling differences, for example due to different inclusion criteria and definitions of diagnostic labels at each site. For example, if one site uses the Structured Clinical Interview for DSM-5 (SCID-5) administered by a trained mental health professional who is familiar with the DSM-5 diagnostic criteria, while another site relies on self-report questionnaire data to define clinical labels. This increases the heterogeneity within the clinical groups (e.g., by mixing inclusion criteria across cohorts) and could also add noise to the diagnostic labels (e.g., if diagnostic assessments have different reliability across studies). This is important to consider if clinical labels are used to separate data into training and testing sets (i.e., controls only in the training set) and when comparing the outputs of normative modeling across patient groups from different sites.</p><p id="P19">Furthermore, there is likely to be dissimilarities in the available demographic, cognitive, and clinical questionnaire data across sites as well which needs to be considered when deciding which studies to include and which covariates to use in modeling. If the goal is to share the model, allowing transfer to new samples, using unique covariates that are specific to your sample (and not commonly collected) will hinder the ability of others to use your model on their own data. There is a careful balance that should be considered regarding the benefits gained from a new site joining the sample versus the site related nuisance variance that accompanies the addition of new sites.</p></sec></sec><sec id="S8"><title>Overview of the procedure</title><sec id="S9"><title>Experimental design</title><p id="P20">There are many choices and considerations that should be carefully planned before embarking on a normative modeling analysis – the decision points can be grouped into the following stages: data selection, data preparation, algorithm/modeling, and evaluation/interpretation. These stages, and the corresponding step numbers of the procedure are summarized in <xref ref-type="fig" rid="F2">Figure 2</xref>. There are additional resources and support for running normative modeling analysis that are summarized in <xref ref-type="fig" rid="F3">Figure 3</xref>.</p><sec id="S10"><title>Data selection – reference cohort inclusion criteria</title><p id="P21">Creating the training dataset that will serve as the “normative” reference cohort is the first important decision. Ideally, the training dataset will be a large and representative sample, and the included subjects should not be missing vital demographic (age, sex) or biological (neuroimaging) data. However, data imputation may be used if necessary but should be used cautiously. In most research studies, data are missing not at random, and we interpret more than just mean effects. In this case, mean imputation may bias results and other forms of imputation should be considered<sup><xref ref-type="bibr" rid="R56">56</xref>,<xref ref-type="bibr" rid="R57">57</xref></sup>. It is important that the reference cohort provides good coverage (complementary covariates) of the test set (e.g., clinical) population.</p><p id="P22">The sample size of the reference cohort (training set) is important to consider in normative modeling, although we emphasize that the focus is different to classical power calculations, which target a fundamentally different question (i.e., determining a required sample size to detect a group level comparison of a specified effect size at a given significance level). In contrast, in normative modeling, the focus is usually on quantifying deviations from a reference model at the individual level. In this context, the size of the reference cohort primarily influences the test set deviation scores by influencing the accuracy and precision with which the target phenotype (i.e., response variable) can be predicted. As the sample sizes increase, the predictive intervals will shrink, which results in an increased sensitivity to detect individual differences. However, there is not a specific cutoff that represents an ideal sample size, and we emphasize that context is key. For instance, you could build a clinical normative model for a sample of individuals with major depression disorder (MDD) for the purpose of stratification or detecting subgroups (individuals who have recurrent episodes or individuals who do not respond to medication). In this case, the reference cohort might consist of individuals that have experienced single MDD episodes and those that have responded well to medication. The sample size for this normative modeling research question would likely be relatively small due to data availability (e.g., clinical datasets typically have stricter data sharing requirements). The main takeaway from this MDD example is that sample size is highly dependent on the research question which in turn guides the inclusion criteria for the reference cohort you want to measure deviations from. If you are modeling “healthy” lifespan populations, the sample size will likely be large (on the order of thousands) because of the plethora of publicly shared data that can be leveraged. On the other hand, if you want to model a specific clinical population or a specific functional task, the sample size will be smaller due to availability of data. A smaller dataset that properly addresses the research question at hand is completely acceptable.</p></sec><sec id="S11"><title>Data selection - covariate selection</title><p id="P23">The next choice should be regarding which covariates to include. One of the main criteria to include a covariate is the relevance to the posed research question. In normative modeling, usually we are interested in studying the deviations from the norm of the population, in other words, we are more interested in residuals. Thus, when we include a covariate in the design matrix for estimating the normative model, we are mainly interested in removing its effect from the residuals (thus deviations) than investigating its effect on the neuroimaging variable. Normative modeling is a tool to study unknowns (that are encoded in the deviations). To do so, we need to first account for known variation in the data by regressing them out of the data (thus we include the knowns in the covariates), and then we interpret the residual variation in the deviation scores. For example, if you want to know the effect of smoking on the ventral striatum, that is not confounded by other substance use, you should include substance use variables (e.g., drinks per week, etc.) in the covariate matrix, estimate the normative model, and then correlate the ventral striatum deviation score (that has the effect of drinking removed from it) with smoking frequency. When pooling data from multiple sites, the available measures across sites may influence the selection of covariates because ideally, the variables should be consistent across sites. For example, you should not use different versions of a cognitive test, as they could test for different dimensions of general cognitive ability. For neurodevelopmental or lifespan model, the suggested minimum covariates to include are age, sex, site (using random- or fixed-effects), and optionally a metric of data quality (i.e., mean framewise displacement or Freesurfer Euler number). Modeling site is very important; however, an exhaustive explanation is outside the scope of this protocol but see <sup><xref ref-type="bibr" rid="R20">20</xref>,<xref ref-type="bibr" rid="R21">21</xref></sup> for an in-depth account of modeling site variation. Diagnostic labels could also be included as covariates to utilize the variance explained by these labels without constraining the mapping to only reflect case-control differences. Furthermore, additional biological covariates could also be included, for example blood biomarkers, or structural brain measures if predicting functional brain measures. Additional or alternative covariates may include other demographics (race, ethnicity, gender, education level, marital status, household income) and cognitive variables.</p></sec><sec id="S12"><title>Data Selection – MRI modality and spatial resolution of brain data</title><p id="P24">Next, it is necessary to decide on the modality of brain imaging to model. In this protocol, we use cortical thickness and subcortical volume measurements from structural MRI (T1-weighted) images. However, other modalities such as resting-state and task-based functional MRI or diffusion weighted MRI could also be selected in this step (data for these modalities is not provided with this protocol). The resolution of brain data is important to consider while keeping in mind the increasing computational complexity with modeling smaller units. Vertex or voxel-level modeling of brain data provides high-resolution deviation maps. Still, region of interest (ROI) level modeling may allow for easier interpretation/visualization of the output deviation maps and will have a lower penalty in multiple comparison correction (if doing post-hoc analysis) on the deviation maps. The PCNtoolkit can run models in parallel to speed up computation time; however, there is still a univariate nature, meaning a separate model is fit for each brain region. This univariate approach does not address the spatial autocorrelation<sup><xref ref-type="bibr" rid="R58">58</xref>–<xref ref-type="bibr" rid="R65">65</xref></sup> or functional heterogeneity (functional mis-registration) present in (f)MRI data<sup><xref ref-type="bibr" rid="R66">66</xref></sup>. Spatial autocorrelation refers to the complex spatial correlation patterns present in MRI data. Nearby regions are often more correlated than distant regions, thus they are not statistically independent. Spatial correlations are difficult to model due to their heterogeneity, complexity and high dimensionality with a limited sample size. Techniques such as Markov Random Fields<sup><xref ref-type="bibr" rid="R62">62</xref>,<xref ref-type="bibr" rid="R63">63</xref></sup>, network/graph theory (topology)<sup><xref ref-type="bibr" rid="R58">58</xref>,<xref ref-type="bibr" rid="R59">59</xref>,<xref ref-type="bibr" rid="R64">64</xref>,<xref ref-type="bibr" rid="R65">65</xref></sup>, and spatial Bayesian latent factor methods<sup><xref ref-type="bibr" rid="R61">61</xref>,<xref ref-type="bibr" rid="R67">67</xref></sup> have been applied to address the problem of spatial autocorrelation in raw or preprocessed MRI data. Progress in addressing spatial autocorrelation in the context of normative modeling has also been made in which Kronecker algebra and low rank approximations are used to build multivariate normative models<sup><xref ref-type="bibr" rid="R68">68</xref>,<xref ref-type="bibr" rid="R69">69</xref></sup>. In the context of normative modeling, we recommend paying extra attention to image registration in order to properly model the functional regions, as the spatial overlap of regions across individuals is not guaranteed with functional areas. In addition to taking extra measures to align the fMRI data, rather than modeling single voxels or parcels (as is often done in structural MRI), it may be beneficial to model brain networks as these features better capture the spatial patterns of functional units.</p></sec><sec id="S13"><title>Data preparation – Preprocessing and quality checking</title><p id="P25">Example data has been curated and shared for the purposes of this protocol. As mentioned in the data selection – MRI modality section above, we use structural MRI and have run Freesurfer to extract cortical thickness and subcortical volume measures. If using other data than the provided protocol data (i.e., your own data) then you will be to preprocess it accordingly and quality check the data to ensure only high-quality data is included. If you are new to working with MRI data, we recommend <underline><styled-content style="color:#087adc">Andy’s Brain Book</styled-content></underline><sup><xref ref-type="bibr" rid="R70">70</xref></sup> that includes videos and code tutorials for most neuroimaging software (i.e., Freesurfer, FSL, SPM).</p></sec><sec id="S14"><title>Data preparation – Setup computational environment</title><p id="P26">In this stage you will create a python virtual environment and install the required python packages. Then you will clone the GitHub repository which contains all the code and data required to follow along with the procedure section. You can run the entire protocol in the cloud using Google Colab or chose to run the code on your own computer or server.</p></sec><sec id="S15"><title>Data preparation – Format design matrix (site effects)</title><p id="P27">It is rare for a single scanning site to acquire large enough samples that are an accurate representation of the general population. Therefore, it is common to pool data obtained across multiple MRI centers. Some projects, such as the ABCD study<sup><xref ref-type="bibr" rid="R71">71</xref></sup>, have begun to harmonize scanning protocols because multi-site pooling was planned prior to data collection. In contrast, other projects, such as ENIGMA<sup><xref ref-type="bibr" rid="R72">72</xref></sup>, combine data post-collection and not have harmonized scanning sessions prior to data collection. If possible, to eliminate additional sources of variance, multi-site pooled data should be preprocessed using identical pipelines and software versions. However, due to data sharing restrictions and privacy concerns regarding health data, raw data may be unavailable, making pre or post data collection harmonization efforts impossible. Data harmonization techniques, such as COMBAT<sup><xref ref-type="bibr" rid="R73">73</xref>–<xref ref-type="bibr" rid="R76">76</xref></sup>, aim to remove site-related variance from the data as a preprocessing step before further analyses are run. There are some issues with harmonization, principally that all sources of variance that are correlated with the batch-effects (i.e., site-related variance) are removed which can unintentionally remove important, unknown, clinically relevant variance from the data. COMBAT also requires that the user have access to all the data when harmonizing which may have implications for data privacy. We therefore do not recommend users focus on data harmonization techniques when preparing their data sets for normative modeling. Hierarchical Bayesian Regression (HBR)<sup><xref ref-type="bibr" rid="R27">27</xref>,<xref ref-type="bibr" rid="R28">28</xref></sup> implemented in the PCNtoolkit has been thoroughly developed and tested to address these challenges when using multi-site data in normative modeling. HBR estimates site-specific mean effects and variations in the normative model estimation stage using a Bayesian hierarchical model, which produces site-agnostic deviation scores (z-statistics). This distinction between harmonization techniques (i.e., COMBAT) and HBR-normative modeling is very important when using deviation scores as features in subsequent interpretation analyses, as harmonization has been shown to overexaggerate confidence in downstream analyses<sup><xref ref-type="bibr" rid="R77">77</xref></sup>.</p></sec><sec id="S16"><title>Data preparation - Train-test split</title><p id="P28">Whilst there are no hard rules for selecting the relative proportion of training and test data, some general guidelines that may help this decision can be considered. On the one hand, it is important to ensure the training set be sufficiently large to model the target phenotype with sufficient accuracy and precision. On the other hand, ensuring the test set is not too small is also important to provide sufficient sensitivity to detect downstream differences (which may depend on the expected frequency of clinically relevant deviations in the test set). In practice a 70% train, 30% test or 80% train, 20% test split often provides a reasonable balance between these competing objectives, but in certain applications it may be necessary to deviate from these recommendations. The main purpose of the train-test split is to establish out of sample generalizability and whether there is over (or under) fitting occurring. More important than the exact ratio of the train/test split, we believe it is critical to focus on preserving the sample characteristics across the train/test split. For example, it would not be sensible to model age ranges of childhood and adolescence in the reference cohort and have the test cohort consist of late adulthood ages. This scenario would detect high deviations in this test set due to not properly modeling the target population. If you want to investigate the hypothesis that a certain clinical group (e.g., individuals with a psychosis diagnosis) have more extreme deviation patterns than a control group (individuals with no psychiatric diagnosis), you need to verify that it is because they are patients not because they are in the test set. In order to verify this, it is important to also include some controls (from the same imaging site as the patients) in the test set. In other words, you cannot separate site variation from diagnostic variation if you do not have control reference data.</p><p id="P29">The train-test ratio decision naturally relates to the sample size requirements of the reference cohort mentioned in the data selection – reference cohort inclusion criteria section above, and the same consideration of the context needs to be taken when creating the train-test split. Does this split align with the research question being asked? More specifically, does the training set adequately match the reference (“normative”) cohort and does the testing set represent the target cohort in which deviations (from the reference cohort) will be interpreted? We discourage cross validation, or iteratively resampling of the data set into train and test sets, unless the dataset is very small, and if it is used then practitioners should be aware of the problems it introduces. Ideally, the train/test split of the dataset will only be done once. While cross validation is useful for testing stability and sensitivity of models to perturbations, it also leads to having multiple models which are not easy to combine and interpret and it induces dependence between folds which violates most parametric statistical tests<sup><xref ref-type="bibr" rid="R78">78</xref></sup>.</p></sec><sec id="S17"><title>Algorithm &amp; Modeling - algorithm selection</title><p id="P30">After the data have been carefully chosen and curated, it is time to move onto the normative modeling implementation. There are several algorithms for implementing a normative model including Gaussian process regression<sup><xref ref-type="bibr" rid="R79">79</xref></sup>, Bayesian linear regression<sup><xref ref-type="bibr" rid="R25">25</xref>,<xref ref-type="bibr" rid="R67">67</xref></sup>, hierarchical Bayesian regression<sup><xref ref-type="bibr" rid="R27">27</xref>,<xref ref-type="bibr" rid="R28">28</xref></sup>, generalized additive models of location, scale, and shape<sup><xref ref-type="bibr" rid="R26">26</xref></sup>, neural processes<sup><xref ref-type="bibr" rid="R68">68</xref></sup>, random feature approximation<sup><xref ref-type="bibr" rid="R80">80</xref></sup>, quantile regression<sup><xref ref-type="bibr" rid="R81">81</xref></sup> and many of these are implemented in the PCNtoolkit software package (<xref ref-type="table" rid="T1">Table 1</xref>). The algorithms have different properties depending on their ability to model non-linear effects, scaling to large data sets (in terms of computation time), handling of random or fixed effects (e.g., to model site effects), their ability to model heteroscedastic or non-Gaussian noise distributions and their suitability for use in a federated or decentralized learning environment. An overview of these algorithm implementations is covered in <xref ref-type="table" rid="T1">Table 1</xref>. Gaussian process regression (GPR) was widely used in the beginning phases of normative modeling, which can flexibly model non-linear effects but does not computationally scale well when the training data increases (i.e., beyond a few thousand data points). In this work, we focus on Bayesian linear regression (BLR), which is highly scalable (fast compute time with large samples) and flexible (can be transferred to new sites not included in the training sample and can be combined with likelihood warping to model non-Gaussian effects). Hierarchical Bayesian regression (HBR) is another appealing choice as it has been used to better address multi-site datasets and allows for transfer learning (e.g., prediction for unseen sites) and can be estimated in a federated learning framework which is useful if there are privacy concerns and/or sharing restrictions meaning data cannot easily be pooled at a single computing site.</p><p id="P31">The remaining steps including estimating the normative model, evaluation the model performance, interpretating the model fit, and ideas for post-hoc analysis of the normative modeling outputs are covered in more detail in the protocol section.</p></sec></sec></sec><sec id="S18" sec-type="materials"><title>Materials</title><sec id="S19"><title>Equipment</title><list list-type="bullet" id="L1"><list-item><label>•</label><p id="P32">Computing infrastructure: a Linux computer or HPC (SLURM or Torque) with enough space to store the imaging data of the train and test set.</p><list list-type="bullet" id="L2"><list-item><label>•</label><p id="P33">If a Linux computer or server is unavailable, this protocol can also be run in Google Colab (for free). If using Google Colab, only a computer with an internet connection and modern internet browser (e.g., Chrome or Firefox) installed is necessary.</p></list-item></list></list-item><list-item><label>•</label><p id="P34">Python installation (<ext-link ext-link-type="uri" xlink:href="https://www.python.org/downloads/">https://www.python.org/downloads/</ext-link>).</p><list list-type="bullet" id="L3"><list-item><label>•</label><p id="P35">Recommended: Anaconda or virtual environment to manage the required python packages (<ext-link ext-link-type="uri" xlink:href="https://www.anaconda.com/">https://www.anaconda.com/</ext-link> or <ext-link ext-link-type="uri" xlink:href="https://virtualenv.pypa.io/en/latest/">https://virtualenv.pypa.io/en/latest/</ext-link>).</p></list-item></list></list-item><list-item><label>•</label><p id="P36">PCNtoolkit python package version 0.20 (and dependencies) installed via pip (<ext-link ext-link-type="uri" xlink:href="https://pcntoolkit.readthedocs.io/en/latest/pages/installation.html">https://pcntoolkit.readthedocs.io/en/latest/pages/installation.html</ext-link>).</p></list-item><list-item><label>•</label><p id="P37">Covariates and response variables. Examples of these are provided with this protocol.</p><list list-type="bullet" id="L4"><list-item><label>•</label><p id="P38">Demographic and behavioral data used as predictor variables</p><list list-type="bullet" id="L5"><list-item><label>•</label><p id="P39">Age, sex/gender, site/scanner ID, race/ethnicity, cognition, data quality metric (Euler number if structural, mean framewise displacement if functional)</p></list-item></list></list-item></list></list-item><list-item><label>•</label><p id="P40">Biological data to be modeled. An example structural MRI dataset is provided with this protocol.</p><list list-type="bullet" id="L6"><list-item><label>•</label><p id="P41">Structural MRI: cortical thickness, surface area, subcortical volume</p></list-item><list-item><label>•</label><p id="P42">Functional MRI: parcellated task activation maps, resting-state networks</p></list-item></list></list-item></list></sec></sec><sec id="S20" sec-type="methods"><title>Procedure</title><p id="P43">The data selection stage (<xref ref-type="fig" rid="F2">Figure 2</xref>, panel 1) does not require code, as it is more of a research question formulation stage (i.e., choosing inclusion criteria and what type of imaging modality to model). Data preprocessing (running Freesurfer) and quality checking have also already been performed, and code for running Freesurfer or other preprocessing is not included in this protocol. Thus, for this protocol, the procedure begins at the <italic>data preparation – setting up computational environment stage</italic>. See the experimental design section for guidance on the data selection stage and preprocessing if using different data than what is provided with the protocol.</p><sec id="S21"><title>Data Preparation: Prepare computational environment</title><sec id="S22"><title>Timing: 1-3 minutes</title><list list-type="order" id="L7"><list-item><label>1</label><p id="P44">Begin by cloning the GitHub repository using the following commands. This repository contains the necessary code and example data. Then install the python packages using pip and import them into the python environment (either Google Colab or using a local python installation on your computer), as follows:
<preformat preformat-type="computer code">
git clone <ext-link ext-link-type="uri" xlink:href="https://github.com/predictive-clinical-neuroscience/PCNtoolkit-demo.git">https://github.com/predictive-clinical-neuroscience/PCNtoolkit-demo.git</ext-link>
<styled-content style="color:#79c68e"># set this path to the git cloned PCNtoolkit-demo repository --&gt; Uncomment whichever line you need for either running on your own computer or on Google Colab.
#os.chdir('/Users/saigerutherford/repos/PCNtoolkit-demo/') # if running on your own computer, use this line (change the path to match where you cloned the repository)
#os.chdir('PCNtoolkit-demo/') # if running on Google Colab, use this line</styled-content>
<styled-content style="color:#b21be2">import</styled-content> os
pip install -r requirements.txt
<styled-content style="color:#b21be2">import</styled-content> pandas <styled-content style="color:#b21be2">as</styled-content> pd
<styled-content style="color:#b21be2">import</styled-content> numpy <styled-content style="color:#b21be2">as</styled-content> np
<styled-content style="color:#b21be2">import</styled-content> matplotlib.pyplot <styled-content style="color:#b21be2">as</styled-content> plt
<styled-content style="color:#b21be2">import</styled-content> seaborn <styled-content style="color:#b21be2">as</styled-content> sns
<styled-content style="color:#b21be2">import</styled-content> joypy
<styled-content style="color:#b21be2">from</styled-content> sklearn.model_selection <styled-content style="color:#b21be2">import</styled-content> train_test_split
<styled-content style="color:#b21be2">from</styled-content> pcntoolkit.normative <styled-content style="color:#b21be2">import</styled-content> estimate, evaluate
<styled-content style="color:#b21be2">from</styled-content> pcntoolkit.utils <styled-content style="color:#b21be2">import</styled-content> create_bspline_basis, compute_MSLL
</preformat>
</p></list-item></list></sec></sec><sec id="S23"><title>Data Preparation: Prepare covariate data</title><sec id="S24"><title>Timing: 5-8 minutes</title><list list-type="simple" id="L8"><list-item><label>2</label><p id="P45">The data set (downloaded in Step 1) includes a multi-site dataset from the <underline><styled-content style="color:#087adc">Human Connectome Project Young Adult study</styled-content></underline>, <underline><styled-content style="color:#087adc">CAMCAN</styled-content></underline>, and <underline><styled-content style="color:#087adc">IXI</styled-content></underline>. It is also possible to use different datasets (i.e., your own data or additional public datasets) in this step. If using your own data here, it is recommended to load the example data to view the column names in order to match your data to this format. Read in the data files using pandas, then merge the covariate (age &amp; sex) data from each site into a single data frame (named cov).</p><p id="P46">The columns of this covariate data frame represent the predictor variables. Additional columns may be added here, depending on the research question.
<preformat preformat-type="computer code">
hcp = pd.read csv(<styled-content style="color:#a42c42">'data/HCP1200 age gender.csv'</styled-content>)
cam = pd.read csv(<styled-content style="color:#a42c42">'data/cam age gender.csv'</styled-content>)
ixi = pd.read csv(<styled-content style="color:#a42c42">'data/IXI age gender.csv'</styled-content>)
cam hcp = pd.merge(hcp, cam, how=<styled-content style="color:#a42c42">'outer'</styled-content>)
cov = pd.merge(cam_hcp, ixi, how=<styled-content style="color:#a42c42">'outer'</styled-content>)
sns.set(font scale=<styled-content style="color:#0f885c">1.5</styled-content>, style=<styled-content style="color:#a42c42">'darkgrid'</styled-content>)
sns.displot(cov, x=<styled-content style="color:#a42c42">"age"</styled-content>, hue=<styled-content style="color:#a42c42">"site"</styled-content>, multiple=<styled-content style="color:#a42c42">"stack"</styled-content>, height=6)
cov.groupby([<styled-content style="color:#a42c42">'site'</styled-content>]).describe()
</preformat>
</p></list-item></list></sec></sec><sec id="S25"><title>Data Preparation: Prepare brain data</title><sec id="S26"><title>Timing: 10-15 minutes</title><list list-type="simple" id="L9"><list-item><label>3</label><p id="P47">Next, format and combine the MRI data using the following commands. The example data contains cortical thickness maps estimated by running recon-all from Freesurfer (version 6.0). The dimensionality of the data was reduced by using ROIs from the Desikan-Killiany atlas. Including the <underline><styled-content style="color:#087adc">Euler number</styled-content></underline> as a covariate is also recommended, as this is a proxy metric for data quality. The Euler number from each subject’s recon-all output folder was extracted into a text file and is merged into the cortical thickness data frame. The Euler number is site-specific, thus, to use the same exclusion threshold across sites it is important to center the site by subtracting the site median from all subjects at a site. Then take the square root and multiply by negative one and exclude any subjects with a square root above 10.
<preformat preformat-type="computer code">
cam = pd.read_csv(<styled-content style="color:#a42c42">'data/CAMCAN_aparc_thickness.csv'</styled-content>)
hcpya = pd.read_csv(<styled-content style="color:#a42c42">'data/HCP1200_aparc_thickness.csv'</styled-content>)
ixi = pd.read_csv(<styled-content style="color:#a42c42">'data/IXI_aparc_thickness.csv'</styled-content>)
hcpya_cam = pd.merge(hcpya, cam, how=<styled-content style="color:#a42c42">'outer'</styled-content>)
brain_all = pd.merge(ixi, hcpya_cam, how=<styled-content style="color:#a42c42">'outer'</styled-content>)
hcp_euler = pd.read_csv(<styled-content style="color:#a42c42">'data/hcp-ya_euler.csv'</styled-content>)
cam_euler = pd.read_csv(<styled-content style="color:#a42c42">'data/cam_euler.csv'</styled-content>)
ixi_euler = pd.read_csv(<styled-content style="color:#a42c42">'data/ixi_euler.csv'</styled-content>)
hcp_euler[<styled-content style="color:#a42c42">'site'</styled-content>] = <styled-content style="color:#a42c42">'hcp'</styled-content>
cam_euler[<styled-content style="color:#a42c42">'site'</styled-content>] = <styled-content style="color:#a42c42">'cam'</styled-content>
ixi_euler[<styled-content style="color:#a42c42">'site'</styled-content>] = <styled-content style="color:#a42c42">'ixi'</styled-content>
hcp_euler.dropna(inplace=<styled-content style="color:#4536fe">True</styled-content>)
cam_euler.dropna(inplace=<styled-content style="color:#4536fe">True</styled-content>)
ixi_euler.dropna(inplace=<styled-content style="color:#4536fe">True</styled-content>)
hcp_euler[<styled-content style="color:#a42c42">'rh_euler'</styled-content>] = hcp_euler[<styled-content style="color:#a42c42">'rh_euler'</styled-content>].astype(<styled-content style="color:#34819a">int</styled-content>)
hcp_euler[<styled-content style="color:#a42c42">'lh_euler'</styled-content>] = hcp_euler[<styled-content style="color:#a42c42">'lh_euler'</styled-content>].astype(<styled-content style="color:#34819a">int</styled-content>)
cam_euler[<styled-content style="color:#a42c42">'rh_euler'</styled-content>] = cam_euler[<styled-content style="color:#a42c42">'rh_euler'</styled-content>].astype(<styled-content style="color:#34819a">int</styled-content>)
cam_euler[<styled-content style="color:#a42c42">'lh_euler'</styled-content>] = cam_euler[<styled-content style="color:#a42c42">'lh_euler'</styled-content>].astype(<styled-content style="color:#34819a">int</styled-content>)
ixi_euler[<styled-content style="color:#a42c42">'rh_euler'</styled-content>] = ixi_euler[<styled-content style="color:#a42c42">'rh_euler'</styled-content>].astype(<styled-content style="color:#34819a">int</styled-content>)
ixi_euler[<styled-content style="color:#a42c42">'lh_euler'</styled-content>] = ixi_euler[<styled-content style="color:#a42c42">'lh_euler'</styled-content>].astype(<styled-content style="color:#34819a">int</styled-content>)
hcp_cam_euler = pd.merge(hcp_euler, cam_euler, how=<styled-content style="color:#a42c42">'outer'</styled-content>)
df_euler = pd.merge(ixi_euler, hcp_cam_euler, how=<styled-content style="color:#a42c42">'outer'</styled-content>)
df_euler[<styled-content style="color:#a42c42">'avg_euler'</styled-content>] = df_euler[[<styled-content style="color:#a42c42">'lh_euler'</styled-content>,<styled-content style="color:#a42c42">'rh_euler'</styled-content>]].mean(axis=<styled-content style="color:#82a061">1</styled-content>)
df_euler.groupby(by=<styled-content style="color:#a42c42">'site'</styled-content>).median()
df_euler[<styled-content style="color:#a42c42">'site_median'</styled-content>] = df_euler[<styled-content style="color:#a42c42">'site'</styled-content>]
df_euler[<styled-content style="color:#a42c42">'site_median'</styled-content>] = df_euler[<styled-content style="color:#a42c42">'site_median'</styled-content>].replace({<styled-content style="color:#a42c42">'hcp'</styled-content> :<styled-content style="color:#82a061">-43</styled-content>, <styled-content style="color:#a42c42">'cam'</styled-content> :<styled-content style="color:#82a061">-61</styled-content>, <styled-content style="color:#a42c42">'ixi'</styled-content> :<styled-content style="color:#82a061">-56</styled-content>})
df_euler[<styled-content style="color:#a42c42">'avg_euler_centered'</styled-content>] = df_euler[<styled-content style="color:#a42c42">'avg_euler'</styled-content>] - df_euler[<styled-content style="color:#a42c42">'site_median'</styled-content>]
df_euler[<styled-content style="color:#a42c42">'avg_euler_centered_neg'</styled-content>] = df_euler[<styled-content style="color:#a42c42">'avg_euler_centered'</styled-content>]*-1
df_euler['avg_euler_centered_neg_sqrt'] =
np.sqrt(np.absolute(df_euler[<styled-content style="color:#a42c42">'avg_euler_centered_neg'</styled-content>]))
brain = pd.merge(df_euler, brain_all, how=<styled-content style="color:#a42c42">'inner'</styled-content>) brain_good = brain.query(<styled-content style="color:#a42c42">'avg_euler_centered_neg_sqrt &lt; 10'</styled-content>)
</preformat>
</p></list-item></list></sec></sec><sec id="S27"><title>CRITICAL STEP</title><p id="P48">If possible, data should be visually inspected to verify that the data inclusion is not too strict or too lenient. Subjects above the Euler number threshold should be manually checked to verify and justify their exclusion due to poor data quality. This is just one approach for automated QC used by the developers of the PCNtoolkit. Other approaches such as the <underline><styled-content style="color:#087adc">ENIGMA QC pipeline</styled-content></underline> or UK Biobank’s QC pipeline <sup><xref ref-type="bibr" rid="R55">55</xref></sup> are also viable options for automated QC.</p><sec id="S28"><title>Data Preparation: Check that subjects (rows) align across covariate and brain dataframes</title><sec id="S29"><title>Timing: 3-5 minutes</title><list list-type="simple" id="L10"><list-item><label>4</label><p id="P49">The normative modeling function requires the covariate predictors and brain features to be in separate text files. However, it is important to first (inner) merge them together, using the following commands, to confirm that the same subjects are in each file and that the rows (representing subjects) align. This requires that both data frames have ‘<monospace>subject_id</monospace>’ as a column name. Once this is confirmed, exclude rows with NaN values and separate the brain features and covariate predictors into their own dataframes, using the commands below.
<preformat preformat-type="computer code">
<styled-content style="color:#078238"># make sure to use how="inner" so that we only include subjects that have data in both the covariate and the cortical thickness files</styled-content>
all_data = pd.merge(brain_good, cov, how=<styled-content style="color:#a41b59">'inner'</styled-content>)
<styled-content style="color:#078238"># Create a list of all the ROIs you want to run a normative model for</styled-content>
roi_ids = [<styled-content style="color:#a41b59">'lh_MeanThickness_thickness'</styled-content>,
         <styled-content style="color:#a41b59">'rh_MeanThickness_thickness'</styled-content>,
         <styled-content style="color:#a41b59">'lh_bankssts_thickness'</styled-content>,
         <styled-content style="color:#a41b59">'lh_caudalanteriorcingulate_thickness'</styled-content>,
         <styled-content style="color:#a41b59">'lh_superiorfrontal_thickness'</styled-content>,
         <styled-content style="color:#a41b59">'rh_superiorfrontal_thickness'</styled-content>]
<styled-content style="color:#c818e2">from</styled-content> sklearn.model_selection <styled-content style="color:#c818e2">import</styled-content> train_test_split all_data = all_data.dropna() all_data_features = all_data[[subset=roi_ids]] all data covariates = all data[[<styled-content style="color:#a41b59">'age'</styled-content>,<styled-content style="color:#a41b59">'sex'</styled-content>,<styled-content style="color:#a41b59">'site'</styled-content>]]
</preformat>
</p></list-item></list></sec></sec></sec><sec id="S30"><title>CRITICAL STEP</title><p id="P50"><monospace>roi_ids</monospace> is a variable that represents which brain areas will be modeled and can be used to select subsets of the data frame if you do not wish to run models for the whole brain.</p><sec id="S31"><title>Data Preparation: Add variable to model site/scanner effects</title><sec id="S32"><title>Timing: 3-5 minutes</title><list list-type="simple" id="L11"><list-item><label>5</label><p id="P51">Currently, the different sites are coded in a single column (named ‘site’) and are represented as a string data type. However, the PCNtoolkit requires binary variables. Use the pandas package as follows to address this, which has a built-in function, pd.get_dummies, that takes in the string ‘site’ column and dummy encodes the site variable so that there is now a column for each site and the columns contain binary variables (0=not in this site, 1=present in this site).
<preformat preformat-type="computer code">
all_data_covariates = pd.get_dummies(all_data_covariates, columns=[<styled-content style="color:#a41b59">'site'</styled-content>])
all_data[<styled-content style="color:#a41b59">'Average_Thickness'</styled-content>] =
all data[[<styled-content style="color:#a41b59">'lh MeanThickness thickness'</styled-content>,<styled-content style="color:#a41b59">'rh MeanThickness thickness'</styled-content>]].mean(axis=1)
</preformat>
</p></list-item></list></sec></sec></sec><sec id="S33"><title>Data Preparation: Train/Test split</title><sec id="S34"><title>Timing: 5-10 minutes</title><list list-type="simple" id="L12"><list-item><label>6</label><p id="P52">In this example, we use 80% of the data for training and 20% for testing. Please carefully read the experimental design section on train/test split considerations when using your own data in this step. Using a function from scikit-learn (<monospace>train_test_split</monospace>), stratify the train/test split using the site variable to make sure that the train/test sets both contain data from all sites, using the following commands. Next, confirm that your train and test arrays are the same size (rows), using the following commands. You do not need the same size columns (subjects) in the train and test arrays, but the rows represent the covariate and responses which should be the same across train and test arrays.
<preformat preformat-type="computer code">
X_train, X_test, y_train, y_test = train_test_split(all_data_covariates, all_data_features,
stratify=all_data[<styled-content style="color:#a41b59">'site'</styled-content>], test_size=<styled-content style="color:#90aa6c">0.2</styled-content>, random_state=<styled-content style="color:#90aa6c">42</styled-content>)
tr_cov_size = X_train.shape
tr_resp_size = y_train.shape
te_cov_size = X_test.shape
te_resp_size = y_test.shape
<styled-content style="color:#795e26">print</styled-content>(<styled-content style="color:#a41b59">"Train covariate size is: "</styled-content>, tr_cov_size)
<styled-content style="color:#795e26">print</styled-content>(<styled-content style="color:#a41b59">"Test covariate size is: "</styled-content>, te_cov_size)
<styled-content style="color:#795e26">print</styled-content>(<styled-content style="color:#a41b59">"Train response size is: "</styled-content>, tr_resp_size)
<styled-content style="color:#795e26">print</styled-content>(<styled-content style="color:#a41b59">"Test response size is: "</styled-content>, te resp size)
</preformat>
</p></list-item></list></sec></sec><sec id="S35"><title>CRITICAL STEP</title><p id="P53">The model would not learn the site effects if all the data from one site was only in the test set. Therefore, we stratify the train/test split using the site variable.</p><list list-type="simple" id="L13"><list-item><label>7</label><p id="P54">When the data were split into train and test sets, the row index was not reset. This means that the row index in the train and test data frames still correspond to the full data frame (before splitting the data occurred). The test set row index informs which subjects belong to which site, and this information is needed to evaluate per site performance metrics. Resetting the row index of the train/test data frames fixes this issue. Then extract the site row indices to a list (one list per site) and create a list called site_names that is used to decide which sites to evaluate model performance for, as follows:
<preformat preformat-type="computer code">
x_col_names = [<styled-content style="color:#a41b59">'age'</styled-content>, <styled-content style="color:#a41b59">'sex'</styled-content>, <styled-content style="color:#a41b59">'site_cam'</styled-content>, <styled-content style="color:#a41b59">'site_hcp'</styled-content>, <styled-content style="color:#a41b59">'site_ixi'</styled-content>]
X_train = pd.read_csv(<styled-content style="color:#a41b59">'data/covariate_files/cov_tr.txt'</styled-content>, sep=<styled-content style="color:#a41b59">'\t'</styled-content>, header=<styled-content style="color:#1c2ffe">None</styled-content>, names=x_col_names)
X_test = pd.read_csv(<styled-content style="color:#a41b59">'data/covariate_files/cov_te.txt'</styled-content>, sep=<styled-content style="color:#a41b59">'\t'</styled-content>, header=<styled-content style="color:#1c2ffe">None</styled-content>, names=x_col_names)
y_train = pd.read_csv(<styled-content style="color:#a41b59">'data/response_files/resp_tr.txt'</styled-content>, sep=<styled-content style="color:#a41b59">'\t'</styled-content>, header=<styled-content style="color:#1c2ffe">None</styled-content>)
y_test = pd.read_csv(<styled-content style="color:#a41b59">'data/response_files/resp_te.txt'</styled-content>, sep=<styled-content style="color:#a41b59">'\t'</styled-content>, header=<styled-content style="color:#1c2ffe">None</styled-content>)
X_train.reset_index(drop=<styled-content style="color:#1c2ffe">True</styled-content>, inplace=<styled-content style="color:#1c2ffe">True</styled-content>)
X_test.reset_index(drop=<styled-content style="color:#1c2ffe">True</styled-content>, inplace=<styled-content style="color:#1c2ffe">True</styled-content>)
y_train.reset_index(drop=<styled-content style="color:#1c2ffe">True</styled-content>, inplace=<styled-content style="color:#1c2ffe">True</styled-content>)
y_test.reset_index(drop=<styled-content style="color:#1c2ffe">True</styled-content>, inplace=<styled-content style="color:#1c2ffe">True</styled-content>)
cam_idx = X_test.index[X_test[<styled-content style="color:#a41b59">'site_cam'</styled-content> ]== <styled-content style="color:#11885d">1</styled-content>].to_list()
hcp_idx = X_test.index[X_test[<styled-content style="color:#a41b59">'site_hcp'</styled-content>] == <styled-content style="color:#11885d">1</styled-content>].to_list()
ixi_idx = X_test.index[X_test[<styled-content style="color:#a41b59">'site_ixi'</styled-content>] == <styled-content style="color:#11885d">1</styled-content>].to_list()
<styled-content style="color:#11885d"># Save the site indices into a single list</styled-content>
sites = [cam_idx, hcp_idx, ixi_idx]
<styled-content style="color:#11885d"># Create a list with sites names to use in evaluating per-site metrics</styled-content>
site_names = [<styled-content style="color:#a41b59">'cam'</styled-content>, <styled-content style="color:#a41b59">'hcp'</styled-content>, <styled-content style="color:#a41b59">'ixi'</styled-content>]
</preformat>
</p></list-item></list></sec><sec id="S36"><title>Data Preparation: Setup output directories</title><sec id="S37"><title>Timing: 1-3 minutes</title><list list-type="simple" id="L14"><list-item><label>8</label><p id="P55">Save each brain region to its own text file (organized in separate directories) using the following commands, because for each response variable, <bold>Y</bold> (e.g., brain region) we fit a separate normative model.
<preformat preformat-type="computer code">
<styled-content style="color:#c323e0">for</styled-content> c <styled-content style="color:#1c2ffe">in</styled-content> y_train.columns:
      y_train[c].to_csv(<styled-content style="color:#a41b59">'resp_tr_'</styled-content> + c + <styled-content style="color:#a41b59">'.txt'</styled-content>, header=<styled-content style="color:#1c2ffe">False</styled-content>, index=<styled-content style="color:#1c2ffe">False</styled-content>)
      X_train.to_csv(<styled-content style="color:#a41b59">'cov_tr.txt'</styled-content>, sep = <styled-content style="color:#a41b59">'\t'</styled-content>, header=<styled-content style="color:#1c2ffe">False</styled-content>, index = <styled-content style="color:#1c2ffe">False</styled-content>)
      y_train.to_csv(<styled-content style="color:#a41b59">'resp_tr.txt'</styled-content>, sep = <styled-content style="color:#a41b59">'\t'</styled-content>, header=<styled-content style="color:#1c2ffe">False</styled-content>, index = <styled-content style="color:#1c2ffe">False</styled-content>)
<styled-content style="color:#c323e0">for</styled-content> c <styled-content style="color:#1c2ffe">in</styled-content> y_test.columns:
      y_test[c].to_csv(<styled-content style="color:#a41b59">'resp_te_'</styled-content> + c + <styled-content style="color:#a41b59">'.txt'</styled-content>, header=<styled-content style="color:#1c2ffe">False</styled-content>, index=<styled-content style="color:#1c2ffe">False</styled-content>)
      X_test.to_csv(<styled-content style="color:#a41b59">'cov_te.txt'</styled-content>, sep = <styled-content style="color:#a41b59">'\t'</styled-content>, header=<styled-content style="color:#1c2ffe">False</styled-content>, index = <styled-content style="color:#1c2ffe">False</styled-content>)
      y_test.to_csv(<styled-content style="color:#a41b59">'resp_te.txt'</styled-content>, sep = <styled-content style="color:#a41b59">'\t'</styled-content>, header=<styled-content style="color:#1c2ffe">False</styled-content>, index = <styled-content style="color:#1c2ffe">False</styled-content>)
<styled-content style="color:#1c2ffe">! if</styled-content> [[ ! -e data/ROI_models/ ]]; <styled-content style="color:#1c2ffe">then</styled-content> mkdir data/ROI_models; <styled-content style="color:#1c2ffe">fi</styled-content>
<styled-content style="color:#1c2ffe">! if</styled-content> [[ ! -e data/covariate_files/ ]]; <styled-content style="color:#1c2ffe">then</styled-content> mkdir data/covariate_files; <styled-content style="color:#1c2ffe">fi</styled-content>
<styled-content style="color:#1c2ffe">! if</styled-content> [[ ! -e data/response_files/ ]]; <styled-content style="color:#1c2ffe">then</styled-content> mkdir data/response_files; <styled-content style="color:#1c2ffe">fi</styled-content>
<styled-content style="color:#1c2ffe">! for</styled-content> i <styled-content style="color:#1c2ffe">in</styled-content> `cat data/roi_dir_names`; <styled-content style="color:#1c2ffe">do</styled-content> cd data/ROI_models; mkdir ${i}; cd ../../; cp
resp_tr_${i}.txt data/ROI_models/${i}/resp_tr.txt; cp resp_te_${i}.txt
data/ROI_models/${i}/resp_te.txt; cp cov_tr.txt
data/ROI_models/${i}/cov_tr.txt; cp cov_te.txt
data/ROI_models/${i}/cov_te.txt; <styled-content style="color:#1c2ffe">done</styled-content>
<styled-content style="color:#1c2ffe">!</styled-content> mv resp_*.txt data/response_files/
<styled-content style="color:#1c2ffe">!</styled-content> mv cov_t*.txt data/covariate_files/
</preformat>
</p></list-item></list></sec></sec><sec id="S38"><title>Algorithm &amp; Modeling: Basis expansion using B-splines</title><sec id="S39"><title>Timing: 1-3 minutes</title><list list-type="simple" id="L15"><list-item><label>9</label><p id="P56">Now, set up a B-spline basis set that allows us to perform nonlinear regression using a linear model, using the following commands. This basis is deliberately chosen to not to be too flexible so that it can only model relatively slowly varying trends. To increase the flexibility of the model you can change the parameterization (e.g., by adding knot points to the B-spline basis or increasing the order of the interpolating polynomial). Note that in the neuroimaging literature, it is more common to use a polynomial basis expansion for this. Piecewise polynomials like B-splines are superior to polynomial basis expansions because they do not introduce a global curvature. For further details on the use of B-splines see Fraza et al<sup><xref ref-type="bibr" rid="R25">25</xref></sup>.
<preformat preformat-type="computer code">
<styled-content style="color:#018325"># Create a cubic B-spline basis (used for regression)</styled-content>
xmin = <styled-content style="color:#018325">10#16 # xmin &amp; xmax are the boundaries for ages of participants in the dataset</styled-content>
xmax = <styled-content style="color:#018325">95#90</styled-content>
B = create_bspline_basis(xmin, xmax)
<styled-content style="color:#018325"># create the basis expansion for the covariates for each of the</styled-content>
<styled-content style="color:#bc2ee9">for</styled-content> roi <styled-content style="color:#7b33fe">in</styled-content> roi_ids:
   <styled-content style="color:#856427">print</styled-content>(<styled-content style="color:#a41b59">'Creating basis expansion for ROI:'</styled-content>, roi)
   roi_dir = os.path.join(data_dir, roi)
   os.chdir(roi_dir)
   <styled-content style="color:#018325"># create output dir</styled-content>
   os.makedirs(os.path.join(roi_dir,<styled-content style="color:#a41b59">'blr'</styled-content>), exist_ok=<styled-content style="color:#7b33fe">True</styled-content>)
   <styled-content style="color:#018325"># load train &amp; test covariate data matrices</styled-content>
   X_tr = np.loadtxt(os.path.join(roi_dir, <styled-content style="color:#a41b59">'cov_tr.txt'</styled-content>))
   X_te = np.loadtxt(os.path.join(roi_dir, <styled-content style="color:#a41b59">'cov_te.txt'</styled-content>))
   <styled-content style="color:#018325"># add intercept column</styled-content>
   X_tr = np.concatenate((X_tr, np.ones((X_tr.shape[0],1))), axis=1)
   X_te = np.concatenate((X_te, np.ones((X_te.shape[0],1))), axis=1)
   np.savetxt(os.path.join(roi_dir, <styled-content style="color:#a41b59">'cov_int_tr.txt'</styled-content>), X_tr)
   np.savetxt(os.path.join(roi_dir, <styled-content style="color:#a41b59">'cov_int_te.txt'</styled-content>), X_te)
   <styled-content style="color:#018325"># create Bspline basis set</styled-content>
   Phi = np.array([B(i) <styled-content style="color:#bc2ee9">for</styled-content> i <styled-content style="color:#7b33fe">in</styled-content> X_tr[:,0]])
   Phis = np.array([B(i) <styled-content style="color:#bc2ee9">for</styled-content> i <styled-content style="color:#7b33fe">in</styled-content> X_te[:,0]])
   X_tr = np.concatenate((X_tr, Phi), axis=1)
   X_te = np.concatenate((X_te, Phis), axis=1)
   np.savetxt(os.path.join(roi_dir, <styled-content style="color:#a41b59">'cov_bspline_tr.txt'</styled-content>), X_tr)
   np.savetxt(os.path.join(roi dir, <styled-content style="color:#a41b59">'cov bspline te.txt'</styled-content>), X te)
</preformat>
</p></list-item></list></sec></sec><sec id="S40"><title>Algorithm &amp; Modeling - estimate normative model</title><sec id="S41"><title>Timing: 3-5 minutes per model (multiply by number of ROIs/models)</title><list list-type="simple" id="L16"><list-item><label>10</label><p id="P57">Set up a variable (<monospace>data_dir</monospace>) that specifies the path to the ROI directories that were created in Step 7. Initiate two empty pandas data frames where the evaluation metrics are the column names, as follows; one will be used for overall test set evaluation (<monospace>blr_metrics</monospace>) and one will be used for site-specific test set evaluation (<monospace>blr_site_metrics</monospace>). After the normative model has been estimated, these data frames will be saved as individual csv files.
<preformat preformat-type="computer code">
<styled-content style="color:#229224"># set this path to wherever your ROI_models folder is located (where you copied all of the covariate &amp; response text files to in Step 4)</styled-content>
data_dir = <styled-content style="color:#a41b59">'/Users/saigerutherford/repos/PCNToolkit-demo/data/ROI models/'</styled-content>
<styled-content style="color:#229224"># Create pandas dataframes with header names to save out the overall and per-site model evaluation metrics</styled-content>
blr_metrics = pd.DataFrame(columns = [ <styled-content style="color:#a41b59">'ROI'</styled-content>, <styled-content style="color:#a41b59">'MSLL'</styled-content>, <styled-content style="color:#a41b59">'EV'</styled-content>, <styled-content style="color:#a41b59">'SMSE'</styled-content>, <styled-content style="color:#a41b59">'RMSE'</styled-content>, <styled-content style="color:#a41b59">'Rho'</styled-content>])
blr_site_metrics = pd.DataFrame(columns = [<styled-content style="color:#a41b59">'ROI'</styled-content>, <styled-content style="color:#a41b59">'site'</styled-content>, <styled-content style="color:#a41b59">'y_mean'</styled-content>, <styled-content style="color:#a41b59">'y_var'</styled-content>, <styled-content style="color:#a41b59">'yhat_mean'</styled-content>,
              <styled-content style="color:#a41b59">'yhat_var'</styled-content>, <styled-content style="color:#a41b59">'MSLL'</styled-content>, <styled-content style="color:#a41b59">'EV'</styled-content>, <styled-content style="color:#a41b59">'SMSE'</styled-content>, <styled-content style="color:#a41b59">'RMSE'</styled-content>, <styled-content style="color:#a41b59">'Rho'</styled-content>])
</preformat>
</p></list-item><list-item><label>11</label><p id="P58">Estimate the normative models using a for loop to iterate over brain regions. The estimate function uses a few specific arguments that are worthy of commenting on:
<list list-type="bullet" id="L17"><list-item><label>•</label><p id="P59">alg = <monospace>'blr'</monospace>: specifies we should use Bayesian Linear Regression. See <xref ref-type="table" rid="T1">Table 1</xref> for other available algorithms.</p></list-item><list-item><label>•</label><p id="P60">optimizer = 'powell': use Powell's derivative-free optimization method (faster in this case than L-BFGS)</p></list-item><list-item><label>•</label><p id="P61">savemodel = False: do not write out the final estimated model to disk</p></list-item><list-item><label>•</label><p id="P62">saveoutput = False: return the outputs directly rather than writing them to disk</p></list-item><list-item><label>•</label><p id="P63">standardize = False: Do not standardize the covariates or response variables</p></list-item></list>
</p></list-item></list><p id="P64">An important consideration is whether to re-scale or standardize the covariates or responses. Whilst this generally only has a minor effect on the final model accuracy, it has implications for the interpretation of models and how they are configured. If the covariates and responses are both standardized (standardize = True), the model will return standardized coefficients. If (as in this case) the response variables are not standardized (standardized = False), then the scaling both covariates and responses will be reflected in the estimated coefficients. Also, under the linear modeling approach employed here, if the coefficients are unstandardized and do not have a zero mean, it is necessary to add an intercept column to the design matrix (this is done above in step 9 (B-spline)).</p></sec></sec><sec id="S42"><title>CRITICAL STEP</title><p id="P65">This code fragment will loop through each region of interest in the roi_ids list (created in step 4) using Bayesian Linear Regression and evaluate the model on the independent test set. In principle, we could estimate the normative models on the whole data matrix at once (e.g., with the response variables stored in a n_subjects by n_brain_measures NumPy array or a text file instead of saved out into separate directories). However, running the models iteratively gives some extra flexibility in that it does not require that the included subjects are the same for each of the brain measures.
<preformat preformat-type="computer code">
<styled-content style="color:#229224"># Loop through ROIs</styled-content>
<styled-content style="color:#ba24e5">for</styled-content> roi <styled-content style="color:#7949fe">in</styled-content> roi_ids:
      <styled-content style="color:#856427">print</styled-content>(<styled-content style="color:#a31515">'Running ROI:'</styled-content>, roi)
      roi_dir = os.path.join(data_dir, roi)
      os.chdir(roi_dir)
      <styled-content style="color:#229224"># configure the covariates to use. Change *_bspline_* to *_int_* to</styled-content>
      cov_file_tr = os.path.join(roi_dir, <styled-content style="color:#a31515">'cov_bspline_tr.txt'</styled-content>)
      cov_file_te = os.path.join(roi_dir, <styled-content style="color:#a31515">'cov_bspline_te.txt'</styled-content>)
      <styled-content style="color:#229224"># load train &amp; test response files</styled-content>
      resp_file_tr = os.path.join(roi_dir, <styled-content style="color:#a31515">'resp_tr.txt'</styled-content>)
      resp_file_te = os.path.join(roi_dir, <styled-content style="color:#a31515">'resp_te.txt'</styled-content>)
      <styled-content style="color:#229224"># run a basic model</styled-content>
      yhat_te, s2_te, nm, Z, metrics_te             = estimate(cov_file_tr,
            resp_file_tr,
            testresp=resp_file_te,
            testcov=cov_file_te,
            alg = <styled-content style="color:#a31515">'blr'</styled-content>,
            optimizer = <styled-content style="color:#a31515">'powell'</styled-content>,
            savemodel = <styled-content style="color:#7949fe">False</styled-content>,
            saveoutput = <styled-content style="color:#7949fe">False</styled-content>,
            standardize = <styled-content style="color:#7949fe">False</styled-content>)
<styled-content style="color:#229224"># display and save metrics</styled-content>
      <styled-content style="color:#856427">print</styled-content>(<styled-content style="color:#a31515">'EV='</styled-content>, metrics_te[<styled-content style="color:#a31515">'EXPV'</styled-content>][<styled-content style="color:#229224">0</styled-content>])
      <styled-content style="color:#856427">print</styled-content>(<styled-content style="color:#a31515">'RHO='</styled-content>, metrics_te[<styled-content style="color:#a31515">'Rho'</styled-content>][<styled-content style="color:#229224">0</styled-content>])
      <styled-content style="color:#856427">print</styled-content>(<styled-content style="color:#a31515">'MSLL='</styled-content>, metrics_te[<styled-content style="color:#a31515">'MSLL'</styled-content>][<styled-content style="color:#229224">0</styled-content>])
      blr_metrics.loc[<styled-content style="color:#917748">len</styled-content>(blr_metrics)] = [roi, metrics_te[<styled-content style="color:#a31515">'MSLL'</styled-content>][<styled-content style="color:#229224">0</styled-content>],
      metrics_te[<styled-content style="color:#a31515">'EXPV'</styled-content>][<styled-content style="color:#229224">0</styled-content>], metrics_te[<styled-content style="color:#a31515">'SMSE'</styled-content>][<styled-content style="color:#229224">0</styled-content>], metrics_te[<styled-content style="color:#a31515">'RMSE'</styled-content>][<styled-content style="color:#229224">0</styled-content>],
      metrics_te[<styled-content style="color:#a31515">'Rho'</styled-content>][<styled-content style="color:#229224">0</styled-content>]]
      # <styled-content style="color:#229224">Compute metrics per site in test set, save to pandas df</styled-content>
      <styled-content style="color:#229224"># load true test data</styled-content>
      X_te = np.loadtxt(cov_file_te)
      y_te = np.loadtxt(resp_file_te)
      y_te = y_te[:, np.newaxis] <styled-content style="color:#229224"># make sure it is a 2-d array</styled-content>
      <styled-content style="color:#229224"># load training data (required to compute the MSLL)</styled-content>
      y_tr = np.loadtxt(resp_file_tr)
      y_tr = y_tr[:, np.newaxis]
      <styled-content style="color:#ba24e5">for</styled-content> num, site <styled-content style="color:#ba24e5">in</styled-content> <styled-content style="color:#917748">enumerate</styled-content>(sites):
    y_mean_te_site = np.array([[np.mean(y_te[site])]])
    y_var_te_site = np.array([[np.var(y_te[site])]])
    yhat_mean_te_site = np.array([[np.mean(yhat_te[site])]])
    yhat_var_te_site = np.array([[np.var(yhat_te[site])]])
    metrics_te_site = evaluate(y_te[site], yhat_te[site], s2_te[site], y_mean_te_site, y_var_te_site)
    site_name = site_names[num]
    blr_site_metrics.loc[<styled-content style="color:#917748">len</styled-content>(blr_site_metrics)] = [roi, site_names[num],
            y_mean_te_site[<styled-content style="color:#229224">0</styled-content>],
            y_var_te_site[<styled-content style="color:#229224">0</styled-content>],
            yhat_mean_te_site[<styled-content style="color:#229224">0</styled-content>],
            yhat_var_te_site[<styled-content style="color:#229224">0</styled-content>],
            metrics_te_site[<styled-content style="color:#a31515">'MSLL'</styled-content>][<styled-content style="color:#229224">0</styled-content>],
            metrics_te_site[<styled-content style="color:#a31515">'EXPV'</styled-content>][<styled-content style="color:#229224">0</styled-content>],
            metrics_te_site[<styled-content style="color:#a31515">'SMSE'</styled-content>][<styled-content style="color:#229224">0</styled-content>],
            metrics_te_site[<styled-content style="color:#a31515">'RMSE'</styled-content>][<styled-content style="color:#229224">0</styled-content>],
            metrics_te_site[<styled-content style="color:#a31515">'Rho'</styled-content>][<styled-content style="color:#229224">0</styled-content>]]
</preformat>
</p></sec><sec id="S43"><title>Evaluation &amp; Interpretation - evaluate normative model performance</title><sec id="S44"><title>Timing: 5-10 minutes</title><list list-type="simple" id="L18"><list-item><label>12</label><p id="P66">In step 11, when we looped over each region of interest in the <monospace>roi_ids</monospace> list (created in step 4) and evaluated the normative model on the independent test set, it also computed the evaluation metrics such as the explained variance, mean standardized log-loss and Pearson correlation between true and predicted test responses. The evaluation metrics were calculated for the full test set and calculated separately for each scanning site. The metrics were saved out to a csv file. In this step we load the evaluation metrics into a panads data frame and use the describe function to show the range, mean, and standard deviation of each of the evaluation metrics. <xref ref-type="table" rid="T2">Table 2</xref> shows how to interpret the ranges/directions of good model fit.
<preformat preformat-type="computer code">
metrics_te([<styled-content style="color:#c95d30">'EXPV'</styled-content>]).describe()
metrics_te([<styled-content style="color:#c95d30">'MSLL'</styled-content>]).describe()
metrics_te([<styled-content style="color:#c95d30">'SMSE'</styled-content>]).describe()
metrics_te([<styled-content style="color:#c95d30">'Rho'</styled-content>]).describe()
metrics_te_site([<styled-content style="color:#c95d30">'EV'</styled-content>]).describe()
metrics_te_site([<styled-content style="color:#c95d30">'MSLL'</styled-content>]).describe()
metrics_te_site([<styled-content style="color:#c95d30">'SMSE'</styled-content>]).describe()
metrics_te_site([<styled-content style="color:#c95d30">'Rho'</styled-content>]).describe()
</preformat>
</p></list-item></list></sec></sec><sec id="S45"><title>Evaluation &amp; Interpretation - visualize normative model outputs</title><sec id="S46"><title>Timing: 15-20 minutes</title><list list-type="simple" id="L19"><list-item><label>13</label><p id="P67">In this step we look at different ways of visualizing the evaluation metrics from step 12. There are typically many models fit across the different brain regions and it can be a lot of effort to keep track of the performance across all the brain regions. Data visualization will help to understand if there are any emerging patterns and find if there are any brain areas (or certain sites) where the model does not fit well. We summarize the deviation scores in the test set by counting how many subjects have an ‘extreme’ deviation (either positive or negative) and visualize the count of extreme negative and positive deviations by plotting them on a 3D brain plot. This step requires using a separate python notebook (<ext-link ext-link-type="uri" xlink:href="https://github.com/predictive-clinical-neuroscience/PCNtoolkit-demo/blob/main/tutorials/BLR_protocol/visualizations.ipynb">https://github.com/predictive-clinical-neuroscience/PCNtoolkit-demo/blob/main/tutorials/BLR_protocol/visualizations.ipynb</ext-link>)</p></list-item></list></sec></sec><sec id="S47"><title>Evaluation &amp; Interpretation – post-hoc analysis ideas using normative modeling outputs</title><sec id="S48"><title>Timing: 1-2 hours</title><list list-type="simple" id="L20"><list-item><label>14</label><p id="P68">There are many interesting analyses that can be conducted using the outputs of normative modeling (deviation scores). An in-depth tutorial on each of these analyses is outside the scope of this protocol. However, on <underline><styled-content style="color:#087adc">GitHub</styled-content></underline>, we include code examples (python notebooks that can be run via Colab) of the following post-hoc analysis: (<ext-link ext-link-type="uri" xlink:href="https://github.com/predictive-clinical-neuroscience/PCNtoolkit-demo/blob/main/tutorials/BLR_protocol/post_hoc_analysis.ipynb">https://github.com/predictive-clinical-neuroscience/PCNtoolkit-demo/blob/main/tutorials/BLR_protocol/post_hoc_analysis.ipynb</ext-link>)</p><list list-type="bullet" id="L21"><list-item><label>•</label><p id="P69">Using deviation scores as predictors in a regression and classification and comparing the performance to using the true data as predictors. Code for implementing several common predictive modeling frameworks (that are mentioned in comparison to other methods section) is provided. Deviation scores from normative modeling could be used as input features to any of these predictive modeling frameworks.</p></list-item><list-item><label>•</label><p id="P70">Using a pre-trained normative model and transferring it to a new, unseen data set.</p></list-item><list-item><label>•</label><p id="P71">Classical case-control testing (univariate t-tests) on deviation maps compared to univariate t-tests on the true data.</p></list-item></list></list-item></list></sec></sec></sec><sec id="S49"><title>Timing</title><p id="P72">The normative modeling portion of this protocol (including evaluation and visualization) can be completed in approximately 57-72 minutes. If using the additional code for post-hoc analysis of the normative modeling outputs, you would add approximately 1-2 hours to the estimated normative modeling time. These timing estimates are if using the Google Colab platform to run the code. If running this protocol on your own computer (where you need to install python and dependencies), this will add extra time to the protocol.</p></sec><sec id="S50"><title>Anticipated Results</title><p id="P73">There are multiple end products created from running a normative model analysis. First, the evaluation metrics for each model (brain region) are saved to a file. In this protocol, we saved the metrics to a CSV file format, however, in the pcn.estimate() function you could set the argument ‘binary = True’ which would save the metrics in pickle (.pkl) format. Pickle format is good to use if you are estimating many models in parallel on a large dataset, as it is faster because it avoids reading/writing intermediate text files. These metrics are further summarized into per site metrics to check model fit for each site included in the test set. The short and full names of the evaluation metrics and a brief interpretation guide is summarized in <xref ref-type="table" rid="T2">Table 2</xref>. The evaluation metrics can be visualized in numerous formats, histograms/density plots, scatter plots with fitted centiles, or brain-space visualizations. Several examples of these visualizations are shown in <xref ref-type="fig" rid="F4">Figure 4</xref> and code for creating these plots is shared on GitHub. Quality checking the normative model evaluation metrics should be done to ensure proper model estimation. If a model fits well to the data, the evaluation metrics should follow a Gaussian distribution. The model estimation (Procedure step 11) should properly handle confounding site effects, nevertheless, it is also a good idea to check per site metrics to make sure the model is fitting all sites equally well and that there are no obvious site outliers. In addition to the summary level evaluation metrics, there are also many individual metrics (one value per subject for each model/brain region). These individual-level outputs can be very helpful for interpretation because they precisely quantify the uncertainty of each individual predicted value at every location across the brain. If a given individual is identified as having an ‘extreme’ deviation, an<bold>d</bold> there is low uncertainty you can be confident this is a biologically valid finding and not due to modeling errors. Vice versa, if there are extreme deviations and high levels of uncertainty, more caution should be given to interpretating these results and the deviations may be due to modelin<bold>g</bold> errors rather than true biological variation. The uncertainty estimates are separated into two components (noise and modeling, described in <xref ref-type="table" rid="T2">Table 2</xref>) to help pinpoint the sources of uncertainty.</p><p id="P74">A benefit of the PCNtoolkit software for normative modeling, that sets our approach apart from other normative modeling implementations<sup><xref ref-type="bibr" rid="R84">84</xref></sup>, is the fine-scale resolution allowed by the model. Other normative modeling work<sup><xref ref-type="bibr" rid="R84">84</xref></sup> has focused on modeling gross features such as total brain volume or gray matter volume, which is not adequate for normative modeling applied to mental health conditions and neurodevelopmental disorders, where the effects are subtle and widespread (individuals within a patient group tend to deviate in different regions, see <xref ref-type="fig" rid="F4">Figure 4E-F</xref>) across the cortex and subcortex and averaging over large brain areas usually overlooks these elusive psychiatric effects. This resolution also allows for a better mechanistic understanding because you can quantify the deviation and associated uncertainty for each individual with high spatial precision.</p><p id="P75">Reliability (the extent to which a measurement gives results that are very consistent) and validity (the degree to which a measurement measures what it is supposed to measure) are important constructs to keep in mind when interpreting results. In recent work, reliability of normative modeling in schizophrenia and bipolar disorder using structural MRI measures was established via replication<sup><xref ref-type="bibr" rid="R37">37</xref></sup>. Validity is arguably more challenging to assess but should be established by means of out of sample model fit. In other recent work, normative models were fit using a lifespan (age 3-100) big data sample (N=58,836) and carefully tested out-of-sample (variance explained, skewness, kurtosis, and standardized mean squared error) showing excellent model fit (12-68% variance explained) in an independent test set from a sample (and site) that was not included in the training set<sup><xref ref-type="bibr" rid="R85">85</xref></sup>. This work suggests validity, but this is an on-going evaluation and out of sample model fit must always be considered and reported.</p></sec><sec id="S51"><title>Troubleshooting</title><p id="P76">We re-iterate that there is additional documentation available online through <underline><styled-content style="color:#087adc">read the docs</styled-content></underline> including additional tutorials for other algorithm implementations (Gaussian Process Regression and Hierarchical Bayesian Regression), a glossary to clarify the jargon associated with the software, a reference guide with links to normative modeling publications, and a frequently asked questions page where many common errors (and their solutions) are discussed in detail. The problems encountered when troubleshooting a normative modeling analysis can fall into three categories: computing errors, data issues, and misunderstanding or misinterpreting the outputs.</p><sec id="S52"><title>Computing errors</title><p id="P77">The computing errors might involve python or the computer hardware. Potential python errors may include installation of python or installation of the necessary packages and their dependencies. We recommend using Anaconda to install python 3.8 (required for this protocol) on your system, and the use of a virtual environment for the PCNtoolkit to ensure that the packages required for normative modeling do not interfere with other python versions and packages you may have installed on your system. In general, it is good to have a virtual environment setup for each project or analysis. If you are unfamiliar with setting up virtual environments, and run into issues with python, it is always an option to run the analysis in the cloud via Colab which eliminates the need to setup python on your own system. Hardware problems might include lack of memory to store the data or models running very slowly due to outdated hardware. These hardware errors do not have an easy solution, and we recommend using Google Colab to run normative modeling analysis if your personal computer or server is very slow or lacks the storage space.</p></sec><sec id="S53"><title>Data issues</title><p id="P78">Data issues that may be encountered are data missing not at random (see Experimental Design section regarding caution using data imputation), improperly coded data (i.e., strings instead of integers or floats, NaN values coded incorrectly), collinearity of columns in the covariate design matrix, or outlier data that does not make biological sense (i.e., negative cortical thickness values, negative age values). While these data errors can be incredibly frustrating to troubleshoot, they can typically be fixed by careful quality checking of the input data and removal of bad ROIs or subjects as needed.</p></sec><sec id="S54"><title>Interpretation confusion</title><p id="P79">Finally, an example of interpretation confusion may be poor model performance on a certain brain region or site. This can usually be addressed by returning to the input data for additional quality checking to confirm that the poor performance is not due to data quality issues. If there are no data quality issues, then it may be the reality that the model does not fit well some brain regions, and you may want to consider including additional covariates in the model to help explain more variance. Another interpretation confusion may arise when seeing negative explained variance values. When testing out of sample, the explained variance is not restricted to be positive, if it is negative this mean that the model fit is very poor (it is worse than an intercept-only model).</p></sec></sec></body><back><ack id="S55"><title>Acknowledgements</title><p>This research was supported by grants from the European Research Council (ERC, grant “MENTALPRECISION” 10100118 and “BRAINMINT” 802998), the Wellcome Trust under an Innovator award (“BRAINCHART”, 215698/Z/19/Z) and a Strategic Award (098369/Z/12/Z), the Dutch Organisation for Scientific Research (VIDI grant 016.156.415). TW also gratefully acknowledges the Niels Stensen Fellowship as well as the European Union’s Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie Grant agreement No. 895011.</p></ack><sec id="S56" sec-type="data-availability"><title>Data Availability Statement</title><p id="P80">All data used in this protocol are available on <underline><styled-content style="color:#087adc">GitHub</styled-content></underline> and <underline><styled-content style="color:#087adc">Zenodo</styled-content></underline><sup><xref ref-type="bibr" rid="R86">86</xref></sup> in csv files. We also include a template csv file to help format user’s own data into the correct form for running the protocol using their own data set.</p></sec><sec id="S57" sec-type="data-availability"><title>Code Availability Statement</title><p id="P81">All code is available on <underline><styled-content style="color:#087adc">GitHub</styled-content></underline> in the format of python notebooks that can be run in the cloud (for free) using <underline><styled-content style="color:#087adc">Google Colab</styled-content></underline>. We have also shared the GitHub repository on <underline><styled-content style="color:#087adc">Zenodo</styled-content></underline> to create a citable DOI for this software that also allows versions which are necessary as additional code and tutorials may be added over time<sup><xref ref-type="bibr" rid="R86">86</xref></sup>.</p></sec><fn-group><fn id="FN3" fn-type="con"><p id="P82"><bold>Author Contributions</bold></p><p id="P83">Conceptualization: SR, SMK, TW, CF, MZ, RD, PB, AW, SV, HGR, CFB, AFM; Methodology: SR, SMK, TW, CF, MZ, RD, AFM; Data Curation: SR, AFM; Writing – Original Draft: SR; Writing – Reviewing and Editing: SR, SMK, TW, CF, MZ, RD, PB, AW, SV, HGR, CFB, AFM; Visualization: SR; Supervision: HR, CFB, AFM; Funding Acquisition: HR, CFB, AFM</p></fn><fn id="FN4" fn-type="conflict"><p id="P84"><bold>Conflict of Interests</bold></p><p id="P85">CFB is director and shareholder of SBGNeuro Ltd. HGR received speaker’s honorarium from Lundbeck and Janssen. The other authors report no conflicts of interest.</p></fn></fn-group><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>D</given-names></name><etal/></person-group><article-title>Parcellating cortical functional networks in individuals</article-title><source>Nat Neurosci</source><year>2015</year><volume>18</volume><fpage>1853</fpage><lpage>1860</lpage></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Finn</surname><given-names>ES</given-names></name><name><surname>Constable</surname><given-names>RT</given-names></name></person-group><article-title>Individual variation in functional brain connectivity: implications for personalized approaches to psychiatric disease</article-title><source>Dialogues Clin Neurosci</source><year>2016</year><volume>18</volume><fpage>277</fpage><lpage>287</lpage></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Braga</surname><given-names>RM</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name></person-group><article-title>Parallel Interdigitated Distributed Networks within the Individual Estimated by Intrinsic Functional Connectivity</article-title><source>Neuron</source><year>2017</year><volume>95</volume><fpage>457</fpage><lpage>471</lpage><elocation-id>e5</elocation-id></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poldrack</surname><given-names>RA</given-names></name></person-group><article-title>Precision Neuroscience: Dense Sampling of Individual Brains</article-title><source>Neuron</source><year>2017</year><volume>95</volume><fpage>727</fpage><lpage>729</lpage></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vanderwal</surname><given-names>T</given-names></name><etal/></person-group><article-title>Individual differences in functional connectivity during naturalistic viewing conditions</article-title><source>NeuroImage</source><year>2017</year><volume>157</volume><fpage>521</fpage><lpage>530</lpage></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Braun</surname><given-names>U</given-names></name><etal/></person-group><article-title>From Maps to Multi-dimensional Network Mechanisms of Mental Disorders</article-title><source>Neuron</source><year>2018</year><volume>97</volume><fpage>14</fpage><lpage>31</lpage></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gratton</surname><given-names>C</given-names></name><etal/></person-group><article-title>Defining Individual-Specific Functional Neuroanatomy for Precision Psychiatry</article-title><source>Biological Psychiatry</source><year>2020</year><volume>88</volume><fpage>28</fpage><lpage>39</lpage></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hyman</surname><given-names>SE</given-names></name></person-group><article-title>Can neuroscience be integrated into the DSM-V?</article-title><source>Nat Rev Neurosci</source><year>2007</year><volume>8</volume><fpage>725</fpage><lpage>732</lpage></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Insel</surname><given-names>T</given-names></name><etal/></person-group><article-title>Research Domain Criteria (RDoC): Toward a New Classification Framework for Research on Mental Disorders</article-title><source>AJP</source><year>2010</year><volume>167</volume><fpage>748</fpage><lpage>751</lpage></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Michelini</surname><given-names>G</given-names></name><name><surname>Palumbo</surname><given-names>IM</given-names></name><name><surname>DeYoung</surname><given-names>CG</given-names></name><name><surname>Latzman</surname><given-names>RD</given-names></name><name><surname>Kotov</surname><given-names>R</given-names></name></person-group><article-title>Linking RDoC and HiTOP: A new interface for advancing psychiatric nosology and neuroscience</article-title><source>Clinical Psychology Review</source><year>2021</year><volume>86</volume><elocation-id>102025</elocation-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Narrow</surname><given-names>WE</given-names></name><name><surname>Kuhl</surname><given-names>EA</given-names></name></person-group><article-title>Dimensional approaches to psychiatric diagnosis in DSM-5</article-title><source>J Ment Health Policy Econ</source><year>2011</year><volume>14</volume><fpage>197</fpage><lpage>200</lpage></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cuthbert</surname><given-names>BN</given-names></name><name><surname>Insel</surname><given-names>TR</given-names></name></person-group><article-title>Toward the future of psychiatric diagnosis: the seven pillars of RDoC</article-title><source>BMC Med</source><year>2013</year><volume>11</volume><fpage>126</fpage></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanislow</surname><given-names>CA</given-names></name></person-group><article-title>RDoC at 10: changing the discourse for psychopathology</article-title><source>World Psychiatry</source><year>2020</year><volume>19</volume><fpage>311</fpage><lpage>312</lpage></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kotov</surname><given-names>R</given-names></name><etal/></person-group><article-title>The Hierarchical Taxonomy of Psychopathology (HiTOP): A dimensional alternative to traditional nosologies</article-title><source>Journal of Abnormal Psychology</source><year>2017</year><volume>126</volume><fpage>454</fpage><lpage>477</lpage></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kotov</surname><given-names>R</given-names></name><etal/></person-group><article-title>The Hierarchical Taxonomy of Psychopathology (HiTOP): A Quantitative Nosology Based on Consensus of Evidence</article-title><source>Annu Rev Clin Psychol</source><year>2021</year><volume>17</volume><elocation-id>annurev-clinpsy-081219-093304</elocation-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haro</surname><given-names>JM</given-names></name><etal/></person-group><article-title>ROAMER: roadmap for mental health research in Europe</article-title><source>Int J Methods Psychiatr Res</source><year>2014</year><volume>23</volume><issue>Suppl 1</issue><fpage>1</fpage><lpage>14</lpage></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schumann</surname><given-names>G</given-names></name><etal/></person-group><article-title>Stratified medicine for mental disorders</article-title><source>Eur Neuropsychopharmacol</source><year>2014</year><volume>24</volume><fpage>5</fpage><lpage>50</lpage></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feczko</surname><given-names>E</given-names></name><etal/></person-group><article-title>The Heterogeneity Problem: Approaches to Identify Psychiatric Subtypes</article-title><source>Trends in Cognitive Sciences</source><year>2019</year><volume>23</volume><fpage>584</fpage><lpage>601</lpage></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shen</surname><given-names>X</given-names></name><etal/></person-group><article-title>Using connectome-based predictive modeling to predict individual behavior from brain connectivity</article-title><source>Nature Protocols</source><year>2017</year><volume>12</volume><fpage>506</fpage><lpage>518</lpage></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sripada</surname><given-names>C</given-names></name><etal/></person-group><article-title>Basic Units of Inter-Individual Variation in Resting State Connectomes</article-title><source>Scientific Reports</source><year>2019</year><volume>9</volume><elocation-id>1900</elocation-id></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woo</surname><given-names>C-W</given-names></name><name><surname>Chang</surname><given-names>LJ</given-names></name><name><surname>Lindquist</surname><given-names>MA</given-names></name><name><surname>Wager</surname><given-names>TD</given-names></name></person-group><article-title>Building better biomarkers: brain models in translational neuroimaging</article-title><source>Nat Neurosci</source><year>2017</year><volume>20</volume><fpage>365</fpage><lpage>377</lpage></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marquand</surname><given-names>AF</given-names></name><etal/></person-group><article-title>Conceptualizing mental disorders as deviations from normative functioning</article-title><source>Molecular Psychiatry</source><year>2019</year><volume>24</volume><fpage>1415</fpage><lpage>1424</lpage></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gau</surname><given-names>R</given-names></name><etal/></person-group><article-title>Brainhack: Developing a culture of open, inclusive, community-driven neuroscience</article-title><source>Neuron</source><year>2021</year><volume>109</volume><fpage>1769</fpage><lpage>1775</lpage></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olah</surname><given-names>C</given-names></name><name><surname>Carter</surname><given-names>S</given-names></name></person-group><source>Research Debt Distill</source><year>2017</year><volume>2</volume><fpage>e5</fpage></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fraza</surname><given-names>CJ</given-names></name><name><surname>Dinga</surname><given-names>R</given-names></name><name><surname>Beckmann</surname><given-names>CF</given-names></name><name><surname>Marquand</surname><given-names>AF</given-names></name></person-group><article-title>Warped Bayesian Linear Regression for Normative Modelling of Big Data</article-title><source>bioRxiv</source><year>2021</year><elocation-id>2021.04.05.438429</elocation-id><pub-id pub-id-type="doi">10.1101/2021.04.05.438429</pub-id></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dinga</surname><given-names>R</given-names></name><etal/></person-group><source>Normative modeling of neuroimaging data using generalized additive models of location scale and shape</source><year>2021</year><pub-id pub-id-type="doi">10.1101/2021.06.14.448106</pub-id><comment><ext-link ext-link-type="uri" xlink:href="http://biorxiv.org/lookup/doi/10.1101/2021.06.14.448106">http://biorxiv.org/lookup/doi/10.1101/2021.06.14.448106</ext-link></comment></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kia</surname><given-names>SM</given-names></name><etal/></person-group><article-title>Hierarchical Bayesian Regression for Multi-site Normative Modeling of Neuroimaging Data</article-title><source>Medical Image Computing and Computer Assisted Intervention – MICCAI2020</source><person-group person-group-type="editor"><name><surname>Martel</surname><given-names>AL</given-names></name><etal/></person-group><publisher-name>Springer International Publishing</publisher-name><year>2020</year><fpage>699</fpage><lpage>709</lpage><pub-id pub-id-type="doi">10.1007/978-3-030-59728-3_68</pub-id></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kia</surname><given-names>SM</given-names></name><etal/></person-group><article-title>Federated Multi-Site Normative Modeling using Hierarchical Bayesian Regression</article-title><source>bioRxiv</source><year>2021</year><elocation-id>2021.05.28.446120</elocation-id><pub-id pub-id-type="doi">10.1101/2021.05.28.446120</pub-id></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Floris</surname><given-names>DL</given-names></name><etal/></person-group><article-title>Atypical Brain Asymmetry in Autism—A Candidate for Clinically Meaningful Stratification</article-title><source>Biological Psychiatry: Cognitive Neuroscience and Neuroimaging</source><year>2020</year><pub-id pub-id-type="doi">10.1016/j.bpsc.2020.08.008</pub-id></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zabihi</surname><given-names>M</given-names></name><etal/></person-group><article-title>Dissecting the Heterogeneous Cortical Anatomy of Autism Spectrum Disorder Using Normative Models</article-title><source>Biological Psychiatry: Cognitive Neuroscience and Neuroimaging</source><year>2019</year><volume>4</volume><fpage>567</fpage><lpage>578</lpage></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zabihi</surname><given-names>M</given-names></name><etal/></person-group><article-title>Fractionating autism based on neuroanatomical normative modeling</article-title><source>Translational Psychiatry</source><year>2020</year><volume>10</volume><fpage>1</fpage><lpage>10</lpage></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolfers</surname><given-names>T</given-names></name><etal/></person-group><article-title>Individual differences v the average patient: mapping the heterogeneity in ADHD using normative models</article-title><source>Psychological Medicine</source><year>2020</year><volume>50</volume><fpage>314</fpage><lpage>323</lpage></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolfers</surname><given-names>T</given-names></name><etal/></person-group><article-title>Refinement by integration: aggregated effects of multimodal imaging markers on adult ADHD</article-title><source>J Psychiatry Neurosci</source><year>2017</year><volume>42</volume><fpage>386</fpage><lpage>394</lpage></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Verdi</surname><given-names>S</given-names></name><name><surname>Marquand</surname><given-names>AF</given-names></name><name><surname>Schott</surname><given-names>JM</given-names></name><name><surname>Cole</surname><given-names>JH</given-names></name></person-group><article-title>Beyond the average patient: how neuroimaging models can address heterogeneity in dementia</article-title><source>Brain</source><year>2021</year><pub-id pub-id-type="doi">10.1093/brain/awab165</pub-id></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolfers</surname><given-names>T</given-names></name><etal/></person-group><source>Extensive brain structural heterogeneity in individuals with schizophrenia and bipolar disorder</source><year>2020</year><pub-id pub-id-type="doi">10.1101/2020.05.08.20095091</pub-id><comment><ext-link ext-link-type="uri" xlink:href="http://medrxiv.org/lookup/doi/10.1101/2020.05.08.20095091">http://medrxiv.org/lookup/doi/10.1101/2020.05.08.20095091</ext-link></comment></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolfers</surname><given-names>T</given-names></name><etal/></person-group><article-title>Mapping the Heterogeneous Phenotype of Schizophrenia and Bipolar Disorder Using Normative Models</article-title><source>JAMA Psychiatry</source><year>2018</year><volume>75</volume><fpage>1146</fpage><lpage>1155</lpage></element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolfers</surname><given-names>T</given-names></name><etal/></person-group><article-title>Replicating extensive brain structural heterogeneity in individuals with schizophrenia and bipolar disorder</article-title><source>Human Brain Mapping</source><year>2021</year><volume>42</volume><fpage>2546</fpage><lpage>2555</lpage></element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sripada</surname><given-names>C</given-names></name><name><surname>Angstadt</surname><given-names>M</given-names></name><name><surname>Rutherford</surname><given-names>S</given-names></name><name><surname>Taxali</surname><given-names>A</given-names></name></person-group><article-title>Brain Network Mechanisms of General Intelligence</article-title><source>bioRxiv</source><year>2019</year><elocation-id>657205</elocation-id><pub-id pub-id-type="doi">10.1101/657205</pub-id></element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sripada</surname><given-names>C</given-names></name><etal/></person-group><source>Brain Connectivity Patterns in Children Linked to Neurocognitive Abilities</source><year>2020</year><pub-id pub-id-type="doi">10.1101/2020.09.10.291500</pub-id><comment><ext-link ext-link-type="uri" xlink:href="http://biorxiv.org/lookup/doi/10.1101/2020.09.10.291500">http://biorxiv.org/lookup/doi/10.1101/2020.09.10.291500</ext-link></comment></element-citation></ref><ref id="R40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosenberg</surname><given-names>MD</given-names></name><etal/></person-group><article-title>A neuromarker of sustained attention from whole-brain functional connectivity</article-title><source>Nature Neuroscience</source><year>2015</year><volume>19</volume><fpage>165</fpage><lpage>171</lpage></element-citation></ref><ref id="R41"><label>41</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosenberg</surname><given-names>MD</given-names></name><etal/></person-group><article-title>Functional connectivity predicts changes in attention observed across minutes, days, and months</article-title><source>PNAS</source><year>2020</year><volume>117</volume><fpage>3797</fpage><lpage>3807</lpage></element-citation></ref><ref id="R42"><label>42</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marquand</surname><given-names>AF</given-names></name><name><surname>Haak</surname><given-names>KV</given-names></name><name><surname>Beckmann</surname><given-names>CF</given-names></name></person-group><article-title>Functional corticostriatal connection topographies predict goal directed behaviour in humans</article-title><source>Nat Hum Behav</source><year>2017</year><volume>1</volume></element-citation></ref><ref id="R43"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marquand</surname><given-names>A</given-names></name><etal/></person-group><article-title>Quantitative prediction of subjective pain intensity from whole-brain fMRI data using Gaussian processes</article-title><source>NeuroImage</source><year>2010</year><volume>49</volume><fpage>2178</fpage><lpage>2189</lpage></element-citation></ref><ref id="R44"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wager</surname><given-names>TD</given-names></name><etal/></person-group><article-title>An fMRI-Based Neurologic Signature of Physical Pain</article-title><source>New England Journal of Medicine</source><year>2013</year><volume>368</volume><fpage>1388</fpage><lpage>1397</lpage></element-citation></ref><ref id="R45"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sripada</surname><given-names>C</given-names></name><name><surname>Angstadt</surname><given-names>M</given-names></name><name><surname>Rutherford</surname><given-names>S</given-names></name><name><surname>Taxali</surname><given-names>A</given-names></name><name><surname>Shedden</surname><given-names>K</given-names></name></person-group><article-title>Toward a “treadmill test” for cognition: Improved prediction of general cognitive ability from the task activated brain</article-title><source>Human Brain Mapping</source><year>2020</year><volume>41</volume><fpage>3186</fpage><lpage>3197</lpage></element-citation></ref><ref id="R46"><label>46</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sripada</surname><given-names>C</given-names></name><name><surname>Taxali</surname><given-names>A</given-names></name><name><surname>Angstadt</surname><given-names>M</given-names></name><name><surname>Rutherford</surname><given-names>S</given-names></name></person-group><source>Boost in Test-Retest Reliability in Resting State fMRI with Predictive Modeling</source><year>2019</year><comment><ext-link ext-link-type="uri" xlink:href="http://biorxiv.org/lookup/doi/10.1101/796714">http://biorxiv.org/lookup/doi/10.1101/796714</ext-link></comment><pub-id pub-id-type="doi">10.1101/796714</pub-id></element-citation></ref><ref id="R47"><label>47</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Finn</surname><given-names>ES</given-names></name><etal/></person-group><article-title>Functional connectome fingerprinting: identifying individuals using patterns of brain connectivity</article-title><source>Nature Neuroscience</source><year>2015</year><volume>18</volume><fpage>1664</fpage><lpage>1671</lpage></element-citation></ref><ref id="R48"><label>48</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>H-T</given-names></name><etal/></person-group><article-title>Finding the needle in a high-dimensional haystack: Canonical correlation analysis for neuroscientists</article-title><source>NeuroImage</source><year>2020</year><volume>216</volume><elocation-id>116745</elocation-id></element-citation></ref><ref id="R49"><label>49</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>SM</given-names></name><etal/></person-group><article-title>A positive-negative mode of population covariation links brain connectivity, demographics and behavior</article-title><source>Nature Neuroscience</source><year>2015</year><volume>18</volume><fpage>1565</fpage><lpage>1567</lpage></element-citation></ref><ref id="R50"><label>50</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dadi</surname><given-names>K</given-names></name><etal/></person-group><article-title>Benchmarking functional connectome-based predictive models for restingstate fMRI</article-title><source>NeuroImage</source><year>2019</year><volume>192</volume><fpage>115</fpage><lpage>134</lpage></element-citation></ref><ref id="R51"><label>51</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lake</surname><given-names>EMR</given-names></name><etal/></person-group><article-title>The Functional Brain Organization of an Individual Allows Prediction of Measures of Social Abilities Transdiagnostically in Autism and Attention-Deficit/Hyperactivity Disorder</article-title><source>Biological Psychiatry</source><year>2019</year><volume>86</volume><fpage>315</fpage><lpage>326</lpage></element-citation></ref><ref id="R52"><label>52</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cole</surname><given-names>JH</given-names></name><name><surname>Franke</surname><given-names>K</given-names></name></person-group><article-title>Predicting Age Using Neuroimaging: Innovative Brain Ageing Biomarkers</article-title><source>Trends in Neurosciences</source><year>2017</year><volume>40</volume><fpage>681</fpage><lpage>690</lpage></element-citation></ref><ref id="R53"><label>53</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Han</surname><given-names>LKM</given-names></name><etal/></person-group><article-title>Brain aging in major depressive disorder: results from the ENIGMA major depressive disorder working group</article-title><source>Molecular Psychiatry</source><year>2020</year><fpage>1</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.1038/s41380-020-0754-0</pub-id></element-citation></ref><ref id="R54"><label>54</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sturmfels</surname><given-names>P</given-names></name><etal/></person-group><article-title>A Domain Guided CNN Architecture for Predicting Age from Structural Brain Images</article-title><source>arXiv:1808.04362 [cs, stat]</source><year>2018</year></element-citation></ref><ref id="R55"><label>55</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alfaro-Almagro</surname><given-names>F</given-names></name><etal/></person-group><article-title>Image processing and Quality Control for the first 10,000 brain imaging datasets from UK Biobank</article-title><source>Neuroimage</source><year>2018</year><volume>166</volume><fpage>400</fpage><lpage>424</lpage></element-citation></ref><ref id="R56"><label>56</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Donders</surname><given-names>ART</given-names></name><name><surname>van der Heijden</surname><given-names>GJMG</given-names></name><name><surname>Stijnen</surname><given-names>T</given-names></name><name><surname>Moons</surname><given-names>KGM</given-names></name></person-group><article-title>Review: A gentle introduction to imputation of missing values</article-title><source>Journal of Clinical Epidemiology</source><year>2006</year><volume>59</volume><fpage>1087</fpage><lpage>1091</lpage></element-citation></ref><ref id="R57"><label>57</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Madley-Dowd</surname><given-names>P</given-names></name><name><surname>Hughes</surname><given-names>R</given-names></name><name><surname>Tilling</surname><given-names>K</given-names></name><name><surname>Heron</surname><given-names>J</given-names></name></person-group><article-title>The proportion of missing data should not be used to guide decisions on multiple imputation</article-title><source>Journal of Clinical Epidemiology</source><year>2019</year><volume>110</volume><fpage>63</fpage><lpage>73</lpage></element-citation></ref><ref id="R58"><label>58</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burt</surname><given-names>JB</given-names></name><name><surname>Helmer</surname><given-names>M</given-names></name><name><surname>Shinn</surname><given-names>M</given-names></name><name><surname>Anticevic</surname><given-names>A</given-names></name><name><surname>Murray</surname><given-names>JD</given-names></name></person-group><article-title>Generative modeling of brain maps with spatial autocorrelation</article-title><source>NeuroImage</source><year>2020</year><volume>220</volume><elocation-id>117038</elocation-id></element-citation></ref><ref id="R59"><label>59</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shinn</surname><given-names>M</given-names></name><etal/></person-group><article-title>Spatial and temporal autocorrelation weave human brain networks</article-title><source>bioRxiv</source><year>2021</year><elocation-id>2021.06.01.446561</elocation-id><pub-id pub-id-type="doi">10.1101/2021.06.01.446561</pub-id></element-citation></ref><ref id="R60"><label>60</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>SM</given-names></name><name><surname>Nichols</surname><given-names>TE</given-names></name></person-group><article-title>Threshold-free cluster enhancement: addressing problems of smoothing, threshold dependence and localisation in cluster inference</article-title><source>Neuroimage</source><year>2009</year><volume>44</volume><fpage>83</fpage><lpage>98</lpage></element-citation></ref><ref id="R61"><label>61</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guo</surname><given-names>C</given-names></name><name><surname>Kang</surname><given-names>J</given-names></name><name><surname>Johnson</surname><given-names>TD</given-names></name></person-group><article-title>A spatial Bayesian latent factor model for image-on-image regression</article-title><source>Biometrics n/a</source><year>2020</year></element-citation></ref><ref id="R62"><label>62</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name></person-group><article-title>Constrained linear basis sets for HRF modelling using Variational Bayes</article-title><source>NeuroImage</source><year>2004</year><volume>21</volume><fpage>1748</fpage><lpage>1761</lpage></element-citation></ref><ref id="R63"><label>63</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>W</given-names></name><name><surname>Zhu</surname><given-names>P</given-names></name><name><surname>Anderson</surname><given-names>JS</given-names></name><name><surname>Yurgelun-Todd</surname><given-names>D</given-names></name><name><surname>Fletcher</surname><given-names>PT</given-names></name></person-group><article-title>Spatial Regularization of Functional Connectivity Using High-Dimensional Markov Random Fields</article-title><source>Med Image Comput Comput Assist Interv</source><year>2010</year><volume>13</volume><fpage>363</fpage><lpage>370</lpage></element-citation></ref><ref id="R64"><label>64</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>HF</given-names></name><name><surname>Kennedy</surname><given-names>H</given-names></name><name><surname>Wang</surname><given-names>X-J</given-names></name></person-group><article-title>Spatial embedding of structural similarity in the cerebral cortex</article-title><source>Proc Natl Acad Sci U S A</source><year>2014</year><volume>111</volume><fpage>16580</fpage><lpage>16585</lpage></element-citation></ref><ref id="R65"><label>65</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roberts</surname><given-names>JA</given-names></name><etal/></person-group><article-title>The contribution of geometry to the human connectome</article-title><source>NeuroImage</source><year>2016</year><volume>124</volume><fpage>379</fpage><lpage>393</lpage></element-citation></ref><ref id="R66"><label>66</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bijsterbosch</surname><given-names>J</given-names></name><etal/></person-group><article-title>Challenges and future directions for representations of functional brain organization</article-title><source>Nature Neuroscience</source><year>2020</year><volume>23</volume><fpage>1484</fpage><lpage>1495</lpage></element-citation></ref><ref id="R67"><label>67</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huertas</surname><given-names>I</given-names></name><etal/></person-group><article-title>A Bayesian spatial model for neuroimaging data based on biologically informed basis functions</article-title><source>NeuroImage</source><year>2017</year><volume>161</volume><fpage>134</fpage><lpage>148</lpage></element-citation></ref><ref id="R68"><label>68</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kia</surname><given-names>SM</given-names></name><name><surname>Marquand</surname><given-names>A</given-names></name></person-group><article-title>Normative Modeling of Neuroimaging Data using Scalable Multi-Task Gaussian Processes</article-title><source>arXiv:1806.01047 [cs, stat]</source><year>2018</year></element-citation></ref><ref id="R69"><label>69</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kia</surname><given-names>SM</given-names></name><name><surname>Beckmann</surname><given-names>CF</given-names></name><name><surname>Marquand</surname><given-names>AF</given-names></name></person-group><article-title>Scalable Multi-Task Gaussian Process Tensor Regression for Normative Modeling of Structured Variation in Neuroimaging Data</article-title><source>arXiv:1808.00036 [cs, stat]</source><year>2018</year></element-citation></ref><ref id="R70"><label>70</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Jahn</surname><given-names>A</given-names></name><etal/></person-group><source>andrewjahn/AndysBrainBook:</source><year>2022</year><publisher-name>Zenodo</publisher-name><pub-id pub-id-type="doi">10.5281/zenodo.5879294</pub-id></element-citation></ref><ref id="R71"><label>71</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Casey</surname><given-names>BJ</given-names></name><etal/></person-group><article-title>The Adolescent Brain Cognitive Development (ABCD) study: Imaging acquisition across 21 sites</article-title><source>Developmental Cognitive Neuroscience</source><year>2018</year><volume>32</volume><fpage>43</fpage><lpage>54</lpage></element-citation></ref><ref id="R72"><label>72</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thompson</surname><given-names>PM</given-names></name><etal/></person-group><article-title>ENIGMA and global neuroscience: A decade of large-scale studies of the brain in health and disease across more than 40 countries</article-title><source>Transl Psychiatry</source><year>2020</year><volume>10</volume><fpage>100</fpage></element-citation></ref><ref id="R73"><label>73</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beer</surname><given-names>JC</given-names></name><etal/></person-group><article-title>Longitudinal ComBat: A method for harmonizing longitudinal multiscanner imaging data</article-title><source>NeuroImage</source><year>2020</year><volume>220</volume><elocation-id>117129</elocation-id></element-citation></ref><ref id="R74"><label>74</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fortin</surname><given-names>J-P</given-names></name><etal/></person-group><article-title>Harmonization of multi-site diffusion tensor imaging data</article-title><source>NeuroImage</source><year>2017</year><volume>161</volume><fpage>149</fpage><lpage>170</lpage></element-citation></ref><ref id="R75"><label>75</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fortin</surname><given-names>J-P</given-names></name><etal/></person-group><article-title>Harmonization of cortical thickness measurements across scanners and sites</article-title><source>NeuroImage</source><year>2018</year><volume>167</volume><fpage>104</fpage><lpage>120</lpage></element-citation></ref><ref id="R76"><label>76</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>WE</given-names></name><name><surname>Li</surname><given-names>C</given-names></name><name><surname>Rabinovic</surname><given-names>A</given-names></name></person-group><article-title>Adjusting batch effects in microarray expression data using empirical Bayes methods</article-title><source>Biostatistics</source><year>2007</year><volume>8</volume><fpage>118</fpage><lpage>127</lpage></element-citation></ref><ref id="R77"><label>77</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nygaard</surname><given-names>V</given-names></name><name><surname>Rødland</surname><given-names>EA</given-names></name><name><surname>Hovig</surname><given-names>E</given-names></name></person-group><article-title>Methods that remove batch effects while retaining group differences may lead to exaggerated confidence in downstream analyses</article-title><source>Biostatistics</source><year>2016</year><volume>17</volume><fpage>29</fpage><lpage>39</lpage></element-citation></ref><ref id="R78"><label>78</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Noirhomme</surname><given-names>Q</given-names></name><etal/></person-group><article-title>Biased binomial assessment of cross-validated estimation of classification accuracies illustrated in diagnosis predictions</article-title><source>Neuroimage Clin</source><year>2014</year><volume>4</volume><fpage>687</fpage><lpage>694</lpage></element-citation></ref><ref id="R79"><label>79</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marquand</surname><given-names>AF</given-names></name><name><surname>Wolfers</surname><given-names>T</given-names></name><name><surname>Mennes</surname><given-names>M</given-names></name><name><surname>Buitelaar</surname><given-names>J</given-names></name><name><surname>Beckmann</surname><given-names>CF</given-names></name></person-group><article-title>Beyond Lumping and Splitting: A Review of Computational Approaches for Stratifying Psychiatric Disorders</article-title><source>Biological Psychiatry: Cognitive Neuroscience and Neuroimaging</source><year>2016</year><volume>1</volume><fpage>433</fpage><lpage>447</lpage></element-citation></ref><ref id="R80"><label>80</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rahimi</surname><given-names>A</given-names></name><name><surname>Recht</surname><given-names>B</given-names></name></person-group><source>Random Features for Large-Scale Kernel Machines</source><volume>8</volume></element-citation></ref><ref id="R81"><label>81</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lv</surname><given-names>J</given-names></name><etal/></person-group><article-title>Individual deviations from normative models of brain structure in a large crosssectional schizophrenia cohort</article-title><source>Molecular Psychiatry</source><year>2020</year><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.1038/s41380-020-00882-5</pub-id></element-citation></ref><ref id="R82"><label>82</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Snelson</surname><given-names>E</given-names></name><name><surname>Ghahramani</surname><given-names>Z</given-names></name><name><surname>Rasmussen</surname><given-names>C</given-names></name></person-group><chapter-title>Warped Gaussian Processes</chapter-title><source>Advances in Neural Information Processing Systems</source><publisher-name>MIT Press</publisher-name><year>2004</year><volume>16</volume></element-citation></ref><ref id="R83"><label>83</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hensman</surname><given-names>J</given-names></name><name><surname>Fusi</surname><given-names>N</given-names></name><name><surname>Lawrence</surname><given-names>ND</given-names></name></person-group><article-title>Gaussian Processes for Big Data</article-title><source>arXiv:1309.6835 [cs, stat]</source><year>2013</year></element-citation></ref><ref id="R84"><label>84</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bethlehem</surname><given-names>RaI</given-names></name><etal/></person-group><article-title>Brain charts for the human lifespan</article-title><source>bioRxiv</source><year>2021</year><elocation-id>2021.06.08.447489</elocation-id><pub-id pub-id-type="doi">10.1101/2021.06.08.447489</pub-id></element-citation></ref><ref id="R85"><label>85</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rutherford</surname><given-names>S</given-names></name><etal/></person-group><source>Charting Brain Growth and Aging at High Spatial Precision</source><year>2021</year><elocation-id>2021.08.08.455487</elocation-id><pub-id pub-id-type="doi">10.1101/2021.08.08.455487</pub-id><comment><ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2021.08.08.455487v2">https://www.biorxiv.org/content/10.1101/2021.08.08.455487v2</ext-link></comment></element-citation></ref><ref id="R86"><label>86</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rutherford</surname><given-names>S</given-names></name><etal/></person-group><source>The Normative Modeling Framework for Computational Psychiatry</source><publisher-name>Zenodo</publisher-name><year>2021</year><pub-id pub-id-type="doi">10.5281/zenodo.5592153</pub-id></element-citation></ref></ref-list><ref-list><title>Related links</title><p>Key reference(s) using this protocol</p><ref id="R87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marquand</surname><given-names>AF</given-names></name><name><surname>Kia</surname><given-names>SM</given-names></name><name><surname>Zabihi</surname><given-names>M</given-names></name><etal/></person-group><article-title>Conceptualizing mental disorders as deviations from normative functioning</article-title><source>Mol Psychiatry</source><year>2019</year><volume>24</volume><fpage>1415</fpage><lpage>1424</lpage><pub-id pub-id-type="doi">10.1038/s41380-019-0441-1</pub-id></element-citation></ref><ref id="R88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zabihi</surname><given-names>M</given-names></name><name><surname>Floris</surname><given-names>DL</given-names></name><name><surname>Kia</surname><given-names>SM</given-names></name><etal/></person-group><article-title>Fractionating autism based on neuroanatomical normative modeling</article-title><source>Transl Psychiatry</source><year>2020</year><volume>10</volume><fpage>384</fpage><pub-id pub-id-type="doi">10.1038/s41398-020-01057-0</pub-id></element-citation></ref><ref id="R89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolfers</surname><given-names>T</given-names></name><name><surname>Doan</surname><given-names>NT</given-names></name><name><surname>Kaufmann</surname><given-names>T</given-names></name><etal/></person-group><article-title>Mapping the Heterogeneous Phenotype of Schizophrenia and Bipolar Disorder Using Normative Models</article-title><source>JAMA Psychiatry</source><year>2018</year><volume>75</volume><issue>11</issue><fpage>1146</fpage><lpage>1155</lpage><pub-id pub-id-type="doi">10.1001/jamapsychiatry.2018.2467</pub-id></element-citation></ref></ref-list></back><floats-group><boxed-text id="BX1" position="float" orientation="portrait"><caption><title>Editorial summary</title></caption><p>This protocol guides the user through normative modeling analysis using the Predictive Clinical Neuroscience toolkit (PCNtoolkit), enabling individual differences to be mapped at the level of a single subject or observation in relation to a reference model.</p></boxed-text><fig id="F1" position="float"><label>Figure 1</label><caption><title>Conceptual Overview of Normative Modeling.</title><p><bold>A)</bold> Classical example of normative modeling: the use of height and weight growth charting in pediatrics. <bold>B)</bold> Case-control models (left) theoretically make assumptions that there is a boundary that can separate groups and that there is within-group homogeneity. In reality (right), there is nested variation across controls and patient groups and within-group heterogeneity, resulting in unclear separation boundaries. Normative modeling is well equipped to handle this reality. <bold>C)</bold> An example application of normative modeling in computational psychiatry using neuroimaging data. Mean cortical thickness (y-axis) is predicted from age (x-axis) using a training set consisting of multi-site structural MRI from neurotypical controls and a test set consisting of neurotypical controls and patient groups. Every dot indicates the deviation score for a single individual from normal development. <bold>D)</bold> Regression model equation and design matrix setup for the model shown in panel C.</p></caption><graphic xlink:href="EMS145667-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Practical Overview of Normative Modeling Framework.</title><p>The workflow consists of four stages: data selection, data preparation, algorithm &amp; modeling, and evaluation &amp; interpretation, which are visualized by the numbered shaded blue boxes. The steps involved at each of these stages are summarized in the box below and highlighted in the images above.</p></caption><graphic xlink:href="EMS145667-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Overview of Resources for Running a Normative Modeling Analysis.</title><p><bold>A)</bold> Detailed documentation, including installation instructions, input/output descriptions of all classes and functions implemented in the python package, tutorials for all algorithms, frequently asked questions, a glossary explaining acronyms and other jargon, references to existing normative modeling literature, and a citation guide, is available <underline><styled-content style="color:#087adc">online</styled-content></underline>. <bold>B)</bold> Example of the documentation showing the required input, expected output of the main function used in the pcntoolkit software, the estimate function. <bold>C)</bold> All of the code and data used in this protocol is available to run in the cloud via Google Colab. Additional tutorials (shown under the tutorials header in panel A) are also available to run in Google Colab.</p></caption><graphic xlink:href="EMS145667-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Visualization of Normative Model Evaluation Metrics.</title><p><bold>A)</bold> A ridge plot showing the distribution across all brain regions of the standardized mean squared error (SMSE), an evaluation metric that represents accuracy, visualized for each site in the test set. Visualizing for each test site can help identify if there are sites where the model is performing poorly. Ideally, the distribution will be Gaussian and should look similar across all sites. Small shifts in the mean across sites is to be expected and is acceptable. <bold>B)</bold> Explained variance is shown for cortical thickness of every brain region in the Destrieux parcellation) and volume of subcortical regions. Visualizing the evaluation metrics in brain space helps to identify patterns and see the big picture. <bold>C)</bold> The number of extreme deviations (both positive and negative) are counted for each individual in the test set, group ID is used to plot the distribution of the extreme deviation count for each group. A statistical test can be done on the count to determine if there is a significant difference between groups. Testing group differences in the count of deviations does not require there to be spatial overlap of the deviations within the group (i.e., this test can account for within-group heterogeneity of deviations). <bold>D)</bold> The normative trajectory for an example brain region (lateral ventricle) showing age (x-axis) versus the predicted volume (y-axis). The centiles of variation are shown by the lines and shaded confidence intervals. Each subject in the test set is plotted as a single point. <bold>E-F)</bold> Extreme deviations, separated into positive (<bold>E</bold>) and negative (<bold>F</bold>), are summarized for each group. For each brain region, the number of subjects with an extreme deviation in that region is counted, then divided by the group sample size, to show the percent of subjects with an extreme deviation. These visualizations demonstrate the benefit of normative modeling as there is within group heterogeneity that other methods (i.e., case-control group difference testing) are not equipped to handle. Abbreviations: HC = Controls, MDD=Major Depressive Disorder, SZ=Schizophrenia, SAD=Social Anxiety Disorder, EP=Early Psychosis.</p></caption><graphic xlink:href="EMS145667-f004"/></fig><table-wrap id="T1" position="float" orientation="portrait"><label>Table 1</label><caption><title>PCNtoolkit Normative Modeling Algorithm Overview<xref ref-type="table-fn" rid="TFN1">*</xref>.</title></caption><table frame="box" rules="all"><thead><tr><th align="left" valign="top">Algorithm</th><th align="left" valign="top">Implemented in PCNtoolkit?</th><th align="left" valign="top">Transfer to new sites?</th><th align="left" valign="top">Fast compute time with large sample sizes?</th><th align="left" valign="top">Model non-Gaussianity?</th><th align="left" valign="top">Federated learning framework?</th></tr></thead><tbody><tr><td align="left" valign="top">Gaussian Process Regression (GPR)<xref ref-type="table-fn" rid="TFN2">**</xref></td><td align="left" valign="top">yes</td><td align="left" valign="top">no</td><td align="left" valign="top">no</td><td align="left" valign="top">no</td><td align="left" valign="top">no</td></tr><tr><td align="left" valign="top">Hierarchical Bayesian Regression (HBR)</td><td align="left" valign="top">yes</td><td align="left" valign="top">yes</td><td align="left" valign="top">yes</td><td align="left" valign="top">yes</td><td align="left" valign="top">yes</td></tr><tr><td align="left" valign="top">Bayesian Linear Regression (BLR)</td><td align="left" valign="top">yes</td><td align="left" valign="top">yes</td><td align="left" valign="top">yes</td><td align="left" valign="top">yes</td><td align="left" valign="top">no</td></tr><tr><td align="left" valign="top">Generalized additive models of location, scale, and shape (GAMLSS)<xref ref-type="table-fn" rid="TFN3">***</xref></td><td align="left" valign="top">no</td><td align="left" valign="top">yes</td><td align="left" valign="top">yes</td><td align="left" valign="top">yes</td><td align="left" valign="top">no</td></tr></tbody></table><table-wrap-foot><fn id="TFN1"><label>*</label><p id="P86">Random feature approximation and neural processes algorithms are not well documented in the PCNtoolkit and do not have tutorials available, thus these algorithms are not included in the table and are only recommended for advanced users who can implement the code on their own.</p></fn><fn id="TFN2"><label>**</label><p id="P87">The vanilla GPR algorithm implemented in the PCNtoolkit cannot model non-Gaussianity and does not scale well to large datasets. However, this is a question of implementation, and there are versions of GPs algorithms that satisfy these criteria<sup><xref ref-type="bibr" rid="R82">82</xref>,<xref ref-type="bibr" rid="R83">83</xref></sup>.</p></fn><fn id="TFN3"><label>***</label><p id="P88">Implemented in R, see this GitHub <underline><styled-content style="color:#087adc">repository</styled-content></underline>.</p></fn></table-wrap-foot></table-wrap><table-wrap id="T2" position="float" orientation="portrait"><label>Table 2</label><caption><title>Normative Model Metrics.</title><p>The <bold>‘</bold>Individual or summary?’ column refers to whether there is a value for every subject or if the metric is summarized across all subjects. For summary metrics, there is one value per brain region (model), and for individual metrics there are <monospace>n_subjects x n_brain_regions</monospace> values.</p></caption><table frame="box" rules="all"><thead><tr><th align="left" valign="top">Variable name</th><th align="center" valign="top">Full name</th><th align="center" valign="top">Definition</th><th align="center" valign="top">Interpretation</th><th align="center" valign="top">Individual or summary?</th></tr></thead><tbody><tr><td align="left" valign="top"><italic>y</italic></td><td align="left" valign="top">True data</td><td align="left" valign="top" rowspan="2" style="background-color:#d9d9d9"/><td align="left" valign="top" rowspan="2" style="background-color:#d9d9d9"/><td align="left" valign="top">individual</td></tr><tr><td align="left" valign="top"><inline-formula><mml:math id="M1"><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>d</mml:mi></mml:msub></mml:math></inline-formula></td><td align="left" valign="top">Predictive mean</td><td align="left" valign="top">individual</td></tr><tr><td align="left" valign="top"><inline-formula><mml:math id="M2"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula></td><td align="left" valign="top">Predictive noise variance</td><td align="left" valign="top">Represents uncertainty in the data.</td><td align="left" valign="top" style="background-color:#d9d9d9"/><td align="left" valign="top">individual</td></tr><tr><td align="left" valign="top"><inline-formula><mml:math id="M3"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mo>*</mml:mo><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></td><td align="left" valign="top">Predictive modeling variance</td><td align="left" valign="top">Represents uncertainty in model estimation.</td><td align="left" valign="top" style="background-color:#d9d9d9"/><td align="left" valign="top">individual</td></tr><tr><td align="left" valign="top" rowspan="2">Z</td><td align="left" valign="top" rowspan="2">Deviation score</td><td align="left" valign="top" rowspan="2">A statistical estimate (Z-score) of how much each subject deviates from the normative range.</td><td align="left" valign="top">Z &gt; 2 ‘extreme’ positive deviation</td><td align="left" valign="top" rowspan="2">individual</td></tr><tr style="border-top: hidden"><td align="left" valign="top">Z &lt; -2 ‘extreme’ negative deviation</td></tr><tr><td align="left" valign="top">Rho</td><td align="left" valign="top">Pearson correlation between true and predicted responses</td><td align="left" valign="top">A measure of linear correlation between true and predicted responses. It is the ratio between the covariance of true and predicted values and the product of their standard deviations.</td><td align="left" valign="top">Ranges between -1 and 1. Closer to 1 = better model performance.</td><td align="left" valign="top">summary</td></tr><tr><td align="left" valign="top">pRho</td><td align="left" valign="top">Parametric p-value for the Pearson correlation</td><td align="left" valign="top">The probability of obtaining test results at least as extreme as the results actually observed, under the assumption that the null hypothesis is true.</td><td align="left" valign="top">Ranges between 0 and 1. Closer to 0 = more statistically significant.</td><td align="left" valign="top">summary</td></tr><tr><td align="left" valign="top">SMSE</td><td align="left" valign="top">Standardized mean squared error</td><td align="left" valign="top">The square root of the squared residual between the mean prediction and the target at each test point, averaged over samples in the test set, normalized by the variance of the targets in the test set.</td><td align="left" valign="top">Closer to 0 = better (more accurate) model performance.</td><td align="left" valign="top">summary</td></tr><tr><td align="left" valign="top">EV</td><td align="left" valign="top">Explained variance</td><td align="left" valign="top">The proportion to which the predicted value accounts for the variance of the true value. Sensitive to the mean fit, dependent on flexibility of the model.</td><td align="left" valign="top">Closer to 1 = better model performance.</td><td align="left" valign="top">summary</td></tr><tr><td align="left" valign="top">MSLL</td><td align="left" valign="top">Mean standardized log-loss</td><td align="left" valign="top">The log loss minus the loss that would be obtained under the trivial model which predicts using a Gaussian with the mean and variance of the training data, averaged over the test set. Sensitive to the variance, penalizes the flexibility of the model.</td><td align="left" valign="top">More negative = better model performance.</td><td align="left" valign="top">summary</td></tr></tbody></table></table-wrap></floats-group></article>