<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS206468</article-id><article-id pub-id-type="doi">10.1101/2025.06.12.659336</article-id><article-id pub-id-type="archive">PPR1035728</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">1</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Credit Assignment via Behavioral Timescale Synaptic Plasticity: Theoretical Frameworks</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Cone</surname><given-names>Ian</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><contrib contrib-type="author"><name><surname>Clopath</surname><given-names>Claudia</given-names></name><xref ref-type="aff" rid="A2">2</xref><xref ref-type="fn" rid="FN1">#</xref></contrib><contrib contrib-type="author"><name><surname>Costa</surname><given-names>Rui Ponte</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="fn" rid="FN1">#</xref></contrib></contrib-group><aff id="A1"><label>1</label>Centre for Neural Circuits and Behaviour, Department of Physiology, Anatomy and Genetics, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>University of Oxford</institution></institution-wrap>, <city>Oxford</city>, <country country="GB">United Kingdom</country></aff><aff id="A2"><label>2</label>Department of Bioengineering, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/041kmwe10</institution-id><institution>Imperial College London</institution></institution-wrap>, <city>London</city>, <country country="GB">United Kingdom</country></aff><author-notes><corresp id="CR1">
<label>*</label><email>ian.cone@dpag.ox.ac.uk</email></corresp><fn id="FN1"><label>#</label><p id="P1">co-senior</p></fn></author-notes><pub-date pub-type="nihms-submitted"><day>15</day><month>06</month><year>2025</year></pub-date><pub-date pub-type="preprint"><day>13</day><month>06</month><year>2025</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P2">Behavioral Timescale Synaptic Plasticity (BTSP) is a form of synaptic plasticity in which dendritic Ca<sup>2+</sup> plateau potentials in hippocampal pyramidal neurons drive rapid place field formation. Unlike traditional learning rules, BTSP learns correlations on the timescales of seconds and rapidly changes single-unit activity in only a few trials. To explore how BTSP-like learning can be integrated into network models, we propose a generalized BTSP rule (gBTSP), which we apply to unsupervised and supervised learning tasks, in both feedforward and recurrent networks. Unsupervised gBTSP mirrors classical frameworks of competitive learning, learning place field maps (in the feed-forward case), and attractive memory networks (in the recurrent case). For supervised learning, we show that plateau events can reduce task error, enabling gBTSP to solve tasks such as trajectory matching and delayed non-match-to-sample. However, we find that credit assignment via gBTSP becomes harder to achieve with increased network depth or CA3-like recurrence. This suggests that additional features may be needed to support BTSP-mediated few-shot learning of complex tasks in the hippocampus.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P3">Recent experimental observations have revealed the existence of a novel plasticity phenomenon occurring in hippocampus, termed “Behavioral Timescale Synaptic Plasticity” (BTSP). BTSP occurs in hippocampal pyramidal cells following strong, dendritic “plateau potentials”, and has been observed to be a “primary” driver of field formation (such as place fields) in both hippocampal areas CA1<sup><xref ref-type="bibr" rid="R1">1</xref>–<xref ref-type="bibr" rid="R3">3</xref></sup> and CA3<sup><xref ref-type="bibr" rid="R4">4</xref></sup>. Unlike other established learning rules, BTSP operates over a wide temporal range, potentiating and depressing inputs which were active seconds before or after a postsynaptic “plateau” event. A similarly distinctive feature of BTSP is its rapid learning speed - once triggered, it can form long-lasting hippocampal fields in a one-shot or few-shot manner.</p><p id="P4">While the discovery of BTSP has advanced our understanding of single-cell learning in hippocampus, we are still lacking a comprehensive theoretical framework to understand how BTSP may contribute to network level plasticity. For example, experiments have shown that inputs from entorhinal cortex layer 3 (EC3) are necessary to trigger plateau potentials in CA1, and as such, have been hypothesized to act as a sort of “target signal”<sup><xref ref-type="bibr" rid="R5">5</xref></sup> which guides plateau generation. But what sort of “targets” should EC3 produce? That is, “when” and “where” should BTSP-triggering plateau events occur for hippocampal learning to be successful? Or, from a more general perspective, “when” and “where” should BTSP events occur to optimize a network’s function?</p><p id="P5">Furthermore, how can we reconcile the hallmarks of BTSP (wide temporal kernel and fewshot learning) with traditional learning frameworks (particularly supervised ones)<sup><xref ref-type="bibr" rid="R6">6</xref>–<xref ref-type="bibr" rid="R13">13</xref></sup>, for which small learning rates and temporally precise credit assignment are generally required for convergence? Does the presence of BTSP put constraints on the possible tasks and the neural architectures (i.e. circuit designs) which can learn them?</p><p id="P6">Previous theoretical work on BTSP has described in detail its single-cell properties<sup><xref ref-type="bibr" rid="R1">1</xref>,<xref ref-type="bibr" rid="R2">2</xref>,<xref ref-type="bibr" rid="R14">14</xref></sup> and consequences in memory networks<sup><xref ref-type="bibr" rid="R4">4</xref>,<xref ref-type="bibr" rid="R15">15</xref>,<xref ref-type="bibr" rid="R16">16</xref></sup>. However, such work has thus far have been forced to assume specific, hand-tuned plateau induction protocols. In contrast, this work aims to formulate BTSP in such a way that we can describe where and when post-synaptic plateaus should occur such that the network learns a given unsupervised or supervised objective.</p><p id="P7">Towards this goal, we formulate a generalized BTSP rule which can a) match existing experimental data, and b) give us analytical, differentiable expressions for how the learning performance (i.e. the loss) depends plateau events. We take this rule and demonstrate its ability to learn in both feed-forward and recurrent networks, on both supervised and unsupervised tasks. Since we derive an analytical expression for plateau “function”, we can predict the occurrence of plateau events, given that we know the weights, inputs and task. Further, by applying constraints on our expression for plateau events, we can approximate the sparse nature of these events in vivo. However, we show that the rapid, one-shot formation of single fields associated with BTSP runs into critical stability issues when applied in deep/recurrent networks, because of exploding and vanishing mathematical terms. We finish by discussing how potential architectures and tasks may be able to avoid this issue, and what the implications are for our understanding of hippocampal networks.</p><p id="P8">Altogether, this work provides a unified, analytical framework for understanding BTSP in relation to network-level learning, establishing a theoretical foundation through which we can explore how this unique form of plasticity can be integrated into hippocampus-mediated learning processes.</p></sec><sec id="S2" sec-type="results"><title>Results</title><sec id="S3"><title>Generalized BTSP Rule Recapitulates Experimentally Observed Plasticity Kernels</title><p id="P9">We begin by building a generalized learning rule, based on experimental observations of BTSP. For clarity, we will hereafter refer to our rule as “gBTSP” (generalized BTSP, <xref ref-type="fig" rid="F1">Figure 1a-c</xref>) and refer to the experimental phenomena as simply “BTSP”. To start, consider the simple case of a single postsynaptic neuron which triggers an instantaneous plateau event, and a single presynaptic neuron which fires a spike (<xref ref-type="fig" rid="F1">Figure 1a</xref>). We assume the postsynaptic plateau updates weight <italic>W</italic> via some function, <italic>W<sub>kernel</sub></italic>, which depends on the timing of the presynaptic spike relative to the plateau, i.e. Δ<italic>W</italic> ∝ <italic>W<sub>kernel</sub></italic>(<italic>t<sub>pre</sub></italic> – <italic>t<sub>plateau</sub></italic>).</p><p id="P10">Owing to the wide temporal window in which plateau potentials have been observed to potentiate and depress inputs<sup><xref ref-type="bibr" rid="R1">1</xref>–<xref ref-type="bibr" rid="R3">3</xref></sup>, we assume that <italic>W<sub>kernel</sub></italic> operates on a timescale much larger than that of mere pre-post activity correlations. Specifically, we choose a <italic>W<sub>kernel</sub></italic> such that the application of our learning rule matches observed plasticity following application of a single plateau and bursting inputs in vitro (<xref ref-type="fig" rid="F1">Figure 1d</xref>)<sup><xref ref-type="bibr" rid="R2">2</xref></sup>. Next, we relax our previous assumption that there is a single presynaptic neuron which fires a single spike, instead considering continuous presynaptic activity (of each unit <italic>j</italic>), <italic>x<sub>j</sub></italic>(<italic>t</italic>) (<xref ref-type="fig" rid="F1">Figure 1b</xref>). Now, the change in weights following a single plateau is a function of both the weight kernel and the presynaptic activity, i.e. Δ<italic>W<sub>j</sub></italic> ∝ <italic>f</italic>(<italic>W<sub>kernel</sub></italic>(<italic>t</italic> – <italic>t<sub>plateau</sub></italic>), <italic>x<sub>j</sub></italic>(<italic>t</italic>)). See <xref ref-type="sec" rid="S10">Methods</xref> for full derivation and expression.</p><p id="P11">To match experimental data showing that the amplitude of the formed field depends on the initial membrane voltage of the postsynaptic cell<sup><xref ref-type="bibr" rid="R1">1</xref></sup>, we also add in a dependence on the synaptic strength prior to the plateau event (see <xref ref-type="sec" rid="S10">Methods</xref>). Following these additions to our rule, we can now use the same <italic>W<sub>kernel</sub></italic> from <xref ref-type="fig" rid="F1">Figure 1d</xref> and show that for place field-like inputs <italic>x<sub>j</sub></italic>(<italic>t</italic>), our rule recapitulates the observed plasticity kernels measure from single plateaus in vivo (<xref ref-type="fig" rid="F1">Figure 1e</xref>)<sup><xref ref-type="bibr" rid="R1">1</xref></sup>. With this framework, the previously observed asymmetric offset of observed plasticity (<xref ref-type="fig" rid="F1">Figure 1e</xref>)<sup><xref ref-type="bibr" rid="R1">1</xref></sup> is a direct consequence of the shape of <italic>W<sub>kernel</sub></italic> <xref ref-type="fig" rid="F1">Figure 1d</xref> (see <xref ref-type="sec" rid="S10">Methods</xref>).</p><p id="P12">Finally, we want to consider the case for which there are multiple postsynaptic neurons, each of which may have a plateau (or potentially multiple). So, we introduce <italic>P<sub>i</sub></italic>(<italic>t</italic>), a function representing the post-synaptic plateau potential at time <italic>t</italic> for neuron <italic>i</italic>. Critically, this post-synaptic plateau <italic>P<sub>i</sub></italic>(<italic>t</italic>) is used only for learning and is distinct from the post-synaptic network activity, <italic>y<sub>i</sub></italic>(<italic>t</italic>). Now, the change in the weights will depend on the weight kernel, the presynaptic activity, synaptic strength, and post-synaptic plateaus, i.e. Δ<italic>W<sub>ij</sub></italic> ∝ <italic>f</italic>(<italic>W<sub>kernel</sub></italic>(<italic>t</italic> – <italic>t<sub>plateau</sub></italic>), <italic>x<sub>j</sub></italic>(<italic>t</italic>), <italic>W<sub>ij</sub>, P<sub>i</sub></italic>(<italic>t</italic>)) (<xref ref-type="fig" rid="F1">Figure 1c</xref>).</p><p id="P13">The full form of this dependence is given by the following equation, which we will hereafter refer to as “generalized” BTSP, since it is derived from various steps of generalization from our initial fundamental assumption (Δ<italic>W</italic> ∝ <italic>W<sub>kernel</sub></italic>(<italic>t<sub>pre</sub></italic> – <italic>t<sub>plateau</sub></italic>)): <disp-formula id="FD1"><label>(1)</label><mml:math id="M1"><mml:mrow><mml:mo>Δ</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mi>T</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mo>Δ</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mo>Δ</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mtext>kernel </mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math></disp-formula></p><p id="P14">See <xref ref-type="sec" rid="S10">Methods</xref> for full details and derivation. From this gBTSP equation, we can now take any set of inputs, choose any kernel, apply any arbitrary distribution of plateaus, and obtain a resulting change in the network’s synaptic weights. Note that gBTSP (as with BTSP) does not depend on postsynaptic activity directly, distinguishing it from standard Hebbian and Hebbian-like (e.g. STDP) learning rules.</p><p id="P15">Given this mathematical description of our learning rule, we now seek to gain a deeper understanding of its function. How does it operate inside of a network? What types of learning tasks is it well or poorly suited for? We will now investigate the properties of gBTSP in both unsupervised and supervised contexts, for both feed-forward and recurrent networks.</p></sec><sec id="S4"><title>Unsupervised gBTSP leads to competitive learning and one-shot field formation in feed-forward networks</title><p id="P16">To understand how gBTSP operates in the simplest case, we first consider gBTSP as an unsupervised rule. Returning to the simple case where we have a single plateau (and a short temporal kernel), <xref ref-type="disp-formula" rid="FD1">Equation 1</xref> simplifies greatly (see <xref ref-type="sec" rid="S10">Methods</xref>), giving us an expression for plasticity of the form Δ<italic>W<sub>j</sub></italic> = <italic>x<sub>j</sub></italic>(<italic>t<sub>plateau</sub></italic>) - <italic>λW<sub>j</sub></italic>. So, in this approximation, upon each plateau event, the weights would move towards a fixed point <inline-formula><mml:math id="M2"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>λ</mml:mi></mml:mfrac><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Such a formulation is reminiscent of classical conceptions of “competitive learning”<sup><xref ref-type="bibr" rid="R17">17</xref>–<xref ref-type="bibr" rid="R20">20</xref></sup>, whereby postsynaptic neurons <italic>y<sub>i</sub></italic> “compete” with each other to encode a pattern <inline-formula><mml:math id="M3"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mi>j</mml:mi><mml:mi>p</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> in its weights <italic>W<sub>ij</sub></italic> (where <italic>p</italic> is the index of a particular pattern, and <italic>j</italic> indexes over the pattern’s components). The decay term (–<italic>λW<sub>j</sub></italic>) acts as heterosynaptic depression, promoting competition between units<sup><xref ref-type="bibr" rid="R21">21</xref></sup>.</p><p id="P17">Often, competitive learning is concerned with encoding <italic>multiple</italic> input patterns (or indeed, a whole distribution of possible input patterns), using various forms of “competition” (via some rule) to assign different postsynaptic neurons to represent distinct parts of the input space<sup><xref ref-type="bibr" rid="R17">17</xref>–<xref ref-type="bibr" rid="R20">20</xref></sup> This algorithm has appealing aspects in the context of BTSP (and the hippocampus) – when presented with an input distribution, competitive learning can quickly (few-shot for a single unit) assign a unit to represent a part of that input space. Over the course of sampling the input distribution, a3 population-level representation slowly emerges. We might consider the hippocampus to be solving an analogous problem, e.g. forming a latent representation which tiles a given input space, taking care to have both a) coverage over the whole space, and b) well-separated or orthogonal latents which do not interfere with each other.</p><p id="P18">In order to adapt gBTSP for competitive learning, we must select a criterion for triggering plasticity events. Commonly, competitive learning methods only apply the weight update to the “best matching unit” (e.g. one which has a small Euclidean distance between <inline-formula><mml:math id="M4"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mi>j</mml:mi><mml:mi>p</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> and <italic>W<sub>j</sub></italic>)<sup><xref ref-type="bibr" rid="R19">19</xref>,<xref ref-type="bibr" rid="R22">22</xref></sup>. If we followed that logic, we would only trigger plateau events for these “best matching units”. However, this does not easily map onto learning in continuous time, particularly when we consider our temporally extended weight kernel. Instead, we choose an even simpler criterion, whereby a plateau event occurs in random neuron if the sum of total postsynaptic network activity ∑<italic><sub>i</sub> y<sub>i</sub></italic>(<italic>t</italic>) falls below some threshold <italic>θ</italic> (see <xref ref-type="sec" rid="S10">Methods</xref>). In other words, if ∑<italic><sub>i</sub> y<sub>i</sub></italic>(<italic>t</italic>) &lt; <italic>θ</italic>, we consider the currently arriving input <bold>x(t)</bold> to be poorly represented in the output layer <bold>y(t)</bold>. To amend this, the network fires a plateau, forming a new field (or translocating an existing one) that is tuned to <bold>x(t)</bold>. To test this simple algorithm for plateau assignment, we imagine a network of CA1 neurons to be receiving noisy but spatially tuned input from CA3 neurons, as an agent traverses an environment (<xref ref-type="fig" rid="F2">Figure 2a</xref>). We consider both 1D (modelling an animal on a treadmill) and 2D (modelling an animal freely moving in a box) environments.</p><p id="P19">For the case of a 1D environment, our agent moves along a treadmill at a uniform velocity (<xref ref-type="fig" rid="F2">Figure 2b</xref>), receiving spatially tuned inputs (see <xref ref-type="sec" rid="S10">Methods</xref>), and applying a gBTSP plateau every time the low activity condition (∑<italic><sub>i</sub> y<sub>i</sub></italic>(<italic>t</italic>) &lt; <italic>θ</italic>) is met. After training, the population activity has evolved to span the space of the inputs, forming place fields which tile the length of the track (<xref ref-type="fig" rid="F2">Figure 2c</xref>). Following the evolution of a single neuron in the network reveals that plateaus can both form and translocate fields in a one-shot manner (<xref ref-type="fig" rid="F2">Figure 2d</xref>). The full, population level representation takes ~10 laps to mature, during which time there is a high likelihood of plateau events (as the network fills in “blank” spaces in the representation). The probability of plateau events scales inversely with the activity of the network, as we would reasonably expect from our criterion for triggering plateaus (<xref ref-type="fig" rid="F2">Figure 2e</xref>). For subsequent laps after the network has evolved a mature representation (around lap 10), noise can still cause our plateau condition to be triggered. This can cause the translocation of existing fields (<xref ref-type="fig" rid="F2">Figure 2d</xref>), also opening representational gaps that were previously filled. This effect leads to representational drift in unsorted representations, whereby the cosine similarity between the unsorted representation of the current lap and that of a reference lap (lap 10) increases as a function of experience (<xref ref-type="fig" rid="F2">Figure 2f, blue</xref>), as has been reported experimentally<sup><xref ref-type="bibr" rid="R23">23</xref>,<xref ref-type="bibr" rid="R24">24</xref></sup>. However, this does not mean the content of the representation is fading – if we instead calculate the cosine similarity between sorted representation of the current lap and the sorted representation of a reference lap (lap 10), this measure remains stable over experience (<xref ref-type="fig" rid="F2">Figure 2f, orange</xref>). This reveals that most of the representational drift occurring in the network is index-related, i.e. neurons may shift their tuning (or “label”) and “shuffle” where they occur in the sequence, but the internal, population-level sequential structure is maintained (<xref ref-type="fig" rid="F2">Figure 2c</xref>)<sup><xref ref-type="bibr" rid="R25">25</xref></sup>.</p><p id="P20">We can extend further to a 2D environment (<xref ref-type="fig" rid="F2">Figure 2g</xref>), where an agent takes a random walk inside a box, again receiving spatially tuned but noisy inputs (see <xref ref-type="sec" rid="S10">Methods</xref>). Unlike the case of the 1D treadmill, where each lap the animal encountered the exact same input, here, the animal’s random walk means that it will experience a unique sequence of inputs each trial. Over the course of training, individual cells develop characteristic 2D place fields which evenly tile the space. Place field emergence in single-cells is still one- to few-shot, even in the 2D case (<xref ref-type="fig" rid="F2">Figure 2h</xref>). We make the agent traverse the entire environment after training and find that the sum of network activity provides a map which covers the extent of the box environment (<xref ref-type="fig" rid="F2">Figure 2i</xref>).</p><p id="P21">In summary, we find that for unsupervised learning in feed-forward networks, our mathematical formulation of BTSP can be mapped onto the classical framework of competitive learning. By applying gBTSP in simulated environments, we find that our network acts as we would expect from a competitive learner, taking a high-dimensional input space and summarizing it with a discrete set of lower-dimensional latent states. If BTSP indeed follows a simple threshold principle for competition, our model would predict that plateau probability across a network should be inversely proportional to that network’s activity (<xref ref-type="fig" rid="F2">Figure 2e</xref>). Further, our model predicts that representational drift for a given learned neural trajectory is mostly a consequence of a “musical chairs-like” resorting, whereby transient and stochastic dips in total network activity in one location are likely to trigger a translocating plateau event, leading to a dip in network activity in the translocated field’s previous location (<xref ref-type="fig" rid="F2">Figure 2d-f</xref>).</p></sec><sec id="S5"><title>Unsupervised gBTSP can facilitate attractor learning in recurrent networks</title><p id="P22">Given that BTSP has been observed in CA3, driving plasticity in recurrent CA3→CA3 synapses<sup><xref ref-type="bibr" rid="R4">4</xref></sup>, we now consider how unsupervised gBTSP might be understood in the context of a recurrent network. A common model of CA3 is that of an attractor network<sup><xref ref-type="bibr" rid="R26">26</xref>–<xref ref-type="bibr" rid="R30">30</xref></sup>, where an “attractor” can be framed in the context of discrete memory states (e.g. a Hopfield model)<sup><xref ref-type="bibr" rid="R31">31</xref>,<xref ref-type="bibr" rid="R32">32</xref></sup>, or a continuous manifold<sup><xref ref-type="bibr" rid="R27">27</xref>,<xref ref-type="bibr" rid="R33">33</xref>–<xref ref-type="bibr" rid="R35">35</xref></sup>. Experimental results have demonstrated CA3’s ability to both pattern complete and tune its activity via velocity-dependent inputs<sup><xref ref-type="bibr" rid="R4">4</xref>,<xref ref-type="bibr" rid="R36">36</xref>,<xref ref-type="bibr" rid="R37">37</xref></sup>, hallmarks of a (recurrent) attractor network. As such, it is reasonable to suspect BTSP may be involved with the formation or maintenance of these networks. Indeed, previous theoretical work has shown that the BTSP rule’s characteristic kernel is well suited for optimal memory storage in discrete memory networks<sup><xref ref-type="bibr" rid="R4">4</xref></sup>, but it remains unclear if/how an unsupervised form of BTSP can give rise to attractors.</p><p id="P23">In order to simplify our problem, we will utilize a two-part architecture in our network, inspired by similar parametrizations of recurrent nets designed to learn or sustain attractors<sup><xref ref-type="bibr" rid="R38">38</xref>–<xref ref-type="bibr" rid="R41">41</xref></sup>. In short, we imagine there to be two distinct populations in CA3, with only one of the populations eligible to receive plateaus via gBTSP. This assumption is based on experimental results which have shown that the ability or propensity of pyramidal cells in CA3 to have complex bursting events (i.e. a plateau) is variable from cell to cell, and may depend on features such as topographic position and/or dendritic morphology<sup><xref ref-type="bibr" rid="R42">42</xref>,<xref ref-type="bibr" rid="R43">43</xref></sup>. Both of our populations (“visible” neurons <italic>u<sub>j</sub></italic>(<italic>t</italic>) and “seed” neurons <italic>s<sub>i</sub></italic>(<italic>t</italic>)) connect recurrently to each other, via “encoding” weights <bold>W<sup>e</sup></bold> and “decoding” weights <bold>W<sup>d</sup></bold>, with the visible neurons receiving external input <italic>o<sub>k</sub></italic>(<italic>t</italic>), and only the seed neurons are eligible for plateaus (<xref ref-type="fig" rid="F3">Figure 3a</xref>). The relative strength of recurrent/external input onto the visible neurons is governed by a gating function which depends on the norm of the external input (see <xref ref-type="sec" rid="S10">Methods</xref>): when external input is high, recurrent input is low, and vice versa. Owing to this gating, high external input effectively turns the network into a feed-forward one, and when input is removed, the network restores its recurrency. This dual nature of the network allows us to take advantage of recurrent computation in the low-input phase, while making use of unsupervised, feed-forward gBTSP in the high-input phase. For full details, see <xref ref-type="sec" rid="S10">Methods</xref>.</p><p id="P24">Since our aim is to learn attractor states (i.e. <bold>u(t)</bold> = <bold>u(t – 1)</bold> for no input), we would like our effective recurrence, <bold>W<sup>rec</sup> = W<sup>d</sup>W<sup>e</sup></bold> to be approximately to the identity matrix. To avoid trivial solutions, we make two choices. First, we set the seed population to be smaller (in number) than the visible population, forcing the network to compress and then decompress its representations (this is equivalent to making <bold>W<sup>rec</sup></bold> low-rank). Second, we apply the same competitive learning framework from the feed-forward case (∑<italic><sub>i</sub> s<sub>i</sub></italic>(<italic>t</italic>) &lt; <italic>θ</italic>) to learn the encoding weights, so that the seed neurons learn latent representations which tile the input space. The decoder weights are set to be the transpose of the encoder weights, which is sufficient since the learned encoding is well-separated (near orthogonal). Ideally, some biophysically plausible learning rule can govern the evolution of these decoder weights<sup><xref ref-type="bibr" rid="R44">44</xref></sup>, but for the purposes of this study, we use the transpose relationship as a simple approximation.</p><p id="P25">We simulate an agent running along a 1D treadmill, again receiving spatially selective inputs which are processed by our model CA3 network (<xref ref-type="fig" rid="F3">Figure 3a</xref>). The seed neurons are allowed to plateau, doing so under the same low-activity criteria as in the feed-forward case. During training, the agent runs along the track and external inputs are strong. Plateau events occur in response, guiding the evolution of the encoding weights (and thereby the decoder weights). Seed neurons form receptive fields to their visible neuron counterparts (<xref ref-type="fig" rid="F3">Figure 3b</xref>), similar to the formation of place receptive fields in the purely feedforward case (<xref ref-type="fig" rid="F2">Figure 2c</xref>). After just the first lap of training, the recurrent weights have formed a ring topology, with fixed point nodes (memories) at locations dictated by the plateau events (<xref ref-type="fig" rid="F3">Figure 3c</xref>). This topology is well explained by the first two principal components (<xref ref-type="supplementary-material" rid="SD1">Supplemental Figure 1</xref>). So long as external input continues, the network remains largely feed-forward, but upon removal of external inputs, the network is dominated by recurrency, and relaxes into one of its learned fixed points. If partial and intermittent inputs are given, the network can switch between these encoding (feed-forward) and recall (recurrent) modes repeatedly, recovering a new memory each time it samples its inputs (<xref ref-type="fig" rid="F3">Figure 3d</xref>).</p><p id="P26">Altogether, by using a low-rank formulation of our network recurrency, and gating plateau events to occur in a certain subpopulation of our network, we demonstrated that gBTSP can play a crucial role in the rapid formation of an attractor network. Such a role would be consistent with observations of BTSP in CA3<sup><xref ref-type="bibr" rid="R10">10</xref></sup>, a region often hypothesized to play the role of an attractor<sup><xref ref-type="bibr" rid="R26">26</xref>–<xref ref-type="bibr" rid="R30">30</xref></sup>. Future experimental and theoretical work can further illuminate the functional structure of CA3 and the role BTSP plays in forming and maintaining attractor states.</p></sec><sec id="S6"><title>Supervised gBTSP can support rapid task learning in feed-forward networks</title><p id="P27">While competitive learning provides an unsupervised framework by which we might understand the function of BTSP during novel, unguided exploration, it still leaves unanswered what role direct supervisory credit assignment might play. A popular hypothesis for BTSP posits that EC3 inputs to the distal dendrites act as supervisory “targets”, which in turn trigger plateau events so that the somatic activity can match this dendritic target<sup><xref ref-type="bibr" rid="R5">5</xref></sup>. However, it is not clear what these targets are, i.e. “when” and “where” should a plateau event occur? To rephrase the question in a more quantifiable way: if we define a given loss <inline-formula><mml:math id="M5"><mml:mi>ℒ</mml:mi></mml:math></inline-formula> as the mean squared error between the network output <italic>y<sub>i</sub></italic>(<italic>t</italic>) and some target <inline-formula><mml:math id="M6"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>ı</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, when and where should we trigger plateau events to minimize this loss? Equipped with our learning rule, we have the tools to answer this question. To this end, we set our expression for Δ<italic>W<sub>ij</sub></italic> from gBTSP (<xref ref-type="disp-formula" rid="FD1">Equation 1</xref>) to be equal to expressions for Δ<italic>W<sub>ij</sub></italic> from traditional supervised learning (in the simplest feed-forward case, the “delta rule”), and solve for <italic>P<sub>i</sub></italic>(<italic>t</italic>) (see <xref ref-type="sec" rid="S10">Methods</xref>). In the case of a simple feed-forward network, that expression is the following: <disp-formula id="FD2"><label>(2)</label><mml:math id="M7"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mi>∑</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mo>Δ</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mo>Δ</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p id="P28">Where is our <inline-formula><mml:math id="M8"><mml:mrow><mml:msub><mml:mi>ε</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>ı</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> task error. This expression gives the plateau function <italic>P<sub>i</sub></italic>(<italic>t</italic>) which will descend the loss gradient on a given trial. Equipped with this formula, we can now test the ability of gBTSP to learn in supervised learning contexts.</p><p id="P29">As a sanity check, we first consider the trivial case where our inputs are already spatially selective (such as those arriving from CA3)<sup><xref ref-type="bibr" rid="R1">1</xref>,<xref ref-type="bibr" rid="R14">14</xref></sup> and our output represents a single CA1 pyramidal cell subject to gBTSP (<xref ref-type="fig" rid="F4">Figure 4a</xref>). We choose a target function <inline-formula><mml:math id="M9"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> that is a putative place field, modeled as a Gaussian bump centered at a specific location in the environment (see <xref ref-type="sec" rid="S10">Methods</xref>). We find that the network can match this target through plateau-driven learning (<xref ref-type="fig" rid="F4">Figure 4b</xref>), demonstrating the fundamental capability of gBTSP to adapt network weights toward a desired output function (<xref ref-type="supplementary-material" rid="SD1">Supplemental Figure 2</xref>). The plateau function which solves the task is, as expected, centered at the location of our target function, and is most significant within the first 3-5 trials. The field itself also rapidly emerges on this same timescale (<xref ref-type="fig" rid="F4">Figure 4c</xref>), in agreement with experimental results where place fields were formed via the artificial induction of plateaus a) at the location of the desired place field, and b) over only a few (&lt;10) trials<sup><xref ref-type="bibr" rid="R1">1</xref>–<xref ref-type="bibr" rid="R3">3</xref></sup>.</p><p id="P30">Next, we test our ability to train the network on a more complicated task, in a network with a single hidden layer which is subject to gBTSP. In this task, we model an agent learning to match its location in a 2D arena to some target trajectory in that arena (indicated, say, by targeted illumination). One can consider this task as a navigation-based analogue to smooth pursuit or continuous reaching tasks. Rather than merely generating static spatial patterns, the network now must take a dynamic input <italic>x</italic>(<italic>t</italic>) and learn to generate a dynamic 2D position output <italic>y</italic>(<italic>t</italic>) (see <xref ref-type="sec" rid="S10">Methods</xref>, <xref ref-type="fig" rid="F4">Figure 4d</xref>). After the first 10 trials, the agent has learned to track the target trajectory (<xref ref-type="fig" rid="F4">Figure 4e</xref>). Unlike the previous example, where the plateau location was obvious by design, here it is unclear a priori when and where plateaus should occur in the hidden layer to solve the task. We find that a more complex pattern emerges for the plateau function in a sample neuron, and there is no longer a simple correlation between the network target and the shape of its plateaus (<xref ref-type="fig" rid="F4">Figure 4f</xref>). This is because our expression for the plateau function (<xref ref-type="disp-formula" rid="FD2">Equation 2</xref>) will depend on the backpropagated error (see <xref ref-type="sec" rid="S10">Methods</xref>) in networks with more than one layer. Finally, our model predicts that, in a supervised framework, the probability of plateau events in the full population should be inversely correlated with task performance (or positively correlated with task error), decreasing over the course of task learning (<xref ref-type="fig" rid="F4">Figure 4g</xref>).</p><p id="P31">Together, these results demonstrate that we can use gBTSP to descend the gradient of a supervised loss. In other words, the algorithm “distributes” plateau events to certain neurons at certain times in order to optimize overall network performance. If EC3 does indeed dictate plateau induction via supervised “targets”, as has been suggested<sup><xref ref-type="bibr" rid="R5">5</xref></sup>, then our framework provides a computational tool to understand and potentially infer the content of these signals. One testable prediction our supervised framework makes is that plateau probability should rise and fall with the inverse of task performance (<xref ref-type="fig" rid="F4">Figure 4g</xref>).</p></sec><sec id="S7"><title>Supervised gBTSP in recurrent networks fails to support rapid, one-shot learning</title><p id="P32">Finally, we wish to examine the feasibility of our rule in a fully recurrent network (to mimic CA3), learning a supervised task which requires maintenance of an internal memory (via recurrency). Our network consists of hidden units with activation <italic>h<sub>j</sub></italic>(<italic>t</italic>), recurrently connected via weights <inline-formula><mml:math id="M10"><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>, and projected to output <italic>y</italic>(<italic>t</italic>) via weights <inline-formula><mml:math id="M11"><mml:msubsup><mml:mi>W</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> (<xref ref-type="fig" rid="F5">Figure 5a</xref>). Internal weights <inline-formula><mml:math id="M12"><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> are trained indirectly through plateau induction, which is dictated by a recurrent update rule, that we derive by comparing our gBTSP weight update to that of backpropagation through time (BPTT) (see <xref ref-type="sec" rid="S10">Methods</xref>).</p><p id="P33">We illustrate the behavior of the model using a standard delayed-non-match-to-sample (DNMS) task, where our simulated agent must distinguish between sequential pairs of odors, and only “lick” in responses to non-matching pairs (AB, BA), refraining from licking following matching pairs (AA, BB) (<xref ref-type="fig" rid="F5">Figure 5a</xref>). We choose this task because it requires the network to maintain a memory of the first odor’s identity (by leveraging recurrent learning). Moreover, previous experimental work has shown that animals trained on the same task developed two distinct hippocampal sequences of activity which encoded the identity of the first odor<sup><xref ref-type="bibr" rid="R45">45</xref></sup>.</p><p id="P34">To avoid instabilities during training, we combine our update with an adaptive optimizer (ADAM) before updating the weights of the network (see <xref ref-type="sec" rid="S10">Methods</xref>)<sup><xref ref-type="bibr" rid="R46">46</xref></sup>. We find that gBTSP can learn the target function, choosing to “lick” when the two samples are non-matching, and forgoing licking when the two samples match (<xref ref-type="fig" rid="F5">Figure 5b</xref>). However, unlike the simpler tasks we have thus far described, training a recurrent network on the DNMS task takes many thousands of trials (<xref ref-type="fig" rid="F5">Figure 5c</xref>). In order to solve the task, the network develops distinct internal representations for the cases when Odor 1 = A, and when Odor 1 = B (<xref ref-type="fig" rid="F5">Figure 5d</xref>). These representations are well explained by their first three principal components, with Odor 1 = A trials and Odor 2 = B trials making distinct trajectories in this subspace (<xref ref-type="fig" rid="F5">Figure 5e</xref>, <xref ref-type="supplementary-material" rid="SD1">Supplemental Figure 3</xref>). These distinct representations act as a memory trace of the first odor’s identity, thereby allowing the network to judge “match” vs. “no-match” upon presentation of the second odor. These representations resemble neural sequences observed in experimental studies<sup><xref ref-type="bibr" rid="R45">45</xref></sup>, but as in previous theoretical work<sup><xref ref-type="bibr" rid="R47">47</xref></sup>, we found that adding a ramping component to the task target best recovered this sequential activity (see <xref ref-type="sec" rid="S10">Methods</xref>). The plateaus in the network which facilitate learning were constrained to be stochastic and sparse, with only 10% of neurons allowed to plateau on a given trial, and only events which crossed an absolute magnitude threshold contributing to learning (<xref ref-type="fig" rid="F5">Figure 5f</xref>). Though these constraints may result in single trial samples of <italic>P</italic>(<italic>t</italic>) which share the sparse nature of plateaus observed in vivo<sup><xref ref-type="bibr" rid="R5">5</xref>,<xref ref-type="bibr" rid="R48">48</xref></sup>, when we examine the evolution of single cell fields, we see that they develop very slowly, taking thousands of trials (<xref ref-type="fig" rid="F5">Figure 5g,h</xref>). Another alternative would be to increase learning rates, but doing so results in unstable learning (<xref ref-type="supplementary-material" rid="SD1">Supplemental Figure 4</xref>). In short, spatiotemporal credit assignment in recurrent networks is notoriously difficult<sup><xref ref-type="bibr" rid="R49">49</xref></sup>, and unsurprisingly, solving for <italic>P<sub>i</sub></italic>(<italic>t</italic>) via gBTSP (as opposed to solving for <italic>W<sub>ij</sub></italic> directly via BPTT) does not bypass these limitations. In other words, the standard tool of gradient descent does not stably resolve the question of “where” and “when” BTSP events should occur in a recurrent network in order to solve a supervised task. We will now elaborate on a more complete answer and discuss how we can reconcile these apparent hard limits on the speed of learning with the existence of BTSP in CA3, a highly recurrent network.</p></sec><sec id="S8"><title>Rapid activity changes due to gBTSP are fundamentally limited in deep and/or recurrent networks</title><p id="P35">In shallow feed-forward networks, gBTSP could recover few-shot learning as observed experimentally with BTSP. However, as we have demonstrated particularly for supervised learning in the recurrent network, single-cell learning via gBTSP was very slow. Moreover, attempting to speed-up learning results in instabilities (<xref ref-type="supplementary-material" rid="SD1">Supplemental Figure 4</xref>). Why is this?</p><p id="P36">For the following, we will step aside from the specifics of gBTSP to make a more general formulation of the problem. Let us assume only that a) plateau events exist, and b), they cause single-cell activity to change by a fixed amount Δ<italic>x</italic>, remaining agnostic about the type(s) of learning involved in bringing about this change Δ<italic>x</italic>. We can consider learning via these plateau events from the perspective of optimizing within a loss landscape, taking a step Δ<italic>x</italic> along the direction of the descending gradient (first derivative). In landscapes with “fine-grained” or “sharp” features, a step of size Δ<italic>x</italic> can overshoot the global minimum (<xref ref-type="fig" rid="F6">Figure 6a</xref>). Conventional learning approaches address this issue by reducing step sizes (i.e. taking a step of size δ<italic>x</italic> &lt; Δ<italic>x</italic>) (<xref ref-type="fig" rid="F6">Figure 6ai</xref>), thereby allowing learning to converge to the minimum.</p><p id="P37">An alternative approach involves modifying the loss landscape itself. By “stretching” the landscape, the same step size Δ<italic>x</italic> becomes proportionally smaller relative to the landscape features, “smoothing” out sharp features preventing overshooting (<xref ref-type="fig" rid="F6">Figure 6aii</xref>). Mathematically, this “stretching” operation locally shrinks both the first and second derivatives of the loss with respect to activity. Since we are assuming each optimization step takes a fixed step size Δ<italic>x</italic> regardless of the gradient (first derivative) amplitude, we can focus on conditions on the second derivative (which we will hereafter refer to, for simplicity, as the local “curvature” <italic>C</italic>), and show how this curvature depends on features of the network. Intuitively, learning in this “stretched” landscape might be considered akin to the evolution of microwave popcorn, in the sense that while population-level representations (the popcorn bag) may evolve gradually, individual units (the kernels) undergo rapid, stochastic transitions to their final states on timescales significantly shorter than the overall system evolution. To support this “popcorn”-like approach (which we posit to be more BTSP-like), local curvature must be small (i.e. the loss must be locally “shallow”) to prevent overshooting, but non-zero to enable learning in the first place.</p><p id="P38">In the case of a single-layer feedforward network, inputs <italic>x<sub>j</sub></italic>(<italic>t</italic>) project to output <italic>y<sub>i</sub></italic>(<italic>t</italic>) = ∑<italic><sub>j</sub> W<sub>ij</sub> x<sub>j</sub></italic>(<italic>t</italic>). (<xref ref-type="fig" rid="F6">Figure 6b</xref>). “Plateaus” of size Δ<italic>x</italic> occur at the inputs, and the loss is the mean squared error between output <bold>y</bold> and target <inline-formula><mml:math id="M13"><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mstyle></mml:math></inline-formula>. Solving for the curvature, we find that <italic>C</italic> ∝ <italic>W<sup>T</sup>W</italic> (see <xref ref-type="sec" rid="S10">Methods</xref>). It is trivial enough to construct a network where <italic>W<sup>T</sup>W</italic> is small but non-zero. For example, if <italic>y<sub>i</sub></italic>(<italic>t</italic>) receives many inputs, each with a small weight <italic>W<sub>ij</sub></italic>, any change in a single input <italic>x<sub>j</sub></italic>(<italic>t</italic>) will lead to small change in <italic>y<sub>i</sub></italic>(<italic>t</italic>). So, in the case of a single layer feed-forward network, a small but non-zero curvature is achievable, meaning rapid changes in activity arising from BTSP can lead to stable learning.</p><p id="P39">If we consider a deep feed-forward network with layers <italic>l</italic> and layer specific weights <italic>W<sub>l</sub></italic> (<xref ref-type="fig" rid="F6">Figure 6c</xref>), the expression for the curvature becomes more complicated, depending on products of all the layer-specific weights together in sequence <inline-formula><mml:math id="M14"><mml:mo>(</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:mo>∝</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>∏</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>L</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>∏</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>L</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:math></inline-formula>. Unfortunately, it is not trivial to make these products small but non-zero - in fact, they are the same troublesome mathematical objects which lead to the problem of exploding and vanishing gradients in gradient descent<sup><xref ref-type="bibr" rid="R49">49</xref>–<xref ref-type="bibr" rid="R51">51</xref></sup>.</p><p id="P40">Recurrent networks (<xref ref-type="fig" rid="F6">Figure 6d</xref>) can be conceptualized similarly to deep feed-forward networks (<xref ref-type="fig" rid="F6">Figure 6c</xref>), but with each “layer” representing a different timestep in the network, with the weight matrix <italic>W</italic> is applied at each timestep. In turn, curvature of the loss in a recurrent network depends on similar products <inline-formula><mml:math id="M15"><mml:mo>(</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:mo>∝</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>∏</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:msubsup><mml:mi>W</mml:mi></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>∏</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:msubsup><mml:mi>W</mml:mi></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:math></inline-formula> which also lead to exploding and vanishing contributions from an update Δ<italic>x</italic>.</p><p id="P41">These conditions set fundamental limits on both the architectures and the tasks for which deep or recurrent artificial networks can support rapid changes in single-unit activity. Despite these theoretical limitations, few-shot BTSP events have been observed in CA3<sup><xref ref-type="bibr" rid="R4">4</xref></sup>, which is highly recurrent. The analysis above is idealized, and biological neural networks may have yet unknown mechanisms which allow them to bypass these restrictions. However, if we hypothesize that recurrent connectivity in CA3 is indeed subject to these constraints, specialized architectural features would be required to stabilize learning dynamics and prevent vanishing or exploding effects arising from rapid plasticity events driven by BTSP.</p></sec></sec><sec id="S9" sec-type="discussion"><title>Discussion</title><p id="P42">The discovery of Behavioral Timescale Synaptic Plasticity (BTSP) unearthed an apparent paradox in our understanding of learning in the hippocampus. One the one hand, successful models of complex population-level hippocampal function (e.g. the formation of cognitive maps<sup><xref ref-type="bibr" rid="R52">52</xref>–<xref ref-type="bibr" rid="R54">54</xref></sup>) depend critically on recurrent computation, and in turn, seem to depend on the slow, precise training of recurrent weights. On the other hand, experiments in hippocampus observe a learning rule (BTSP) which is very fast and has a very distinct lack of temporal specificity. BTSP’s hallmark features—its wide temporal kernel spanning seconds and its rapid, one-shot field formation—run counter to conventional wisdom that precise, gradual weight changes are necessary for stable learning. To examine the computational implications of BTSP, we proposed a generalized mathematical framework, gBTSP, for which plasticity is governed by wide temporal kernels and a postsynaptic “plateau function” P(<italic>t</italic>). We test its properties across different network architectures (feed-forward and recurrent) and learning paradigms (supervised and unsupervised).</p><p id="P43">We demonstrated that unsupervised gBTSP in feed-forward networks maps well onto the framework of competitive learning, wherein neurons “compete” to represent distinct regions of the input space. This framework accounts for experimentally observed phenomena, including the rapid formation of place fields and their distribution across the environment. If we assume BTSP is operating according to unsupervised principles, our model predicts that plateau probability should inversely correlate with network activity, offering a testable hypothesis for future experiments. Moreover, we found that individual neurons can undergo rapid remapping while the population-level representation maintains coverage of the environment—exhibiting representational drift primarily through index “shuffling” rather than degradation of the underlying representation. However, we only consider a few hundred trials of unsupervised learning, so it remains unclear to what extent this model can explain recent experimental results regarding place field stability over days<sup><xref ref-type="bibr" rid="R55">55</xref></sup> or over the course of goal-oriented spatial learning<sup><xref ref-type="bibr" rid="R56">56</xref></sup>. One could also imagine extending our framework by considering other forms of competitive learning, such as self-organizing maps<sup><xref ref-type="bibr" rid="R19">19</xref>,<xref ref-type="bibr" rid="R57">57</xref></sup>, which assume an underlying functional structure which is maintained during learning. Such an extension might explain the observations of functional clustering of field formation events around “seed” plateau neurons<sup><xref ref-type="bibr" rid="R58">58</xref></sup>, and other topographically related phenomenon observed in plateau generation<sup><xref ref-type="bibr" rid="R59">59</xref></sup>.</p><p id="P44">In recurrent networks like CA3, we demonstrated that unsupervised gBTSP can facilitate attractor learning when implemented with appropriate architectural constraints. This aligns with previous theoretical work showing BTSP’s suitability for memory storage in discrete attractor networks<sup><xref ref-type="bibr" rid="R4">4</xref></sup>. To preserve stability during learning, we used a low-rank parameterization of the network’s recurrent weights, only applying gBTSP to the “encoding” portion of this parameterization. However, there are also other promising avenues for considering BTSP in the context of unsupervised, recurrent learning. For example, under certain conditions STDP in a recurrent network can approximate Hidden Markov Model Learning, a very powerful tool for discovering underlying latent structure<sup><xref ref-type="bibr" rid="R60">60</xref></sup>. Recent experimental work which recorded hippocampal activity over the course of learning observed an orthogonalization of the latent map<sup><xref ref-type="bibr" rid="R61">61</xref></sup> – a feature they found was best described by networks which learned HMMs<sup><xref ref-type="bibr" rid="R60">60</xref>,<xref ref-type="bibr" rid="R62">62</xref></sup>, including a version of the STDP-recurrent network. Although BTSP learns with a much larger temporal kernel than STDP, they have a similar fundamental structure. One can imagine that a mapping of BTSP onto HMM learning may be possible, though the rapid learning and large temporal kernel of BTSP present non-trivial challenges to stability and convergence.</p><p id="P45">For learning based on explicit error functions (i.e. supervised learning), we derived analytical expressions that determine when and where plateau events should occur to optimize task performance. This formulation allows us to understand BTSP in the context of gradient-based learning, with the plateau function effectively distributing “credit” for errors across the network. Further, because we have an explicit analytical expression for our plateau function, we can constrain it to be stochastic and sparse, akin to BTSP events observed in vivo<sup><xref ref-type="bibr" rid="R5">5</xref>,<xref ref-type="bibr" rid="R48">48</xref></sup>. We show that gBTSP can successfully learn feed-forward tasks, while retaining key features of observed BTSP, such as few-shot learning.</p><p id="P46">While our supervised gBTSP successfully learned complex tasks in feed-forward networks, maintaining the rapid learning characteristic of BTSP, deep recurrent networks proved more challenging. We showed that these challenges arise from fundamental stability limitations of large, rapid activity changes in deep and recurrent networks, limitations which are similar mathematically to exploding or vanishing gradients in backpropagation<sup><xref ref-type="bibr" rid="R49">49</xref>–<xref ref-type="bibr" rid="R51">51</xref></sup>. This presents an apparent paradox, as BTSP has been experimentally observed in the highly recurrent CA3 region. Perhaps structures such as so-called orthogonal or unitary networks, which preserve spectral norms of the recurrent weights (and thereby maintain stable gradient flow), can offer a solution, but training in these networks is difficult to reconcile with gBTSP<sup><xref ref-type="bibr" rid="R63">63</xref>–<xref ref-type="bibr" rid="R65">65</xref></sup>. Alternatively, it might be sensible to model CA3 as dynamically regulating its recurrence, gating certain pathways such that they behave as feed-forward networks during learning episodes (note that we used this method earlier to train our unsupervised recurrent network; <xref ref-type="fig" rid="F3">Figure 3</xref>).</p><p id="P47">Our analysis has focused on a “strong” hypothesis, by which hippocampal learning is governed mainly via BTSP, and the plateau events follow some unifying principle (such as minimizing a particular error or loss function). We call this the “strong” assumption, because a) it remains unknown what fraction of overall learning is due to discrete, rapid BTSP events, b) it is highly likely that multiple forms of plasticity, including BTSP, are active simultaneously, and c) it is unclear if plateau-driven learning is guided by any sort of governing computational principle. A “softer” hypothesis might posit that BTSP is but a small fraction of hippocampal learning, and/or it is relegated to a trivial function such as taking mere random “snapshots” of complex representations occurring in other cortical areas. While this “soft” hypothesis remains worthy of consideration and further study, rates of BTSP appear to be relatively high, particularly in novel environments<sup><xref ref-type="bibr" rid="R5">5</xref>,<xref ref-type="bibr" rid="R48">48</xref></sup>, and previous theoretical work suggests that purely random plateau occurrence is inconsistent with the task-specific formation of complex hippocampal representations (i.e. splitter cells)<sup><xref ref-type="bibr" rid="R66">66</xref></sup>.</p><p id="P48">The limitations we identify suggest that while BTSP may indeed play a crucial role in hippocampal learning, at the very least, its implementation likely requires specialized circuit designs and/or other forms of plasticity to maintain stability. Still, the stark contrast between traditional gradient-based learning (where both population and single-unit representations evolve gradually), and BTSP-like learning, (where individual units can change rapidly while population representations evolve more gradually), highlights a fundamental difference between learning in artificial and biological systems.</p><p id="P49">Ultimately, this work introduces a generalized mathematical and analytical framework for BTSP (gBTSP) and uses this framework to investigate how plateau events may be distributed to solve learning tasks. Our findings suggest that while placing the entire burden of credit assignment on plateau events alone may be insufficient to explain complex aspects of hippocampal learning, BTSP is capable of rapid memory formation and latent encoding, particularly in feed-forward, and constrained recurrent networks. Future work should identify the biological circuits and plasticity mechanisms that stabilize hippocampal networks undergoing BTSP, particularly within CA3, to better understand how BTSP contributes to the development of hippocampal cognitive functions.</p></sec><sec id="S10" sec-type="methods"><title>Methods</title><p id="P50">All parameters for the following methods are included in <xref ref-type="table" rid="T1">Table 1</xref>.</p><sec id="S11"><title>Generalized Learning Rule for Behavioral Timescale Plasticity</title><p id="P51">To begin our derivation, we consider the simple case of a single postsynaptic neuron which triggers an instantaneous plateau event, and a single presynaptic neuron which fires a spike (<xref ref-type="fig" rid="F1">Figure 1a</xref>). We assume the postsynaptic plateau updates weight <italic>W</italic> via some function, <italic>W<sub>kernel</sub></italic>, which depends on the timing of the presynaptic spike relative to the plateau: <disp-formula id="FD3"><label>(3)</label><mml:math id="M16"><mml:mrow><mml:mo>Δ</mml:mo><mml:mi>W</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p id="P52">Specifically, we choose a <italic>W<sub>kernel</sub></italic> such that the application of our learning rule matches observed plasticity following application of a single plateau and bursting inputs in vitro (<xref ref-type="fig" rid="F1">Figure 1d</xref>)<sup><xref ref-type="bibr" rid="R2">2</xref></sup>. The specific form of the weight kernel is: <disp-formula id="FD4"><label>(4)</label><mml:math id="M17"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mi>p</mml:mi></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mi>p</mml:mi></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>t</mml:mi><mml:mo>&lt;</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mi>p</mml:mi></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mi>p</mml:mi></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>t</mml:mi><mml:mo>≥</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mi>p</mml:mi></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:math></disp-formula></p><p id="P53">Where <italic>t<sup>p</sup></italic> is the time of the plateau, and <italic>τ<sub>b</sub></italic> and <italic>τ<sub>b</sub></italic> are “backward” and “forward” time constants.</p><p id="P54">Next, we relax our previous assumption that there is a single presynaptic neuron which fires a single spike, instead describing the continuous activity of presynaptic neuron <italic>j</italic> at time <italic>t</italic> as <italic>x<sub>j</sub></italic>(<italic>t</italic>) (<xref ref-type="fig" rid="F1">Figure 1b</xref>). Now, the change in weights following a single plateau depends on the integrated presynaptic activity across a temporal window Δ<italic>t</italic> relative to the time of the plateau): <disp-formula id="FD5"><label>(5)</label><mml:math id="M18"><mml:mo>Δ</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mo>Δ</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo>Δ</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mtext> </mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:math></disp-formula></p><p id="P55">Note that if <italic>x<sub>j</sub></italic>(<italic>t</italic>) is taken to be a delta function <italic>δ</italic>(<italic>t</italic> - <italic>t<sub>pre</sub></italic>), <xref ref-type="disp-formula" rid="FD5">Equation 5</xref> reduces to <xref ref-type="disp-formula" rid="FD3">Equation 3</xref>. Further, the asymmetric offset of observed plasticity in <xref ref-type="fig" rid="F1">Figure 1e</xref> is a direct consequence of the shape of <italic>W<sub>kernel</sub></italic> (<xref ref-type="disp-formula" rid="FD4">Equation 4</xref>). For some intuition on why this is the case, notice that <xref ref-type="disp-formula" rid="FD5">Equation 5</xref> is equivalent to a cross-correlation, so we can imagine “sliding” or “smearing” <italic>W<sub>kernel</sub></italic> across the input <italic>x<sub>j</sub></italic>(<italic>t</italic>) to get a given horizontal slice of <xref ref-type="fig" rid="F1">Figure 1e</xref>.</p><p id="P56">To match experimental data showing that the amplitude of the formed field depends on the initial membrane voltage of the postsynaptic cell<sup><xref ref-type="bibr" rid="R1">1</xref></sup>, we add in a dependence on the synaptic strength prior to the plateau event, leading to the equation: <disp-formula id="FD6"><label>(6)</label><mml:math id="M19"><mml:mo>Δ</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mo>Δ</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo>Δ</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mtext> </mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></disp-formula> where the weight dependence is parametrized by <italic>λ</italic>. Note since Δ<italic>W</italic> is only applied when a plateau occurs, −<italic>λW</italic> is not a continuous weight decay.</p><p id="P57">Finally, we want to consider the case for which there are multiple postsynaptic neurons, each of which may have multiple plateaus. So, we introduce <italic>P<sub>i</sub></italic>(<italic>t</italic>), a function representing the postsynaptic plateau potential at time <italic>t</italic> for neuron <italic>i</italic>. Now, the change in weights depends on an integral over the presynaptic activity, as well as an integral over any post-synaptic plateaus (<xref ref-type="fig" rid="F1">Figure 1c</xref>): <disp-formula id="FD7"><label>(1)</label><mml:math id="M20"><mml:mo>Δ</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mi>T</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mo>Δ</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mo>Δ</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:math></disp-formula></p><p id="P58">in which weight <italic>W<sub>ij</sub></italic> is updated after each trial according to the presence of <italic>P<sub>i</sub></italic>(<italic>t</italic>). Note that if <italic>P<sub>i</sub></italic>(<italic>t</italic>) is taken to be a delta function <italic>δ</italic>(<italic>t</italic> - <italic>t<sub>plateau</sub></italic>), <xref ref-type="disp-formula" rid="FD1">Equation 1</xref> reduces to <xref ref-type="disp-formula" rid="FD6">Equation 6</xref>. Since <xref ref-type="disp-formula" rid="FD1">Equation 1</xref> is derived from various degrees of generalization (<xref ref-type="disp-formula" rid="FD3">Equations 3</xref>, <xref ref-type="disp-formula" rid="FD5">5</xref>, and <xref ref-type="disp-formula" rid="FD6">6</xref>), we call this equation “generalized BTSP”.</p></sec><sec id="S12"><title>Unsupervised Feed-Forward Task</title><p id="P59">Notice in <xref ref-type="disp-formula" rid="FD6">Equation 6</xref>, that if we take the temporal kernel <italic>W<sub>kernel</sub></italic>(<italic>t</italic> – <italic>t<sub>plateau</sub></italic>) to be the delta function <italic>δ</italic>(<italic>t</italic> – <italic>t<sub>plateau</sub></italic>), the integral over time goes away and we get the following expression: <disp-formula id="FD8"><label>(7)</label><mml:math id="M21"><mml:mo>Δ</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></disp-formula></p><p id="P60">So, in this approximation, upon each plateau event, the weights would move towards a fixed point <inline-formula><mml:math id="M22"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>λ</mml:mi></mml:mfrac><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, akin to classical conceptions of “competitive learning”<sup><xref ref-type="bibr" rid="R17">17</xref>–<xref ref-type="bibr" rid="R20">20</xref></sup>.</p><p id="P61">For the 1-D unsupervised feed-forward task in <xref ref-type="fig" rid="F2">Figure 2b-e</xref>, we assume an animal is running along a 1-D treadmill at constant velocity <italic>β</italic>, i.e. the animal’s position <italic>u</italic>(<italic>t</italic>) = <italic>βt</italic>. The external sensory input is modeled in the form of stereotypical 1-D tuning curves with added noise: <disp-formula id="FD9"><label>(8)</label><mml:math id="M23"><mml:msub><mml:mtext>x</mml:mtext><mml:mtext>j</mml:mtext></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mtext>e</mml:mtext><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>u</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>N</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></disp-formula> where <italic>j</italic> indexes over <italic>N</italic> total inputs, and <italic>u<sub>j</sub></italic> are the locations (or equivalently, times) of the tuning curve centers, which have standard deviation σ. Zero-mean Gaussian noise is added, with standard deviation <italic>σ<sub>N</sub></italic>. These inputs are connected to an output <italic>y<sub>i</sub></italic>(<italic>t</italic>) by feed-forward weights <italic>W<sub>ij</sub></italic> : <disp-formula id="FD10"><label>(9)</label><mml:math id="M24"><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mi>∑</mml:mi><mml:mi>j</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> which are learned via gBTSP. We used the following rule to trigger a plateau: <disp-formula id="FD11"><label>(10)</label><mml:math id="M25"><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext> </mml:mtext><mml:mrow><mml:mstyle displaystyle="true"><mml:msub><mml:mi>∑</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:mi>θ</mml:mi><mml:mo>:</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula> Where <italic>θ</italic> is a firing rate threshold, and <italic>K</italic> is a random index from 1 to N. A single plateau can drive the network above the threshold <italic>θ</italic> (at a given time). Weights were initialized at zero and the network was trained on 100 laps.</p><p id="P62">For the 2-D unsupervised feed-forward task in <xref ref-type="fig" rid="F2">Figure 2f-h</xref>, we assume an animal begins at a random location inside a 2-D box, (<italic>u</italic><sub>0</sub>, <italic>v</italic><sub>0</sub>) and takes <italic>T</italic> steps of a random walk along a trajectory (<italic>u</italic>(<italic>t</italic>), <italic>v</italic>(<italic>t</italic>)). The external sensory input is modeled in the form of stereotypical 2-D tuning curves with added noise: <disp-formula id="FD12"><label>(11)</label><mml:math id="M26"><mml:msub><mml:mtext>x</mml:mtext><mml:mtext>j</mml:mtext></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mtext>e</mml:mtext><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>u</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msup><mml:msup><mml:mtext>e</mml:mtext><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>v</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>N</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></disp-formula> where j indexes over <italic>N</italic><sup><xref ref-type="bibr" rid="R2">2</xref></sup> total inputs, and (<italic>u<sub>j</sub>, v<sub>j</sub></italic>) are the 2-D locations of the tuning curve centers, which have standard deviation <italic>σ</italic>. Zero-mean Gaussian noise is added, with standard deviation <italic>σ<sub>N</sub></italic>. These inputs are connected to an output <italic>y<sub>i</sub></italic>(<italic>t</italic>) by feed-forward weights <italic>W<sub>ij</sub></italic> (<xref ref-type="disp-formula" rid="FD10">Equation 9</xref>), which are learned via gBTSP, just as in the 1-D case.</p></sec><sec id="S13"><title>Unsupervised Recurrent Task</title><p id="P63">For the unsupervised recurrent task in <xref ref-type="fig" rid="F3">Figure 3</xref>, we assume an animal is running along a 1D treadmill at constant velocity <italic>β</italic>, i.e. the animal’s position <italic>u</italic>(<italic>t</italic>) = <italic>βt</italic>. The external sensory input is modeled the same as for the unsupervised feed-forward task (<xref ref-type="disp-formula" rid="FD9">Equation 8</xref>). There are two populations of neurons, “visible” neurons <italic>x<sub>j</sub></italic>(<italic>t</italic>) and “seed” neurons <italic>s<sub>i</sub></italic>(<italic>t</italic>). These populations connect recurrently to each other, but not amongst themselves. Visible neurons receive external input <italic>o<sub>k</sub></italic>(<italic>t</italic>), and only the seed neurons eligible for plateaus (<xref ref-type="fig" rid="F3">Figure 3a</xref>). The activity of these two populations is governed by the following equations: <disp-formula id="FD13"><label>(12)</label><mml:math id="M27"><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:msub><mml:mi>∑</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msubsup></mml:mrow></mml:mstyle><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula> <disp-formula id="FD14"><label>(13)</label><mml:math id="M28"><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mstyle displaystyle="true"><mml:msub><mml:mi>∑</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msubsup></mml:mrow></mml:mstyle><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mstyle displaystyle="true"><mml:msub><mml:mi>∑</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle><mml:msub><mml:mi>o</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula> where <inline-formula><mml:math id="M29"><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msubsup></mml:math></inline-formula> are “encoding” weights, <inline-formula><mml:math id="M30"><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msubsup></mml:math></inline-formula> are “decoding” weights, and <inline-formula><mml:math id="M31"><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> are input weights. <italic>α</italic> is a gating variable governed by the norm of the external input: when external input is high, recurrent input is low, and vice versa: <disp-formula id="FD15"><label>(14)</label><mml:math id="M32"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>C</mml:mi><mml:mo>−</mml:mo><mml:mo>‖</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>o</mml:mi></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>t</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo>‖</mml:mo></mml:mrow><mml:mi>C</mml:mi></mml:mfrac></mml:math></disp-formula> Where C is a constant and ||<bold>o(t)</bold>|| is the norm of the external input. In the limit of no external input (<italic>α</italic> = 0), our equation for the visible neurons reduces to: <disp-formula id="FD16"><label>(15)</label><mml:math id="M33"><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:msub><mml:mi>∑</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>′</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mstyle displaystyle="true"><mml:msub><mml:mi>∑</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msubsup></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:msup><mml:mi>j</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mi>e</mml:mi></mml:msubsup><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:msup><mml:mi>j</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:msub><mml:mi>∑</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>′</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:msup><mml:mi>j</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:msup><mml:mi>j</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula> where <inline-formula><mml:math id="M34"><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:msup><mml:mi>j</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> is the low-rank recurrence, <inline-formula><mml:math id="M35"><mml:mstyle displaystyle="true"><mml:msub><mml:mi>∑</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msubsup><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, of the visible neurons. However, in the limit of large external input, our network becomes effectively feed-forward: <disp-formula id="FD17"><label>(16)</label><mml:math id="M36"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:msub><mml:mo>∑</mml:mo><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>O</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p id="P64">This dual nature of the network allows us to take advantage of recurrent computation in the low-input phase, while making use of unsupervised, feed-forward gBTSP in the high-input phase. Encoding weights are learned via the same competitive learning algorithm as the feed-forward case (<xref ref-type="disp-formula" rid="FD11">Equation 10</xref>). The decoder weights are set to be the transpose of the encoder weights. Following a single lap of training, a test phase was conducted, whereby inputs were only shown for one timestep before being removed. The inputs were shown at times 0, 2, 4, 6, and 8 seconds.</p></sec><sec id="S14"><title>Supervised Feed-Forward Task</title><p id="P65">In order to apply plateaus in the supervised context, we derive an expression for <italic>P</italic>(<italic>t</italic>) which minimizes a given error/loss. Assuming some target output <inline-formula><mml:math id="M37"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, and a loss function <inline-formula><mml:math id="M38"><mml:mi>ℒ</mml:mi></mml:math></inline-formula> (here we choose a mean squared error loss). <disp-formula id="FD18"><label>(17)</label><mml:math id="M39"><mml:mrow><mml:mi>ℒ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P66">We can compare our gBTSP weight update <disp-formula id="FD19"><label>(1)</label><mml:math id="M40"><mml:mo>Δ</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mi>T</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mo>Δ</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mo>Δ</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:math></disp-formula> to that of simple backpropagation (for a single layer, this is just the delta rule): <disp-formula id="FD20"><label>(18)</label><mml:math id="M41"><mml:mo>Δ</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mi>T</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>ε</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:math></disp-formula></p><p id="P67">Where the error term <inline-formula><mml:math id="M42"><mml:mrow><mml:msub><mml:mi>ε</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>ı</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. By setting these two equations to be equal, we can find an expression for the function <italic>P<sub>i</sub></italic>(<italic>t</italic>): <disp-formula id="FD21"><label>(2)</label><mml:math id="M43"><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mi>∑</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mo>Δ</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mo>Δ</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mtext>kernel </mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p id="P68">For the first task, we consider a shallow feed-forward network (<xref ref-type="disp-formula" rid="FD10">Equation 9</xref>). We choose a target function <inline-formula><mml:math id="M44"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> that is a putative place field, modeled as a Gaussian bump centered at a specific location in the environment: <disp-formula id="FD22"><label>(19)</label><mml:math id="M45"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mtext>e</mml:mtext><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>u</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msup></mml:math></disp-formula></p><p id="P69">Where <italic>u</italic>(<italic>t</italic>) is the animal’s position, and <italic>u</italic><sub>0</sub> is the location of the tuning curve center, which has standard deviation σ.</p><p id="P70">For the navigation task, the network has three layers (input, hidden, output), for which only the hidden neurons can receive plateaus, i.e. only the input to hidden weights <italic>Wj<sub>k</sub></italic> are trainable: <disp-formula id="FD23"><label>(20)</label><mml:math id="M46"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mi>∑</mml:mi><mml:mi>j</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mi>∑</mml:mi><mml:mi>k</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p id="P71">The 2D target trajectory for the task is: <disp-formula id="FD24"><label>(21)</label><mml:math id="M47"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>cos</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>sin</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>4</mml:mn><mml:mi>π</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>4</mml:mn></mml:mfrac><mml:mi>cos</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>8</mml:mn><mml:mi>π</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>sin</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>sin</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>4</mml:mn><mml:mi>π</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>4</mml:mn></mml:mfrac><mml:mi>sin</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>8</mml:mn><mml:mi>π</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p id="P72">We train the network (<xref ref-type="disp-formula" rid="FD1">Equations 1</xref> and <xref ref-type="disp-formula" rid="FD2">2</xref>) for 100 trials on both tasks.</p></sec><sec id="S15"><title>Supervised Recurrent Task</title><p id="P73">For our recurrent task, a network of hidden units with activation <italic>h<sub>j</sub></italic>(<italic>t</italic>) is recurrently connected via weights <inline-formula><mml:math id="M48"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>. The dynamics of the hidden units are governed by the following: <disp-formula id="FD25"><label>(22)</label><mml:math id="M49"><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mi>∑</mml:mi><mml:mi>j</mml:mi></mml:munder><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mi>∑</mml:mi><mml:mi>k</mml:mi></mml:munder><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></disp-formula> here <italic>φ</italic> is a non-linear function (i.e. tanh) of the recurrent inputs, and these activations are initialized at <italic>h</italic><sub>0</sub>. Input <italic>x<sub>k</sub></italic>(<italic>t</italic>) is projected to the network via input weights <inline-formula><mml:math id="M50"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>. We initialize the internal weights as a random Gaussian matrix with a gain factor <italic>g</italic>. These hidden units project to output <italic>y</italic>(<italic>t</italic>) via weights <inline-formula><mml:math id="M51"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mtext>out </mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>: <disp-formula id="FD26"><label>(23)</label><mml:math id="M52"><mml:mrow><mml:mi>y</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mi>∑</mml:mi><mml:mi>j</mml:mi></mml:munder><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mtext>out </mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P74">To find <italic>P<sub>i</sub></italic>(<italic>t</italic>) which minimizes the error in a recurrent network, we again compare our gBTSP rule <disp-formula id="FD27"><label>(1)</label><mml:math id="M53"><mml:mo>Δ</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mi>T</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mo>Δ</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mo>Δ</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mtext>kernel </mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:math></disp-formula> to the full backpropagation through time update: (for a full derivation, see Murray, 2019<sup><xref ref-type="bibr" rid="R13">13</xref></sup>): <disp-formula id="FD28"><label>(24)</label><mml:math id="M54"><mml:mo>Δ</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mi>T</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi>φ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mi>∑</mml:mi><mml:mi>j</mml:mi></mml:munder><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mi>∑</mml:mi><mml:mi>k</mml:mi></mml:munder><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:math></disp-formula> where <italic>φ</italic>′ is the derivative of our activation function, and the Lagrange multiplier <italic>z<sub>i</sub></italic>(<italic>t</italic>) is equal to: <disp-formula id="FD29"><label>(25)</label><mml:math id="M55"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munderover><mml:mi>∑</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi>φ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mi>∑</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle><mml:msub><mml:mi>ε</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> where <italic>u<sub>i</sub></italic>(<italic>t</italic>) is our total input current to the unit, i.e., <disp-formula id="FD30"><label>(26)</label><mml:math id="M56"><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mi>∑</mml:mi><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mi>∑</mml:mi><mml:mi>l</mml:mi></mml:munder><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula></p><p id="P75">The Lagrange multiplier <italic>z<sub>i</sub></italic>(<italic>t</italic>) is calculated in the “backwards” phase, by starting with the terminal value, <italic>z<sub>i</sub></italic>(<italic>t</italic>), and working back to <italic>z<sub>i</sub></italic>(0). <italic>z<sub>i</sub></italic>(<italic>t</italic>) takes the form: <disp-formula id="FD31"><label>(27)</label><mml:math id="M57"><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mi>∑</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle><mml:msub><mml:mi>ε</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula></p><p id="P76">By setting <xref ref-type="disp-formula" rid="FD1">Equation 1</xref> and <xref ref-type="disp-formula" rid="FD28">Equation 24</xref> to be equal, we solve for the plateau function and get the following expression: <disp-formula id="FD32"><label>(28)</label><mml:math id="M58"><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>τ</mml:mi></mml:mfrac><mml:msup><mml:mi>φ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mi>∑</mml:mi><mml:mi>j</mml:mi></mml:munder><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mo>Δ</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mo>Δ</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p id="P77">The delayed non-match to sample task consists of two inputs, representing odor A and odor B, and two outputs: one representing licking probability and the other which represents a ramping temporal component. This component encourages the network to develop sequential internal representations<sup><xref ref-type="bibr" rid="R47">47</xref></sup>. For each trial, a random odor combination (AA,AB,BA,BB) was selected. The first odor input was presented for the first 1s of the trial, and the second odor input was present between 7-8s. No odor inputs were given in the delay period. For non-matching pairs, the target for licking probability was 1 for all timesteps after 8 seconds, and 0 otherwise. For matching pairs, the target licking probability was always 0. Output weights were trained using the delta rule, while recurrent weights were trained using our gBTSP update (<xref ref-type="disp-formula" rid="FD1">Equation 1</xref>), after selecting plateaus (<xref ref-type="disp-formula" rid="FD32">Equation 28</xref>). The network was trained for 50,000 trials, with the gBTSP update (<xref ref-type="disp-formula" rid="FD1">Equation 1</xref>) passed through a momentum-based optimizer (ADAM<sup><xref ref-type="bibr" rid="R46">46</xref></sup>) to avoid critical instabilities (see <xref ref-type="table" rid="T1">Table 1</xref> for parameters).</p></sec><sec id="S16"><title>Constraints on Few-Shot Learning</title><p id="P78">In the case of the shallow network, inputs <italic>x<sub>j</sub></italic>(<italic>t</italic>) project to output <italic>y<sub>i</sub></italic>(<italic>t</italic>) = ∑<italic><sub>j</sub> W<sub>ij</sub> x<sub>j</sub></italic>(<italic>t</italic>). (<xref ref-type="fig" rid="F6">Figure 6b</xref>). “Plateaus” of size Δ<italic>x</italic> occur at the inputs, and the loss is the mean squared error between output <bold>y</bold> and target <inline-formula><mml:math id="M59"><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mstyle></mml:math></inline-formula>. Solving for the Hessian (local curvature), we find: <disp-formula id="FD33"><label>(29)</label><mml:math id="M60"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>ℒ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>W</mml:mi><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>W</mml:mi><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mi>ℒ</mml:mi></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>W</mml:mi><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mo>∂</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mi>ℒ</mml:mi></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mi>x</mml:mi><mml:mo>∂</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mo>∂</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mi>ℒ</mml:mi></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mi>W</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p id="P79">If we consider a deep feed-forward network with layers <italic>l</italic> and layer specific weights <italic>W<sub>l</sub></italic> (<xref ref-type="fig" rid="F6">Figure 6c</xref>), the expression for the Hessian becomes more complicated: <disp-formula id="FD34"><label>(30)</label><mml:math id="M61"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>ℒ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>L</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>L</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mi>ℒ</mml:mi></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>L</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>L</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mo>∂</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mi>ℒ</mml:mi></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mi>x</mml:mi><mml:mo>∂</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mo>∂</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mi>ℒ</mml:mi></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>L</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>L</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p id="P80">For recurrent networks (<xref ref-type="fig" rid="F6">Figure 6d</xref>), the Hessian in a recurrent network depends on the <italic>T</italic>th product of <italic>W</italic>, which also leads to exploding and vanishing contributions from an update Δ<italic>x</italic>: <disp-formula id="FD35"><label>(31)</label><mml:math id="M62"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>ℒ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:munderover><mml:mi>W</mml:mi></mml:mstyle><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:munderover><mml:mi>W</mml:mi></mml:mstyle><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mi>ℒ</mml:mi></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:munderover><mml:mi>W</mml:mi></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:munderover><mml:mi>W</mml:mi></mml:mstyle><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mo>∂</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mi>ℒ</mml:mi></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mi>x</mml:mi><mml:mo>∂</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mo>∂</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mi>ℒ</mml:mi></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:munderover><mml:mi>W</mml:mi></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:munderover><mml:mi>W</mml:mi></mml:mstyle></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p id="P81">These conditions set fundamental limits on both the architectures and the tasks for which deep or recurrent artificial networks can support rapid changes in single-unit activity.</p></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplemental Figures</label><media xlink:href="EMS206468-supplement-Supplemental_Figures.pdf" mimetype="application" mime-subtype="pdf" id="d44aAcEbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S17"><title>Acknowledgements</title><p>This work was supported by BBSRC (BB/N013956/1), Wellcome Trust (200790/Z/16/Z), the Simons Foundation (564408), EPSRC (EP/R035806/1 and EP/X029336/1) and ERC-UKRI (EP/Y027841/1).</p></ack><fn-group><fn id="FN2" fn-type="con"><p id="P82"><bold>Author Contributions</bold></p><p id="P83">I.C., C.C. and R.P.C. conceived and designed the model. I.C. developed and performed the simulations. I.C., C.C. and R.P.C. wrote the manuscript.</p></fn><fn id="FN3" fn-type="conflict"><p id="P84"><bold>Competing Interests</bold></p><p id="P85">The authors declare no competing interests.</p></fn></fn-group><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Milstein</surname><given-names>AD</given-names></name><etal/></person-group><article-title>Bidirectional synaptic plasticity rapidly modifies hippocampal representations</article-title><source>eLife</source><year>2021</year><volume>10</volume><elocation-id>e73046</elocation-id><pub-id pub-id-type="pmcid">PMC8776257</pub-id><pub-id pub-id-type="pmid">34882093</pub-id><pub-id pub-id-type="doi">10.7554/eLife.73046</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bittner</surname><given-names>KC</given-names></name><name><surname>Milstein</surname><given-names>AD</given-names></name><name><surname>Grienberger</surname><given-names>C</given-names></name><name><surname>Romani</surname><given-names>S</given-names></name><name><surname>Magee</surname><given-names>JC</given-names></name></person-group><article-title>Behavioral time scale synaptic plasticity underlies CA1 place fields</article-title><source>Science</source><year>2017</year><volume>357</volume><fpage>1033</fpage><lpage>1036</lpage><pub-id pub-id-type="pmcid">PMC7289271</pub-id><pub-id pub-id-type="pmid">28883072</pub-id><pub-id pub-id-type="doi">10.1126/science.aan3846</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bittner</surname><given-names>KC</given-names></name><etal/></person-group><article-title>Conjunctive input processing drives feature selectivity in hippocampal CA1 neurons</article-title><source>Nat Neurosci</source><year>2015</year><volume>18</volume><fpage>1133</fpage><lpage>1142</lpage><pub-id pub-id-type="pmcid">PMC4888374</pub-id><pub-id pub-id-type="pmid">26167906</pub-id><pub-id pub-id-type="doi">10.1038/nn.4062</pub-id></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Briguglio</surname><given-names>JJ</given-names></name><name><surname>Romani</surname><given-names>S</given-names></name><name><surname>Magee</surname><given-names>JC</given-names></name></person-group><article-title>Mechanisms of memory-supporting neuronal dynamics in hippocampal area CA3</article-title><source>Cell</source><year>2024</year><volume>0</volume><pub-id pub-id-type="pmid">39454575</pub-id></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grienberger</surname><given-names>C</given-names></name><name><surname>Magee</surname><given-names>JC</given-names></name></person-group><article-title>Entorhinal cortex directs learning-related changes in CA1 representations</article-title><source>Nature</source><year>2022</year><volume>611</volume><fpage>554</fpage><lpage>562</lpage><pub-id pub-id-type="pmcid">PMC9668747</pub-id><pub-id pub-id-type="pmid">36323779</pub-id><pub-id pub-id-type="doi">10.1038/s41586-022-05378-6</pub-id></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LeCun</surname><given-names>Y</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><article-title>Deep learning</article-title><source>Nature</source><year>2015</year><volume>521</volume><fpage>436</fpage><lpage>444</lpage><pub-id pub-id-type="pmid">26017442</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Werbos</surname><given-names>PJ</given-names></name></person-group><article-title>Backpropagation through time: what it does and how to do it</article-title><source>Proc IEEE</source><year>1990</year><volume>78</volume><fpage>1550</fpage><lpage>1560</lpage></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laje</surname><given-names>R</given-names></name><name><surname>Buonomano</surname><given-names>DV</given-names></name></person-group><article-title>Robust timing and motor patterns by taming chaos in recurrent neural networks</article-title><source>Nat Neurosci</source><year>2013</year><volume>16</volume><fpage>925</fpage><lpage>933</lpage><pub-id pub-id-type="pmcid">PMC3753043</pub-id><pub-id pub-id-type="pmid">23708144</pub-id><pub-id pub-id-type="doi">10.1038/nn.3405</pub-id></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DePasquale</surname><given-names>B</given-names></name><name><surname>Cueva</surname><given-names>CJ</given-names></name><name><surname>Rajan</surname><given-names>K</given-names></name><name><surname>Escola</surname><given-names>GS</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name></person-group><article-title>full-FORCE: A target-based method for training recurrent networks</article-title><source>PLOS ONE</source><year>2018</year><volume>13</volume><elocation-id>e0191527</elocation-id><pub-id pub-id-type="pmcid">PMC5802861</pub-id><pub-id pub-id-type="pmid">29415041</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0191527</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lillicrap</surname><given-names>TP</given-names></name><name><surname>Cownden</surname><given-names>D</given-names></name><name><surname>Tweed</surname><given-names>DB</given-names></name><name><surname>Akerman</surname><given-names>CJ</given-names></name></person-group><article-title>Random synaptic feedback weights support error backpropagation for deep learning</article-title><source>Nat Commun</source><year>2016</year><volume>7</volume><elocation-id>13276</elocation-id><pub-id pub-id-type="pmcid">PMC5105169</pub-id><pub-id pub-id-type="pmid">27824044</pub-id><pub-id pub-id-type="doi">10.1038/ncomms13276</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lillicrap</surname><given-names>TP</given-names></name><name><surname>Santoro</surname><given-names>A</given-names></name></person-group><article-title>Backpropagation through time and the brain</article-title><source>Curr Opin Neurobiol</source><year>2019</year><volume>55</volume><fpage>82</fpage><lpage>89</lpage><pub-id pub-id-type="pmid">30851654</pub-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Williams</surname><given-names>RJ</given-names></name><name><surname>Zipser</surname><given-names>D</given-names></name></person-group><article-title>A Learning Algorithm for Continually Running Fully Recurrent Neural Networks</article-title><source>Neural Comput</source><year>1989</year><volume>1</volume><fpage>270</fpage><lpage>280</lpage></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murray</surname><given-names>JM</given-names></name></person-group><article-title>Local online learning in recurrent networks with random feedback</article-title><source>eLife</source><year>2019</year><volume>8</volume><elocation-id>e43299</elocation-id><pub-id pub-id-type="pmcid">PMC6561704</pub-id><pub-id pub-id-type="pmid">31124785</pub-id><pub-id pub-id-type="doi">10.7554/eLife.43299</pub-id></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cone</surname><given-names>I</given-names></name><name><surname>Shouval</surname><given-names>HZ</given-names></name></person-group><article-title>Behavioral Time Scale Plasticity of Place Fields: Mathematical Analysis</article-title><source>Front Comput Neurosci</source><year>2021</year><volume>15</volume><pub-id pub-id-type="pmcid">PMC7959845</pub-id><pub-id pub-id-type="pmid">33732128</pub-id><pub-id pub-id-type="doi">10.3389/fncom.2021.640235</pub-id></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>PY</given-names></name><name><surname>Roxin</surname><given-names>A</given-names></name></person-group><article-title>Rapid memory encoding in a recurrent network model with behavioral time scale synaptic plasticity</article-title><source>PLOS Comput Biol</source><year>2023</year><volume>19</volume><elocation-id>e1011139</elocation-id><pub-id pub-id-type="pmcid">PMC10484462</pub-id><pub-id pub-id-type="pmid">37624848</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1011139</pub-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>Y</given-names></name><name><surname>Maass</surname><given-names>W</given-names></name></person-group><article-title>A simple model for Behavioral Time Scale Synaptic Plasticity (BTSP) provides content addressable memory with binary synapses and one-shot learning</article-title><source>Nat Commun</source><year>2025</year><volume>16</volume><fpage>342</fpage><pub-id pub-id-type="pmcid">PMC11695864</pub-id><pub-id pub-id-type="pmid">39747916</pub-id><pub-id pub-id-type="doi">10.1038/s41467-024-55563-6</pub-id></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fukushima</surname><given-names>K</given-names></name></person-group><article-title>Cognitron: A self-organizing multilayered neural network</article-title><source>Biol Cybern</source><year>1975</year><volume>20</volume><fpage>121</fpage><lpage>136</lpage><pub-id pub-id-type="pmid">1203338</pub-id></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grossberg</surname><given-names>S</given-names></name></person-group><article-title>Adaptive pattern classification and universal recoding: I. Parallel development and coding of neural feature detectors</article-title><source>Biol Cybern</source><year>1976</year><volume>23</volume><fpage>121</fpage><lpage>134</lpage><pub-id pub-id-type="pmid">974165</pub-id></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kohonen</surname><given-names>T</given-names></name></person-group><article-title>Self-organized formation of topologically correct feature maps</article-title><source>Biol Cybern</source><year>1982</year><volume>43</volume><fpage>59</fpage><lpage>69</lpage></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rumelhart</surname><given-names>DE</given-names></name><name><surname>Zipser</surname><given-names>D</given-names></name></person-group><article-title>Feature Discovery by Competitive Learning</article-title><source>Cogn Sci</source><year>1985</year><volume>9</volume><fpage>75</fpage><lpage>112</lpage></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wallis</surname><given-names>G</given-names></name><name><surname>Rolls</surname><given-names>ET</given-names></name></person-group><article-title>INVARIANT FACE AND OBJECT RECOGNITION IN THE VISUAL SYSTEM</article-title><source>Prog Neurobiol</source><year>1997</year><volume>51</volume><fpage>167</fpage><lpage>194</lpage><pub-id pub-id-type="pmid">9247963</pub-id></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fritzke</surname><given-names>B</given-names></name></person-group><article-title>Growing cell structures—A self-organizing network for unsupervised and supervised learning</article-title><source>Neural Netw</source><year>1994</year><volume>7</volume><fpage>1441</fpage><lpage>1460</lpage></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ziv</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Long-term dynamics of CA1 hippocampal place codes</article-title><source>Nat Neurosci</source><year>2013</year><volume>16</volume><fpage>264</fpage><lpage>266</lpage><pub-id pub-id-type="pmcid">PMC3784308</pub-id><pub-id pub-id-type="pmid">23396101</pub-id><pub-id pub-id-type="doi">10.1038/nn.3329</pub-id></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geva</surname><given-names>N</given-names></name><name><surname>Deitch</surname><given-names>D</given-names></name><name><surname>Rubin</surname><given-names>A</given-names></name><name><surname>Ziv</surname><given-names>Y</given-names></name></person-group><article-title>Time and experience differentially affect distinct aspects of hippocampal representational drift</article-title><source>Neuron</source><year>2023</year><volume>111</volume><fpage>2357</fpage><lpage>2366</lpage><elocation-id>e5</elocation-id><pub-id pub-id-type="pmid">37315556</pub-id></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rubin</surname><given-names>A</given-names></name><etal/></person-group><article-title>Revealing neural correlates of behavior without behavioral measurements</article-title><source>Nat Commun</source><year>2019</year><volume>10</volume><fpage>4745</fpage><pub-id pub-id-type="pmcid">PMC6802184</pub-id><pub-id pub-id-type="pmid">31628322</pub-id><pub-id pub-id-type="doi">10.1038/s41467-019-12724-2</pub-id></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khona</surname><given-names>M</given-names></name><name><surname>Fiete</surname><given-names>IR</given-names></name></person-group><article-title>Attractor and integrator networks in the brain</article-title><source>Nat Rev Neurosci</source><year>2022</year><volume>23</volume><fpage>744</fpage><lpage>766</lpage><pub-id pub-id-type="pmid">36329249</pub-id></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Samsonovich</surname><given-names>A</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><article-title>Path Integration and Cognitive Mapping in a Continuous Attractor Neural Network Model</article-title><source>J Neurosci</source><year>1997</year><volume>17</volume><fpage>5900</fpage><lpage>5920</lpage><pub-id pub-id-type="pmcid">PMC6573219</pub-id><pub-id pub-id-type="pmid">9221787</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.17-15-05900.1997</pub-id></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rolls</surname><given-names>ET</given-names></name></person-group><article-title>An attractor network in the hippocampus: Theory and neurophysiology</article-title><source>Learn Mem</source><year>2007</year><volume>14</volume><fpage>714</fpage><lpage>731</lpage><pub-id pub-id-type="pmid">18007016</pub-id></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wills</surname><given-names>TJ</given-names></name><name><surname>Lever</surname><given-names>C</given-names></name><name><surname>Cacucci</surname><given-names>F</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name><name><surname>O’Keefe</surname><given-names>J</given-names></name></person-group><article-title>Attractor Dynamics in the Hippocampal Representation of the Local Environment</article-title><source>Science</source><year>2005</year><pub-id pub-id-type="pmcid">PMC2680068</pub-id><pub-id pub-id-type="pmid">15879220</pub-id><pub-id pub-id-type="doi">10.1126/science.1108905</pub-id></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsodyks</surname><given-names>M</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><article-title>Associative memory and hippocampal place cells</article-title><source>Int J Neural Syst</source><year>1995</year><volume>6</volume><fpage>81</fpage><lpage>86</lpage></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hopfield</surname><given-names>JJ</given-names></name></person-group><article-title>Neural networks and physical systems with emergent collective computational abilities</article-title><source>Proc Natl Acad Sci</source><year>1982</year><volume>79</volume><fpage>2554</fpage><lpage>2558</lpage><pub-id pub-id-type="pmcid">PMC346238</pub-id><pub-id pub-id-type="pmid">6953413</pub-id><pub-id pub-id-type="doi">10.1073/pnas.79.8.2554</pub-id></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abu-Mostafa</surname><given-names>Y</given-names></name><name><surname>Jacques</surname><given-names>J</given-names><prefix>St</prefix></name></person-group><article-title>Information capacity of the Hopfield model</article-title><source>IEEE Trans Inf Theory</source><year>1985</year><volume>31</volume><fpage>461</fpage><lpage>464</lpage></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Agmon</surname><given-names>H</given-names></name><name><surname>Burak</surname><given-names>Y</given-names></name></person-group><article-title>A theory of joint attractor dynamics in the hippocampus and the entorhinal cortex accounts for artificial remapping and grid cell field-to-field variability</article-title><source>eLife</source><year>2020</year><volume>9</volume><elocation-id>e56894</elocation-id><pub-id pub-id-type="pmcid">PMC7447444</pub-id><pub-id pub-id-type="pmid">32779570</pub-id><pub-id pub-id-type="doi">10.7554/eLife.56894</pub-id></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burak</surname><given-names>Y</given-names></name><name><surname>Fiete</surname><given-names>IR</given-names></name></person-group><article-title>Accurate Path Integration in Continuous Attractor Network Models of Grid Cells</article-title><source>PLOS Comput Biol</source><year>2009</year><volume>5</volume><elocation-id>e1000291</elocation-id><pub-id pub-id-type="pmcid">PMC2632741</pub-id><pub-id pub-id-type="pmid">19229307</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000291</pub-id></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ságodi</surname><given-names>Á</given-names></name><name><surname>Martín-Sánchez</surname><given-names>G</given-names></name><name><surname>Sokół</surname><given-names>P</given-names></name><name><surname>Park</surname><given-names>IM</given-names></name></person-group><article-title>Back to the Continuous Attractor</article-title><year>2024</year><pub-id pub-id-type="doi">10.48550/arXiv.2408.00109</pub-id></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Neunuebel</surname><given-names>JP</given-names></name><name><surname>Knierim</surname><given-names>JJ</given-names></name></person-group><article-title>CA3 Retrieves Coherent Representations from Degraded Input: Direct Evidence for CA3 Pattern Completion and Dentate Gyrus Pattern Separation</article-title><source>Neuron</source><year>2014</year><volume>81</volume><fpage>416</fpage><lpage>427</lpage><pub-id pub-id-type="pmcid">PMC3904133</pub-id><pub-id pub-id-type="pmid">24462102</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2013.11.017</pub-id></element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guzman</surname><given-names>SJ</given-names></name><name><surname>Schlögl</surname><given-names>A</given-names></name><name><surname>Frotscher</surname><given-names>M</given-names></name><name><surname>Jonas</surname><given-names>P</given-names></name></person-group><article-title>Synaptic mechanisms of pattern completion in the hippocampal CA3 network</article-title><source>Science</source><year>2016</year><volume>353</volume><fpage>1117</fpage><lpage>1123</lpage><pub-id pub-id-type="pmid">27609885</pub-id></element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Seung</surname><given-names>HS</given-names></name></person-group><chapter-title>Learning Continuous Attractors in Recurrent Networks</chapter-title><source>Advances in Neural Information Processing Systems</source><publisher-name>MIT Press</publisher-name><year>1997</year><volume>10</volume></element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Darshan</surname><given-names>R</given-names></name><name><surname>Rivkind</surname><given-names>A</given-names></name></person-group><article-title>Learning to represent continuous variables in heterogeneous neural networks</article-title><source>Cell Rep</source><year>2022</year><volume>39</volume><elocation-id>110612</elocation-id><pub-id pub-id-type="pmid">35385721</pub-id></element-citation></ref><ref id="R40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sussillo</surname><given-names>D</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name></person-group><article-title>Generating Coherent Patterns of Activity from Chaotic Neural Networks</article-title><source>Neuron</source><year>2009</year><volume>63</volume><fpage>544</fpage><lpage>557</lpage><pub-id pub-id-type="pmcid">PMC2756108</pub-id><pub-id pub-id-type="pmid">19709635</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2009.07.018</pub-id></element-citation></ref><ref id="R41"><label>41</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chandra</surname><given-names>S</given-names></name><name><surname>Sharma</surname><given-names>S</given-names></name><name><surname>Chaudhuri</surname><given-names>R</given-names></name><name><surname>Fiete</surname><given-names>I</given-names></name></person-group><article-title>Episodic and associative memory from spatial scaffolds in the hippocampus</article-title><source>Nature</source><year>2025</year><volume>638</volume><fpage>739</fpage><lpage>751</lpage><pub-id pub-id-type="pmid">39814883</pub-id></element-citation></ref><ref id="R42"><label>42</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Magó</surname><given-names>Á</given-names></name><name><surname>Kis</surname><given-names>N</given-names></name><name><surname>Lükő</surname><given-names>B</given-names></name><name><surname>Makara</surname><given-names>JK</given-names></name></person-group><article-title>Distinct dendritic Ca2+ spike forms produce opposing input-output transformations in rat CA3 pyramidal cells</article-title><source>eLife</source><year>2021</year><volume>10</volume><elocation-id>e74493</elocation-id><pub-id pub-id-type="pmcid">PMC8612760</pub-id><pub-id pub-id-type="pmid">34817378</pub-id><pub-id pub-id-type="doi">10.7554/eLife.74493</pub-id></element-citation></ref><ref id="R43"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raus Balind</surname><given-names>S</given-names></name><etal/></person-group><article-title>Diverse synaptic and dendritic mechanisms of complex spike burst generation in hippocampal CA3 pyramidal cells</article-title><source>Nat Commun</source><year>2019</year><volume>10</volume><fpage>1859</fpage><pub-id pub-id-type="pmcid">PMC6478939</pub-id><pub-id pub-id-type="pmid">31015414</pub-id><pub-id pub-id-type="doi">10.1038/s41467-019-09767-w</pub-id></element-citation></ref><ref id="R44"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tapson</surname><given-names>J</given-names></name><name><surname>van Schaik</surname><given-names>A</given-names></name></person-group><article-title>Learning the pseudoinverse solution to network weights</article-title><source>Neural Netw</source><year>2013</year><volume>45</volume><fpage>94</fpage><lpage>100</lpage><pub-id pub-id-type="pmid">23541926</pub-id></element-citation></ref><ref id="R45"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taxidis</surname><given-names>J</given-names></name><etal/></person-group><article-title>Differential Emergence and Stability of Sensory and Temporal Representations in Context-Specific Hippocampal Sequences</article-title><source>Neuron</source><year>2020</year><volume>108</volume><fpage>984</fpage><lpage>998</lpage><elocation-id>e9</elocation-id><pub-id pub-id-type="pmcid">PMC7736335</pub-id><pub-id pub-id-type="pmid">32949502</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2020.08.028</pub-id></element-citation></ref><ref id="R46"><label>46</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kingma</surname><given-names>DP</given-names></name><name><surname>Ba</surname><given-names>J</given-names></name></person-group><article-title>Adam: A Method for Stochastic Optimization</article-title><year>2017</year><pub-id pub-id-type="doi">10.48550/arXiv.1412.6980</pub-id></element-citation></ref><ref id="R47"><label>47</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>S</given-names></name><name><surname>Seay</surname><given-names>M</given-names></name><name><surname>Taxidis</surname><given-names>J</given-names></name><name><surname>Golshani</surname><given-names>P</given-names></name><name><surname>Buonomano</surname><given-names>DV</given-names></name></person-group><article-title>Multiplexing working memory and time in the trajectories of neural networks</article-title><source>Nat Hum Behav</source><year>2023</year><volume>7</volume><fpage>1170</fpage><lpage>1184</lpage><pub-id pub-id-type="pmcid">PMC10913811</pub-id><pub-id pub-id-type="pmid">37081099</pub-id><pub-id pub-id-type="doi">10.1038/s41562-023-01592-y</pub-id></element-citation></ref><ref id="R48"><label>48</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Priestley</surname><given-names>JB</given-names></name><name><surname>Bowler</surname><given-names>JC</given-names></name><name><surname>Rolotti</surname><given-names>SV</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name><name><surname>Losonczy</surname><given-names>A</given-names></name></person-group><article-title>Signatures of rapid plasticity in hippocampal CA1 representations during novel experiences</article-title><source>Neuron</source><year>2022</year><volume>110</volume><fpage>1978</fpage><lpage>1992</lpage><elocation-id>e6</elocation-id><pub-id pub-id-type="pmcid">PMC9233041</pub-id><pub-id pub-id-type="pmid">35447088</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2022.03.026</pub-id></element-citation></ref><ref id="R49"><label>49</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Pascanu</surname><given-names>R</given-names></name><name><surname>Mikolov</surname><given-names>T</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name></person-group><source>On the difficulty of training recurrent neural networks</source><conf-name>Proceedings of the 30th International Conference on Machine Learning</conf-name><series>PMLR</series><year>2013</year><fpage>1310</fpage><lpage>1318</lpage></element-citation></ref><ref id="R50"><label>50</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Simard</surname><given-names>P</given-names></name><name><surname>Frasconi</surname><given-names>P</given-names></name></person-group><article-title>Learning long-term dependencies with gradient descent is difficult</article-title><source>IEEE Trans Neural Netw</source><year>1994</year><volume>5</volume><fpage>157</fpage><lpage>166</lpage><pub-id pub-id-type="pmid">18267787</pub-id></element-citation></ref><ref id="R51"><label>51</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hochreiter</surname><given-names>S</given-names></name><name><surname>Schmidhuber</surname><given-names>J</given-names></name></person-group><article-title>Long short-term memory</article-title><source>Neural Comput</source><year>1997</year><volume>9</volume><fpage>1735</fpage><lpage>1780</lpage><pub-id pub-id-type="pmid">9377276</pub-id></element-citation></ref><ref id="R52"><label>52</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whittington</surname><given-names>JCR</given-names></name><name><surname>McCaffary</surname><given-names>D</given-names></name><name><surname>Bakermans</surname><given-names>JJW</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name></person-group><article-title>How to build a cognitive map: insights from models of the hippocampal formation</article-title><year>2022</year><comment>Preprint at <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2202.01682">http://arxiv.org/abs/2202.01682</ext-link></comment></element-citation></ref><ref id="R53"><label>53</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stachenfeld</surname><given-names>KL</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name></person-group><article-title>The hippocampus as a predictive map</article-title><source>Nat Neurosci</source><year>2017</year><volume>20</volume><fpage>1643</fpage><lpage>1653</lpage><pub-id pub-id-type="pmid">28967910</pub-id></element-citation></ref><ref id="R54"><label>54</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behrens</surname><given-names>TEJ</given-names></name><etal/></person-group><article-title>What Is a Cognitive Map? Organizing Knowledge for Flexible Behavior</article-title><source>Neuron</source><year>2018</year><volume>100</volume><fpage>490</fpage><lpage>509</lpage><pub-id pub-id-type="pmid">30359611</pub-id></element-citation></ref><ref id="R55"><label>55</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vaidya</surname><given-names>SP</given-names></name><name><surname>Li</surname><given-names>G</given-names></name><name><surname>Chitwood</surname><given-names>RA</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Magee</surname><given-names>JC</given-names></name></person-group><article-title>Formation of an expanding memory representation in the hippocampus</article-title><source>Nat Neurosci</source><year>2025</year><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="pmid">40467863</pub-id></element-citation></ref><ref id="R56"><label>56</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qian</surname><given-names>FK</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Magee</surname><given-names>JC</given-names></name></person-group><article-title>Mechanisms of experience-dependent place-cell referencing in hippocampal area CA1</article-title><source>Nat Neurosci</source><year>2025</year><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="pmid">40169932</pub-id></element-citation></ref><ref id="R57"><label>57</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kohonen</surname><given-names>T</given-names></name></person-group><article-title>Essentials of the self-organizing map</article-title><source>Neural Netw</source><year>2013</year><volume>37</volume><fpage>52</fpage><lpage>65</lpage><pub-id pub-id-type="pmid">23067803</pub-id></element-citation></ref><ref id="R58"><label>58</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geiller</surname><given-names>T</given-names></name><etal/></person-group><article-title>Local circuit amplification of spatial selectivity in the hippocampus</article-title><source>Nature</source><year>2021</year><fpage>1</fpage><lpage>5</lpage><pub-id pub-id-type="pmcid">PMC9746172</pub-id><pub-id pub-id-type="pmid">34853473</pub-id><pub-id pub-id-type="doi">10.1038/s41586-021-04169-9</pub-id></element-citation></ref><ref id="R59"><label>59</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McKenzie</surname><given-names>S</given-names></name><etal/></person-group><article-title>Preexisting hippocampal network dynamics constrain optogenetically induced place fields</article-title><source>Neuron</source><year>2021</year><volume>109</volume><fpage>1040</fpage><lpage>1054</lpage><elocation-id>e7</elocation-id><pub-id pub-id-type="pmcid">PMC8095399</pub-id><pub-id pub-id-type="pmid">33539763</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2021.01.011</pub-id></element-citation></ref><ref id="R60"><label>60</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kappel</surname><given-names>D</given-names></name><name><surname>Nessler</surname><given-names>B</given-names></name><name><surname>Maass</surname><given-names>W</given-names></name></person-group><article-title>STDP Installs in Winner-Take-All Circuits an Online Approximation to Hidden Markov Model Learning</article-title><source>PLOS Comput Biol</source><year>2014</year><volume>10</volume><elocation-id>e1003511</elocation-id><pub-id pub-id-type="pmcid">PMC3967926</pub-id><pub-id pub-id-type="pmid">24675787</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003511</pub-id></element-citation></ref><ref id="R61"><label>61</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>W</given-names></name><etal/></person-group><article-title>Learning produces an orthogonalized state machine in the hippocampus</article-title><source>Nature</source><year>2025</year><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="pmcid">PMC11964937</pub-id><pub-id pub-id-type="pmid">39939774</pub-id><pub-id pub-id-type="doi">10.1038/s41586-024-08548-w</pub-id></element-citation></ref><ref id="R62"><label>62</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>George</surname><given-names>D</given-names></name><etal/></person-group><article-title>Clone-structured graph representations enable flexible learning and vicarious evaluation of cognitive maps</article-title><source>Nat Commun</source><year>2021</year><volume>12</volume><fpage>2392</fpage><pub-id pub-id-type="pmcid">PMC8062558</pub-id><pub-id pub-id-type="pmid">33888694</pub-id><pub-id pub-id-type="doi">10.1038/s41467-021-22559-5</pub-id></element-citation></ref><ref id="R63"><label>63</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arjovsky</surname><given-names>M</given-names></name><name><surname>Shah</surname><given-names>A</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name></person-group><article-title>Unitary Evolution Recurrent Neural Networks</article-title><year>2016</year><pub-id pub-id-type="doi">10.48550/arXiv.1511.06464</pub-id></element-citation></ref><ref id="R64"><label>64</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Le</surname><given-names>QV</given-names></name><name><surname>Jaitly</surname><given-names>N</given-names></name><name><surname>Hinton</surname><given-names>GE</given-names></name></person-group><article-title>A Simple Way to Initialize Recurrent Networks of Rectified Linear Units</article-title><year>2015</year><pub-id pub-id-type="doi">10.48550/arXiv.1504.00941</pub-id></element-citation></ref><ref id="R65"><label>65</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Henaff</surname><given-names>M</given-names></name><name><surname>Szlam</surname><given-names>A</given-names></name><name><surname>LeCun</surname><given-names>Y</given-names></name></person-group><source>Recurrent Orthogonal Networks and Long-Memory Tasks</source><conf-name>Proceedings of The 33rd International Conference on Machine Learning</conf-name><series>PMLR</series><year>2016</year><fpage>2034</fpage><lpage>2042</lpage></element-citation></ref><ref id="R66"><label>66</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cone</surname><given-names>I</given-names></name><name><surname>Clopath</surname><given-names>C</given-names></name></person-group><article-title>Latent representations in hippocampal network model co-evolve with behavioral exploration of task structure</article-title><source>Nat Commun</source><year>2024</year><volume>15</volume><fpage>687</fpage><pub-id pub-id-type="pmcid">PMC10806076</pub-id><pub-id pub-id-type="pmid">38263408</pub-id><pub-id pub-id-type="doi">10.1038/s41467-024-44871-6</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>Generalized BTSP recovers experimentally observed plasticity kernels</title><p><bold>(a-c)</bold> Schematics of different BTSP induction setups. <bold>a)</bold> A single plateau occurs in a postsynaptic neuron, and a single spike occurs in presynaptic neuron. Weight changes Δ<italic>W</italic> depend on some function of the relative time between the plateau and the presynaptic spike. <bold>b)</bold> A single plateau occurs in a postsynaptic neuron at <italic>t<sub>plateau</sub></italic>, but now presynaptic neurons have some activity <italic>x<sub>j</sub></italic>(<italic>t</italic>). Weight changes Δ<italic>W</italic> can be described as some function of the weight kernel and presynaptic activity. <bold>c)</bold> Potentially continuous plateau activity <italic>P<sub>i</sub></italic>(<italic>t</italic>) occurs in the postsynaptic population. The resulting plasticity (“generalized BTSP” or “gBTSP”) depends on the weight kernel, presynaptic activity, and the postsynaptic plateau activity. <bold>d)</bold> Left, the kernel in our model uses two decaying exponentials, each with a different time constant. Right, the experimentally observed kernel, reprinted with permission from Bittner et al. 20172; copyright AAAS. <bold>e)</bold> Left, the Δ<italic>W</italic> in our model when using the weight kernel from panel d) and a set of place fields (putatively from CA3) as presynaptic inputs. Right, observed Δ<italic>W</italic> in vivo, reprinted with permission from Milstein et al. 2021<sup><xref ref-type="bibr" rid="R1">1</xref></sup>; CC BY 4.0.</p></caption><graphic xlink:href="EMS206468-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Competitive learning via gBTSP allows for one-shot formation of fields which tile the input space</title><p><bold>a)</bold> Modelled inputs from CA3 project to our model CA1 neurons through weights <italic>W<sub>ij</sub></italic>. A plateau fires at a random postsynaptic neuron when the sum of postsynaptic activity is below some threshold <italic>θ</italic>. <bold>b)</bold> For this task setup, inputs are drawn from a simulated agent running along a 1D treadmill. <bold>c)</bold> The learned fields across the population uniformly tile the 1D space. <bold>d)</bold> Using this plateau condition, single cells develop and translocate fields in a one-shot manner. For this particular unit, two plateau events occurred during training. <bold>e)</bold> The probability of a plateau event (blue line) peaks upon introduction to the novel environment, before decreasing to a baseline rate once a sufficient map has been learned. This time course is inverse to the total network activity (orange line). <bold>f)</bold> The baseline rate of plateau events (due to noise) causes representational drift. Blue, cosine similarity between unsorted network activity at the current lap and unsorted network activity at lap 10. Orange, cosine similarity between sorted network activity at the current lap and sorted activity at lap 10. Both measures peak at lap 10 because the cosine similarity of the activity at lap 10 with itself is 1. <bold>g)</bold> For this task setup, inputs are drawn from a simulated agent randomly exploring a 2D box. <bold>h)</bold> In a 2D environment, single fields still develop and translocate rapidly. <bold>i)</bold> Sum of neural activity for a trial where the agent explores the entire 2D environment. The learned latent representation covers the extent of the box.</p></caption><graphic xlink:href="EMS206468-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Building an attractor network via gBTSP.</title><p><bold>a)</bold> A set of spatially tuned noisy inputs are drawn from a simulated agent running along a 1D treadmill. These inputs project to “visible” neurons through a set of input weights. Visible neurons project to “seed” neurons via encoding weights, and seed neurons project back to visible neurons through decoding weights. There are no recurrent weights within each layer. This produces an effective recurrent weight matrix <bold>W<sup>rec</sup> = W<sup>e</sup>W<sup>d</sup></bold>. A plateau fires at a random seed neuron when the sum of postsynaptic activity is below some threshold <italic>θ.</italic> <bold>b)</bold> Plateau events create seed neurons which are sensitive to certain combinations of visible neurons. <bold>c)</bold> The effective recurrent weight matrix, <bold>W<sup>rec</sup></bold>, forms a ring attractor, as viewed in the first two principal components. Each of the nodes along the attractor is a fixed point created by a plateau event. <bold>d)</bold> Partial inputs given to the network for a single timestep at times 0,2,4,6, and 8 seconds recover a memory state of the network, which persists until the next partial input is presented.</p></caption><graphic xlink:href="EMS206468-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Feed-forward network rapidly acquires task via supervised gBTSP.</title><p><bold>a)</bold> Feed-forward network with inputs <italic>x<sub>j</sub></italic>(<italic>t</italic>) project to output <italic>y</italic>(<italic>t</italic>) via weights <italic>W<sub>j</sub></italic>. The inputs <italic>x<sub>j</sub></italic>(<italic>t</italic>) are spatially selective and represent an animal running along a 1D track. <bold>b)</bold> A unimodal gaussian target function (dotted black line) and the trained output (blue line) after the first 10 trials of gBTSP training. <bold>c)</bold> Top, the plateau function <italic>P</italic>(<italic>t</italic>) over the first 10 trials of training. Middle, the output <italic>y</italic>(<italic>t</italic>) over the first 10 trials of training. Bottom, the output activity <italic>y</italic>(<italic>t</italic>) over the first 10 trials of training. <bold>d)</bold> A two-layer network with inputs <italic>x<sub>k</sub></italic>(<italic>t</italic>) hidden units <italic>h<sub>j</sub></italic>(<italic>t</italic>), and 2D output <italic>y<sub>i</sub></italic>(<italic>t</italic>) which represents location. The target trajectory moves in a set 2D path each trial, and the network must learn to track the target. <bold>e)</bold> The target path (dotted black line), and the learned path (colored line). The color here represents the time at which the agent is in a given location. <bold>f)</bold> Plateau function for the first unit in the hidden layer, <italic>P</italic><sub>1</sub>(<italic>t</italic>), over the first 10 trials of training. <bold>g)</bold> Task performance (proportional to 1 - <italic>ε<sub>i</sub></italic>(<italic>t</italic>)) and plateau probability over the first 10 trials of training.</p></caption><graphic xlink:href="EMS206468-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>Learning a complex recurrent task with gBTSP requires slow and precise credit assignment</title><p><bold>a)</bold> Simulated agents are trained on a delayed-non-match-to-sample (DNMS) task where they must distinguish between sequential “odor” pairs. The agent must learn to “lick” for non-matching sequences (AB, BA), and refrain from licking for matching sequences (AA,BB). Right, the model consists of a recurrent network with two odor inputs, hidden activities <bold>x(t)</bold> and recurrent weights <bold>W</bold>. The hidden units project to an output <bold>y(t)</bold> via weights <bold>V</bold>. Recurrent weights <bold>W</bold> are trained via plateaus occurring in the hidden units according to our gBTSP algorithm (see <xref ref-type="sec" rid="S10">Methods</xref>). Output weights are trained via the delta rule. <bold>b)</bold> After training, the model output has learned to lick following odor 2 in the AB/BA trials while refraining from licking in the AA/BB trials. <bold>c)</bold> Mean squared error (MSE) decreases over training, demonstrating successful learning, albeit across tens of thousands of trials. <bold>d)</bold> Neural activity patterns across all 100 neurons, averaged over trials which began with odor A (left column), or odor B (right column). The neurons are sorted by time of maximum activity in the odor A trials (top row), or time of maximum activity in odor B trials (bottom row). The activity maps reveal the network has learned distinct sequences of activity for the initial odors, thereby forming a working memory of the first odor’s identity. <bold>e)</bold> Activity of each trial type (odor A or odor B), projected onto the first 3 principal components of the total activity space after training. For variance explained, see (<xref ref-type="supplementary-material" rid="SD1">Supplemental Figure 3</xref>). <bold>f)</bold> Single-trial plateau events across neurons and time, showing sparse activation. <bold>g)</bold> Evolution of activity for a representative single unit during AA trials over training. The final neural tuning slowly develops over many thousands of trials. <bold>h)</bold> Activity of the same representative unit at t = 5 seconds, across AA trials, again highlighting gradual field development.</p></caption><graphic xlink:href="EMS206468-f005"/></fig><fig id="F6" position="float"><label>Figure 6</label><caption><title>Shallow losses are required for few-shot learning</title><p><bold>a)</bold> Red, an arbitrary loss function <inline-formula><mml:math id="M63"><mml:mrow><mml:mi>ℒ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> which depends on the network state, <italic>x</italic>. In order to learn, the network is restricted to make discrete jumps of size Δ<italic>x</italic>. Blue dotted circles, previous values of <inline-formula><mml:math id="M64"><mml:mrow><mml:mi>ℒ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Filled blue circle, current value of <inline-formula><mml:math id="M65"><mml:mrow><mml:mi>ℒ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> Top middle, smaller discrete jumps of size δ<italic>x</italic> are sufficient to reach our learning objective, but results in a slow evolution of network activity over learning (“dough” learning, right). Bottom middle, stretching the loss function also allows us to reach our learning objective, while maintaining a fixed step size Δ<italic>x</italic>. Single unit activities rapidly change over the course of learning, even if the population representation evolves slowly (“popcorn” learning). This stretching picture requires a shallow but non-zero curvature (right). <bold>b)</bold> Shallow feed-forward network, and its associated curvature. <bold>c)</bold> Deep feed-forward network, with L layers, and its associated curvature. <bold>d)</bold> Recurrent network which runs for T timesteps, and its associated curvature. Note that this picture can be related to that of the deep feed-forward network, if we imagine each “layer” to be the activity of the recurrent net at a time t, and the weights between these layers to be the shared weight matrix W.</p></caption><graphic xlink:href="EMS206468-f006"/></fig><table-wrap id="T1" position="float" orientation="portrait"><label>Table 1</label><caption><title>Model Parameters</title></caption><table frame="box" rules="all"><thead><tr><th align="left" valign="top">Parameter</th><th align="left" valign="top">Value</th><th align="left" valign="top">Units</th><th align="left" valign="top">Description</th></tr></thead><tbody><tr><td align="center" valign="top"><bold><italic>T</italic></bold></td><td align="left" valign="top">200</td><td align="left" valign="top">dt</td><td align="left" valign="top">Total timesteps</td></tr><tr><td align="center" valign="top"><bold><italic>dt</italic></bold></td><td align="left" valign="top">50</td><td align="left" valign="top">ms</td><td align="left" valign="top">Timestep</td></tr><tr><td align="center" valign="top"><bold><italic>τ<sub>b</sub></italic></bold></td><td align="left" valign="top">1.31</td><td align="left" valign="top">s</td><td align="left" valign="top">“Backwards” kernel time constant</td></tr><tr><td align="center" valign="top"><bold><italic>τ<sub>f</sub></italic></bold></td><td align="left" valign="top">0.69</td><td align="left" valign="top">s</td><td align="left" valign="top">“Forwards” kernel time constant</td></tr><tr><td align="center" valign="top"><bold><italic>λ</italic></bold></td><td align="left" valign="top">1</td><td align="left" valign="top">-</td><td align="left" valign="top">Weight constant</td></tr><tr><td align="center" valign="top"><bold>Δ<italic>t</italic></bold></td><td align="left" valign="top">5</td><td align="left" valign="top">s</td><td align="left" valign="top">Time window of integration around plateau</td></tr><tr><td align="center" valign="top"><bold>γ</bold></td><td align="left" valign="top">10</td><td align="left" valign="top">-</td><td align="left" valign="top">Constant input, to go from Δ<italic>W</italic> to Δ<italic>V</italic> (<xref ref-type="fig" rid="F1">Figure 1</xref>)</td></tr><tr><td align="center" valign="top"><bold>σ</bold></td><td align="left" valign="top">0.075</td><td align="left" valign="top">s</td><td align="left" valign="top">Standard deviation of input Gaussians</td></tr><tr><td align="center" valign="top"><bold>θ</bold></td><td align="left" valign="top">8</td><td align="left" valign="top">-</td><td align="left" valign="top">Threshold for plateau event (<xref ref-type="fig" rid="F2">Figure 2</xref>)</td></tr><tr><td align="center" valign="top"><bold><italic>N<sub>input</sub></italic></bold></td><td align="left" valign="top">200</td><td align="left" valign="top">-</td><td align="left" valign="top">Number of input neurons</td></tr><tr><td align="center" valign="top"><bold><italic>N<sub>output</sub></italic></bold></td><td align="left" valign="top">81</td><td align="left" valign="top">-</td><td align="left" valign="top">Number of output neurons</td></tr><tr><td align="center" valign="top"><bold>η</bold></td><td align="left" valign="top">0.95</td><td align="left" valign="top">-</td><td align="left" valign="top">Learning rate (<xref ref-type="fig" rid="F2">Figure 2</xref>)</td></tr><tr><td align="center" valign="top"><bold>σ<sub>η</sub></bold></td><td align="left" valign="top"><inline-formula><mml:math id="M66"><mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>35</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula></td><td align="left" valign="top">-</td><td align="left" valign="top">Noise, output neuron activity</td></tr><tr><td align="center" valign="top"><bold><italic>L</italic></bold></td><td align="left" valign="top">100</td><td align="left" valign="top">cm</td><td align="left" valign="top">Box side length</td></tr><tr><td align="center" valign="top"><bold>σ<sub>w</sub></bold></td><td align="left" valign="top"><inline-formula><mml:math id="M67"><mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula></td><td align="left" valign="top">cm</td><td align="left" valign="top">Random walk updates (2D)</td></tr><tr><td align="center" valign="top"><bold>ϑ</bold></td><td align="left" valign="top">0.15</td><td align="left" valign="top">-</td><td align="left" valign="top">Threshold for plotting neural activity (<xref ref-type="fig" rid="F2">Figure 2i</xref>)</td></tr><tr><td align="center" valign="top"><bold><italic>N<sub>seed</sub></italic></bold></td><td align="left" valign="top">81</td><td align="left" valign="top">-</td><td align="left" valign="top">Number of seed neurons</td></tr><tr><td align="center" valign="top"><bold><italic>N<sub>visible</sub></italic></bold></td><td align="left" valign="top">100</td><td align="left" valign="top">-</td><td align="left" valign="top">Number of visible neurons</td></tr><tr><td align="center" valign="top"><bold>θ</bold></td><td align="left" valign="top">.6</td><td align="left" valign="top">-</td><td align="left" valign="top">Threshold for plateau event (<xref ref-type="fig" rid="F3">Figure 3</xref>)</td></tr><tr><td align="center" valign="top"><bold>η</bold></td><td align="left" valign="top">0.3</td><td align="left" valign="top">-</td><td align="left" valign="top">Learning rate (<xref ref-type="fig" rid="F3">Figure 3</xref>)</td></tr><tr><td align="center" valign="top"><bold>W<sup>in</sup></bold></td><td align="left" valign="top"><inline-formula><mml:math id="M68"><mml:mi mathvariant="double-struck">I</mml:mi></mml:math></inline-formula></td><td align="left" valign="top">-</td><td align="left" valign="top">Input weights (<xref ref-type="fig" rid="F3">Figure 3</xref>)</td></tr><tr><td align="center" valign="top"><bold>C</bold></td><td align="left" valign="top">2.71</td><td align="left" valign="top">-</td><td align="left" valign="top">Constant for gating term</td></tr><tr><td align="center" valign="top"><bold><italic>N<sub>input</sub></italic></bold></td><td align="left" valign="top">100</td><td align="left" valign="top">-</td><td align="left" valign="top">Number of input neurons (<xref ref-type="fig" rid="F4">Figure 4</xref>)</td></tr><tr><td align="center" valign="top"><bold><italic>N<sub>inter</sub></italic></bold></td><td align="left" valign="top">10</td><td align="left" valign="top">-</td><td align="left" valign="top">Number of hidden neurons (<xref ref-type="fig" rid="F4">Figure 4</xref>, fixation task only)</td></tr><tr><td align="center" valign="top"><bold><italic>N<sub>output</sub></italic></bold></td><td align="left" valign="top">1, 2</td><td align="left" valign="top">-</td><td align="left" valign="top">Number of output units (<xref ref-type="fig" rid="F4">Figure 4</xref>, place cell task, fixation task)</td></tr><tr><td align="center" valign="top"><bold><italic>T</italic></bold></td><td align="left" valign="top">100</td><td align="left" valign="top">dt</td><td align="left" valign="top">Total timesteps (<xref ref-type="fig" rid="F5">Figure 5</xref>)</td></tr><tr><td align="center" valign="top"><bold><italic>τ<sub>net</sub></italic></bold></td><td align="left" valign="top">10</td><td align="left" valign="top">dt</td><td align="left" valign="top">Network time constant (<xref ref-type="fig" rid="F5">Figure 5</xref>)</td></tr><tr><td align="center" valign="top"><bold><italic>N<sub>input</sub></italic></bold></td><td align="left" valign="top">2</td><td align="left" valign="top">-</td><td align="left" valign="top">Number of input neurons (<xref ref-type="fig" rid="F5">Figure 5</xref>)</td></tr><tr><td align="center" valign="top"><bold><italic>N<sub>rec</sub></italic></bold></td><td align="left" valign="top">100</td><td align="left" valign="top">-</td><td align="left" valign="top">Number of recurrent neurons (<xref ref-type="fig" rid="F5">Figure 5</xref>)</td></tr><tr><td align="center" valign="top"><bold><italic>N<sub>output</sub></italic></bold></td><td align="left" valign="top">2</td><td align="left" valign="top">-</td><td align="left" valign="top">Number of output neurons (<xref ref-type="fig" rid="F5">Figure 5</xref>)</td></tr><tr><td align="center" valign="top"><bold>g</bold></td><td align="left" valign="top">.85</td><td align="left" valign="top">-</td><td align="left" valign="top">Gain, recurrent weight initialization (<xref ref-type="fig" rid="F5">Figure 5</xref>)</td></tr><tr><td align="center" valign="top"><bold>η</bold></td><td align="left" valign="top">0.01</td><td align="left" valign="top">-</td><td align="left" valign="top">Learning rate, ADAM (<xref ref-type="fig" rid="F5">Figure 5</xref>)</td></tr><tr><td align="center" valign="top"><bold><italic>β<sub>1</sub></italic></bold></td><td align="left" valign="top">0.9</td><td align="left" valign="top">-</td><td align="left" valign="top">Decay rate for first moment estimate in output weights, ADAM (<xref ref-type="fig" rid="F5">Figure 5</xref>)</td></tr><tr><td align="center" valign="top"><bold><italic>β<sub>2</sub></italic></bold></td><td align="left" valign="top">0.99</td><td align="left" valign="top">-</td><td align="left" valign="top">Decay rate for second moment estimate in output weights, ADAM (<xref ref-type="fig" rid="F5">Figure 5</xref>)</td></tr><tr><td align="center" valign="top"><bold><italic>β<sub>1,rec</sub></italic></bold></td><td align="left" valign="top">0.999</td><td align="left" valign="top">-</td><td align="left" valign="top">Decay rate for first moment estimate in recurrent weights, ADAM (<xref ref-type="fig" rid="F5">Figure 5</xref>)</td></tr><tr><td align="center" valign="top"><bold><italic>β<sub>2,rec</sub></italic></bold></td><td align="left" valign="top">0.9999</td><td align="left" valign="top">-</td><td align="left" valign="top">Decay rate for second moment estimate in recurrent weights, ADAM (<xref ref-type="fig" rid="F5">Figure 5</xref>)</td></tr><tr><td align="center" valign="top"><bold><italic>ε</italic></bold></td><td align="left" valign="top">10<sup>-8</sup></td><td align="left" valign="top">-</td><td align="left" valign="top">Constant to avoid division by zero, ADAM (<xref ref-type="fig" rid="F5">Figure 5</xref>)</td></tr></tbody></table></table-wrap></floats-group></article>