<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS206955</article-id><article-id pub-id-type="doi">10.1101/2025.06.16.659971</article-id><article-id pub-id-type="archive">PPR1037438</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">1</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Predisposed and learned preferences for multipoint visual statistics in visually naïve newly hatched chicks</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Zanon</surname><given-names>Mirko</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="fn" rid="FN1">*</xref></contrib><contrib contrib-type="author"><name><surname>Lemaire</surname><given-names>Bastien S.</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="fn" rid="FN1">*</xref></contrib><contrib contrib-type="author"><name><surname>Piasini</surname><given-names>Eugenio</given-names></name><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Caramellino</surname><given-names>Riccardo</given-names></name><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A4">4</xref></contrib><contrib contrib-type="author"><name><surname>Nallet</surname><given-names>Caroline</given-names></name><xref ref-type="aff" rid="A5">5</xref></contrib><contrib contrib-type="author"><name><surname>Balasubramanian</surname><given-names>Vijay</given-names></name><xref ref-type="aff" rid="A3">3</xref><xref ref-type="aff" rid="A6">6</xref></contrib><contrib contrib-type="author"><name><surname>Gervain</surname><given-names>Judit</given-names></name><xref ref-type="aff" rid="A5">5</xref><xref ref-type="aff" rid="A7">7</xref><xref ref-type="aff" rid="A8">8</xref></contrib><contrib contrib-type="author"><name><surname>Zoccolan</surname><given-names>Davide</given-names></name><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Vallortigara</surname><given-names>Giorgio</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib></contrib-group><aff id="A1"><label>1</label>Center for Mind/Brain Sciences, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/05trd4x28</institution-id><institution>University of Trento</institution></institution-wrap>, <city>Rovereto</city>, <country country="IT">Italy</country></aff><aff id="A2"><label>2</label>Neuroscience area, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/004fze387</institution-id><institution>International School for Advanced Studies (SISSA)</institution></institution-wrap>, <city>Trieste</city>, <country country="IT">Italy</country></aff><aff id="A3"><label>3</label>Computational Neuroscience Initiative, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/00b30xv10</institution-id><institution>University of Pennsylvania</institution></institution-wrap>, <city>Philadelphia</city>, <country country="US">United States</country></aff><aff id="A4"><label>4</label>Department of Medicine, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/022fs9h90</institution-id><institution>University of Fribourg</institution></institution-wrap>, <city>Fribourg</city>, <country country="CH">Switzerland</country></aff><aff id="A5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02fgakj19</institution-id><institution>Integrative Neuroscience and Cognition Center</institution></institution-wrap>, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/05f82e368</institution-id><institution>Université Paris Cité</institution></institution-wrap> &amp; <institution-wrap><institution-id institution-id-type="ror">https://ror.org/02feahw73</institution-id><institution>CNRS</institution></institution-wrap>, <city>Paris</city>, <country country="FR">France</country></aff><aff id="A6"><label>6</label>Rudolf Peierls Centre for Theoretical Physics, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>University of Oxford</institution></institution-wrap>, <city>Oxford</city>, <country country="GB">UK</country></aff><aff id="A7"><label>7</label>Department of Developmental and Social Psychology, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/00240q980</institution-id><institution>University of Padua</institution></institution-wrap>, <city>Padua</city>, <country country="IT">Italy</country></aff><aff id="A8"><label>8</label>Padova Neuroscience Center, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/00240q980</institution-id><institution>University of Padua</institution></institution-wrap>, <city>Padua</city>, <country country="IT">Italy</country></aff><author-notes><corresp id="CR1">Correspondence to: <email>mirko.zanon@unitn.it</email>; <email>giorgio.vallortigara@unitn.it</email></corresp><fn id="FN1"><label>*</label><p id="P1">The two authors share first authorship</p></fn></author-notes><pub-date pub-type="nihms-submitted"><day>11</day><month>07</month><year>2025</year></pub-date><pub-date pub-type="preprint"><day>17</day><month>06</month><year>2025</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nd/4.0/">CC BY-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P2">Recent studies have revealed that human and non-human animals (rats) can detect luminance distribution and correlations between pixels in an image (ranging from 2-point to 4-point). This sensitivity is believed to stem from optimization processes in the visual system that operate through efficient coding mechanisms to extract the most informative image statistics from the environment. However, it is yet to be determined whether this optimization is evolutionarily given by inborn mechanisms or shaped by visual experience. Here we report that newly-hatched visually naïve domestic chicks spontaneously prefer to approach luminance, 2-point and 4-point correlation patterns (respectively, horizontal lines and rectangular patterns), while showing no preference for 3-point correlation over white noise controls. This parallels the ranking observed in adult humans and rats, thus suggesting that evolutionarily given biological predispositions largely drive efficient coding of natural images. We also found that learning by exposure to visual stimuli, as occurs naturally during visual imprinting, induced a preference for white noise over point correlation patterns in chicks exposed to 3- and 4-point patterns. We hypothesize that this behavior could reflect chicks’ preference for stimuli of lower statistical complexity.</p></abstract><kwd-group><kwd>Efficient coding</kwd><kwd>Image statistics</kwd><kwd>Multipoint correlation</kwd><kwd>Imprinting</kwd><kwd>Innate predisposition</kwd></kwd-group></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P3">A prominent theory in the field of systems neuroscience is that sensory systems have evolved to efficiently encode the structure of the natural world. According to the hypothesis of efficient coding, neuronal tuning is shaped by the need to optimally encode the statistical structure of input signals(<xref ref-type="bibr" rid="R1">1</xref>–<xref ref-type="bibr" rid="R6">6</xref>). In vision, this means that our perception should be specifically tuned to the statistical features that are the most informative about the visual world. This idea raises a fundamental question: how do basic image properties shape visual perception in animals?</p><p id="P4">Natural images can, for example, be statistically characterized in terms of the correlations between their pixels (e.g., up to the fourth order, correlations between values of four adjacent pixels in a 2 x 2 disposition; see <xref ref-type="fig" rid="F1">Figure 1a</xref>; (<xref ref-type="bibr" rid="R7">7</xref>, <xref ref-type="bibr" rid="R8">8</xref>)). Correlated pixels define regions, patterns, and objects. Indeed, while the average of single pixel values describes the overall luminance of an image, 2-point correlations give rise to horizontal, vertical and oblique patterns; 3-point correlations define L-shaped forms; 4-point correlations induce rectangles and squares in an image (<xref ref-type="fig" rid="F1">Figure 1a</xref>). Higher-order correlations would reflect more complex visual textures (not considered in these studies). By contrast, an image with no pixel correlations is usually called ‘white noise’: in such a pattern, the pixels are randomly set as white or black independently of one another and the multi-point correlations are all minimized.</p><p id="P5">By analyzing these features in natural scenes, the authors of (<xref ref-type="bibr" rid="R7">7</xref>, <xref ref-type="bibr" rid="R8">8</xref>) reported that, across natural image patches, there is a prominent variation (bigger variance in the frequency of appearance) of 2-point correlations, followed by 4-point and finally 3-point correlations.</p><p id="P6">According to the hypothesis of efficient neural coding, if our sensory systems encode environmental signals in an information theoretically optimal way, then these natural image statistics should be reflected in the sensitivities of our visual system: we should be better at perceiving the more variable, i.e. more informative and thus more salient, statistical structures in natural scenes.</p><p id="P7">To test this idea, Hermundstad et al. (<xref ref-type="bibr" rid="R7">7</xref>) conducted psychophysical experiments on human participants, measuring sensitivity to these different visual textures in a discrimination task. Participants were asked to discriminate between the textures, and their perceptual sensitivity was compared to predictions based on the statistics of natural images discussed above. The results showed that human sensitivity was higher for more variable multi-point correlations, supporting the idea that the brain prioritizes processing unpredictable features. In particular, participants performed best with the 2-point, followed by 4-point and lastly 3-point patterns. Such larger sensitivity to the most salient features in natural scenes provides a strong indication that our nervous system encodes visual information efficiently, i.e., it extracts the most information at the lowest possible cost by giving more importance to more informative (i.e. less predictable) features.</p><p id="P8">Intriguingly, these findings have been recently duplicated in rats (<xref ref-type="bibr" rid="R10">10</xref>). After preliminary training where rats learned to differentiate white noise from structured textures (correlation patterns), the animals were tested in a behavioral discrimination task. Their performance was measured by presenting stimuli with varying levels of correlation and fitting psychometric curves. The results revealed that rats, like humans, exhibit a clear sensitivity ranking (better with 1- or 2-point than with 4- and 3-point correlations), supporting the idea that visual perception follows efficient coding principles.</p><p id="P9">Whether the same sensitivity ranking can be observed in non-mammalian vertebrates is currently unknown. The efficient neural coding hypothesis makes the strong prediction that this should be the case, since any visual species should effectively allocate computational resources to encode the most informative features in natural images. This expectation is reinforced by the similarities of the visual systems among vertebrates (<xref ref-type="bibr" rid="R11">11</xref>–<xref ref-type="bibr" rid="R13">13</xref>).</p><p id="P10">The origins of efficient coding mechanisms remain largely unexplored, i.e. whether they reflect learning during ontogeny (e.g., by exposure to natural image statistics, encoded directly in an individual nervous system; (<xref ref-type="bibr" rid="R2">2</xref>, <xref ref-type="bibr" rid="R14">14</xref>–<xref ref-type="bibr" rid="R16">16</xref>)) or evolutionarily-given inborn predispositions (e.g., by exposure to natural image patterns during natural history, encoded in the genome; (<xref ref-type="bibr" rid="R17">17</xref>, <xref ref-type="bibr" rid="R18">18</xref>)) or a mix of both.</p><p id="P11">To address these questions, we studied perception of multipoint correlation patterns in newly-hatched domestic chicks, a precocial species ideal for the investigation of biological predispositions and early learning (<xref ref-type="bibr" rid="R18">18</xref>–<xref ref-type="bibr" rid="R24">24</xref>). Newly-hatched chicks possess a range of predisposed visual preferences that guide early learning for pecking at specific food colours and shapes (<xref ref-type="bibr" rid="R25">25</xref>, <xref ref-type="bibr" rid="R26">26</xref>), detection of animacy (<xref ref-type="bibr" rid="R20">20</xref>), to be used in recognition of social partners (<xref ref-type="bibr" rid="R27">27</xref>–<xref ref-type="bibr" rid="R29">29</xref>), prey (<xref ref-type="bibr" rid="R30">30</xref>, <xref ref-type="bibr" rid="R31">31</xref>) and predators (<xref ref-type="bibr" rid="R32">32</xref>). We focus here on spontaneous (innate) preferences for visual textures defined by multipoint correlations and on how experience with these visual stimuli could shape chicks’ choices by filial imprinting, a form of exposure learning.</p><p id="P12">In Experiment 1, chicks were hatched in the dark to prevent any exposure to statistical regularities of the visual environment and then tested in free-choice tests with specified 1-point statistics (luminance), 2-point correlations (horizontal lines), 3-point correlations (L-shapes with corner to the bottom right) and 4-point correlations (rectangular patterns) <italic>vs</italic>. white noise (Experiment 1a; see <xref ref-type="fig" rid="F1">Figure 1a</xref>). We also tested chicks with additional 2-point patterns not used in previous animal studies, which produced horizontal, vertical and oblique line patterns (Experiment 1b; see <xref ref-type="fig" rid="F1">Figure 1a</xref>), to provide data on possible orientational biases during exposure to asymmetric and not rotationally invariant configurations and to allow for a better comparison with human studies (<xref ref-type="bibr" rid="R7">7</xref>).</p><p id="P13">In Experiment 2, we investigated whether exposure to different correlation patterns affects learning by filial imprinting. To this end, we exposed newly-hatched visually naïve chicks to the different texture statistics (used in Experiment 1a) for one day and then tested their preferences for the familiar (imprinted) texture <italic>vs</italic>. white noise (and vice versa, with imprinting on the noise pattern).</p><sec id="S2"><title>Experiment 1: Spontaneous choice</title><p id="P14">In this experiment, we assessed the innate preference (and discriminability) of chicks for different texture statistics over white noise with free-dual-choice tests. The number of males and females was balanced in each group (see <xref ref-type="fig" rid="F2">Figure 2</xref> and <xref ref-type="fig" rid="F3">Figure 3</xref> for the relative numbers).</p><p id="P15">In Experiment 1a we tested the same four texture statistics that (<xref ref-type="bibr" rid="R10">10</xref>) studied in rats: 1-point, 2-point horizontal, 3-point, 4-point correlations.</p><p id="P16">In Experiment 1b we tested different kinds of 2-point patterns (yielding bands with different orientations: horizontal, vertical and oblique) to better investigate possible orientational biases during the exposure to asymmetric and not rotationally invariant configurations. This was motivated by the fact that horizontal 2-point patterns align with the stimulus motion direction, while vertical ones are perpendicular, potentially causing illusions like the Barber-Pole effect (<xref ref-type="bibr" rid="R33">33</xref>, <xref ref-type="bibr" rid="R34">34</xref>). Moreover, chicks tend to prefer objects moving along their elongation axis, a possible cue for animacy (<xref ref-type="bibr" rid="R35">35</xref>). In addition, this allowed a finer comparison with the sensitivity of humans, who have been found to be more sensitive to cardinal (horizontal, vertical) than oblique orientations (<xref ref-type="bibr" rid="R7">7</xref>, <xref ref-type="bibr" rid="R36">36</xref>).</p></sec></sec><sec id="S3" sec-type="results"><title>Results</title><sec id="S4"><title>Experiment 1a</title><p id="P17">Looking at the chicks’ preference over time (<xref ref-type="fig" rid="F2">Figure 2a</xref>), it is clear that males and females show similar time-varying trends for 1-, 3- and 4-point patterns. For example, both sexes show a strong preference for the 1-point luminance pattern as compared to white noise (e.g., females, minute 5: PI = 0.56 ± 0.17, 95% C.I. [0.20, 0.93]; females, minute 10: PI = 0.65 ± 0.15, 95% C.I. [0.32, 0.97]; males, minute 5: PI = 0.66 ± 0.14, 95% C.I. [0.38, 0.95]; males, minute 10: PI = 0.71 ± 0.11, 95% C.I. [0.47, 0.94]). For the 3-point patterns chicks’ behavior is always at chance (e.g., females, minute 5: PI = -0.06 ± 0.16, 95% C.I. [-0.40, 0.28]; females, minute 10: PI = -0.08 ± 0.17, 95% C.I. [-0.43, 0.28]; males, minute 5: PI = -0.23 ± 0.17, 95% C.I. [-0.59, 0.13]; males, minute 10: PI = -0.08 ± 0.19, 95% C.I. [-0.47, 0.30]). For the 4-point patterns, preference towards the correlation pattern emerges over time (e.g., females, minute 1: PI = 0.07 ± 0.19, 95% C.I. [-0.33, 0.47]; females, minute 15: PI = 0.39 ± 0.18, 95% C.I. [0.02, 0.75]; males, minute 1: PI = 0.00 ± 0.23, 95% C.I. [-0.47, 0.48]; males, minute 15: PI = 0.13 ± 0.21, 95% C.I. [-0.31, 0.57]). For 2-point patterns, the two sexes show opposite preferences: males show a stable preference for white noise, while females spend more time close to the multipoint pattern during the first minutes of test (e.g., females, minute 1: PI = 0.26 ± 0.19, 95% C.I. [-0.13, 0.66]; females, minute 15: PI = -0.39 ± 0.18, 95% C.I. [-0.76, -0.02]; males, minute 1: PI = -0.44 ± 0.20, 95% C.I. [-0.85, -0.03]; males, minute 15: PI = -0.39 ± 0.18, 95% C.I. [-0.76, -0.02]). The different initial preference for the two sexes in the 2-point group is also visible from the first choice (<xref ref-type="supplementary-material" rid="SD1">Supplementary Figure 1</xref>). All data for the minute-by-minute choice can be found in <xref ref-type="supplementary-material" rid="SD1">Supplementary Table 1</xref>.</p><p id="P18">If we compute the discrimination score (strength of choice, independent of its direction), the curves for males and females align in their trend for all conditions (<xref ref-type="fig" rid="F2">Figure 2b</xref>), as confirmed by permutation test comparisons over choices during the 15 minutes of testing (1-point, male vs. female: p=0.47; 2-point, male vs. female: p=0.30; 3-point, male vs. female: p=0.97; 4-point, male vs. female: p=0.48). Data merged across sexes are shown in <xref ref-type="fig" rid="F2">Figure 2c</xref>.</p><p id="P19">Disentangling the complex time profiles by averaging the score in 5-minute time bins (<xref ref-type="fig" rid="F2">Figure 2d</xref>), we found a stable discrimination in time for 1-point (average discrimination score for minutes 1-5, permutation test against chance p&lt;0.01; average discrimination score for minutes 6-10, permutation test against chance p&lt;0.01; average discrimination score for minutes 11-15, permutation test against chance p&lt;0.01), as well as for 2-point patterns (average discrimination score for minutes 1-5, permutation test against chance p&lt;0.01; average discrimination score for minutes 6-10, permutation test against chance p&lt;0.01; average discrimination score for minutes 11-15, permutation test against chance p&lt;0.01). The 4-point pattern was discriminated from the middle of the 15 minutes (average discrimination score for minutes 1-5, permutation test against chance p&gt;0.05; average discrimination score for minutes 6-10, permutation t-test against chance p&lt;0.01; average discrimination score for minutes 11-15, permutation test against chance p&lt;0.01). By contrast, the 3-point pattern was never discriminated in any time interval (average discrimination score for minutes 1-5, permutation t-test against chance p&gt;0.05; average discrimination score for minutes 6-10, permutation test against chance p&gt;0.05; average discrimination score for minutes 11-15, permutation t-test against chance p&gt;0.05).</p><p id="P20">Comparisons between the actual multipoint correlation patterns (2-point, 3-point and 4-point conditions; 1-point is not included in this comparison since it has a different saliency being related to luminance) show differences between 2-point vs. 3-point (permutation Holm corrected p=0.04), and 2-point vs. 4-point (permutation Holm corrected p=0.02) in the first time interval (minutes 1-5); between 4-point vs. 3-point (permutation Holm corrected p=0.03) in the second time interval (minutes 6-10); and between 2-point vs. 3-point (permutation Holm corrected p=0.04), and 4-point vs. 3-point (permutation Holm corrected p=0.02) in the last time interval (minutes 11-15).</p></sec><sec id="S5"><title>Experiment 1b</title><p id="P21">Looking at the chicks’ preference over time (<xref ref-type="fig" rid="F3">Figure 3a</xref>), it is clear that males and females show similar time-varying trends for 2-point vertical and oblique patterns. For example in the vertical group both sexes show a slight preference for the pattern (e.g., females, minute 5: PI = 0.07 ± 0.14, 95% C.I. [-0.21, 0.35]; females, minute 10: PI = 0.17 ± 0.13, 95% C.I. [-0.10, 0.44]; males, minute 5: PI = 0.15 ± 0.15, 95% C.I. [-0.16, 0.45]; males, minute 10: PI = 0.20 ± 0.15, 95% C.I. [-0.11, 0.50]). For the oblique group, there is no preference (e.g., females, minute 3: PI = 0.02 ± 0.15, 95% C.I. [-0.28, 0.31]; females, minute 12: PI = 0.01 ± 0.15, 95% C.I. [-0.29, 0.31]; males, minute 3: PI = 0.07 ± 0.15, 95% C.I. [-0.23, 0.37]; males, minute 12: PI = 0.06 ± 0.15, 95% C.I. [-0.23, 0.35]). For 2-point horizontal patterns,the two sexes initially show opposite preferences: males show a stable preference for white noise, while females spend more time close to the multipoint pattern during the first minutes of test (e.g., females, minute 1: PI = 0.27 ± 0.13, 95% C.I. [0.02, 0.53]; females, minute 15: PI = 0.01 ± 0.13, 95% C.I. [-0.25, 0.27]; males, minute 1: PI = -0.37 ± 0.14, 95% C.I. [-0.66, -0.08]; males, minute 15: PI = -0.30 ± 0.14, 95% C.I. [-0.58, -0.01]). The different initial preference for the two sexes in the horizontal group is also visible from the first choice (<xref ref-type="supplementary-material" rid="SD1">Supplementary Figure 2</xref>). All data for the minute-by-minute choice can be found in <xref ref-type="supplementary-material" rid="SD1">Supplementary Table 2</xref>.</p><p id="P22">By computing the discrimination score (strength of choice, independent of its direction), the curves for males and females align in their trend for all conditions (<xref ref-type="fig" rid="F3">Figure 3b</xref>), as confirmed by permutation test comparisons (horizontal, male vs. female: p=0.1; vertical, male vs. female: p=0.3; oblique, male vs. female: p=0.7). Data merged across sexes are shown in <xref ref-type="fig" rid="F4">Figure 4c</xref>.</p><p id="P23">Disentangling the complex time profiles by averaging the score in 5-minute time bins (<xref ref-type="fig" rid="F3">Figure 3d</xref>), we found a stable discrimination in time for the 2-point horizontal pattern (average discrimination score for minutes 1-5, permutation test against chance p&lt;0.01; average discrimination score for minutes 6-10, permutation test against chance p&lt;0.01; average discrimination score for minutes 11-15, permutation test against chance p&lt;0.01). The vertical pattern was discriminated towards the middle-end of the 15 minutes (average discrimination score for minutes 1-5, permutation test against chance p&gt;0.05; average discrimination score for minutes 6-10, permutation test against chance p&lt;0.01; average discrimination score for minutes 11-15, permutation test against chance p&lt;0.01). By contrast, the oblique pattern was never discriminated at any time interval (average discrimination score for minutes 1-5, permutation test against chance p&gt;0.05; average discrimination score for minutes 6-10, permutation test against chance p&gt;0.05; average discrimination score for minutes 11-15, permutation test against chance p&gt;0.05).</p><p id="P24">Comparisons between the various 2-point correlation patterns show differences between horizontal vs. oblique (permutation Holm corrected p&lt;0.01), and horizontal vs. vertical (permutation Holm corrected p=0.01) patterns in the first time interval (minutes 1-5).</p></sec></sec><sec id="S6" sec-type="discussion"><title>Discussion</title><sec id="S7"><title>Experiment 1a</title><p id="P25">We found that chicks spontaneously preferred 1-point luminance textures and 2-point correlation textures. Moreover, a preference for 4-point textures was mainly observed later during the time course of the test (minutes 6-15). While in general the choice is consistent across sexes, 2-point patterns are processed differently in the first minutes (see <xref ref-type="fig" rid="F2">Figure 2a</xref> and first choice, <xref ref-type="supplementary-material" rid="SD1">Supplementary Figure 1</xref>): females have an initial preference for the 2-point pattern, while males have a stable preference for the white noise patterns over the multipoint statistics. No preference at all was found for 3-point patterns.</p><p id="P26">1-point patterns define changes in the luminance of an image, a cue that chicks can easily use for discrimination (<xref ref-type="bibr" rid="R37">37</xref>). Here, we found a spontaneous preference for brighter stimuli, which is in line with previous findings in domestic chicks (<xref ref-type="bibr" rid="R38">38</xref>, <xref ref-type="bibr" rid="R39">39</xref>).</p><p id="P27">Interestingly, for the 2-point horizontal patterns males and females expressed different initial preferences, with males preferring white noise and females the correlation pattern. The reason for this sex difference is unclear, though a variety of early visual processing mechanisms, from biological motion to responses to face-like stimuli seem to be modulated by sex in young chicks (<xref ref-type="bibr" rid="R17">17</xref>, <xref ref-type="bibr" rid="R19">19</xref>, <xref ref-type="bibr" rid="R21">21</xref>, <xref ref-type="bibr" rid="R40">40</xref>, <xref ref-type="bibr" rid="R41">41</xref>).</p><p id="P28">Still, irrespective of its direction, the spontaneous discrimination of image statistics seems to follow a ranking that mirrors the one documented in humans and rats (<xref ref-type="bibr" rid="R7">7</xref>, <xref ref-type="bibr" rid="R10">10</xref>). For rats the 1-point and 2-point patterns are most discriminable from white noise, followed by the 4-, and finally the 3-point patterns (<xref ref-type="bibr" rid="R10">10</xref>). Similarly, chicks easily discriminate 1-point patterns from white noise, and they show discrimination for 2-point horizontal patterns and for 4-point textures; while no discrimination occurs at all for 3-point patterns. This ranking is also partially consistent with the one reported by (<xref ref-type="bibr" rid="R7">7</xref>), although, unlike humans, chicks do not show any preference for oblique 2-point textures.</p><p id="P29">In interpreting these findings, it is important to consider the strengths and limitations of our spontaneous preference tests for measuring visual perception. Finding a significant preference for a given texture <italic>vs</italic>. white noise means that the two patterns are discriminable by the chicks’ visual system. By contrast, the lack of a preference does not necessarily imply that the texture is not perceived as different from white noise. Chicks could still be able to discriminate between the two stimuli, without showing any tendency to stay closer to one than to the other. Similarly, the strength of the preference could reflect both the perceptual discriminability of the visual patterns and the innate level of attractiveness of one stimulus over the other.</p><p id="P30">These caveats notwithstanding, our results seem generally consistent with the hypothesis of efficient coding mechanisms, i.e., that animals’ visual systems are adapted to collect the most informative features from natural scenes, since the observed ranking largely matches the variability of the statistics in natural images. Our results further suggest that these mechanisms are already available at birth, since they are based on spontaneous preferences in visually naïve animals. This, of course, does not exclude the possibility that evolutionarily-driven predispositions could be modulated by exposure to the actual features of a natural environment during development (<xref ref-type="bibr" rid="R7">7</xref>, <xref ref-type="bibr" rid="R10">10</xref>).</p></sec><sec id="S8"><title>Experiment 1b</title><p id="P31">In this experiment, we found consistent results with Experiment 1a for the horizontal group, thus replicating those findings. Males and females had opposite initial spontaneous preferences when exposed to the horizontal 2-point correlation patterns against white noise. However, interestingly, the spontaneous preference and the sex differences faded away when the line orientations were changed (vertical and oblique cases; <xref ref-type="fig" rid="F3">Figure 3</xref>). Still, for the vertical pattern there is a delayed discrimination (at minutes 6-15), while the oblique pattern was not discriminated (or preferred to white noise) at any time interval. These findings suggest that chicks do not only focus on the mere statistical 2-point correlations present in images but also use other information when showing a spontaneous preference. In our experimental setup, images were moving on the horizontal axis of the screen to increase their attractiveness (moving stimuli have been described to be more attractive than stationary ones in filial imprinting; (<xref ref-type="bibr" rid="R27">27</xref>, <xref ref-type="bibr" rid="R42">42</xref>–<xref ref-type="bibr" rid="R44">44</xref>)). When the 2-point pattern is horizontally oriented, the lines are parallel to the motion direction, while they are perpendicular in the case of vertical patterns. This different relation between the pattern direction and the direction of motion could cause some sort of illusion in specific configurations, as known, <italic>e.g</italic>., for the Barber-Pole illusion (<xref ref-type="bibr" rid="R33">33</xref>, <xref ref-type="bibr" rid="R34">34</xref>). Moreover, it was shown that chicks prefer objects moving along their main axis of elongation, since this can be recognized as a sign of animacy (<xref ref-type="bibr" rid="R35">35</xref>); see (<xref ref-type="bibr" rid="R43">43</xref>) for a review). This could account for the effects of orientation in the 2-point pattern groups, though it remains unclear why motion perception direction should be modulated by sex.</p></sec></sec><sec id="S9"><title>Experiment 2: Discrimination after imprinting</title><p id="P32">In this experiment, we tested the learned preferences of chicks imprinted on different kinds of correlation statistics or on white noise. Four different groups of chicks were imprinted on textures defined by different multipoint correlations (respectively, with 1-, horizontal 2-, 3- and 4-point) and later tested in a free-dual-choice test between the imprinted texture and white noise. Four other independent groups of chicks were imprinted on white noise images and then tested with white noise <italic>vs</italic>. one of the four texture statistics. The white noise stimuli used for the four groups were equivalent.</p><sec id="S10" sec-type="results"><title>Results</title><p id="P33">Chicks imprinted above chance with all four patterns and white noise, meaning they spent most of their time close to the imprinting stimulus during the 14 hours of exposition (see <xref ref-type="supplementary-material" rid="SD1">Supplementary Figure 4</xref>). Averaging across this exposition period, chicks spent 65% of their time (95% C.I. [62,69%], Cohen’s d = 0.77) close to the displayed object.</p><p id="P34">Concerning the dual choice test phase following imprinting, examination of the chicks’ preference in time (<xref ref-type="fig" rid="F4">Figure 4a</xref> and 4b) makes it clear that chicks imprinted on both the multipoint patterns and white noise show similar time-varying trends at test. For example, for the 1-point statistic both groups show a slight preference for the luminance pattern over noise (e.g., imprinted on noise, minute 1: PI = 0.20 ± 0.24, 95% C.I. [-0.31, 0.71]; imprinted on pattern, minute 1: PI = 0.17 ± 0.23, 95% C.I. [-0.31, 0.65]). For 2-point patterns the preference is close to chance (e.g., imprinted on noise, minute 1: PI = 0.10 ± 0.24, 95% C.I. [-0.41, 0.61]; imprinted on pattern, minute 1: PI = -0.17 ± 0.23, 95% C.I. [-0.65, 0.31]). For 3- and 4-point patterns the preference is stable towards the white noise (e.g., 3-point imprinted on noise, minute 2: PI = -0.51 ± 0.20, 95% C.I. [-0.93, -0.08], minute 14: PI = -0.30 ± 0.22, 95% C.I. [-0.76, 0.16]; 3-point imprinted on pattern, minute 2: PI = -0.19 ± 0.23, 95% C.I. [-0.67, 0.28], minute 14: PI = -0.27 ± 0.22, 95% C.I. [-0.74, 0.19]; 4-point imprinted on noise, minute 2: PI = -0.44 ± 0.20, 95% C.I. [-0.86, -0.01], minute 14: PI = -0.54 ± 0.20, 95% C.I. [-0.97, -0.12]; 4-point imprinted on pattern, minute 2: PI = -0.33 ± 0.23, 95% C.I. [-0.82, 0.17], minute 14: PI = -0.38 ± 0.24, 95% C.I. [-0.89, 0.12]). Choices at all time points are reported in <xref ref-type="supplementary-material" rid="SD1">Supplementary Table 3</xref>.</p><p id="P35">The similarity, at test, in behaviour between groups imprinted with a pattern or noise is also visible from first choices (<xref ref-type="supplementary-material" rid="SD1">Supplementary Figure 5</xref>), and is confirmed by permutation test comparisons on the discrimination score (1-point, imprinting with pattern vs. noise: permutation p=0.6; 2-point, imprinting with pattern vs. noise: permutation p=0.7; 3-point, imprinting with pattern vs. noise: permutation p=0.6; 4-point, imprinting with pattern vs. noise: permutation p=0.7). Data merged across types of imprinting are shown in <xref ref-type="fig" rid="F4">Figure 4c</xref>.</p><p id="P36">Simplifying the time profiles by averaging the score in 5 minutes time bins (<xref ref-type="fig" rid="F4">Figure 4d</xref>), we found a stable discrimination in time for 3-point (average discrimination score for minutes 1-5, permutation test against chance p&lt;0.01; average discrimination score for minutes 6-10, permutation test against chance p&lt;0.01; average discrimination score for minutes 11-15, permutation test against chance p&lt;0.01), as well as for 4-point patterns (average discrimination score for minutes 1-5, permutation test against chance p&lt;0.01; average discrimination score for minutes 6-10, permutation test against chance p&lt;0.01; average discrimination score for minutes 11-15, permutation test against chance p&lt;0.01). The 1-point pattern was discriminated towards the end of the 15 minutes (average discrimination score for minutes 1-5, permutation test against chance p&gt;0.05; average discrimination score for minutes 6-10, permutation test against chance p&gt;0.05; average discrimination score for minutes 11-15, permutation test against chance p=0.03). By contrast, the 2-point pattern was never discriminated at any time interval (average discrimination score for minutes 1-5, permutation test against chance p&gt;0.05; average discrimination score for minutes 6-10, permutation test against chance p&gt;0.05; average discrimination score for minutes 11-15, permutation test against chance p&gt;0.05).</p><p id="P37">Comparisons between the multipoint correlation patterns (2-point, 3-point and 4-point conditions; 1-point is not included in this comparison since it has a different saliency being related to luminance) show differences between 2-point vs. 3-point patterns (permutation Holm corrected p&lt;0.01), and 2-point vs. 4-point patterns (permutation Holm corrected p&lt;0.01) in the first time interval (minutes 1-5); between 4-point vs. 2-point patterns (permutation Holm corrected p&lt;0.01) in the second time interval (minutes 6-10); and between 2-point vs. 4-point patterns (permutation Holm corrected p&lt;0.01) in the last time interval (minutes 11-15).</p></sec></sec><sec id="S11" sec-type="discussion"><title>Discussion</title><p id="P38">Previous studies investigated sensitivity to different kinds of correlation statistics using operant conditioning procedures, in which subjects were required to explicitly discriminate structured textures from white noise patterns (<xref ref-type="bibr" rid="R7">7</xref>, <xref ref-type="bibr" rid="R10">10</xref>). In the case of rats, this was achieved by teaching them an association between stimulus identity and reward ports. In Experiment 2, we explored whether pixel correlations could affect a different, non-associative form of learning, namely filial imprinting (there is evidence that imprinting attains more to declarative-like rather than procedural forms of learning; (<xref ref-type="bibr" rid="R45">45</xref>)).</p><p id="P39">Our results suggest that chicks imprint equally well on all patterns and white noise, spending 65% of their time (above chance) close to the displayed object. Still, it is interesting to notice how in (<xref ref-type="bibr" rid="R28">28</xref>), chicks underwent a similar procedure with different stimuli, spending 96% of their time close to their imprinting objects. Such a difference suggests that our correlation patterns are probably not the most optimal stimuli for imprinting, possibly also because of the absence of colour.</p><p id="P40">At test, the 2-point groups showed no preference, as if chicks did not differentiate between the correlation patterns and white noise. The preference for 1-point luminance appears only towards the end of the test (minutes 11-15). However, we know from the results of Experiment 1 that chicks can discriminate these two patterns. Thus, it appears that, after imprinting, the difference of 2-point patterns (and to some extent 1-point patterns) from white noise was no longer judged relevant enough to elicit a strong differential behavioral approach. Interestingly, however, stronger preferences appeared in the 4- and 3-point patterns. In both these groups, chicks preferred white noise when imprinted on it but also when imprinted on the correlation patterns. This suggests that chicks imprinted with 3- and 4-point patterns tend to explore novel stimuli (the white noise) while chicks imprinted with noise mostly remain attracted to this familiar pattern. Generally speaking, in these cases, white noise seems visually more attractive than 3- and 4-point patterns.</p><p id="P41">Interestingly, imprinting leads to an outcome that is mirror-reversed with respect to the spontaneous preferences test. Several studies showed that young chicks tend to behave differently in imprinting tests on the basis of the perceived novelty of the stimulus (<xref ref-type="bibr" rid="R46">46</xref>–<xref ref-type="bibr" rid="R48">48</xref>). Strikingly, completely unfamiliar stimuli tend to be avoided whereas slight novelty is explored (<xref ref-type="bibr" rid="R49">49</xref>). Here, the results suggest that 3- and 4-point patterns elicited clear choices, whereas 2- and 1-point did not. The different orders of the correlation patterns show increasing complexity, starting from single-pixel luminance to multiple-pixel correlations. In this sense, white noise can be considered the lowest in complexity, lacking any correlation. Our stimuli thus show increasing complexity starting from noise to 1-, 2-, 3- and 4-point patterns, defined by the number of units involved, as visible by the sketches in <xref ref-type="fig" rid="F1">Figure 1a</xref>), with white noise at the lowest bound. If chicks possess a mechanism to detect pixel correlations, as apparent from the results of Experiment 1, a white noise image can be considered to be closer to e.g. a 2-point than to a 4-point pattern. Our results converge with chicks being sensitive to such an ordering: clear choice in imprinting is apparent when white noise is compared with 3- or 4-point patterns, but not with ‘simpler’ 1- or 2-point patterns.</p></sec><sec id="S12" sec-type="conclusions"><title>Conclusions</title><p id="P42">We found that newly-hatched visually naïve domestic chicks show a spontaneous preference to approach 1-point, 2-point and 4-point correlation patterns (respectively, luminance, horizontal lines and rectangular patterns), but no preference at all for 3-point correlation pattern versus white noise. This ranking resembles the one observed in adult humans and rats and could suggest evolutionarily-set biological predispositions underlying efficient coding of natural images. Interestingly, we also found that imprinting to visual patterns (both multipoint correlation or noise) induces a stronger preference (and thus a discrimination) for white noise over point correlation patterns in animals exposed to 3- and 4-point stimuli, while the preference for 2- and 1-point patterns is no longer present at the beginning of the test. This behavior could reflect an attraction to stimuli of lower statistical complexity and an avoidance of strongly novel patterns, with a modulation provided by innate preferences.</p><p id="P43">Our results provide the first evidence for an evolutionary grounding of efficient coding mechanisms and open the way to further investigation of their underlying neural and genetic mechanisms.</p></sec><sec id="S13" sec-type="materials | methods"><title>Materials and methods</title><sec id="S14" sec-type="subjects"><title>Subjects</title><p id="P44">The number of animals tested in each group was a priori determined by a power analysis considering an effect size (Cohen’s d) of 0.55 in the spontaneous preference test (inferred from Caramellini et al.(<xref ref-type="bibr" rid="R10">10</xref>)) and of 0.75 in the imprinting test, inferred from Lemaire et al. (<xref ref-type="bibr" rid="R28">28</xref>)), and an alpha of 0.05. Twenty-eight individuals per group for the spontaneous preference test (Experiment 1a) and 16 individuals per group in the imprinting test (Experiment 2) were required to achieve a power of 0.8. Experiment 1b (on different orientations of 2-point patterns) was run a posteriori, and the power analysis was based on a more appropriate effect size from Experiment 1a considering the group tested with horizontal 2-point patterns: for an effect size of 0.37 (see Experiment 1b Results section), to reach a power of 0.8, 47 chicks per group were required. Overall, we tested 671 chicks (263 males) of the strain Ross 308, from which we included 529 chicks (184 males) in the analysis (after excluding non-moving animals; see Data analysis subparagraph). The eggs were obtained from a commercial hatchery (Azienda Agricola Crescenti, Brescia) and were incubated in complete darkness in our laboratory under controlled temperature (37.7 °C) and humidity (40% humidity). Three days before hatching, eggs were moved into opaque black boxes within a hatching chamber at 37.7 °C and 60% of humidity. Soon after hatching, chicks were briefly sexed under dim light (based on sexual dimorphism of the wing feathers) and singly housed in testing cages, positioning them in the center. All procedures received approval from the Ethical Committee of the University of Trento and the Italian Ministry of Health (permit number 53/2020-PR released on 21/01/2020).</p></sec><sec id="S15"><title>Apparatus</title><p id="P45">All experiments took place in testing cages of 90×60×60 cm, with water and food available <italic>ad libitum</italic>. At two opposite sides of the cage, two high frame rate (120 Hz) screens displayed the stimuli. Image presentation was automated and controlled by a custom Matlab script which ensured the display of stimuli at precise times and randomized stimulus position on the screens in order to avoid positional bias (<xref ref-type="bibr" rid="R9">9</xref>). The behaviour of each chick was continuously recorded using an overhead camera. The experimental setup and methods are described in detail in Zanon et al. (<xref ref-type="bibr" rid="R9">9</xref>). See <xref ref-type="fig" rid="F1">Figure 1b</xref> for a schematic representation of the set-up.</p></sec><sec id="S16"><title>Stimuli</title><p id="P46">Textures with different multipoint correlations and white noise patterns were generated using Metex (<xref ref-type="bibr" rid="R50">50</xref>). This program creates textures in which the probability of occurrence of a given correlation can be controlled systematically, while minimizing the contribution of other multipoint correlations to the structure of the images (this is achieved by sampling images from the maximum-entropy distribution that is compatible with the requested correlation<sup>8</sup>). This way, the pixels in the generated texture are as random as possible, while respecting the desired multipoint correlation constraint. In contrast, white noise images contain no multipoint correlations. The space of possible textures is parameterized by what we will refer to as the intensity of the corresponding statistic, which can take on values between -1 and 1. When the intensity is zero, the texture does not contain any structure and, therefore, it is the same as white noise. When the intensity is close to one of its extreme values (i.e., close to either +1 or -1), the structure dictated by the correlation gives rise to textures with the prominent, characteristic features shown in <xref ref-type="fig" rid="F1">Figure 1a</xref> (see Victor and Conte (<xref ref-type="bibr" rid="R8">8</xref>) for the mathematical details on how the space of textures is parameterized).</p><p id="P47">We used high intensity values (+0.9) for all the statistics we tested; in this way, we ensured that the resulting textures were highly discriminable from white noise. For Experiments 1a and 2 we used 1-point, 2-point horizontal, 3-point corner bottom right, and 4-point; while for Experiment 1b we used 2-point horizontal, vertical and oblique left (see <xref ref-type="fig" rid="F1">Figure 1a</xref>). The remaining patterns (2-point oblique right and 3-point corner top left/right and bottom left) were not investigated for time reasons, also considering the supposed scarce biological relevance and novelty compared to the already considered ones.</p><p id="P48">Thus, we created 10 images for each of the aforementioned statistics of interest (1-point, 2-point horizontal, vertical and oblique, 3-point corner bottom right and 4-point). In all dual-choice phases of all experiments each chick was displaying one of these patterns against white noise (always generated in a new different random pattern); while in the imprinting phase of Experiment 2, patterns of a given statistic were randomly varied spanning the 10 created patterns: in this way we avoided the possibility that the chick can imprint on the identity of a very specific stimulus, considering that the same pattern was never displayed more than once to the same subject across experimental sessions.</p><p id="P49">The image size was 300×300 pixels (8.3×8.3 cm) to ensure a minimum angle of view for the whole stimulus (estimated for a maximum distance of 90 cm, from one side of the cage to the opposite screen) of 2.9°, which is clearly perceived by chicks (<xref ref-type="bibr" rid="R51">51</xref>). A single pixel had a dimension of 0.16 cm, ensuring a minimum angle of view of 0.11° at a distance of 45 cm. Thus, we could be confident that chicks could visually discriminate the different patterns already from the center of the cage.</p><p id="P50">The stimuli displayed on the screens were moving (translating) horizontally to attract the chicks’ attention. We used the following parameters of our Matlab script (<xref ref-type="bibr" rid="R9">9</xref>): translation amplitude 0.32 corresponding to 42.5 cm spanned and translation frequency 0.11 corresponding to 275 cm/min).</p></sec></sec><sec id="S17"><title>Experimental pipeline</title><sec id="S18"><title>Experiment 1</title><p id="P51">Experiments 1a and 1b consisted of spontaneous dual-choice tests. After positioning in the center of the cage, chicks underwent a dual-choice multipoint pattern <italic>vs</italic>. white noise test (each chick was assigned to one of the four specific textures, see <xref ref-type="fig" rid="F1">Figure 1a</xref>). The whole test lasted 30 minutes (to ensure chicks could initiate movement, after which only the first 15 minutes were analyzed). Chicks that stayed in the center of the apparatus and did not make a choice between the presented stimuli for more than 15 minutes were discarded from analysis. Chicks were exposed to one single texture of a given correlation for the whole duration of the test. The experimental texture was displayed on a random side of the cage, while on the opposite screen, the white noise stimulus was displayed. Both stimuli were horizontally translating on screens to increase attractiveness (<xref ref-type="bibr" rid="R27">27</xref>, <xref ref-type="bibr" rid="R42">42</xref>–<xref ref-type="bibr" rid="R44">44</xref>).</p></sec><sec id="S19"><title>Experiment 2</title><p id="P52">This experiment consists of an imprinting exposure followed by a dual-choice test. After positioning in the center of the cage, chicks underwent one day of imprinting with a specific pattern (24 hours divided into 7 sessions of 2 hours: 14 hours of active imprinting, plus a night resting time of 10 hours with black screens; for a reference to the procedure see also Lemaire et al. (<xref ref-type="bibr" rid="R28">28</xref>)). During this imprinting phase, the stimulus was displayed only on one screen (while the opposite screen was black). The active screen changed randomly every session (i.e., every 2h) and a new instance of the same imprinting multipoint correlation pattern (or white noise pattern) was displayed in each session: this prevents chicks from learning and focusing on a specific stimulus or screen during the imprinting phase.</p><p id="P53">Once the imprinting phase was completed, chicks were repositioned at the center of the cage to avoid any positional bias at the beginning of the test (dual-choice texture <italic>vs</italic>. white noise). The test phase was similar to Experiment 1, with both stimuli horizontally translating on the opposite screens. The statistical textures, and consequently of the white noise, were randomly allocated to specific screens.</p><p id="P54">In order to limit the number of animals used we decided to employ only one sex in Experiment 2: we selected female chicks as they are usually more attached to social stimuli than males in imprinting tests (<xref ref-type="bibr" rid="R52">52</xref>–<xref ref-type="bibr" rid="R55">55</xref>). Females also showed a stronger preference for textures against white noise in Experiment 1 (see <xref ref-type="fig" rid="F2">Figure 2a</xref> and 3a).</p></sec></sec><sec id="S20"><title>Data analysis</title><p id="P55">For all the experiments, the location of the subjects within the arena was analysed with DeepLabCut (<xref ref-type="bibr" rid="R56">56</xref>, <xref ref-type="bibr" rid="R57">57</xref>). The animal was considered close to a screen (stimulus) when it was less than 30 cm from it.</p><p id="P56">We analyzed the first 15 minutes following the subject’s first choice. We discarded from the analyses chicks that stayed in the center of the apparatus and did not make a choice between the presented stimuli for more than 15 minutes (see <xref ref-type="supplementary-material" rid="SD1">Supplementary Table 1</xref> for the exact numbers of chicks used and analysed).</p><p id="P57">To take into account that chick preferences or discrimination performance could vary during different epochs of the 15 minutes, we ran the statistical analysis independently in 5-minute intervals (‘beginning’: minutes 1-5; ‘middle’: minutes 6-10; and ‘end’: minutes 11-15; see details below).</p><p id="P58">As metrics for evaluating chick preferences, we recorded the first stimulus approached by each animal, and calculated a <italic>preference index</italic> (at single minute resolution) using the formula: <disp-formula id="FD1"><mml:math id="M1"><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi/><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mspace width="0.2em"/><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula> with <italic>t</italic> being the seconds spent close to a stimulus (respectively correlation patterns and white noise). This index reflects the preference of the animals for the displayed stimuli. An index value of +1 indicates that the animals spent all their time close to the multipoint texture; an index value of -1 indicates that the animals spent all their time close to the white noise; while a value of 0 indicates chance level.</p><p id="P59">We investigated actual choice (between noise and pattern) over time by plotting the chicks’ average <italic>preference index</italic> minute by minute, divided by sex. We took sex into consideration for our analysis of Experiment 1 since a variety of early visual processing mechanisms, from biological motion to responses to face-like stimuli, seem to be modulated by sex in young chicks (<xref ref-type="bibr" rid="R17">17</xref>, <xref ref-type="bibr" rid="R19">19</xref>, <xref ref-type="bibr" rid="R21">21</xref>, <xref ref-type="bibr" rid="R40">40</xref>, <xref ref-type="bibr" rid="R41">41</xref>).</p><p id="P60">To compare results with previous studies (<xref ref-type="bibr" rid="R7">7</xref>, <xref ref-type="bibr" rid="R10">10</xref>), we also focused on the general ability to discriminate multipoint patterns from white noise, as opposed to the specific preference for one or the other. To quantify this discrimination, we computed a <italic>discrimination score</italic> based on the <italic>preference index</italic>. For each subgroup, defined by sex, statistical condition, and time interval, we first calculated the group mean of the <italic>preference index</italic>. If this mean was negative, indicating a consistent preference for white noise within the group during that interval, we inverted the sign of the preference indices for all individuals at all time points, in that subgroup and interval. If the mean was positive, no transformation was applied.</p><p id="P61">This procedure aligns all group-level preferences in the same direction, allowing us to assess the strength of discrimination regardless of stimulus identity. The resulting <italic>discrimination score</italic> thus provides a measure of the magnitude of group-level choices, with higher values reflecting stronger discrimination. Importantly, because the data are still analyzed and plotted across time, individual time points may still show negative values, indicating temporary divergences from the overall (average in time and across subjects) preference trend in the specific interval. We also note that while a positive <italic>discrimination score</italic> reflects a clear pattern vs. noise discrimination, a score of zero does not necessarily indicate an absence of discrimination, but rather may reflect a lack of consistent preference across individuals or of overall (average in time and across subjects) preference as well.</p><p id="P62">All the statistical analyses were performed on these <italic>discrimination scores</italic> to check if each multipoint pattern was discriminated from noise (i.e., testing <italic>discrimination score</italic> difference from zero) in different time intervals (beginning, middle, and end, as defined above). Analyses were performed in RStudio (version 1.4.17.17) running R (version 4.1.0, R Core Team, 2017).</p><p id="P63">Specifically, we firstly evaluated the contribution of sex (for Experiment 1) or type of imprinting (for Experiment 2) for each multipoint pattern, by running a permutation test (5000 permutations) on the scores of male vs. female (Experiment 1) or imprinting on noise vs. multipoint pattern (Experiment 2).</p><p id="P64">If no significant difference between the sexes or type of imprinting was found, the data were merged and the difference of the overall <italic>discrimination score</italic> from chance level zero was evaluated with a permutation test for each time interval. In this case, multiple (5000) random datasets were created by randomly inverting the sign of the preference indices at the single chick level in order to mimic random choice by subjects. In this way, the distribution of the means for the random datasets was constructed. The p-value was thus evaluated as the percentage of random data points more extreme than the real mean, using the formula: p-value = (b+1)/(n_perm+1), where b is the number of values more extreme than the real statistic value, n_perm = 5000 iterations (<xref ref-type="bibr" rid="R58">58</xref>).</p><p id="P65">Finally, to compare differences between multipoint patterns, Holm-corrected permutation tests were used. As in previous works (<xref ref-type="bibr" rid="R7">7</xref>), we compared only 2-point, 3-point and 4-point (for Experiment 1a and 2), and 2-point horizontal, vertical and oblique (for Experiment 1b) since the 1-point pattern simply corresponds to luminance variations, and is thus not a multipoint correlation.</p></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary materials</label><media xlink:href="EMS206955-supplement-Supplementary_materials.docx" mimetype="application" mime-subtype="vnd.openxmlformats-officedocument.wordprocessingml.document" id="d2aAcJbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S21"><title>Funding</title><p>This project has received funding from the European Union Next Generation UE, PNRR PRIN (DD 104 02/02/22 - M4 - C2 - INV 1.1) grant nr. 2022WX3FM5 to G.V., D.Z., and J.G.; from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation program (grant agreement number 833504 - SPANUMBRA to G.V.); from the ERC Consolidator Grant “BabyRhythm” nr. 773202 and the FARE grant nr. R204MPRHKE, the European Union Next Generation EU NRRP M6C2 - Investment 2.1 to J.G.; VB was supported in part by the Eastman Professorship at Balliol College, University of Oxford.</p></ack><sec id="S22" sec-type="data-availability"><title>Availability of data and material</title><p id="P66">All the materials and scripts to replicate the analysis are freely available in the Figshare repository: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.28846787.v1">https://doi.org/10.6084/m9.figshare.28846787.v1</ext-link></p></sec><fn-group><title>Declarations</title><fn fn-type="conflict" id="FN2"><p id="P67"><italic>Conflicts of interest/Competing interests:</italic> The authors declare no competing interests.</p></fn><fn fn-type="con" id="FN3"><p id="P68"><italic>Authors’ contributions:</italic> M.Z., B.S.L. performed the experiments and the overall data analysis. G.V., D.Z. and J.G. supervised the project. M.Z., B.S.L. and E.P. performed statistical analysis. M.Z., B.S.L. and G.V. wrote the initial draft. All the authors contributed to the reshaping, the correction and improvement, and the discussion for the final version of the manuscript.</p></fn></fn-group><ref-list><title>Bibliography</title><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barlow</surname><given-names>H</given-names></name></person-group><article-title>Redundancy reduction revisited</article-title><source>Netw Comput Neural Syst</source><year>2001</year><volume>12</volume><fpage>241</fpage><lpage>253</lpage><pub-id pub-id-type="pmid">11563528</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Matteucci</surname><given-names>G</given-names></name><name><surname>Piasini</surname><given-names>E</given-names></name><name><surname>Zoccolan</surname><given-names>D</given-names></name></person-group><article-title>Unsupervised learning of mid-level visual representations</article-title><source>Curr Opin Neurobiol</source><year>2024</year><volume>84</volume><elocation-id>102834</elocation-id><pub-id pub-id-type="pmid">38154417</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratliff</surname><given-names>CP</given-names></name><name><surname>Borghuis</surname><given-names>BG</given-names></name><name><surname>Kao</surname><given-names>Y-H</given-names></name><name><surname>Sterling</surname><given-names>P</given-names></name><name><surname>Balasubramanian</surname><given-names>V</given-names></name></person-group><article-title>Retina is structured to process an excess of darkness in natural scenes</article-title><year>2010</year><pub-id pub-id-type="doi">10.1073/pnas.1005846107</pub-id><pub-id pub-id-type="pmcid">PMC2951394</pub-id><pub-id pub-id-type="pmid">20855627</pub-id></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group><article-title>Vision and the statistics of the visual environment</article-title><source>Curr Opin Neurobiol</source><year>2003</year><volume>13</volume><fpage>144</fpage><lpage>149</lpage><pub-id pub-id-type="pmid">12744966</pub-id></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tesileanu</surname><given-names>T</given-names></name><name><surname>Piasini</surname><given-names>E</given-names></name><name><surname>Balasubramanian</surname><given-names>V</given-names></name></person-group><article-title>Efficient processing of natural scenes in visual cortex</article-title><source>Front Cell Neurosci</source><year>2022</year><volume>16</volume><elocation-id>1006703</elocation-id><pub-id pub-id-type="doi">10.3389/fncel.2022.1006703</pub-id><pub-id pub-id-type="pmcid">PMC9760692</pub-id><pub-id pub-id-type="pmid">36545653</pub-id></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tkačik</surname><given-names>G</given-names></name><name><surname>Prentice</surname><given-names>JS</given-names></name><name><surname>Victor</surname><given-names>JD</given-names></name><name><surname>Balasubramanian</surname><given-names>V</given-names></name></person-group><article-title>Local statistics in natural scenes predict the saliency of synthetic textures</article-title><source>Proc Natl Acad Sci</source><year>2010</year><volume>107</volume><fpage>18149</fpage><lpage>18154</lpage><pub-id pub-id-type="doi">10.1073/pnas.0914916107</pub-id><pub-id pub-id-type="pmcid">PMC2964243</pub-id><pub-id pub-id-type="pmid">20923876</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hermundstad</surname><given-names>AM</given-names></name><etal/></person-group><article-title>Variance predicts salience in central sensory processing</article-title><source>eLife</source><year>2014</year><volume>3</volume><elocation-id>e03722</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.03722</pub-id><pub-id pub-id-type="pmcid">PMC4271187</pub-id><pub-id pub-id-type="pmid">25396297</pub-id></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Victor</surname><given-names>JD</given-names></name><name><surname>Conte</surname><given-names>MM</given-names></name></person-group><article-title>Local image statistics: maximum-entropy constructions and perceptual salience</article-title><source>J Opt Soc Am A</source><year>2012</year><volume>29</volume><elocation-id>1313</elocation-id><pub-id pub-id-type="doi">10.1364/JOSAA.29.001313</pub-id><pub-id pub-id-type="pmcid">PMC3396046</pub-id><pub-id pub-id-type="pmid">22751397</pub-id></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zanon</surname><given-names>M</given-names></name><name><surname>Lemaire</surname><given-names>BS</given-names></name><name><surname>Vallortigara</surname><given-names>G</given-names></name></person-group><article-title>Steps towards a computational ethology: an automatized, interactive setup to investigate filial imprinting and biological predispositions</article-title><source>Biol Cybern</source><year>2021</year><volume>115</volume><fpage>575</fpage><lpage>584</lpage><pub-id pub-id-type="doi">10.1007/s00422-021-00886-6</pub-id><pub-id pub-id-type="pmcid">PMC8642325</pub-id><pub-id pub-id-type="pmid">34272970</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caramellino</surname><given-names>R</given-names></name><etal/></person-group><article-title>Rat sensitivity to multipoint statistics is predicted by efficient coding of natural scenes</article-title><source>eLife</source><year>2021</year><volume>10</volume><elocation-id>e72081</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.72081</pub-id><pub-id pub-id-type="pmcid">PMC8651284</pub-id><pub-id pub-id-type="pmid">34872633</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Vallortigara</surname><given-names>G</given-names></name></person-group><chapter-title>The cognitive chicken: Visual and spatial cognition in a non-mammalian brain</chapter-title><source>The Oxford Handbook of Comparative Cognition</source><publisher-name>Oxford University Press</publisher-name><year>2012</year><fpage>48</fpage><lpage>66</lpage></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knudsen</surname><given-names>EI</given-names></name></person-group><article-title>Evolution of neural processing for visual perception in vertebrates</article-title><source>J Comp Neurol</source><year>2020</year><volume>528</volume><fpage>2888</fpage><lpage>2901</lpage><pub-id pub-id-type="doi">10.1002/cne.24871</pub-id><pub-id pub-id-type="pmcid">PMC7586818</pub-id><pub-id pub-id-type="pmid">32003466</pub-id></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Vallortigara</surname><given-names>G</given-names></name></person-group><chapter-title>Visual cognition and representation in birds and primates</chapter-title><source>Vertebrate Comparative Cognition: Are Primates Superior to Non-Primates?</source><publisher-name>Kluwer Academic/Plenum Publishers</publisher-name><year>2004</year><fpage>57</fpage><lpage>94</lpage></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berardi</surname><given-names>N</given-names></name><name><surname>Pizzorusso</surname><given-names>T</given-names></name><name><surname>Maffei</surname><given-names>L</given-names></name></person-group><article-title>Critical periods during sensory development</article-title><source>Curr Opin Neurobiol</source><year>2000</year><volume>10</volume><fpage>138</fpage><lpage>145</lpage><pub-id pub-id-type="pmid">10679428</pub-id></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Espinosa</surname><given-names>JS</given-names></name><name><surname>Stryker</surname><given-names>MP</given-names></name></person-group><article-title>Development and Plasticity of the Primary Visual Cortex</article-title><source>Neuron</source><year>2012</year><volume>75</volume><fpage>230</fpage><lpage>249</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.06.009</pub-id><pub-id pub-id-type="pmcid">PMC3612584</pub-id><pub-id pub-id-type="pmid">22841309</pub-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Matteucci</surname><given-names>G</given-names></name><name><surname>Zoccolan</surname><given-names>D</given-names></name></person-group><article-title>Unsupervised experience with temporal continuity of the visual environment is causally involved in the development of V1 complex cells</article-title><source>Sci Adv</source><year>2020</year><volume>6</volume><elocation-id>eaba3742</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.aba3742</pub-id><pub-id pub-id-type="pmcid">PMC7259963</pub-id><pub-id pub-id-type="pmid">32523998</pub-id></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosa Salva</surname><given-names>O</given-names></name><name><surname>Grassi</surname><given-names>M</given-names></name><name><surname>Lorenzi</surname><given-names>E</given-names></name><name><surname>Regolin</surname><given-names>L</given-names></name><name><surname>Vallortigara</surname><given-names>G</given-names></name></person-group><article-title>Spontaneous preference for visual cues of animacy in naïve domestic chicks: The case of speed changes</article-title><source>Cognition</source><year>2016</year><volume>157</volume><fpage>49</fpage><lpage>60</lpage><pub-id pub-id-type="pmid">27592411</pub-id></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Vallortigara</surname><given-names>G</given-names></name></person-group><source>Born Knowing: Imprinting and the Origins of Knowledge</source><publisher-name>MIT press</publisher-name><year>2021</year></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Di Giorgio</surname><given-names>E</given-names></name><etal/></person-group><article-title>Filial responses as predisposed and learned preferences: Early attachment in chicks and babies</article-title><source>Behav Brain Res</source><year>2017</year><volume>325</volume><fpage>90</fpage><lpage>104</lpage><pub-id pub-id-type="pmid">27616345</pub-id></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lorenzi</surname><given-names>E</given-names></name><name><surname>Vallortigara</surname><given-names>G</given-names></name></person-group><chapter-title>Evolutionary and Neural Bases of the Sense of Animacy</chapter-title><person-group person-group-type="editor"><name><surname>Kaufman</surname><given-names>AB</given-names></name><name><surname>Call</surname><given-names>J</given-names></name><name><surname>Kaufman</surname><given-names>JC</given-names></name></person-group><source>The Cambridge Handbook of Animal Cognition</source><edition>1st Ed</edition><publisher-name>Cambridge University Press</publisher-name><year>2021</year><fpage>295</fpage><lpage>321</lpage></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosa Salva</surname><given-names>O</given-names></name><name><surname>Mayer</surname><given-names>U</given-names></name><name><surname>Vallortigara</surname><given-names>G</given-names></name></person-group><article-title>Roots of a social brain: Developmental models of emerging animacy-detection mechanisms</article-title><source>Neurosci Biobehav Rev</source><year>2015</year><volume>50</volume><fpage>150</fpage><lpage>168</lpage><pub-id pub-id-type="pmid">25544151</pub-id></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosa Salva</surname><given-names>O</given-names></name><etal/></person-group><article-title>Sensitive periods for social development: Interactions between predisposed and learned mechanisms</article-title><source>Cognition</source><year>2021</year><volume>213</volume><elocation-id>104552</elocation-id><pub-id pub-id-type="pmid">33402251</pub-id></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Versace</surname><given-names>E</given-names></name><name><surname>Martinho-Truswell</surname><given-names>A</given-names></name><name><surname>Kacelnik</surname><given-names>A</given-names></name><name><surname>Vallortigara</surname><given-names>G</given-names></name></person-group><article-title>Priors in Animal and Artificial Intelligence: Where Does Learning Begin?</article-title><source>Trends Cogn Sci</source><year>2018</year><volume>22</volume><fpage>963</fpage><lpage>965</lpage><pub-id pub-id-type="pmid">30097305</pub-id></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Versace</surname><given-names>E</given-names></name><name><surname>Vallortigara</surname><given-names>G</given-names></name></person-group><article-title>Origins of Knowledge: Insights from Precocial Species</article-title><source>Front Behav Neurosci</source><year>2015</year><volume>9</volume><pub-id pub-id-type="doi">10.3389/fnbeh.2015.00338</pub-id><pub-id pub-id-type="pmcid">PMC4673401</pub-id><pub-id pub-id-type="pmid">26696856</pub-id></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gamberale-Stille</surname><given-names>G</given-names></name><name><surname>Tullberg</surname><given-names>B</given-names></name></person-group><article-title>Fruit or aposematic insect? Context-dependent colour preferences in domestic chicks</article-title><source>Proc R Soc Lond B Biol Sci</source><year>2001</year><volume>268</volume><fpage>2479</fpage><lpage>2484</lpage><pub-id pub-id-type="doi">10.1098/rspb.2001.1814</pub-id><pub-id pub-id-type="pmcid">PMC1088910</pub-id><pub-id pub-id-type="pmid">11749705</pub-id></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roper</surname><given-names>TJ</given-names></name><name><surname>Marples</surname><given-names>NM</given-names></name></person-group><article-title>Colour preferences of domestic chicks in relation to food and water presentation</article-title><source>Appl Anim Behav Sci</source><year>1997</year><volume>54</volume><fpage>207</fpage><lpage>213</lpage></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bolhuis</surname><given-names>JJ</given-names></name></person-group><article-title>Mechanisms of avian imprinting: a review</article-title><source>Biol Rev</source><year>1991</year><volume>66</volume><fpage>303</fpage><lpage>345</lpage><pub-id pub-id-type="pmid">1801945</pub-id></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lemaire</surname><given-names>BS</given-names></name><name><surname>Rucco</surname><given-names>D</given-names></name><name><surname>Josserand</surname><given-names>M</given-names></name><name><surname>Vallortigara</surname><given-names>G</given-names></name><name><surname>Versace</surname><given-names>E</given-names></name></person-group><article-title>Stability and individual variability of social attachment in imprinting</article-title><source>Sci Rep</source><year>2021</year><volume>11</volume><elocation-id>7914</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-021-86989-3</pub-id><pub-id pub-id-type="pmcid">PMC8041793</pub-id><pub-id pub-id-type="pmid">33846440</pub-id></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McCabe</surname><given-names>BJ</given-names></name></person-group><article-title>Visual Imprinting in Birds: Behavior, Models, and Neural Mechanisms</article-title><source>Front Physiol</source><year>2019</year><volume>10</volume><fpage>658</fpage><pub-id pub-id-type="doi">10.3389/fphys.2019.00658</pub-id><pub-id pub-id-type="pmcid">PMC6558373</pub-id><pub-id pub-id-type="pmid">31231236</pub-id></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clara</surname><given-names>E</given-names></name><name><surname>Regolin</surname><given-names>L</given-names></name><name><surname>Vallortigara</surname><given-names>G</given-names></name><name><surname>Rogers</surname><given-names>LJ</given-names></name></person-group><article-title>Chicks prefer to peck at insect-like elongated stimuli moving in a direction orthogonal to their longer axis</article-title><source>Anim Cogn</source><year>2009</year><volume>12</volume><fpage>755</fpage><lpage>765</lpage><pub-id pub-id-type="pmid">19466469</pub-id></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mascalzoni</surname><given-names>E</given-names></name><name><surname>Osorio</surname><given-names>D</given-names></name><name><surname>Regolin</surname><given-names>L</given-names></name><name><surname>Vallortigara</surname><given-names>G</given-names></name></person-group><article-title>Symmetry perception by poultry chicks and its implications for three-dimensional object recognition</article-title><source>Proc R Soc B Biol Sci</source><year>2012</year><volume>279</volume><fpage>841</fpage><lpage>846</lpage><pub-id pub-id-type="doi">10.1098/rspb.2011.1486</pub-id><pub-id pub-id-type="pmcid">PMC3259931</pub-id><pub-id pub-id-type="pmid">21920978</pub-id></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hébert</surname><given-names>M</given-names></name><name><surname>Versace</surname><given-names>E</given-names></name><name><surname>Vallortigara</surname><given-names>G</given-names></name></person-group><article-title>Inexperienced preys know when to flee or to freeze in front of a threat</article-title><source>Proc Natl Acad Sci</source><year>2019</year><volume>116</volume><fpage>22918</fpage><lpage>22920</lpage><pub-id pub-id-type="doi">10.1073/pnas.1915504116</pub-id><pub-id pub-id-type="pmcid">PMC6859328</pub-id><pub-id pub-id-type="pmid">31659039</pub-id></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Snowden</surname><given-names>RJ</given-names></name><name><surname>Freeman</surname><given-names>TCA</given-names></name></person-group><article-title>The visual perception of motion</article-title><source>Curr Biol</source><year>2004</year><volume>14</volume><fpage>R828</fpage><lpage>R831</lpage><pub-id pub-id-type="pmid">15458658</pub-id></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>P</given-names></name><name><surname>Chubb</surname><given-names>C</given-names></name><name><surname>Sperling</surname><given-names>G</given-names></name></person-group><article-title>Two mechanisms that determine the Barber-Pole Illusion</article-title><source>Vision Res</source><year>2015</year><volume>111</volume><fpage>43</fpage><lpage>54</lpage><pub-id pub-id-type="pmid">25872181</pub-id></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosa Salva</surname><given-names>O</given-names></name><name><surname>Hernik</surname><given-names>M</given-names></name><name><surname>Broseghini</surname><given-names>A</given-names></name><name><surname>Vallortigara</surname><given-names>G</given-names></name></person-group><article-title>Visually-naïve chicks prefer agents that move as if constrained by a bilateral body-plan</article-title><source>Cognition</source><year>2018</year><volume>173</volume><fpage>106</fpage><lpage>114</lpage><pub-id pub-id-type="pmid">29367016</pub-id></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Girshick</surname><given-names>AR</given-names></name><name><surname>Landy</surname><given-names>MS</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group><article-title>Cardinal rules: visual orientation perception reflects knowledge of environmental statistics</article-title><source>Nat Neurosci</source><year>2011</year><volume>14</volume><fpage>926</fpage><lpage>932</lpage><pub-id pub-id-type="doi">10.1038/nn.2831</pub-id><pub-id pub-id-type="pmcid">PMC3125404</pub-id><pub-id pub-id-type="pmid">21642976</pub-id></element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zolman</surname><given-names>JF</given-names></name><name><surname>Lattin</surname><given-names>WJ</given-names></name></person-group><article-title>Development of brightness preferences in young chicks: Effects on brightness discrimination learning</article-title><source>J Comp Physiol Psychol</source><year>1972</year><volume>79</volume><fpage>271</fpage><lpage>283</lpage><pub-id pub-id-type="pmid">5025996</pub-id></element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clarke</surname><given-names>CH</given-names></name><name><surname>Jones</surname><given-names>BR</given-names></name></person-group><article-title>Domestic Chicks’ Attraction to Video Images: Effects of Stimulus Movement, Brightness, Colour and Complexity</article-title><source>Int J Comp Psychol</source><year>2000</year><volume>13</volume></element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delius</surname><given-names>JD</given-names></name><name><surname>Thompson</surname><given-names>G</given-names></name></person-group><article-title>Brightness Dependence of Colour Preferences in Herring Gull Chicks</article-title><source>Z Für Tierpsychol</source><year>1970</year><volume>27</volume><fpage>842</fpage><lpage>849</lpage><pub-id pub-id-type="pmid">5511688</pub-id></element-citation></ref><ref id="R40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miura</surname><given-names>M</given-names></name><name><surname>Matsushima</surname><given-names>T</given-names></name></person-group><article-title>Preference for biological motion in domestic chicks: sex-dependent effect of early visual experience</article-title><source>Anim Cogn</source><year>2012</year><volume>15</volume><fpage>871</fpage><lpage>879</lpage><pub-id pub-id-type="pmid">22622813</pub-id></element-citation></ref><ref id="R41"><label>41</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosa Salva</surname><given-names>O</given-names></name><name><surname>Regolin</surname><given-names>L</given-names></name><name><surname>Vallortigara</surname><given-names>G</given-names></name></person-group><article-title>Faces are special for newly hatched chicks: evidence for inborn domain□specific mechanisms underlying spontaneous preferences for face□like stimuli</article-title><source>Dev Sci</source><year>2010</year><volume>13</volume><fpage>565</fpage><lpage>577</lpage><pub-id pub-id-type="pmid">20590721</pub-id></element-citation></ref><ref id="R42"><label>42</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hess</surname><given-names>EH</given-names></name></person-group><article-title>Imprinting</article-title><source>Science</source><year>1959</year><volume>130</volume><pub-id pub-id-type="pmid">17816335</pub-id></element-citation></ref><ref id="R43"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lemaire</surname><given-names>BS</given-names></name><name><surname>Vallortigara</surname><given-names>G</given-names></name></person-group><article-title>Life is in motion (through a chick’s eye)</article-title><source>Anim Cogn</source><year>2022</year><volume>26</volume><fpage>129</fpage><lpage>140</lpage><pub-id pub-id-type="doi">10.1007/s10071-022-01703-8</pub-id><pub-id pub-id-type="pmcid">PMC9877072</pub-id><pub-id pub-id-type="pmid">36222937</pub-id></element-citation></ref><ref id="R44"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lorenz</surname><given-names>KZ</given-names></name></person-group><article-title>The Companion in the Bird’s World</article-title><source>The Auk</source><year>1937</year><volume>54</volume><fpage>245</fpage><lpage>273</lpage></element-citation></ref><ref id="R45"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bateson</surname><given-names>P</given-names></name></person-group><article-title>Is imprinting such a special case?</article-title><source>Philos Trans R Soc Lond B Biol Sci</source><year>1990</year><volume>329</volume><fpage>125</fpage><lpage>131</lpage></element-citation></ref><ref id="R46"><label>46</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bateson</surname><given-names>P</given-names></name></person-group><article-title>Brief exposure to a novel stimulus during imprinting in chicks and its influence on subsequent preferences</article-title><source>Anim Learn Behav</source><year>1979</year><volume>7</volume><fpage>259</fpage><lpage>262</lpage></element-citation></ref><ref id="R47"><label>47</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bateson</surname><given-names>P</given-names></name></person-group><article-title>Preferences for familiarity and novelty: A model for the simultaneous development of both</article-title><source>J Theor Biol</source><year>1973</year><volume>41</volume><fpage>249</fpage><lpage>259</lpage><pub-id pub-id-type="pmid">4751397</pub-id></element-citation></ref><ref id="R48"><label>48</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jackson</surname><given-names>PS</given-names></name><name><surname>Bateson</surname><given-names>P</given-names></name></person-group><article-title>Imprinting and exploration of slight novelty in chicks</article-title><source>Nature</source><year>1974</year><volume>251</volume><pub-id pub-id-type="pmid">4421398</pub-id></element-citation></ref><ref id="R49"><label>49</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Versace</surname><given-names>E</given-names></name><name><surname>Spierings</surname><given-names>MJ</given-names></name><name><surname>Caffini</surname><given-names>M</given-names></name><name><surname>Ten Cate</surname><given-names>C</given-names></name><name><surname>Vallortigara</surname><given-names>G</given-names></name></person-group><article-title>Spontaneous generalization of abstract multimodal patterns in young domestic chicks</article-title><source>Anim Cogn</source><year>2017</year><volume>20</volume><fpage>521</fpage><lpage>529</lpage><pub-id pub-id-type="pmid">28260155</pub-id></element-citation></ref><ref id="R50"><label>50</label><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Piasini</surname><given-names>E</given-names></name></person-group><source>metex - Maximum Entropy TEXtures (1.1.0)</source><year>2021</year><comment>Deposited 2021</comment></element-citation></ref><ref id="R51"><label>51</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wisely</surname><given-names>CE</given-names></name><etal/></person-group><article-title>The chick eye in vision research: An excellent model for the study of ocular disease</article-title><source>Prog Retin Eye Res</source><year>2017</year><volume>61</volume><fpage>72</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1016/j.preteyeres.2017.06.004</pub-id><pub-id pub-id-type="pmcid">PMC5653414</pub-id><pub-id pub-id-type="pmid">28668352</pub-id></element-citation></ref><ref id="R52"><label>52</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cailotto</surname><given-names>M</given-names></name><name><surname>Vallortigara</surname><given-names>G</given-names></name><name><surname>Zanforlin</surname><given-names>M</given-names></name></person-group><article-title>Sex differences in the response to social stimuli in young chicks</article-title><source>Ethol Ecol Evol</source><year>1989</year><volume>1</volume><fpage>323</fpage><lpage>327</lpage></element-citation></ref><ref id="R53"><label>53</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vallortigara</surname><given-names>G</given-names></name></person-group><article-title>Affiliation and Aggression As Related to Gender in Domestic Chicks (Gallus gallus)</article-title><source>J Comp Psychol</source><year>1992</year><volume>29</volume><fpage>56</fpage><lpage>57</lpage><pub-id pub-id-type="pmid">1555402</pub-id></element-citation></ref><ref id="R54"><label>54</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vallortigara</surname><given-names>G</given-names></name><name><surname>Cailotto</surname><given-names>M</given-names></name><name><surname>Zanforlin</surname><given-names>M</given-names></name></person-group><article-title>Sex differences in social reinstatement motivation of the domestic chick (Gallus gallus) revealed by runway tests with social and nonsocial reinforcement</article-title><source>J Comp Psychol</source><year>1990</year><volume>104</volume><fpage>361</fpage><lpage>367</lpage><pub-id pub-id-type="pmid">2282785</pub-id></element-citation></ref><ref id="R55"><label>55</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Workman</surname><given-names>L</given-names></name><name><surname>Andrew</surname><given-names>J</given-names></name></person-group><article-title>Simultaneous changes in behaviour and in iateralization during the development of male and female domestic chicks</article-title><source>Anim Behav</source><year>1989</year><volume>38</volume></element-citation></ref><ref id="R56"><label>56</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathis</surname><given-names>A</given-names></name><etal/></person-group><article-title>DeepLabCut: markerless pose estimation of user-defined body parts with deep learning</article-title><source>Nat Neurosci</source><year>2018</year><volume>21</volume><fpage>1281</fpage><lpage>1289</lpage><pub-id pub-id-type="pmid">30127430</pub-id></element-citation></ref><ref id="R57"><label>57</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nath</surname><given-names>T</given-names></name><etal/></person-group><article-title>Using DeepLabCut for 3D markerless pose estimation across species and behaviors</article-title><source>Nat Protoc</source><year>2019</year><volume>14</volume><fpage>2152</fpage><lpage>2176</lpage><pub-id pub-id-type="pmid">31227823</pub-id></element-citation></ref><ref id="R58"><label>58</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Davison</surname><given-names>AC</given-names></name><name><surname>Hinkley</surname><given-names>DV</given-names></name></person-group><source>Bootstrap methods and their application (Reprinted with corrections 2003)</source><year>1997</year></element-citation></ref></ref-list></back><floats-group><boxed-text id="BX1" position="float" orientation="portrait"><caption><title>Significance statement</title></caption><p>We show that visually naïve chicks spontaneously prefer specific multipoint correlation patterns, mirroring preferences seen in humans and rats, and reflecting the most informative structures in natural scenes. This provides evidence that efficient coding mechanisms may be innately driven by evolutionary predispositions. Notably, early visual experience through imprinting can alter these preferences, highlighting a role for learning in shaping visual processing.</p></boxed-text><fig id="F1" position="float"><label>Figure 1</label><caption><title>Stimuli and apparatus.</title><p><bold><italic>a)</italic></bold> Example of textures with defined statistics (correlation between up to four pixels in a 2 × 2 square arrangement as depicted in the gliders on the left of the patterns, with black dots and lines indicating the involved pixel correlation arrangement for the specific statistics). Each independent coordinate (□L, <italic>β</italic><sub><italic>1</italic></sub>, <italic>β</italic><sub><italic>2</italic></sub>, <italic>β</italic><sub><italic>3</italic></sub>, <italic>β</italic><sub><italic>4</italic></sub>, □<sub><italic>1</italic></sub>, □<sub><italic>2</italic></sub>, □<sub><italic>3</italic></sub>, □<sub><italic>4</italic></sub>, □ as reported in Victor and Conte (<xref ref-type="bibr" rid="R8">8</xref>) describes a given correlation pattern (respectively 1-point, 2-point horizontal, 2-point vertical, 2-point oblique to left, 2-point oblique to right, 3-point corner bottom right, 3-point corner bottom left, 3-point corner top right, 3-point corner top left, 4-point correlation). White noise images have all pixel correlations (up to 4<sup>th</sup> order) equal to zero. See Victor and Conte (<xref ref-type="bibr" rid="R8">8</xref>) for a detailed theoretical background. The textures highlighted with a green contour are the ones used in Experiment 1a and 2, while the textures with a blue contour are used in Experiment 1b. <bold><italic>b)</italic></bold> Schematic illustration of the experimental setup (<xref ref-type="bibr" rid="R9">9</xref>). Lateral view and cage dimensions (left), and upper view with the different choosing areas depicted in different colors (right).</p></caption><graphic xlink:href="EMS206955-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Results for Experiment 1a.</title><p><bold><italic>a)</italic></bold> Preference index (&gt;0: preference for the correlation pattern) during the first 15 minutes following the first choice, divided by conditions and sex. <bold><italic>b)</italic></bold> Discrimination score (&gt;0: preference for pattern or noise) during the first 15 minutes following the first choice, divided by conditions and sex. <bold><italic>c)</italic></bold> Discrimination score (preference for pattern or noise) during the first 15 minutes following the first choice, divided by conditions, with sex merged. <bold><italic>d)</italic></bold> Average discrimination score in time intervals of 5 minutes (respectively average across minutes 1-5, minutes 6-10, and minutes 11-15). Dotted horizontal lines indicate the chance level (i.e., no preference or discrimination); asterisks (*) indicate statistical significance against the chance level (p &lt; 0.05).</p></caption><graphic xlink:href="EMS206955-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Results for Experiment 1b.</title><p><bold><italic>a)</italic></bold> Preference index (&gt;0: preference for the correlation pattern) during the first 15 minutes following the first choice, divided by conditions and sex. <bold><italic>b)</italic></bold> Discrimination score (&gt;0: preference for pattern or noise) during the first 15 minutes following the first choice, divided by conditions and sex. <bold><italic>c)</italic></bold> Discrimination score (preference for pattern or noise) during the first 15 minutes following the first choice, divided by conditions, with sex merged. <bold><italic>d)</italic></bold> Average discrimination score in time intervals of 5 minutes (respectively average across minutes 1-5, minutes 6-10, and minutes 11-15). Dotted horizontal lines indicate the chance level (i.e., no preference or discrimination); asterisks (*) indicate statistical significance against the chance level (p &lt; 0.05).</p></caption><graphic xlink:href="EMS206955-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Results for Experiment 2.</title><p><bold><italic>a)</italic></bold> Preference index (&gt;0: preference for the correlation pattern) during the first 15 minutes following the first choice, divided by conditions and type of imprinting. <bold><italic>b)</italic></bold> Discrimination score (&gt;0: preference for pattern or noise) during the first 15 minutes following the first choice, divided by conditions and type of imprinting. <bold><italic>c)</italic></bold> Discrimination score (preference for pattern or noise) during the first 15 minutes following the first choice, divided by conditions, with type of imprinting merged. <bold><italic>d)</italic></bold> Average discrimination score in time intervals of 5 minutes (respectively average across minutes 1 to 5, minutes 6 to 10, and minutes 11 to 15). Dotted horizontal lines indicate the chance level (i.e., no preference or discrimination); asterisks (*) indicate statistical significance against the chance level (p &lt; 0.05).</p></caption><graphic xlink:href="EMS206955-f004"/></fig></floats-group></article>