<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS206019</article-id><article-id pub-id-type="doi">10.1101/2025.05.27.656332</article-id><article-id pub-id-type="archive">PPR1027517</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">1</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>The Effect of Previously Encountered Sensory Information on Neural Representations of Predictability: Evidence from Human EEG</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-6853-3191</contrib-id><name><surname>Magami</surname><given-names>Kaho</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-7808-3593</contrib-id><name><surname>Bianco</surname><given-names>Roberta</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-9613-8933</contrib-id><name><surname>Hall</surname><given-names>Edward</given-names></name><xref ref-type="aff" rid="A3">3</xref><xref ref-type="aff" rid="A4">4</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-8268-5052</contrib-id><name><surname>Pearce</surname><given-names>Marcus</given-names></name><xref ref-type="aff" rid="A3">3</xref><xref ref-type="aff" rid="A5">5</xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Chait</surname><given-names>Maria</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib></contrib-group><aff id="A1"><label>1</label>Ear Institute, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>University College London</institution></institution-wrap>, <city>London</city>, <postal-code>WC1X 8EE</postal-code>, <country country="GB">United Kingdom</country></aff><aff id="A2"><label>2</label>Neuroscience of Perception &amp; Action Lab, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/042t93s57</institution-id><institution>Italian Institute of Technology (IIT)</institution></institution-wrap>, <postal-code>00161</postal-code>, <city>Rome</city>, <country country="IT">Italy</country></aff><aff id="A3"><label>3</label>School of Electronic Engineering and Computer Science, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/026zzn846</institution-id><institution>Queen Mary University of London</institution></institution-wrap>, <country country="GB">United Kingdom</country></aff><aff id="A4"><label>4</label>Digital and Cognitive Musicology Lab, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/02s376052</institution-id><institution>École Polytechnique Fédérale de Lausanne</institution></institution-wrap>, <country country="CH">Switzerland</country></aff><aff id="A5"><label>5</label>Department of Clinical Medicine, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/01aj84f44</institution-id><institution>Aarhus University</institution></institution-wrap>, <country country="DK">Denmark</country></aff><author-notes><corresp id="CR1"><bold>Corresponding Author:</bold>, Kaho Magami, <email>kaho.magami.19@ucl.ac.uk</email>, Ear Institute, University College London, 332 Gray’s Inn Road, London WC1X 8EE, UK, Maria Chait, <email>m.chdit@ucl.dc.uk</email>, Ear Institute, University College London, 332 Gray’s Inn Road, London WC1X 8EE, UK</corresp></author-notes><pub-date pub-type="nihms-submitted"><day>30</day><month>05</month><year>2025</year></pub-date><pub-date pub-type="preprint"><day>28</day><month>05</month><year>2025</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Accumulating evidence suggests that the brain continuously monitors the predictability of rapidly evolving sound sequences, even when they are not behaviorally relevant. An increasing body of empirical evidence links sustained tonic M/EEG activity to evidence accumulation and tracking the predictability, or inferred precision, of the auditory stimulus. However, it remains unclear whether, and how, this process depends on auditory contextual memory. In the present EEG study, we examined neural responses to sound sequences across two experiments, and compared them to predictions from ideal observer models with varying memory spans. Stimuli were sequences of 50 ms long tone-pips. In Experiment 1 (N=26; both sexes), a regularly repeating sequence of 10 tones (REG) transitioned directly to a different regular sequence (REGxREGy). In Experiment 2 (N=28; both sexes), the same regular sequence was repeated after an intervening random segment (REGxINTREGx). Results from Experiment 2 revealed that the inferred predictability of the resumed REGx pattern was influenced by the preceding INT tones, even several seconds after they ended, indicating that the brain retains contextual memory over time. In contrast, neural responses in Experiment 1 were best explained by models with minimal memory. This dissociation implies that the brain can dynamically adjust its strategy based on inferred environmental structure—resetting context when interruptions signal change, and preserving context when patterns are likely to resume.</p></abstract><kwd-group><kwd>Predictive Coding</kwd><kwd>Auditory scene analysis</kwd><kwd>Auditory memory</kwd><kwd>Regularity encoding</kwd><kwd>EEG</kwd></kwd-group></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">The human brain is remarkably sensitive to the statistical regularities ubiquitously present in our surroundings (<xref ref-type="bibr" rid="R2">Arnal &amp; Giraud, 2012</xref>; <xref ref-type="bibr" rid="R5">Bendixen, 2014</xref>; <xref ref-type="bibr" rid="R6">Bendixen et al., 2012</xref>; <xref ref-type="bibr" rid="R18">de Lange et al., 2018</xref>; <xref ref-type="bibr" rid="R39">Maheu et al., 2019</xref>; <xref ref-type="bibr" rid="R47">Press et al., 2020</xref>; <xref ref-type="bibr" rid="R61">Willmore &amp; King, 2023</xref>; <xref ref-type="bibr" rid="R65">Winkler et al., 2009</xref>). A large body of research has demonstrated that observers can automatically acquire complex statistics from sensory inputs, including auditory, visual, and multimodal streams (<xref ref-type="bibr" rid="R11">Boubenec et al., 2017</xref>; <xref ref-type="bibr" rid="R15">Conway &amp; Christiansen, 2005</xref>; <xref ref-type="bibr" rid="R19">Demarchi et al., 2019</xref>; <xref ref-type="bibr" rid="R23">Fiser &amp; Aslin, 2001</xref>; <xref ref-type="bibr" rid="R26">Garrido et al., 2013</xref>; <xref ref-type="bibr" rid="R33">Horváth et al., 2001</xref>; <xref ref-type="bibr" rid="R50">Saffran et al., 1999</xref>; <xref ref-type="bibr" rid="R56">Stefanics et al., 2014</xref>; <xref ref-type="bibr" rid="R57">Turk-Browne et al., 2009</xref>; <xref ref-type="bibr" rid="R59">Wacongne et al., 2011</xref>). This computational ability is critical for generating predictions about the environment (<xref ref-type="bibr" rid="R5">Bendixen, 2014</xref>; <xref ref-type="bibr" rid="R6">Bendixen et al., 2012</xref>; <xref ref-type="bibr" rid="R18">de Lange et al., 2018</xref>; <xref ref-type="bibr" rid="R24">Friston, 2005</xref>; <xref ref-type="bibr" rid="R47">Press et al., 2020</xref>; <xref ref-type="bibr" rid="R65">Winkler et al., 2009</xref>), which allows the brain to optimize behavior by efficient allocation of cognitive and neural resources, supporting adaptive responses to incoming events (<xref ref-type="bibr" rid="R6">Bendixen et al., 2012</xref>; <xref ref-type="bibr" rid="R11">Boubenec et al., 2017</xref>; <xref ref-type="bibr" rid="R12">Bouwkamp et al., 2025</xref>; <xref ref-type="bibr" rid="R38">Kok et al., 2012</xref>; <xref ref-type="bibr" rid="R43">Nobre et al., 2007</xref>; <xref ref-type="bibr" rid="R55">Southwell &amp; Chait, 2018</xref>; <xref ref-type="bibr" rid="R67">Yon et al., 2018</xref>).</p><p id="P3">An increasingly well-supported observation is that the neural mechanisms underlying the tracking of auditory statistical regularities can be studied through analyses of M/EEG sustained activity. These neural responses systematically vary with the predictability of sequential inputs, providing a direct window into how the brain monitors and adapts to environmental statistics (<xref ref-type="bibr" rid="R3">Barascud et al., 2016</xref>; <xref ref-type="bibr" rid="R31">Herrmann et al., 2019</xref>, <xref ref-type="bibr" rid="R30">2021</xref>; <xref ref-type="bibr" rid="R32">Herrmann &amp; Johnsrude, 2018</xref>; <xref ref-type="bibr" rid="R34">Hu et al., 2024</xref>; <xref ref-type="bibr" rid="R55">Southwell &amp; Chait, 2018</xref>; <xref ref-type="bibr" rid="R69">Zhao et al., 2025</xref>).</p><p id="P4">Experiments using rapidly evolving auditory sequences have progressively revealed how the auditory system processes and accumulates statistical information about the acoustic environment. In the standard paradigm (e.g., <xref ref-type="bibr" rid="R3">Barascud et al., 2016</xref>), participants passively listen to tone sequences that transition between regular (REG) frequency patterns and random (RND) patterns. These sequences elicit a sustained neural response that dynamically tracks the structure of the auditory input (<xref ref-type="bibr" rid="R3">Barascud et al., 2016</xref>; <xref ref-type="bibr" rid="R34">Hu et al., 2024</xref>; <xref ref-type="bibr" rid="R54">Southwell et al., 2017</xref>; <xref ref-type="bibr" rid="R69">Zhao et al., 2025</xref>). Specifically, the emergence of a REG pattern is associated with a gradual increase in sustained neural activity, which plateaus as the regularity becomes established—suggesting that the brain has stabilized a representation of the repeating structure. Notably, longer and more complex patterns result in slower and more moderate amplitude increases, indicating limitations in the brain’s ability to discover and maintain representations of higher-order statistical regularities. Upon transition from REG to RND, the sustained response drops sharply and then settles into a lower, stable level—interpreted as reflecting the low predictability of random sequences. <xref ref-type="bibr" rid="R69">Zhao et al. (2025)</xref> extended these findings to stochastic sequences consisting of RND patterns with different predictability. These rises and drops in the sustained response align with predictions from computational ideal observer models (<xref ref-type="bibr" rid="R29">Harrison et al., 2020</xref>; <xref ref-type="bibr" rid="R46">Pearce, 2005</xref>; <xref ref-type="bibr" rid="R52">Skerritt-Davis &amp; Elhilali, 2018</xref>, <xref ref-type="bibr" rid="R53">2021</xref>), which quantify information content (IC; how surprising a given tone is based on prior exposure) or precision (inferred reliability of the predictive distribution; <xref ref-type="bibr" rid="R66">Yon &amp; Frith, 2021</xref>) providing support for the hypothesis that the sustained response represents a mechanism that tracks predictability within the unfolding signal. However, it remains unclear how the brain determines the context or reference frame, whether derived from immediate sensory input or retrieved from longer-term memory, against which this predictability is assessed.</p><p id="P5">Commonly used modelling measures such as information content (e.g. as used in <xref ref-type="bibr" rid="R29">Harrison et al., 2020</xref>; <xref ref-type="bibr" rid="R46">Pearce, 2005</xref>), or precision (e.g. as used in <xref ref-type="bibr" rid="R69">Zhao et al. 2025</xref>), quantify the expectedness of an event given a particular context of previously encountered events stored in memory. In theory—drawing from Bayesian change-point estimation models (<xref ref-type="bibr" rid="R1">Adams &amp; MacKay, 2007</xref>; <xref ref-type="bibr" rid="R22">Fearnhead &amp; Liu, 2007</xref>; <xref ref-type="bibr" rid="R62">Wilson et al., 2010</xref>)—ideal observers should dynamically evaluate the relevance of a given context and determine how much of it to incorporate when constructing predictive distributions (<xref ref-type="bibr" rid="R28">Glaze et al., 2015</xref>; <xref ref-type="bibr" rid="R42">Nassar et al., 2010</xref>; <xref ref-type="bibr" rid="R52">Skerritt-Davis &amp; Elhilali, 2018</xref>, <xref ref-type="bibr" rid="R53">2021</xref>; <xref ref-type="bibr" rid="R63">Wilson et al., 2013</xref>). However, whether and how the sustained response, as a proxy for predictability processing, depends on experienced auditory events remains unexplored. Addressing these questions is crucial for understanding how past experiences are leveraged to represent the predictability of a given event.</p><p id="P6"><xref ref-type="bibr" rid="R9">Bianco et al. (2025)</xref> showed that REG patterns were recognized more quickly by the brain (as indicated by the MEG sustained response) when they were re-introduced following a scene interruption than when initially presented. This indicates the presence of an automatic memory store that carries a representation of the pattern across the interruption. More broadly, this finding suggests that by manipulating the information encountered by listeners and measuring its effects on the sustained response, it is possible to gain insight into what information is being stored and the conditions under which it is utilized. Here, we ask: Will the sustained response to a regular pattern be influenced by a listener’s prior experience with past information? This is tested by comparing two situations that differ in the relevance of prior experience: one in which a regularity is learned and then replaced by a new one—the prior experience is no longer relevant (Experiment 1), and another in which a regularity is learned, interrupted by a random tone sequence whose length is varied systematically, and then resumed—the prior experience is relevant and could be carried over (Experiment 2).</p></sec><sec id="S2"><title>Experiment 1</title><p id="P7">This experiment examines changes in the EEG sustained response triggered by transitions between two distinct regular (REG) patterns—REGx to REGy – compared with a continuation of REGx (<xref ref-type="fig" rid="F1">Figure 1A</xref>). A similar comparison was made in one of the experimental conditions reported by <xref ref-type="bibr" rid="R9">Bianco et al. (2025)</xref> using MEG. Here, we replicate that approach using EEG to justify the use of EEG in the extension reported in Experiment 2.</p><p id="P8">To inform our interpretation of the data, we use IDyOM, which implements a variable-order Markov model based on the Prediction by Partial Matching algorithm (<xref ref-type="bibr" rid="R29">Harrison et al., 2020</xref>; <xref ref-type="bibr" rid="R46">Pearce, 2005</xref>). The model has been extensively and successfully used to account for regularity processing in artificial sequences, such as those used in the current study (<xref ref-type="bibr" rid="R3">Barascud et al., 2016</xref>; <xref ref-type="bibr" rid="R8">Bianco et al., 2020</xref>, <xref ref-type="bibr" rid="R9">2025</xref>; <xref ref-type="bibr" rid="R29">Harrison et al., 2020</xref>), as well as in more naturalistic musical settings (<xref ref-type="bibr" rid="R14">Cheung et al., 2019</xref>, <xref ref-type="bibr" rid="R13">2023</xref>; <xref ref-type="bibr" rid="R20">Di Liberto et al., 2020</xref>; <xref ref-type="bibr" rid="R37">Kern et al., 2022</xref>; <xref ref-type="bibr" rid="R48">Quiroga-Martinez et al., 2021</xref>).</p><p id="P9">Starting with a null model, IDyOM learns incrementally based on the unfolding tone sequence and uses its learned model to generate a conditional probability distribution for each tone given the preceding tones. <xref ref-type="fig" rid="F1">Figure 1B</xref> shows model predictions. To simulate the availability of different amounts of contextual information for REGy pattern detection, we varied the duration of the input sequence—referred to as the “pre-training window”—the model was trained on before the transition to REGy. In the simulations shown in <xref ref-type="fig" rid="F1">Figure 1B</xref>, this window ranged from just a few seconds to 240 trials. Model predictions were always based on the full context available up to that point (i.e., all prior input; see figure legend). This approach allowed us to systematically manipulate the model’s memory content to examine how varying levels of prior information influence its output. The model quantifies the information content (IC) of each tone —reflecting the surprise elicited by that tone given the preceding context. We compare a <italic>context incorporating model</italic> that retains increasingly long spans of past input (from a few seconds to the entire experiment) with a <italic>reset model</italic> that clears its memory upon detecting a deviant tone—the first tone in REGy that violates expectations based on REGx.</p><p id="P10">All models show a gradual decrease in IC during REGx as the pattern is learned. This decrease occurs at different rates depending on the pre-training window; models with longer pretraining windows exhibit greater variability across trials (indicated by larger error bars) due to cumulative influences from prior tones. At the transition to REGy, all models show a sharp increase in IC, corresponding to the surprise elicited by an unpredictable tone. IC then remains high for a period before gradually reducing again, indicating that the new regularity (REGy) is being learned. The duration of this learning period varies across models: models with a shorter pre-training window (e.g., Model 1.2) take longer to adapt (reflected by a slower decrease in IC), as existing memory content of REGx interferes with the encoding of the new pattern. Conversely, models with a longer pre-training window (e.g., Model 1.4) or where training is reset (e.g., Model 2) exhibit a more rapid decrease in IC, as the representation of REGy is less affected by prior memory of REGx.</p><p id="P11">This example also illustrates how the difference in IC between REGy and the non-changing REG control condition is modulated by the pre-training window. When the pre-training window is short, the difference in IC is consistently large, as the memory of REGx strongly influences the encoding of REGy. However, as the model’s pre-training window increases in length, this difference diminishes due to memory saturation: previously encountered patterns interfere with both REGx and REGy representations. In the <italic>reset</italic> model, the IC difference is also low, reflecting a complete lack of memory competition.</p><p id="P12">As discussed, the M/EEG sustained response is thought to reflect neural tracking of sequence predictability. If the brain represents sequence information similarly to the model, we would expect neural activity to mirror the dynamics of IC.</p></sec><sec id="S3" sec-type="methods"><title>Methods</title><sec id="S4"><title>Stimuli</title><p id="P13">The stimuli (<xref ref-type="fig" rid="F1">Figure 1A</xref>) were 3500 ms long sequences composed of 50 ms tone pips (5 ms raised cosine ramps; 70 tone pips in total). REG sequences were generated by randomly selecting 10 frequencies from a pool of 20 logarithmically spaced values between 222 and 2000 Hz without replacement, and this sequence was cycled to create a regularly repeating pattern. For the REGxREGy sequence, two distinct REG sequences were generated: the first REG pattern (REGx) lasted 2 s, and the second (REGy) lasted 1.5 s. REGx was formed by randomly selecting 10 frequencies from the pool without replacement, and the remaining 10 frequencies were used to form REGy (<xref ref-type="fig" rid="F1">Figure 1A</xref>). A unique sound sequence was generated for each trial and participant. The inter-stimulus interval (ISI) was jittered between 2.5 and 3 s.</p></sec><sec id="S5" sec-type="methods"><title>Procedure</title><p id="P14">These data were collected as part of a separate study (Magami et al., in prep), that contained other stimuli (presented in a separate block).</p><p id="P15">Participants were seated in an acoustically shielded room (IAC triple-walled sound attenuating booth). They listened to auditory stimuli while engaging in a decoy visual task, presented on a computer screen located about 90 cm away. The visual task consisted of sequentially presented triplets of photographs of landscapes, and participants were instructed to press a key when the first and third images were the same (occurring in 40% of trials). Feedback regarding the number of hits, misses, and false alarms for the visual task was provided at the end of each block. The duration of the image presentation was jittered between 2 and 5 s, and images were cross faded to avoid abrupt visual transients. The timing of image presentation was not correlated with that of the auditory stimuli.</p><p id="P16">Overall, 120 sound stimuli were presented for each of the two sound conditions (REG, REGxREGy). These stimuli were presented randomly and arranged in 4 blocks. Sounds were presented diotically through headphones (3A Insert Earphone, 3M) via a Fireface UC sound card (RME) at a comfortable listening level (adjusted by each participant). Stimulus presentation was controlled with the Psychtoolbox package (Psychophysics Toolbox Version 3) in MATLAB (2019b The MathWorks, Inc.).</p></sec><sec id="S6"><title>Recording, data processing, and statistical analysis</title><p id="P17">EEG signals were recorded using a Biosemi system (Biosemi Active Two AD-box ADC-17, Biosemi, Netherlands) from 64 electrodes at a sampling rate of 2048 Hz. Recording was restarted at the beginning of each block. For data analysis, the Fieldtrip (<ext-link ext-link-type="uri" xlink:href="http://www.fieldtriptoolbox.org/">http://www.fieldtriptoolbox.org/</ext-link>) toolbox for MATLAB (2018a, MathWorks) was used.</p><p id="P18">The recorded data were down-sampled to 256 Hz, low-pass filtered at 30 Hz (two-pass, Butterworth, 5th-order) and detrended by a 1<sup>st</sup>-order polynomial. The data were divided into epochs of 6 s, from 1 s pre-stimulus onset to 1.5 s post-stimulus offset. The epochs were then baseline-corrected relative to the pre-onset interval (-0.5 s to 0 s relative to the sound onset). Outlier epochs and channels were removed by visual inspection, resulting in the removal of an average of 4.24 % of epochs and 0.9 channels per participant. De-noising source separation (DSS; <xref ref-type="bibr" rid="R16">De Cheveigné &amp; Parra, 2014</xref>; <xref ref-type="bibr" rid="R17">De Cheveigné &amp; Simon, 2008</xref>) analysis was then applied to each subject’s data across all conditions to maximize reproducibility across trials (over the interval of 0 s to 4 s relative to sound onset). For each participant, the first three DSS components were retained and projected back into sensor space. Finally, the data were re-referenced to the average of all channels, and the averages over epochs for each channel, condition and subject were calculated.</p><p id="P19">To quantify the effects, we selected the most auditory-responsive channels: for each participant, the N1 component (negative event-related potential happening at around 100 ms post-stimulus onset) of the sound onset response was identified from the averaged data. At the peak of the N1, the 5 channels showing the most positive activity and the 5 channels showing the most negative activity were considered to best reflect the brain’s auditory-related activity. In the figures below, we quantify the instantaneous power of the brain response by computing the RMS (root mean square) across these channels, following a similar approach in other works (<xref ref-type="bibr" rid="R3">Barascud et al., 2016</xref>; <xref ref-type="bibr" rid="R54">Southwell et al., 2017</xref>; <xref ref-type="bibr" rid="R69">Zhao et al., 2025</xref>). The RMS reflects the instantaneous power of the brain response regardless of polarity. Field maps at relevant time points are also provided.</p></sec><sec id="S7"><title>Statistical analysis</title><p id="P20">To statistically evaluate the effect of interruption, the differences between sound conditions were calculated for each participant. This difference was then subjected to bootstrap resampling (<xref ref-type="bibr" rid="R21">Efron &amp; Tibshirani, 1994</xref>). The difference between conditions was considered significant if the proportion of bootstrap iterations falling above or below zero exceeded 99% (p&lt;.01) for more than 8 adjacent samples (<xref ref-type="bibr" rid="R3">Barascud et al., 2016</xref>).</p></sec><sec id="S8" sec-type="subjects"><title>Participants</title><p id="P21">Twenty-eight paid participants participated in Experiment 1. All reported no history of hearing or neurological disorders. Two participants were excluded due to exceptionally noisy EEG data. Data from the remaining twenty-six participants (19 females; average age 24.81, ± 4.20) were used for analyses. All experimental procedures were approved by the research ethics committee of University College London, and written informed consent was obtained from each participant.</p></sec></sec><sec id="S9" sec-type="results | discussion"><title>Results and discussion</title><sec id="S10"><title>The EEG sustained response tracks regularity discovery and violation</title><p id="P22">The group averaged responses for the two conditions (REG, REGxREGy) are shown in <xref ref-type="fig" rid="F1">Figure 1C</xref>. Overall, we successfully replicated the findings from <xref ref-type="bibr" rid="R9">Bianco et al. (2025)</xref> with EEG.</p><p id="P23">The brain response exhibited an N1 peak at around 100 ms post-onset, then increased its amplitude until it reached a plateau before the end of the 2<sup>nd</sup> cycle of the REG sequence. This sustained response pattern aligns with previous literature and is thought to reflect a rapid, automatic process of regularity detection (<xref ref-type="bibr" rid="R3">Barascud et al., 2016</xref>; <xref ref-type="bibr" rid="R31">Herrmann et al., 2019</xref>, <xref ref-type="bibr" rid="R30">2021</xref>; <xref ref-type="bibr" rid="R32">Herrmann &amp; Johnsrude, 2018</xref>; <xref ref-type="bibr" rid="R34">Hu et al., 2024</xref>; <xref ref-type="bibr" rid="R54">Southwell et al., 2017</xref>). Following the emergence of the REGy pattern, the sustained response rapidly dropped in amplitude, persisted at a low level (whilst the new REG pattern was being discovered) and then returned to the pre-transition level. To analyze the difference in the post-transition responses between conditions, we baseline-corrected the data relative to the pre-transition window (1.5-2 s post-onset; <xref ref-type="fig" rid="F1">Figure 1C</xref>, right). Bootstrap resampling revealed a significant difference between the amplitudes of REG (control) and REGxREGy, starting from 220 ms (~5 tones) after the interruption, consistent with the timing shown in the MEG data from <xref ref-type="bibr" rid="R9">Bianco et al. (2025)</xref>.</p><p id="P24">As noted previously (<xref ref-type="bibr" rid="R3">Barascud et al., 2016</xref>; <xref ref-type="bibr" rid="R9">Bianco et al., 2025</xref>), unlike during regularity discovery, the EEG response latency here diverges from model predictions, which show a spike in IC immediately following the first tone that violates the REG pattern. Several factors could account for this divergence. One possibility is that the delay reflects a circuit-related delay in encoding the violation of the REG pattern. Alternatively, it might reflect a “wait-and-see” period, during which the system accumulates information about the scene change before responding. Indeed, <xref ref-type="bibr" rid="R9">Bianco et al. (2025)</xref> demonstrated that this latency is not fixed but scales with sequence information content (tone-pip duration), challenging the idea of a simple refractory period.</p><p id="P25">Following the abrupt drop in the sustained response, levels remained low for a period before rising again. The difference between conditions disappeared at 800 ms post-interruption (16 tones), at which point the response to REGy returned to the levels of the no change control condition (REG). Overall, these patterns indicate that the EEG sustained response dynamically tracks the brain’s process of discovering predictability, detecting its violation, and then fully re-establishing a new regularity.</p></sec><sec id="S11"><title>Reconciling differences between modeling and the EEG response</title><p id="P26">There are notable differences between the EEG responses and the model’s behavior. For instance, as previously noted, the model exhibits an immediate response to the transition from REGx to REGy, whereas brain responses show a delay of about five tones.</p><p id="P27">A key point of divergence lies in how the model handles multiple cycles of regularity. Even in the control condition (no change, REG), the model continues to refine its representation of REG with each successive cycle. In contrast, the EEG sustained response to REG plateaus after approximately two cycles, indicating that the brain’s representation stabilizes relatively quickly.</p><p id="P28">As a result, in the model, REGy never reaches the same representational strength as REG in the control condition, since REG continues to be refined indefinitely. However, EEG data show that the transition from REGx to REGy leads to a return to the same level of sustained activity observed for REG within about one second of REGy onset. This discrepancy suggests that aspects of evidence accumulation—or more generally, auditory processing—that shape brain responses are not fully captured by the model.</p><p id="P29">Despite these differences, the models most consistent with the EEG findings are those in which the post-transition difference between REG and REGy is minimal—that is, models in which REGx and REGy do not strongly compete in memory. Such models typically either have a long pre-training window (e.g., Model 1.4) or are reset at the point of transition (Model 2), enabling a rapid reinstatement of a REGx-like response to REGy.</p><p id="P30">To further refine this interpretation, in Experiment 2, we asked how prior context affects the ‘rediscovery’ of a previously experienced regularity. To address this, we examined responses to an identical REG pattern while systematically varying the immediately preceding context.</p></sec><sec id="S12"><title>Experiment 2</title><p id="P31">We investigated the EEG sustained response evoked by an ongoing regular (REG) pattern occasionally interrupted partway. We employed a stimulus set (<xref ref-type="fig" rid="F2">Figure 2A</xref>) in which 25% of the trials consisted of a regularly repeating sequence of tones. In the remaining trials, the regular pattern was interrupted by the insertion of 1, 3, or 5 novel tones (referred to as conditions INT1, INT3, and INT5, respectively) after which the original REG pattern resumed. We asked how this interruption would affect the representation of REG, with a specific focus on the speed at which the regularity was re-discovered and the post-interruption sustained response.</p><p id="P32">As in Experiment 1, we constrained our hypothesis using IDyOM (<xref ref-type="fig" rid="F2">Figure 2B</xref>). In this case, the stimuli consisted of a continuous REG pattern interspersed with occasional deviant tones. As a result, the IC differences between conditions are markedly smaller than those observed in Experiment 1 (<xref ref-type="fig" rid="F1">Figure 1B</xref>). Nevertheless, the overall dynamics are consistent with those reported previously.</p><p id="P33">Importantly, the post-interruption behavior of the <italic>context incorporating</italic> model reveals two key phenomena: (1) Despite the post-interruption sequences being structurally identical across the INT conditions, IC levels remain distinct between them (<xref ref-type="fig" rid="F2">Figure 2C</xref>). This occurs because the model incorporates the interruption tones into its predictive framework, increasing baseline uncertainty. (2) The model exhibits “phantom” IC spikes, reflecting an expectation for the interruption to recur. This behavior arises because the model lacks the capacity to infer higher-order rules, such as the one-time occurrence of interruptions and the guaranteed resumption of the pre-interruption pattern. Overall, the model’s behavior is dictated by its perfect memory of all prior experiences, with every past observation—regardless of its present relevance—being weighted equally. This includes the singleton interruptions, which continue to influence the model’s present IC estimates. This pattern is largely preserved across models with different pre-training window lengths, though models with longer pre-training show less pronounced differences in post-interruption IC (due to memory saturation; as discussed in Experiment 1, above).</p><p id="P34">For a model whose memory is reset at the interruption (Model 2), IC differences between conditions are also present because the ‘post-interruption world’ contains different numbers of unique elements for each interruption condition. The interruption tones are incorporated into model predictions, thereby decreasing baseline predictability. This model does not display phantom spikes, because its memory does not contain the previously experienced REG and its transition to the interruption tones.</p><p id="P35">Another difference between the models concerns the speed at which the REG pattern is re-discovered, reflected in the timing of the decrease in IC following the interruption. The <italic>context-incorporating</italic> models exhibit a rapid re-discovery of REG, whereas in the <italic>reset</italic> model, this process is slower due to the unavailability of pre-interruption memory.</p><p id="P36">Building on these insights, we examine whether passively listening participants exposed to these sequences will mirror model behavior. Specifically, we investigate human susceptibility to past interruptions, and whether these transient disruptions affect subsequent representations of regularity in a similar manner to modelling.</p></sec></sec><sec id="S13" sec-type="methods"><title>Methods</title><sec id="S14"><title>Stimuli</title><p id="P37">The stimuli were 3500 ms long sequences of 50 ms tone pips (5 ms raised cosine ramps; 70 tone pips in total). Tone frequencies were drawn from a pool of 20 logarithmically spaced values between 222 and 2000 Hz. Each stimulus comprised a sequence of regularly repeating tones (REG), generated in the same manner as in Experiment 1 (<xref ref-type="fig" rid="F2">Figure 2A</xref>). In 25% of trials, the REG pattern continued with no interruption (INT0). In the remaining trials, an interruption in the form of 1, 3, or 5 new tones was introduced at 2000 ms post-onset (following 4 cycles of REG). These conditions will be referred to as INT1, INT3 and INT5, respectively. The frequencies of INT tones were randomly selected without replacement from the pool of remaining frequencies not used to form the REG sequence. Following INT, the original REG pattern was re-started. The duration of this remaining portion varied across conditions (1500 ms, 1450 ms, 1350 ms, and 1250 ms for INT0, 1, 3, and 5 conditions, respectively), ensuring that the overall tone number remained fixed at 70 tones. The ISI was jittered between 2.5-3 s. A unique sound sequence was generated for each trial and participant.</p></sec><sec id="S15" sec-type="methods"><title>Procedure</title><p id="P38">General procedures were identical to those in Experiment 1. Overall, 600 sound stimuli were presented (150 stimuli per condition; in random order). The session was divided into 5 blocks, each approximately 10 min long. Participants were allowed a short rest between blocks.</p></sec><sec id="S16"><title>Recording and data processing</title><p id="P39">General protocols were identical to those described in Experiment 1. On average, 1.47% of epochs were removed as outliers, along with 0.5 channels per participant. For the detailed comparisons of RMS values between conditions, we applied two different baseline correction time windows to the output RMS. For the comparison of the post-interruption neural response, we applied baseline correction at the time window before the interruption onset (1.5 s to 2 s post-onset). To compare the timing where the neural response after interruption tones stabilizes, we applied baseline correction at a different time window (3 s to 3.3 s post-onset). Additionally, post-interruption neural responses were compared across INT conditions (INT1, INT3, and INT5) by subtracting the control condition (INT0) from each INT condition, followed by baseline correction in the 1.5–2 s post-onset window.</p><p id="P40">To uncover activity potentially masked by the slow DC changes, the same analysis was performed on high-pass filtered data at 2 Hz (two-pass, Butterworth, 4th-order) with baseline correction applied just before the onset of the interruption (1.8 s to 2 s post-onset). DSS was applied to the data around the interruption tone (1.5 s to 4 s post-onset), and 2 components of the DSS outputs were retained for the data representation. As we were especially interested in the mismatch negativity (MMN)-like response to the pattern interruption, we selected the electrodes best reflecting the MMN response. To do this, we averaged the data across all conditions across all participants and selected the 10 electrodes with the most negative activation at the typical MMN response time (150 ms to 200 ms post-interruption-onset).</p><p id="P41">To examine the possible presence of the “phantom” interruption peaks, we analyzed the high-pass filtered data at 2 Hz by applying DSS separately to each experimental condition (2 s to 4 s post-onset) and extracted 2 components for the data representation. Analyzing each condition separately was necessary because the “phantom” peaks occur at a different latency in each condition (tone 52 and 62 in INT1, 54 and 64 in INT3, and 56 and 66 in INT5; <xref ref-type="fig" rid="F2">Figure 2B, C</xref>). The output data were then segmented into 600 ms epochs (from 400 ms before the model-based peak timing to 200 ms after the peak timing) to limit the analysis at around the model-inferred peak locations. The initial 200 ms of each epoch was used for baseline correction, and the responses from 10 channels (same as those used in the RMS calculation) were averaged.</p></sec><sec id="S17"><title>Statistical analysis</title><p id="P42">To statistically evaluate the effect of interruption, the differences between sound conditions (INT0, INT1, INT3, and INT5) were calculated for each participant. This difference was then subjected to bootstrap resampling (<xref ref-type="bibr" rid="R21">Efron &amp; Tibshirani, 1994</xref>). The difference between conditions was considered significant if the proportion of bootstrap iterations falling above or below zero exceeded 99% (p&lt;.01) for more than 8 adjacent samples (<xref ref-type="bibr" rid="R3">Barascud et al., 2016</xref>).</p><p id="P43">For the bootstrap analysis on data baseline-corrected to 3–3.3 s post-onset, we defined the final significance point as the moment when the neural response stabilized. To assess whether this timing differed across conditions, we repeated the bootstrap analysis for each condition pair (INT0 vs. INT1, INT0 vs. INT3, and INT0 vs. INT5). Specifically, we performed 1000 iterations of bootstrap resampling per pair and identified the last significant data point within the interval from INT offset to 3 s (the onset of the baseline correction window) in each iteration.</p></sec><sec id="S18" sec-type="subjects"><title>Participants</title><p id="P44">Thirty paid participants participated in Experiment 2. All reported no history of hearing or neurological disorders. Two participants were excluded due to exceptionally noisy EEG data. Data from the remaining twenty-eight participants (22 females; average age 23.4, ± 3.41) were used for analyses. All experimental procedures were approved by the research ethics committee of University College London, and written informed consent was obtained from each participant.</p></sec></sec><sec id="S19" sec-type="results | discussion"><title>Results and discussion</title><sec id="S20"><title>All interruption conditions elicit early MMN-like responses</title><p id="P45">Sensitivity to the interruption was evaluated by analyzing the response at the transition. To isolate the MMN-like response which we expected to be evoked by the INT (deviant) tones (<xref ref-type="fig" rid="F3">Figure 3</xref>), the EEG data were high-pass filtered at 2 Hz and averaged across trials for each condition (as detailed in the <xref ref-type="sec" rid="S13">Methods</xref> section). Indeed, the response is not visible in the non-high-pass-filtered data; see <xref ref-type="fig" rid="F4">Figure 4</xref>. Bootstrap resampling revealed significant deflection in the INT1, INT3, and INT5 conditions relative to the INT0 condition (<xref ref-type="fig" rid="F3">Figure 3</xref>), with latencies emerging between 70-100 ms post interruption onset. Notably, this latency and the corresponding topography (<xref ref-type="fig" rid="F3">Figure 3</xref>; bottom) are consistent with those commonly associated with the MMN response (<xref ref-type="bibr" rid="R64">Winkler, 2007</xref>). Overall, this suggests that the interruption was similarly detected by the brain in all conditions.</p></sec><sec id="S21"><title>The EEG sustained response tracks the dynamics of sequence IC</title><p id="P46">For each participant and condition, the RMS over 10 selected channels (detailed in the <xref ref-type="sec" rid="S13">Methods</xref> section) was calculated at each time point on the non-high-pass filtered data. The group averaged RMS amplitude for the four conditions (INT0, INT1, INT3, and INT5) is shown in <xref ref-type="fig" rid="F4">Figure 4A</xref>. The general trajectory mirrored the pattern observed in Experiment 1: the sustained response increased and plateaued as the brain adapted to the REG pattern, dropped in amplitude following the INT tones, and then recovered (but not fully to baseline) as the brain re-engaged with the REG pattern. This trajectory aligns with the information content patterns predicted by the IDyOM models.</p><p id="P47">Following the REG interruption, the sustained response dropped rapidly. To analyze differences in post-interruption responses across conditions, we baseline-corrected the data relative to the pre-interruption window (1.5–2 s post-onset; <xref ref-type="fig" rid="F4">Figure 4B</xref>). Bootstrap resampling (see <xref ref-type="sec" rid="S13">Methods</xref>) revealed a significant difference between the control condition (INT0) and the interruption conditions (INT1, INT3, and INT5), starting at 187 ms (~4 tones) after the interruption onset. This finding is consistent with previous observations (<xref ref-type="bibr" rid="R3">Barascud et al., 2016</xref>; <xref ref-type="bibr" rid="R9">Bianco et al., 2025</xref>), including Experiment 1 in this study.</p><p id="P48">As noted previously, one possibility is that the delay reflects a fixed refractory period after the MMN-like response or some other circuit-related delay in encoding the violation of the REG pattern. Alternatively, it might reflect a “wait-and-see” period. If the 4-tone latency reflects a period of assessment—during which the system evaluates whether the REG violation is a spurious event or indicative of a consistent stimulus change—we might expect no interruption response in INT1 but a larger response in INT5. This was partially observed: while all interruption conditions exhibited a similar latency for the sustained response drop, the trough was deeper for INT3 and INT5 than for INT1 (<xref ref-type="fig" rid="F4">Figure 4D</xref>)</p></sec><sec id="S22"><title>The EEG sustained response indicates a memory trace for REG post interruption</title><p id="P49">To assess the time required to re-learn the REG pattern—reflected in the recovery of the sustained response—we baseline-corrected the data relative to the post-recovery window (3–3.3 s post-onset; see indicated in <xref ref-type="fig" rid="F4">Figure 4C</xref>). Bootstrap resampling (see <xref ref-type="sec" rid="S13">Methods</xref>) identified time points where responses to the interruption conditions (INT1, INT3, and INT5) remained significantly below the control (INT0) condition. We defined amplitude recovery as the latest time point where this significant difference was observed. This occurred approximately 216 ms (~4 tones), 202 ms (~4 tones), and 285 ms (~5 tones) after the offset of the final interruption tone in the INT1, INT3, and INT5 conditions, respectively.</p><p id="P50">Under perfect memory conditions—as seen in the model dynamics—the timing of REG re-discovery following the interruption should be the same across all INT conditions, once the duration of the interruption is accounted for (i.e., subtracting 1, 3, or 5 tones, respectively; e.g., see <xref ref-type="fig" rid="F2">Figure 2C</xref>). In contrast, our results show a longer latency following INT5 compared to INT1 and INT3. Bootstrap resampling confirmed a consistent difference between the INT1/INT3 and INT5 conditions (<xref ref-type="fig" rid="F4">Figure 4C</xref>), suggesting that INT5 requires one additional tone to re-establish the REG pattern after REG is reintroduced. This may reflect neural memory constraints that limit the speed of pattern re-learning.</p><p id="P51">Critically, and notwithstanding the differences between conditions highlighted above, the observed recovery times were consistently shorter than a regularity cycle (i.e., &lt;10 tones) and faster than model predictions for the discovery of a new REG pattern (i.e., 1 cycle + ~5 tones, as observed in Experiment 1). This indicates that, despite the interruption, the brain retained a memory of the REG pattern, enabling faster re-discovery (see also <xref ref-type="bibr" rid="R9">Bianco et al., 2025</xref>).</p></sec><sec id="S23"><title>Persistent post-interruption sustained response differences between conditions</title><p id="P52">In contrast to the results in Experiment 1, after the interruption, persistent differences in the sustained response between INT 1, 3, 5 and INT0 were observed; <xref ref-type="fig" rid="F4">Figure 4B</xref> indicates that sustained responses did not return to the pre-interruption baseline in INT conditions. Given that the amplitude of the sustained response is hypothesized to reflect the brain’s representation of the predictability of unfolding sounds, this reduced amplitude suggests a decrease in inferred predictability with exposure to a greater number of INT tones, similar to that observed in modelling.</p><p id="P53">One salient feature in the model is the expectation of “phantom” interruption events at the onset of every regularity cycle following the pattern interruption (tone 52 and 62 in INT1, 54 and 64 in INT3, and 56 and 66 in INT5, as shown in <xref ref-type="fig" rid="F2">Figure 2B and C</xref>). Our analysis (see <xref ref-type="sec" rid="S13">Methods</xref>) did not yield consistent EEG parallels. We cannot rule-out the possibility that the noisy nature of EEG signals obscured them and that the fluctuations in the time domain (e.g. see <xref ref-type="fig" rid="F4">Figure 4B</xref>) are a smeared manifestation of these peaks.</p><p id="P54">The general pattern of a speeded re-discovery of REG and a persistent lower sustained response in the INT conditions matches the predictions of the “context incorporating” family of models. This is because the <italic>reset</italic> model does not predict faster re-discovery of REG, and the <italic>context incorporating</italic> models maintain a memory of the INT tones that directly affect the representation of the REG sequence following its resumption.</p><p id="P55">The mean amplitude patterns across INT conditions (<xref ref-type="fig" rid="F4">Figure 4D</xref>, left) were consistent with an effect of INT duration on the sustained response, although there was no statistically significant difference between the INT conditions (<italic>F</italic>(2,54) = 1.81, p = 0.17; repeated-measure ANOVA). The difference from the control (INT0) appeared graded, as reflected in the pattern of significance (horizontal lines) in <xref ref-type="fig" rid="F4">Figure 4B</xref>. Direct condition comparisons revealed only a small effect between INT1 and INT5 (<xref ref-type="fig" rid="F4">Figure 4D</xref>, right). This is perhaps not surprising given that the conditions only differed by the introduction of 2 tones. But overall, we can conclude that the pattern of EEG data is consistent with a model that maintains a long enough pre-training window to incorporate a memory of the preceding REG and the INT tones into the inferred predictability of the post-interruption REG.</p><p id="P56">Overall, these results indicate that the presence of interrupting tones affected the representation of REG even a second or more after the interruption had ended. This pattern aligns with the predictions of <italic>context incorporating</italic> models (Model 1) which suggest that memory of the INT tones influences the IC of the REG pattern in a manner reflected in the EEG data.</p></sec></sec><sec id="S24"><title>General Discussion</title><p id="P57">Our analysis focused on the dynamics of the EEG sustained response. Accumulating evidence suggests that it reflects the process of predictability tracking in statistically structured sequences (<xref ref-type="bibr" rid="R3">Barascud et al., 2016</xref>; <xref ref-type="bibr" rid="R9">Bianco et al., 2025</xref>; <xref ref-type="bibr" rid="R34">Hu et al., 2024</xref>; <xref ref-type="bibr" rid="R69">Zhao et al., 2025</xref>), supported by the coordinated processing of information across a distributed neural network. Source localization of the MEG sustained response (<xref ref-type="bibr" rid="R3">Barascud et al., 2016</xref>; <xref ref-type="bibr" rid="R9">Bianco et al., 2025</xref>; <xref ref-type="bibr" rid="R34">Hu et al., 2024</xref>) implicates a distributed network involving the auditory cortex (AC), hippocampus (HC), and inferior frontal gyrus (IFG) in representing REG patterns. This activity fluctuates dynamically, decreasing during REG interruptions and reinstating upon the discovery of a new REG pattern. These fluctuations likely reflect the disruption of top-down connectivity when an existing model is deemed no longer relevant and the strengthening of top-down connectivity when predictive models are available.</p><p id="P58">We investigated whether and how the passive-listening brain utilizes past experiences to represent ongoing sound sequences by recording EEG sustained responses in two situations: one in which a REG sequence is replaced by a different REG sequence (Experiment 1) — and another in which a REG sequence is occasionally disrupted by a varying number of new tones (Experiment 2).</p><sec id="S25"><title>Sustained responses to REG patterns are affected by brief interruptions</title><p id="P59">Experiment 2 revealed that sustained responses to the post-interruption REG patterns were affected by the INT tones. This finding suggests that the brain represents the post-INT REG sequence using past information, including the history of INT tones.</p><p id="P60">Prior research shows that the brain incorporates long-term sensory history when processing sequences (<xref ref-type="bibr" rid="R39">Maheu et al., 2019</xref>; <xref ref-type="bibr" rid="R49">Rubin et al., 2016</xref>; <xref ref-type="bibr" rid="R58">Ulanovsky et al., 2004</xref>; see also <xref ref-type="bibr" rid="R19">Demarchi et al., 2019</xref>; <xref ref-type="bibr" rid="R25">Fritsche et al., 2022</xref>), though estimates of this duration vary depending on the specifics of the paradigm used. For instance, <xref ref-type="bibr" rid="R49">Rubin et al.(2016)</xref> found that auditory cortex neurons in anesthetized cats best fit prediction models accounting for more than ten previous tones (~9 seconds). Similarly, <xref ref-type="bibr" rid="R7">Benjamin et al. (2024)</xref> showed that tone information remains decodable from MEG responses for approximately eight successive items (2 seconds) during passive listening. <xref ref-type="bibr" rid="R52">Skerritt-Davis and Elhilali (2018)</xref> revealed that memory span, estimated by fitting a Bayesian perceptual model to behavioral data, correlated with performance, extending up to the full duration of each sequence (60 tones; ~19 seconds). <xref ref-type="bibr" rid="R69">Zhao et al. (2025)</xref> applied a similar model to random tone-pip sequences and found that most listeners based their judgments on a context of 20–40 tones (~1-2 seconds).</p><p id="P61">Here, we show that even brief contextual perturbations—such as a single interrupting tone—can alter the brain’s representation of an ongoing pattern. Given the link between the sustained response and perceived predictability, the reduced sustained response amplitude following interrupting (INT) tones indicates that the inferred predictability of the REG pattern was diminished after the interruption, despite no change in the stimulus itself.</p><p id="P62">This phenomenon—where transient surprise alters neural responses to an otherwise unchanged stimulus—has been observed across multiple research domains. In post-traumatic stress disorder (PTSD), for example, neural and physiological responses to a stimulus can change after a surprising or stressful event coincides with it, even if the stimulus itself remains the same (<xref ref-type="bibr" rid="R35">Kaczkurkin et al., 2017</xref>; <xref ref-type="bibr" rid="R44">Nutt &amp; Malizia, 2004</xref>; <xref ref-type="bibr" rid="R51">Sartory et al., 2013</xref>; <xref ref-type="bibr" rid="R60">Wessa &amp; Flor, 2007</xref>). Similarly, in perceptual decision-making, when participants predict an image’s location or value based on previous patterns, a surprising rule deviation can significantly alter their representation of the stimulus and its environment (<xref ref-type="bibr" rid="R36">Kao et al., 2020</xref>; <xref ref-type="bibr" rid="R40">McGuire et al., 2014</xref>; <xref ref-type="bibr" rid="R42">Nassar et al., 2010</xref>, <xref ref-type="bibr" rid="R41">2012</xref>). This consistency across different psychological domains suggests a fundamental heuristic employed by the brain to track environmental changes.</p></sec><sec id="S26"><title>Sustained response dynamics reflect memory of INT and pre-interruption REG</title><p id="P63">As discussed above, the sustained response modulations are consistent with a memory trace for the interruption, which causes the sustained response to settle below the level observed in the control condition (INT0). As seen also in the model, the same memory effects also influence the speed of REG re-discovery after INT. Specifically, re-discovery occurs more rapidly than the initial discovery of a new regularity (see also <xref ref-type="bibr" rid="R9">Bianco et al., 2025</xref>). In all cases, the sustained response begins to rise before a full cycle of the REG pattern has elapsed. Thus, both the modulation of the sustained response and the accelerated re-discovery of REG following INT reflect the system’s use of prior information, aligning with the notion of a “context-incorporating” memory process, even within a simplified model framework.</p><p id="P64">Interestingly, the response dynamics also suggest memory decay. According to the model, under perfect memory conditions, the latency of REG re-discovery should be identical across INT conditions once the duration of the interruption is accounted for. However, this is not what we observe in the EEG data: following INT5, the re-discovery is delayed by approximately one tone (50 ms) compared to shorter interruptions. This delay cannot be explained by increased memory interference, as each INT condition uses a distinct set of tones, eliminating overlap. Instead, the delay points to a reduction in memory duration—i.e., decay—rather than a loss of memory content. This finding is significant because it demonstrates that memory decay can be detected within this paradigm, even during passive listening.</p></sec><sec id="S27"><title>Distinct sustained response patterns in Experiment 1 and Experiment 2 suggest listeners can use or ignore context depending on its relevance</title><p id="P65">Experiment 1 yielded a different pattern of results to Experiment 2, despite the use of similar sound stimuli and the same analysis protocol. While acknowledging that Experiments 1 and 2 were conducted separately and differ in several respects—making direct comparisons necessarily speculative—this divergence suggests that the passive-listening brain may employ a flexible context integration strategy.</p><p id="P66">In Experiment 1, the sustained response indicated that the REGy representation remained unaffected by the REGx context, as reflected in the full recovery of REGy amplitude to the REGx level (<xref ref-type="fig" rid="F1">Figure 1</xref>). This pattern aligns with models where the REGx memory was either diluted by other contextual memories or erased entirely. In our simple modelling world, the results of Experiment 1 are either consistent with the <italic>reset</italic> model (Model 2) or a <italic>context incorporating</italic> model that learns from a relatively long prior context (e.g. Model 1.4).</p><p id="P67">In contrast, as discussed above, the pattern of results in Experiment 2 is not consistent with a <italic>reset</italic> model, but rather with models maintaining a memory of the preceding trials. Notably, as illustrated in <xref ref-type="fig" rid="F2">Figure 2</xref>, <italic>context incorporating</italic> models predict a greater IC deviation from the control condition (REG, INT0) in the REGxREGy condition (Experiment 1) than in the INT5 condition (Experiment 2). However, the EEG data reveal the opposite pattern—the INT5 condition shows a larger deviation from the control. Therefore, to reconcile both experiments, a parsimonious conclusion is that different strategies are used by the brain in the two experiments: a “memory reset” strategy for Experiment 1 and a “memory incorporating” strategy for Experiment 2.</p><p id="P68">One possible explanation for the existence of different strategies in the two experiments lies in the distinct differences in stimulus set, and hence listeners’ belief about the environment imposed in the two experiments. In Experiment 1, a violation of REGx (the first tone violating the REGx pattern) was always associated with a transition to a new pattern (REGy), meaning that REGx was not relevant, and its representation could be discarded to facilitate the learning of REGy. In contrast, in Experiment 2, the regular pattern consistently re-emerged shortly after an interruption, reinforcing the expectation that the pre-interruption REG sequence remained relevant. Therefore, in Experiment 1, participants may have automatically adapted by discarding the REGx representation, similar to the behavior of the <italic>reset</italic> model, which erases prior context when making new predictions. Conversely, in Experiment 2, participants may have learned that the pre-interruption REG pattern remained relevant, leading them to preserve its memory even after the interruption. This difference suggests the brain’s ability to flexibly adjust its memory integration strategies based on the statistical structure of the auditory environment.</p><p id="P69">Importantly, a similar effect was also observed in <xref ref-type="bibr" rid="R9">Bianco et al. (2025</xref>; <xref ref-type="fig" rid="F6">Figure 6</xref> reproduces their findings). In that study, the authors investigated two experimental auditory environments. One, labelled ‘ENVnovel’, consisted of sequences that always transitioned to a new pattern (REGxREGy, as in the current study; REGxRND; and a REGx control). The other context, ‘ENVresume’, presented in a separate set of blocks, included REGxRND and REGx sequences but also, crucially, a condition in which the original REGx pattern resumed after an interruption by 10 random tones (REGx-RND-REGx; Unlike in the present Experiment 2, the length of the interruption was not varied). Thus, while in ENVnovel it was possible to “discover” that once REGx was disrupted, the associated predictive model was no longer relevant (since REGx would not reappear), this was not the case in ENVresume, where REGx was reintroduced 30% of the time. The results of that experiment revealed a pattern consistent with the findings reported here: the sustained response in the REGx-RND-REGx condition was consistently lower than in its control counterpart. This suggests that the brain retains information about past regularities in memory even when they are not guaranteed to reoccur.</p><p id="P70">This flexibility in adjusting the duration of reference memory is considered a crucial feature of the brain, allowing it to maintain an accurate representation of a dynamically changing environment (<xref ref-type="bibr" rid="R10">Bland &amp; Schaefer, 2012</xref>; <xref ref-type="bibr" rid="R28">Glaze et al., 2015</xref>; <xref ref-type="bibr" rid="R45">O’Reilly, 2013</xref>; <xref ref-type="bibr" rid="R68">Yu &amp; Dayan, 2005</xref>). Such adjustments occur in response to environmental state changes or change points—moments when past observations become unreliable for predicting future events. When a change point occurs, minimizing the influence of past memory and prioritizing new evidence accumulation enables a rapid adaptation to the new environment (<xref ref-type="bibr" rid="R28">Glaze et al., 2015</xref>; <xref ref-type="bibr" rid="R42">Nassar et al., 2010</xref>; <xref ref-type="bibr" rid="R45">O’Reilly, 2013</xref>; <xref ref-type="bibr" rid="R52">Skerritt-Davis &amp; Elhilali, 2018</xref>, <xref ref-type="bibr" rid="R53">2021</xref>). Empirical studies, mostly conducted using tasks involving slow decision-making and active attention allocation, suggest that humans can flexibly adjust their change point assumptions based on volatility estimates (<xref ref-type="bibr" rid="R4">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="R28">Glaze et al., 2015</xref>, <xref ref-type="bibr" rid="R27">2018</xref>; <xref ref-type="bibr" rid="R42">Nassar et al., 2010</xref>). The present results suggest that similar heuristics might be operating on a faster time scale associated with sensory processing. Further controlled studies are needed to clarify these effects. For example, comparing results from conditions (REGx-INT-REGy vs REGx-INT-REGx) presented in separate blocks versus intermixed within the same block could help determine whether strategy adjustments occur on a trial-by-trial basis, at the block level, or require prolonged exposure throughout the experiment.</p><p id="P71">Additionally – it is important to stress that we use simple model comparisons focusing on varying the length of the pre-training window (consisting of counts of occurring n-grams). However, we did not account for other model dynamics or potential parameter variations. Moreover, while we used the IDyOM model due to its success in predicting human sequential processing (<xref ref-type="bibr" rid="R3">Barascud et al., 2016</xref>; <xref ref-type="bibr" rid="R14">Cheung et al., 2019</xref>; <xref ref-type="bibr" rid="R20">Di Liberto et al., 2020</xref>; <xref ref-type="bibr" rid="R37">Kern et al., 2022</xref>; <xref ref-type="bibr" rid="R48">Quiroga-Martinez et al., 2021</xref>), this model does not account for complex cognitive constraints, such as dynamic memory limitations and low-level auditory sensitivity. Further exploration of various models and model parameters is critical for our understanding of how the brain dynamically tracks the ongoing sequences under dynamic environments.</p></sec></sec></body><back><ack id="S28"><title>Acknowledgments</title><p>This work was supported by a BBSRC project grant to MC. KM is funded by Japan Student Services Organization. The funders had no role in study design, data collection, and analysis, decision to publish, or preparation of the manuscript.</p></ack><sec id="S29" sec-type="data-availability"><title>Data sharing</title><p id="P72">The data reported in this manuscript alongside related information will be available on OSF upon publication.</p></sec><fn-group><fn id="FN1" fn-type="conflict"><p id="P73"><bold>Conflicts of interest:</bold> The authors declared no conflicts of interest concerning the research, authorship, and/or publication of this article.</p></fn></fn-group><ref-list><ref id="R1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adams</surname><given-names>RP</given-names></name><name><surname>MacKay</surname><given-names>DJC</given-names></name></person-group><article-title>Bayesian Online Changepoint Detection</article-title><source>arXiv</source><year>2007</year><elocation-id>arXiv:0710.3742</elocation-id><pub-id pub-id-type="doi">10.48550/arXiv.0710.3742</pub-id></element-citation></ref><ref id="R2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arnal</surname><given-names>LH</given-names></name><name><surname>Giraud</surname><given-names>AL</given-names></name></person-group><article-title>Cortical oscillations and sensory predictions</article-title><source>Trends in Cognitive Sciences</source><year>2012</year><volume>16</volume><issue>7</issue><fpage>390</fpage><lpage>398</lpage><pub-id pub-id-type="pmid">22682813</pub-id></element-citation></ref><ref id="R3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barascud</surname><given-names>N</given-names></name><name><surname>Pearce</surname><given-names>MT</given-names></name><name><surname>Griffiths</surname><given-names>TD</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Chait</surname><given-names>M</given-names></name></person-group><article-title>Brain responses in humans reveal ideal observer-like sensitivity to complex acoustic patterns</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><year>2016</year><volume>113</volume><issue>5</issue><fpage>E616</fpage><lpage>E625</lpage><pub-id pub-id-type="pmcid">PMC4747708</pub-id><pub-id pub-id-type="pmid">26787854</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1508523113</pub-id></element-citation></ref><ref id="R4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Walton</surname><given-names>ME</given-names></name><name><surname>Rushworth</surname><given-names>MFS</given-names></name></person-group><article-title>Learning the value of information in an uncertain world</article-title><source>Nature Neuroscience</source><year>2007</year><volume>10</volume><issue>9</issue><fpage>1214</fpage><lpage>1221</lpage><pub-id pub-id-type="pmid">17676057</pub-id></element-citation></ref><ref id="R5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bendixen</surname><given-names>A</given-names></name></person-group><article-title>Predictability effects in auditory scene analysis: A review</article-title><source>Frontiers in Neuroscience</source><year>2014</year><day>8</day><month>MAR</month><volume>8</volume><fpage>1</fpage><lpage>16</lpage><pub-id pub-id-type="pmcid">PMC3978260</pub-id><pub-id pub-id-type="pmid">24744695</pub-id><pub-id pub-id-type="doi">10.3389/fnins.2014.00060</pub-id></element-citation></ref><ref id="R6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bendixen</surname><given-names>A</given-names></name><name><surname>SanMiguel</surname><given-names>I</given-names></name><name><surname>Schröger</surname><given-names>E</given-names></name></person-group><article-title>Early electrophysiological indicators for predictive processing in audition: A review</article-title><source>International Journal of Psychophysiology</source><year>2012</year><volume>83</volume><issue>2</issue><fpage>120</fpage><lpage>131</lpage><pub-id pub-id-type="pmid">21867734</pub-id></element-citation></ref><ref id="R7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benjamin</surname><given-names>L</given-names></name><name><surname>Sablé-Meyer</surname><given-names>M</given-names></name><name><surname>Fló</surname><given-names>A</given-names></name><name><surname>Dehaene-Lambertz</surname><given-names>G</given-names></name><name><surname>Al Roumi</surname><given-names>F</given-names></name></person-group><article-title>Long-Horizon Associative Learning Explains Human Sensitivity to Statistical and Network Structures in Auditory Sequences</article-title><source>The Journal of Neuroscience</source><year>2024</year><volume>44</volume><issue>14</issue><elocation-id>e1369232024</elocation-id><pub-id pub-id-type="pmcid">PMC10993028</pub-id><pub-id pub-id-type="pmid">38408873</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1369-23.2024</pub-id></element-citation></ref><ref id="R8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bianco</surname><given-names>R</given-names></name><name><surname>Harrison</surname><given-names>PM</given-names></name><name><surname>Hu</surname><given-names>M</given-names></name><name><surname>Bolger</surname><given-names>C</given-names></name><name><surname>Picken</surname><given-names>S</given-names></name><name><surname>Pearce</surname><given-names>MT</given-names></name><name><surname>Chait</surname><given-names>M</given-names></name></person-group><article-title>Long-term implicit memory for sequential auditory patterns in humans</article-title><source>eLife</source><year>2020</year><volume>9</volume><elocation-id>e56073</elocation-id><pub-id pub-id-type="pmcid">PMC7338054</pub-id><pub-id pub-id-type="pmid">32420868</pub-id><pub-id pub-id-type="doi">10.7554/eLife.56073</pub-id></element-citation></ref><ref id="R9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bianco</surname><given-names>R</given-names></name><name><surname>Magami</surname><given-names>K</given-names></name><name><surname>Pearce</surname><given-names>M</given-names></name><name><surname>Chait</surname><given-names>M</given-names></name></person-group><article-title>Discovery, Interruption, and Updating of Auditory Regularities in Memory: Evidence from Low-Frequency Brain Dynamics in Human MEG</article-title><year>2025</year><elocation-id>2025.03.28.645906</elocation-id><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2025.03.28.645906</pub-id></element-citation></ref><ref id="R10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bland</surname><given-names>AR</given-names></name><name><surname>Schaefer</surname><given-names>A</given-names></name></person-group><article-title>Different varieties of uncertainty in human decision-making</article-title><source>Frontiers in Neuroscience</source><year>2012</year><volume>6</volume><pub-id pub-id-type="pmcid">PMC3370661</pub-id><pub-id pub-id-type="pmid">22701401</pub-id><pub-id pub-id-type="doi">10.3389/fnins.2012.00085</pub-id></element-citation></ref><ref id="R11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boubenec</surname><given-names>Y</given-names></name><name><surname>Lawlor</surname><given-names>J</given-names></name><name><surname>Górska</surname><given-names>U</given-names></name><name><surname>Shamma</surname><given-names>S</given-names></name><name><surname>Englitz</surname><given-names>B</given-names></name></person-group><article-title>Detecting changes in dynamic and complex acoustic environments</article-title><source>eLife</source><year>2017</year><volume>6</volume><fpage>1</fpage><lpage>28</lpage><pub-id pub-id-type="pmcid">PMC5367897</pub-id><pub-id pub-id-type="pmid">28262095</pub-id><pub-id pub-id-type="doi">10.7554/eLife.24910</pub-id></element-citation></ref><ref id="R12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bouwkamp</surname><given-names>FG</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name><name><surname>Spaak</surname><given-names>E</given-names></name></person-group><article-title>Spatial Predictive Context Speeds Up Visual Search by Biasing Local Attentional Competition</article-title><source>Journal of Cognitive Neuroscience</source><year>2025</year><volume>37</volume><issue>1</issue><fpage>28</fpage><lpage>42</lpage><pub-id pub-id-type="pmid">39348146</pub-id></element-citation></ref><ref id="R13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheung</surname><given-names>VKM</given-names></name><name><surname>Harrison</surname><given-names>PMC</given-names></name><name><surname>Koelsch</surname><given-names>S</given-names></name><name><surname>Pearce</surname><given-names>MT</given-names></name><name><surname>Friederici</surname><given-names>AD</given-names></name><name><surname>Meyer</surname><given-names>L</given-names></name></person-group><article-title>Cognitive and sensory expectations independently shape musical expectancy and pleasure</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><year>2023</year><volume>379</volume><issue>1895</issue><elocation-id>20220420</elocation-id><pub-id pub-id-type="pmcid">PMC10725761</pub-id><pub-id pub-id-type="pmid">38104601</pub-id><pub-id pub-id-type="doi">10.1098/rstb.2022.0420</pub-id></element-citation></ref><ref id="R14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheung</surname><given-names>VKM</given-names></name><name><surname>Harrison</surname><given-names>PMC</given-names></name><name><surname>Meyer</surname><given-names>L</given-names></name><name><surname>Pearce</surname><given-names>MT</given-names></name><name><surname>Haynes</surname><given-names>J-D</given-names></name><name><surname>Koelsch</surname><given-names>S</given-names></name></person-group><article-title>Uncertainty and Surprise Jointly Predict Musical Pleasure and Amygdala, Hippocampus, and Auditory Cortex Activity</article-title><source>Current Biology</source><year>2019</year><volume>29</volume><issue>23</issue><fpage>4084</fpage><lpage>4092</lpage><elocation-id>e4</elocation-id><pub-id pub-id-type="pmid">31708393</pub-id></element-citation></ref><ref id="R15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Conway</surname><given-names>CM</given-names></name><name><surname>Christiansen</surname><given-names>MH</given-names></name></person-group><article-title>Modality-constrained statistical learning of tactile, visual, and auditory sequences</article-title><source>Journal of Experimental Psychology: Learning Memory and Cognition</source><year>2005</year><volume>31</volume><issue>1</issue><fpage>24</fpage><lpage>39</lpage><pub-id pub-id-type="pmid">15641902</pub-id></element-citation></ref><ref id="R16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Cheveigné</surname><given-names>A</given-names></name><name><surname>Parra</surname><given-names>LC</given-names></name></person-group><article-title>Joint decorrelation, a versatile tool for multichannel data analysis</article-title><source>NeuroImage</source><year>2014</year><volume>98</volume><fpage>487</fpage><lpage>505</lpage><pub-id pub-id-type="pmid">24990357</pub-id></element-citation></ref><ref id="R17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Cheveigné</surname><given-names>A</given-names></name><name><surname>Simon</surname><given-names>JZ</given-names></name></person-group><article-title>Denoising based on spatial filtering</article-title><source>Journal of Neuroscience Methods</source><year>2008</year><volume>171</volume><issue>2</issue><fpage>331</fpage><lpage>339</lpage><pub-id pub-id-type="pmcid">PMC2483698</pub-id><pub-id pub-id-type="pmid">18471892</pub-id><pub-id pub-id-type="doi">10.1016/j.jneumeth.2008.03.015</pub-id></element-citation></ref><ref id="R18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Lange</surname><given-names>FP</given-names></name><name><surname>Heilbron</surname><given-names>M</given-names></name><name><surname>Kok</surname><given-names>P</given-names></name></person-group><article-title>How Do Expectations Shape Perception?</article-title><source>Trends in Cognitive Sciences</source><year>2018</year><volume>22</volume><issue>9</issue><fpage>764</fpage><lpage>779</lpage><pub-id pub-id-type="pmid">30122170</pub-id></element-citation></ref><ref id="R19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Demarchi</surname><given-names>G</given-names></name><name><surname>Sanchez</surname><given-names>G</given-names></name><name><surname>Weisz</surname><given-names>N</given-names></name></person-group><article-title>Automatic and feature-specific prediction-related neural activity in the human auditory system</article-title><source>Nature Communications</source><year>2019</year><volume>10</volume><issue>1</issue><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="pmcid">PMC6672009</pub-id><pub-id pub-id-type="pmid">31371713</pub-id><pub-id pub-id-type="doi">10.1038/s41467-019-11440-1</pub-id></element-citation></ref><ref id="R20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Di Liberto</surname><given-names>GM</given-names></name><name><surname>Pelofi</surname><given-names>C</given-names></name><name><surname>Bianco</surname><given-names>R</given-names></name><name><surname>Patel</surname><given-names>P</given-names></name><name><surname>Mehta</surname><given-names>AD</given-names></name><name><surname>Herrero</surname><given-names>JL</given-names></name><name><surname>de Cheveigné</surname><given-names>A</given-names></name><name><surname>Shamma</surname><given-names>S</given-names></name><name><surname>Mesgarani</surname><given-names>N</given-names></name></person-group><article-title>Cortical encoding of melodic expectations in human temporal cortex</article-title><source>eLife</source><year>2020</year><volume>9</volume><fpage>1</fpage><lpage>26</lpage><pub-id pub-id-type="pmcid">PMC7053998</pub-id><pub-id pub-id-type="pmid">32122465</pub-id><pub-id pub-id-type="doi">10.7554/eLife.51784</pub-id></element-citation></ref><ref id="R21"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Efron</surname><given-names>B</given-names></name><name><surname>Tibshirani</surname><given-names>RJ</given-names></name></person-group><source>An Introduction to the Bootstrap</source><publisher-name>Chapman and Hall/CRC</publisher-name><year>1994</year><pub-id pub-id-type="doi">10.1201/9780429246593</pub-id></element-citation></ref><ref id="R22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fearnhead</surname><given-names>P</given-names></name><name><surname>Liu</surname><given-names>Z</given-names></name></person-group><article-title>On-Line Inference for Multiple Changepoint Problems</article-title><source>Journal of the Royal Statistical Society Series B: Statistical Methodology</source><year>2007</year><volume>69</volume><issue>4</issue><fpage>589</fpage><lpage>605</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9868.2007.00601.x</pub-id></element-citation></ref><ref id="R23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiser</surname><given-names>J</given-names></name><name><surname>Aslin</surname><given-names>RN</given-names></name></person-group><article-title>Unsupervised statistical learning of higher-order spatial structures from visual scenes</article-title><source>Psychological Science</source><year>2001</year><volume>12</volume><issue>6</issue><fpage>499</fpage><lpage>504</lpage><pub-id pub-id-type="pmid">11760138</pub-id></element-citation></ref><ref id="R24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name></person-group><article-title>A theory of cortical responses</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><year>2005</year><volume>360</volume><issue>1456</issue><fpage>815</fpage><lpage>836</lpage><pub-id pub-id-type="pmcid">PMC1569488</pub-id><pub-id pub-id-type="pmid">15937014</pub-id><pub-id pub-id-type="doi">10.1098/rstb.2005.1622</pub-id></element-citation></ref><ref id="R25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fritsche</surname><given-names>M</given-names></name><name><surname>Solomon</surname><given-names>SG</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><article-title>Brief Stimuli Cast a Persistent Long-Term Trace in Visual Cortex</article-title><source>The Journal of Neuroscience</source><year>2022</year><volume>42</volume><issue>10</issue><fpage>1999</fpage><lpage>2010</lpage><pub-id pub-id-type="pmcid">PMC8916757</pub-id><pub-id pub-id-type="pmid">35064003</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1350-21.2021</pub-id></element-citation></ref><ref id="R26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garrido</surname><given-names>MI</given-names></name><name><surname>Sahani</surname><given-names>M</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>Outlier Responses Reflect Sensitivity to Statistical Structure in the Human Brain</article-title><source>PLoS Computational Biology</source><year>2013</year><volume>9</volume><issue>3</issue><pub-id pub-id-type="pmcid">PMC3610625</pub-id><pub-id pub-id-type="pmid">23555230</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1002999</pub-id></element-citation></ref><ref id="R27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glaze</surname><given-names>CM</given-names></name><name><surname>Filipowicz</surname><given-names>ALS</given-names></name><name><surname>Kable</surname><given-names>JW</given-names></name><name><surname>Balasubramanian</surname><given-names>V</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><article-title>A bias-variance trade-off governs individual differences in on-line learning in an unpredictable environment</article-title><source>Nature Human Behaviour</source><year>2018</year><volume>2</volume><issue>3</issue><fpage>213</fpage><lpage>224</lpage><pub-id pub-id-type="doi">10.1038/s41562-018-0297-4</pub-id></element-citation></ref><ref id="R28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glaze</surname><given-names>CM</given-names></name><name><surname>Kable</surname><given-names>JW</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><article-title>Normative evidence accumulation in unpredictable environments</article-title><source>eLife</source><year>2015</year><month>August</month><volume>4</volume><fpage>1</fpage><lpage>27</lpage><comment>2015</comment><pub-id pub-id-type="pmcid">PMC4584511</pub-id><pub-id pub-id-type="pmid">26322383</pub-id><pub-id pub-id-type="doi">10.7554/eLife.08825</pub-id></element-citation></ref><ref id="R29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harrison</surname><given-names>PMC</given-names></name><name><surname>Bianco</surname><given-names>R</given-names></name><name><surname>Chait</surname><given-names>M</given-names></name><name><surname>Pearce</surname><given-names>MT</given-names></name></person-group><article-title>PPM-Decay: A computational model of auditory prediction with memory decay</article-title><source>PLoS Computational Biology</source><year>2020</year><volume>16</volume><issue>11</issue><pub-id pub-id-type="pmcid">PMC7668605</pub-id><pub-id pub-id-type="pmid">33147209</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008304</pub-id></element-citation></ref><ref id="R30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herrmann</surname><given-names>B</given-names></name><name><surname>Araz</surname><given-names>K</given-names></name><name><surname>Johnsrude</surname><given-names>IS</given-names></name></person-group><article-title>Sustained neural activity correlates with rapid perceptual learning of auditory patterns</article-title><source>NeuroImage</source><year>2021</year><volume>238</volume><elocation-id>118238</elocation-id><pub-id pub-id-type="pmid">34098064</pub-id></element-citation></ref><ref id="R31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herrmann</surname><given-names>B</given-names></name><name><surname>Buckland</surname><given-names>C</given-names></name><name><surname>Johnsrude</surname><given-names>IS</given-names></name></person-group><article-title>Neural signatures of temporal regularity processing in sounds differ between younger and older adults</article-title><source>Neurobiology of Aging</source><year>2019</year><volume>83</volume><fpage>73</fpage><lpage>85</lpage><pub-id pub-id-type="pmid">31585369</pub-id></element-citation></ref><ref id="R32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herrmann</surname><given-names>B</given-names></name><name><surname>Johnsrude</surname><given-names>IS</given-names></name></person-group><article-title>Neural signatures of the processing of temporal patterns in sound</article-title><source>Journal of Neuroscience</source><year>2018</year><volume>38</volume><issue>24</issue><fpage>5466</fpage><lpage>5477</lpage><pub-id pub-id-type="pmcid">PMC8174133</pub-id><pub-id pub-id-type="pmid">29773757</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0346-18.2018</pub-id></element-citation></ref><ref id="R33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horváth</surname><given-names>J</given-names></name><name><surname>Czigler</surname><given-names>I</given-names></name><name><surname>Sussman</surname><given-names>E</given-names></name><name><surname>Winkler</surname><given-names>I</given-names></name></person-group><article-title>Simultaneously active pre-attentive representations of local and global rules for sound sequences in the human brain</article-title><source>Cognitive Brain Research</source><year>2001</year><volume>12</volume><issue>1</issue><fpage>131</fpage><lpage>144</lpage><pub-id pub-id-type="pmid">11489616</pub-id></element-citation></ref><ref id="R34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hu</surname><given-names>M</given-names></name><name><surname>Bianco</surname><given-names>R</given-names></name><name><surname>Hidalgo</surname><given-names>AR</given-names></name><name><surname>Chait</surname><given-names>M</given-names></name></person-group><article-title>Concurrent Encoding of Sequence Predictability and Event-Evoked Prediction Error in Unfolding Auditory Patterns</article-title><source>The Journal of Neuroscience</source><year>2024</year><volume>44</volume><issue>14</issue><elocation-id>e1894232024</elocation-id><pub-id pub-id-type="pmcid">PMC10993036</pub-id><pub-id pub-id-type="pmid">38350998</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1894-23.2024</pub-id></element-citation></ref><ref id="R35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaczkurkin</surname><given-names>AN</given-names></name><name><surname>Burton</surname><given-names>PC</given-names></name><name><surname>Chazin</surname><given-names>SM</given-names></name><name><surname>Manbeck</surname><given-names>AB</given-names></name><name><surname>Espensen-Sturges</surname><given-names>T</given-names></name><name><surname>Cooper</surname><given-names>SE</given-names></name><name><surname>Sponheim</surname><given-names>SR</given-names></name><name><surname>Lissek</surname><given-names>S</given-names></name></person-group><article-title>Neural Substrates of Overgeneralized Conditioned Fear in PTSD</article-title><source>The American Journal of Psychiatry</source><year>2017</year><volume>174</volume><issue>2</issue><fpage>125</fpage><lpage>134</lpage><pub-id pub-id-type="pmcid">PMC7269602</pub-id><pub-id pub-id-type="pmid">27794690</pub-id><pub-id pub-id-type="doi">10.1176/appi.ajp.2016.15121549</pub-id></element-citation></ref><ref id="R36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kao</surname><given-names>C—H</given-names></name><name><surname>Khambhati</surname><given-names>AN</given-names></name><name><surname>Bassett</surname><given-names>DS</given-names></name><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>McGuire</surname><given-names>JT</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Kable</surname><given-names>JW</given-names></name></person-group><article-title>Functional brain network reconfiguration during learning in a dynamic environment</article-title><source>Nature Communications</source><year>2020</year><volume>11</volume><issue>1</issue><fpage>1682</fpage><pub-id pub-id-type="pmcid">PMC7125157</pub-id><pub-id pub-id-type="pmid">32245973</pub-id><pub-id pub-id-type="doi">10.1038/s41467-020-15442-2</pub-id></element-citation></ref><ref id="R37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kern</surname><given-names>P</given-names></name><name><surname>Heilbron</surname><given-names>M</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name><name><surname>Spaak</surname><given-names>E</given-names></name></person-group><article-title>Cortical activity during naturalistic music listening reflects short-range predictions based on long-term experience</article-title><source>eLife</source><year>2022</year><volume>11</volume><elocation-id>e80935</elocation-id><pub-id pub-id-type="pmcid">PMC9836393</pub-id><pub-id pub-id-type="pmid">36562532</pub-id><pub-id pub-id-type="doi">10.7554/eLife.80935</pub-id></element-citation></ref><ref id="R38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kok</surname><given-names>P</given-names></name><name><surname>Jehee</surname><given-names>JFM</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><article-title>Less Is More: Expectation Sharpens Representations in the Primary Visual Cortex</article-title><source>Neuron</source><year>2012</year><volume>75</volume><issue>2</issue><fpage>265</fpage><lpage>270</lpage><pub-id pub-id-type="pmid">22841311</pub-id></element-citation></ref><ref id="R39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maheu</surname><given-names>M</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Meyniel</surname><given-names>F</given-names></name></person-group><article-title>Brain signatures of a multiscale process of sequence learning in humans</article-title><source>eLife</source><year>2019</year><volume>8</volume><fpage>1</fpage><lpage>24</lpage><pub-id pub-id-type="pmcid">PMC6361584</pub-id><pub-id pub-id-type="pmid">30714904</pub-id><pub-id pub-id-type="doi">10.7554/eLife.41541</pub-id></element-citation></ref><ref id="R40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McGuire</surname><given-names>JT</given-names></name><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Kable</surname><given-names>JW</given-names></name></person-group><article-title>Functionally dissociable influences on learning rate in a dynamic environment</article-title><source>Neuron</source><year>2014</year><volume>84</volume><issue>4</issue><fpage>870</fpage><lpage>881</lpage><pub-id pub-id-type="pmcid">PMC4437663</pub-id><pub-id pub-id-type="pmid">25459409</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2014.10.013</pub-id></element-citation></ref><ref id="R41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Rumsey</surname><given-names>KM</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Parikh</surname><given-names>K</given-names></name><name><surname>Heasly</surname><given-names>B</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><article-title>Rational regulation of learning dynamics by pupil-linked arousal systems</article-title><source>Nature Neuroscience</source><year>2012</year><volume>15</volume><issue>7</issue><fpage>1040</fpage><lpage>1046</lpage><pub-id pub-id-type="pmcid">PMC3386464</pub-id><pub-id pub-id-type="pmid">22660479</pub-id><pub-id pub-id-type="doi">10.1038/nn.3130</pub-id></element-citation></ref><ref id="R42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Heasly</surname><given-names>B</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><article-title>An approximately Bayesian delta-rule model explains the dynamics of belief updating in a changing environment</article-title><source>Journal of Neuroscience</source><year>2010</year><volume>30</volume><issue>37</issue><fpage>12366</fpage><lpage>12378</lpage><pub-id pub-id-type="pmcid">PMC2945906</pub-id><pub-id pub-id-type="pmid">20844132</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0822-10.2010</pub-id></element-citation></ref><ref id="R43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nobre</surname><given-names>A</given-names></name><name><surname>Correa</surname><given-names>A</given-names></name><name><surname>Coull</surname><given-names>J</given-names></name></person-group><article-title>The hazards of time</article-title><source>Current Opinion in Neurobiology</source><year>2007</year><volume>17</volume><issue>4</issue><fpage>465</fpage><lpage>470</lpage><pub-id pub-id-type="pmid">17709239</pub-id></element-citation></ref><ref id="R44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nutt</surname><given-names>DJ</given-names></name><name><surname>Malizia</surname><given-names>AL</given-names></name></person-group><article-title>Structural and functional brain changes in posttraumatic stress disorder</article-title><source>The Journal of Clinical Psychiatry</source><year>2004</year><volume>65 Suppl 1</volume><fpage>11</fpage><lpage>17</lpage><pub-id pub-id-type="pmid">14728092</pub-id></element-citation></ref><ref id="R45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Reilly</surname><given-names>JX</given-names></name></person-group><article-title>Making predictions in a changing world-inference, uncertainty, and learning</article-title><source>Frontiers in Neuroscience</source><year>2013</year><volume>7</volume><pub-id pub-id-type="pmcid">PMC3682109</pub-id><pub-id pub-id-type="pmid">23785310</pub-id><pub-id pub-id-type="doi">10.3389/fnins.2013.00105</pub-id></element-citation></ref><ref id="R46"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Pearce</surname><given-names>MT</given-names></name></person-group><source>The construction and evaluation of statistical models of melodic structure in music perception and composition</source><publisher-name>PhD Thesis, City, University of London</publisher-name><year>2005</year><comment><ext-link ext-link-type="uri" xlink:href="http://openaccess.city.ac.uk/1189/">http://openaccess.city.ac.uk/1189/</ext-link></comment></element-citation></ref><ref id="R47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Press</surname><given-names>C</given-names></name><name><surname>Kok</surname><given-names>P</given-names></name><name><surname>Yon</surname><given-names>D</given-names></name></person-group><article-title>The Perceptual Prediction Paradox</article-title><source>Trends in Cognitive Sciences</source><year>2020</year><volume>24</volume><issue>1</issue><fpage>13</fpage><lpage>24</lpage><pub-id pub-id-type="pmid">31787500</pub-id></element-citation></ref><ref id="R48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quiroga-Martinez</surname><given-names>DR</given-names></name><name><surname>Hansen</surname><given-names>NC</given-names></name><name><surname>Højlund</surname><given-names>A</given-names></name><name><surname>Pearce</surname><given-names>M</given-names></name><name><surname>Brattico</surname><given-names>E</given-names></name><name><surname>Holmes</surname><given-names>E</given-names></name><name><surname>Friston</surname><given-names>K</given-names></name><name><surname>Vuust</surname><given-names>P</given-names></name></person-group><article-title>Musicianship and melodic predictability enhance neural gain in auditory cortex during pitch deviance detection</article-title><source>Human Brain Mapping</source><year>2021</year><volume>42</volume><issue>17</issue><fpage>5595</fpage><lpage>5608</lpage><pub-id pub-id-type="pmcid">PMC8559476</pub-id><pub-id pub-id-type="pmid">34459062</pub-id><pub-id pub-id-type="doi">10.1002/hbm.25638</pub-id></element-citation></ref><ref id="R49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rubin</surname><given-names>J</given-names></name><name><surname>Ulanovsky</surname><given-names>N</given-names></name><name><surname>Nelken</surname><given-names>I</given-names></name><name><surname>Tishby</surname><given-names>N</given-names></name></person-group><article-title>The Representation of Prediction Error in Auditory Cortex</article-title><source>PLOS Computational Biology</source><year>2016</year><volume>12</volume><issue>8</issue><elocation-id>e1005058</elocation-id><pub-id pub-id-type="pmcid">PMC4973877</pub-id><pub-id pub-id-type="pmid">27490251</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005058</pub-id></element-citation></ref><ref id="R50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saffran</surname><given-names>JR</given-names></name><name><surname>Johnson</surname><given-names>EK</given-names></name><name><surname>Aslin</surname><given-names>RN</given-names></name><name><surname>Newport</surname><given-names>EL</given-names></name></person-group><article-title>Statistical learning of tone sequences by human infants and adults</article-title><source>Cognition</source><year>1999</year><volume>70</volume><issue>1</issue><fpage>27</fpage><lpage>52</lpage><pub-id pub-id-type="pmid">10193055</pub-id></element-citation></ref><ref id="R51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sartory</surname><given-names>G</given-names></name><name><surname>Cwik</surname><given-names>J</given-names></name><name><surname>Knuppertz</surname><given-names>H</given-names></name><name><surname>Schürholt</surname><given-names>B</given-names></name><name><surname>Lebens</surname><given-names>M</given-names></name><name><surname>Seitz</surname><given-names>RJ</given-names></name><name><surname>Schulze</surname><given-names>R</given-names></name></person-group><article-title>In search of the trauma memory: A meta-analysis of functional neuroimaging studies of symptom provocation in posttraumatic stress disorder (PTSD)</article-title><source>PloS One</source><year>2013</year><volume>8</volume><issue>3</issue><elocation-id>e58150</elocation-id><pub-id pub-id-type="pmcid">PMC3607590</pub-id><pub-id pub-id-type="pmid">23536785</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0058150</pub-id></element-citation></ref><ref id="R52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skerritt-Davis</surname><given-names>B</given-names></name><name><surname>Elhilali</surname><given-names>M</given-names></name></person-group><article-title>Detecting change in stochastic sound sequences</article-title><source>PLoS Computational Biology</source><year>2018</year><volume>14</volume><issue>5</issue><fpage>1</fpage><lpage>24</lpage><pub-id pub-id-type="pmcid">PMC5993325</pub-id><pub-id pub-id-type="pmid">29813049</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006162</pub-id></element-citation></ref><ref id="R53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skerritt-Davis</surname><given-names>B</given-names></name><name><surname>Elhilali</surname><given-names>M</given-names></name></person-group><article-title>Computational framework for investigating predictive processing in auditory perception</article-title><source>Journal of Neuroscience Methods</source><year>2021</year><volume>360</volume><elocation-id>109177</elocation-id><pub-id pub-id-type="pmcid">PMC9017011</pub-id><pub-id pub-id-type="pmid">33839191</pub-id><pub-id pub-id-type="doi">10.1016/j.jneumeth.2021.109177</pub-id></element-citation></ref><ref id="R54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Southwell</surname><given-names>R</given-names></name><name><surname>Baumann</surname><given-names>A</given-names></name><name><surname>Gal</surname><given-names>C</given-names></name><name><surname>Barascud</surname><given-names>N</given-names></name><name><surname>Friston</surname><given-names>K</given-names></name><name><surname>Chait</surname><given-names>M</given-names></name></person-group><article-title>Is predictability salient? A study of attentional capture by auditory patterns</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><year>2017</year><volume>372</volume><issue>1714</issue><pub-id pub-id-type="pmcid">PMC5206273</pub-id><pub-id pub-id-type="pmid">28044016</pub-id><pub-id pub-id-type="doi">10.1098/rstb.2016.0105</pub-id></element-citation></ref><ref id="R55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Southwell</surname><given-names>R</given-names></name><name><surname>Chait</surname><given-names>M</given-names></name></person-group><article-title>Enhanced deviant responses in patterned relative to random sound sequences</article-title><source>Cortex</source><year>2018</year><volume>109</volume><fpage>92</fpage><lpage>103</lpage><pub-id pub-id-type="pmcid">PMC6259587</pub-id><pub-id pub-id-type="pmid">30312781</pub-id><pub-id pub-id-type="doi">10.1016/j.cortex.2018.08.032</pub-id></element-citation></ref><ref id="R56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stefanics</surname><given-names>G</given-names></name><name><surname>Stefanics</surname><given-names>G</given-names></name><name><surname>Kremláček</surname><given-names>J</given-names></name><name><surname>Czigler</surname><given-names>I</given-names></name></person-group><article-title>Visual mismatch negativity: A predictive coding view</article-title><source>Frontiers in Human Neuroscience</source><year>2014</year><month>September</month><volume>8</volume><fpage>1</fpage><lpage>19</lpage><pub-id pub-id-type="pmcid">PMC4165279</pub-id><pub-id pub-id-type="pmid">25278859</pub-id><pub-id pub-id-type="doi">10.3389/fnhum.2014.00666</pub-id></element-citation></ref><ref id="R57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turk-Browne</surname><given-names>NB</given-names></name><name><surname>Scholl</surname><given-names>BJ</given-names></name><name><surname>Chun</surname><given-names>MM</given-names></name><name><surname>Johnson</surname><given-names>MK</given-names></name></person-group><article-title>Neural Evidence of Statistical Learning: Efficient Detection of Visual Regularities Without Awareness</article-title><source>J Cogn Neurosci</source><year>2009</year><volume>21</volume><issue>10</issue><fpage>1934</fpage><lpage>1945</lpage><pub-id pub-id-type="pmcid">PMC2773825</pub-id><pub-id pub-id-type="pmid">18823241</pub-id><pub-id pub-id-type="doi">10.1162/jocn.2009.21131</pub-id></element-citation></ref><ref id="R58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ulanovsky</surname><given-names>N</given-names></name><name><surname>Las</surname><given-names>L</given-names></name><name><surname>Farkas</surname><given-names>D</given-names></name><name><surname>Nelken</surname><given-names>I</given-names></name></person-group><article-title>Multiple time scales of adaptation in auditory cortex neurons</article-title><source>Journal of Neuroscience</source><year>2004</year><volume>24</volume><issue>46</issue><fpage>10440</fpage><lpage>10453</lpage><pub-id pub-id-type="pmcid">PMC6730303</pub-id><pub-id pub-id-type="pmid">15548659</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1905-04.2004</pub-id></element-citation></ref><ref id="R59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wacongne</surname><given-names>C</given-names></name><name><surname>Labyt</surname><given-names>E</given-names></name><name><surname>Van Wassenhove</surname><given-names>V</given-names></name><name><surname>Bekinschtein</surname><given-names>T</given-names></name><name><surname>Naccache</surname><given-names>L</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><article-title>Evidence for a hierarchy of predictions and prediction errors in human cortex</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><year>2011</year><volume>108</volume><issue>51</issue><fpage>20754</fpage><lpage>20759</lpage><pub-id pub-id-type="pmcid">PMC3251061</pub-id><pub-id pub-id-type="pmid">22147913</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1117807108</pub-id></element-citation></ref><ref id="R60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wessa</surname><given-names>M</given-names></name><name><surname>Flor</surname><given-names>H</given-names></name></person-group><article-title>Failure of Extinction of Fear Responses in Posttraumatic Stress Disorder: Evidence From Second-Order Conditioning</article-title><source>American Journal of Psychiatry</source><year>2007</year><volume>164</volume><issue>11</issue><fpage>1684</fpage><lpage>1692</lpage><pub-id pub-id-type="pmid">17974933</pub-id></element-citation></ref><ref id="R61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Willmore</surname><given-names>BDB</given-names></name><name><surname>King</surname><given-names>AJ</given-names></name></person-group><article-title>Adaptation in auditory processing</article-title><source>Physiological Reviews</source><year>2023</year><volume>103</volume><issue>2</issue><fpage>1025</fpage><lpage>1058</lpage><pub-id pub-id-type="pmcid">PMC9829473</pub-id><pub-id pub-id-type="pmid">36049112</pub-id><pub-id pub-id-type="doi">10.1152/physrev.00011.2022</pub-id></element-citation></ref><ref id="R62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><article-title>Bayesian online learning of the hazard rate in change-point problems</article-title><source>Neural Computation</source><year>2010</year><volume>22</volume><issue>9</issue><fpage>2452</fpage><lpage>2476</lpage><pub-id pub-id-type="pmcid">PMC2966286</pub-id><pub-id pub-id-type="pmid">20569174</pub-id><pub-id pub-id-type="doi">10.1162/NECO_a_00007</pub-id></element-citation></ref><ref id="R63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><article-title>A Mixture of Delta-Rules Approximation to Bayesian Inference in Change-Point Problems</article-title><source>PLOS Computational Biology</source><year>2013</year><volume>9</volume><issue>7</issue><elocation-id>e1003150</elocation-id><pub-id pub-id-type="pmcid">PMC3723502</pub-id><pub-id pub-id-type="pmid">23935472</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003150</pub-id></element-citation></ref><ref id="R64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winkler</surname><given-names>I</given-names></name></person-group><article-title>Interpreting the mismatch negativity</article-title><source>Journal of Psychophysiology</source><year>2007</year><volume>21</volume><issue>3–4</issue><fpage>147</fpage><lpage>163</lpage><pub-id pub-id-type="doi">10.1027/0269-8803.21.34.147</pub-id></element-citation></ref><ref id="R65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winkler</surname><given-names>I</given-names></name><name><surname>Denham</surname><given-names>SL</given-names></name><name><surname>Nelken</surname><given-names>I</given-names></name></person-group><article-title>Modeling the auditory scene: Predictive regularity representations and perceptual objects</article-title><source>Trends in Cognitive Sciences</source><year>2009</year><volume>13</volume><issue>12</issue><fpage>532</fpage><lpage>540</lpage><pub-id pub-id-type="pmid">19828357</pub-id></element-citation></ref><ref id="R66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yon</surname><given-names>D</given-names></name><name><surname>Frith</surname><given-names>CD</given-names></name></person-group><article-title>Precision and the Bayesian brain</article-title><source>Current Biology</source><year>2021</year><volume>31</volume><issue>17</issue><fpage>R1026</fpage><lpage>R1032</lpage><pub-id pub-id-type="pmid">34520708</pub-id></element-citation></ref><ref id="R67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yon</surname><given-names>D</given-names></name><name><surname>Gilbert</surname><given-names>SJ</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name><name><surname>Press</surname><given-names>C</given-names></name></person-group><article-title>Action sharpens sensory representations of expected outcomes</article-title><source>Nature Communications</source><year>2018</year><volume>9</volume><issue>1</issue><fpage>4288</fpage><pub-id pub-id-type="pmcid">PMC6191413</pub-id><pub-id pub-id-type="pmid">30327503</pub-id><pub-id pub-id-type="doi">10.1038/s41467-018-06752-7</pub-id></element-citation></ref><ref id="R68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>AJ</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><article-title>Uncertainty, neuromodulation, and attention</article-title><source>Neuron</source><year>2005</year><volume>46</volume><issue>4</issue><fpage>681</fpage><lpage>692</lpage><pub-id pub-id-type="pmid">15944135</pub-id></element-citation></ref><ref id="R69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>S</given-names></name><name><surname>Skerritt-Davis</surname><given-names>B</given-names></name><name><surname>Elhilali</surname><given-names>M</given-names></name><name><surname>Dick</surname><given-names>F</given-names></name><name><surname>Chait</surname><given-names>M</given-names></name></person-group><article-title>Sustained EEG responses to rapidly unfolding stochastic sounds reflect Bayesian inferred reliability tracking</article-title><source>Progress in Neurobiology</source><year>2025</year><volume>244</volume><elocation-id>102696</elocation-id><pub-id pub-id-type="pmid">39647599</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>Experiment 1 stimuli, model simulations, and EEG results</title><p><bold>[A]</bold> Left: Schematic illustration of the frequency selection method in Experiment 1, with each frequency represented as a circle. In this example, the brown frequencies were allocated to REGx and the pink to REGy. Right: Spectrograms depicting example stimuli for each condition. The dashed line marks the onset of REGy. <bold>[B]</bold> Model simulations. We implemented the model using the “new_ppm_simple” function from the ppm R package, available on GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/pmcharrison/ppm">https://github.com/pmcharrison/ppm</ext-link>). All parameters were kept with their default settings, as described in the repository documentation. Middle: Information content (IC; log transformed) computed from variants of the IDyOM model, each incorporating different memory constraints. The y-axis is inverted (bottom = higher IC). The REG condition is shown in gray; REGxREGy condition is shown in green. For each condition, data are averaged over trials, with shaded areas representing twice the standard deviation (STDEV). Models vary by the duration of the “pre-training window”. Model 1.1 is pre-trained on 2 cycles of REGx (indicated by the brown arrow). Model 1.2 is pre-trained on 4 cycles of REGx. Model 1.3 is pre-trained over 3 trials. Model 1.4 is pre-trained over all 240 trials. Model 2 is reset upon pattern interruption, resulting in a pre-training window of length zero. All models estimate variable-order conditional probabilities for the next tone given the immediately preceding sequence of tones. The stimulus context over which the model learns representations of statistical structure that inform its conditional probabilistic predictions consists of the pre-training window and all tones experienced up to the time of prediction. The context varies between models, for example when predicting tone 50, the context is: Model 1.1, tones 20-49 of the current sequence; Model 1.2, tones 1-49 of the current sequence; Model 1.3, the three preceding trials plus tones 1-49 of the current sequence; Model 1.4, the 240 preceding trials plus tones 1-49 of the current sequence; Model 2, tones 41-49 of the current sequence. Right: Raw (non-log-transformed) IC values averaged over the last REGy cycle (tone 61 to 70; corresponding to 3 – 3.5 s). Left: IC differences (between REGxREGy and REG computed over tone 61-70) across all five models. <bold>[C]</bold> EEG data. Left: Group-averaged brain responses (RMS over 10 most responsive auditory channels; see <xref ref-type="sec" rid="S3">Methods</xref>). Shading indicates twice the SEM (computed via bootstrap resampling, 1000 iterations). Data are baseline-corrected relative to the 0.5-second pre-onset window. Right: The same data but baseline-corrected using the 1.5–2 s pre-transition window. Significant differences (p&lt;.01) between conditions are indicated by the horizontal bold line. Scalp topographies are based on activity averaged over the time window of significant differences (2.2–2.8 s relative to stimulus onset); the color ranges from -4 to 4 uV.</p></caption><graphic xlink:href="EMS206019-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Experiment 2 stimuli and model simulations</title><p><bold>[A]</bold> Left: Schematic of the frequency selection method in Experiment 2, with each frequency represented as a circle. The brown circles represent frequencies randomly chosen for REG; the pink circles represent tones chosen for the interruption tones (INT3 here). White circles denote unused frequencies in this trial. Middle: Spectrograms showing example stimuli for each condition. The white dashed box highlights the INT tones. The REG sequences before and after the INT tone follow an identical pattern. Right: Design schematics illustrating the stimulus sequences for each condition. ‘I’ indicates the interruption tones. <bold>[B]</bold> Model simulations. Middle: IC values (log-transformed) computed from variations of the IDyOM model, each with different memory constraints (as detailed in <xref ref-type="fig" rid="F1">Figure 1</xref>), plotted for the INT0 and INT5 conditions from Experiment 2, and REGxREGy condition from Experiment 1. For each condition, data are averaged over trials, with shaded areas representing twice the standard deviation (STDEV). The y-axis is inverted (bottom = higher IC). Right: Raw (non-log-transformed) IC values averaged over the last REG cycle (tone 61 to 70; corresponding to 3 – 3.5 s). Left: IC differences (between INT5 and INT0 computed over tone 61-70) across all five models. <bold>[C]</bold> IC values for all four conditions, computed using Model 1.2.</p></caption><graphic xlink:href="EMS206019-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Experiment 2: INT evoked deviance response</title><p>High-pass filtered mean EEG data, averaged over 10 channels (indicated in the scalp topographies). Shaded areas represent twice the SEM. Significant differences (p&lt;.01) between INT0 and interruption conditions (INT1, INT3, INT5) are indicated by the horizontal lines above the EEG traces. Scalp topographies, calculated for two time windows (2.1-2.2s and 2.25-2.3s), are shown at the bottom.</p></caption><graphic xlink:href="EMS206019-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Experiment 2: sustained response dynamics.</title><p><bold>[A]</bold> Group-averaged RMS of brain responses. Shaded areas represent twice the SEM. Data are baseline-corrected to the -0.5–0 s pre-onset window. Scalp topographies illustrate two response phases: N1 component (80–150 ms post-sound onset) and the sustained response (1–2 s post-sound onset); the color ranges from -4 to 4 uV. <bold>[B]</bold> Same data as in [A] but baseline-corrected to the pre-interruption window (1.5–2 s). Significant differences (p&lt;.01) between INT0 and INT1, INT3, INT5 are indicated by bold horizontal lines above the EEG traces. Scalp topographies are provided for three time windows: 2.2-2.3 s, 2.3-2.5 s, and 3-3.5 s relative to sound onset. <bold>[C]</bold> Same data as in [A], baseline-corrected to 3–3.3 s. Significant differences (p&lt;.01) between INT0 and INT1, INT3, INT5 are indicated by bold lines below the EEG traces. The histogram (inset) shows the latencies associated with REG re-discovery. The results demonstrate delayed rediscovery of REG in the INT5 condition. <bold>[D]</bold> Right: EEG data (RMS) for each of the interruption conditions after subtracting the INT0 condition, baseline-corrected within the pre-transition window (1.5–2 s). Grey lines beneath the traces mark significant differences (p&lt;.01) between INT conditions (INT1 vs. INT3, INT1 vs. INT5, INT3 vs. INT5). Left: Same data averaged over the 3–3.5 s time window (gray shading). Error bars represent SEM.</p></caption><graphic xlink:href="EMS206019-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>Comparing EEG across Experiments.</title><p>Group-averaged RMS of brain responses. The difference between REGxREGy and REG (Experiment 1) is shown in green. The difference between INT5 and INT0 (Experiment 2) is shown in purple. Data are baseline-corrected using the pre-transition window (1.5–2 s). Shaded areas indicate ±2 SEM.</p></caption><graphic xlink:href="EMS206019-f005"/></fig><fig id="F6" position="float"><label>Figure 6</label><caption><title>Results from <xref ref-type="bibr" rid="R9">Bianco et al. (2025)</xref> reveal results consistent with Experiment 2 here.</title><p>The study presented stimuli in two contexts. In ‘ENVnovel’, transitions were always to a new pattern (REGxREGy, as in the current study; REGRND; and a REG control). ‘ENVresume’, presented in a separate set of blocks, included REGRND and REG sequences but also, crucially, a condition in which the original REGx pattern resumed after an interruption by 10 random tones (REGx-RND-REGx). <bold>[A]</bold> Group-average MEG brain responses (RMS across “auditory” channels; see more details in <xref ref-type="bibr" rid="R9">Bianco et al. (2025)</xref>) from the ENVnovel block. Data are baseline-corrected to the -0.5–0 s pre-onset window. Significant differences are indicated by the bold line below the MEG traces. These results are consistent with those in Experiment 1 here. <bold>[B]</bold> Data from the ENVresume block, demonstrating a persistent difference between REG and REGx-RND-REGx conditions following the resumption of REGx. <bold>[C]</bold> Design schematics illustrating the stimulus sequences for each condition. <bold>[D]</bold> Direct comparison of REGxREGy from ENVnovel and REGx-RND-REGx from ENVresume. REGRND condition data are subtracted from each condition of interest. Significant differences between conditions are indicated by bold lines below the traces. The results demonstrate a reduced sustained response in ENVresume relative to ENVnovel, consistent with the observations in Experiment 1 and 2 here.</p></caption><graphic xlink:href="EMS206019-f006"/></fig></floats-group></article>