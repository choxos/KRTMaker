<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS207446</article-id><article-id pub-id-type="doi">10.1101/2025.07.15.664842</article-id><article-id pub-id-type="archive">PPR1053183</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">1</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Multiple Routes to Metacognitive Judgments of Working Memory in the Macaque Prefrontal Cortex</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Ning</surname><given-names>Chuan</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="fn" rid="FN1">*</xref></contrib><contrib contrib-type="author"><name><surname>Fu</surname><given-names>Guobin</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="fn" rid="FN1">*</xref></contrib><contrib contrib-type="author"><name><surname>Zhang</surname><given-names>Yan-Yu</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A3">3</xref><xref ref-type="fn" rid="FN1">*</xref></contrib><contrib contrib-type="author"><name><surname>Meyniel</surname><given-names>Florent</given-names></name><xref ref-type="aff" rid="A4">4</xref><xref ref-type="aff" rid="A5">5</xref></contrib><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Liping</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="corresp" rid="CR1">#</xref></contrib></contrib-group><aff id="A1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02sx86615</institution-id><institution>Institute of Neuroscience</institution></institution-wrap>, Key Laboratory of Primate Neurobiology, CAS Center for Excellence in Brain Science and Intelligence Technology, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/034t30j35</institution-id><institution>Chinese Academy of Sciences</institution></institution-wrap>, <city>Shanghai</city><postal-code>200031</postal-code>, <country country="CN">China</country></aff><aff id="A2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05qbk4x57</institution-id><institution>University of Chinese Academy of Sciences</institution></institution-wrap>, <city>Beijing</city><postal-code>100049</postal-code>, <country country="CN">China</country></aff><aff id="A3"><label>3</label>Brain Health Institute, National Center for Mental Disorders, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/05bd2wa15</institution-id><institution>Shanghai Mental Health Center</institution></institution-wrap>, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/0220qvk04</institution-id><institution>Shanghai Jiao Tong University</institution></institution-wrap> School of Medicine and School of Psychology, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/0220qvk04</institution-id><institution>Shanghai Jiao Tong University</institution></institution-wrap>, <city>Shanghai</city><postal-code>200030</postal-code>, <country country="CN">China</country></aff><aff id="A4"><label>4</label>Cognitive Neuroimaging Unit, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/02vjkv261</institution-id><institution>INSERM</institution></institution-wrap>, CEA, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/02feahw73</institution-id><institution>CNRS</institution></institution-wrap>, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/03xjwb503</institution-id><institution>Université Paris-Saclay</institution></institution-wrap>, NeuroSpin center, <city>Gif-sur-Yvette</city>, <country country="FR">France</country></aff><aff id="A5"><label>5</label>Institut de neuromodulation, GHU Paris, psychiatrie et neurosciences, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/02kxjxy06</institution-id><institution>centre hospitalier Sainte-Anne</institution></institution-wrap>, pôle hospitalo-universitaire 15, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/05f82e368</institution-id><institution>Université Paris Cité</institution></institution-wrap>, <city>Paris</city>, <country country="FR">France</country></aff><author-notes><corresp id="CR1"><label>#</label><bold>Corresponding author:</bold> Liping Wang, Address: Institute of Neuroscience, Chinese Academy of Sciences, 320 YueYang Road, Shanghai 200031, China, <email>liping.wang@ion.ac.cn</email></corresp><fn id="FN1" fn-type="equal"><label>*</label><p id="P1">C.N., G.F., and Y.Y.Z. contributed equally to this work</p></fn></author-notes><pub-date pub-type="nihms-submitted"><day>23</day><month>07</month><year>2025</year></pub-date><pub-date pub-type="preprint"><day>18</day><month>07</month><year>2025</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P2">The ability to evaluate one’s own memory is known as metamemory. Whether metamemory is inherent to memory strength or requires additional computation in the brain remains largely unknown. We investigated the metacognitive mechanism of working memory (WM) using two-photon calcium imaging in the prefrontal cortex of macaque monkeys, who were trained to memorize spatial sequences of varying difficulties. In some trials, after viewing the sequence, monkeys could opt out of retrieval for a smaller reward, reflecting their confidence in WM (meta-WM). We discovered that PFC neurons encoded WM strength by jointly representing the remembered locations through population coding and their associated uncertainties. This WM strength faithfully predicted the monkeys’ recall performance and opt-out decisions. In addition to memory strength, other factors— trial history and arousal—encoded in baseline activity predicted opt-out decisions, serving as cues for meta-WM. We identified a code of meta-WM itself that integrated WM strength and these cues. Importantly, WM strength, cues, and meta-WM were represented in different subspaces within the same PFC population. The dynamics and geometry of PFC activity implement metacognitive computations, integrating WM strength with cues into a meta-WM signal that guides behavior.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P3">Working memory (WM) refers to the short-term maintenance and control of information necessary for future actions<sup><xref ref-type="bibr" rid="R1">1</xref></sup>. However, WM is significantly limited, typically holding only three or four items at a time, and its precision decreases as the number of items increases<sup><xref ref-type="bibr" rid="R2">2</xref>,<xref ref-type="bibr" rid="R3">3</xref></sup>. Imagine you must remember to buy wine on your way home from work, email a friend later in the evening, and take a pill at 9 p.m. Given our self-awareness of WM capacity, we often set external reminders to aid our memory, such as scheduling alarm clocks on our smartphones. This process relies on metacognitive judgments about our WM limitations<sup><xref ref-type="bibr" rid="R4">4</xref></sup>. This meta-level WM process is referred to as “meta-WM”<sup><xref ref-type="bibr" rid="R5">5</xref>,<xref ref-type="bibr" rid="R6">6</xref></sup>,<xref ref-type="bibr" rid="R7">7</xref>. We routinely use meta-WM to improve our decisions, for example, by offloading our memory to the external environment<sup><xref ref-type="bibr" rid="R8">8</xref></sup>. Convergent findings have emphasized the importance of the prefrontal cortex (PFC) in two aspects of WM, including the maintenance of WM content<sup><xref ref-type="bibr" rid="R9">9</xref>–<xref ref-type="bibr" rid="R11">11</xref></sup> and accurate metacognitive judgments about memory or perception in humans<sup><xref ref-type="bibr" rid="R12">12</xref>–<xref ref-type="bibr" rid="R14">14</xref></sup>, monkeys<sup><xref ref-type="bibr" rid="R15">15</xref>,<xref ref-type="bibr" rid="R16">16</xref></sup>, and rodents<sup><xref ref-type="bibr" rid="R17">17</xref>,<xref ref-type="bibr" rid="R18">18</xref></sup>. The connectivity between the prefrontal cortex and other brain areas is vital for metamemory and perceptual metacognition<sup><xref ref-type="bibr" rid="R16">16</xref>,<xref ref-type="bibr" rid="R19">19</xref></sup>, with different parts of the PFC used for these two domains<sup><xref ref-type="bibr" rid="R19">19</xref>,<xref ref-type="bibr" rid="R20">20</xref></sup>.</p><p id="P4">While metacognition research pertains to personal beliefs and knowledge about self-performance, the neuroscience of confidence has been mostly restricted to studying the neural representation of uncertainty within sensory or motor systems<sup><xref ref-type="bibr" rid="R21">21</xref></sup>. Thus, a key challenge lies in understanding how the brain integrates the neural representation of uncertainty and performance judgment into a single, unified framework. Furthermore, a long-standing debate about metacognition concerns whether meta-WM is inherent to WM strength or requires additional computation<sup><xref ref-type="bibr" rid="R21">21</xref></sup>. On one hand, judgments of higher memory strength are generally associated with higher accuracy in memory tasks<sup><xref ref-type="bibr" rid="R7">7</xref>,<xref ref-type="bibr" rid="R22">22</xref></sup>. In perception decision-making, neurons in the parietal cortex jointly represent the decision of direction and the degree of certainty underlying the decision to opt out<sup><xref ref-type="bibr" rid="R23">23</xref>,<xref ref-type="bibr" rid="R24">24</xref></sup>. On the other hand, metamemory does not always reflect accuracy but rather favors the use of (sometimes misleading) cues, such as fluency<sup><xref ref-type="bibr" rid="R25">25</xref></sup>, processing experience, prior beliefs<sup><xref ref-type="bibr" rid="R26">26</xref>,<xref ref-type="bibr" rid="R27">27</xref></sup>, and interoceptive signals<sup><xref ref-type="bibr" rid="R28">28</xref></sup>.</p><p id="P5">Therefore, despite previous studies on confidence and metacognition, the neural bases of WM and meta-WM at the single- or population-level in the PFC remain largely unknown. Furthermore, there is still a lack of a complete conceptual framework to explain how the brain combines WM strength and cues into a meta-WM signal for further action. To investigate the neural representations and computations of metacognition about WM, in this study, we aimed to test 1) whether WM, cues, and metacognitive judgment (meta-WM) are represented by the same neurons in the PFC, and 2) whether and how PFC neurons integrate the current strength of WM and cues to inform meta-WM to control behavior.</p></sec><sec id="S2" sec-type="results"><title>Results</title><sec id="S3"><title>Paradigm and behavior</title><p id="P6">We trained two macaque monkeys (D and Z) to learn a delayed-sequence reproduction meta-WM task (<xref ref-type="fig" rid="F1">Fig. 1A</xref>). Task difficulty was controlled by varying both the sequence length and spatial location combination. The monkeys had to maintain fixation on the cross at the center of the screen as the baseline to initiate a trial. On each trial, spatial sequences with a length of 1, 2, 3, or 4 items were visually presented during the sample period. Each item was randomly drawn (without replacement) from one of the six spatial locations of a hexagon and presented sequentially. The monkeys were required to memorize the sequence for a short delay with fixation and report it during the response period (see <xref ref-type="sec" rid="S13">Methods</xref>). In a random 65% of the trials (“choice” condition), after the delay period, the monkeys were allowed to freely choose to perform (“memory” condition) or opt out of retrieval (“offload” condition, smaller reward). In the other trials (“forced-to-test” condition), the monkeys were forced to perform the retrieval task. Monkey did not know the condition before the decision period. This task design of prospective meta-WM encourages monkeys to estimate their confidence about their WM on each trial during the delay period, and to opt out when they are less confident about their WM in the “choice” condition.</p><p id="P7">We examined the relationship between the probability of choosing the offload option (offloading rate), task performance (accuracy of sequence recall), and WM difficulty (sequence length and location combination) to test whether the offloading rate could reflect monkeys’ judgment of their own WM. WM performance declined as the sequence length increased. Crucially, the monkeys performed significantly better when they decided to perform the memory task than when they were forced to do it. This is true regardless of the sequence length (<xref ref-type="fig" rid="F1">Fig. 1B</xref>, ps &lt; 0.001 for each monkey) and the sequence type (<xref ref-type="supplementary-material" rid="SD1">Fig. S1A</xref>), suggesting that the meta-WM was not determined solely by the sequence locations and length but also by trial-to-trial variability that affects WM.</p><p id="P8"><xref ref-type="fig" rid="F1">Figure 1C</xref> shows the proportion of response sequences for each stimulus sequence (also see <xref ref-type="supplementary-material" rid="SD1">Fig. S1B</xref>). We defined for each sequence, recall accuracy as the probability of correct retrieval, and recall variability as the entropy of the distributions of retrievals across trials (see two examples in <xref ref-type="fig" rid="F1">Fig. 1C</xref> upper right). We found that, across sequences, the offloading rate measured in the choice condition was negatively correlated with recall accuracy and positively correlated with recall variability measured in the forced-to-test condition (<xref ref-type="fig" rid="F1">Fig. 1D and 1E</xref>, ps &lt; 0.001 for both monkeys). Thus, in this paradigm, the offloading decision reflects the monkeys’ accurate assessment of their own WM.</p></sec><sec id="S4"><title>Recordings and single-neuron responses</title><p id="P9">During the delay, monkeys had to maintain WM and meta-WM representations, which respectively correspond to a (first-order) representation of the remembered locations and a (second-order) representation of the strength of the first-order representation. To search for the neural representations of the two aspects of WM and their dynamics, we injected TET-Off GCaMP6f virus into the LPFCs of the two monkeys to enable two-photon calcium imaging (<xref ref-type="fig" rid="F1">Fig. 1F</xref> and <xref ref-type="sec" rid="S13">Methods</xref>) and recorded more than 15,000 single neurons [monkey D, 4,758 neurons from 12 fields of view (FOVs); monkey Z, 10,960 neurons from 16 FOVs (<xref ref-type="supplementary-material" rid="SD1">Fig. S2A</xref>)]. We first focused on neural activity during the late delay period (1.1 seconds before decision). Many neurons showed selectivity for single- or multiple-location (22.3% for monkey D, 10.2% for monkey Z, see examples in <xref ref-type="fig" rid="F1">Fig. 1G-H</xref>). Meanwhile, some neurons exhibited selectivity for meta-WM decision before the decision was made (see example in <xref ref-type="fig" rid="F1">Fig. 1I</xref>). The distributions of cell selectivity for location and meta-WM decision are shown in <xref ref-type="supplementary-material" rid="SD1">Figure S2B</xref> and relatively consistent across the two monkeys (<xref ref-type="supplementary-material" rid="SD1">Table S1</xref>).</p></sec><sec id="S5"><title>Representation of WM and memory strength in the LPFC neural population</title><p id="P10">Next, we examined whether the PFC population neurons represent the WM of sequential locations and their uncertainties (i.e., WM strength). We decoded single-trial WM representations of locations from population neural activity during the delay period. For each FOV, we trained six linear support vector machines (SVMs) to decode the probability of each location (one SVM per location). The decoded probability of a sequence in WM was defined as a joint probability of multiple locations (since the locations were always presented clockwise, we did not decode their ordinal positions). In addition, the uncertainty of the sequence representation in WM was measured as the entropy of the decoder’s probability distributions across all sequences. We inverted and normalized the entropy as a trial-by-trial measure of WM strength (<xref ref-type="fig" rid="F2">Fig. 2A</xref>, see <xref ref-type="sec" rid="S13">Methods</xref>).</p><p id="P11">We investigated whether decoding of WM locations from the LPFC neurons reflects the locations reported by monkeys. In the forced-to-test condition, for each sequence, we compared, on average across trials, the decoded locations (<xref ref-type="fig" rid="F2">Fig. 2B</xref>) with behavior (<xref ref-type="fig" rid="F2">Fig. 2C</xref>). In most FOVs across two monkeys, we found strong positive correlations for most sequences (example FOVs in <xref ref-type="fig" rid="F2">Fig. 2D</xref>, all ps &lt; 0.001; other FOVs in <xref ref-type="supplementary-material" rid="SD1">Figs. S3 and S5A</xref>). Similar results could be found in the choice condition (<xref ref-type="supplementary-material" rid="SD1">Fig S4</xref>).</p><p id="P12">We then examined whether the decoded WM strength predicted retrieval performance. Sequences with stronger WM strength across trials resulted in reduced variability of retrievals across trials in both monkeys (<xref ref-type="fig" rid="F2">Figs. 2E</xref> and <xref ref-type="supplementary-material" rid="SD1">S5B</xref>). Furthermore, WM strength was higher in correct trials than in error trials for most sequences (see the example sequence in <xref ref-type="fig" rid="F2">Fig. 2F</xref>, all sequences for each monkey in <xref ref-type="fig" rid="F2">Fig. 2G</xref>, and <xref ref-type="supplementary-material" rid="SD1">Fig. S5C</xref> for other FOVs). Thus, the results indicate that the population activity of LPFC neurons jointly represents the remembered locations and their associated uncertainty, and this joint representation predicts the monkeys’ recall performance.</p></sec><sec id="S6"><title>Meta-WM representations in the LPFC neural population</title><p id="P13">We next asked whether the meta-WM judgment is also represented in the same neural population. At the single-neuron level, we found a substantial number of neurons selective to the meta-WM decision (whether to offload or not) during the delay period. <xref ref-type="fig" rid="F3">Figures 3A-B</xref> show an example neuron with higher neural responses in the offloading trials than in the memory trials (<xref ref-type="fig" rid="F3">Fig. 3A</xref>) and a significant association with offloading rates across sequences (<xref ref-type="fig" rid="F3">Fig. 3B</xref>). We refer to such neurons as meta-WM neurons (see <xref ref-type="sec" rid="S13">Methods</xref>).</p><p id="P14">At the population level, we used linear regression (SVM-based) to train a decoder of meta-WM decisions from single-trial neural responses during the late delay period from each FOV. The decoder returns a <italic>meta-WM score</italic> in favor of performing the memory task (<xref ref-type="fig" rid="F3">Fig. 3C</xref>; see <xref ref-type="sec" rid="S13">Methods</xref>). Note that all decoding results are cross-validated. We discovered that the meta-WM judgment at single trials could be accurately decoded from the delay responses in both monkeys (<xref ref-type="fig" rid="F3">Figs. 3D-E</xref> and <xref ref-type="supplementary-material" rid="SD1">S6</xref>). The meta-WM score was significantly correlated with the offloading rate across sequences (<xref ref-type="fig" rid="F3">Fig. 3F</xref> ps &lt; 0.001). Importantly, within nearly all sequences, the meta-WM score was larger when monkeys chose to perform the memory task than when they chose to offload (<xref ref-type="fig" rid="F3">Fig. 3G</xref>, ps &lt; 0.001; see <xref ref-type="supplementary-material" rid="SD1">Fig. S7</xref> for results from other FOVs). Therefore, the metacognitive judgment of WM (i.e., meta-WM) was also represented in LPFC neurons.</p></sec><sec id="S7"><title>The relationship between WM, memory strength, and meta-WM judgment</title><p id="P15">What is the relationship between the neural representation of WM (and its uncertainty) and the neural representation of the metacognitive judgment about WM (i.e., meta-WM)? There was a gradient of selectivity in PFC: some neurons were significantly tuned to only one aspect (<xref ref-type="supplementary-material" rid="SD1">Fig. S8</xref>), and others tuned to both (see example neurons in <xref ref-type="fig" rid="F4">Fig 4A-B</xref>); at the population level, the coding of meta-WM and WM positively correlated across neurons (<xref ref-type="fig" rid="F4">Fig. 4C</xref>).</p><p id="P16">The fact that both WM and meta-WM are coded in the same population could promote that the neural representation of meta-WM is informed by the neural presentation of WM and, in particular, memory strength. If WM indeed informs meta-WM, one prediction is that the time course of decoding WM should parallel that of meta-WM and, in fact, precede it. This was the case indeed, with decoding of WM that occurred significantly earlier than meta-WM (212.3±102.4 ms, <xref ref-type="fig" rid="F4">Figs. 4D</xref> and <xref ref-type="supplementary-material" rid="SD1">S8E</xref>). Another prediction is that when the strength of WM is higher, the meta-WM score should be higher; this correlation was clearly observed (<xref ref-type="fig" rid="F4">Fig. 4E</xref>, p &lt; 0.001). This correlation is partly driven by the fact that WM strength and the meta-WM score differ across sequences (<xref ref-type="supplementary-material" rid="SD1">Fig. S6C</xref>), but it remained significant across trials within each sequence (<xref ref-type="fig" rid="F4">Fig. 4F</xref>, p &lt; 0.001; <xref ref-type="supplementary-material" rid="SD1">Fig. S10</xref> for results from other FOVs). Thus, these results indicate that the representation of WM and the associated uncertainty (rather than just the sequence type) informs the metacognitive judgment in the LPFC. Nevertheless, we should also notice that this process is not perfect: the correlation between meta-WM and WM strength could be stronger. Meta-WM may sometimes fail to be correctly informed by WM strength, which would result in error trials (e.g., meta-illusion<sup><xref ref-type="bibr" rid="R29">29</xref>,<xref ref-type="bibr" rid="R30">30</xref></sup>). We tested this possibility by analyzing single error trials, where monkeys chose to perform the task (memory condition) but made mistakes in their retrieval. When analyzing error trials, however, there could be another cause of error trials: monkeys could retain incorrect locations with strong WM strength and thus with a high meta-WM score. In this case, there would be no mismatch between WM and meta-WM.</p><p id="P17">A total of 173 error trials from a single example recording session in one FOV were included. Using the trial medians of WM strength and meta-WM from all choice condition trials (<xref ref-type="fig" rid="F4">Fig. 4G</xref>) (also see <xref ref-type="supplementary-material" rid="SD1">Fig. S9</xref> for other dividing criteria), 53% (93 out of 173) of error trials were classified as high-score meta-WM. In these 93 trials, we found that 34 trials showed high WM strength while encoding incorrect response sequences (<xref ref-type="fig" rid="F4">Fig. 4G</xref>, green dots, the decoding probability of the <italic>response</italic> locations was the highest among all the sequences), suggesting the monkeys maintained the incorrect locations with strong WM strength and thus high-score meta-WM during the delay period. We thus excluded these error trials, as there is no mismatch between WM and meta-WM. Importantly, we still found a significant proportion (36%, 50 out of 139) of mismatch error trials (<xref ref-type="fig" rid="F4">Fig. 4G</xref>, black circles), where weak WM strength erroneously resulted in a high meta-WM score, and this erroneous mapping was not due to internal noise (<xref ref-type="fig" rid="F4">Fig. 4H</xref>, tested against a shuffled distribution, p &lt; 0.01). The results of error-trial analyses from other FOVs for two monkeys are shown in the <xref ref-type="supplementary-material" rid="SD1">Figure. S10C</xref>.</p><p id="P18">Taken together, these results from the correlation and error-trial analyses indicate that there could be additional processes contributing to meta-WM beyond WM, and an incorrect mapping to meta-WM could result in errors in single trials.</p></sec><sec id="S8"><title>Baseline activity also contributes to the metacognitive judgment</title><p id="P19">Is the imperfect relationship between meta-WM and memory strength caused by a noisy readout of memory strength or additional intervening processes? We examined whether the arousal state and prior confidence of monkeys before sequence presentation could bias the meta-WM judgment<sup><xref ref-type="bibr" rid="R21">21</xref>,<xref ref-type="bibr" rid="R26">26</xref>,<xref ref-type="bibr" rid="R27">27</xref>,<xref ref-type="bibr" rid="R31">31</xref>,<xref ref-type="bibr" rid="R32">32</xref></sup>. We analyzed pupil dilation during the baseline period as it is often a behaviorally relevant proxy for arousal<sup><xref ref-type="bibr" rid="R31">31</xref>,<xref ref-type="bibr" rid="R32">32</xref></sup>. Pupil size during the baseline period was associated with different upcoming metacognitive judgments (offload or not) on the current trial (<xref ref-type="fig" rid="F5">Figs. 5A-B</xref>; see other sequence lengths and the other monkey in <xref ref-type="supplementary-material" rid="SD1">Fig. S11</xref>). To test whether monkeys could derive prior confidence about the quality of their retrievals in past trials<sup><xref ref-type="bibr" rid="R33">33</xref>,<xref ref-type="bibr" rid="R34">34</xref></sup>, we assumed that the prior confidence corresponds to a leaky mean of past rewards, in which more recent trials have an increasing weight on the prior<sup><xref ref-type="bibr" rid="R35">35</xref>,<xref ref-type="bibr" rid="R36">36</xref></sup> (see <xref ref-type="sec" rid="S13">Methods</xref>). We found that the reward from the previous two (monkey D) or five (monkey Z) trials influenced the meta-WM judgment on the current trial (<xref ref-type="fig" rid="F5">Fig. 5C</xref>).</p><p id="P20">The neural activity during the baseline period of a large proportion of neurons (monkey D: 22.5% and monkey Z: 19.0%; see <xref ref-type="sec" rid="S13">Methods</xref>) also covaried with the upcoming metacognitive judgment (see an example neuron in <xref ref-type="fig" rid="F5">Fig. 5D</xref>). The metacognitive judgment could actually be successfully decoded from population activity during the baseline in the two monkeys, which we refer to as the “baseline meta score” (<xref ref-type="fig" rid="F5">Figs. 5E</xref>, left and <xref ref-type="supplementary-material" rid="SD1">S12A</xref>). As a control, we verified that the average baseline meta score across presentations of each sequence type did not correlate with the offloading rate across sequences (<xref ref-type="fig" rid="F5">Figs. 5E</xref>, right, and <xref ref-type="supplementary-material" rid="SD1">S12A</xref>, p &gt; 0.05), which had not yet been presented to the monkeys. The baseline meta score recapitulated the effect of pupil-linked arousal and trial history (<xref ref-type="fig" rid="F5">Fig. 5F</xref>). We determined the extent to which the baseline meta score and WM strength accounted for the meta-WM score with a linear regression analysis. Both components contributed to the meta-WM score, with a stronger effect of WM strength and no interaction between the two components (<xref ref-type="fig" rid="F5">Figs. 5G</xref>, <xref ref-type="supplementary-material" rid="SD1">S12B, and S13</xref>). Model comparison indicated that the two components provide a better account of the meta-WM score than each component in isolation (<xref ref-type="fig" rid="F5">Figs. 5H</xref>, <xref ref-type="supplementary-material" rid="SD1">S12C</xref>), suggesting that the baseline effect contributes to metacognitive judgment in addition to WM strength. The baseline activity accounted for some error trials that resulted from a high meta-WM score with a weak WM strength (<xref ref-type="supplementary-material" rid="SD1">Fig. S14</xref>). Compared to the offload trials, which generally have weak WM strength and low meta-WM scores, the error trials displayed similar WM strength but significantly higher baseline meta scores (<xref ref-type="fig" rid="F5">Fig. 5I</xref>). These results suggest that baseline activity is an additional, sometimes misleading factor contributing to meta-WM.</p></sec><sec id="S9"><title>Three metacognition components in the PFC</title><p id="P21">Finally, we asked whether the prefrontal populations of neurons are highly overlapped or separated in encoding the three metacognition components (baseline, WM, and meta-WM). At the single-neuron level, we identified three groups of component-selective neurons in the lateral prefrontal cortex (LPFC) that included a significant number of mixed-selective neurons (<xref ref-type="fig" rid="F6">Fig. 6A</xref>), which showed a preference for two or three components. At the population-neuron level, we examined whether each component could be linearly separated in the population activity. We searched the line in the n-dimensional activity space along which baseline activity was separated between memory and offload trials, and we termed this line the baseline subspace<sup><xref ref-type="bibr" rid="R37">37</xref></sup>; similarly, we searched the WM strength subspace and meta-WM score subspace in the population neurons (<xref ref-type="fig" rid="F6">Fig. 6B</xref>; see <xref ref-type="sec" rid="S13">Methods</xref>). These one-dimensional subspaces each explained a significant amount of variance (40.1%, 52.4%, and 71.5% for the baseline, WM, and meta-WM, respectively, from FOV 8 of monkey D; see other FOVs from two monkeys in <xref ref-type="supplementary-material" rid="SD1">Fig. S15</xref>). Importantly, those subspaces were oriented in a near-orthogonal manner, as evident by the large principal angles between them (<xref ref-type="fig" rid="F6">Fig. 6C</xref>). To further quantify the degree of alignment across different subspaces, for any two components—e.g., baseline and WM—we calculated the variance accounted for (VAF) ratio<sup><xref ref-type="bibr" rid="R9">9</xref>,<xref ref-type="bibr" rid="R11">11</xref></sup> by projecting the data from the baseline subspace to the WM subspace and computing the remaining data variance ratio after the projection. If the two component subspaces are nearly orthogonal, the projection from one subspace will capture little of the variance in the other subspace, resulting in a low VAF ratio. The result showed low VAF ratios for all cross-subspace pairs (<xref ref-type="fig" rid="F6">Fig. 6D</xref>). The orthogonality between WM and meta-WM was slightly lower than other pairs (ps &lt; 0.001), providing again the neural basis for the strong correlation between them. As a control, we randomly split the trials into two halves to obtain separate estimations of each subspace and computed the principal angles and VAF ratio; the orthogonality of the subspaces was lost (<xref ref-type="fig" rid="F6">Figs. 6C and 6D</xref>). The neural dynamics in each subspace confirmed their contributions throughout the duration of a trial (<xref ref-type="fig" rid="F6">Fig. 6E</xref>). Therefore, the results suggested that, at the collective level, the three metacognition components were encoded in separate PFC neural subspaces, although with mixed selectivity in single neurons.</p><p id="P22">Two-photon imaging enabled us to explore whether the neurons representing metacognition components are anatomically segregated in the PFC. An example FOV demonstrated that the three groups of component-selective neurons were nearly uniformly distributed (<xref ref-type="fig" rid="F6">Fig. 6F and 6G</xref>). For each neuron, we first calculated the spatial distances to other neurons and then compared the intra-group distances with the distances between groups (see <xref ref-type="sec" rid="S13">Methods</xref><sup><xref ref-type="bibr" rid="R38">38</xref></sup>). We found that the spatial distances within the groups showed no significant difference compared to those between the groups for all three groups of neurons (<xref ref-type="fig" rid="F6">Fig. 6H</xref>, ps &gt; 0.05). This suggests that the three components were anatomically intermingled in the PFC. Similar results are observed in other FOVs and the second monkey (<xref ref-type="supplementary-material" rid="SD1">Fig. S16</xref>; see results in <xref ref-type="supplementary-material" rid="SD1">Fig. S17</xref> for defining selective neurons based on their contributions to corresponding subspaces). Therefore, while the metacognition components were functionally separate in subspaces of the PFC population activity, they remained anatomically intermingled.</p><p id="P23">Finally, we summarize our findings by proposing a conceptual model for the metacognitive WM system implemented in PFC (<xref ref-type="fig" rid="F6">Fig. 6I</xref>). The representations of metacognitive processes were composed of neural activities and their dynamics in the separate neural ensembles of baseline, WM, and meta-WM. The baseline activity already shifts the neural states along the meta-WM judgment axis (regarding whether to offload or not; note that the effect of baseline activity is additive and does not interact with the upcoming WM strength). Then, as the sequence is presented and stored in WM, sequence-specific features (e.g., spatial locations in the current task) and trial-by-trial WM-specific features, further push the neural state along the metacognitive judgment axis, owing to the correlation between WM-strength and meta-WM in the neural space. Presumably, on the WM trajectory, each point, jointly representing the WM locations and their uncertainty, can be further unfolded as the vectorial combinations of neural representations of multiple location signals, which were likely propagated from posterior sensory regions. Specifically, as the sequence difficulty (e.g., sequence length) escalates, the WM strength (e.g., tuning strength of spatial location) weakens due to limited resources. Thus, the projection of the neural state onto the metacognitive judgment axis leads to the final meta-WM decision to control behavior.</p></sec></sec><sec id="S10" sec-type="discussion"><title>Discussion</title><p id="P24">We recorded tens of thousands of neurons in the lateral PFC of macaque monkeys performing the spatial delay-sequence reproduction meta-WM task. We found that PFC neuronal responses could represent two aspects of WM: 1) the remembered locations and the associated uncertainty in WM, which corresponds to WM strength, through population coding, and 2) the metacognitive judgments of WM uncertainty about the remembered locations, which predicted the probability of offload decisions. Furthermore, neural activity during the baseline period, resulting from the internal neural states and history of rewards, also predicted metacognitive judgments on top of memory strength. Crucially, these three components of metacognition in WM—baseline prior, WM, and meta-WM—were functionally represented by three distinct subspaces of the population activity of anatomically intermingled neurons. We thus proposed that neural activity in the macaque PFC underlies the process of metacognition in WM by integrating several components of the metacognitive judgment, providing a novel and unifying model of metacognitive computations.</p><sec id="S11"><title>Meta-WM, memory strength, and meta-memory cues in the PFC neural population</title><p id="P25">The current study identifies a neural implementation of metacognition that integrates first-order and cue-based components that have previously been studied separately in neuroscience<sup><xref ref-type="bibr" rid="R7">7</xref>,<xref ref-type="bibr" rid="R21">21</xref></sup>,<xref ref-type="bibr" rid="R26">26</xref>. In principle, metacognition should benefit from the first-order information about uncertainty carried by decision or memory systems. However, this is only possible if neural circuits make first-order uncertainty available to the metacognitive system. If not, then metacognition has no choice but to infer the probability that a decision or memory is correct from indirect cues. Experimental manipulations or models of uncertainty<sup><xref ref-type="bibr" rid="R6">6</xref>,<xref ref-type="bibr" rid="R39">39</xref></sup>,40 have provided evidence that first-order uncertainty contributes to metacognitive judgments, but it is more challenging to demonstrate this contribution on a trial-by-trial basis. Recent advances in neuroscience have made it possible to decode neural representations of (first-order) sensory or memory data and their associated uncertainty, then compare the decoded uncertainty with decisions<sup><xref ref-type="bibr" rid="R41">41</xref></sup> or confidence reports<sup><xref ref-type="bibr" rid="R7">7</xref>,<xref ref-type="bibr" rid="R42">42</xref></sup>, and ultimately conclude that first-order uncertainty is available for higher-order processes such as metacognition. However, such a conclusion requires ruling out the possibility that the contribution of first-order uncertainty could be explained by other factors that serve as indirect metacognitive cues. The existence and use of such cues are well established, particularly in the metamemory literature<sup><xref ref-type="bibr" rid="R25">25</xref>–<xref ref-type="bibr" rid="R28">28</xref></sup>. Our results show that arousal and past performance are indeed cues to metacognitive judgment, but their contribution was in addition to memory strength.</p><p id="P26">Our results show not only that two components (first-order and cue-based) contribute to metacognition, but also that they coexist and are integrated in the lateral prefrontal cortex. This finding implies that the LPFC is capable of representing different reference frames<sup><xref ref-type="bibr" rid="R21">21</xref></sup>. One is world-centered, corresponding to whether the content of WM is informative about the presented sequence. The other is self-centered, corresponding to whether subjects feel confident about their memory recall. Our results suggest that these reference frames correspond to distinct subspaces of LPFC population activity.</p><p id="P27">We used two approaches<sup><xref ref-type="bibr" rid="R43">43</xref></sup> to identify first-order and cue-based components of metacognition in the LPFC. One approach is correlational, aiming to identify neural correlates of metacognitive judgments<sup><xref ref-type="bibr" rid="R13">13</xref>,<xref ref-type="bibr" rid="R15">15</xref>,<xref ref-type="bibr" rid="R40">40</xref>,<xref ref-type="bibr" rid="R44">44</xref>–<xref ref-type="bibr" rid="R46">46</xref></sup>. To this end, we trained a decoder of the monkey’s offload decision (a self-centered reference frame). The other approach is code-driven: we decoded the memory strength from a population code of the presented sample locations (this reference frame is world-centered). This approach has been used previously, assuming a probabilistic population code, to decode perceptual uncertainty<sup><xref ref-type="bibr" rid="R41">41</xref>,<xref ref-type="bibr" rid="R42">42</xref></sup> or WM uncertainty<sup><xref ref-type="bibr" rid="R7">7</xref></sup> from sensory cortices. In contrast, correlates of metacognition have typically been reported beyond sensory cortices using the correlational approach. In previous studies, these correlates were often related to either metacognitive judgment or its components<sup><xref ref-type="bibr" rid="R16">16</xref>,<xref ref-type="bibr" rid="R23">23</xref>,<xref ref-type="bibr" rid="R40">40</xref>,<xref ref-type="bibr" rid="R41">41</xref>,<xref ref-type="bibr" rid="R44">44</xref>,<xref ref-type="bibr" rid="R46">46</xref>–<xref ref-type="bibr" rid="R48">48</xref></sup>. Some studies have come close to combining the two components, e.g., Okazawa and colleagues found that neural geometry in the parietal cortex encoded not only the (first-order) decision variable but also task difficulty (a potential cue for metacognition), but the latter did not affect monkey confidence<sup><xref ref-type="bibr" rid="R24">24</xref></sup>. Here, we extended these previous findings by combining both approaches (code-driven, correlational) and identifying neural representations of metacognitive judgment and its components (first-order, cue-based) in activity subspaces of the same region, the LPFC, thereby providing a unified framework that integrates the neural representation of uncertainty and the neural representation of performance judgment in WM.</p></sec><sec id="S12"><title>Potential computational mechanisms of metacognition in the PFC</title><p id="P28">Apparently, how the metacognitive process is implemented and shaped within the neural landscapes of the prefrontal circuit remains only partly understood. Nevertheless, based on our neural data, we can posit that: 1) the potential multiple neural subpopulations (baseline, WM and meta-WM), with certain mixed-selectivity, in the prefrontal circuits may serve as the mechanistic underpinning for the information transition in different neural subspaces<sup><xref ref-type="bibr" rid="R49">49</xref>,<xref ref-type="bibr" rid="R50">50</xref></sup>; the WM (locations and their uncertainties) and prior signals could be firstly encoded in other brain regions such as visual, parietal or subcortical cortices and then propagated to PFC for maintenance. 2) These multiple routes converge in the PFC and interact through a structure-enabled gain modulation mechanism with meta-WM to inform metacognitive judgment<sup><xref ref-type="bibr" rid="R51">51</xref></sup>, suggesting that the metacognitive computation could be implemented within the PFC rather than through reciprocal connections between brain regions. However, due to the lack of recordings from the sensory cortex, the present results do not exclude the simultaneous presence of the metacognitive computation within the PFC and between brain regions. Multiple circuitries for metacognition in WM may coexist within the brain. 3) The nature of this interaction or mapping may be predetermined by the anatomical connectivity between populations, likely established during task learning in monkeys; this connectivity may differ between subjects and partly account for differences in meta-WM performance. Examining the development of connections among different neural populations in the PFC and across brain regions during learning is crucial. While further causal interventions are needed for each metacognitive component (the current study only shows correlation), this proposal necessitates additional theoretical and experimental explorations in the broader domain of metacognitive computations.</p></sec></sec><sec id="S13" sec-type="materials | methods" specific-use="web-only"><title>Materials and Methods</title><sec id="S14"><title>Experimental models</title><p id="P29">Two healthy male monkeys D and Z (Macaca mulatta, weight: 8.5/10 kg, age: 8/9 years)</p><p id="P30">participated in the study. Both monkeys were housed in individual cages. Food was available ad libitum, while water intake was restricted to daily requirement in the cage. On testing days, monkeys received juice rewards for correct responses during the experiments. All experimental procedures were approved by the Animal Care Committee of the Institute of Neuroscience, Chinese Academy of Sciences (CEBSIT-2020035R02).</p></sec></sec><sec id="S15"><title>Behavioral task</title><sec id="S16"><title>Visual stimuli</title><p id="P31">All visual stimuli were presented on a 24-inch touch monitor (Dell P2418HT) with a refresh rate of 60 Hz and a resolution of 1920×1080. The stimuli were generated using Matlab (MathWorks, MA, USA) with extensions from Psychtoolbox<sup><xref ref-type="bibr" rid="R54">54</xref>,<xref ref-type="bibr" rid="R55">55</xref></sup>. In this study, stimuli were created from six spatial locations arranged in a hexagonal configuration. In each trial, locations were presented sequentially on the screen, with sequence lengths ranging from 1 to 4 trial-by-trial randomly (see <xref ref-type="fig" rid="F1">Fig. 1A</xref>). Each spatial location (if sampled) would be sampled only once per sequence, and each sequence would be exhibited in a clockwise direction, such that sampled locations with smaller numerical labels would always be shown before those with larger labels (for example, if locations 2, 4, 5 were sampled, the sequence would always be 2-4-5). For both monkeys, there were a total of 56 sequences: 6 (or <inline-formula><mml:math id="M1"><mml:msubsup><mml:mi>C</mml:mi><mml:mn>6</mml:mn><mml:mn>1</mml:mn></mml:msubsup></mml:math></inline-formula>) length-1 sequences, 15 (or <inline-formula><mml:math id="M2"><mml:msubsup><mml:mi>C</mml:mi><mml:mn>6</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>) length-2 sequences, 20 (or <inline-formula><mml:math id="M3"><mml:msubsup><mml:mi>C</mml:mi><mml:mn>6</mml:mn><mml:mn>3</mml:mn></mml:msubsup></mml:math></inline-formula>) length-3 sequences, and 15 (or <inline-formula><mml:math id="M4"><mml:msubsup><mml:mi>C</mml:mi><mml:mn>6</mml:mn><mml:mn>4</mml:mn></mml:msubsup></mml:math></inline-formula>)length-4 sequences. All possible combinations of stimulus locations were used in the experiment and each trial randomly involved only one sequence. Given the relatively low task performance for length-4 sequences in the training session, we primarily focused on sequences of lengths 1, 2, and 3 in the two-photon imaging experiment, However, for consistency, a limited number of length-4 sequences were still included during imaging experiment for behavioral analysis. The ratios of the four sequence lengths (length 1, 2, 3, and 4) in all trials were 20:20:20:9 for Monkey D and 20:20:20:3 for Monkey Z.</p></sec><sec id="S17"><title>Task structure</title><p id="P32">Monkeys were trained to perform a delayed-sequence reproduction meta-WM task. The monkeys were required to make behavioral reports using eye saccades to appropriate locations on a monitor screen. Each monkey was seated in a primate chair positioned 35 cm away from the monitor during the experiments. All experiments were carried out in a dark room when the light was off. Here, we used an Eyelink 1000 Plus eye-tracking system with a sampling rate at 1000 Hz to track the monkeys’ gaze positions during each trial.</p><p id="P33">Each trial began with the monkey fixating on a central cross (0.98° in diameter), which had to be maintained within an invisible window with a radius of 2.57°. The monkeys maintained this fixation for a baseline period of 1.1 seconds during which a hexagonal layout of six empty circles (each 4.08° in diameter) were presented, positioned 11.55° from the fixation point. During the subsequent sample period, 1 to 4 red stimuli were sequentially displayed on the screen in a clockwise manner, each displayed for 0.2s with a 0.4s inter-stimulus interval. This was followed by a delay period (1.5-1.7 s), during which the layout disappeared, leaving only the central cross visible. Subsequently, in the decision period, each trial would fall under either the “choice” condition (65%) or the “forced-to-test” condition (35%). Under the “choice” condition, the monkeys were required to select via saccade between a green square representing “memory” option (no hints during the response) and a red triangle representing “offload” option (previously displayed locations reappear as hints). The choice symbols (green square / red triangle) appeared randomly on either the left or right side of the screen from trial to trial to prevent anticipatory motor preparation signals during the delay period. Under the “forced-to-test” condition, only the “memory” option was shown randomly on the left or right side. After the decision, there was a second delay period (another 1.5 - 1.7 s), which was not included in the analysis. Note that in this study, “delay period” only denotes the first delay, i.e. the interval between the sample and the decision periods. Following this second delay, the response period began with the hexagonal layout reappearing on the screen. All circles were empty under the “memory” and “forced-to-test” conditions, while in the “offload” condition, the previously shown sample stimuli were displayed again as hints. In summary, each trial included the following periods: baseline, sample, delay, decision, second delay, and response.</p><p id="P34">The monkeys’ behavior varied during the response period depending on the condition of the decision period. In memory trials, monkeys were required to make saccades to the targets that did not appear during the sample period in a clockwise order. After selecting all the correct targets, they returned their gaze to the central fixation cross to submit the trial. If correct, they received a reward of 3 drops of water. A correct trial necessitated responses in a clockwise order. In offload trials, all red stimuli from the original sequences reappeared simultaneously. The monkeys first made saccades to these cued locations (behavior akin to note-taking), then skipped over them and made saccade to the remaining targets. Upon successful completion, they received a reduced reward of 2 drops of water. Monkey D received 3 water drops for correct responses under memory and forced-to-test conditions, 2 for correct offload trials, and 0 for error trials, following a 3-2-0 reward scheme; monkey Z was rewarded according to a 2-1-0 scheme.</p><p id="P35">On a single experimental day (one session), several runs (typically 5 runs) were conducted. Each run comprised one-third forced-to-test trials and two-thirds choice trials. Specifically, for monkey D, each run included 69 forced-to-test trials (with sequence lengths of 1, 2, 3, and 4 involving 20, 20, 20, and 9 trials, respectively), totaling 207 trials per run (69 forced-to-test trials and 138 choice trials). Similarly, each run for monkey Z included 63 forced-to-test trials and 126 choice trials, totaling 189 trials per run. Consequently, each session encompassed approximately 1000 trials (at least 800).</p></sec></sec><sec id="S18"><title>Two-photon calcium imaging</title><sec id="S19"><title>Surgery procedures</title><p id="P36">Two sequential surgical procedures were performed on each monkey under general anesthesia. During the first surgery, three head posts were implanted to stabilize the head position during subsequent training and recording sessions: two on the posterior of the head and one on the middle of the forehead. A Y-shaped steel frame was then attached to the head posts. Following a recovery period of 10 days, both monkeys were trained to perform the behavioral task over the course of a year until they met established performance criteria (significant correlation between accuracy and offloading rate across sequences).</p><p id="P37">Following the training period, a second surgical procedure was performed. A 22 mm craniotomy was created over the lateral prefrontal cortex, extending from the principal sulcus (PS) to the arcuate sulcus (AS), approximately corresponding to Walker’s areas 46 and 8<sup><xref ref-type="bibr" rid="R56">56</xref></sup>. The dura mater (16 mm in diameter) was removed to expose the underlying cortex. Viral injections and implantation of an imaging window were then carried out.</p><p id="P38">Approximately 500 nl of an equal mixture of rAAV2/9-hsyn-tTA (3×10^12 vg/ml) and rAAV2/9-TRE3-GCaMP6f (1×10^13 vg/ml) was injected at a depth of 600 μm to deliver TET-Off GCaMP6f virus<sup><xref ref-type="bibr" rid="R57">57</xref></sup> (from Gene editing facility of Institute of Neuroscience, Chinese Academy of Sciences). The injection sites were positioned along the PS.</p><p id="P39">The imaging window unit was constructed by attaching an 18 mm diameter, 0.17 mm thick glass coverslip to a titanium ring (15 mm outer diameter, 13 mm inner diameter). The unit was carefully placed on the cortical surface, with the titanium ring secured to the skull using dental acrylic. To protect the coverslip, a steel shell was placed over the entire imaging window.</p></sec><sec id="S20"><title>Set-up</title><p id="P40">In vivo two-photon calcium imaging was performed using a Thorlabs two-photon microscope and a femtosecond laser (Chameleon Discovery, Coherent). A 16× objective lens (0.8 N.A., Nikon) was used to image a 700 μm × 700 μm area at 30 frames per second. The recording depth ranged from 80 μm to 250 μm below the pia, and each imaging experimental day (session) lasted 3–5 hours. We aimed to cover most regions with GCaMP6f expression within the recording windows located along the principal sulcus (PS). A total of 28 fields of view (FOVs) were recorded: 12 FOVs from monkey D (4,758 neurons) and 16 FOVs from monkey Z (10,960 neurons); for the position and neuron count of each FOV, see <xref ref-type="supplementary-material" rid="SD1">Figure S2</xref> and <xref ref-type="supplementary-material" rid="SD1">Table S1</xref>.</p></sec><sec id="S21"><title>Imaging data processing</title><p id="P41">We implemented the image processing pipeline using MATLAB and Python. Images were first motion-corrected using a rigid motion-correction algorithm from the NoRMCorre package<sup><xref ref-type="bibr" rid="R58">58</xref></sup>. Source extraction was performed using the Suite2p package<sup><xref ref-type="bibr" rid="R59">59</xref></sup>, which is based on singular value decomposition (SVD). Scores<sup><xref ref-type="bibr" rid="R59">59</xref></sup> were calculated for each extracted spatial component, and regions of interest (ROIs) marking putative neuronal locations were selected by thresholding these scores. The resulting fluorescence traces were sampled at a frame rate of 30 Hz. The ΔF/F was calculated as (F - F<sub>0</sub>) / F<sub>0</sub>, where F represents the raw fluorescence signal and F<sub>0</sub> is defined as the mode value within the preceding 30-second window.</p></sec><sec id="S22"><title>ROI alignment of two-session recording of the same FOV</title><p id="P42">In this study, we recorded the same FOV across two consecutive sessions to obtain additional (double) trials for further analyses. Thus, a total of 27 FOVs were examined over 54 recording sessions, with the exception that FOV 3 of monkey D was imaged in 3 consecutive recording sessions. After processing the imaging data, the ROIs from both sessions were aligned and merged to double the number of trials for each ROI.</p><p id="P43">To assess the similarity between ROIs across two consecutive recording sessions (A and B) for alignment purposes, we employed a weighted composite similarity score incorporating both structural and functional features: <list list-type="simple" id="L1"><list-item><label>(1)</label><p id="P44">Median position (weight = 1): Spatial proximity of ROIs, with a threshold of less than 10 pixels in median position distance.</p></list-item><list-item><label>(2)</label><p id="P45">Size (area) (weight = 0.5): Comparison similarity of the area encompassed by each ROI.</p></list-item><list-item><label>(3)</label><p id="P46">Aspect ratio (weight = 0.5): Evaluation of the shape characteristics (x pixel size / y pixel size) of the ROIs.</p></list-item><list-item><label>(4)</label><p id="P47">Stimulus-evoked neuronal activity (weight = 2): Assessment of the similarity in neuronal responses to each stimulus sequence.</p></list-item></list>
</p><p id="P48">For each term listed above, we first generated a similarity queue sorted in descending order. Subsequently, we assigned scores ranging from 20 to 1 to each item in the queue, multiplying each score by the corresponding term weight. The alignment procedure comprised the following steps: <list list-type="simple" id="L2"><list-item><label>(1)</label><p id="P49">Session A to session B: For each ROI in session A, identify up to top 20 ROIs in session B within a 10-pixel median position distance. Rank these candidate ROIs based on the weighted composite similarity score.</p></list-item><list-item><label>(2)</label><p id="P50">Session B to session A: For each ROI in session B, identify up to top 20 ROIs in session A within a 10-pixel median position distance. Rank these candidate ROIs based on the weighted composite similarity score.</p></list-item><list-item><label>(3)</label><p id="P51">Identification of overlapping A-B pairs: Determine the set of ROI pairs that are mutually identified in both steps above, indicating a bidirectional match.</p></list-item></list>
</p></sec></sec><sec id="S23"><title>Behavioral and single-neuron analysis (Related to <xref ref-type="fig" rid="F1">Figure 1</xref>)</title><sec id="S24"><title>Accuracy and offloading rate</title><p id="P52">The length-averaged accuracy (<xref ref-type="fig" rid="F1">Fig. 1B</xref>) was calculated by dividing the number of correct trials by the total number of trials in the relevant conditions (offload, memory, forced-to-test) for each length. The sequence-averaged accuracy was determined by dividing the number of correct trials by the total number of trials in the forced-to-test condition for each sequence (<xref ref-type="fig" rid="F1">Fig. 1D</xref>). The sequence-averaged offloading rate was determined by dividing the number of offload trials by the number of choice trials for each sequence (<xref ref-type="fig" rid="F1">Fig. 1D</xref>).</p></sec><sec id="S25"><title>Behavior recall variability</title><p id="P53">In this study, we quantified working memory (WM) representations in terms of their content (locations) and strength. Behavior recall variability was measured by the normalized entropy of the probability distribution of response sequences following the presentation of a stimulus sequence during the sample period.</p><p id="P54">We computed <italic>entropy</italic> in a classical manner, using the distribution of all possible response probabilities of sequences, where: <disp-formula id="FD1"><mml:math id="M5"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mspace width="6.0em"/><mml:mi>E</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>y</mml:mi><mml:mo>(</mml:mo><mml:mtext>s</mml:mtext><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mspace width="0.2em"/><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>q</mml:mi><mml:mo>)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:munder><mml:mi>∑</mml:mi><mml:mrow><mml:mtext>r</mml:mtext><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.2em"/><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>q</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:munder><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mspace width="0.2em"/><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.2em"/><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>q</mml:mi><mml:mspace width="0.2em"/><mml:mo>∣</mml:mo><mml:mspace width="0.2em"/><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mspace width="0.2em"/><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>q</mml:mi><mml:mspace width="0.2em"/><mml:mo stretchy="false">)</mml:mo><mml:mo>∗</mml:mo><mml:mi>log</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.2em"/><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>q</mml:mi><mml:mspace width="0.2em"/><mml:mo>∣</mml:mo><mml:mspace width="0.2em"/><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mspace width="0.2em"/><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>q</mml:mi><mml:mspace width="0.2em"/><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mspace width="6.3em"/><mml:mi>E</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>y</mml:mi><mml:mspace width="0.2em"/><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p id="P55">Here, we also compute the theoretical upper bound of <italic>entropy</italic> by calculating the entropy of a uniform distribution, denoted as <italic>Max</italic>. Finally, we determined the recall variability by normalizing the entropy from [0, Max] to [0, 1], where: <disp-formula id="FD2"><mml:math id="M6"><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mspace width="0.2em"/><mml:mi>v</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>b</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mspace width="0.2em"/><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mspace width="0.2em"/><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>E</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>y</mml:mi><mml:mspace width="0.2em"/><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mspace width="0.2em"/><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>q</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mfrac><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:math></disp-formula></p><p id="P56">In this context, a recall variability of 1 represents a uniform probability distribution (which would be noisy WM), and a recall variability of 0 indicates that the probability of one specific sequence is 1 (representing very high precision of WM).</p><p id="P57">For example, in <xref ref-type="fig" rid="F1">Figure 1C</xref>, responses to the sequence [1-3] of monkey D were mostly concentrated around its corresponding physical stimulus, indicating low variability. In contrast, responses to the sequence [2-5-6] were widely distributed, reflecting high variability.</p></sec><sec id="S26"><title>WM selectivity of each neuron</title><p id="P58">We conducted linear regression for each neuron to quantify its tuning properties as follows: <disp-formula id="FD3"><mml:math id="M7"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>X</mml:mi><mml:mo>∗</mml:mo><mml:mi>β</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></disp-formula></p><p id="P59">For the regression of location WM, <italic>y</italic> represented the neuronal activity for each trial (a column vector with 1 by number of trials), <italic>β</italic><sub>0</sub> was the intercept term, <italic>β</italic> was the regression coefficient to be fitted (a 1-by-6 vector, indicating weights of 6 locations), and <italic>X</italic> represented the stimulus sequence for each trial (a design matrix with 6 by number of trials, with a one-hot-like 1-by-6 vector for each trial, e.g. stimulus sequence [3-5] would be [0 0 1 0 1 0].). Only correct trials (in both the memory and forced-to-test conditions) were used in the regression of location WM.</p><p id="P60">After conducting linear regression, we obtained <italic>β, r</italic><sup>2</sup>(the coefficient of determination, representing regression explained variance), and <italic>p</italic> value of regression (representing the overall effectiveness of location <italic>β</italic>s to predict neural activity) for each neuron. Those neurons whose <italic>p</italic> values of linear regression were less than 0.01 would be considered location WM selective neurons. We further computed 2-norm of 6 location <italic>β</italic>s to evaluate tuning strength of each neuron, thereby summarizing the six coefficients by a single scalar metric.</p></sec><sec id="S27"><title>Decision selectivity of each neuron</title><p id="P61">We conducted linear regression for each neuron to quantify the tuning properties as follows: <disp-formula id="FD4"><mml:math id="M8"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo>∗</mml:mo><mml:mi>β</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></disp-formula></p><p id="P62">For the regression of decision, <italic>y</italic> represented the neuronal activity for each trial (a column vector with 1 by number of trial), <italic>β</italic><sub>0</sub> was the intercept term, <italic>β</italic> was the regression coefficient to be fitted, and <italic>x</italic> represented the behavioral label for each trial (0 for offload and 1 for memory).</p><p id="P63">After conducting linear regression, we obtained <italic>β</italic>, r<sup>2</sup>(the coefficient of determination, representing regression explained variance), and <italic>p</italic> value for each neuron. Those neurons whose <italic>p</italic> values of linear regression were less than 0.01 would be considered decision selective neurons.</p></sec></sec><sec id="S28"><title>Neural activity-based WM analysis (Related to <xref ref-type="fig" rid="F2">Figure 2</xref>)</title><sec id="S29"><title>Location probability distributions of behavior</title><p id="P64">As mentioned in the “Behavior recall variability” section above, we computed stimuli-to-response matrix of behavior data from the forced-to-test condition (<xref ref-type="fig" rid="F1">Fig. 1C</xref>), including both correct trials (diagonal) and error trials (non-diagonal). Each element of the matrix denotes the probability for a monkey to execute one particular sequence given the presentation sequence during the sample period.</p><p id="P65">Based on this matrix, we could in turn compute each stimulus location’s behavioral probability distribution from the stimuli-to-response matrix of behavior data (<xref ref-type="fig" rid="F2">Fig. 2C</xref>). Each element of the matrix denotes the probability for a monkey to execute one particular location given the presentation of a specific sequence during the sample period.</p></sec><sec id="S30"><title>Neural decoder-based WM strength</title><p id="P66">WM strength was defined as the inverted normalized entropy of the distribution of all possible decoded probabilities of sequences, given the neuronal population activity.</p><p id="P67">We trained six linear binary Support Vector Machines (SVMs) as sub-decoders to decode the probability of each location being represented by neuronal data, in which the labels for training were binary (0 or 1; from stimulus label) and then in testing set the output of the decoder was the probability. Given the time-averaged neuronal activity during delay, we trained the decoder on correct trials and tested it on both correct trials and error trials, using location-balanced resampling and K-fold (K=5) cross-validation. Each SVM sub-decoder was optimized using the MATLAB function ‘fitcecoc’. This allowed us to predict the location probability distribution for each trial. Different sub-decoders were trained for trials of different sequence lengths.</p><p id="P68">The chance level of Pearson’s correlation between location probability distributions of behavior data and those predicted by neural decoders of locations was computed via substituting decoded location probability distributions with random values sampled from a uniform probability distribution.</p><p id="P69">We then used the decoded location probability distributions to compute decoded probability of each sequence with multiple items through a joint probability approach, which involved calculating the product of all possible locations’ probabilities, with the assumption that each location was encoded independently from the others. We denote the probability of location <italic>i</italic> as <italic>p</italic>(<italic>location</italic> = <italic>i</italic>|<italic>activity</italic>). Take sequence [3-5] as an example, the decoded probability of the sequence was then <italic>P</italic>(<italic>seq</italic> = 35 | <italic>activity</italic>), where: <disp-formula id="FD5"><mml:math id="M9"><mml:mrow><mml:mtable equalrows="true" equalcolumns="true"><mml:mtr><mml:mtd><mml:mrow><mml:mspace width="5.0em"/><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mtext>seq</mml:mtext><mml:mo>=</mml:mo><mml:mn>35</mml:mn><mml:mo>∣</mml:mo><mml:mspace width="0.2em"/><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mspace width="0.2em"/><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.2em"/><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>∣</mml:mo><mml:mspace width="0.2em"/><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mspace width="0.2em"/><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>∗</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mspace width="0.2em"/><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.2em"/><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>∣</mml:mo><mml:mspace width="0.2em"/><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mspace width="0.2em"/><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>∗</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mspace width="0.2em"/><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.2em"/><mml:mo>=</mml:mo><mml:mn>3</mml:mn><mml:mo>∣</mml:mo><mml:mspace width="0.2em"/><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mspace width="0.2em"/><mml:mo stretchy="false">)</mml:mo><mml:mo>∗</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mspace width="0.2em"/><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.2em"/><mml:mo>=</mml:mo><mml:mn>4</mml:mn><mml:mo>∣</mml:mo><mml:mspace width="0.2em"/><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mspace width="0.2em"/><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>∗</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mspace width="0.2em"/><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.2em"/><mml:mo>=</mml:mo><mml:mn>5</mml:mn><mml:mo>∣</mml:mo><mml:mspace width="0.2em"/><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mspace width="0.2em"/><mml:mo stretchy="false">)</mml:mo><mml:mo>∗</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mspace width="0.2em"/><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.2em"/><mml:mo>=</mml:mo><mml:mn>6</mml:mn><mml:mo>∣</mml:mo><mml:mspace width="0.2em"/><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mspace width="0.2em"/><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p id="P70">Then, we computed <italic>entropy</italic> in a classical way, through distribution of all possible decoded probabilities of sequences, where: <disp-formula id="FD6"><mml:math id="M10"><mml:mi>E</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>y</mml:mi><mml:mspace width="0.2em"/><mml:mo stretchy="false">(</mml:mo><mml:mspace width="0.2em"/><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mspace width="0.2em"/><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:munder><mml:mstyle displaystyle="true"><mml:mi>∑</mml:mi></mml:mstyle><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>q</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:munder><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mspace width="0.2em"/><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>q</mml:mi><mml:mspace width="0.2em"/><mml:mo>∣</mml:mo><mml:mspace width="0.2em"/><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mspace width="0.2em"/><mml:mo stretchy="false">)</mml:mo><mml:mo>∗</mml:mo><mml:mi>log</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mspace width="0.2em"/><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>q</mml:mi><mml:mspace width="0.2em"/><mml:mo>∣</mml:mo><mml:mspace width="0.2em"/><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mspace width="0.2em"/><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.2em"/><mml:mi>M</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mspace width="0.2em"/><mml:mo stretchy="false">]</mml:mo></mml:math></disp-formula></p><p id="P71">Here, we also compute the theoretical upper bound of the <italic>entropy</italic>, by computing entropy of a uniform distribution, denoted as <italic>Max</italic>. Finally, we computed WM strength by inverting and normalizing the entropy from [0, Max] to [0, 1], where: <disp-formula id="FD7"><mml:math id="M11"><mml:mrow><mml:mspace width="0.2em"/><mml:mi>W</mml:mi><mml:mi>M</mml:mi><mml:mi/><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>g</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mspace width="0.2em"/><mml:mo stretchy="false">(</mml:mo><mml:mtext>a</mml:mtext><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mspace width="0.2em"/><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mspace width="0.2em"/><mml:mi>M</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mspace width="0.2em"/><mml:mo>−</mml:mo><mml:mspace width="0.2em"/><mml:mi>E</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>y</mml:mi><mml:mspace width="0.2em"/><mml:mo stretchy="false">(</mml:mo><mml:mspace width="0.2em"/><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mspace width="0.2em"/><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mspace width="0.2em"/><mml:mi>M</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:mfrac><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P72">WM strength = 0 represented a uniform probability distribution over all possible sequences and WM strength = 1 represented distributions where probability of one specific sequence came to exactly 1.</p><p id="P73">For analyses utilizing pseudo-population where data from all sessions were combined, we resampled the same number of trials (including memory correct trials and forced-to-test correct trials) of each sequence type across sessions. The resampling trial numbers across sequences were determined in a sequence length-dependent and location-balanced manner. Within each sequence length, resampling was performed to balance the number of trials across different locations. This resampling was repeated 32 times. For each resampling, we trained and tested a new set of decoders from which to recompute WM strength. After all resampling procedures, we averaged the testing results to produce the final pseudo-population-based evaluations of WM (<xref ref-type="supplementary-material" rid="SD1">Fig. S3</xref>).</p></sec></sec><sec id="S31"><title>Neural activity-based meta-WM analysis (Related to <xref ref-type="fig" rid="F3">Figure 3</xref>)</title><sec id="S32"><title>Meta-WM selectivity of each neuron</title><p id="P74">We conducted linear regression for each neuron to quantify its tuning properties regarding putative meta-WM (or how well the monkeys might consider their WM of stimuli locations to be) as follows: <disp-formula id="FD8"><mml:math id="M12"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>X</mml:mi><mml:mo>∗</mml:mo><mml:mi>β</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></disp-formula></p><p id="P75">Where <italic>y</italic> represented the neuronal activity for each sequence (a column vector with 1 by number of sequences), <italic>β</italic><sub>0</sub> was the intercept term, <italic>β</italic> was the regression coefficient to be fitted (a scalar), and <italic>x</italic> represented the behavioral offloading rate for each sequence (a column vector with 1 by number of sequences).</p><p id="P76">After conducting linear regression, we obtained <italic>β</italic>, r<sup>2</sup>(the coefficient of determination, representing regression explained variance), and <italic>p</italic> value for each neuron. Those neurons whose <italic>p</italic> values of linear regression were less than 0.01 would be considered meta-WM selective neurons. We further computed the 2-norm of <italic>β</italic>, here was an absolute value, to evaluate the tuning strength of each neuron.</p></sec><sec id="S33"><title>Neural decoder-based meta-WM</title><p id="P77">Here, meta-WM is defined as the probability with which a population of neurons encodes a decision of the memory option for a larger reward (likely judging current WM strength to be good).</p><p id="P78">We used a single linear SVM to decode the probability of choosing memory in the choice trials. The SVM functioned as a multivariable linear regressor by extracting the posterior probability as the output. Here, the input was the time-averaged population neuronal activity during the delay, and the output was the probability of choosing memory for the trials. We optimized the decoder to estimate the meta-WM values of the trials, using resampling to balance trial numbers for memory &amp; offload trials and K-fold (K=20) cross-validation for training and testing. For example, if there are 600 memory trials and 500 offload trials, then in each resampling iteration, we randomly select 500 trials from each condition without replacement. The optimization was performed using the MATLAB function ‘fitcecoc’. Here, the posterior probabilities extracted from applying the optimized decoder over trial-wise data were denoted as meta-WM scores, which represented the probability of choosing memory in current trials.</p><p id="P79">To further discriminate between memory and offload decisions based on the estimated meta-WM scores from the SVM, we fitted an optimal decision boundary by maximizing the values of (hit rate – false alarm rate), as in <xref ref-type="supplementary-material" rid="SD1">Figure S6A</xref>. Hit/False alarm rates represent proportions of trials where meta-WM scores exceed the decision boundary in all memory/offload trials, respectively. Trials with meta-WM scores above the boundary were classified as memory, while those below the boundary were classified as offload.</p><p id="P80">The AUROC curves were plotted as results from a moving decision boundary from 0.01 to 0.99 with a step of 0.001, in which each decision boundary could result in a pair of hit rate and false alarm rate. We plotted all the paired results and connected all the dots to compute the area under the curve. The shuffled AUROC distribution was computed by first shuffling the trial decision labels of “memory” and “offload”, then training and testing meta-WM decoders.</p></sec><sec id="S34"><title>Analysis of relationship between WM strength and meta-WM (Related to <xref ref-type="fig" rid="F4">Figure 4</xref>) <italic>Dynamics analysis of WM and meta-WM</italic></title><p id="P81">To explore the temporal dynamics of both WM (as in locations of constituent stimuli) and meta-WM of remembered sequences, we conducted two sets of correlations across time frames within each trial, ranging from the last target onset to the late delay. We resampled 16 times to compare latency times as shown in <xref ref-type="fig" rid="F4">Figure 4D</xref>. This resampling procedure aligned with the methods described in the “Neural decoder-based WM strength” and “Neural decoder-based meta-WM” sections.</p><p id="P82">As illustrated in <xref ref-type="fig" rid="F2">Figure 2</xref>, we used both location-level correlations and sequence-averaged WM strength to assess the neural dynamics of WM. Specifically, we employed a location-level correlation between location probabilities from the decoder (e.g., [0.1, 0.1, 0.9, 0.1, 0.9, 0.1]) and stimuli (e.g., [0, 0, 1, 0, 1, 0]) to track the dynamics of WM, testing when they began to deviate from the baseline. One-sample t-tests were used to determine whether the location-level correlation at each time frame (starting from the onset of the last target to 1.1 seconds into the delay period) had a higher mean value compared to that during the baseline period.</p><p id="P83">As shown in <xref ref-type="fig" rid="F3">Figure 3</xref>, we computed Peason’s correlation between sequence-averaged behavioral metrics (offloading rates) and sequence-averaged meta-WM scores. This correlation was also used to investigate the dynamics of meta-WM over time and identify when they deviated from the baseline. Again, one-sample t-tests were performed to examine whether the correlation at each time point showed a higher mean value than that of the baseline period.</p></sec><sec id="S35"><title>Validity of low-strength mismatch trial proportions in memory-error trials (<xref ref-type="fig" rid="F4">Fig. 4H</xref>)</title><p id="P84">The shuffled distribution was computed based on 1,000 iterations of random resampling of trials. In the results of recording session shown in <xref ref-type="fig" rid="F4">Figure 4H</xref> (monkey D FOV 8), there were 1,200 choice trials, of which 173 were memory-error trials (including 34 “match trials” where the probability distributions—from which WM strength was computed—peaked around the actual response sequences). For each resampling, 139 trials (excluding the 34 match trials from the 173 memory-error trials) were randomly selected without replacement from the 1,200 choice trials, to determine the proportion of trials that belonged to low-strength mismatches by chance. We then computed the 99th percentile of the shuffled distribution as the chance-level threshold (dashed line in <xref ref-type="fig" rid="F4">Fig. 4H</xref>).</p></sec></sec><sec id="S36"><title>Neural activity-based baseline meta-WM analysis (Related to <xref ref-type="fig" rid="F5">Figure 5</xref>)</title><sec id="S37"><title>Pupil size</title><p id="P85">The pupil size was filtered between 0.01 Hz and 10 Hz using a second-order Butterworth filter and then z-scored<sup><xref ref-type="bibr" rid="R60">60</xref></sup>.</p></sec><sec id="S38"><title>Trial history</title><p id="P86">We tested the role of trial history in generating prior beliefs. We first obtained a quantitative description of reward per trial from the approximation of real reward: Monkey D received 3 water drops for correct responses under memory and forced-to-test conditions, 2 for correct offload trials, and 0 for error trials, following a 3-2-0 reward scheme; monkey Z was rewarded according to a 2-1-0 scheme. We could then describe trial history as the number of rewards received over a certain number of past trials.</p><p id="P87">We multiplied the trial history values with exponential history weights over time<sup><xref ref-type="bibr" rid="R61">61</xref>,<xref ref-type="bibr" rid="R62">62</xref></sup>, such that more recent trials would have greater impact on a current meta-WM judgment. We then summed the adjusted trial history to obtain the weighted mean history reward value. This value was then used to predict whether the current trial would be classified as a memory or offload trial. We optimized this decision discrimination ability - measured by AUROC - to determine the optimal mean (μ) of an exponential distribution. The parameter can be further utilized to generate historical weights.</p></sec><sec id="S39"><title>Baseline meta-WM selectivity of each neuron</title><p id="P88">We refer to the decision selectivity during the baseline period as baseline meta-WM (prior) selectivity, since the results in <xref ref-type="fig" rid="F5">Figure 5D</xref> indicated that baseline meta-WM exhibited variability at the trial level but not at the sequence level. After conducting linear regression, we obtained <italic>β</italic> (the regression coefficient), <italic>r</italic><sup>2</sup> (the coefficient of determination, representing regression explained variance), and <italic>p</italic> value for each neuron. Those neurons whose <italic>p</italic> value of linear regression less than 0.01 were considered baseline meta-WM (prior) selective neurons.</p></sec><sec id="S40"><title>Neural decoder-based baseline meta-WM</title><p id="P89">The decoder architecture and training approach, as well as the decision boundary fitting, were exactly the same as those used for the meta-WM neural decoder described above except that the input was the baseline-averaged neuron activity instead of delay-averaged.</p></sec><sec id="S41"><title>Linear regression of trial-level meta-WM</title><p id="P90">In this analysis, we utilized baseline meta-WM and (delay) WM strength as predictors to regress the (delay) meta-WM of each trial, where: <disp-formula id="FD9"><mml:math id="M13"><mml:mrow><mml:mtable equalrows="true" equalcolumns="true"><mml:mtr><mml:mtd><mml:mrow><mml:mspace width="0.2em"/><mml:mi>M</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mo>_</mml:mo><mml:mtext>WM</mml:mtext><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>∗</mml:mo><mml:mspace width="0.2em"/><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi/><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mspace width="0.2em"/><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>∗</mml:mo><mml:mspace width="0.2em"/><mml:mi>W</mml:mi><mml:mi>M</mml:mi><mml:mi/><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>g</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mspace width="0.2em"/><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mspace width="0.2em"/><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi/><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>∗</mml:mo><mml:mspace width="0.2em"/><mml:mi>W</mml:mi><mml:mi>M</mml:mi><mml:mi/><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>g</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mspace width="0.2em"/><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p id="P91">The regression coefficients were estimated using a resampling approach with replacement. For each resampling iteration, the number of samples matched the total number of trials. We used the resampled trials to conduct linear regression and to calculate the <italic>β</italic> coefficients and regression explained variance. This process was repeated 1,000 times to generate a distribution of <italic>β</italic> coefficients for statistical testing.</p></sec></sec><sec id="S42"><title>Three task variables relationship analysis (Related to <xref ref-type="fig" rid="F6">Figure 6</xref>)</title><sec id="S43"><title>Subspace estimation and principal angles between subspaces</title><p id="P92">Based on the previously decoded variables (baseline meta-WM, WM strength, and meta-WM), we performed linear regression to model these variables across trials using neuronal population activity. For example, we regressed meta-WM scores on neuronal population activity. To avoid overfitting, we employed Lasso regularization with 3-fold cross-validation in the linear regression. The beta coefficients obtained from these regressions defined an one-dimensional subspace (axis) for each variable, forming vectors within the neuronal state space. We then computed the angles between these one-dimensional subspaces<sup><xref ref-type="bibr" rid="R63">63</xref></sup>. As a control, we randomly split the trials into two halves to obtain separate estimations of each subspace and computed the angles between them; this process was repeated 112 times.</p></sec><sec id="S44"><title>Variance accounted for (VAF) ratio between subspaces</title><p id="P93">For given two one-dimensional subspaces, which are vectors of beta coefficients, <inline-formula><mml:math id="M14"><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula>and <inline-formula><mml:math id="M15"><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>b</mml:mi></mml:msub></mml:math></inline-formula>, the VAF ratio<sup><xref ref-type="bibr" rid="R63">63</xref>,64</sup> for subspace pair (a, b) was defined as <disp-formula id="FD10"><mml:math id="M16"><mml:mi>V</mml:mi><mml:mi>A</mml:mi><mml:mi>F</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>b</mml:mi><mml:mo>_</mml:mo><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>b</mml:mi><mml:mo>_</mml:mo><mml:mtext>unit</mml:mtext></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:mo>∗</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>a</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>a</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p id="P94">Where<inline-formula><mml:math id="M17"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>b</mml:mi><mml:mo>_</mml:mo><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>is the unit vector of <inline-formula><mml:math id="M18"><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>b</mml:mi></mml:msub></mml:math></inline-formula>. As a control, we randomly split the trials into two halves to obtain separate estimations of each subspace and computed the VAF ratio between them, and this process was repeated 112 times.</p></sec><sec id="S45"><title>Time course of AUROC within subspaces</title><p id="P95">As previously described, for each variable, we derived a vector of regression coefficients <inline-formula><mml:math id="M19"><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:math></inline-formula> via linear regression to quantify the subspace. Taking the meta-WM subspace as an example, we projected the neuronal population activity matrix (F) at each time bin (33 ms) onto this vector to compute the estimated meta-WM scores (EMS): <disp-formula id="FD11"><mml:math id="M20"><mml:mtext>EMS</mml:mtext><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo>∗</mml:mo><mml:mi>F</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></disp-formula></p><p id="P96">Here, <inline-formula><mml:math id="M21"><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>→</mml:mo></mml:mover></mml:math></inline-formula> is a 1-by-n vector, where n denotes the number of neurons; <italic>F</italic> is an n-by-m matrix, with m representing the number of trials; and <italic>β</italic><sub>0</sub> is the intercept term from the linear regression model. This projection, from neuronal activity to the meta-WM subspace, yielded a scalar meta-WM score for each trial at each time bin. The same procedure was employed to estimate scores for the baseline meta and WM strength subspaces. Subsequently, we analyzed the time courses of AUROC to differentiate between memory and offload trials within both the baseline meta and meta-WM subspaces, as well as between low-strength and high-strength trials within the WM strength subspace.</p></sec><sec id="S46"><title>Spatial organization of selective neurons</title><p id="P97">We quantified and compared the spatial distances within and between groups (baseline meta-WM, WM, meta-WM)<sup>65</sup>. We quantified the distance within groups by computing the average distance of each neuron to other neurons within the same group. We quantified the distance between groups by computing the average distance of each neuron to other neurons in different groups.</p></sec><sec id="S47"><title>Subspace-selective neurons (Related to <xref ref-type="supplementary-material" rid="SD1">Fig. S17</xref>)</title><p id="P98">We randomly split the trials into two halves to obtain two separate estimations for each subspace and the corresponding neuronal coefficients, denoted as <italic>β</italic><sub><italic>A</italic></sub> and <italic>β</italic><sub><italic>B</italic></sub> for a given example neuron. For each of the 112 resampling iterations, we computed the difference between the coefficients (<italic>β</italic><sub><italic>diff</italic></sub> = <italic>β</italic><sub><italic>A</italic></sub> − <italic>β</italic><sub><italic>B</italic></sub>) and their mean (<italic>β</italic><sub><italic>mean</italic></sub> = (<italic>β</italic><sub><italic>A</italic></sub> + <italic>β</italic><sub><italic>B</italic></sub>)/<sup>2</sup>). We then computed the mean difference between the coefficients across all resampling iterations (<italic>β</italic><sub><italic>diff_mean</italic></sub>). A neuron was considered to contribute to the subspace in a given resampling if the absolute value of <italic>β</italic><sub><italic>mean</italic></sub> exceeded five times the absolute value of <italic>β</italic><sub><italic>diff_mean</italic></sub>. Neurons meeting this criterion in more than 99% of the resampling iterations were classified as subspace-selective, indicating a statistically significant and consistent contribution to the subspace.</p></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supp</label><media xlink:href="EMS207446-supplement-Supp.pdf" mimetype="application" mime-subtype="pdf" id="d53aAcLbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S48"><title>Acknowledgments</title><p>We thank Marion Rouault, Gouki Okazawa, Xi Jiang, and Zhenghe Tian for their critical comments on the manuscript. This work was supported by the STI2030-Major Project (2021ZD0204102), the National Science Fund for Distinguished Young Scholars (32225022), the CAS Project for Young Scientists in Basic Research (YSBR-071), and the Shanghai Municipal Science and Technology Major Project 2021SHZDZX to L.W. FM is supported by a European Research Council grant (ERC StG 947105-NEURAL-PROB).</p></ack><fn-group><fn fn-type="conflict" id="FN2"><p id="P99"><bold>Declaration of interests</bold></p><p id="P100">The authors declare no competing interests.</p></fn></fn-group><ref-list><ref id="R1"><label>1</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Baddeley</surname><given-names>AD</given-names></name><name><surname>Hitch</surname><given-names>G</given-names></name></person-group><chapter-title>Working Memory</chapter-title><person-group person-group-type="editor"><name><surname>Bower</surname><given-names>GH</given-names></name></person-group><source>Psychology of Learning and Motivation</source><publisher-name>Academic Press</publisher-name><year>1974</year><fpage>47</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1016/s0079-7421(08)60452-1</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luck</surname><given-names>SJ</given-names></name><name><surname>Vogel</surname><given-names>EK</given-names></name></person-group><article-title>The capacity of visual working memory for features and conjunctions</article-title><source>Nature</source><year>1997</year><volume>390</volume><fpage>279</fpage><lpage>281</lpage><pub-id pub-id-type="pmid">9384378</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cowan</surname><given-names>N</given-names></name></person-group><article-title>The magical number 4 in short-term memory: a reconsideration of mental storage capacity</article-title><source>Behav Brain Sci</source><year>2001</year><volume>24</volume><fpage>87</fpage><lpage>114</lpage><comment>discussion 114–185</comment><pub-id pub-id-type="pmid">11515286</pub-id></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Risko</surname><given-names>EF</given-names></name><name><surname>Gilbert</surname><given-names>SJ</given-names></name></person-group><article-title>Cognitive Offloading</article-title><source>Trends Cogn Sci</source><year>2016</year><volume>20</volume><fpage>676</fpage><lpage>688</lpage><pub-id pub-id-type="pmid">27542527</pub-id></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flavell</surname><given-names>JH</given-names></name><name><surname>Wellman</surname><given-names>HM</given-names></name></person-group><article-title>Metamemory</article-title><year>1975</year></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yoo</surname><given-names>AH</given-names></name><name><surname>Acerbi</surname><given-names>L</given-names></name><name><surname>Ma</surname><given-names>WJ</given-names></name></person-group><article-title>Uncertainty is maintained and used in working memory</article-title><source>J Vis</source><year>2021</year><volume>21</volume><fpage>13</fpage><pub-id pub-id-type="doi">10.1167/jov.21.8.13</pub-id><pub-id pub-id-type="pmcid">PMC8356567</pub-id><pub-id pub-id-type="pmid">34369970</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>HH</given-names></name><name><surname>Sprague</surname><given-names>TC</given-names></name><name><surname>Yoo</surname><given-names>AH</given-names></name><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Curtis</surname><given-names>CE</given-names></name></person-group><article-title>Joint representation of working memory and uncertainty in human cortex</article-title><source>Neuron</source><year>2021</year><volume>109</volume><fpage>3699</fpage><lpage>3712</lpage><elocation-id>e3696</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuron.2021.08.022</pub-id><pub-id pub-id-type="pmcid">PMC8602749</pub-id><pub-id pub-id-type="pmid">34525327</pub-id></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Honig</surname><given-names>M</given-names></name><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Fougnie</surname><given-names>D</given-names></name></person-group><article-title>Humans incorporate trial-to-trial working memory uncertainty into rewarded decisions</article-title><source>Proc Natl Acad Sci U S A</source><year>2020</year><volume>117</volume><fpage>8391</fpage><lpage>8397</lpage><pub-id pub-id-type="doi">10.1073/pnas.1918143117</pub-id><pub-id pub-id-type="pmcid">PMC7165478</pub-id><pub-id pub-id-type="pmid">32229572</pub-id></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xie</surname><given-names>Y</given-names></name><name><surname>Hu</surname><given-names>P</given-names></name><name><surname>Li</surname><given-names>J</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Song</surname><given-names>W</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name><name><surname>Yang</surname><given-names>T</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Tang</surname><given-names>S</given-names></name><name><surname>Min</surname><given-names>B</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name></person-group><article-title>Geometry of sequence working memory in macaque prefrontal cortex</article-title><source>Science</source><year>2022</year><volume>375</volume><fpage>632</fpage><lpage>639</lpage><pub-id pub-id-type="pmid">35143322</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>C</given-names></name><name><surname>Hu</surname><given-names>P</given-names></name><name><surname>Min</surname><given-names>B</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name></person-group><article-title>Flexible control of sequence working memory in the macaque frontal cortex</article-title><source>Neuron</source><year>2024</year><volume>112</volume><fpage>3502</fpage><lpage>3514</lpage><elocation-id>e3506</elocation-id><pub-id pub-id-type="pmid">39178858</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tian</surname><given-names>Z</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>C</given-names></name><name><surname>Min</surname><given-names>B</given-names></name><name><surname>Xu</surname><given-names>B</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name></person-group><article-title>Mental programming of spatial sequences in working memory in the macaque frontal cortex</article-title><source>Science</source><year>2024</year><volume>385</volume><elocation-id>eadp6091</elocation-id><pub-id pub-id-type="pmid">39325894</pub-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fleming</surname><given-names>SM</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>The neural basis of metacognitive ability</article-title><source>Philos Trans R Soc Lond B Biol Sci</source><year>2012</year><volume>367</volume><fpage>1338</fpage><lpage>1349</lpage><pub-id pub-id-type="doi">10.1098/rstb.2011.0417</pub-id><pub-id pub-id-type="pmcid">PMC3318765</pub-id><pub-id pub-id-type="pmid">22492751</pub-id></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vaccaro</surname><given-names>AG</given-names></name><name><surname>Fleming</surname><given-names>SM</given-names></name></person-group><article-title>Thinking about thinking: A coordinate-based meta-analysis of neuroimaging studies of metacognitive judgements</article-title><source>Brain Neurosci Adv</source><year>2018</year><volume>2</volume><elocation-id>2398212818810591</elocation-id><pub-id pub-id-type="doi">10.1177/2398212818810591</pub-id><pub-id pub-id-type="pmcid">PMC6238228</pub-id><pub-id pub-id-type="pmid">30542659</pub-id></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miyamoto</surname><given-names>K</given-names></name><name><surname>Trudel</surname><given-names>N</given-names></name><name><surname>Kamermans</surname><given-names>K</given-names></name><name><surname>Lim</surname><given-names>MC</given-names></name><name><surname>Lazari</surname><given-names>A</given-names></name><name><surname>Verhagen</surname><given-names>L</given-names></name><name><surname>Wittmann</surname><given-names>MK</given-names></name><name><surname>Rushworth</surname><given-names>MFS</given-names></name></person-group><article-title>Identification and disruption of a neural mechanism for accumulating prospective metacognitive information prior to decision-making</article-title><source>Neuron</source><year>2021</year><volume>109</volume><fpage>1396</fpage><lpage>1408</lpage><elocation-id>e1397</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuron.2021.02.024</pub-id><pub-id pub-id-type="pmcid">PMC8063717</pub-id><pub-id pub-id-type="pmid">33730554</pub-id></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Middlebrooks</surname><given-names>PG</given-names></name><name><surname>Sommer</surname><given-names>MA</given-names></name></person-group><article-title>Neuronal correlates of metacognition in primate frontal cortex</article-title><source>Neuron</source><year>2012</year><volume>75</volume><fpage>517</fpage><lpage>530</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.05.028</pub-id><pub-id pub-id-type="pmcid">PMC3418516</pub-id><pub-id pub-id-type="pmid">22884334</pub-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miyamoto</surname><given-names>K</given-names></name><name><surname>Osada</surname><given-names>T</given-names></name><name><surname>Setsuie</surname><given-names>R</given-names></name><name><surname>Takeda</surname><given-names>M</given-names></name><name><surname>Tamura</surname><given-names>K</given-names></name><name><surname>Adachi</surname><given-names>Y</given-names></name><name><surname>Miyashita</surname><given-names>Y</given-names></name></person-group><article-title>Causal neural network of metamemory for retrospection in primates</article-title><source>Science</source><year>2017</year><volume>355</volume><fpage>188</fpage><lpage>193</lpage><pub-id pub-id-type="pmid">28082592</pub-id></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kepecs</surname><given-names>A</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name><name><surname>Zariwala</surname><given-names>HA</given-names></name><name><surname>Mainen</surname><given-names>ZF</given-names></name></person-group><article-title>Neural correlates, computation and behavioural impact of decision confidence</article-title><source>Nature</source><year>2008</year><volume>455</volume><fpage>227</fpage><lpage>231</lpage><pub-id pub-id-type="pmid">18690210</pub-id></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joo</surname><given-names>HR</given-names></name><name><surname>Liang</surname><given-names>H</given-names></name><name><surname>Chung</surname><given-names>JE</given-names></name><name><surname>Geaghan-Breiner</surname><given-names>C</given-names></name><name><surname>Fan</surname><given-names>JL</given-names></name><name><surname>Nachman</surname><given-names>BP</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name><name><surname>Frank</surname><given-names>LM</given-names></name></person-group><article-title>Rats use memory confidence to guide decisions</article-title><source>Curr Biol</source><year>2021</year><volume>31</volume><fpage>4571</fpage><lpage>4583</lpage><elocation-id>e4574</elocation-id><pub-id pub-id-type="doi">10.1016/j.cub.2021.08.013</pub-id><pub-id pub-id-type="pmcid">PMC8551068</pub-id><pub-id pub-id-type="pmid">34473948</pub-id></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baird</surname><given-names>B</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Gorgolewski</surname><given-names>KJ</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name></person-group><article-title>Medial and lateral networks in anterior prefrontal cortex support metacognitive ability for memory and perception</article-title><source>J Neurosci</source><year>2013</year><volume>33</volume><fpage>16657</fpage><lpage>16665</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0786-13.2013</pub-id><pub-id pub-id-type="pmcid">PMC6618531</pub-id><pub-id pub-id-type="pmid">24133268</pub-id></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kwok</surname><given-names>SC</given-names></name><name><surname>Cai</surname><given-names>Y</given-names></name><name><surname>Buckley</surname><given-names>MJ</given-names></name></person-group><article-title>Mnemonic Introspection in Macaques Is Dependent on Superior Dorsolateral Prefrontal Cortex But Not Orbitofrontal Cortex</article-title><source>J Neurosci</source><year>2019</year><volume>39</volume><fpage>5922</fpage><lpage>5934</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0330-19.2019</pub-id><pub-id pub-id-type="pmcid">PMC6650985</pub-id><pub-id pub-id-type="pmid">31123101</pub-id></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fleming</surname><given-names>SM</given-names></name></person-group><article-title>Metacognition and Confidence: A Review and Synthesis</article-title><source>Annu Rev Psychol</source><year>2024</year><volume>75</volume><fpage>241</fpage><lpage>268</lpage><pub-id pub-id-type="pmid">37722748</pub-id></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lau</surname><given-names>H</given-names></name><name><surname>Michel</surname><given-names>M</given-names></name><name><surname>LeDoux</surname><given-names>JE</given-names></name><name><surname>Fleming</surname><given-names>SM</given-names></name></person-group><article-title>The mnemonic basis of subjective experience</article-title><source>Nature Reviews Psychology</source><year>2022</year><volume>1</volume><fpage>479</fpage><lpage>488</lpage><pub-id pub-id-type="doi">10.1038/s44159-022-00068-6</pub-id></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiani</surname><given-names>R</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><article-title>Representation of confidence associated with a decision by neurons in the parietal cortex</article-title><source>Science</source><year>2009</year><volume>324</volume><fpage>759</fpage><lpage>764</lpage><pub-id pub-id-type="doi">10.1126/science.1169405</pub-id><pub-id pub-id-type="pmcid">PMC2738936</pub-id><pub-id pub-id-type="pmid">19423820</pub-id></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Okazawa</surname><given-names>G</given-names></name><name><surname>Hatch</surname><given-names>CE</given-names></name><name><surname>Mancoo</surname><given-names>A</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name><name><surname>Kiani</surname><given-names>R</given-names></name></person-group><article-title>Representational geometry of perceptual decisions in the monkey parietal cortex</article-title><source>Cell</source><year>2021</year><volume>184</volume><fpage>3748</fpage><lpage>3761</lpage><elocation-id>e3718</elocation-id><pub-id pub-id-type="doi">10.1016/j.cell.2021.05.022</pub-id><pub-id pub-id-type="pmcid">PMC8273140</pub-id><pub-id pub-id-type="pmid">34171308</pub-id></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alter</surname><given-names>AL</given-names></name><name><surname>Oppenheimer</surname><given-names>DM</given-names></name></person-group><article-title>Uniting the tribes of fluency to form a metacognitive nation</article-title><source>Pers Soc Psychol Rev</source><year>2009</year><volume>13</volume><fpage>219</fpage><lpage>235</lpage><pub-id pub-id-type="pmid">19638628</pub-id></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koriat</surname><given-names>A</given-names></name><name><surname>Bjork</surname><given-names>RA</given-names></name><name><surname>Sheffer</surname><given-names>L</given-names></name><name><surname>Bar</surname><given-names>SK</given-names></name></person-group><article-title>Predicting one’s own forgetting: the role of experience-based and theory-based processes</article-title><source>J Exp Psychol Gen</source><year>2004</year><volume>133</volume><fpage>643</fpage><lpage>656</lpage><pub-id pub-id-type="pmid">15584811</pub-id></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hu</surname><given-names>X</given-names></name><name><surname>Zheng</surname><given-names>J</given-names></name><name><surname>Su</surname><given-names>N</given-names></name><name><surname>Fan</surname><given-names>T</given-names></name><name><surname>Yang</surname><given-names>C</given-names></name><name><surname>Yin</surname><given-names>Y</given-names></name><name><surname>Fleming</surname><given-names>SM</given-names></name><name><surname>Luo</surname><given-names>L</given-names></name></person-group><article-title>A Bayesian inference model for metamemory</article-title><source>Psychol Rev</source><year>2021</year><volume>128</volume><fpage>824</fpage><lpage>855</lpage><pub-id pub-id-type="doi">10.1037/rev0000270</pub-id><pub-id pub-id-type="pmcid">PMC9006386</pub-id><pub-id pub-id-type="pmid">34043396</pub-id></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiacconi</surname><given-names>CM</given-names></name><name><surname>Peter</surname><given-names>EL</given-names></name><name><surname>Owais</surname><given-names>S</given-names></name><name><surname>Kohler</surname><given-names>S</given-names></name></person-group><article-title>Knowing by heart: Visceral feedback shapes recognition memory judgments</article-title><source>J Exp Psychol Gen</source><year>2016</year><volume>145</volume><fpage>559</fpage><lpage>572</lpage><pub-id pub-id-type="pmid">27019022</pub-id></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferrigno</surname><given-names>S</given-names></name><name><surname>Kornell</surname><given-names>N</given-names></name><name><surname>Cantlon</surname><given-names>JF</given-names></name></person-group><article-title>A metacognitive illusion in monkeys</article-title><source>Proc Biol Sci</source><year>2017</year><volume>284</volume><pub-id pub-id-type="doi">10.1098/rspb.2017.1541</pub-id><pub-id pub-id-type="pmcid">PMC5597844</pub-id><pub-id pub-id-type="pmid">28878068</pub-id></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rahnev</surname><given-names>D</given-names></name><name><surname>Denison</surname><given-names>RN</given-names></name></person-group><article-title>Suboptimality in perceptual decision making</article-title><source>Behav Brain Sci</source><year>2018</year><volume>41</volume><elocation-id>e223</elocation-id><pub-id pub-id-type="doi">10.1017/S0140525X18000936</pub-id><pub-id pub-id-type="pmcid">PMC6110994</pub-id><pub-id pub-id-type="pmid">29485020</pub-id></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gavas</surname><given-names>RD</given-names></name><name><surname>Tripathy</surname><given-names>SR</given-names></name><name><surname>Chatterjee</surname><given-names>D</given-names></name><name><surname>Sinha</surname><given-names>A</given-names></name></person-group><article-title>Cognitive load and metacognitive confidence extraction from pupillary response</article-title><source>Cognitive Systems Research</source><year>2018</year><volume>52</volume><fpage>325</fpage><lpage>334</lpage><pub-id pub-id-type="doi">10.1016/j.cogsys.2018.07.021</pub-id></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lempert</surname><given-names>KM</given-names></name><name><surname>Chen</surname><given-names>YL</given-names></name><name><surname>Fleming</surname><given-names>SM</given-names></name></person-group><article-title>Relating Pupil Dilation and Metacognitive Confidence during Auditory Decision-Making</article-title><source>PLoS One</source><year>2015</year><volume>10</volume><elocation-id>e0126588</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0126588</pub-id><pub-id pub-id-type="pmcid">PMC4423945</pub-id><pub-id pub-id-type="pmid">25950839</pub-id></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Purcell</surname><given-names>BA</given-names></name><name><surname>Kiani</surname><given-names>R</given-names></name></person-group><article-title>Hierarchical decision processes that operate over distinct timescales underlie choice and changes in strategy</article-title><source>Proc Natl Acad Sci U S A</source><year>2016</year><volume>113</volume><fpage>E4531</fpage><lpage>4540</lpage><pub-id pub-id-type="doi">10.1073/pnas.1524685113</pub-id><pub-id pub-id-type="pmcid">PMC4978308</pub-id><pub-id pub-id-type="pmid">27432960</pub-id></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rouault</surname><given-names>M</given-names></name><name><surname>Fleming</surname><given-names>SM</given-names></name></person-group><article-title>Formation of global self-beliefs in the human brain</article-title><source>Proc Natl Acad Sci U S A</source><year>2020</year><volume>117</volume><fpage>27268</fpage><lpage>27276</lpage><pub-id pub-id-type="doi">10.1073/pnas.2003094117</pub-id><pub-id pub-id-type="pmcid">PMC7959580</pub-id><pub-id pub-id-type="pmid">33060292</pub-id></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hattori</surname><given-names>R</given-names></name><name><surname>Danskin</surname><given-names>B</given-names></name><name><surname>Babic</surname><given-names>Z</given-names></name><name><surname>Mlynaryk</surname><given-names>N</given-names></name><name><surname>Komiyama</surname><given-names>T</given-names></name></person-group><article-title>Area-Specificity and Plasticity of History-Dependent Value Coding During Learning</article-title><source>Cell</source><year>2019</year><volume>177</volume><fpage>1858</fpage><lpage>1872</lpage><elocation-id>e1815</elocation-id><pub-id pub-id-type="doi">10.1016/j.cell.2019.04.027</pub-id><pub-id pub-id-type="pmcid">PMC6663310</pub-id><pub-id pub-id-type="pmid">31080067</pub-id></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stuber</surname><given-names>GD</given-names></name><name><surname>Steinmetz</surname><given-names>NA</given-names></name><name><surname>Bowen</surname><given-names>AJ</given-names></name><name><surname>Hjort</surname><given-names>MM</given-names></name><name><surname>Ottenheimer</surname><given-names>DJ</given-names></name></person-group><article-title>A stable, distributed code for cue value in mouse cortex during reward learning</article-title><source>eLife</source><year>2023</year><volume>12</volume><pub-id pub-id-type="doi">10.7554/eLife.84604</pub-id><pub-id pub-id-type="pmcid">PMC10328514</pub-id><pub-id pub-id-type="pmid">37382590</pub-id></element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>N</given-names></name><name><surname>Daie</surname><given-names>K</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name><name><surname>Druckmann</surname><given-names>S</given-names></name></person-group><article-title>Robust neuronal dynamics in premotor cortex during motor planning</article-title><source>Nature</source><year>2016</year><volume>532</volume><fpage>459</fpage><lpage>464</lpage><pub-id pub-id-type="doi">10.1038/nature17643</pub-id><pub-id pub-id-type="pmcid">PMC5081260</pub-id><pub-id pub-id-type="pmid">27074502</pub-id></element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>Y</given-names></name><name><surname>Nitz</surname><given-names>DA</given-names></name><name><surname>Xu</surname><given-names>X</given-names></name><name><surname>Giocomo</surname><given-names>LM</given-names></name></person-group><article-title>Subicular neurons encode concave and convex geometries</article-title><source>Nature</source><year>2024</year><volume>627</volume><fpage>821</fpage><lpage>829</lpage><pub-id pub-id-type="doi">10.1038/s41586-024-07139-z</pub-id><pub-id pub-id-type="pmcid">PMC10972755</pub-id><pub-id pub-id-type="pmid">38448584</pub-id></element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyniel</surname><given-names>F</given-names></name><name><surname>Schlunegger</surname><given-names>D</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><article-title>The Sense of Confidence during Probabilistic Learning: A Normative Account</article-title><source>PLoS Comput Biol</source><year>2015</year><volume>11</volume><elocation-id>e1004305</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004305</pub-id><pub-id pub-id-type="pmcid">PMC4468157</pub-id><pub-id pub-id-type="pmid">26076466</pub-id></element-citation></ref><ref id="R40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bang</surname><given-names>D</given-names></name><name><surname>Fleming</surname><given-names>SM</given-names></name></person-group><article-title>Distinct encoding of decision confidence in human medial prefrontal cortex</article-title><source>Proc Natl Acad Sci U S A</source><year>2018</year><volume>115</volume><fpage>6082</fpage><lpage>6087</lpage><pub-id pub-id-type="doi">10.1073/pnas.1800795115</pub-id><pub-id pub-id-type="pmcid">PMC6003322</pub-id><pub-id pub-id-type="pmid">29784814</pub-id></element-citation></ref><ref id="R41"><label>41</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walker</surname><given-names>EY</given-names></name><name><surname>Cotton</surname><given-names>RJ</given-names></name><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name></person-group><article-title>A neural basis of probabilistic computation in visual cortex</article-title><source>Nat Neurosci</source><year>2020</year><volume>23</volume><fpage>122</fpage><lpage>129</lpage><pub-id pub-id-type="pmid">31873286</pub-id></element-citation></ref><ref id="R42"><label>42</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geurts</surname><given-names>LS</given-names></name><name><surname>Cooke</surname><given-names>JRH</given-names></name><name><surname>van Bergen</surname><given-names>RS</given-names></name><name><surname>Jehee</surname><given-names>JFM</given-names></name></person-group><article-title>Subjective confidence reflects representation of Bayesian probability in cortex</article-title><source>Nat Hum Behav</source><year>2022</year><volume>6</volume><fpage>294</fpage><lpage>305</lpage><pub-id pub-id-type="doi">10.1038/s41562-021-01247-w</pub-id><pub-id pub-id-type="pmcid">PMC7612428</pub-id><pub-id pub-id-type="pmid">35058641</pub-id></element-citation></ref><ref id="R43"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walker</surname><given-names>EY</given-names></name><name><surname>Pohl</surname><given-names>S</given-names></name><name><surname>Denison</surname><given-names>RN</given-names></name><name><surname>Barack</surname><given-names>DL</given-names></name><name><surname>Lee</surname><given-names>J</given-names></name><name><surname>Block</surname><given-names>N</given-names></name><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Meyniel</surname><given-names>F</given-names></name></person-group><article-title>Studying the neural representations of uncertainty</article-title><source>Nat Neurosci</source><year>2023</year><volume>26</volume><fpage>1857</fpage><lpage>1867</lpage><pub-id pub-id-type="pmid">37814025</pub-id></element-citation></ref><ref id="R44"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lebreton</surname><given-names>M</given-names></name><name><surname>Abitbol</surname><given-names>R</given-names></name><name><surname>Daunizeau</surname><given-names>J</given-names></name><name><surname>Pessiglione</surname><given-names>M</given-names></name></person-group><article-title>Automatic integration of confidence in the brain valuation signal</article-title><source>Nat Neurosci</source><year>2015</year><volume>18</volume><fpage>1159</fpage><lpage>1167</lpage><pub-id pub-id-type="pmid">26192748</pub-id></element-citation></ref><ref id="R45"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rutishauser</surname><given-names>U</given-names></name><name><surname>Aflalo</surname><given-names>T</given-names></name><name><surname>Rosario</surname><given-names>ER</given-names></name><name><surname>Pouratian</surname><given-names>N</given-names></name><name><surname>Andersen</surname><given-names>RA</given-names></name></person-group><article-title>Single-Neuron Representation of Memory Strength and Recognition Confidence in Left Human Posterior Parietal Cortex</article-title><source>Neuron</source><year>2018</year><volume>97</volume><fpage>209</fpage><lpage>220</lpage><elocation-id>e203</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuron.2017.11.029</pub-id><pub-id pub-id-type="pmcid">PMC5754243</pub-id><pub-id pub-id-type="pmid">29249283</pub-id></element-citation></ref><ref id="R46"><label>46</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Komura</surname><given-names>Y</given-names></name><name><surname>Nikkuni</surname><given-names>A</given-names></name><name><surname>Hirashima</surname><given-names>N</given-names></name><name><surname>Uetake</surname><given-names>T</given-names></name><name><surname>Miyamoto</surname><given-names>A</given-names></name></person-group><article-title>Responses of pulvinar neurons reflect a subject’s confidence in visual categorization</article-title><source>Nat Neurosci</source><year>2013</year><volume>16</volume><fpage>749</fpage><lpage>755</lpage><pub-id pub-id-type="pmid">23666179</pub-id></element-citation></ref><ref id="R47"><label>47</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rutishauser</surname><given-names>U</given-names></name><name><surname>Ye</surname><given-names>S</given-names></name><name><surname>Koroma</surname><given-names>M</given-names></name><name><surname>Tudusciuc</surname><given-names>O</given-names></name><name><surname>Ross</surname><given-names>IB</given-names></name><name><surname>Chung</surname><given-names>JM</given-names></name><name><surname>Mamelak</surname><given-names>AN</given-names></name></person-group><article-title>Representation of retrieval confidence by single neurons in the human medial temporal lobe</article-title><source>Nat Neurosci</source><year>2015</year><volume>18</volume><fpage>1041</fpage><lpage>1050</lpage><pub-id pub-id-type="doi">10.1038/nn.4041</pub-id><pub-id pub-id-type="pmcid">PMC4482779</pub-id><pub-id pub-id-type="pmid">26053402</pub-id></element-citation></ref><ref id="R48"><label>48</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vivar-Lazo</surname><given-names>M</given-names></name><name><surname>Fetsch</surname><given-names>CR</given-names></name></person-group><article-title>Neural basis of concurrent deliberation toward a choice and degree of confidence</article-title><source>bioRxiv</source><year>2024</year><pub-id pub-id-type="doi">10.1101/2024.08.06.606833</pub-id></element-citation></ref><ref id="R49"><label>49</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rigotti</surname><given-names>M</given-names></name><name><surname>Barak</surname><given-names>O</given-names></name><name><surname>Warden</surname><given-names>MR</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name></person-group><article-title>The importance of mixed selectivity in complex cognitive tasks</article-title><source>Nature</source><year>2013</year><volume>497</volume><fpage>585</fpage><lpage>590</lpage><pub-id pub-id-type="doi">10.1038/nature12160</pub-id><pub-id pub-id-type="pmcid">PMC4412347</pub-id><pub-id pub-id-type="pmid">23685452</pub-id></element-citation></ref><ref id="R50"><label>50</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jazayeri</surname><given-names>M</given-names></name><name><surname>Ostojic</surname><given-names>S</given-names></name></person-group><article-title>Interpreting neural computations by examining intrinsic and embedding dimensionality of neural activity</article-title><source>Curr Opin Neurobiol</source><year>2021</year><volume>70</volume><fpage>113</fpage><lpage>120</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2021.08.002</pub-id><pub-id pub-id-type="pmcid">PMC8688220</pub-id><pub-id pub-id-type="pmid">34537579</pub-id></element-citation></ref><ref id="R51"><label>51</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beiran</surname><given-names>M</given-names></name><name><surname>Dubreuil</surname><given-names>A</given-names></name><name><surname>Valente</surname><given-names>A</given-names></name><name><surname>Mastrogiuseppe</surname><given-names>F</given-names></name><name><surname>Ostojic</surname><given-names>S</given-names></name></person-group><article-title>Shaping Dynamics With Multiple Populations in Low-Rank Recurrent Networks</article-title><source>Neural Comput</source><year>2021</year><volume>33</volume><fpage>1572</fpage><lpage>1615</lpage><pub-id pub-id-type="pmid">34496384</pub-id></element-citation></ref></ref-list><ref-list><title>Methods references</title><ref id="R52"><label>52</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname><given-names>DH</given-names></name></person-group><article-title>The Psychophysics Toolbox</article-title><source>Spat Vis</source><year>1997</year><volume>10</volume><fpage>433</fpage><lpage>436</lpage><pub-id pub-id-type="pmid">9176952</pub-id></element-citation></ref><ref id="R53"><label>53</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pelli</surname><given-names>DG</given-names></name></person-group><article-title>The VideoToolbox software for visual psychophysics: transforming numbers into movies</article-title><source>Spat Vis</source><year>1997</year><volume>10</volume><fpage>437</fpage><lpage>442</lpage><pub-id pub-id-type="pmid">9176953</pub-id></element-citation></ref><ref id="R54"><label>54</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petrides</surname><given-names>M</given-names></name><name><surname>Tomaiuolo</surname><given-names>F</given-names></name><name><surname>Yeterian</surname><given-names>EH</given-names></name><name><surname>Pandya</surname><given-names>DN</given-names></name></person-group><article-title>The prefrontal cortex: comparative architectonic organization in the human and the macaque monkey brains</article-title><source>Cortex</source><year>2012</year><volume>48</volume><fpage>46</fpage><lpage>57</lpage><pub-id pub-id-type="pmid">21872854</pub-id></element-citation></ref><ref id="R55"><label>55</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sadakane</surname><given-names>O</given-names></name><name><surname>Masamizu</surname><given-names>Y</given-names></name><name><surname>Watakabe</surname><given-names>A</given-names></name><name><surname>Terada</surname><given-names>S</given-names></name><name><surname>Ohtsuka</surname><given-names>M</given-names></name><name><surname>Takaji</surname><given-names>M</given-names></name><name><surname>Mizukami</surname><given-names>H</given-names></name><name><surname>Ozawa</surname><given-names>K</given-names></name><name><surname>Kawasaki</surname><given-names>H</given-names></name><name><surname>Matsuzaki</surname><given-names>M</given-names></name><name><surname>Yamamori</surname><given-names>T</given-names></name></person-group><article-title>Long-Term Two-Photon Calcium Imaging of Neuronal Populations with Subcellular Resolution in Adult Non-human Primates</article-title><source>Cell Rep</source><year>2015</year><volume>13</volume><fpage>1989</fpage><lpage>1999</lpage><pub-id pub-id-type="pmid">26655910</pub-id></element-citation></ref><ref id="R56"><label>56</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pnevmatikakis</surname><given-names>EA</given-names></name><name><surname>Giovannucci</surname><given-names>A</given-names></name></person-group><article-title>NoRMCorre: An online algorithm for piecewise rigid motion correction of calcium imaging data</article-title><source>J Neurosci Methods</source><year>2017</year><volume>291</volume><fpage>83</fpage><lpage>94</lpage><pub-id pub-id-type="pmid">28782629</pub-id></element-citation></ref><ref id="R57"><label>57</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Stringer</surname><given-names>C</given-names></name><name><surname>Dipoppa</surname><given-names>M</given-names></name><name><surname>Schröder</surname><given-names>S</given-names></name><name><surname>Rossi</surname><given-names>LF</given-names></name><name><surname>Dalgleish</surname><given-names>H</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><article-title>Suite2p: beyond 10,000 neurons with standard two-photon microscopy</article-title><year>2017</year><pub-id pub-id-type="doi">10.1101/061507</pub-id></element-citation></ref><ref id="R58"><label>58</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Osorio</surname><given-names>S</given-names></name><name><surname>Irani</surname><given-names>M</given-names></name><name><surname>Herrada</surname><given-names>J</given-names></name><name><surname>Aboitiz</surname><given-names>F</given-names></name></person-group><article-title>Neural responses to sensory novelty with and without conscious access</article-title><source>Neuroimage</source><year>2022</year><volume>262</volume><elocation-id>119516</elocation-id><pub-id pub-id-type="pmid">35931308</pub-id></element-citation></ref><ref id="R59"><label>59</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hattori</surname><given-names>R</given-names></name><name><surname>Danskin</surname><given-names>B</given-names></name><name><surname>Babic</surname><given-names>Z</given-names></name><name><surname>Mlynaryk</surname><given-names>N</given-names></name><name><surname>Komiyama</surname><given-names>T</given-names></name></person-group><article-title>Area-Specificity and Plasticity of History-Dependent Value Coding During Learning</article-title><source>Cell</source><year>2019</year><volume>177</volume><fpage>1858</fpage><lpage>1872</lpage><elocation-id>e1815</elocation-id><pub-id pub-id-type="doi">10.1016/j.cell.2019.04.027</pub-id></element-citation></ref><ref id="R60"><label>60</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stuber</surname><given-names>GD</given-names></name><name><surname>Steinmetz</surname><given-names>NA</given-names></name><name><surname>Bowen</surname><given-names>AJ</given-names></name><name><surname>Hjort</surname><given-names>MM</given-names></name><name><surname>Ottenheimer</surname><given-names>DJ</given-names></name></person-group><article-title>A stable, distributed code for cue value in mouse cortex during reward learning</article-title><source>eLife</source><year>2023</year><volume>12</volume><pub-id pub-id-type="doi">10.7554/eLife.84604.3</pub-id></element-citation></ref><ref id="R61"><label>61</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xie</surname><given-names>Y</given-names></name><name><surname>Hu</surname><given-names>P</given-names></name><name><surname>Li</surname><given-names>J</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Song</surname><given-names>W</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name><name><surname>Yang</surname><given-names>T</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Tang</surname><given-names>S</given-names></name><name><surname>Min</surname><given-names>B</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name></person-group><article-title>Geometry of sequence working memory in macaque prefrontal cortex</article-title><source>Science</source><year>2022</year><volume>375</volume><fpage>632</fpage><lpage>639</lpage><pub-id pub-id-type="doi">10.1126/science.abm0204</pub-id></element-citation></ref><ref id="R62"><label>62</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tian</surname><given-names>Z</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>C</given-names></name><name><surname>Min</surname><given-names>B</given-names></name><name><surname>Xu</surname><given-names>B</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name></person-group><article-title>Mental programming of spatial sequences in working memory in the macaque frontal cortex</article-title><source>Science</source><year>2024</year><volume>385</volume><elocation-id>eadp6091</elocation-id><pub-id pub-id-type="doi">10.1126/science.adp6091</pub-id></element-citation></ref><ref id="R63"><label>63</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>Y</given-names></name><name><surname>Nitz</surname><given-names>DA</given-names></name><name><surname>Xu</surname><given-names>X</given-names></name><name><surname>Giocomo</surname><given-names>LM</given-names></name></person-group><article-title>Subicular neurons encode concave and convex geometries</article-title><source>Nature</source><year>2024</year><volume>627</volume><fpage>821</fpage><lpage>829</lpage><pub-id pub-id-type="doi">10.1038/s41586-024-07139-z</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Fig. 1</label><caption><title>Task design, behavior, and two-photon calcium imaging.</title><p><bold>(A)</bold> Schematic of a delayed-sequence reproduction meta-WM task. Monkeys initiate a trial by fixating at the central cross for 1.1s (denoted as “baseline” period). On each trial, a sequence containing 1, 2, 3, or 4 items is presented sequentially in a clockwise order (from location 1 to 6) on the display (“sample” period). After a 1.5-1.7s delay period, in 65% of (choice) trials, the monkeys can freely choose either to perform the retrieval task (“memory” condition, with a large reward if correct, green square) or opt out of retrieval (“offload” condition, with a small reward if correct, red triangle). In the remaining 35% of trials, the monkeys are forced to perform the task (“forced-to-test” condition). The chosen options appear randomly on either the left or right side of the screen across trials. Monkeys were required to saccade to the items that did not appear during the sample period in a clockwise order, thereby minimizing the possibility of motor preparation for the stimuli during the delay.</p><p><bold>(B)</bold> Behavioral accuracy of the three conditions for different sequence lengths in both monkeys. Accuracy denotes the fraction of correct responses in each condition. Error bars represent SEMs across sessions. ***: p &lt; 0.001 (two-sample t-test for each length).</p><p><bold>(C)</bold> Calculation of recall variability for monkey D. The stimuli-to-response matrix in the forced-to-test condition (left) includes both correct trials (diagonal) and error trials (non-diagonal). Each element of the matrix denotes the probability for monkey D to execute one particular sequence given a stimulus sequence. Recall variability is defined as the normalized entropy of response sequence probabilities given a stimulus sequence. Of the two example sequences [1-3] and [2-5-6] shown here (inset to the upper right), for monkey D, the former has low variability (concentrated probabilities), and the latter has high variability (widely distributed probabilities).</p><p><bold>(D)</bold> Pearson correlations between the behavioral accuracy (from the forced-to-test condition) and the offloading rate (from the choice condition) across all sequences for both monkeys. Offloading rate denotes the probability of choosing offload in choice trials. Each dot represents a sequence, and the dot size represents sequence lengths (larger = longer). 1 sequence: one sequence.</p><p><bold>(E)</bold> Pearson correlations between the recall variability (computed as in (C), from forced-to-test condition) and the offloading rate (from choice condition) across all sequences for both monkeys.</p><p><bold>(F)</bold> Two-photon calcium imaging setup. Each monkey has an image recording window over the LPFC with both the arcuate sulcus (AS) and the principal sulcus (PS) in view. Normalized calcium traces for three example neurons (orange circles) in one representative FOV (red square) are shown in the rightmost panel. Vertical red lines indicate the start of each trial. ΔF/F: normalized fluorescent intensity.</p><p>(<bold>G-I</bold>), Three example neurons in (F). Each shows tuning to a single location (G); multiple locations ((H); [1], [2], [6]; and sequences only containing those locations, [1-2], [1-6], [2-6], [1-2-6]); or meta-WM decisions (I), respectively. Each panel contains both stacked single trial ΔF/F traces (top) and averaged traces (bottom). “LastT” labels on horizontal axes mark the onset times of the last target stimulus. Shaded areas around average traces represent SEMs across trials.</p></caption><graphic xlink:href="EMS207446-f001"/></fig><fig id="F2" position="float"><label>Fig. 2</label><caption><title>Joint representation of WM content and its strength in the LPFC neural population.</title><p><bold>(A)</bold> Schematic illustration of a population decoder that represents both WM content (locations) and WM strength. We used the decoded location probability distribution to compute the decoded probability of each sequence (e.g., [3-5]) with multiple items. This was achieved through a joint probability approach, which involved calculating the product of all possible locations’ probabilities. Neural decoder-based WM strength was defined and computed as the inverted normalized entropy of the distribution of decoded probabilities of all sequences ([3-5], [3-4], [3], [5], etc.; see <xref ref-type="sec" rid="S13">Methods</xref> subsection “Neural decoder-based WM strength”).</p><p><bold>(B)</bold> Location probability distributions based on an example neural population decoder (monkey D, FOV 8), representing, for each sequence in the forced-to-test condition, the decoded probabilities of each location. The missing columns correspond to sequences that lacked correct trials during the session. For similar analysis using all data across FOVs, see <xref ref-type="supplementary-material" rid="SD1">Figs. S3 and S5A</xref>.</p><p><bold>(C)</bold> Behavioral location probability distributions (monkey D), representing, for each sequence in the forced-to-test condition, the response probabilities of each location based on task performance.</p><p><bold>(D)</bold> Histogram of Pearson correlation between location probability distributions, given a same stimulus sequence, of neural population decoder (B) and behavior (C) (***: p &lt; 0.001, two-tailed t-test against correlation value by chance). Gray dashed line, chance level.</p><p><bold>(E)</bold> Pearson correlations between the behavioral recall variability and the neural WM strength (both from forced-to-test conditions, including correct and error trials) across all sequences for both monkeys (monkey D FOV 8 &amp; monkey Z FOV 9 are shown here; see <xref ref-type="supplementary-material" rid="SD1">Fig. S5B</xref> for other FOVs). Each dot represents one sequence.</p><p><bold>(F)</bold> (Left) Time courses of neural WM strength across all trials within an example sequence [3-4] (sorted by WM strength descending, separately for correct/error trials), involving trials in the forced-to-test and the memory conditions. (Right) Comparison of neural WM strength under correct/error trials within the example sequence [3-4] (***: p &lt; 0.001, two-tailed two-sample t-test). Each dot represents a single trial.</p><p><bold>(G)</bold> Within-sequence comparison of neural WM strength between error trials and correct trials of all sequences (***: p &lt; 0.001, two-tailed paired-sample t-test, from monkey D FOV 8 &amp; monkey Z FOV 9), using forced-to-test and memory (correct + error) trials. Each dot represents a sequence and the red lines represent the mean across sequences.</p></caption><graphic xlink:href="EMS207446-f002"/></fig><fig id="F3" position="float"><label>Fig. 3</label><caption><title>Representation of meta-WM judgements in the LPFC neural population.</title><p>(<bold>A-B</bold>) An example meta-WM neuron, which is selective to meta-WM decisions as well as offloading rate. (A) Selectivity of meta-WM decisions. (B) (Left) Time courses of activity during the delay period, sorted by the offloading rate associated with each sequence. (Right) Linear regression between offloading rates and the delay-averaged neuron activity. Each dot represents one sequence.</p><p><bold>(C)</bold> Schematic illustration of a meta-WM neural decoder, which evaluates meta-WM scores for individual trials by decoding the probability of choosing the memory option in each trial, subsequently making decisions.</p><p>(<bold>D-G</bold>), Results of the meta-WM decoder from FOV 8 of monkey D and FOV 9 of monkey Z, using choice (memory + offload) trials.</p><p><bold>(D)</bold> Probability density functions (Pdfs) of the estimated meta-WM scores for all memory trials and all offload trials for both monkeys. Black solid lines represent decision boundaries of the meta-WM decoder.</p><p><bold>(E)</bold> The meta-WM decoder’s performance was evaluated using the area under receiver operating characteristic (AUROC) curve. The “95%” represents 95th percentile of the AUROC computed from trial label-shuffled decoders as control.</p><p><bold>(F)</bold> Pearson correlations between the offloading rate and the estimated meta-WM scores across all sequences for both monkeys. Each dot represents a sequence.</p><p><bold>(G)</bold> Within-sequence comparison of meta-WM scores between the offload and the memory trials of all sequences (***: p &lt; 0.001, two-tailed paired-sample t-tests). Each dot represents a sequence, and red lines represent the means across sequences.</p></caption><graphic xlink:href="EMS207446-f003"/></fig><fig id="F4" position="float"><label>Fig. 4</label><caption><title>Relationship between WM vs. Meta-WM judgment.</title><p>(<bold>A-B</bold>) An example neuron with mixed selectivity for both location WM and meta-WM. (A) Single trials (top) and averaged (bottom) neuronal activity grouped by trials with different locations. Linear regression between 6 locations and neuron activity resulted in r<sup>2</sup> = 0.279, p &lt; 0.001. (B) The same neuron in (A). (Left) Single trials (top) and averaged (bottom) neuron activity of memory and offload decisions. (Middle) Neuronal activity in different sequences sorted by offloading rates. (Right) Linear regression between offloading rates and neuronal activity. Shaded areas represent SEMs. Each dot represents one sequence.</p><p><bold>(C)</bold> Neuronal tuning strength (2-norm of beta coefficients of linear regression; see <xref ref-type="sec" rid="S13">Methods</xref> subsection “WM &amp; Meta-WM selectivity of each neuron”) for WM (location memory) and for meta-WM of all neurons and the corresponding Venn diagram of selective neurons from monkeys D (left) and Z (right). Each dot represents one neuron.</p><p>(<bold>D-H</bold>) Results from an example FOV (FOV 8 of monkey D) using choice (memory + offload) trials. For data covering all FOVs &amp; both monkeys, see <xref ref-type="supplementary-material" rid="SD1">Fig. S10</xref>.</p><p><bold>(D)</bold> Decoding timecourses of WM and meta-WM. Latency of WM (after ‘LastT’, the onset time of last target stimulus): mean = 0 ms, std &lt; 0.001 ms. Latency of meta-WM: mean = 212.287 ms, std = 102.367 ms. Shaded areas are significant time periods, compared with the baseline period (single-tailed one-sample t-test, p &lt; 0.01).</p><p><bold>(E)</bold> Pearson correlation between WM strength and meta-WM across individual trials. Each dot represents one trial.</p><p><bold>(F)</bold> Pearson correlation between WM strength and meta-WM of trials within each sequence, compared with chance level of 0 (two-tailed one-sample t-test). Each dot represents one sequence.</p><p><bold>(G)</bold> (Top) Memory-error trials are categorized into four groups according to high or low levels of WM strength and meta-WM, determined by median values of all choice condition trials. Among error trials, 24% exhibited high WM strength and high meta-WM, including 20% match trials (where the decoding probability of response locations was the highest among all sequences) and 4% others. Meanwhile, 29% showed a mismatch with low WM strength and high meta-WM. (Bottom) Two example memory-error trials with the sequence of stimuli [3-5] and response [3-4] illustrate match and mismatch. The high-strength match trial had concentrated probabilities responding as sequence [3-4], while the low-strength mismatch trial had widely distributed probabilities across many response sequences.</p><p><bold>(H)</bold> Test of trial proportion validity for low-strength mismatch trials in memory-error trials. Black line represents real data. Gray dashed line represents 99th percentile of a shuffle distribution. In each resampling iteration, trials were randomly sampled from all choice trials to evaluate the probability that the observed proportion of low-strength mismatch trials arose by chance or from random noise.</p></caption><graphic xlink:href="EMS207446-f004"/></fig><fig id="F5" position="float"><label>Fig. 5</label><caption><title>Neural activities during baseline predict meta-WM judgment.</title><p><bold>(A)</bold> Time course of pupil sizes under memory trials and offload trials, and comparison between them during the baseline period (yellow areas), taking length 2 trials as an example (***: p &lt; 0.001, two-tailed t-test). Shaded areas around time course lines represent SEM across sessions.</p><p><bold>(B)</bold> Comparison between baseline-averaged pupil sizes of the memory trials and those of the offload trials (***: p &lt; 0.001, two-tailed t-test), including trials from all lengths.</p><p><bold>(C)</bold> The distribution of trial history weight (see <xref ref-type="sec" rid="S13">Methods</xref> subsection “Trial history”). Each dot represents fitted weight from one recording session. Stars represent the significant weights with p &lt; 0.05, compared with chance level of 0.1 (two-tailed t-test).</p><p><bold>(D)</bold> An example neuron exhibiting decision selectivity during the baseline period. (Left) Single trials (top) and averaged (bottom) neuron activity of memory and offload decisions. Shaded areas represent SEMs across trials.</p><p><bold>(E)</bold> Performance of the baseline meta-WM decoder. (Left) AUROC was 0.622, and 95th percentile of the shuffle distribution of AUROC was 0.534. (Right) Pearson correlation between offloading rates and sequence-averaged baseline meta-WM. Each dot represents one sequence. For (E-I), data from choice trials of the FOV 8 (monkey D).</p><p><bold>(F)</bold> Prior (baseline meta-WM) linear regression, using coefficients of pupil size and history reward. Both coefficients and their interaction term significantly impacted baseline meta (two-tailed t-tests). Each dot represents a coefficient from a random resampling-based regression model, with red lines representing mean values. ***: p &lt; 0.001.</p><p><bold>(G)</bold> Meta-WM linear regression, using coefficients of baseline and WM strength. While both baseline meta-WM and WM strength (measured during the delay) are positively impacted meta-WM (single-tailed one-sample t-tests), WM strength was a strong predictor of meta-WM overall (two-tailed paired-sample t-tests between coefficients). Each dot represents a coefficient from a random resampling-based regression model, with red lines representing mean values. ***: p &lt; 0.001.</p><p><bold>(H)</bold> Comparison of Akaike information criterion (AIC) in three meta-WM linear regression models (***: p &lt; 0.001, two-tailed t-test). Models with lower AIC are considered to have higher performance, as AIC incorporates a penalty for the number of parameters. The input factors were baseline meta-WM, WM strength, and both, respectively. Error bars represent STDs.</p><p><bold>(I)</bold> (Left) Comparison between the offload trials and the low-strength mismatch (subset of memory-error trials) trials in WM strength (left) and baseline meta-WM (right), and in the difference between WM strength and baseline meta-WM (bracket over left &amp; right panels). Each dot represents one trial. All statistical tests are two-tailed t-tests. NS: non-significant. **: p &lt; 0.01.</p></caption><graphic xlink:href="EMS207446-f005"/></fig><fig id="F6" position="float"><label>Fig. 6</label><caption><title>Three task variables in the PFC.</title><p><bold>(A)</bold> Venn diagram showing selective neurons from both monkeys related to WM (location memory), meta-WM, and baseline meta (prior), respectively.</p><p><bold>(B)</bold> Schematic of subspaces of baseline meta-WM, WM strength, and meta-WM in neuronal state space. For example, the meta-WM subspace represents an axis derived from the meta-WM decoder that captures meta-WM scores across trials, forming a vector within the neuronal state space (see <xref ref-type="sec" rid="S13">Methods</xref> subsection “Subspace estimation and principal angles between subspaces”). BSL: Baseline.</p><p><bold>(C)</bold> Principal angles between different subspaces in (B). As a control, we randomly split trials in half to obtain two separate estimations of each subspace and computed their angle. deg: degree. Each FOV was individually analyzed; error bars represent SEM across FOVs.</p><p><bold>(D)</bold> Variance accounted for (VAF) ratio between different subspaces (see <xref ref-type="sec" rid="S13">Methods</xref> subsection “VAF ratio between subspaces”). Each FOV was individually analyzed; error bars represent SEM across FOVs.</p><p><bold>(E)</bold> Time courses of AUROC to differentiate between memory and offload trials within the baseline meta subspace and the meta-WM subspace, as well as between low-strength and high-strength trials within the WM strength subspace. Shaded areas in the WM strength and meta-WM subspaces indicate significant time periods, compared to the baseline period (single-tailed one-sample t-test, p &lt; 0.01).</p><p>(<bold>F-G</bold>) (F) Spatial organization of selective neurons for baseline meta, WM, and meta-WM (from FOV 4 of monkey D; 66, 120, 108 neurons, respectively). Each dot represents a neuron. In the merged panel (G), crosses represent spatial centroids.</p><p><bold>(H)</bold> Comparison of spatial distances within groups and between groups (two-tailed t-test; FOV 4 of monkey D). Each gray dot represents the average spatial distance between one neuron and others within the same group in (F). The black bar represents a calculation similar to that of the gray dots, but specifically for results between different groups, and it shows the median value among neurons. NS: non-significant.</p><p><bold>(I)</bold> Illustration of sequential mapping from WM strength to meta-WM and prior integration effect. In the PFC neural state space, the baseline signal influences neural states along the meta-WM judgment axis. With incoming external WM signals, these states shift sequentially along the judgment axis, owing to sequence-specific features (e.g., length) and additional, sequence-independent processes. The linear integration of baseline and WM signals’ projections onto this axis results in the final meta-WM decision controlling behavior.</p></caption><graphic xlink:href="EMS207446-f006"/></fig></floats-group></article>