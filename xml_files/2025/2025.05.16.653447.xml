<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS205714</article-id><article-id pub-id-type="doi">10.1101/2025.05.16.653447</article-id><article-id pub-id-type="archive">PPR1022913</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">2</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Towards foundation models that learn across biological scales</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Kalfon</surname><given-names>Jeremie</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Cantini</surname><given-names>Laura</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Peyre</surname><given-names>Gabriel</given-names></name><xref ref-type="aff" rid="A2">2</xref></contrib></contrib-group><aff id="A1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02feahw73</institution-id><institution>CNRS</institution></institution-wrap> UMR 3738, Machine Learning for Integrative Genomics group Institut Pasteur, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/05f82e368</institution-id><institution>Université Paris Cité</institution></institution-wrap>, <city>Paris</city>, <country country="FR">France</country></aff><aff id="A2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02feahw73</institution-id><institution>CNRS</institution></institution-wrap> and DMA de l’Ecole Normale Supérieure, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/02feahw73</institution-id><institution>CNRS</institution></institution-wrap>, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/05a0dhs15</institution-id><institution>Ecole Normale Supérieure</institution></institution-wrap>, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/013cjyk83</institution-id><institution>Université PSL</institution></institution-wrap>, <city>Paris</city>, <postal-code>75005</postal-code><country country="FR">France</country></aff><author-notes><corresp id="CR1">Correspondence to: Jeremie Kalfon &lt;<email>jeremie.kalfon@pasteur.fr</email>&gt;.</corresp></author-notes><pub-date pub-type="nihms-submitted"><day>21</day><month>05</month><year>2025</year></pub-date><pub-date pub-type="preprint"><day>18</day><month>05</month><year>2025</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">We have reached a point where many bio foundation models exist across 4 different scales, from molecules to molecular chains, cells, and tissues. However, while related in many ways, these models do not yet bridge these scales. We present a framework and architecture called Xpressor that enables cross-scale learning by (1) using a novel cross-attention mechanism to compress high-dimensional gene representations into lower-dimensional cell-state vectors, and (2) implementing a multi-scale fine-tuning approach that allows cell models to leverage and adapt protein-level representations. Using a cell Foundation Model as an example, we demonstrate that our architecture improves model performance across multiple tasks, including cell-type prediction (+12%) and embedding quality (+8%). Together, these advances represent first steps toward models that can understand and bridge different scales of biological organization.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><label>1</label><title>Introduction</title><p id="P2">Biology processes information across different scales, from individual molecules to entire tissues. Recent advances in artificial intelligence have led to the development of foundation models that excel at representing biological data at specific scales, such as protein structures (<xref ref-type="bibr" rid="R40">Rao et al., 2020</xref>) or cell states (<xref ref-type="bibr" rid="R24">Kalfon et al., 2024</xref>; <xref ref-type="bibr" rid="R14">Cui et al., 2024</xref>). However, these models typically operate in isolation, unable to leverage the rich interconnections between different biological scales. Having models that can learn across biological scales will be crucial to capture the complexity of the biological phenomena.</p><p id="P3">The main premise of our work is that by using information gained from a lower scale (e.g., molecules), we might improve the input representations of an higher scale phenomena (e.g., cells) (<xref ref-type="bibr" rid="R10">Bunne et al., 2024</xref>; Song et al.). Reciprocally, using relationships learned at the higher scale, we might improve the lower-scale models too. Finally, we would want to use joint representations of molecules, DNA, proteins, cells, and tissues, which are all the elements of the organisms we want to study.</p><p id="P4">While it is likely infeasible to learn across all scales at once, we might be able to use foundation models that have been trained at specific scales, which we call uniscale models, using only fine-tuning and some architectural changes (see <xref ref-type="fig" rid="F1">Figure 1</xref>). We first review the existing uniscale foundation models in depth for each of the four main biological modalities (<xref ref-type="bibr" rid="R46">Si et al., 2024</xref>).</p><sec id="S2"><label>1.1</label><title>Foundation models across scales</title><p id="P5"><bold>Molecular foundation models (mFM)</bold> try to model with atomistic precision the complex quantum physics-based rules that govern molecules and their interactions (<xref ref-type="bibr" rid="R1">Abramson et al., 2024</xref>). They generate embeddings of molecules by encoding their chemical representation, often using SMILES notation. These embeddings should contain information to predict molecular measurements such as binding to a target, potency, solubility, and more (<xref ref-type="bibr" rid="R33">Méndez-Lucio et al., 2024</xref>; <xref ref-type="bibr" rid="R44">Ross et al., 2022</xref>). The models are often built with invariances concerning the symmetries of molecules (relative positions and angles) (<xref ref-type="bibr" rid="R3">Batzner et al., 2022</xref>). These models can also be paired with ones that learn to predict the structure and dynamics of these molecules. Training data in this context is mostly limited by compute since molecular dynamics simulations can be generated at will (<xref ref-type="bibr" rid="R26">Kozinsky et al., 2023</xref>). The first use cases of such models are in material generation and drug discovery.</p><p id="P6">However, computing binding affinities and force-fields similar to the most precise molecular dynamics methods remains a frontier (<xref ref-type="bibr" rid="R4">Benali et al., 2025</xref>; <xref ref-type="bibr" rid="R42">Rhodes et al., 2025</xref>).</p><p id="P7"><bold>Nucleotide foundation models (nFM)</bold> are a category of models designed to analyze sequences of nucleotides or amino acids, which are encoded in triplets of nucleotides, primarily using data derived from sequencing across various life forms. Although new architectures have been introduced to handle large context sizes (<xref ref-type="bibr" rid="R35">Nguyen et al., 2023</xref>), most models generally rely on traditional transformer models with small context sizes and are trained with masking. These models are based on the transformer architecture and language model techniques (LM) (<xref ref-type="bibr" rid="R52">Vaswani et al., 2023</xref>) to produce representations of the lengthy and repetitive molecular structures found in DNA and RNA, sometimes termed dnaLM and rnaLM (<xref ref-type="bibr" rid="R15">Dalla-Torre et al., 2024</xref>; <xref ref-type="bibr" rid="R53">Wang et al., 2024a</xref>; <xref ref-type="bibr" rid="R17">Fradkin et al., 2024</xref>; <xref ref-type="bibr" rid="R9">Brixi et al., 2025</xref>).</p><p id="P8">While protein language models like ESM2 (<xref ref-type="bibr" rid="R40">Rao et al., 2020</xref>) have shown real-world usage in helping generate 3D models of proteins, dnaLM mainly focused on the task of understanding regulatory mechanisms, such as binding interactions and chemical modifications on DNA. It has been shown however, that representations learned by dnaLM can also contain information about the secondary structures of proteins and even protein-protein interactions (<xref ref-type="bibr" rid="R9">Brixi et al., 2025</xref>; <xref ref-type="bibr" rid="R13">Cornman et al., 2024</xref>).</p><p id="P9">For these reasons, we fold protein language models into the nFM category, proposing that their distinctions will blur in the future.</p><p id="P10">Numerous challenges still exist in accurately predicting the diverse conformations of RNA, DNA, and proteins, as well as in modeling their intricate interactions (<xref ref-type="bibr" rid="R1">Abramson et al., 2024</xref>). Indeed, it is still hard to measure complexes with the same accuracy as individual proteins. A goal would be to generate nFMs that learn across the very related lexicons, which are DNA, RNA, and proteins, by introducing architectures and training modalities that go beyond what exists today (<xref ref-type="bibr" rid="R57">Xia et al., 2025</xref>). Indeed, there we could use the framework of ”learning across scales” by using the representations of molecules, learned and compressed by mFMs, as the very tokens of nFMs, allowing them to talk about ribonucleotides, deoxyribonucleotides, amino acids, and their potential modifications.</p><p id="P11">Currently, the main applications of nFMs have been in drug, and target discovery, as well as many other fields of biology.</p><p id="P12"><bold>Cell foundation models (cFM)</bold> are a class of models trained on a matrix of abundances of the different chemical elements (proteins, RNAs) present in cells. (<xref ref-type="bibr" rid="R10">Bunne et al., 2024</xref>; <xref ref-type="bibr" rid="R24">Kalfon et al., 2024</xref>; <xref ref-type="bibr" rid="R49">Theodoris et al., 2023</xref>; <xref ref-type="bibr" rid="R14">Cui et al., 2024</xref>; <xref ref-type="bibr" rid="R19">Hao et al., 2024</xref>; <xref ref-type="bibr" rid="R43">Rosen et al., 2023</xref>). Their architecture is often based on bidirectional encoder-based transformers trained on single-cell RNA-sequencing data. While diverse training strategies have been presented, the model’s architectures have, for now, remained fairly classical. The goal of these cFMs is to generate an accurate model of the cell that would allow predictions of cell evolution and response to perturbations (<xref ref-type="bibr" rid="R25">Kedzierska et al., 2023</xref>).</p><p id="P13">However, immense challenges remain. Current promises have not stood up to experimental validations (<xref ref-type="bibr" rid="R5">Bendidi et al., 2024</xref>; <xref ref-type="bibr" rid="R7">Boiarsky et al., 2023</xref>). While many reasons can be formulated, issues exist around data quality, diversity, and coverage. Indeed, single-cell data is very noisy, only measures a tiny fraction of the molecular composition of cells, and has been mostly produced on human and model animals (<xref ref-type="bibr" rid="R39">Program et al., 2023</xref>). While data will remain an important challenge, an area of improvement would be to, again, distill the rules of molecular interactions from sequence learned at the sequence level onto cFMs. This allows them to better learn the complex regulatory mechanisms of the cell.</p><p id="P14"><bold>Tissue foundation models (tFM)</bold> strive to understand the interactions between cells that form tissues, mostly in higher-order organisms. Often based on imaging techniques, they consider the 2D structural relationship of cells or group of cells in a tissue slice. The stained microscopy slides allow the prediction of tissue type, organs, and even some protein expression levels. These models are often versions of the famous vision transformer architecture and framework (Dino V2), applied to medical images (<xref ref-type="bibr" rid="R37">Oquab et al., 2024</xref>; <xref ref-type="bibr" rid="R55">Wang et al., 2024c</xref>). They thus learn on image patches where each pixel has some channels of information (often from 2 to 30 different chemical elements are represented within these channels) (<xref ref-type="bibr" rid="R8">Bray et al., 2016</xref>; <xref ref-type="bibr" rid="R56">Wenckstern et al., 2025</xref>). The number of channels can go up to tens of thousands in spatial transcriptomics image modalities, where each channel represent a transcripts location at a subcellular level(e.g., xenium) or at a cell-group-level (e.g., visium).</p><p id="P15">Overall, even more challenges arise in tissue foundation models. Most of the data exists behind institutional barriers, the resolution of high channel count modalities is really poor, while the channel amount of high-resolution modalities is really small, making it hard to predict even the cell state. Slices are often of tiny subparts of tissues. Most of the available data is in 2D slides, and 3D modalities are still burgeoning (<xref ref-type="bibr" rid="R2">Alon et al., 2021</xref>). We lack good measurements of what cells are communicating, but we know that they do, from sequences to molecules and even entire organelles (<xref ref-type="bibr" rid="R20">Hertle et al., 2021</xref>). tFMs’ vocabulary can be seen as made of cells. Their tokens are cell representations and could be be the rich representations learned by cFMs. The goal of a tFM is then to predict the presence of cells given other cells in spatial context.</p></sec><sec id="S3"><label>1.2</label><title>Architectural modifications: compressed representations</title><p id="P16">For biological representations, previous methods have leveraged many different methods from matrix factorization, nearest neighbors, and neural networks (<xref ref-type="bibr" rid="R18">Gunawan et al., 2023</xref>; <xref ref-type="bibr" rid="R6">Bengio et al., 2014</xref>) amongst which popular approaches are Variational Autoencoder (VAE) such as scVI and scArches (<xref ref-type="bibr" rid="R29">Lopez et al., 2018</xref>; <xref ref-type="bibr" rid="R30">Lotfollahi et al., 2022</xref>). In the domain of protein embedding, the HourGlass embedding method (<xref ref-type="bibr" rid="R31">Lu et al., 2024</xref>) introduced FSQ (<xref ref-type="bibr" rid="R34">Mentzer et al., 2023</xref>) as a framework to encode both amino acid sequences and 3D structural information from a pLM into a quantized latent space. Meanwhile, DNA sequence model embeddings have been mostly restricted to metagenomics, with the exception of DNA-BERT-S (<xref ref-type="bibr" rid="R58">Zhou et al., 2024</xref>).</p><p id="P17">Finally, it has been shown not only in biology but also in the NLP community that for transformer models, embeddings based on average,max,sum-pooling of last-layer tokens are very restrictive and do not perform well (<xref ref-type="bibr" rid="R45">Schockaert, 2023</xref>; <xref ref-type="bibr" rid="R27">Lee et al., 2025</xref>; <xref ref-type="bibr" rid="R23">Ilse et al., 2018</xref>). Indeed, current state-of-the-art methods use more complex approaches such as cross-attention mechanism and additional pre-training or fine-tuning tasks.</p><p id="P18">In the following, we will show that we can use a similar cross-attention mechanisms to compress the output embeddings of a foundation model into a set of lower-dimensional vectors.</p></sec><sec id="S4"><label>1.3</label><title>Training modifications: fine-tuning</title><p id="P19">An extensive literature exists on fine-tuning. The simplest and most powerful approach remains to continue training on a small set of epochs and with a lower learning rate (<xref ref-type="bibr" rid="R11">Christophe et al., 2024</xref>). Common tools include low-rank approximations of the Multi-layer perception (MLP) and Query, Key, Values (QKV) matrices using LoRA, QLORA, and COLA (<xref ref-type="bibr" rid="R22">Hu et al., 2021</xref>; <xref ref-type="bibr" rid="R16">Dettmers et al., 2023</xref>; <xref ref-type="bibr" rid="R41">Ray et al., 2023</xref>; <xref ref-type="bibr" rid="R48">Tang et al., 2024</xref>), which allow cheap fine-tuning of large foundation models. Other common approaches also mostly revolve around reducing the memory footprint of fine-tuning by only back-propagating the loss across a specific subset of parameters, from updating only specific layers of the model, only the MLPs, the QKV matrices, or only the biases of the MLPs (<xref ref-type="bibr" rid="R38">Peters et al., 2019</xref>; <xref ref-type="bibr" rid="R12">Chronopoulou et al., 2019</xref>). Finally, adapter layers have also been used for their versatility. They often consist of an additional MLP on top of the large model’s output representations (<xref ref-type="bibr" rid="R21">Houlsby et al., 2019</xref>).</p><p id="P20">In the following, we will show that the adapter layer is a sensible approach to perform multi-scale fine-tuning.</p></sec><sec id="S5"><label>1.4</label><title>Contributions</title><p id="P21">Following up on these recent advances, we propose: <list list-type="bullet" id="L1"><list-item><p id="P22">A cross-attention ”compressor” block whose goal is to compress a foundation model’s output embeddings into a small set of low-dimensional vectors, called the <italic>Xpressor</italic> (Cross-Attention Compressor transformer). This is learnt using an auto-encoding approach with a reconstruction loss. The Xpressor is modality agnostic and can be used by mFMs, nFMs, cFMs, tFMs, or even other non-biological domains, and can work in addition to other training tasks like masking or denoising (see <xref ref-type="fig" rid="F2">Figure 2A</xref>).</p></list-item><list-item><p id="P23">A multi-scale fine-tuning approach using adapter layers. This allows the fine-tuning of models from one level using the upper-scale model’s task (see <xref ref-type="fig" rid="F2">Figure 2B</xref>).</p></list-item></list></p></sec></sec><sec id="S6"><label>2</label><title>Xpressor</title><sec id="S7" sec-type="intro"><label>2.1</label><title>Background</title><p id="P24">scPRINT (<xref ref-type="bibr" rid="R24">Kalfon et al., 2024</xref>) is a foundation model trained on more than 50 million unique single-cell RNA-seq profiles, representing around 100B tokens. It learns with a multi-task pre-training loss, allowing state-of-the-art zeroshot abilities in denoising and label prediction. scPRINT builds on previous foundation models, like scGPT (<xref ref-type="bibr" rid="R14">Cui et al., 2024</xref>) and scFoundation (<xref ref-type="bibr" rid="R19">Hao et al., 2024</xref>). It improves upon them on multiple benchmarks and is also easier to use and faster to train than many other similar models. Additionally, it comes with a gymnasium of benchmarks presented in <xref ref-type="bibr" rid="R24">Kalfon et al. (2024)</xref>. For these reasons, we chose to use it as our cFM and the starting point for our work.</p><p id="P25">ESM2 (<xref ref-type="bibr" rid="R40">Rao et al., 2020</xref>) is a protein language model that learns embeddings of amino acid sequences. It has been shown to be able to learn the evolutionary constraints of proteins and to be able to predict contact maps. Models like ESMfold (<xref ref-type="bibr" rid="R28">Lin et al., 2022</xref>) have been created to predict a protein’s 3D structure directly from its output embeddings. It is also simple to use. For these reasons, we chose to use it as our nFM.</p></sec><sec id="S8"><label>2.2</label><title>Approach</title><p id="P26">Our first contribution is the compression of output embeddings of foundation models using a transformer block and a bottleneck-learning training modality (see <xref ref-type="supplementary-material" rid="SD1">Supplementary Material 3.5</xref>): we call it the Xpressor (see <xref ref-type="fig" rid="F2">Figure 2A</xref>). Compression / decompression is a key mechanism to transfer representations across scales (see <xref ref-type="supplementary-material" rid="SD1">Supplementary Material 1.1</xref>), we thus models that can compress and decompress their input into a lower-dimensional space. To do so, we introduce an additional set of transformer blocks called ”Xpressor blocks”. In the context of scPRINT, these blocks represent cell features.</p><p id="P27">As inputs scPRINT continues to use a set of summed up gene expression and gene ID tokens. The first ones are generated using an MLP on each expression values of genes in a cell <italic>j</italic>, the other ones are generated from ESM2’s output embeddings of each gene sequenced aggregated with mean-pooling. The newly proposed Xpressor block uses as input a set of learned latent tokens <bold><italic>T</italic></bold>. It then performs cross-attention between the last layer of the gene embeddings and the latent tokens (see <xref ref-type="fig" rid="F2">Figure 2A</xref>). The goal is for the Xpressor blocks to be of smaller dimensions and context size than the main blocks, such that we end up with <bold><italic>C</italic></bold><sub><italic>j</italic></sub> a set of <italic>n</italic> tokens of dimension <italic>d</italic><sub><italic>t</italic></sub> generated from the encoded gene expression and ID matrices <bold><italic>E</italic></bold><sub><italic>j</italic></sub> and <bold><italic>G</italic></bold>. Where <bold><italic>G</italic></bold> and <bold><italic>E</italic></bold><sub><italic>j</italic></sub> are sets of <italic>m</italic> tokens of size <italic>d</italic><sub><italic>c</italic></sub> representing the IDs of the genes and their corresponding expression in cell <italic>j</italic>, respectively, where <italic>d</italic><sub><italic>c</italic></sub> &lt; <italic>d</italic><sub><italic>t</italic></sub> and <italic>n</italic> &lt;&lt; <italic>m</italic>: <disp-formula id="FD1"><mml:math id="M1"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mtext>Transformer</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>G</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mtext>Xpressor</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p id="P28">for a cell <italic>j</italic>, with the <italic>Xpressor</italic> being initialized with a learned set of input cell tokens, and <bold><italic>C</italic></bold><sub><italic>j</italic></sub> being the cell to-kens associated with the input <bold><italic>E</italic></bold> <sub><italic>j</italic></sub>.</p><p id="P29">The <italic>Transformer</italic> and <italic>Xpressor</italic> are both transformer with N and M layers, respectively. Indeed, we have designed both blocks to contain a cross-attention architecture (see <xref ref-type="fig" rid="F2">Figure 2C</xref>) such that we can also do: <inline-formula><mml:math id="M2"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>O</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mspace width="0.2em"/><mml:mtext>Transformer</mml:mtext><mml:mspace width="0.2em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, <bold><italic>G</italic></bold>), with <inline-formula><mml:math id="M3"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>O</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> being the output of the <italic>Transformer</italic> when using the <italic>Xpressor</italic> representation as input. We add an optional MLP after cross-attention to a transformation of the embeddings prior to the self-attention round. In our example, the decompression is done with gene ID tokens as input only (<bold><italic>G</italic></bold>) (see <xref ref-type="fig" rid="F2">Figure 2A</xref>). These tokens remain the same for all cells of a given species and thus do not depend on <italic>j</italic>. In the context of protein language models, for example, this would be replaced by positional tokens.</p><p id="P30">As can be seen in <xref ref-type="fig" rid="F2">Figure 2A</xref>, the <italic>Transformer</italic> blocks are applied twice. The first application act as an encoder, only using self attention, while the <italic>Xpressor</italic> and second application of the <italic>Transformer</italic> blocks act as decoders. We follow these definitions from the original ”Attention is All You Need” paper (<xref ref-type="bibr" rid="R52">Vaswani et al., 2023</xref>). It has to be noted that in our case cross-attention is performed first instead of last. Related ideas have also been explored in <xref ref-type="bibr" rid="R27">Lee et al. (2025)</xref>,where the authors propose a cross-attention-based method to update tokens using “latent” embeddings followed by a classical mean-pooling.</p><p id="P31">The goal of the <italic>Xpressor</italic> and the entire model can be seen as to perform compression of the gene tokens into a set of cell tokens similar to the classical information bottleneck from Tishby et al. (see <xref ref-type="supplementary-material" rid="SD1">Supplementary Material 3.5</xref>). This is our main training objective to train the <italic>Xpressor</italic> blocks, while the <italic>Transformer</italic> is also trained with masking.</p><p id="P32">In our case, each embedding represents different cell components. At training time, we present multiple losses to both regularize it and ensure differences across them, similar to what can be done in VAEs (see <xref ref-type="supplementary-material" rid="SD1">Supplementary Material 3.6</xref>).</p></sec><sec id="S9" sec-type="results"><label>2.3</label><title>Results</title><p id="P33">We show that such an instantiation of the transformer leads to better performance over the gymnasium of tasks available in the scPRINT cFM</p><p id="P34">Indeed, we now look at three specific tasks: cell-type prediction, embedding quality, and gene-network inference. The tasks are the same as presented in <xref ref-type="bibr" rid="R24">Kalfon et al. (2024)</xref>.</p><p id="P35">“Embedding quality” refers to the average scIB (<xref ref-type="bibr" rid="R32">Luecken et al., 2022</xref>) score for batch correction and biological consistency of cell embeddings. In this context scIB looks at the quality of the embeddings based on measures of similarity, nearest neighbors, and clustering.</p><p id="P36">Cell-label predictions are generated using a classifier on top of the cell embeddings generated by each model. We follow the approach of <xref ref-type="bibr" rid="R24">Kalfon et al. (2024)</xref> here, which was recently presented with a different mechanism in <xref ref-type="bibr" rid="R54">Wang et al. (2024b)</xref>. This classification task allows us to see how one can steer the model’s embeddings to represent meaningful biological features.</p><p id="P37">Finally, we display two different metrics for gene-network inference. The gene network inference benchmark tries to estimate the quality of the self-attention matrices based on similarity to a gene-gene ground-truth matrix. Here we use EPR, an odds-ratio measure where, e.g. a value of N means that the predictions are N-times as likely to be correct as a random guess. One is the EPR score on the genome-wide perturb-seq gene-network from BenGRN (<xref ref-type="bibr" rid="R24">Kalfon et al., 2024</xref>), while the second is the average EPR of multiple predicted gene-networks across various cell types compared to the BenGRN’s omnipath ground truth gene network (<xref ref-type="bibr" rid="R51">Türei et al., 2016</xref>).</p><p id="P38">In our comparison, the regular transformer’s class-pooling is done similarly to scGPT’s (<xref ref-type="bibr" rid="R14">Cui et al., 2024</xref>) approach, where a class token is added to the model’s input and an additional loss is placed on it:<inline-formula><mml:math id="M4"><mml:mrow><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:msubsup><mml:mi>G</mml:mi><mml:mi>j</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mo>|</mml:mo><mml:msub><mml:mo>|</mml:mo><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Both models use the same latent dimensions, architectures, training paradigm, and number of input tokens for both genes and cells.</p><p id="P39">We see that the Xpressor outperforms the simpler class-pooling approach on embedding quality and cell-label prediction, while the gene-network inference results remain roughly similar.</p><p id="P40">We will now see how we can further train -or fine-tune-these representations using information from the upper scale. While Xpressor layers with their small set of low-dimensional tokens are best suited for this task, we will focus on commonly available foundation models and architectures, presenting a general approach.</p></sec></sec><sec id="S10"><label>3</label><title>Multi-scale Fine-tuning</title><sec id="S11" sec-type="intro"><label>3.1</label><title>Background</title><p id="P41">To merge foundation models, we need a way to connect the lower-scale models to the upper one. It had been proposed in <xref ref-type="bibr" rid="R43">Rosen et al. (2023)</xref>; <xref ref-type="bibr" rid="R24">Kalfon et al. (2024)</xref> to use protein language model-based representations, like those of ESM2, as input tokens for the models. This decreases the number of parameters the model has to learn; It allows the model to work on genes unseen at training time; Moreover, it also lets the model use information that it would not have gained otherwise, such as protein structure, homology, and mutations.</p></sec><sec id="S12"><label>3.2</label><title>Approach</title><p id="P42">We propose going beyond simply reusing lower-scale models’ representations and fine-tuning them during the pre-training of the upper-scale model using an adapter layer (see <xref ref-type="fig" rid="F2">Figure 2B</xref>). With such layer, each output embedding <bold><italic>e</italic></bold> is transformed with a differentiable function <italic>f</italic> (here, an MLP): <disp-formula id="FD2"><mml:math id="M5"><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p id="P43">By using an MLP, the adapter layer not only applies a transformation of its input but also adds information (see <xref ref-type="supplementary-material" rid="SD1">Supplementary Material 3.4</xref>). In our case, we use ESM2 as the lower-scale model and scPRINT as the upper-scale model. The initial ESM2 embedding is known to contain a representation of the protein’s sequence, evolutionary similarity, and constraints.</p><p id="P44">Indeed, this is what allows this representation to replace the multiple sequence alignment (MSA) step in ESMfold (<xref ref-type="bibr" rid="R28">Lin et al., 2022</xref>). We posit that this initial embedding already contains the information necessary to understand some of the rules in gene interactions (homology and similar evolutionary constraints). However, representations from ESM2 are very different from those from single-cell foundation models. Our goal is to enrich these representations with knowledge gained from co-expression information across millions of cells.</p></sec><sec id="S13" sec-type="results"><label>3.3</label><title>Results</title><p id="P45">We show that a cFM trained using the pooled embeddings of a pretrained nFM performs better in most tasks from the <xref ref-type="bibr" rid="R24">Kalfon et al. (2024)</xref> gymnasium benchmark than one with learned representations (see <xref ref-type="table" rid="T2">Table 2</xref>). This is possible because we allow the model to start from a very rich representation instead of a random set of vectors, while still giving it the flexibility to incorporate additional knowledge. Each foundation model tested uses the same latent dimensions, architectures, training, and number of input tokens. We report the performance at the best epoch, and the training is stopped after 20 epochs.</p><p id="P46">We also show the difference in cell embeddings obtained between the regular transformer and the Xpressor (see <xref ref-type="fig" rid="F3">Figure 3</xref>). The dataset is a very challenging mix of modalities with various batch effects and amounts of noise. Cell types are also quite similar, making the task more difficult. We can see that the Xpressor embeddings contain more structure and resolve different cell types better than a transformer with class-pooling.</p><p id="P47">Using ESM2’s embeddings allows scPRINT to work on genes and sequences unseen at training time, to learn from an unlimited number of species, and to integrate DNA, RNA, and protein-level information such as mutations and structural variants.</p><p id="P48">Finally, contrary to other methods, this version does not require an update to the original model and can be added to the new model. Moreover, with this approach, scPRINT still maintains its ability to work on genes and sequences unseen at training time.</p></sec></sec><sec id="S14" sec-type="conclusions"><title>Conclusion</title><p id="P49">We have proposed a framework towards building compositional hierarchical foundation models for life, from atoms to tissues. We highlighted progress and challenges remaining for each specific scale of biological representations. While data generation efforts focusing on breadth and quality remain paramount to progress, we believe that the composition of foundation models could drive progress forward. Having a vocabulary for biological entities will allow us to better reference them, helping us define the impact of a molecule on a tissue or the interaction between RNA and proteins. Such a model of life should not be seen as one being trained end-to-end but as a set of models distilling the key information that they have learned and that the next one requires.</p><p id="P50">We have presented one small piece in this approach, where a cell foundation model (scPRINT) uses and fine-tunes a protein sequence foundation model (ESM2). We have also shown how XPressor can compress the output representations of transformers into a small set of lower-dimensional vectors, bridging proteins to cells. Such an approach could be used to bridge molecules to proteins and cells to tissues by using compressed representations that are then fine-tuned. This is a promising back-bone architecture for a general model going from atoms to tissues.</p><p id="P51">Future work should focus on using Xpressor’s representations to power upper scale models or the ability to learn a Xpressor on top of a pre-trained foundation model. The Xpressor approach could also be extended to decoder-based language models. Finally, fine-tuning using and adaptor layer suffers from a main drawback, the non-additivity of MLPs and therefore the limited use of such fine-tuned models in other contexts than for their compressed representations. Implementing intelligent GPU scheduling and using LoRA-type methods to fine-tune only XPressor blocks will allow for more complex fine-tuning in GPU-rich settings. We will need to show that this can be applied to the other scales of biological representations and generate benchmarks that better capture the diversity of real-world biological tasks across these scales.</p></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary</label><media xlink:href="EMS205714-supplement-Supplementary.pdf" mimetype="application" mime-subtype="pdf" id="d104aAcEbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S15"><title>Acknowledgments</title><p>The project leading to this manuscript has received funding from the Inception program (Investissement d’Avenir grant ANR-16-CONV-0005) L.C. and the European Union (ERC StG, MULTIview-CELL, 101115618) L.C. We acknowledge the help of the HPC Core Facility of the Institut Pasteur and Déborah Philipps for the administrative support. L.C.</p><p>The work of G. Peyré was supported by the French government under management of Agence Nationale de la Recherche as part of the ’Investissements d’avenir’ program, reference ANR19-P3IA-0001 (PRAIRIE 3IA Institute). G.P.</p></ack><fn-group><fn id="FN1"><p id="P52"><bold>Impact Statement</bold></p><p id="P53">This paper presents work whose goal is to advance the fields of computational biology and machine learning. No ethical issues are raised by the work other than what is typically noted in computational biology and foundation model papers. It might have an impact on building better models for drug discovery, target discovery, and improving our understanding of biological systems.</p></fn><fn id="FN2"><p id="P54"><bold>Software and Data</bold></p><p id="P55">The software and data for training scPRINT as well as gymnasium tasks and code to reproduce the results of the manuscript are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/cantinilab/XPressor">https://github.com/cantinilab/XPressor</ext-link>.</p><p id="P56">WandB logs, are available in the following link: <ext-link ext-link-type="uri" xlink:href="https://api.wandb.ai/links/ml4ig/h370j6io">https://api.wandb.ai/links/ml4ig/h370j6io</ext-link></p><p id="P57">Model checkpoints are available in the following link: <ext-link ext-link-type="uri" xlink:href="https://huggingface.co/jkobject/scPRINT/tree/main">https://huggingface.co/jkobject/scPRINT/tree/main</ext-link></p><p id="P58">Checkpoints, wandb logs, and more will be made available after the review and deanonymization process.</p></fn></fn-group><ref-list><ref id="R1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abramson</surname><given-names>J</given-names></name><name><surname>Adler</surname><given-names>J</given-names></name><name><surname>Dunger</surname><given-names>J</given-names></name><name><surname>Evans</surname><given-names>R</given-names></name><name><surname>Green</surname><given-names>T</given-names></name><name><surname>Pritzel</surname><given-names>A</given-names></name><name><surname>Ronneberger</surname><given-names>O</given-names></name><name><surname>Willmore</surname><given-names>L</given-names></name><name><surname>Ballard</surname><given-names>AJ</given-names></name><name><surname>Bambrick</surname><given-names>J</given-names></name><name><surname>Bodenstein</surname><given-names>SW</given-names></name><etal/></person-group><article-title>Accurate structure prediction of biomolecular interactions with AlphaFold 3</article-title><source>Nature</source><year>2024</year><month>June</month><volume>630</volume><issue>8016</issue><fpage>493</fpage><lpage>500</lpage><comment>ISSN 1476-4687</comment><pub-id pub-id-type="doi">10.1038/s41586-024-07487-w</pub-id><pub-id pub-id-type="pmcid">PMC11168924</pub-id><pub-id pub-id-type="pmid">38718835</pub-id></element-citation></ref><ref id="R2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alon</surname><given-names>S</given-names></name><name><surname>Goodwin</surname><given-names>DR</given-names></name><name><surname>Sinha</surname><given-names>A</given-names></name><name><surname>Wassie</surname><given-names>AT</given-names></name><name><surname>Chen</surname><given-names>F</given-names></name><name><surname>Daugharthy</surname><given-names>ER</given-names></name><name><surname>Bando</surname><given-names>Y</given-names></name><name><surname>Kajita</surname><given-names>A</given-names></name><name><surname>Xue</surname><given-names>AG</given-names></name><name><surname>Marrett</surname><given-names>K</given-names></name><name><surname>Prior</surname><given-names>R</given-names></name><etal/></person-group><article-title>Expansion sequencing: Spatially precise in situ transcriptomics in intact biological systems</article-title><source>Science</source><year>2021</year><month>January</month><volume>371</volume><issue>6528</issue><elocation-id>eaax2656</elocation-id><pub-id pub-id-type="doi">10.1126/science.aax2656</pub-id><pub-id pub-id-type="pmcid">PMC7900882</pub-id><pub-id pub-id-type="pmid">33509999</pub-id></element-citation></ref><ref id="R3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Batzner</surname><given-names>S</given-names></name><name><surname>Musaelian</surname><given-names>A</given-names></name><name><surname>Sun</surname><given-names>L</given-names></name><name><surname>Geiger</surname><given-names>M</given-names></name><name><surname>Mailoa</surname><given-names>JP</given-names></name><name><surname>Kornbluth</surname><given-names>M</given-names></name><name><surname>Molinari</surname><given-names>N</given-names></name><name><surname>Smidt</surname><given-names>TE</given-names></name><name><surname>Kozinsky</surname><given-names>B</given-names></name></person-group><article-title>E(3)-equivariant graph neural networks for data-efficient and accurate interatomic potentials</article-title><source>Nature Communications</source><year>2022</year><month>May</month><volume>13</volume><issue>1</issue><elocation-id>2453</elocation-id><comment>ISSN 2041-1723</comment><pub-id pub-id-type="doi">10.1038/s41467-022-29939-5</pub-id><pub-id pub-id-type="pmcid">PMC9068614</pub-id><pub-id pub-id-type="pmid">35508450</pub-id></element-citation></ref><ref id="R4"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Benali</surname><given-names>A</given-names></name><name><surname>Plé</surname><given-names>T</given-names></name><name><surname>Adjoua</surname><given-names>O</given-names></name><name><surname>Agarawal</surname><given-names>V</given-names></name><name><surname>Applencourt</surname><given-names>T</given-names></name><name><surname>Blazhynska</surname><given-names>MRC</given-names><suffix>III</suffix></name><name><surname>Gasperich</surname><given-names>K</given-names></name><name><surname>Hossain</surname><given-names>K</given-names></name><name><surname>Kim</surname><given-names>J</given-names></name><name><surname>Knight</surname><given-names>C</given-names></name><etal/></person-group><source>Pushing the accuracy limit of foundation neural network models with quantum monte carlo forces and path integrals</source><year>2025</year><comment>URL <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2504.07948">https://arxiv.org/abs/2504.07948</ext-link></comment></element-citation></ref><ref id="R5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bendidi</surname><given-names>I</given-names></name><name><surname>Whitfield</surname><given-names>S</given-names></name><name><surname>Kenyon-Dean</surname><given-names>K</given-names></name><name><surname>Yedder</surname><given-names>HB</given-names></name><name><surname>Mesbahi</surname><given-names>YE</given-names></name><name><surname>Noutahi</surname><given-names>E</given-names></name><name><surname>Denton</surname><given-names>AK</given-names></name></person-group><article-title>Benchmarking Transcriptomics Foundation Models for Perturbation Analysis : One PCA still rules them all</article-title><year>2024</year><month>November</month></element-citation></ref><ref id="R6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Courville</surname><given-names>A</given-names></name><name><surname>Vincent</surname><given-names>P</given-names></name></person-group><article-title>Representation Learning: A Review and New Perspectives</article-title><year>2014</year><month>April</month><pub-id pub-id-type="pmid">23787338</pub-id></element-citation></ref><ref id="R7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boiarsky</surname><given-names>R</given-names></name><name><surname>Singh</surname><given-names>N</given-names></name><name><surname>Buendia</surname><given-names>A</given-names></name><name><surname>Getz</surname><given-names>G</given-names></name><name><surname>Sontag</surname><given-names>D</given-names></name></person-group><article-title>A Deep Dive into Single-Cell RNA Sequencing Foundation Models</article-title><year>2023</year><month>October</month></element-citation></ref><ref id="R8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bray</surname><given-names>MA</given-names></name><name><surname>Singh</surname><given-names>S</given-names></name><name><surname>Han</surname><given-names>H</given-names></name><name><surname>Davis</surname><given-names>CT</given-names></name><name><surname>Borgeson</surname><given-names>B</given-names></name><name><surname>Hartland</surname><given-names>C</given-names></name><name><surname>Kost-Alimova</surname><given-names>M</given-names></name><name><surname>Gustafsdottir</surname><given-names>SM</given-names></name><name><surname>Gibson</surname><given-names>CC</given-names></name><name><surname>Carpenter</surname><given-names>AE</given-names></name></person-group><article-title>Cell Painting, a high-content image-based assay for morphological profiling using multiplexed fluorescent dyes</article-title><source>Nature Protocols</source><year>2016</year><month>September</month><volume>11</volume><issue>9</issue><fpage>1757</fpage><lpage>1774</lpage><comment>ISSN 1750-2799</comment><pub-id pub-id-type="doi">10.1038/nprot.2016.105</pub-id><pub-id pub-id-type="pmcid">PMC5223290</pub-id><pub-id pub-id-type="pmid">27560178</pub-id></element-citation></ref><ref id="R9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brixi</surname><given-names>G</given-names></name><name><surname>Durrant</surname><given-names>MG</given-names></name><name><surname>Ku</surname><given-names>J</given-names></name><name><surname>Poli</surname><given-names>M</given-names></name><name><surname>Brockman</surname><given-names>G</given-names></name><name><surname>Chang</surname><given-names>D</given-names></name><name><surname>Gonzalez</surname><given-names>GA</given-names></name><name><surname>King</surname><given-names>SH</given-names></name><name><surname>Li</surname><given-names>DB</given-names></name><name><surname>Merchant</surname><given-names>AT</given-names></name><name><surname>Naghipourfar</surname><given-names>M</given-names></name><etal/></person-group><article-title>Genome modeling and design across all domains of life with Evo 2</article-title><year>2025</year><month>February</month></element-citation></ref><ref id="R10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bunne</surname><given-names>C</given-names></name><name><surname>Roohani</surname><given-names>Y</given-names></name><name><surname>Rosen</surname><given-names>Y</given-names></name><name><surname>Gupta</surname><given-names>A</given-names></name><name><surname>Zhang</surname><given-names>X</given-names></name><name><surname>Roed</surname><given-names>M</given-names></name><name><surname>Alexandrov</surname><given-names>T</given-names></name><name><surname>AlQuraishi</surname><given-names>M</given-names></name><name><surname>Brennan</surname><given-names>P</given-names></name><name><surname>Burkhardt</surname><given-names>DB</given-names></name><name><surname>Califano</surname><given-names>A</given-names></name><etal/></person-group><article-title>How to build the virtual cell with artificial intelligence: Priorities and opportunities</article-title><source>Cell</source><year>2024</year><month>December</month><volume>187</volume><issue>25</issue><fpage>7045</fpage><lpage>7063</lpage><comment>ISSN 0092-8674, 1097-4172</comment><pub-id pub-id-type="doi">10.1016/j.cell.2024.11.015</pub-id><pub-id pub-id-type="pmcid">PMC12148494</pub-id><pub-id pub-id-type="pmid">39672099</pub-id></element-citation></ref><ref id="R11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christophe</surname><given-names>C</given-names></name><name><surname>Kanithi</surname><given-names>PK</given-names></name><name><surname>Munjal</surname><given-names>P</given-names></name><name><surname>Raha</surname><given-names>T</given-names></name><name><surname>Hayat</surname><given-names>N</given-names></name><name><surname>Rajan</surname><given-names>R</given-names></name><name><surname>Al-Mahrooqi</surname><given-names>A</given-names></name><name><surname>Gupta</surname><given-names>A</given-names></name><name><surname>Salman</surname><given-names>MU</given-names></name><name><surname>Gosal</surname><given-names>G</given-names></name><name><surname>Kanakiya</surname><given-names>B</given-names></name><etal/></person-group><article-title>Med42 – Evaluating Fine-Tuning Strategies for Medical LLMs: Full-Parameter vs. Parameter-Efficient Approaches</article-title><year>2024</year><month>April</month></element-citation></ref><ref id="R12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chronopoulou</surname><given-names>A</given-names></name><name><surname>Baziotis</surname><given-names>C</given-names></name><name><surname>Potamianos</surname><given-names>A</given-names></name></person-group><article-title>An Embarrassingly Simple Approach for Transfer Learning from Pretrained Language Models</article-title><year>2019</year><month>May</month></element-citation></ref><ref id="R13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cornman</surname><given-names>A</given-names></name><name><surname>West-Roberts</surname><given-names>J</given-names></name><name><surname>Camargo</surname><given-names>AP</given-names></name><name><surname>Roux</surname><given-names>S</given-names></name><name><surname>Beracochea</surname><given-names>M</given-names></name><name><surname>Mirdita</surname><given-names>M</given-names></name><name><surname>Ovchinnikov</surname><given-names>S</given-names></name><name><surname>Hwang</surname><given-names>Y</given-names></name></person-group><article-title>The OMG dataset: An Open MetaGenomic corpus for mixed-modality genomic language modeling</article-title><year>2024</year><month>August</month></element-citation></ref><ref id="R14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cui</surname><given-names>H</given-names></name><name><surname>Wang</surname><given-names>C</given-names></name><name><surname>Maan</surname><given-names>H</given-names></name><name><surname>Pang</surname><given-names>K</given-names></name><name><surname>Luo</surname><given-names>F</given-names></name><name><surname>Duan</surname><given-names>N</given-names></name><name><surname>Wang</surname><given-names>B</given-names></name></person-group><article-title>scGPT: Toward building a foundation model for single-cell multi-omics using generative AI</article-title><source>Nature Methods</source><year>2024</year><month>February</month><fpage>1</fpage><lpage>11</lpage><comment>ISSN 1548-7105</comment><pub-id pub-id-type="pmid">38409223</pub-id></element-citation></ref><ref id="R15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dalla-Torre</surname><given-names>H</given-names></name><name><surname>Gonzalez</surname><given-names>L</given-names></name><name><surname>Mendoza-Revilla</surname><given-names>J</given-names></name><name><surname>Carranza</surname><given-names>NL</given-names></name><name><surname>Grzywaczewski</surname><given-names>AH</given-names></name><name><surname>Oteri</surname><given-names>F</given-names></name><name><surname>Dallago</surname><given-names>C</given-names></name><name><surname>Trop</surname><given-names>E</given-names></name><name><surname>de Almeida</surname><given-names>BP</given-names></name><name><surname>Sirelkhatim</surname><given-names>H</given-names></name><name><surname>Richard</surname><given-names>G</given-names></name><etal/></person-group><article-title>The Nucleotide Transformer: Building and Evaluating Robust Foundation Models for Human Genomics</article-title><year>2024</year><month>October</month><pub-id pub-id-type="doi">10.1038/s41592-024-02523-z</pub-id><pub-id pub-id-type="pmcid">PMC11810778</pub-id><pub-id pub-id-type="pmid">39609566</pub-id></element-citation></ref><ref id="R16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dettmers</surname><given-names>T</given-names></name><name><surname>Pagnoni</surname><given-names>A</given-names></name><name><surname>Holtzman</surname><given-names>A</given-names></name><name><surname>Zettlemoyer</surname><given-names>L</given-names></name></person-group><article-title>QLoRA: Efficient Finetuning of Quantized LLMs</article-title><year>2023</year><month>May</month></element-citation></ref><ref id="R17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fradkin</surname><given-names>P</given-names></name><name><surname>Shi</surname><given-names>R</given-names></name><name><surname>Isaev</surname><given-names>K</given-names></name><name><surname>Frey</surname><given-names>BJ</given-names></name><name><surname>Morris</surname><given-names>Q</given-names></name><name><surname>Lee</surname><given-names>LJ</given-names></name><name><surname>Wang</surname><given-names>B</given-names></name></person-group><article-title>Orthrus: Towards Evolutionary and Functional RNA Foundation Models</article-title><year>2024</year><month>October</month></element-citation></ref><ref id="R18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gunawan</surname><given-names>I</given-names></name><name><surname>Vafaee</surname><given-names>F</given-names></name><name><surname>Meijering</surname><given-names>E</given-names></name><name><surname>Lock</surname><given-names>JG</given-names></name></person-group><article-title>An introduction to representation learning for single-cell data analysis</article-title><source>Cell Reports Methods</source><year>2023</year><month>August</month><volume>3</volume><issue>8</issue><elocation-id>100547</elocation-id><comment>ISSN 2667-2375</comment><pub-id pub-id-type="doi">10.1016/j.crmeth.2023.100547</pub-id><pub-id pub-id-type="pmcid">PMC10475795</pub-id><pub-id pub-id-type="pmid">37671013</pub-id></element-citation></ref><ref id="R19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hao</surname><given-names>M</given-names></name><name><surname>Gong</surname><given-names>J</given-names></name><name><surname>Zeng</surname><given-names>X</given-names></name><name><surname>Liu</surname><given-names>C</given-names></name><name><surname>Guo</surname><given-names>Y</given-names></name><name><surname>Cheng</surname><given-names>X</given-names></name><name><surname>Wang</surname><given-names>T</given-names></name><name><surname>Ma</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>X</given-names></name><name><surname>Song</surname><given-names>L</given-names></name></person-group><article-title>Large-scale foundation model on single-cell transcriptomics</article-title><source>Nature Methods</source><year>2024</year><month>June</month><fpage>1</fpage><lpage>11</lpage><comment>ISSN 1548-7105</comment><pub-id pub-id-type="pmid">38844628</pub-id></element-citation></ref><ref id="R20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hertle</surname><given-names>AP</given-names></name><name><surname>Haberl</surname><given-names>B</given-names></name><name><surname>Bock</surname><given-names>R</given-names></name></person-group><article-title>Horizontal genome transfer by cell-to-cell travel of whole organelles</article-title><source>Science Advances</source><year>2021</year><month>January</month><volume>7</volume><issue>1</issue><elocation-id>eabd8215</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.abd8215</pub-id><pub-id pub-id-type="pmcid">PMC7775762</pub-id><pub-id pub-id-type="pmid">33523859</pub-id></element-citation></ref><ref id="R21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Houlsby</surname><given-names>N</given-names></name><name><surname>Giurgiu</surname><given-names>A</given-names></name><name><surname>Jastrzebski</surname><given-names>S</given-names></name><name><surname>Morrone</surname><given-names>B</given-names></name><name><surname>de Laroussilhe</surname><given-names>Q</given-names></name><name><surname>Gesmundo</surname><given-names>A</given-names></name><name><surname>Attariyan</surname><given-names>M</given-names></name><name><surname>Gelly</surname><given-names>S</given-names></name></person-group><article-title>Parameter-Efficient Transfer Learning for NLP</article-title><year>2019</year><month>June</month></element-citation></ref><ref id="R22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hu</surname><given-names>EJ</given-names></name><name><surname>Shen</surname><given-names>Y</given-names></name><name><surname>Wallis</surname><given-names>P</given-names></name><name><surname>Allen-Zhu</surname><given-names>Z</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Chen</surname><given-names>W</given-names></name></person-group><article-title>LoRA: Low-Rank Adaptation of Large Language Models</article-title><year>2021</year><month>October</month></element-citation></ref><ref id="R23"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Ilse</surname><given-names>M</given-names></name><name><surname>Tomczak</surname><given-names>J</given-names></name><name><surname>Welling</surname><given-names>M</given-names></name></person-group><chapter-title>Attention-based Deep Multiple Instance Learning</chapter-title><source>Proceedings of the 35th International Conference on Machine Learning</source><conf-name>PMLR</conf-name><year>2018</year><month>July</month><fpage>2127</fpage><lpage>2136</lpage></element-citation></ref><ref id="R24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kalfon</surname><given-names>J</given-names></name><name><surname>Samaran</surname><given-names>J</given-names></name><name><surname>Peyré</surname><given-names>G</given-names></name><name><surname>Cantini</surname><given-names>L</given-names></name></person-group><article-title>scPRINT: Pre-training on 50 million cells allows robust gene network predictions</article-title><year>2024</year><month>July</month><pub-id pub-id-type="doi">10.1038/s41467-025-58699-1</pub-id><pub-id pub-id-type="pmcid">PMC12003772</pub-id><pub-id pub-id-type="pmid">40240364</pub-id></element-citation></ref><ref id="R25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kedzierska</surname><given-names>KZ</given-names></name><name><surname>Crawford</surname><given-names>L</given-names></name><name><surname>Amini</surname><given-names>AP</given-names></name><name><surname>Lu</surname><given-names>AX</given-names></name></person-group><article-title>Assessing the limits of zero-shot foundation models in single-cell biology</article-title><year>2023</year><month>October</month></element-citation></ref><ref id="R26"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kozinsky</surname><given-names>B</given-names></name><name><surname>Musaelian</surname><given-names>A</given-names></name><name><surname>Johansson</surname><given-names>A</given-names></name><name><surname>Batzner</surname><given-names>S</given-names></name></person-group><chapter-title>Scaling the Leading Accuracy of Deep Equivariant Models to Biomolecular Simulations of Realistic Size</chapter-title><source>Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, SC ‘23</source><conf-name>Association for Computing Machinery</conf-name><conf-loc>New York, NY, USA</conf-loc><year>2023</year><month>November</month><fpage>1</fpage><lpage>12</lpage><comment>ISBN 9798400701092</comment><pub-id pub-id-type="doi">10.1145/3581784.3627041</pub-id></element-citation></ref><ref id="R27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>C</given-names></name><name><surname>Roy</surname><given-names>R</given-names></name><name><surname>Xu</surname><given-names>M</given-names></name><name><surname>Raiman</surname><given-names>J</given-names></name><name><surname>Shoeybi</surname><given-names>M</given-names></name><name><surname>Catanzaro</surname><given-names>B</given-names></name><name><surname>Ping</surname><given-names>W</given-names></name></person-group><article-title>NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding Models</article-title><year>2025</year><month>January</month></element-citation></ref><ref id="R28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>Z</given-names></name><name><surname>Akin</surname><given-names>H</given-names></name><name><surname>Rao</surname><given-names>R</given-names></name><name><surname>Hie</surname><given-names>B</given-names></name><name><surname>Zhu</surname><given-names>Z</given-names></name><name><surname>Lu</surname><given-names>W</given-names></name><name><surname>Costa</surname><given-names>AdS</given-names></name><name><surname>Fazel-Zarandi</surname><given-names>M</given-names></name><name><surname>Sercu</surname><given-names>T</given-names></name><name><surname>Candido</surname><given-names>S</given-names></name><name><surname>Rives</surname><given-names>A</given-names></name></person-group><article-title>Language models of protein sequences at the scale of evolution enable accurate structure prediction</article-title><year>2022</year><month>July</month></element-citation></ref><ref id="R29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lopez</surname><given-names>R</given-names></name><name><surname>Regier</surname><given-names>J</given-names></name><name><surname>Cole</surname><given-names>MB</given-names></name><name><surname>Jordan</surname><given-names>MI</given-names></name><name><surname>Yosef</surname><given-names>N</given-names></name></person-group><article-title>Deep generative modeling for single-cell transcriptomics</article-title><source>Nature Methods</source><year>2018</year><month>December</month><volume>15</volume><issue>12</issue><fpage>1053</fpage><lpage>1058</lpage><comment>ISSN 1548-7105</comment><pub-id pub-id-type="doi">10.1038/s41592-018-0229-2</pub-id><pub-id pub-id-type="pmcid">PMC6289068</pub-id><pub-id pub-id-type="pmid">30504886</pub-id></element-citation></ref><ref id="R30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lotfollahi</surname><given-names>M</given-names></name><name><surname>Naghipourfar</surname><given-names>M</given-names></name><name><surname>Luecken</surname><given-names>MD</given-names></name><name><surname>Khajavi</surname><given-names>M</given-names></name><name><surname>Büttner</surname><given-names>M</given-names></name><name><surname>Wagenstetter</surname><given-names>M</given-names></name><name><surname>Avsec</surname><given-names>Ž</given-names></name><name><surname>Gayoso</surname><given-names>A</given-names></name><name><surname>Yosef</surname><given-names>N</given-names></name><name><surname>Interlandi</surname><given-names>M</given-names></name><name><surname>Rybakov</surname><given-names>S</given-names></name><etal/></person-group><article-title>Mapping single-cell data to reference atlases by transfer learning</article-title><source>Nature Biotechnology</source><year>2022</year><month>January</month><volume>40</volume><issue>1</issue><fpage>121</fpage><lpage>130</lpage><comment>ISSN 1546-1696</comment><pub-id pub-id-type="doi">10.1038/s41587-021-01001-7</pub-id><pub-id pub-id-type="pmcid">PMC8763644</pub-id><pub-id pub-id-type="pmid">34462589</pub-id></element-citation></ref><ref id="R31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>AX</given-names></name><name><surname>Yan</surname><given-names>W</given-names></name><name><surname>Yang</surname><given-names>KK</given-names></name><name><surname>Gligorijevic</surname><given-names>V</given-names></name><name><surname>Cho</surname><given-names>K</given-names></name><name><surname>Abbeel</surname><given-names>P</given-names></name><name><surname>Bonneau</surname><given-names>R</given-names></name><name><surname>Frey</surname><given-names>N</given-names></name></person-group><article-title>Tokenized and Continuous Embedding Compressions of Protein Sequence and Structure</article-title><year>2024</year><month>November</month><pub-id pub-id-type="doi">10.1016/j.patter.2025.101289</pub-id><pub-id pub-id-type="pmcid">PMC12191763</pub-id><pub-id pub-id-type="pmid">40575127</pub-id></element-citation></ref><ref id="R32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luecken</surname><given-names>MD</given-names></name><name><surname>Büttner</surname><given-names>M</given-names></name><name><surname>Chaichoompu</surname><given-names>K</given-names></name><name><surname>Danese</surname><given-names>A</given-names></name><name><surname>Interlandi</surname><given-names>M</given-names></name><name><surname>Mueller</surname><given-names>MF</given-names></name><name><surname>Strobl</surname><given-names>DC</given-names></name><name><surname>Zappia</surname><given-names>L</given-names></name><name><surname>Dugas</surname><given-names>M</given-names></name><name><surname>Colomé-Tatché</surname><given-names>M</given-names></name><name><surname>Theis</surname><given-names>FJ</given-names></name></person-group><article-title>Benchmarking atlas-level data integration in single-cell genomics</article-title><source>Nature Methods</source><year>2022</year><month>January</month><volume>19</volume><issue>1</issue><fpage>41</fpage><lpage>50</lpage><comment>ISSN 1548-7105</comment><pub-id pub-id-type="doi">10.1038/s41592-021-01336-8</pub-id><pub-id pub-id-type="pmcid">PMC8748196</pub-id><pub-id pub-id-type="pmid">34949812</pub-id></element-citation></ref><ref id="R33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Méndez-Lucio</surname><given-names>O</given-names></name><name><surname>Nicolaou</surname><given-names>CA</given-names></name><name><surname>Earnshaw</surname><given-names>B</given-names></name></person-group><article-title>MolE: A foundation model for molecular graphs using disentangled attention</article-title><source>Nature Communications</source><year>2024</year><month>November</month><volume>15</volume><issue>1</issue><elocation-id>9431</elocation-id><comment>ISSN 2041-1723</comment><pub-id pub-id-type="doi">10.1038/s41467-024-53751-y</pub-id><pub-id pub-id-type="pmcid">PMC11557931</pub-id><pub-id pub-id-type="pmid">39532853</pub-id></element-citation></ref><ref id="R34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mentzer</surname><given-names>F</given-names></name><name><surname>Minnen</surname><given-names>D</given-names></name><name><surname>Agustsson</surname><given-names>E</given-names></name><name><surname>Tschannen</surname><given-names>M</given-names></name></person-group><article-title>Finite Scalar Quantization: VQ-VAE Made Simple</article-title><year>2023</year><month>October</month></element-citation></ref><ref id="R35"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Nguyen</surname><given-names>E</given-names></name><name><surname>Poli</surname><given-names>M</given-names></name><name><surname>Faizi</surname><given-names>M</given-names></name><name><surname>Thomas</surname><given-names>A</given-names></name><name><surname>Birch-Sykes</surname><given-names>C</given-names></name><name><surname>Wornow</surname><given-names>M</given-names></name><name><surname>Patel</surname><given-names>A</given-names></name><name><surname>Rabideau</surname><given-names>C</given-names></name><name><surname>Massaroli</surname><given-names>S</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Ermon</surname><given-names>S</given-names></name><etal/></person-group><source>Hyenadna: Long-range genomic sequence modeling at single nucleotide resolution</source><year>2023</year><comment>URL <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2306.15794">https://arxiv.org/abs/2306.15794</ext-link></comment></element-citation></ref><ref id="R36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oord</surname><given-names>Avd</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Vinyals</surname><given-names>O</given-names></name></person-group><article-title>Representation Learning with Contrastive Predictive Coding</article-title><pub-id pub-id-type="pmid">37990998</pub-id></element-citation></ref><ref id="R37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oquab</surname><given-names>M</given-names></name><name><surname>Darcet</surname><given-names>T</given-names></name><name><surname>Moutakanni</surname><given-names>T</given-names></name><name><surname>Vo</surname><given-names>H</given-names></name><name><surname>Szafraniec</surname><given-names>M</given-names></name><name><surname>Khalidov</surname><given-names>V</given-names></name><name><surname>Fernandez</surname><given-names>P</given-names></name><name><surname>Haziza</surname><given-names>D</given-names></name><name><surname>Massa</surname><given-names>F</given-names></name><name><surname>El-Nouby</surname><given-names>A</given-names></name><name><surname>Assran</surname><given-names>M</given-names></name><etal/></person-group><article-title>DINOv2: Learning Robust Visual Features without Supervision</article-title><year>2024</year><month>February</month></element-citation></ref><ref id="R38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peters</surname><given-names>ME</given-names></name><name><surname>Ruder</surname><given-names>S</given-names></name><name><surname>Smith</surname><given-names>NA</given-names></name></person-group><article-title>To Tune or Not to Tune? Adapting Pretrained Representations to Diverse Tasks</article-title><year>2019</year><month>June</month></element-citation></ref><ref id="R39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Program</surname><given-names>CSCB</given-names></name><name><surname>Abdulla</surname><given-names>S</given-names></name><name><surname>Aevermann</surname><given-names>B</given-names></name><name><surname>Assis</surname><given-names>P</given-names></name><name><surname>Badajoz</surname><given-names>S</given-names></name><name><surname>Bell</surname><given-names>SM</given-names></name><name><surname>Bezzi</surname><given-names>E</given-names></name><name><surname>Cakir</surname><given-names>B</given-names></name><name><surname>Chaffer</surname><given-names>J</given-names></name><name><surname>Chambers</surname><given-names>S</given-names></name><name><surname>Cherry</surname><given-names>JM</given-names></name><etal/></person-group><article-title>CZ CELL×GENE Discover: A single-cell data platform for scalable exploration, analysis and modeling of aggregated data</article-title><year>2023</year><month>November</month><pub-id pub-id-type="doi">10.1093/nar/gkae1142</pub-id><pub-id pub-id-type="pmcid">PMC11701654</pub-id><pub-id pub-id-type="pmid">39607691</pub-id></element-citation></ref><ref id="R40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rao</surname><given-names>R</given-names></name><name><surname>Meier</surname><given-names>J</given-names></name><name><surname>Sercu</surname><given-names>T</given-names></name><name><surname>Ovchinnikov</surname><given-names>S</given-names></name><name><surname>Rives</surname><given-names>A</given-names></name></person-group><article-title>Transformer protein language models are unsupervised structure learners</article-title><year>2020</year><month>December</month></element-citation></ref><ref id="R41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ray</surname><given-names>A</given-names></name><name><surname>Radenovic</surname><given-names>F</given-names></name><name><surname>Dubey</surname><given-names>A</given-names></name><name><surname>Plummer</surname><given-names>BA</given-names></name><name><surname>Krishna</surname><given-names>R</given-names></name><name><surname>Saenko</surname><given-names>K</given-names></name></person-group><article-title>COLA: A Benchmark for Compositional Text-to-image Retrieval</article-title><year>2023</year><month>November</month></element-citation></ref><ref id="R42"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Rhodes</surname><given-names>B</given-names></name><name><surname>Vandenhaute</surname><given-names>S</given-names></name><name><surname>Šimkus</surname><given-names>V</given-names></name><name><surname>Gin</surname><given-names>J</given-names></name><name><surname>Godwin</surname><given-names>J</given-names></name><name><surname>Duignan</surname><given-names>T</given-names></name><name><surname>Neumann</surname><given-names>M</given-names></name></person-group><source>Orb-v3: atomistic simulation at scale</source><year>2025</year><comment>URL <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2504.06231">https://arxiv.org/abs/2504.06231</ext-link></comment></element-citation></ref><ref id="R43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosen</surname><given-names>Y</given-names></name><name><surname>Roohani</surname><given-names>Y</given-names></name><name><surname>Agarwal</surname><given-names>A</given-names></name><name><surname>Samotorčan</surname><given-names>L</given-names></name><name><surname>Consortium</surname><given-names>TS</given-names></name><name><surname>Quake</surname><given-names>SR</given-names></name><name><surname>Leskovec</surname><given-names>J</given-names></name></person-group><article-title>Universal Cell Embeddings: A Foundation Model for Cell Biology</article-title><year>2023</year><month>November</month></element-citation></ref><ref id="R44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ross</surname><given-names>J</given-names></name><name><surname>Belgodere</surname><given-names>B</given-names></name><name><surname>Chenthamarakshan</surname><given-names>V</given-names></name><name><surname>Padhi</surname><given-names>I</given-names></name><name><surname>Mroueh</surname><given-names>Y</given-names></name><name><surname>Das</surname><given-names>P</given-names></name></person-group><article-title>Large-scale chemical language representations capture molecular structure and properties</article-title><source>Nature Machine Intelligence</source><year>2022</year><month>December</month><volume>4</volume><issue>12</issue><fpage>1256</fpage><lpage>1264</lpage><comment>ISSN 2522-5839</comment><pub-id pub-id-type="doi">10.1038/s42256-022-00580-7</pub-id></element-citation></ref><ref id="R45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schockaert</surname><given-names>S</given-names></name></person-group><article-title>Embeddings as Epistemic States: Limitations on the Use of Pooling Operators for Accumulating Knowledge</article-title><year>2023</year><month>July</month></element-citation></ref><ref id="R46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Si</surname><given-names>Y</given-names></name><name><surname>Zou</surname><given-names>J</given-names></name><name><surname>Gao</surname><given-names>Y</given-names></name><name><surname>Chuai</surname><given-names>G</given-names></name><name><surname>Liu</surname><given-names>Q</given-names></name><name><surname>Chen</surname><given-names>L</given-names></name></person-group><article-title>Foundation models in molecular biology</article-title><source>Biophysics Reports</source><year>2024</year><month>June</month><volume>10</volume><issue>3</issue><fpage>135</fpage><lpage>151</lpage><comment>ISSN 2364-3439</comment><pub-id pub-id-type="doi">10.52601/bpr.2024.240006</pub-id><pub-id pub-id-type="pmcid">PMC11252241</pub-id><pub-id pub-id-type="pmid">39027316</pub-id></element-citation></ref><ref id="R47"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Song</surname><given-names>L</given-names></name><name><surname>Segal</surname><given-names>E</given-names></name><name><surname>Xing</surname><given-names>E</given-names></name></person-group><source>Toward AI-Driven Digital Organism: Multiscale Foundation Models for Predicting, Simulating and Programming Biology at All Levels</source><comment>URL <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2412.06993">http://arxiv.org/abs/2412.06993</ext-link></comment></element-citation></ref><ref id="R48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tang</surname><given-names>Z</given-names></name><name><surname>Somia</surname><given-names>N</given-names></name><name><surname>Yu</surname><given-names>Y</given-names></name><name><surname>Koo</surname><given-names>PK</given-names></name></person-group><article-title>Evaluating the representational power of pre-trained DNA language models for regulatory genomics</article-title><source>bioRxiv</source><year>2024</year><month>September</month><elocation-id>2024.02.29.582810</elocation-id><comment>ISSN 2692-8205</comment><pub-id pub-id-type="doi">10.1186/s13059-025-03674-8</pub-id><pub-id pub-id-type="pmcid">PMC12261763</pub-id><pub-id pub-id-type="pmid">40660356</pub-id></element-citation></ref><ref id="R49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Theodoris</surname><given-names>CV</given-names></name><name><surname>Xiao</surname><given-names>L</given-names></name><name><surname>Chopra</surname><given-names>A</given-names></name><name><surname>Chaffin</surname><given-names>MD</given-names></name><name><surname>Al Sayed</surname><given-names>ZR</given-names></name><name><surname>Hill</surname><given-names>MC</given-names></name><name><surname>Mantineo</surname><given-names>H</given-names></name><name><surname>Brydon</surname><given-names>EM</given-names></name><name><surname>Zeng</surname><given-names>Z</given-names></name><name><surname>Liu</surname><given-names>XS</given-names></name><name><surname>Ellinor</surname><given-names>PT</given-names></name></person-group><article-title>Transfer learning enables predictions in network biology</article-title><source>Nature</source><year>2023</year><month>June</month><volume>618</volume><issue>7965</issue><fpage>616</fpage><lpage>624</lpage><comment>ISSN 1476-4687</comment><pub-id pub-id-type="doi">10.1038/s41586-023-06139-9</pub-id><pub-id pub-id-type="pmcid">PMC10949956</pub-id><pub-id pub-id-type="pmid">37258680</pub-id></element-citation></ref><ref id="R50"><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Tishby</surname><given-names>N</given-names></name><name><surname>Pereira</surname><given-names>FC</given-names></name><name><surname>Bialek</surname><given-names>W</given-names></name></person-group><source>The Information Bottleneck Method</source></element-citation></ref><ref id="R51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Türei</surname><given-names>D</given-names></name><name><surname>Korcsmáros</surname><given-names>T</given-names></name><name><surname>Saez-Rodriguez</surname><given-names>J</given-names></name></person-group><article-title>Omni-Path: Guidelines and gateway for literature-curated signaling pathway resources</article-title><source>Nature Methods</source><year>2016</year><month>December</month><volume>13</volume><issue>12</issue><fpage>966</fpage><lpage>967</lpage><comment>ISSN 1548-7105</comment><pub-id pub-id-type="pmid">27898060</pub-id></element-citation></ref><ref id="R52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vaswani</surname><given-names>A</given-names></name><name><surname>Shazeer</surname><given-names>N</given-names></name><name><surname>Parmar</surname><given-names>N</given-names></name><name><surname>Uszkoreit</surname><given-names>J</given-names></name><name><surname>Jones</surname><given-names>L</given-names></name><name><surname>Gomez</surname><given-names>AN</given-names></name><name><surname>Kaiser</surname><given-names>L</given-names></name><name><surname>Polosukhin</surname><given-names>I</given-names></name></person-group><article-title>Attention Is All You Need</article-title><year>2023</year><month>August</month></element-citation></ref><ref id="R53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>N</given-names></name><name><surname>Bian</surname><given-names>J</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Li</surname><given-names>X</given-names></name><name><surname>Mumtaz</surname><given-names>S</given-names></name><name><surname>Kong</surname><given-names>L</given-names></name><name><surname>Xiong</surname><given-names>H</given-names></name></person-group><article-title>Multi-purpose RNA language modelling with motif-aware pretraining and type-guided fine-tuning</article-title><source>Nature Machine Intelligence</source><year>2024a</year><month>May</month><volume>6</volume><issue>5</issue><fpage>548</fpage><lpage>557</lpage><comment>ISSN 2522-5839</comment><pub-id pub-id-type="doi">10.1038/s42256-024-00836-4</pub-id></element-citation></ref><ref id="R54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>Zhu</surname><given-names>H</given-names></name><name><surname>Hu</surname><given-names>Y</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Zhang</surname><given-names>X</given-names></name><name><surname>Zou</surname><given-names>J</given-names></name><name><surname>Kellis</surname><given-names>M</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Liu</surname><given-names>D</given-names></name><name><surname>Jiang</surname><given-names>L</given-names></name></person-group><article-title>Hierarchical Interpretation of Out-of-Distribution Cells Using Bottlenecked Transformer</article-title><year>2024b</year><month>December</month><pub-id pub-id-type="doi">10.1186/s13059-025-03638-y</pub-id><pub-id pub-id-type="pmcid">PMC12183866</pub-id><pub-id pub-id-type="pmid">40551223</pub-id></element-citation></ref><ref id="R55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Zhao</surname><given-names>J</given-names></name><name><surname>Marostica</surname><given-names>E</given-names></name><name><surname>Yuan</surname><given-names>W</given-names></name><name><surname>Jin</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Li</surname><given-names>R</given-names></name><name><surname>Tang</surname><given-names>H</given-names></name><name><surname>Wang</surname><given-names>K</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>F</given-names></name><etal/></person-group><article-title>A pathology foundation model for cancer diagnosis and prognosis prediction</article-title><source>Nature</source><year>2024c</year><month>October</month><volume>634</volume><issue>8035</issue><fpage>970</fpage><lpage>978</lpage><comment>ISSN 1476-4687</comment><pub-id pub-id-type="doi">10.1038/s41586-024-07894-z</pub-id><pub-id pub-id-type="pmcid">PMC12186853</pub-id><pub-id pub-id-type="pmid">39232164</pub-id></element-citation></ref><ref id="R56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wenckstern</surname><given-names>J</given-names></name><name><surname>Jain</surname><given-names>E</given-names></name><name><surname>Vasilev</surname><given-names>K</given-names></name><name><surname>Pariset</surname><given-names>M</given-names></name><name><surname>Wicki</surname><given-names>A</given-names></name><name><surname>Gut</surname><given-names>G</given-names></name><name><surname>Bunne</surname><given-names>C</given-names></name></person-group><article-title>AI-powered virtual tissues from spatial proteomics for clinical diagnostics and biomedical discovery</article-title><year>2025</year><month>January</month></element-citation></ref><ref id="R57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xia</surname><given-names>Y</given-names></name><name><surname>Jin</surname><given-names>P</given-names></name><name><surname>Xie</surname><given-names>S</given-names></name><name><surname>He</surname><given-names>L</given-names></name><name><surname>Cao</surname><given-names>C</given-names></name><name><surname>Luo</surname><given-names>R</given-names></name><name><surname>Liu</surname><given-names>G</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Liu</surname><given-names>Z</given-names></name><name><surname>Chen</surname><given-names>YJ</given-names></name><name><surname>Guo</surname><given-names>Z</given-names></name><etal/></person-group><article-title>NatureLM: Deciphering the Language of Nature for Scientific Discovery</article-title><year>2025</year><month>February</month></element-citation></ref><ref id="R58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>Z</given-names></name><name><surname>Wu</surname><given-names>W</given-names></name><name><surname>Ho</surname><given-names>H</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Shi</surname><given-names>L</given-names></name><name><surname>Davuluri</surname><given-names>RV</given-names></name><name><surname>Wang</surname><given-names>Z</given-names></name><name><surname>Liu</surname><given-names>H</given-names></name></person-group><article-title>DNABERT-S: Pioneering Species Differentiation with Species-Aware DNA Embeddings</article-title><year>2024</year><month>October</month><pub-id pub-id-type="doi">10.1093/bioinformatics/btaf188</pub-id><pub-id pub-id-type="pmcid">PMC12261423</pub-id><pub-id pub-id-type="pmid">40662791</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><p>Representation of the different biological scales and how the representation of different foundation models could feed the upper scales and their learning could inform the lower scales’ representations.</p></caption><graphic xlink:href="EMS205714-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Overview of the Xpressor architecture and multi-scale fine-tuning approach applied to a cell foundation model.</title><p>A. The Xpressor architecture, composed of M layers, shows how gene-level representations are compressed into cell-state vectors through cross-attention over the output embeddings of a transformer, composed of N layers. These compressed representations are then decompressed back using the same initial transformer model with cross-attention given the initial gene-level tokens. B. Example of the multi-scale fine-tuning setup illustrating how the adapter layer enables joint training of gene-level representations that are then used by a cFM. C. Detailed structure of the transformer and Xpressor blocks showing the cross-attention and selfattention sub-blocks. Blue blocks are our contributions. Shaded blocks indicate inputs and outputs.</p></caption><graphic xlink:href="EMS205714-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><p>Comparison of cell embeddings between the regular transformer with class-pooling (left), scIB: 0.43, and the Xpressor (right), scIB: 0.48. The Xpressor embeddings contain more structure and resolve different cell types better.</p></caption><graphic xlink:href="EMS205714-f003"/></fig><table-wrap id="T1" orientation="portrait" position="float"><label>Table 1</label><caption><title>Comparison of cell embedding approaches</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="middle" align="left" style="border-top:solid 1px #000000;border-bottom:solid 1px #000000">Model</th><th valign="bottom" align="center" style="border-top: 1px solid #000000;border-bottom: 1px solid">Cell Label<break/>Pred.</th><th valign="bottom" align="center" style="border-top: 1px solid #000000;border-bottom: 1px solid">Embed.<break/>Quality</th><th valign="bottom" align="center" style="border-top: 1px solid #000000;border-bottom: 1px solid">Gene-Net<break/>Infer.</th></tr></thead><tbody><tr><td valign="top" align="left">Class-pooling</td><td valign="top" align="center">0.64</td><td valign="top" align="center">0.48</td><td valign="top" align="center"><bold>4.0,2.3</bold></td></tr><tr><td valign="top" align="left" style="border-bottom: 1px solid"><bold>Xpressor</bold></td><td valign="top" align="center" style="border-bottom: 1px solid"><bold>0.72</bold></td><td valign="top" align="center" style="border-bottom: 1px solid"><bold>0.52</bold></td><td valign="top" align="center" style="border-bottom: 1px solid">4.1,2.1</td></tr></tbody></table></table-wrap><table-wrap id="T2" orientation="portrait" position="float"><label>Table 2</label><caption><title>Comparison of input-gene embedding approaches</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="bottom" align="left" style="border-top:solid 1px #000000;border-bottom:solid 1px #000000">Model</th><th valign="bottom" align="center" style="border-top: 1px solid #000000;border-bottom: 1px solid">Cell Label<break/>Pred.</th><th valign="bottom" align="center" style="border-top: 1px solid #000000;border-bottom: 1px solid">Embed.<break/>Quality</th><th valign="bottom" align="center" style="border-top: 1px solid #000000;border-bottom: 1px solid">Gene-Net<break/>Infer.</th></tr></thead><tbody><tr><td valign="top" align="left">Random init.</td><td valign="top" align="center">0.62</td><td valign="top" align="center">0.48</td><td valign="top" align="center">4.5,1.0</td></tr><tr><td valign="top" align="left">ESM2 frozen</td><td valign="top" align="center">0.60</td><td valign="top" align="center">0.484</td><td valign="top" align="center">5.2,1.4</td></tr><tr><td valign="top" align="left" style="border-bottom: 1px solid"><bold>ESM2 fine-tuned</bold></td><td valign="top" align="center" style="border-bottom: 1px solid #000000"><bold>0.70</bold></td><td valign="top" align="center" style="border-bottom: 1px solid #000000"><bold>0.49</bold></td><td valign="top" align="center" style="border-bottom: 1px solid #000000"><bold>4.8,2.4</bold></td></tr></tbody></table></table-wrap></floats-group></article>