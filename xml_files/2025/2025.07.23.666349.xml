<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS207528</article-id><article-id pub-id-type="doi">10.1101/2025.07.23.666349</article-id><article-id pub-id-type="archive">PPR1054414</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">1</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>TU_MyCo-Vision: A Deep Learning Tool for Detection of Cell Morphologies in Fungal Microscopic Images</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Deopujari</surname><given-names>Kartik J.</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Schmal</surname><given-names>Matthias</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Danner</surname><given-names>Caroline</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Qayyum</surname><given-names>Zainab Abdul</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Zwerus</surname><given-names>Jordy T.</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Kopp</surname><given-names>Julian</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Besleaga</surname><given-names>Mihail</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Shirvani</surname><given-names>Roghayeh</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Mach-Aigner</surname><given-names>Astrid R.</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Mach</surname><given-names>Robert L.</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Zimmermann</surname><given-names>Christian</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib></contrib-group><aff id="A1"><label>1</label>Institute of Chemical, Environmental and Bioscience Engineering, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/04d836q62</institution-id><institution>TU Wien</institution></institution-wrap>, <addr-line>Gumpendorfer Strasse 1a</addr-line>, <postal-code>1060</postal-code><city>Wien</city>, <country country="AT">Austria</country></aff><pub-date pub-type="nihms-submitted"><day>25</day><month>07</month><year>2025</year></pub-date><pub-date pub-type="preprint"><day>23</day><month>07</month><year>2025</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Morphological switching in response to environmental stimuli is a well-known phenomenon in fungi, leading to diverse morphotypes. Microscopic observation remains a widely used approach to study these phenotypes. However, variation in sample preparation and operators skill can limit the scale of sample processing or introduce bias. Although several image-based cell detection tools have been developed, most are tailored to specific applications or limited to a particular taxon. To address the need for a tool applicable to the polymorphic, yeast-like fungus <italic>Aureobasidium pullulans</italic>, and with potential applicability to other taxa, we developed TU_MyCo-Vision, an Ultralytics YOLO (You Only Look Once) based object detection tool for identifying 13 fungal morphotypes in bright-field microscopic images.</p><p id="P2">The tool integrates a YOLOv11m-based object detector trained on a custom dataset of 1,504 annotated images and a standalone graphical user interface that enables downstream data analysis and visualization of results. The best-performing model (Zulu_s3) achieved a mean precision of 73.4%, a recall of 66.5%, a mean average precision at 50% IoU (mAP@50) of 73.5%, and a mean average precision at varying IoU thresholds between 50 to 90% IoU (mAP@50-95) of 54.5% across all 13 classes. The single-group analysis pipeline was validated on a 90-image test set, generating six quantitative summaries, including absolute counts, relative and mean relative abundance plots, stacked bar plots, and clustered heatmaps. Multi-group evaluation on previously unseen datasets comprising <italic>Candida albicans, Komagataella phaffii</italic>, and <italic>Aspergillus niger</italic> spores demonstrated the tool’s potential applicability to other genera.</p><p id="P3">TU_MyCo-Vision is distributed as a fully packaged, cross-platform executable, eliminating the need for environment setup or manual installation of dependencies. Built entirely on open-source frameworks, it provides a foundational and potentially extensible solution for automated fungal morphology detection and analysis.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P4">The kingdom of fungi is well known for its diversity, especially when it comes to mode of nutrition, habitat, and morphology. Although diversity introduces its challenges in studying fungi, the identification of morphologies through direct microscopic observation remains a commonly used method (<xref ref-type="bibr" rid="R1">1</xref>). An interesting phenomenon in some fungi is their ability to exhibit different morphologies throughout their life cycle. These changes in morphology may occur in response to environmental stimuli or play a role in pathogenicity (<xref ref-type="bibr" rid="R2">2</xref>). A good example is the morphological switching in <italic>Candida albicans</italic>, where generally the hyphal and pseudohyphal morphologies are considered pathogenic over yeasts, which are regarded as commensal (<xref ref-type="bibr" rid="R2">2</xref>,<xref ref-type="bibr" rid="R3">3</xref>). A Similar tendency to switch morphology is also observed in soil-borne pathogenic fungi <italic>Coccidioides immitis</italic> and <italic>Coccidioides posadasii</italic>, in which spherules form through the progressive enlargement of arthroconidia that enter the body via inhalation (<xref ref-type="bibr" rid="R4">4</xref>). This highlights the importance of morphological assessment, particularly in clinical settings, where treatment decisions may depend on the presence of septate hyphae in <italic>Aspergillus</italic> versus non-septate hyphae in <italic>Mucorales</italic>, as observed through micromorphological analysis. While the microscopic examination has its own advantages, such as its wide applicability and rapid results, it is also sensitive to factors like the quality of sample preparation and operator skill (<xref ref-type="bibr" rid="R5">5</xref>–<xref ref-type="bibr" rid="R7">7</xref>).</p><p id="P5">To address conventional limitations, several deep learning tools have been developed for fungal detection in microscopy. For example, Koo et al. introduced a YOLOv4-based object detector that automates the KOH (potassium hydroxide) examination for rapid hyphae detection in microscopic images (<xref ref-type="bibr" rid="R6">6</xref>). Candescence employs a Fully Convolutional One Stage (FCOS) architecture to identify and classify nine <italic>C. albicans</italic> morphologies from DIC (Differential Interference Contrast) microscopic images (<xref ref-type="bibr" rid="R8">8</xref>). For edible fungi, CCHA-YOLO enables automated and efficient detection of mycelium clamp connections and hyphae autolysis, processes that are typically time-consuming but essential for examining mycelial growth and aging. CCHA-YOLO achieved a high mAP50-95 of 89.02% and includes a web interface to improve accessibility (<xref ref-type="bibr" rid="R9">9</xref>,<xref ref-type="bibr" rid="R10">10</xref>).</p><p id="P6">Separately, an improved YOLOv5-based tool was developed to detect downy mildew spores in natural scenes, facilitating early outbreak prediction through automated spore detection (<xref ref-type="bibr" rid="R11">11</xref>).</p><p id="P7">Fungal polymorphism is important not only in clinical settings but also in biotechnological applications. <italic>Aureobasidium pullulans</italic> is a polyextremotolerant black yeast-like fungus with significant biotechnological importance. It is known to survive across a wide spectrum of extreme environments, including hypersaline, highly acidic or basic, cold, and oligotrophic conditions. <italic>A. pullulans</italic> is well known for producing pullulan, along with other metabolites such as heavy oils and polymalic acid. Members of the <italic>Aureobasidium</italic> genus exhibit remarkable phenotypic plasticity in response to environmental conditions (<xref ref-type="bibr" rid="R12">12</xref>).</p><p id="P8">This leads to the development of various morphotypes, which include yeast-like cells, blastoconidia, chlamydospores, hyphae, pseudohyphae, swollen cells, and septate cells (<xref ref-type="bibr" rid="R13">13</xref>–<xref ref-type="bibr" rid="R15">15</xref>). Li et al. described several morphological forms in <italic>A. pullulans</italic> NG, including yeast-like blastospores (YLB), yeast-like cells (YL), swollen cells (SC), septate swollen cells (SSC), chlamydospore-like cells (CH), hyphal forms (HY), and meristematic structures (MS) (<xref ref-type="bibr" rid="R16">16</xref>). Among these, the SC form plays a key role, acting as a relatively stable intermediate that arises from YL cells. This form is notable for producing key metabolites such as unpigmented pullulan and subsequently differentiating into melanin-rich forms like CH, HY, and MS as the organism progresses into later growth stages. A practical application of this was demonstrated by (<xref ref-type="bibr" rid="R15">15</xref>), where they demonstrated the role of citric acid in controlling the cellular differentiation in <italic>A. pullulans</italic> NG, which led to efficient pullulan biosynthesis due to the growth in the cells in swollen cell form.</p><p id="P9">In the course of our own cultivation experiments with <italic>A. pullulans</italic>, we observed a high degree of morphological variability across conditions and strains and generated a large volume of brightfield microscopy images. While several fungal cell detection tools are available, most are limited to specific taxa or morphologies and lack accessibility for users without computational expertise, preventing their application for our purposes. Thus, we developed TU_MyCo-Vision, an object detection tool based on the Ultralytics YOLOv11m architecture, aiming at detecting thirteen morphotypes in <italic>Aureobasidium</italic>.</p><p id="P10">The pretrained YOLOv11m model was re-trained using a curated dataset of 1504 brightfield microscopic images, primarily representing <italic>A. pullulans</italic>, with additional images from <italic>Aureobasidium melanogenum</italic> and <italic>Trichoderma reesei</italic> to improve generalizability. A hybrid annotation approach combining expert labeling and model-assisted auto-labeling was used for dataset curation. A 5-fold cross-validation strategy was used for training and evaluation. The dataset was iteratively improved during the study, leading to improved performance of the final model. The final model was tested on images of <italic>Komagataella phaffii, Aspergillus niger</italic>, and <italic>C. albicans</italic>, demonstrating potential applicability to genera not part of the training dataset. To improve accessibility, we integrated the model into a graphical user interface (GUI) along with a custom data analysis pipeline, enabling users to interpret results without requiring programming skills. The GUI tool enables fungal cell detection, visualization, and downstream analysis, including single and multi-group comparisons, class exclusion for focused morphology-specific analysis, and interactive plots for easier visualization.</p></sec><sec id="S2" sec-type="materials | methods"><title>Materials and Methods</title><sec id="S3"><label>A</label><title>Dataset generation</title><p id="P11">A microscopic image dataset of <italic>A. pullulans</italic> EXF-150, 3374, 3519, 3750, 4010, 5628, 6298, 6519, 8127, 8128, and 10632 (<xref ref-type="bibr" rid="R17">17</xref>) and NBB 7.2.1 (<xref ref-type="bibr" rid="R18">18</xref>) was generated through a combination of different cultivation experiments aimed at studying the morphology of <italic>A. pullulans</italic>. To increase dataset diversity and improve model generalizability, microscopic image data of <italic>T. reesei</italic> and <italic>A. melanogenum</italic> were included.</p><sec id="S4"><label>A.1</label><title>Cultivation of <italic>A. pullulans</italic></title><p id="P12"><italic>A. pullulans</italic> strains were cultivated in <italic>A. flavus</italic> and <italic>A. parasiticus</italic> medium (AFP), Archimycetes medium (ARCH), Brain Heart Infusion medium (BHI), boiled rice medium, potato dextrose medium (PD), yeast peptone dextrose medium (YPD), M17 medium, malt extract medium (MEX), Muller Hinton broth (MH), and minimal medium. Refer to “<xref ref-type="supplementary-material" rid="SD1">S1 Table 1</xref>” for detailed medium composition. 100 ml Flasks containing 25 ml of respective cultivation medium and strain were incubated for different time periods, and incubation temperatures ranging from 14 °C to 34 °C, and at different shaking speeds ranging from 200 – 220 rpm. Media compositions adapted from (<xref ref-type="bibr" rid="R19">19</xref>)</p><sec id="S5"><label>A.1.1</label><title>Cultivation of <italic>A. melanogenum</italic></title><p id="P13"><italic>A. melanogenum</italic> ATCC 42023 was incubated on MEX plates at 22 °C for 5 days. Yeast-like growth was scraped off with a sterile inoculation loop and resuspended in 0.8% NaCl. 25 ml of fresh medium was inoculated with the suspension with a starting OD600 of 0.05 and incubated at 24°C at 200 rpm for a period between 24h and 168h, approximately.</p></sec><sec id="S6"><label>A.1.2</label><title>Cultivation of <italic>T. reesei</italic></title><p id="P14"><italic>T. reesei</italic> strains RL-P37 (NRRL 15709) and Rut-C30 were cultivated on PD agar plates at 30°C until sporulation. The conidia were harvested and resuspended in 0.8 %(w/v) NaCl, 0.05 % (v/v) Tween-80. 6-well culture plates, with each well containing 5 ml of growth medium, were inoculated to a density of 10<sup>9</sup> conidia/L. The cultures were incubated at 30 °C for 20 hours under static conditions. Three types of media were used for cultivation: Mandels–Andreotti (MA) medium supplemented with either 1% (w/v) lactose or 1% (w/v) glucose as the sole carbon source, and MEX medium.</p></sec><sec id="S7"><label>A.1.3</label><title>Cultivation of <italic>K. phaffii GS115</italic></title><p id="P15">The pre-culture medium (100 mL/L of sterilized 0.1 M potassium phosphate buffer pH 6.0, 13.4 g/L yeast nitrogen base without amino acids and with ammonium sulfate, 5 g/L (NH4)2SO4, 400 mg/L biotin, 20 g/L glycerol and 100 µg/ml Zeocin) was inoculated with a fresh cryo stock, and incubated at 30 °C, 230 rpm for 24 h. Next, the pre-culture was used to inoculate the batch medium (10% of the batch media volume). All cultivations were performed in a Minifors 2 bioreactor system (max. working volume: 2 L; Infors HT, Basel, Switzerland). Process control and feeding were performed using EVE software (Infors HT, Bottmingen, Switzerland). The batch medium composition is described in detail in (<xref ref-type="bibr" rid="R20">20</xref>). The pH was monitored using a pH-sensor EasyFerm Plus (Hamilton, Reno, NV, USA). During cultivations, pH was kept constant at 5.0 and was controlled with base addition only (12.5% NH<sub>4</sub>OH), while acid (10% H<sub>3</sub>PO<sub>4</sub>) was added manually, if necessary. The temperature was kept constant at 30 °C. Aeration was carried out using a mixture of pressurized air and pure oxygen at two vvm to keep dissolved oxygen (dO<sub>2</sub>) above 30% at all times. The dissolved oxygen was monitored using a fluorescence dissolved oxygen electrode, Visiferm DO (Hamilton, Reno, NV, USA). After sugar during batch phase was depleted, the continuous operation was started. During chemostat cultivation volume in the reactor was adjusted and maintained constant via an immersion tube connected to a bleed pump.</p><p id="P16">Samples were taken during chemostat cultivations at alternating time-points depending on the morphological alterations. These alterations highly depend on the cultivation time and the set dilution rate, with details given here (<xref ref-type="bibr" rid="R21">21</xref>). Microscopic analysis was used to observe pseudohyphae growth.</p></sec><sec id="S8"><label>A.1.4</label><title>Cultivation of <italic>K. phaffii CBS7435</italic></title><p id="P17"><italic>K. phaffii CBS7435, △DAS1, △DAS2, △AOX1</italic> was cultivated in M2 citrate-buffered media (<xref ref-type="bibr" rid="R22">22</xref>) supplemented with 20 mg/L thiamine pyrophosphate (TPP). A single yeast colony from a YPD (1% yeast extract, 2% peptone, 2% glucose, and 1.5% bacteriological agar) agar plate was inoculated into a 250 mL shake flask containing 50 mL of YPD broth as a preculture grown at 28 °C and 200 rpm. The samples for microscopy were taken from cultures grown in M2 citrate-buffered media with 1% (v/v) methanol as the carbon source. The dataset from this cultivation will be referred to as <italic>Komagataella phaffii</italic> strain set_A in this article.</p></sec><sec id="S9"><label>A.1.5</label><title>Generation of <italic>A. niger</italic> conidia</title><p id="P18">An industrial strain of <italic>A. niger</italic> was spotted on minimal medium plates from a -80 °C glycerol stock. The plates were incubated at 30 °C for 7 days to allow for sufficient conidiation. Conidia were harvested by pouring 10 mL of 0.1% Tween-20 solution onto the plates and were subsequently scraped off by using a sterile cotton swab. The suspension was filtered using sterile Miracloth to remove agar debris and mycelium. After filtering the suspension was centrifuged at 3000g for 15 minutes at 4 °C. Supernatant was discarded and the centrifugation step was repeated after 10 mL of 0.1% Tween-20 solution was added. After centrifugation, the supernatant was discarded, and up to 10 mL of 0.1% Tween-20 solution was added.</p></sec></sec><sec id="S10"><label>A.2</label><title>Microscopy and Imaging</title><p id="P19">Unstained wet mounts of the <italic>A. pullulans</italic> strains, <italic>K. phaffii</italic> (strain set_A), <italic>A. niger</italic> spores, and <italic>T. reesei</italic> were prepared and observed using brightfield microscopy. For all <italic>A. pullulans</italic> strains, microscopic imaging was performed at multiple time points ranging from 24h to 240h. Images were captured using a Nikon ECLIPSE E200 light microscope, equipped with a BRESSER Mikrookular CMOS sensor-based Full HD eyepiece camera (Art. No. 5913650). Images of <italic>T. reesei, K. phaffi</italic> (strain set_A) and <italic>A. niger</italic> were captured using the same setup but with magnification of 100x and 200x for <italic>T. reesei</italic>, and 100x, 200x and 400x for <italic>K. phaffi</italic> (strain set_A). Appropriate dilutions of the <italic>A. niger</italic> spore suspension were prepared in 0.1% Tween-20 solution, and the conidia were observed using an improved Neubauer counting chamber at 200x magnification. Image acquisition and export was performed using the “Breeser CamLab Lite” software at a resolution of 1920 × 1080 (width x height).</p><p id="P20">Microscopic analysis of <italic>K. phaffii</italic> GS115 was performed using an Olympus CKX41 inverted microscope (Olympus Life Science, Tokyo, Japan) with an IX2-SLP phase contrast slider (Olympus Life Science, Tokyo, Japan) using a Canon EOS 250D (Canon, Tokyo, Japan) camera.</p><p id="P21">Microscopy and imaging of <italic>A. melanogenum</italic> was performed using a Leica DMi8 microscope. Images were captured at multiple time points ranging from 24h to 168h, at 100x, 400x, and 630x magnification. Images with a resolution of 2560 × 1920 (width x height) were exported using Leica Application Suite.</p><sec id="S11"><label>A.1.2</label><title>Dataset expansion strategy</title><p id="P22">We applied a dataset expansion strategy in which the 1920×1080 pixel images were cropped into 640×640 pixel crops, with each representing a unique image (<xref ref-type="fig" rid="F1">Figure 1</xref>). This was inspired by a similar strategy applied by Li et al. (<xref ref-type="bibr" rid="R11">11</xref>) &amp; Juneja et al. (<xref ref-type="bibr" rid="R23">23</xref>), which led to an increase in the number of images available for the dataset and more efficient training. A custom Python script “cropper.py” was used to generate six unique images of size 640×640 from a single 1920×1080 image. The script was also designed to handle the edge cases, where the region of the crop is adjusted if the crop section is out of bounds of the original image size. 15437 images were generated using this dataset expansion strategy.</p></sec><sec id="S12"><label>A.2.2</label><title>Image annotation</title><p id="P23">Images with 640×640 resolution were then manually screened and annotated using LabelMe (v5.4.1) (<xref ref-type="bibr" rid="R24">24</xref>). Objects were annotated with rectangular bounding boxes. In order to track the number of objects from each class, for monitoring and class balancing operations. A Python script, “annotation handler.py,” was used in our study.</p><p id="P24">The Python library Labelme2YOLO (v0.1.7) and Labelme2YOLO (v0.2.5) were used to convert annotations in “.JSON” format to “YOLO” annotation format (<xref ref-type="bibr" rid="R25">25</xref>). The dataset was auto-split into an 80:20 Train: Validation split during the conversion.</p></sec><sec id="S13"><label>A.2.3</label><title>Training and Validation datasets</title><p id="P25">The dataset generation was an iterative process involving repeated manual review of the datasets, removal of noisy or incorrect labels, and addition of new images to the datasets. This led to the creation of three versions of the dataset: X-ray, Yankee, and Zulu. Zulu was the final version of the dataset. X-ray, Yankee, and Zulu datasets consisted of 1028 images, 1002 images, and 1504 images with 8575, 8652, and 11804 objects, respectively, belonging to 13 different classes. See “<xref ref-type="supplementary-material" rid="SD1">S2 Table 2</xref>” for detailed information on the distribution of objects across all the classes in training and validation sets, in all five splits, and three dataset families.</p></sec><sec id="S14"><label>A.2.4</label><title>Test dataset</title><p id="P26">We created an independent global test dataset of 166 images from our primary image bank, which are not part of any of the X-ray, Yankee, and Zulu datasets. The test dataset contained images of <italic>A. pullulans, A. melanogenum</italic>, and <italic>T. reesei</italic>. See “<xref ref-type="supplementary-material" rid="SD1">S3 Table 3</xref>” for class-wise object distribution in global test dataset. This test dataset was used to test all model families using the validator function built into the Ultralytics framework (<xref ref-type="bibr" rid="R26">26</xref>).</p></sec><sec id="S15"><label>A.2.5</label><title>5-fold cross-validation</title><p id="P27">To make the optimum use of our datasets, we performed K-fold stratified cross-validation using a Python cross-validation split script by (<xref ref-type="bibr" rid="R27">27</xref>) as the base script and modified it. With the script “kfold_splitter.py,” every dataset family was split into five folds in order to achieve a balance between class representation and computational costs. A stratified k-fold cross-validation was preferred over a simple k-fold cross-validation in order to account for the imbalanced nature of the dataset (<xref ref-type="bibr" rid="R28">28</xref>). All the computations were performed on Vienna Scientific Cluster-5, powered with an NVIDIA A100 GPU.</p></sec><sec id="S16"><label>A.2.6</label><title>Auto-labelling</title><p id="P28">The final version of the dataset, Zulu, was a hybrid dataset containing auto-labelled images generated with the Yankee_s5 version of our model trained on pre-trained YOLOv11m. The auto-labeling was performed on images from our dataset, which were not part of any previous dataset. A Python script, “datafeed_prediction.py,” was used to run the prediction function of the model on the images. The prediction function outputs the images with annotated objects in bounding boxes, along with corresponding text files with annotations in YOLO format. Post prediction, all 14200 images were manually reviewed to check for correct annotations. Five hundred seventeen images were selected and then added to the Yankee dataset images. The dataset was manually reviewed in order to remove any identical images. This resulted in the final dataset with 1504 images.</p></sec></sec><sec id="S17"><label>B</label><title>Training TU_MyCo-Vision on Ultralytics YOLO with custom dataset using transfer learning approach</title><sec id="S18"><label>B.1.1</label><title>Initial training and hyperparameter exploration</title><p id="P29">Initially, the pre-trained YOLOv8x and, after its release, YOLOv11x and YOLOv11m models were used and trained on our custom dataset using transfer learning. We randomly selected x-ray_split_1 as the representative dataset among the five dataset splits. Keeping the default Ultralytics training hyperparameters as a reference, we arrived at the list of hyperparameters as shown in “<xref ref-type="supplementary-material" rid="SD1">S4 Table 4</xref>” through exploratory trials. A detailed list of all the default hyperparameters and augmentation settings can be found at (<xref ref-type="bibr" rid="R29">29</xref>).</p><p id="P30">Throughout the study, we considered a mAP@50-95 &gt; 0.5 for single-cell classes and mAP@50 &gt; 0.5 for filamentous classes as the criteria for a well-performing model. Moreover, validation metrics like class loss, box loss, and distribution focal loss (dfl) were monitored to prevent overfitting or any instabilities in training. All metrics and loss functions were generated by the Ultralytics framework.</p></sec><sec id="S19"><label>B.1.2</label><title>Hyperparameter optimization</title><p id="P31">Based on the hyperparameters obtained after the exploratory search, a hyperparameter search was performed. These parameters (refer to “<xref ref-type="supplementary-material" rid="SD1">S4 Table 4</xref>”) were used to define the search space for the hyperparameter tuning. For tuning the hyperparameters of the YOLOv8x model on our custom dataset, the “model.tune()” method was used. This utilized the “Tuner” class based on the Ultralytics YOLO mutation algorithm to search for the best-fit hyperparameters (<xref ref-type="bibr" rid="R30">30</xref>). Atotal of 45 iterations were executed, each with a limit of 300 epochs, using the Stochastic Gradient Descent (SGD) optimizer. During each iteration, the current parameter set was mutated, and models were evaluated using the fitness score, calculated based on the key performance indicators.</p></sec></sec><sec id="S20"><label>B.2</label><title>Cross-validation runs</title><p id="P32">Using the tuned hyperparameters (see “<xref ref-type="supplementary-material" rid="SD1">S5 Table 5</xref>”), we performed the training with all five splits obtained after the 5-fold stratified dataset splitting. This process was performed for all the models except for the model trained on the dataset Zulu. For training the Zulu model family, augmentation parameters were slightly modified for more robust augmentation. Refer to “<xref ref-type="supplementary-material" rid="SD1">S6 Table 6</xref>” for the list of hyperparameters used for model Zulu.</p></sec><sec id="S21"><label>B.3</label><title>Model Evaluation</title><p id="P33">The object detection model was evaluated using Intersection over Union (IoU), box-level precision (P) and recall (R), and mean average precision (mAP). The mAP was computed at an IoU threshold of 0.50 (mAP@50) and also averaged across thresholds from 0.50 to 0.95 in 0.05 increments (mAP@50–95) to assess the performance across varying degrees of overlap.</p><p id="P34">During model training, three loss functions were used to guide the learning process: classification loss, box loss, and distribution focal loss (dfl). Classification loss was evaluated to assess the performance of the model in correctly classifying objects of different classes. A lower classification loss indicates better performance in distinguishing between different cell morphologies. Bounding box loss penalizes spatial misalignment between predicted and ground truth boxes. Distribution focal loss (dfl) was used to improve the precision of bounding box predictions by focusing learning on difficult-to-detect objects.</p><p id="P35">The Ultralytics framework also generated visual outputs to support the interpretation of the model’s performance. These included F1 score curves, precision-recall (PR) curves, along with raw and normalized confusion matrices. Qualitative assessments involved visualization of annotated validation images, comparing ground truth and predicted bounding boxes. All results, including numerical metrics and visual outputs, were saved in the runs/detect/val directory for further analysis (<xref ref-type="bibr" rid="R31">31</xref>)</p></sec></sec><sec id="S22"><label>C</label><title>Graphical User Interface Implementation and Data Analysis Workflow</title><p id="P36">To improve user accessibility by eliminating the need to install dependencies or run the Ultralytics framework via terminal, a cross-platform graphical user interface (GUI) was developed in Python (version 3.10 or higher) using multiple open-source libraries. The interface was implemented using customtkinter (v5.2.2) (<xref ref-type="bibr" rid="R32">32</xref>), a wrapper around the standard tkinter library (<xref ref-type="bibr" rid="R33">33</xref>). All image handling operations were performed using Pillow (v11.2.1) (<xref ref-type="bibr" rid="R34">34</xref>), and OpenCV (<xref ref-type="bibr" rid="R35">35</xref>), including image dimension capture, resizing, and rendering. The prediction script was integrated into the GUI, allowing parameterization through interface controls. Except for the imgsz parameter (automatically determined from image dimensions) and interface-based inputs, all model parameters were kept at default values.</p><p id="P37">Annotation data was extracted and analyzed for quantitative assessment of predicted morphotypes.</p><p id="P38">Edge Bounding Box Exclusion: A key data preprocessing step involved the exclusion of bounding boxes positioned at the edges of images to avoid counting partially visible cells (false positives or incorrect detections). This feature was disabled for hyphal morphologies and clumps (C7-E, C7-F, C7-G, and C6), as they typically occupy large regions in the image, resulting in bounding boxes that extend to the image edges. Bounding boxes were excluded from the analysis if either the left or right edges (calculated as center x ± width/2), or the top or bottom edges (center y ± height/2), were within a small threshold (epsilon = 0.001) of the image border (0 or 1 in normalized coordinates).</p><p id="P39">Class Exclusion: To enable targeted analysis, a class exclusion logic was implemented whereby selected morphotypes could be grouped into an “Others” category during processing. Activating this feature resulted in the export of two data tables: a filtered data table (filename_excluded.csv) and a raw data table (filename_rawdata.csv). This was tested using a subset of the test dataset by grouping filamentous morphologies (C7-E, C7-F, C7-G) into the “Others” category for single-group analysis.</p><p id="P40">Single and Multi-Group Analysis: For single-group analysis, a random subset of 90 images from the global test set was analyzed using the single-group pipeline, with and without class exclusion enabled. For multi-group analysis, a test set was constructed with 10 <italic>C. albicans</italic> images (Candescence dataset) (<xref ref-type="bibr" rid="R8">8</xref>) 9 <italic>K. phaffii (strain set_A)</italic>, 9 <italic>K. phaffii GS115</italic>, and 9 <italic>A. niger</italic> spore images. Predictions were performed using default settings, and results were organized into separate folders representing each group. The multi-group analysis pipeline was then applied to compare morphological profiles across these groups.</p><p id="P41">The data analysis pipeline generated interactive visualizations, including absolute count bar plots, relative abundance bar plots, mean relative abundance bar plots, normalized stacked bar plots, and hierarchical clustering heatmaps using Ward’s method. Hierarchical clustering was performed using the scipy.cluster.hierarchy module in the SciPy library (<xref ref-type="bibr" rid="R36">36</xref>). For multi-group analysis, an additional heatmap comparing all individual images across groups was also generated. All plots were rendered interactively via the Plotly library (v6.1.2) (<xref ref-type="bibr" rid="R37">37</xref>) using the generated “.csv” files as input.</p></sec></sec><sec id="S23" sec-type="results"><title>Results</title><sec id="S24"><label>A</label><title>Characterizing morphological variation in <italic>A. pullulans</italic></title><p id="P42">After the cultivation of twelve <italic>A. pullulans</italic> strains in ten different cultivation media, we classified the cell morphologies into thirteen different classes, based on phenotypic observations. These morphologies were broadly categorized into single-celled morphologies, filamentous morphologies, and special morphologies. C1, C2, C2-B, C3-B, C5, and C9 are single-cell classes. C7-G, C7-E, and C7-F are classes for filamentous morphologies, and C4, C6, and C11 are special classes representing budding events, clumping, and irregularly shaped cells, respectively (See <xref ref-type="fig" rid="F2">Figure 2</xref>). Refer to <xref ref-type="table" rid="T1">Table 1</xref> for a detailed description of object classes.</p></sec><sec id="S25"><label>B</label><title>Initial training, Hyperparameter exploration, and optimization</title><p id="P43">Initial training was conducted with the YOLOv8x architecture using the split_1 dataset of X-ray family, selected as a representative subset from the stratified 5-fold cross-validation splits. Using default Ultralytics hyperparameters as a baseline, an exploratory approach was employed to identify a reasonable set of hyperparameters (see “<xref ref-type="supplementary-material" rid="SD1">S4 Table 4</xref>”), which yielded satisfactory early-stage performance across several morphological classes.</p><p id="P44">Version 1 of the model demonstrated high detection accuracy for major single-cell classes. Specifically, mAP@50 values were 0.840 for class C1 (cells with central vacuole), 0.816 for C2 (cells with dual vacuoles), 0.785 for C5 (yeast-like morphologies), 0.822 for C2-B (multiple vacuoles), 0.904 for C3-B (granular cytoplasm), and 0.890 for C8 (septate cells). In contrast, filamentous morphologies posed greater challenges: the model achieved mAP@50 values of 0.811, 0.566, and 0.547 for C7-E (septate hyphae or pseudohyphae), C7-F (vacuolated hyphae), and C7-G (smooth hyphae/nonseptate hyphae), respectively.</p><p id="P45">Evaluation of the normalized confusion matrix revealed misclassification events. Class C5 (yeast-like cells) was particularly prone to confusion, with frequent misclassification as C11 (irregular shapes) and C9 (spheroidal cells). Although C5 achieved 80% correct predictions, it was also associated with a hallucination rate (i.e., proportion of predicted objects of a class that do not correspond to any ground truth instances of that class) of 36%. These findings highlight the morphological overlap among spheroidal and ovoid classes, highlighting a key challenge in differentiating single-cell morphologies with geometrical overlap.</p><p id="P46">The highest mAP@50-95, of 0.5216, was achieved at epoch 486. This level of performance met our minimum criteria for a functional prototype, and the hyperparameter set was selected as a baseline for hyperparameter optimization. Refer to “S7 Folder (V1)” for PR curves, F1 plot, confusion matrices, and other result visualizations.</p><p id="P47">Subsequent optimization was conducted using Ultralytics genetic mutation-based tuner, which adapts hyperparameters iteratively to maximize fitness (<xref ref-type="bibr" rid="R30">30</xref>).</p><p id="P48">The best-performing configuration emerged at iteration 19, with a fitness score of 0.5491. This iteration produced a model with a precision of 73.21%, a recall of 68.01%, a mAP@50 of 0.7268, and mAP@50–95 of 0.5293. These results marked an improvement over the baseline exploratory parameters. Notably, fitness scores plateaued after iteration 19, with the second-best score (0.5404) obtained at iteration 23 (<xref ref-type="fig" rid="F3">Figure 3</xref>), indicating diminishing returns from further mutation. The hyperparameters derived from the optimal iteration (listed in “<xref ref-type="supplementary-material" rid="SD1">S5 Table 5</xref>”) were selected for use in all subsequent training across the dataset splits. This tuning process contributed to performance consistency and stability in downstream model families (X-ray, Yankee, and Zulu), particularly in reducing false positives and improving the balance between sensitivity and specificity. These results validate the effectiveness of targeted hyperparameter optimization in enhancing detection for diverse fungal cell morphologies, especially when addressing under-represented and structurally complex classes such as filamentous forms. Refer to “S8 Folder “hyperparameter_tuning” for additional information.</p></sec><sec id="S26"><label>C</label><title>k-fold cross-validation runs</title><p id="P49">Next, k-fold cross-validation training was performed, initially with the X-ray and Yankee dataset, and finally with the Zulu dataset. Even though the initial choice of model was YOLOv8x. We migrated to the newer model YOLOv11x and later YOLOv11m. The YOLOv11x to YOLOv11m was performed because YOLOv11m is a smaller model, which is computationally more efficient and reduces overfitting, especially on smaller datasets (<xref ref-type="bibr" rid="R38">38</xref>). The evaluation of all the models was performed using the standard object detection metrics, including box precision, box recall, mAP@50 and mAP@50-95.</p><sec id="S27"><label>C.1</label><title>Performance evaluation of X-ray, Yankee, and Zulu models on validation dataset</title><p id="P50">We trained and evaluated three model families, X-ray, Yankee, and Zulu, each corresponding to a new improved version of the TU_MyCo-Vision dataset. All models were trained using the five dataset splits generated after 5-fold cross-validation and assessed based on standard object detection metrics (See <xref ref-type="table" rid="T2">Table 2</xref> for performance summary of three model families). In each family, the dataset split that resulted in the best model performance was considered as the representative model and was further analyzed using confusion matrices, precision-recall (PR) curves, and training/validation loss curves.</p><p id="P51">The X-ray split_4 model achieved high classification accuracy (i.e., all detected objects were assigned to their correct morphological class, according to the normalized confusion matrix) for common morphotypes, including C1 (89%), C2 (88%), C5 (84%), C6 (90%), C8 (88%), and C2-B (79%), with moderate performance for C3-B (76%), C4 (73%), and C11 (58%). C9 was frequently misclassified as C5 (21%), and misclassification of C1 primarily occurred with C2 (4%) and C2-B (6%). Filamentous classes were particularly challenging: C7-E, C7-F, and C7-G were correctly predicted in 75%, 58%, and 52% cases, respectively, with 20-45% of bounding boxes assigned to background or neighboring filamentous classes. Based on the PR curve, corresponding mAP@50 values were 0.649, 0.440, and 0.429, respectively, while higher scores were observed for C1 (0.914), C2 (0.902), C2-B (0.939), C6 (0.921), and C8 (0.882).</p><p id="P52">The Yankee split_5 model achieved greater than 80% accuracy for C1, C2, C3-B, C5, C6, C8, and C7-E. Detection rates for C7-F and C7-G were 55% and 51%, respectively. Misclassifications were prominent between C9 and C5 (18%), C3-B and C5 (14%), and C8 and C11 (10%). PR curve analysis showed mAP@50 values of 0.934 (C1), 0.899 (C2-B), 0.914 (C8), 0.854 (C3-B), 0.756 (C7-E), 0.592 (C7-F), and 0.500 (C7-G). Lower mAP@50 scores were also noted for C4 (0.633), C9 (0.699), and C11 (0.634).</p><p id="P53">The Zulu split_1 model demonstrated high classification accuracy across several classes: 95% for C1, 89% for C6, 84% for C3-B, and less than or equal to 80% for C2, C5, and C2-B. C4 achieved 69% classification accuracy, although 25% of its instances were missed. C11 remained difficult to classify, with 50% classification accuracy and frequent misclassification into C6, C9, or background. The detection of filamentous morphotypes improved, with C7-E, C7-F, and C7-G achieving 76%, 71%, and 67% classification accuracy, respectively, and corresponding mAP@50 values of 0.808, 0.555, and 0.625. C4 and C11 recorded mAP@50 scores of 0.753 and 0.681, respectively, based on the PR curve analysis.</p><p id="P54">Overall, all three model families exhibited stable training dynamics, with steadily decreasing loss curves and consistent improvements in all metrics over epochs. Successive models benefited from dataset enhancements, which contributed to improved performance metrics, particularly for morphologically complex or rare cell types. Among the three, Zulu demonstrated superior performance to its predecessors and showed reliable performance for both single-celled morphologies and complex filamentous classes, supporting its deployment as the final representative model for TU_MyCo-Vision. Refer to the supporting information folder “S9 xray”,” S10 zulu”, and “S11 yankee” for detailed metrics, confusion matrix, PR curve, F1 curve, and other visualizations.</p></sec></sec><sec id="S28"><label>D</label><title>Comparison of all TU_MycoVision model families on the global test dataset</title><p id="P55">A separate global test dataset of 166 images was created in order to test all the models. The test set was curated manually and contained images that are not part of any of the datasets used for the training of our 3 model families. Using the global test dataset, we compared all the models belonging to the X-ray, Yankee, and Zulu model families.</p><p id="P56">15 models were evaluated based primarily on mAP@50-95, precision, and recall performance, with more preference to mAP@50-95 and Precision metrics in the same order of priority for selecting the best performing model. Out of which Zulu_s3 was the best performing model, with a high precision of 73.4%, a recall of 66.5%, and mAP@50-95 of 0.545. These improvements could be attributed to the consistent improvement of our datasets over each family of models, X-ray, Yankee, and Zulu. <xref ref-type="table" rid="T3">Table 3</xref> describes the detailed performance metrics of all the models. Zulu_s5 and zulu_s4 also showed robust performance with mAP@50-95 of 0.546 and 0.527, respectively. Relatively lower mAP@50-95 scores were observed for X-ray models, ranging from 0.493 to 0.513, and also for Yankee models, whose scores ranged from 0.498 to 0.526. This makes the Zulu family of models the best models with a mAP@50-95 ranging from 0.519 to 0.546 to detect 13 fungal cell morphologies in microscopic images.</p><p id="P57">Considering zulu_s3 as our best model, we further analyzed the PR curves and normalized confusion matrix to get more performance insights. The precision recall curve indicates strong performance for single cell classes like C2, C5, C1, C2-B, C3-B, and C8 with an average precision at (50% IoU) of 91.2%, 79.25%, 84.4%, 88.7%, 90%, and 89.7% respectively, based on PR curve analysis (<xref ref-type="fig" rid="F4">Figure 4</xref>). The model performed best for C1, C2, C2-B cell types, which represent vacuolated morphologies, and C3-B, which represents single cells with granules in the cytoplasm, and C8, which are septate cells. Satisfactory performance was observed for the classes C4 (budding events), C6 (cell aggregates/clumps), and C11 (irregular morphologies).</p><p id="P58">The model also performed well for the filamentous cell classes with average classification accuracy values consistently above 51% based on the normalized confusion matrix (<xref ref-type="fig" rid="F4">Figure 4</xref>), which is satisfactory for such complex morphologies. Overall, our model demonstrated detection accuracy of 73.5% for 13 different cell morphologies (Refer <xref ref-type="table" rid="T4">Table 4</xref> for detailed class-wise performance metrics of model zulu_s3). The normalized confusion matrix provides deeper insights into the model’s misclassifications (<xref ref-type="fig" rid="F4">Figure 4</xref>). High classification performance was observed for the classes C2 (82% correct predictions), C5 (83% correct predictions), C3-B (97% correct predictions), and C8 (81% correct predictions). Misclassification was particularly observed between classes C1:C5 with 14% C1 cells misclassified as C5, C5:C9 (11% C9 misclassified as C5), C9:C3-B (11% C9 misclassified as C3-B), C2-B:C5 (14% C2-B misclassified as C5), C8:C3-B (12% C8 misclassified as C3-B). Satisfactory performance was observed for the filamentous classes, with classification accuracies of 57% for C7-E (septate hyphae/pseudohyphae), 78% for C7-F (vacuolated hyphae), and 58% for C7-G (smooth hyphae). Although the numbers for the filamentous classes seem to be on the lower side, it has to be considered that the hyphal structures are mostly spread across large areas along with their complex structures, which affects their detection.</p><p id="P59">See the supporting folder “S13 validation_global_set” for validation performance visualizations of all models validated on the global test dataset.</p><p id="P60">Refer to the supporting information table “S14 Table 7. validation_metrics_global_test_set” for detailed validation metrics of all models.</p></sec><sec id="S29"><label>E</label><title>Graphical User Interface, and Data Analysis</title><p id="P61">We developed a cross-platform graphical user interface to make the detection tool accessible and user-friendly. As all the dependencies and libraries are packaged into a single executable “.exe” for Windows-based systems and “.app” for macOS, the need for the user to set up the required environment is eliminated. This makes the tool suitable for users without advanced computational skills. The GUI is organized into three main panels: Detection, Analysis, and Results Dashboard. Detection panel includes all options from selection of I/O folders, class selection, model parameter adjustments, and prediction execution (<xref ref-type="fig" rid="F5">Figure 5a</xref>). The Analysis panel allows the user to perform single-group and multi-group analyses, along with the class exclusion panel for selecting morphological classes to be grouped as “others” (<xref ref-type="fig" rid="F5">Figure 5c</xref>). The Results Dashboard offers an interactive side-by-side visualization of original and processed images for easy visualization of results (<xref ref-type="fig" rid="F5">Figure 5b</xref>). Quantitative results are accessible via an embedded CSV table, which can be loaded and viewed in the Results Dashboard (<xref ref-type="fig" rid="F5">Figure 5d</xref>). The tool, using the loaded CSV file, also generates and renders plots after clicking the “Click to View Plots” button.</p><sec id="S30"><label>E.1</label><title>Single-Group Analysis of Test Set Validates the Data Processing and Visualization Pipeline</title><p id="P62">We tested the data analysis and visualization pipeline for the single-group analysis function using 90 images from our global test set. Both workflows were evaluated: one with all classes and another with class exclusion activated, in which all filamentous classes (C7-E, C7-F, and C7-G) were grouped together into the “Others” category. The pipeline processed all 90 test images and produced six quantitative visualizations, including absolute count bar plots, normalized stacked bar plots, relative and mean relative abundance plots, and heatmaps with hierarchical clustering (<xref ref-type="fig" rid="F6">Figures 6</xref> and <xref ref-type="fig" rid="F7">7</xref>). This demonstrated the tool’s ability to handle a large number of images, apply class-exclusion logic, and generate quantitative visualization plots within a single, integrated environment.</p></sec><sec id="S31"><label>E.2</label><title>Multi-Group Analysis Demonstrates TU_MyCo-Vision’s applicability to unseen genera</title><p id="P63">In order to assess TU_MyCo-Vision on images from different genera and test the multi-group analysis pipeline, we performed analysis on completely unseen image datasets of <italic>C. albicans</italic> (<xref ref-type="bibr" rid="R8">8</xref>), <italic>K. phaffii</italic> strains, <italic>and A. niger</italic> spores. The model could successfully detect the morphologies in the unseen data (refer to the supporting information folder “S12 data_gui_test” for the annotated images). The data analysis pipeline also successfully processed the data from all the groups and produced quantitative output and visual summaries, enabling comparative analysis among different sample groups (<xref ref-type="fig" rid="F8">Figure 8</xref>). This provided an initial indication of the tool’s potential utility for morphotype quantification across taxonomically diverse fungal samples, although broader validation and detailed biological interpretations are beyond the current study’s scope.</p></sec></sec></sec><sec id="S32" sec-type="discussion"><title>Discussion</title><p id="P64">In this study, TU_MyCo-Vision, an Ultralytics YOLOv11m-based object detection tool, was developed for the identification and classification of thirteen distinct fungal cell morphologies in brightfield microscopic images. The tool was designed to support investigations into the morphological plasticity of <italic>A. pullulans</italic>, which is a polyextremotolerant black yeast-like fungus of emerging biotechnological importance. Based on phenotypic observations using microscopic images, we defined thirteen distinct morphological forms, ranging from yeast -like to filamentous forms, and a set of special morphologies that served as the class definitions for the TU_MyCo-Vision model training. Although initially derived from <italic>A. pullulans</italic>, these morphologies were transferable across the genera tested and imaging contexts. We incorporated images of <italic>A. melanogenum</italic> and <italic>T. reesei</italic> into the training and validation sets to enhance the model’s generalizability.</p><p id="P65">Compared to currently available tools, such as Candescence, which focuses exclusively on <italic>C. albicans</italic> (<xref ref-type="bibr" rid="R8">8</xref>) or CCHA-YOLO, which targets clamp connections in edible fungi (<xref ref-type="bibr" rid="R9">9</xref>), TU_MyCo-Vision is species agnostic. The class definitions are phenotype-centric rather than species-specific or cultivation condition-specific, enhancing the tools’ adaptability to a wide range of research questions. The potential applicability of TU_MyCo-Vision to other genera and species was tested by the successful detection of morphotypes in <italic>C. albicans</italic> images from the Candescence dataset, <italic>K. phaffii strains</italic>, and on spores of <italic>A. niger</italic>.</p><p id="P66">Through an iterative dataset and model improvement process, we could consistently improve the performance of subsequent model families. Zulu, being the latest model family trained on a hybrid dataset of 1504 images, yielded the best-performing model. The model trained on the Zulu_split3 dataset achieved the highest performance with an average precision of 73.4%, a recall of 66.5%, and mAP@50-95 of 0.545. This indicates robust performance of the tool across all thirteen defined morphologies (refer to <xref ref-type="table" rid="T1">Table 1</xref>). Upon closer look at the validation metrics of the Zulu_split3 model, it detected cells of classes C8, C2-B, C2, C4, C3-B, and C1 with precision higher than the average precision of all classes, thus indicating superior performance for the majority of single cell classes. The model struggled with recall, i.e., detecting all the objects present in the image, especially for the filamentous classes, which could be attributed to their very complex and highly variable morphologies. This was also observed for special classes like C4 (budding events), C6 (cell aggregates), and C11 (irregular cell types), which could be the result of less training data, especially for class C11. But as the model was developed to detect the presence of different cell types, the overall performance characteristics of TU_MyCo-Vision make it a suitable tool for this purpose.</p><p id="P67">Notably, the classification of fungal cells into yeast-like, budding, and variation in hyphal morphology, such as septate and non-septate, pseudo-hyphae, is a sought-after requirement from the technician during clinical microscopic examination. It is also extremely beneficial, especially in clinical settings, to detect the presence of any fungal structure in a normally sterile bodily region, as it can be treated as proof of infection (<xref ref-type="bibr" rid="R5">5</xref>).</p><p id="P68">Despite overall strong performance, variability in class-wise results was observed across all model families, including Zulu. These variations stem from diverse morphologies, overlapping geometric features, filamentous classes with complex morphologies, and class imbalance within the dataset, all of which contributed to inconsistent model performance. Such challenges are common in machine learning models, where class imbalance, feature overlap, and limited data can degrade model accuracy (<xref ref-type="bibr" rid="R39">39</xref>). To address these issues, we employed image augmentation, which is an effective strategy to mitigate class imbalance, and adopted a smaller model architecture (YOLOv11x to YOLOv11m) to reduce overfitting on limited data (<xref ref-type="bibr" rid="R38">38</xref>).</p><p id="P69">To complement the core detection capabilities of TU_MyCo-Vision, we developed a cross-platform graphical user interface (GUI) to facilitate detection and downstream data analysis for users without computational skills. The GUI integrates the detection with the Zulu_s3 model and a custom data analysis pipeline that supports analysis of samples within a single group or multi-group analysis, along with additional features like class exclusion. The GUI also enables qualitative visual assessment via an integrated image viewer, which displays the original and annotated image pairs side-by-side.</p><p id="P70">We validated the GUI and data analysis pipeline with 90 images from the test dataset for single-group analysis and the class exclusion feature. For multi-group analysis testing, image sets of <italic>C. albicans, K. phaffii strain GS115, and strain set_A</italic>, and <italic>A. niger</italic> spores were used. This testing demonstrated the tool’s species-agnostic potential and flexibility across imaging conditions. While the primary aim of the testing was to validate the core functionality and user accessibility of TU_MyCo-Vision, we did not perform benchmarking across a wide range of fungal species or experimental conditions, as it is out of the scope of this article. Our focus was to demonstrate the potential capabilities of the tool to detect fungal cells of genera that are not part of the training dataset, highlighting its potential applicability beyond its initial training dataset.</p><p id="P71">In conclusion, TU_MyCo-Vision presents a practical, high-throughput, and user-friendly framework for automated detection and quantification of thirteen different cell types in brightfield fungal microscopic images. By integrating a SOTA (State of the Art) Ultralytics YOLOv11m-based object detector with an open-source, accessible graphical user interface and data analysis suite, this tool lowers the technical barriers for advanced functional phenotyping tools and supports flexible integration with different experimental designs. While additional optimization and systematic benchmarking across diverse fungal taxa and imaging modalities remain necessary, TU_MyCo-Vision provides a scalable and foundational solution for microscopic phenotypic analysis in fungi. Future work should focus on improving model performance, generalizability, and benchmarking across various taxa and imaging modalities.</p></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplemental Table 1</label><media xlink:href="EMS207528-supplement-Supplemental_Table_1.xlsx" mimetype="application" mime-subtype="vnd.openxmlformats-officedocument.spreadsheetml.sheet" id="d8aAcEbB" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD2"><label>Supplemental Table 2</label><media xlink:href="EMS207528-supplement-Supplemental_Table_2.xlsx" mimetype="application" mime-subtype="vnd.openxmlformats-officedocument.spreadsheetml.sheet" id="d8aAcEcB" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD3"><label>Supplemental Table 3</label><media xlink:href="EMS207528-supplement-Supplemental_Table_3.xlsx" mimetype="application" mime-subtype="vnd.openxmlformats-officedocument.spreadsheetml.sheet" id="d8aAcEdB" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD4"><label>Supplemental Table 4</label><media xlink:href="EMS207528-supplement-Supplemental_Table_4.xlsx" mimetype="application" mime-subtype="vnd.openxmlformats-officedocument.spreadsheetml.sheet" id="d8aAcEeB" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD5"><label>Supplemental Table 5</label><media xlink:href="EMS207528-supplement-Supplemental_Table_5.xlsx" mimetype="application" mime-subtype="vnd.openxmlformats-officedocument.spreadsheetml.sheet" id="d8aAcEfB" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD6"><label>Supplemental Table 6</label><media xlink:href="EMS207528-supplement-Supplemental_Table_6.xlsx" mimetype="application" mime-subtype="vnd.openxmlformats-officedocument.spreadsheetml.sheet" id="d8aAcEgB" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD7"><label>Supplemental Table 7</label><media xlink:href="EMS207528-supplement-Supplemental_Table_7.xlsx" mimetype="application" mime-subtype="vnd.openxmlformats-officedocument.spreadsheetml.sheet" id="d8aAcEhB" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD8"><label>Supplementary Material</label><media xlink:href="EMS207528-supplement-Supplementary_Materials.pdf" mimetype="application" mime-subtype="pdf" id="d8aAcEiB" position="anchor"/></supplementary-material></sec></body><back><ack id="S35"><title>Acknowledgements</title><p>The computational results presented have been achieved [in part] using the Vienna Scientific Cluster (VSC). The authors gratefully acknowledge Dr. Florian Kleber and the Computer Vision Lab, Institute of Visual Computing &amp; Human-Centered Technology, Faculty of Informatics, TU Wien, for their valuable guidance and constructive input during the model training and development. Parts of the study were supported by the TU Wien doctoral colleges, ENROL - Engineering for Life Sciences and CO<sub>2</sub> Refinery.</p><sec id="S33"><title>Funding</title><p>This research was funded in whole or in part by the Austrian Science Fund (FWF) [10.55776/P 35642]. For open access purposes, the authors have applied a CC BY public copyright license. Author Johannes. T. Zwerus gratefully acknowledges financial support from the Austrian Federal Ministry of Economy, Energy and Tourism, the National Foundation for Research, Technology and Development, and the Christian Doppler Research Association.</p></sec></ack><sec id="S34" sec-type="data-availability"><title>Data availability</title><p id="P72">All codes used during TU_MyCo-Vision development, standalone executables for Windows OS and MacOS, along with the model weight and supporting files, are available on our GitHub repository at <ext-link ext-link-type="uri" xlink:href="https://github.com/cderntl/TU_MycoVision">https://github.com/cderntl/TU_MycoVision</ext-link>. The X-ray, Yankee, Zulu, global test dataset, and test set for GUI testing are available on our Zenodo repository at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.16274901">https://doi.org/10.5281/zenodo.16274901</ext-link>. Supporting information folders S7-S13 are available on our Zenodo repository at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.16318684">https://doi.org/10.5281/zenodo.16318684</ext-link>.</p></sec><fn-group><fn fn-type="con" id="FN1"><p id="P73"><bold>Author contribution</bold></p><p id="P74">KJD Conceptualization, Data Curation, Formal Analysis, Investigation, Methodology, Software, Visualization, Writing – Original Draft Preparation</p><p id="P75">MS Methodology, Software</p><p id="P76">CD Investigation</p><p id="P77">ZAQ Investigation</p><p id="P78">JTZ Investigation</p><p id="P79">JK Investigation</p><p id="P80">MH Investigation</p><p id="P81">RS Investigation</p><p id="P82">AMA Resources</p><p id="P83">RLM Resources, Supervision</p><p id="P84">CZ Funding Acquisition, Supervision, Writing – Review &amp; Editing</p></fn></fn-group><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gautam</surname><given-names>AK</given-names></name><name><surname>Verma</surname><given-names>RK</given-names></name><name><surname>Avasthi</surname><given-names>S</given-names></name><name><surname>Sushma Bohra</surname><given-names>Y</given-names></name><name><surname>Devadatha</surname><given-names>B</given-names></name><etal/></person-group><article-title>Current Insight into Traditional and Modern Methods in Fungal Diversity Estimates</article-title><source>Journal of Fungi</source><year>2022</year><month>Feb</month><day>24</day><volume>8</volume><issue>3</issue><fpage>226</fpage><pub-id pub-id-type="doi">10.3390/jof8030226</pub-id><pub-id pub-id-type="pmcid">PMC8955040</pub-id><pub-id pub-id-type="pmid">35330228</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fernandes</surname><given-names>KE</given-names></name><name><surname>Carter</surname><given-names>DA</given-names></name></person-group><article-title>Cellular plasticity of pathogenic fungi during infection</article-title><source>PLoS Pathog</source><year>2020</year><month>Jun</month><day>4</day><volume>16</volume><issue>6</issue><elocation-id>e1008571</elocation-id><pub-id pub-id-type="doi">10.1371/journal.ppat.1008571</pub-id><pub-id pub-id-type="pmcid">PMC7271979</pub-id><pub-id pub-id-type="pmid">32497133</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Noble</surname><given-names>SM</given-names></name><name><surname>Gianetti</surname><given-names>BA</given-names></name><name><surname>Witchley</surname><given-names>JN</given-names></name></person-group><article-title>Candida albicans cell-type switching and functional plasticity in the mammalian host</article-title><source>Nat Rev Microbiol</source><year>2017</year><month>Feb</month><day>21</day><volume>15</volume><issue>2</issue><fpage>96</fpage><lpage>108</lpage><pub-id pub-id-type="doi">10.1038/nrmicro.2016.157</pub-id><pub-id pub-id-type="pmcid">PMC5957277</pub-id><pub-id pub-id-type="pmid">27867199</pub-id></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saubolle</surname><given-names>MA</given-names></name><name><surname>McKellar</surname><given-names>PP</given-names></name><name><surname>Sussland</surname><given-names>D</given-names></name></person-group><article-title>Epidemiologic, Clinical, and Diagnostic Aspects of Coccidioidomycosis</article-title><source>J Clin Microbiol</source><year>2007</year><month>Jan</month><volume>45</volume><issue>1</issue><fpage>26</fpage><lpage>30</lpage><pub-id pub-id-type="doi">10.1128/JCM.02230-06</pub-id><pub-id pub-id-type="pmcid">PMC1828958</pub-id><pub-id pub-id-type="pmid">17108067</pub-id></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knoll</surname><given-names>MA</given-names></name><name><surname>Steixner</surname><given-names>S</given-names></name><name><surname>Lass-Flörl</surname><given-names>C</given-names></name></person-group><article-title>How to use direct microscopy for diagnosing fungal infections</article-title><source>Clinical Microbiology and Infection</source><year>2023</year><month>Aug</month><volume>29</volume><issue>8</issue><fpage>1031</fpage><lpage>8</lpage><pub-id pub-id-type="pmid">37187349</pub-id></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koo</surname><given-names>T</given-names></name><name><surname>Kim</surname><given-names>MH</given-names></name><name><surname>Jue</surname><given-names>MS</given-names></name></person-group><article-title>Automated detection of superficial fungal infections from microscopic images through a regional convolutional neural network</article-title><source>PLoS One</source><year>2021</year><month>Aug</month><day>17</day><volume>16</volume><issue>8</issue><elocation-id>e0256290</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0256290</pub-id><pub-id pub-id-type="pmcid">PMC8370604</pub-id><pub-id pub-id-type="pmid">34403443</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lass-Flörl</surname><given-names>C</given-names></name></person-group><article-title>How to make a fast diagnosis in invasive aspergillosis</article-title><source>Med Mycol</source><year>2019</year><month>Apr</month><day>1</day><volume>57</volume><issue>Supplement_2</issue><fpage>S155</fpage><lpage>60</lpage><pub-id pub-id-type="pmid">30816965</pub-id></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bettauer</surname><given-names>V</given-names></name><name><surname>Costa</surname><given-names>ACBP</given-names></name><name><surname>Omran</surname><given-names>RP</given-names></name><name><surname>Massahi</surname><given-names>S</given-names></name><name><surname>Kirbizakis</surname><given-names>E</given-names></name><name><surname>Simpson</surname><given-names>S</given-names></name><etal/></person-group><article-title>A Deep Learning Approach to Capture the Essence of Candida albicans Morphologies</article-title><source>Microbiol Spectr</source><year>2022</year><month>Oct</month><day>26</day><volume>10</volume><issue>5</issue><pub-id pub-id-type="doi">10.1128/spectrum.01472-22</pub-id><pub-id pub-id-type="pmcid">PMC9604015</pub-id><pub-id pub-id-type="pmid">35972285</pub-id></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>L</given-names></name><name><surname>Lin</surname><given-names>S</given-names></name><name><surname>Jin</surname><given-names>W</given-names></name><name><surname>Weng</surname><given-names>H</given-names></name><name><surname>Xu</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>L</given-names></name><etal/></person-group><article-title>CCHA YOLO for mycelium clamp connection (CC) and hyphae Autolysis(HA) detection under microscopy imaging and web deployment</article-title><source>Microchemical Journal</source><year>2024</year><month>Jun</month><volume>201</volume><elocation-id>110483</elocation-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aanen</surname><given-names>DK</given-names></name><name><surname>van ‘t Padje</surname><given-names>A</given-names></name><name><surname>Auxier</surname><given-names>B</given-names></name></person-group><article-title>Longevity of Fungal Mycelia and Nuclear Quality Checks: a New Hypothesis for the Role of Clamp Connections in Dikaryons</article-title><source>Microbiology and Molecular Biology Reviews</source><year>2023</year><month>Sep</month><day>26</day><volume>87</volume><issue>3</issue><pub-id pub-id-type="doi">10.1128/mmbr.00022-21</pub-id><pub-id pub-id-type="pmcid">PMC10521366</pub-id><pub-id pub-id-type="pmid">37409939</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>K</given-names></name><name><surname>Qiao</surname><given-names>C</given-names></name><name><surname>Zhu</surname><given-names>X</given-names></name><name><surname>Song</surname><given-names>Y</given-names></name><name><surname>Zhang</surname><given-names>L</given-names></name><name><surname>Gao</surname><given-names>W</given-names></name><etal/></person-group><article-title>Lightweight fungal spore detection based on improved YOLOv5 in natural scenes</article-title><source>International Journal of Machine Learning and Cybernetics</source><year>2024</year><month>Jun</month><day>28</day><volume>15</volume><issue>6</issue><fpage>2247</fpage><lpage>61</lpage></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xia</surname><given-names>J</given-names></name><name><surname>Xu</surname><given-names>J</given-names></name><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Xu</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Li</surname><given-names>X</given-names></name></person-group><article-title>Economic co-production of poly(malic acid) and pullulan from Jerusalem artichoke tuber by Aureobasidium pullulans HA-4D</article-title><source>BMC Biotechnol</source><year>2017</year><month>Dec</month><day>23</day><volume>17</volume><issue>1</issue><fpage>20</fpage><pub-id pub-id-type="doi">10.1186/s12896-017-0340-y</pub-id><pub-id pub-id-type="pmcid">PMC5324199</pub-id><pub-id pub-id-type="pmid">28231788</pub-id></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kocková-Kratochvílová</surname><given-names>A</given-names></name><name><surname>Černáková</surname><given-names>M</given-names></name><name><surname>Sláviková</surname><given-names>E</given-names></name></person-group><article-title>Morphological changes during the life cycle ofAureobasidium pullulans (de Bary) Arnaud</article-title><source>Folia Microbiol (Praha)</source><year>1980</year><month>Jan</month><volume>25</volume><issue>1</issue><fpage>56</fpage><lpage>67</lpage><pub-id pub-id-type="pmid">7353807</pub-id></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pechak</surname><given-names>DG</given-names></name><name><surname>Crang</surname><given-names>RE</given-names></name></person-group><article-title>An Analysis of Aureobasidium Pullulans Developmental Stages by Means of Scanning Electron Microscopy</article-title><source>Mycologia</source><year>1977</year><month>Jul</month><day>12</day><volume>69</volume><issue>4</issue><fpage>783</fpage><lpage>92</lpage></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeng</surname><given-names>N</given-names></name><name><surname>Zhang</surname><given-names>N</given-names></name><name><surname>Wang</surname><given-names>D</given-names></name><name><surname>Long</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Regulation of cell differentiation to promote pullulan synthesis in Aureobasidium pullulans NG</article-title><source>Appl Microbiol Biotechnol</source><year>2023</year><month>Nov</month><day>12</day><volume>107</volume><issue>22</issue><fpage>6761</fpage><lpage>73</lpage><pub-id pub-id-type="pmid">37698607</pub-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li xue</surname><given-names>B</given-names></name><name><surname>Zhang</surname><given-names>N</given-names></name><name><surname>Peng</surname><given-names>Q</given-names></name><name><surname>Yin</surname><given-names>T</given-names></name><name><surname>Guan fei</surname><given-names>F</given-names></name><name><surname>li Wang</surname><given-names>G</given-names></name><etal/></person-group><article-title>Production of pigment-free pullulan by swollen cell in Aureobasidium pullulans NG which cell differentiation was affected by pH and nutrition</article-title><source>Appl Microbiol Biotechnol</source><year>2009</year><month>Aug</month><day>31</day><volume>84</volume><issue>2</issue><fpage>293</fpage><lpage>300</lpage><pub-id pub-id-type="pmid">19333596</pub-id></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>GostinČar</surname><given-names>C</given-names></name><name><surname>Grube</surname><given-names>M</given-names></name><name><surname>Gunde-Cimerman</surname><given-names>N</given-names></name></person-group><article-title>Evolution of Fungal Pathogens in Domestic Environments?</article-title><source>Fungal Biol</source><year>2011</year><month>Oct</month><volume>115</volume><issue>10</issue><fpage>1008</fpage><lpage>18</lpage><pub-id pub-id-type="pmid">21944213</pub-id></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hilber-Bodmer</surname><given-names>M</given-names></name><name><surname>Schmid</surname><given-names>M</given-names></name><name><surname>Ahrens</surname><given-names>CH</given-names></name><name><surname>Freimoser</surname><given-names>FM</given-names></name></person-group><article-title>Competition assays and physiological experiments of soil and phyllosphere yeasts identify Candida subhashii as a novel antagonist of filamentous fungi</article-title><source>BMC Microbiol</source><year>2017</year><month>Dec</month><day>5</day><volume>17</volume><issue>1</issue><fpage>4</fpage><pub-id pub-id-type="doi">10.1186/s12866-016-0908-z</pub-id><pub-id pub-id-type="pmcid">PMC5216558</pub-id><pub-id pub-id-type="pmid">28056814</pub-id></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="book"><person-group person-group-type="editor"><name><surname>Crous</surname><given-names>PW</given-names></name><name><surname>Verkleij</surname><given-names>GJM</given-names></name><name><surname>Groenewald</surname><given-names>JZ</given-names></name><name><surname>Houbraken</surname><given-names>J</given-names></name></person-group><source>Westerdijk Laboratory Manual Series No. 1 Fungal Biodiversity</source><publisher-name>Westerdijk Fungal Biodiversity Institute</publisher-name><year>2019</year><edition>2nd</edition><comment>2019</comment></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spadiut</surname><given-names>O</given-names></name><name><surname>Dietzsch</surname><given-names>C</given-names></name><name><surname>Herwig</surname><given-names>C</given-names></name></person-group><article-title>Determination of a Dynamic Feeding Strategy for Recombinant Pichia pastoris Strains</article-title><year>2014</year><fpage>185</fpage><lpage>94</lpage><pub-id pub-id-type="doi">10.1007/978-1-4939-0563-8_11</pub-id><pub-id pub-id-type="pmcid">PMC4826592</pub-id><pub-id pub-id-type="pmid">24744034</pub-id></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Besleaga</surname><given-names>M</given-names></name><name><surname>Ebner</surname><given-names>K</given-names></name><name><surname>Glieder</surname><given-names>A</given-names></name><name><surname>Spadiut</surname><given-names>O</given-names></name><name><surname>Kopp</surname><given-names>J</given-names></name></person-group><article-title>Chances and drawbacks of derepressed recombinant enzyme production in continuous cultivations with Komagataella phaffii</article-title><source>Front Bioeng Biotechnol</source><year>2025</year><month>Mar</month><day>10</day><volume>13</volume><pub-id pub-id-type="doi">10.3389/fbioe.2025.1523037</pub-id><pub-id pub-id-type="pmcid">PMC11931149</pub-id><pub-id pub-id-type="pmid">40129455</pub-id></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shirvani</surname><given-names>R</given-names></name><name><surname>Bartik</surname><given-names>A</given-names></name><name><surname>Alves</surname><given-names>GAS</given-names></name><name><surname>Garcia de Otazo Hernandez</surname><given-names>D</given-names></name><name><surname>Müller</surname><given-names>S</given-names></name><name><surname>Föttinger</surname><given-names>K</given-names></name><etal/></person-group><article-title>Nitrogen recovery from low-value biogenic feedstocks via steam gasification to methylotrophic yeast biomass</article-title><source>Front Bioeng Biotechnol</source><year>2023</year><month>May</month><day>30</day><volume>11</volume><pub-id pub-id-type="doi">10.3389/fbioe.2023.1179269</pub-id><pub-id pub-id-type="pmcid">PMC10289294</pub-id><pub-id pub-id-type="pmid">37362211</pub-id></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Juneja</surname><given-names>M</given-names></name><name><surname>Thakur</surname><given-names>S</given-names></name><name><surname>Uniyal</surname><given-names>A</given-names></name><name><surname>Wani</surname><given-names>A</given-names></name><name><surname>Thakur</surname><given-names>N</given-names></name><name><surname>Jindal</surname><given-names>P</given-names></name></person-group><article-title>Deep learning-based classification network for glaucoma in retinal images</article-title><source>Computers and Electrical Engineering</source><year>2022</year><month>Jul</month><volume>101</volume><elocation-id>108009</elocation-id></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Wada</surname><given-names>K</given-names></name></person-group><source>Labelme: Image Polygonal Annotation with Python</source><comment>[Internet] Available from: <ext-link ext-link-type="uri" xlink:href="https://github.com/wkentaro/labelme">https://github.com/wkentaro/labelme</ext-link></comment></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="web"><source>labelme2yolo</source><date-in-citation>cited 2025 Jul 15</date-in-citation><comment>[Internet] Available from: <ext-link ext-link-type="uri" xlink:href="https://github.com/GreatV/labelme2yolo">https://github.com/GreatV/labelme2yolo</ext-link></comment></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Jocher</surname><given-names>G</given-names></name><name><surname>Qiu</surname><given-names>J</given-names></name><name><surname>Chaurasia</surname><given-names>A</given-names></name></person-group><source>Ultralytics YOLO</source><year>2023</year><comment>[Internet] Available from: <ext-link ext-link-type="uri" xlink:href="https://github.com/ultralytics/ultralytics">https://github.com/ultralytics/ultralytics</ext-link></comment></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="web"><source>K-Fold Cross Validation with Ultralytics - Ultralytics YOLO Docs</source><date-in-citation>cited 2025 Jul 15</date-in-citation><comment>Internet [Internet] Available from: <ext-link ext-link-type="uri" xlink:href="https://docs.ultralytics.com/guides/kfold-cross-validation/">https://docs.ultralytics.com/guides/kfold-cross-validation/</ext-link></comment></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Szeghalmy</surname><given-names>S</given-names></name><name><surname>Fazekas</surname><given-names>A</given-names></name></person-group><article-title>A Comparative Study of the Use of Stratified Cross-Validation and Distribution-Balanced Stratified Cross-Validation in Imbalanced Learning</article-title><source>Sensors</source><year>2023</year><month>Feb</month><day>20</day><volume>23</volume><issue>4</issue><elocation-id>2333</elocation-id><pub-id pub-id-type="doi">10.3390/s23042333</pub-id><pub-id pub-id-type="pmcid">PMC9967638</pub-id><pub-id pub-id-type="pmid">36850931</pub-id></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="web"><source>Model Training with Ultralytics YOLO - Ultralytics YOLO Docs</source><date-in-citation>cited 2025 Jul 15</date-in-citation><comment>Internet [Internet] Available from: <ext-link ext-link-type="uri" xlink:href="https://docs.ultralytics.com/modes/train/">https://docs.ultralytics.com/modes/train/</ext-link></comment></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="web"><article-title>Ultralytics YOLO Hyperparameter Tuning Guide - Ultralytics YOLO Docs</article-title><date-in-citation>cited 2025 Jul 15</date-in-citation><comment>Internet [Internet] Available from: <ext-link ext-link-type="uri" xlink:href="https://docs.ultralytics.com/guides/hyperparameter-tuning/">https://docs.ultralytics.com/guides/hyperparameter-tuning/</ext-link></comment></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="web"><source>Performance Metrics Deep Dive - Ultralytics YOLO Docs</source><date-in-citation>cited 2025 Jul 15</date-in-citation><comment>Internet [Internet] Available from: <ext-link ext-link-type="uri" xlink:href="https://docs.ultralytics.com/guides/yolo-performance-metrics/">https://docs.ultralytics.com/guides/yolo-performance-metrics/</ext-link></comment></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="web"><collab>CustomTkinter</collab><date-in-citation>cited 2025 Jul 15</date-in-citation><comment>[Internet] Available from: <ext-link ext-link-type="uri" xlink:href="https://github.com/TomSchimansky/CustomTkinter">https://github.com/TomSchimansky/CustomTkinter</ext-link></comment></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="web"><source>tkinter — Python interface to Tcl/Tk</source><date-in-citation>cited 2025 Jul 15</date-in-citation><comment>[Internet] Available from: <ext-link ext-link-type="uri" xlink:href="https://docs.python.org/3/library/tkinter.html">https://docs.python.org/3/library/tkinter.html</ext-link></comment></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="web"><collab>Pillow</collab><date-in-citation>cited 2025 Jul 15</date-in-citation><comment>[Internet] Available from: <ext-link ext-link-type="uri" xlink:href="https://github.com/python-pillow/Pillow">https://github.com/python-pillow/Pillow</ext-link></comment></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="web"><collab>openCV</collab><date-in-citation>cited 2025 Jul 15</date-in-citation><comment>[Internet] Available from: <ext-link ext-link-type="uri" xlink:href="https://github.com/opencv/opencv">https://github.com/opencv/opencv</ext-link></comment></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Virtanen</surname><given-names>P</given-names></name><name><surname>Gommers</surname><given-names>R</given-names></name><name><surname>Oliphant</surname><given-names>TE</given-names></name><name><surname>Haberland</surname><given-names>M</given-names></name><name><surname>Reddy</surname><given-names>T</given-names></name><name><surname>Cournapeau</surname><given-names>D</given-names></name><etal/></person-group><article-title>SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python</article-title><source>Nat Methods</source><year>2020</year><volume>17</volume><fpage>261</fpage><lpage>72</lpage><comment>[Internet]</comment><pub-id pub-id-type="doi">10.1038/s41592-019-0686-2</pub-id><pub-id pub-id-type="pmcid">PMC7056644</pub-id><pub-id pub-id-type="pmid">32015543</pub-id></element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kruchten</surname><given-names>N</given-names></name><name><surname>Seier</surname><given-names>A</given-names></name><name><surname>Parmer</surname><given-names>C</given-names></name></person-group><article-title>An interactive, open-source, and browser-based graphing library for Python</article-title><year>2024</year><comment>[Internet] Available from: <ext-link ext-link-type="uri" xlink:href="https://github.com/plotly/plotly.py">https://github.com/plotly/plotly.py</ext-link></comment></element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shwartz-Ziv</surname><given-names>R</given-names></name><name><surname>Goldblum</surname><given-names>M</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Bruss</surname><given-names>CB</given-names></name><name><surname>Wilson</surname><given-names>AG</given-names></name></person-group><article-title>Simplifying neural network training under class imbalance</article-title><source>Adv Neural Inf Process Syst</source><year>2023</year><volume>36</volume><fpage>35218</fpage><lpage>45</lpage></element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Santos</surname><given-names>MS</given-names></name><name><surname>Abreu</surname><given-names>PH</given-names></name><name><surname>Japkowicz</surname><given-names>N</given-names></name><name><surname>Fernández</surname><given-names>A</given-names></name><name><surname>Santos</surname><given-names>J</given-names></name></person-group><article-title>A unifying view of class overlap and imbalance: Key concepts, multi-view panorama, and open avenues for research</article-title><source>Information Fusion</source><year>2023</year><month>Jan</month><volume>89</volume><fpage>228</fpage><lpage>53</lpage></element-citation></ref></ref-list></back><floats-group><boxed-text id="BX1" position="float" orientation="portrait"><label>Author Summary</label><p>We developed TU_MyCo-Vision to address challenges in fungal microscopic imaging. Fungi, such as <italic>Aureobasidium pullulans</italic>, display a remarkable ability to switch cell shapes (up to thirteen in this species alone) depending on their environment. While microscopy remains a popular method for observing these changes, manual analysis is limited by individual expertise and the number of images that can be processed, often making results subjective and difficult to scale. To overcome these challenges, we built an Ultralytics YOLOv11-based cell detector that can automatically detect and categorize thirteen fungal cell shapes from brightfield microscopic images. We designed TU_MyCo-Vision to be accessible, with a simple graphical user interface, integrated data analysis suite, and distribution as a standalone application for both Windows and macOS, so it can be used even by those with limited computational skills. Our tool demonstrated strong performance, achieving over 73% precision. Importantly, it also worked well on images from other fungal species, showing potential to be further developed as a general fungal cell morphology tool. We hope TU_MyCo-Vision will contribute to making standardized, high-throughput phenotyping of fungi accessible to a broader community.</p></boxed-text><fig id="F1" position="float"><label>Figure 1</label><caption><p>Representative full-size (1920 × 1080 pixels) microscopic image of A.pullulans (left panel) cropped into six unique 640 × 640 pixel crops (right panel) as part of the dataset expansion strategy.</p></caption><graphic xlink:href="EMS207528-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><p>TU_MyCo-Vision classes and representative cell morphologies, highlighted with white rectangular boxes. C1, C2, and C2-B are vacuolated cells. C3-B are cells with granular cytoplasm. C5 are general yeast-like cells lacking any special features. C9 cells are spheroidal-shaped cells. C4, C6, and C11 are special cell types representing budding events, cell clumping/aggregates, and irregular cell shapes. C7-E (septate hyphae/ pseudo hyphae), C7-G (smooth continuous filamentous/true hyphae), and C7-F (vacuolated hyphae) are filamentous cell classes.</p></caption><graphic xlink:href="EMS207528-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><p>(Left Panel) Fitness vs. iteration plot. Fitness scores across 45 iterations of hyperparameter tuning. The dotted line indicates a smoothed trend. Scatter plots of tuned hyperparameters vs. fitness. (Right Panel) Each subplot shows the relationship between the hyperparameter and resulting fitness scores during the hyperparameter evolution. Annotated values indicate the best-performing parameters. Parameters set to ‘0’ were not tuned during hyperparameter evolution.</p></caption><graphic xlink:href="EMS207528-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><p>Normalized confusion matrix (left) of the Zulu_s3 model validated on the global test set. Precision-all Curve (right) of the zulu_s3 model validated on the global test set.</p></caption><graphic xlink:href="EMS207528-f004"/></fig><fig id="F5" position="float"><label>Figure 5a</label><caption><p>Detection panel, enabling users to select input/output folders, select morphological classes, adjust model parameters, and execute prediction. <xref ref-type="fig" rid="F5">Figure 5b</xref>. Result Dashboard panel image viewer displaying paired original and annotated images side-by-side, with navigation panel. <xref ref-type="fig" rid="F5">Figure 5c</xref>. Analysis panel, which includes the class exclusion feature and options for single-group and multi-group analysis, along with the option to select input/output folders and analysis name. <xref ref-type="fig" rid="F5">Figure 5d</xref>. Results Dashboard panel CSV data table view.</p></caption><graphic xlink:href="EMS207528-f005"/></fig><fig id="F6" position="float"><label>Figure 6a</label><caption><p>Normalized stacked bar plot representing morphological composition across 90 test set images. <xref ref-type="fig" rid="F6">Figure 6b</xref>: Mean relative abundance (%) of each morphological class across all images. <xref ref-type="fig" rid="F6">Figure 6c</xref>: Relative abundance (%) of each morphological class across the dataset. <xref ref-type="fig" rid="F6">Figure 6d</xref>: Relative abundance based hierarchically clustered heatmap.</p></caption><graphic xlink:href="EMS207528-f006"/></fig><fig id="F7" position="float"><label>Figure 7a</label><caption><p>Normalized stacked bar plot of morphological composition in 90 test set images after enabling class exclusion, where C7-E, C7-F, and C7-G (filamentous morphologies) are grouped into the “Others” class. <xref ref-type="fig" rid="F7">Figure 7b</xref>: Mean relative abundance (%) of morphological classes after applying class exclusion. <xref ref-type="fig" rid="F7">Figure 7c</xref>: Relative abundance (%) of classes post-class exclusion. <xref ref-type="fig" rid="F7">Figure 7d</xref>: Relative abundance based hierarchically clustered heatmap post-class exclusion.</p></caption><graphic xlink:href="EMS207528-f007"/></fig><fig id="F8" position="float"><label>Figure 8a</label><caption><p>Normalized stacked bar plot representing morphological composition across four groups: Komagataella_GS115, Komagataella strain set_A, Candida, and spores. Each bar represents relative proportions of thirteen morphotypes, revealing population structure between groups. <xref ref-type="fig" rid="F8">Figure 8b</xref>: Mean relative abundance (%) of each morphological class per group, providing an overview of morphological composition across groups. <xref ref-type="fig" rid="F8">Figure 8c</xref>: Relative abundance (%) of morphological class within groups. <xref ref-type="fig" rid="F8">Figure 8d</xref>: Relative abundance based hierarchically clustered heatmap by group.</p></caption><graphic xlink:href="EMS207528-f008"/></fig><table-wrap id="T1" orientation="portrait" position="float"><label>Table 1</label><caption><title>Detailed description of object classes in TU_MyCo-Vision</title></caption><table frame="box" rules="groups"><thead><tr><th valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Class</th><th valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Cell Shape</th><th valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">Description</th></tr></thead><tbody><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">C1</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Ovoid, oblong, spheroidal,<break/>elongated</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">Eye-like or egg-like appearance due to the presence of a single vacuole-like structure</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">C2</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Ovoid, oblong, spheroidal,<break/>elongated</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">Binocular appearance due to dual vacuole-like structures</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">C2-B</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Ovoid, oblong, spheroidal,<break/>elongated</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid">Multiple vacuole-like structures</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">C3-B</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Ovoid, oblong, spheroidal,<break/>elongated</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">The granular appearance of the cytoplasm due to small bead-like structures</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">C4</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">NA</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">Indicates budding events</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">C5</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">Ovoid, oblong, elongated</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">Lacks any distinctive morphological features.<break/>Includes all yeast like cells</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">C6</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">NA</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">Cell aggregates and clumping</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">C8</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">NA</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">Septate cells</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">C9</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">Spheroidal</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">Spherical/Spheroidal cells without distinctive<break/>morphological features</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">C11</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">NA</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">Irregular-shaped cells that cannot be categorized in the other classes</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">C7-E</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">Filamentous</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">Filaments with an appearance similar to septate hyphae</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">C7-F</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Filamentous</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">Filaments with vacuole-like structures</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid #000000">C7-G</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid #000000">Filamentous</td><td valign="top" align="left" style="border: 1px solid #000000">Smooth filaments without any distinctive features</td></tr></tbody></table></table-wrap><table-wrap id="T2" orientation="portrait" position="float"><label>Table 2</label><caption><title>Comparative summary of average performance metrics across five dataset splits of X-ray, Yankee, and Zulu model families evaluated on the validation dataset</title></caption><table frame="box" rules="groups"><thead><tr><th valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">Metric</th><th valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">X-ray</th><th valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">Yankee</th><th valign="top" align="left" style="border:solid 1px #000000">Zulu</th></tr></thead><tbody><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Dataset version (No. of<break/>images)</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">1028</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">1002</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">1504 (Manual + auto<break/>labelled)</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">Architecture</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">YOLOv8x</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">YOLOv11m</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid">YOLOv11m</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Best Split</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">xray_split4</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">yankee_split5</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">zulu_split1</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Highest mAP@50-95 at epoch</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">309</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">405</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">483</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Precision (mean ± SD)</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">71.56 ± 0.0174</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">72.43 ± 0.0160</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">74.59 ± 0.0230</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Recall (mean ± SD)</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">71.83 ± 0.0356</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">71.67 ± 0.0203</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">72.97 ± 0.0163</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">mAP@50 (mean ± SD)</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">0.7443 ± 0.0202</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid #000000">0.7535 ± 0.0147</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">0.7745 ± 0.0106</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid #000000">mAP@50-95 (mean ± SD)</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid #000000">0.5360 ± 0.0127</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid #000000">0.5357 ± 0.0096</td><td valign="top" align="left" style="border: 1px solid #000000">0.5732 ± 0.0123</td></tr></tbody></table></table-wrap><table-wrap id="T3" orientation="portrait" position="float"><label>Table 3</label><caption><title>Precision, Recall, and mAP@50-95 performance comparison of all TU_MyCo-Vision model families on the global test dataset</title></caption><table frame="box" rules="groups"><thead><tr><th valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">Model</th><th valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">Precision</th><th valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">Recall</th><th valign="top" align="center" style="border:solid 1px #000000">mAP@50-95</th></tr></thead><tbody><tr><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>xray_s1</bold></td><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0,708</td><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0,65</td><td valign="top" align="center" style="border:solid 1px #000000">0,496</td></tr><tr><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>xray_s2</bold></td><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0,64</td><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0,661</td><td valign="top" align="center" style="border:solid 1px #000000">0,511</td></tr><tr><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>xray_s3</bold></td><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0,691</td><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0,604</td><td valign="top" align="center" style="border:solid 1px #000000">0,513</td></tr><tr><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>xray_s4</bold></td><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0,631</td><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0,649</td><td valign="top" align="center" style="border:solid 1px #000000">0,493</td></tr><tr><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>xray_s5</bold></td><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0,64</td><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0,648</td><td valign="top" align="center" style="border:solid 1px #000000">0,494</td></tr><tr><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>yankee_s1</bold></td><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0,659</td><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0,649</td><td valign="top" align="center" style="border:solid 1px #000000">0,505</td></tr><tr><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>yankee_s2</bold></td><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0,619</td><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0,68</td><td valign="top" align="center" style="border:solid 1px #000000">0,498</td></tr><tr><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>yankee_s3</bold></td><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0,653</td><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0,676</td><td valign="top" align="center" style="border:solid 1px #000000">0,518</td></tr><tr><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>yankee_s4</bold></td><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0,705</td><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0,661</td><td valign="top" align="center" style="border:solid 1px #000000">0,521</td></tr><tr><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>yankee_s5</bold></td><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0,686</td><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0,684</td><td valign="top" align="center" style="border:solid 1px #000000">0,526</td></tr><tr><td valign="top" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000"><bold>zulu_s1</bold></td><td valign="top" align="center" style="border-top: 1px solid #000000;border-left: 1px solid">0,658</td><td valign="top" align="center" style="border-top: 1px solid #000000;border-left: 1px solid">0,664</td><td valign="top" align="center" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid">0,521</td></tr><tr><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>zulu_s2</bold></td><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0,715</td><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0,612</td><td valign="top" align="center" style="border:solid 1px #000000">0,519</td></tr><tr><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>zulu_s3</bold></td><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0,734</td><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0,665</td><td valign="top" align="center" style="border:solid 1px #000000">0,545</td></tr><tr><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>zulu_s4</bold></td><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0,638</td><td valign="top" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0,717</td><td valign="top" align="center" style="border:solid 1px #000000">0,527</td></tr><tr><td valign="top" align="center" style="border:solid 1px #000000"><bold>zulu_s5</bold></td><td valign="top" align="center" style="border:solid 1px #000000">0,715</td><td valign="top" align="center" style="border:solid 1px #000000">0,679</td><td valign="top" align="center" style="border:solid 1px #000000">0,546</td></tr></tbody></table></table-wrap><table-wrap id="T4" orientation="portrait" position="float"><label>Table 4</label><caption><title>Class-wise performance metrics of the zulu_s3 model evaluated on the global test dataset</title></caption><table frame="box" rules="groups"><thead><tr><th valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">zulu_s3</th><th valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">Class</th><th valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">Images</th><th valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">Instances</th><th valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">Precision</th><th valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">Recall</th><th valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">mAP@50</th><th valign="top" align="left" style="border:solid 1px #000000">mAP@50-95</th></tr></thead><tbody><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid"/><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>all</bold></td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">166</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">956</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.734</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.665</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.735</td><td valign="top" align="left" style="border:solid 1px #000000">0.545</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid"/><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>C2</bold></td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">27</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">55</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.839</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.851</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.912</td><td valign="top" align="left" style="border:solid 1px #000000">0.730</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid"/><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>C5</bold></td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">77</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">229</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.709</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.789</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.792</td><td valign="top" align="left" style="border:solid 1px #000000">0.587</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid"/><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>C1</bold></td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">31</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">78</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.762</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.731</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.844</td><td valign="top" align="left" style="border:solid 1px #000000">0.677</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid"/><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>C4</bold></td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">63</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">139</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.811</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.475</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.622</td><td valign="top" align="left" style="border:solid 1px #000000">0.327</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid"/><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid"><bold>C6</bold></td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">16</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">25</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">0.639</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">0.600</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">0.699</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid">0.560</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid"/><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>C11</bold></td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">8</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">12</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.613</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.583</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.612</td><td valign="top" align="left" style="border:solid 1px #000000">0.480</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid"/><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>C9</bold></td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">27</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">38</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.557</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.579</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.583</td><td valign="top" align="left" style="border:solid 1px #000000">0.459</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid"/><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>C2-B</bold></td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">28</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">95</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.865</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.739</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.887</td><td valign="top" align="left" style="border:solid 1px #000000">0.729</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid"/><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>C3-B</bold></td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">36</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">74</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.778</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.949</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.900</td><td valign="top" align="left" style="border:solid 1px #000000">0.730</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid"/><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>C8</bold></td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">20</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">26</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.900</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.846</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.897</td><td valign="top" align="left" style="border:solid 1px #000000">0.790</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid"/><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid"><bold>C7-E</bold></td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">36</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">65</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">0.664</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">0.446</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid">0.577</td><td valign="top" align="left" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid">0.338</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-left: 1px solid"/><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000"><bold>C7-F</bold></td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">32</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">49</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.720</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.571</td><td valign="top" align="left" style="border-top:solid 1px #000000;border-left:solid 1px #000000">0.712</td><td valign="top" align="left" style="border:solid 1px #000000">0.391</td></tr><tr><td valign="top" align="left" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid"/><td valign="top" align="left" style="border:solid 1px #000000"><bold>C7-G</bold></td><td valign="top" align="left" style="border:solid 1px #000000">30</td><td valign="top" align="left" style="border:solid 1px #000000">71</td><td valign="top" align="left" style="border:solid 1px #000000">0.680</td><td valign="top" align="left" style="border:solid 1px #000000">0.479</td><td valign="top" align="left" style="border:solid 1px #000000">0.517</td><td valign="top" align="left" style="border:solid 1px #000000">0.291</td></tr></tbody></table></table-wrap></floats-group></article>