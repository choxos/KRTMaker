<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS205781</article-id><article-id pub-id-type="doi">10.1101/2025.05.19.654889</article-id><article-id pub-id-type="archive">PPR1023882</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">1</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Sound offset responses become highly informative in the auditory cortex</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><name><surname>Lamothe</surname><given-names>Charly</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Bagur</surname><given-names>Sophie</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Gosselin</surname><given-names>Etienne</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Bathellier</surname><given-names>Brice</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="corresp" rid="CR1">*</xref></contrib><aff id="A1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05f82e368</institution-id><institution>Université Paris Cité</institution></institution-wrap>, <institution-wrap><institution-id institution-id-type="ror">Institut Pasteur</institution-id><institution>Institut Pasteur</institution></institution-wrap>, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/00pg5jh14</institution-id><institution>AP-HP</institution></institution-wrap>, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/02vjkv261</institution-id><institution>INSERM</institution></institution-wrap>, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/02feahw73</institution-id><institution>CNRS</institution></institution-wrap>, Fondation Pour l’Audition, Institut de l’Audition, IHU reConnect, <postal-code>F-75012</postal-code><city>Paris</city>, <country country="FR">France</country></aff><aff id="A2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03padqz24</institution-id><institution>Brain Plasticity Unit</institution></institution-wrap>, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/02feahw73</institution-id><institution>CNRS</institution></institution-wrap>, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/03zx86w41</institution-id><institution>ESPCI-Paris</institution></institution-wrap>, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/013cjyk83</institution-id><institution>PSL Research University</institution></institution-wrap>, <city>Paris</city>, <country country="FR">France</country></aff></contrib-group><author-notes><corresp id="CR1">
<label>*</label>Corresponding author: <email>brice.bathellier@cnrs.fr</email>
</corresp></author-notes><pub-date pub-type="nihms-submitted"><day>23</day><month>05</month><year>2025</year></pub-date><pub-date pub-type="preprint"><day>21</day><month>05</month><year>2025</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">The entire auditory system downstream of the cochlea features pronounced offset responses, which follow the termination of sounds. Because of their ubiquity, it is still an unsolved question whether offset responses are generated early in the auditory system and then propagated or recomputed at each processing stage. Here, we analysed large-scale sound responses datasets acquired in the cochlear nucleus, inferior colliculus, medial geniculate nucleus and auditory cortex of awake mice. All brain regions showed a significant proportion of offset responses often combined with onset and sustained responses in the same neuron. However, using population activity decoders, we observed that neural representations after the sound offset show a three-fold increase in sound encoding accuracy in the cortex relative to subcortical areas. This result indicates that cortical offsets encode a more precise short-term memory of the elapsed sound than subcortical offsets and that they likely result from specific computational steps.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P2">Sensory processing is a dynamic phenomenon with a high sensitivity to temporal variations of the stimulus at different time scales. This is particularly acute in the auditory system, which processes complex temporal signals to extract a large range of meaningful features. Response dynamics in the auditory system include salient transient responses at the beginning and at the termination of sounds, often termed sound onset and offset respectively (<xref ref-type="bibr" rid="R12">Eggermont, 2015</xref>; <xref ref-type="bibr" rid="R19">Kopp-Scheinpflug et al., 2018</xref>). Transient onset responses are already present in the auditory nerve, where they mainly reflect adaptation, and are then observed throughout the auditory system. By contrast, no strong elevation of the firing rate is observed in the auditory nerve at sound termination, with some reports of weak inhibitory and excitatory offset responses (<xref ref-type="bibr" rid="R17">Grinnell, 1973</xref>; <xref ref-type="bibr" rid="R27">Scheidt et al., 2010</xref>; <xref ref-type="bibr" rid="R34">Westerman and Smith, 1984</xref>; <xref ref-type="bibr" rid="R36">Yin et al., 2019</xref>). Excitatory offset responses actually emerge in the cochlear nucleus (<xref ref-type="bibr" rid="R19">Kopp-Scheinpflug et al., 2018</xref>; <xref ref-type="bibr" rid="R31">Suga, 1964</xref>) and are present in all downstream stages of the main auditory system. Offset responses are thought to be important to signal sound terminations (<xref ref-type="bibr" rid="R2">Anderson and Linden, 2016</xref>; <xref ref-type="bibr" rid="R22">Li et al., 2021</xref>; <xref ref-type="bibr" rid="R30">Solyga and Barkat, 2021</xref>), gap detection (<xref ref-type="bibr" rid="R3">Awwad et al., 2020</xref>), or more generally any abrupt decrease of the sound intensity, which are part of the amplitude modulation features that the brain uses to interpret natural sounds (<xref ref-type="bibr" rid="R8">Bregman, 1994</xref>; <xref ref-type="bibr" rid="R12">Eggermont, 2015</xref>; <xref ref-type="bibr" rid="R20">Kuwada and Batra, 1999</xref>). Offset responses are also recruited by predictive processes, at least in the cortex, to signal omissions of expected gaps (<xref ref-type="bibr" rid="R4">Awwad et al., 2023</xref>). However, beyond this widely accepted but very general concept, it remains unclear what information is actually contained in offset responses and if this information is equivalent at all stages of the auditory system. On the one hand, offset responses could be an unspecific termination signal, independent of the sound that has just ended. On the other hand, offset responses could be a highly specific signal that reflects not only the termination but also the identity of the sound. For pure tones, frequency specificity of offset responses has long been established at diverse stages (<xref ref-type="bibr" rid="R18">Kasai et al., 2012</xref>; <xref ref-type="bibr" rid="R19">Kopp-Scheinpflug et al., 2018</xref>; <xref ref-type="bibr" rid="R35">Xie et al., 2007</xref>). This is however insufficient to assess if the offset response precisely encodes the identity of the elapsed sound, because this identity depends on complex combinations of frequency and temporal features which cannot be probed with pure tones. In order to determine the level of acoustic information in offset responses, we have analysed sound-driven activity from several thousands of neurons in two recent datasets produced by our laboratory and freely available online. These two datasets contain neural recordings at the four stages of the auditory system from the cochlear nucleus to the auditory cortex. We observed that the offset responses present at all considered stages have similar properties at the single cell level. However, strikingly, when decoding the identity of elapsed sounds based on neural population responses built from offset responses, we observed a much better performance in the auditory cortex than in subcortical regions. This marked difference suggests that cortical processing not only signals sound termination but also constructs at sound offset a rich, transiently maintained representation of the elapsed sound.</p></sec><sec id="S2" sec-type="results"><title>Results</title><sec id="S3"><title>Offset responses are prominent at all stages of the auditory system</title><p id="P3">This study is based on two datasets shared in open source repositories (<xref ref-type="bibr" rid="R5">Bagur and Bathellier, 2024</xref>; <xref ref-type="bibr" rid="R14">Gosselin, 2024</xref>). The first dataset (<xref ref-type="fig" rid="F1">Fig. 1A&amp;B</xref>) (<xref ref-type="bibr" rid="R14">Gosselin, 2024</xref>) is more extensively described in a parallel study (<xref ref-type="bibr" rid="R16">Gosselin et al., 2025</xref>), which does not focus on offset responses. It includes Neuropixels recordings in awake mice that sampled 1421 putative neurons (single units) in the cochlear nucleus (CN, ephys 1) and 551 single units in the inferior colliculus (IC, ephys 1). This dataset also includes two-photon calcium imaging of 4217 neurons in the auditory cortex of awake mice (AC, 2P 2). Note that response variability was larger in the auditory cortex dataset, as measured through the correlation across single trials responses for the same sound averaged across all neurons and sounds (<xref ref-type="fig" rid="F1">Fig. 1C</xref>). For all sampled neurons of this dataset, we collected responses to 307 different sounds, each repeated 12 times. For this study, we kept 119 sounds that are all 500 ms long and contain different spectral (pure tones, frequency chords, white noise) and temporal (frequency sweeps, rhythmic and oriented amplitude modulations) features (<xref ref-type="fig" rid="F1">Fig. 1D</xref>). The second dataset (<xref ref-type="fig" rid="F1">Fig. 1A&amp;B</xref>) (<xref ref-type="bibr" rid="R5">Bagur and Bathellier, 2024</xref>) was already used to describe population representations of simple time-varying sounds (<xref ref-type="bibr" rid="R6">Bagur et al., 2025</xref>). It includes silicon probe recordings in awake mice that sampled 442 putative neurons (single units) in the inferior colliculus (IC, ephys 2) and 484 single units in the medial geniculate nucleus (TH, ephys 2). This dataset also includes two-photon calcium imaging of 5936 neurons in the dorsal inferior colliculus (IC, 2P 2) and 19 414 neurons in the auditory cortex of awake mice (AC, 2P 2). As in dataset 1, larger response variability is observed in two-photon imaging data of dataset 2 as reported in (<xref ref-type="bibr" rid="R6">Bagur et al., 2025</xref>) with the same measure as in <xref ref-type="fig" rid="F1">Fig. 1C</xref>. For all sampled neurons of this dataset, we collected responses to 140 different sounds, each repeated 15 times. For this study, we kept 112 sounds that are all 500 ms long and contain different spectral (pure tones, frequency chords) and temporal (frequency sweeps and oriented amplitude modulations) features (<xref ref-type="fig" rid="F1">Fig. 1D</xref>). For extracellular electrophysiology data, single units were identified with Kilosort 2.5 (<xref ref-type="bibr" rid="R25">Pachitariu et al., 2024</xref>) combined with manual curation in Phy. For calcium imaging data, motion correction and neuron segmentation was performed with freely available tools (see <xref ref-type="sec" rid="S11">Methods</xref>), and the data was temporally deconvolved using a simple linear algorithm allowing to achieve a temporal precision of about 3 Hz (<xref ref-type="bibr" rid="R6">Bagur et al., 2025</xref>) which is sufficient to separately identify onset and offset responses for the 500 ms sounds selected in this study (<xref ref-type="fig" rid="F2">Fig. 2</xref>).</p><p id="P4">Plotting response traces of sample neurons from all four recorded regions, we observed, consistent with previous observations, that offset responses were present at all stages of the central auditory system. Of note, the temporal deconvolution of calcium imaging signals in the two-photon datasets (cortex and colliculus) removes the effects of the slow decay time constant of calcium dynamics but does not cancel the effects related to the slow rise time constant of GCAMP6s (∼50 to 100 ms). Therefore, the peak of offset responses in calcium imaging datasets (e.g. <xref ref-type="fig" rid="F2">Fig. 2A</xref>) occurred typically 100 ms later than for electrophysiology recordings (<xref ref-type="fig" rid="F2">Fig. 2A</xref>). At all stages, offset response duration could be short (few tens of millisecond) or prolonged (&gt;100 ms), indicating that long time-scales of activity are not specific to the cortex or to calcium imaging data. This was evident both on single cell traces (<xref ref-type="fig" rid="F2">Fig. 2A</xref>) and on heat maps representing all cell responses ordered according to the offset amplitudes (<xref ref-type="fig" rid="F2">Fig. 2B</xref>). In the latter plots, it is also clear that offset responses can be excitatory or inhibitory (<xref ref-type="fig" rid="F2">Fig. 2B</xref>).</p><p id="P5">Offset responses were observed for pure tones (<xref ref-type="fig" rid="F2">Fig. 2A-B</xref>) but also for broad frequency sounds such as white noise (<xref ref-type="fig" rid="F2">Fig. 2C</xref>). We also observed, consistent with various reports (<xref ref-type="bibr" rid="R28">Scholl et al., 2010</xref>; <xref ref-type="bibr" rid="R29">Sollini et al., 2018</xref>; <xref ref-type="bibr" rid="R35">Xie et al., 2007</xref>), that offset responses often co-occurred with excitatory or inhibitory onset or sustained responses (<xref ref-type="fig" rid="F2">Fig. 2A</xref>). This indicated, as previously seen (<xref ref-type="bibr" rid="R19">Kopp-Scheinpflug et al., 2018</xref>), that many neurons are not dedicated to offset responses.</p></sec><sec id="S4"><title>Offset responses are complex at all stages of the auditory system</title><p id="P6">To evaluate if this mixed specificity of neurons to onset, sustained, or offset phases appears early or late in the auditory system, we systematically identified statistically significant responses in these three phases (<xref ref-type="fig" rid="F3">Fig. 3A</xref>, time bins: baseline -200 to 0 ms, onset 0 to 150 ms, sustained 150 to 500 ms, offsets 500 to 650 ms for electrophysiology and 600 to 750 ms for 2P-imaging). Significant onset, sustained, and offset responses were identified by comparing firing rates during the onset and baseline periods using a non-parametric test (<xref ref-type="fig" rid="F3">Fig. 3A</xref>, see <xref ref-type="sec" rid="S11">Methods</xref>). For offset responses, we used two non-independent non-parametric tests (<xref ref-type="fig" rid="F3">Fig. 3A</xref>) to determine if offset activity is different from both the baseline and the sustained response. For onset, sustained and offset the maximal false discovery rate was 5%, based on the alpha value of the tests (note that the two tests of offset detection being non-independent, the overall, conservative false discovery rate is also 5%, see <xref ref-type="sec" rid="S11">Methods</xref>).</p><p id="P7">Based on this approach, we first quantified the fraction of all sound responses (number of sounds × number of neurons) that included a significant offset response (positive or negative) at each recorded auditory system stage (<xref ref-type="fig" rid="F3">Fig. 3B</xref>). We found this fraction to be between 11.67% and 12.65% in dataset 1 and between 11.91% and 17.31% in dataset 2, therefore systematically above the 5% chance level, consistent with the reported sparseness of offset responses. We then estimated the fraction of neurons with at least one offset response using the signed-rank tests for responses to individual sounds, but applying the Benjamini-Hochberg procedure to correct for multiple testing (119 and 112 tests per neuron in datasets 1 and 2 respectively). These estimates are likely conservative due to the low number of sound repetitions, which limits the statistical power of this offset-neuron identification procedure, with presumably many false negative detections. In dataset 1, in which we observed fewer responses (<xref ref-type="fig" rid="F3">Fig. 3B</xref>), the fraction of neurons with detected offset is roughly equal to or below the chance level: 7.28% for CN, 8.29% for IC, 3.01% for AC (<xref ref-type="fig" rid="F3">Fig. 3C</xref>). In dataset 2, the fraction of neurons with detected offset is clearly above chance level: 18.85% for IC_2P, 19.61% for IC_ephys, 18.44% for TH, 19.27% for AC (<xref ref-type="fig" rid="F3">Fig. 3C</xref>). Using the results of the same statistical procedure, including correction for multiple testing, we also plotted the distribution of the number of offset responses per neuron. We observed that less than 50% of the neurons responded at the offset of more than 20 sounds, yet with an even narrower distribution for datasets derived from two-photon calcium imaging (IC and AC, <xref ref-type="fig" rid="F3">Fig. 3D</xref>). This analysis thus suggests that single cell level measurements can be biased by the properties of the recorded signals, with, for example, an apparent smearing of offset response distributions in calcium imaging data, which is likely due to the larger signal variability with this recording modality as measured <xref ref-type="fig" rid="F1">Fig. 1C</xref> and (<xref ref-type="bibr" rid="R6">Bagur et al., 2025</xref>). Beyond these discrepancies, this analysis highlights no clear progression of the offset distribution among neurons, except that IC seems to be the structure with the largest fraction of neurons displaying many offset responses compared to CN and TH (<xref ref-type="fig" rid="F3">Fig. 3D</xref>).</p><p id="P8">We then reasoned that different auditory system stages could have different degrees of offset specificity with respect to onset and sustained responses. We therefore plotted in <xref ref-type="fig" rid="F3">Fig. 3E</xref> the fractions of all possible combinations of an offset response (either positive, OFF E, or negative, OFF I) with onset (ON E, ON I or none) and sustained (E, I or none) responses. Note that this analysis is done response-by-response and not neuron-by-neuron, and that the fractions are given with respect to the total number of responses with a significant offset response. We observed a fraction of about 40 to 50% pure positive offset responses (OFF E) in the two-photon imaging datasets (<xref ref-type="fig" rid="F3">Fig. 3E</xref>), while in the electrophysiology datasets, this fraction was down to 20 to 40%, with variable results across datasets (e.g. IC ephys - dataset 1: 34.58% and dataset 2: 16.97%, <xref ref-type="fig" rid="F3">Fig. 3E</xref>). Consistent with our sample data plots of <xref ref-type="fig" rid="F2">Fig. 2B&amp;C</xref>, the fraction of pure negative offset was non-negligible (∼ 10 to 25% across datasets). The most prominent responses combined with excitatory offsets were sustained excitatory or inhibitory responses (Sustained E OFF E or Sustained I OFF E, <xref ref-type="fig" rid="F3">Fig. 3E</xref>), or excitatory responses both in the onset and sustained phases (ON E Sustained E OFF E, <xref ref-type="fig" rid="F3">Fig. 3E</xref>) or inhibitory responses both in the onset and sustained phases (ON I Sustained I OFF E, <xref ref-type="fig" rid="F3">Fig. 3E</xref>). However, inhibitory responses before the offset were only detected in electrophysiology datasets (<xref ref-type="fig" rid="F3">Fig. 3E</xref>). The most prominent responses combined with inhibitory offsets are monophasic onset and sustained responses, either inhibitory or excitatory (ON I Sustained I OFF E, ON E Sustained E OFF I, <xref ref-type="fig" rid="F3">Fig. 3E</xref>). However these combinations were also only detected in electrophysiology data, and yet again with some variability, across the IC replicate which could be due to differences in stimulus properties, recording conditions, or neural population sampling (<xref ref-type="fig" rid="F3">Fig. 3E</xref>). Altogether, this analysis of combined response type distributions highlighted clear biases across recording modalities likely related to the higher variability of calcium responses, and to their lesser sensitivity to inhibitory response (but note that many inhibitory offset responses were detected with calcium imaging). Beyond this pertaining issue, the analysis shows that, across the auditory system, offsets are often combined with earlier responses. Moreover, at all stages, there was a large fraction of responses with an excitatory offset only. Hence, we did not observe any clear evolution of neurons with offset specific responses and no clear evolution of their combination with onset and sustained response, although these differences may have been missed due to the unreliability of response detection. Both due to the rich and distributed nature of offset responses and to the difficulties encountered with signal variability at the single cell level, we reasoned that a population level analysis would be better suited to identify changes in the neural code carried by offset responses.</p></sec><sec id="S5"><title>Populations of offset responses are more informative in the auditory cortex</title><p id="P9">We therefore decided to measure the amount of sound information carried by the entire neural populations of each auditory system stage sampled in our dataset. Using the same analysis windows as previously defined, we constructed virtual population vectors by concatenating responses measured in all neurons across all recordings (<xref ref-type="fig" rid="F4">Fig. 4A</xref>). Population vectors were then fed to a 5-fold cross-validated logistic regression decoder to evaluate the fraction of correct sound identity predictions that can be obtained from single trial activity of the neural population. We first established a ceiling of the information available in the full spatio-temporal activity pattern. We sampled the full time-course of the population into 65 time bins of 10 ms duration, concatenated the 65 vectors and submitted them to the same decoder. This showed similar information levels across stages, as shown previously, for dataset 2 (<xref ref-type="bibr" rid="R6">Bagur et al., 2025</xref>) and lower information level in cortex in dataset 1 (<xref ref-type="fig" rid="F4">Fig. 4B</xref>), likely due to the poorer SNR in calcium imaging for dataset 1 (<xref ref-type="fig" rid="F1">Fig. 1C</xref>). We then ran population decoders based on the time-averaged vectors obtained separately for onset, sustained, and offset time windows using the previously defined windows for each auditory system stage. To equalize across different dataset qualities, we reported the decoder accuracy computed for a specific time-bin divided by the ceiling accuracies shown in <xref ref-type="fig" rid="F4">Fig. 4B</xref>. This analysis showed that all stages had a similar level of accuracy, with slight variations, in the onset and sustained phases of the response (<xref ref-type="fig" rid="F4">Fig. 4C</xref>) but that accuracy was at least three fold larger in the auditory cortex than in subcortical areas in the OFF phase (<xref ref-type="fig" rid="F4">Fig. 4C</xref>, dataset 1,CN ephys = 13.27 % +/- 1.84%, ICc ephys = 11.20 % +/- 2.99%, AC 2P = 39.60 % +/- 2.67 %, dataset 2, ICd 2P = 29.55 % +/- 2.21%, ICc ephys = 28.85 % +/- 3.99%, TH ephys = 26.91 % +/- 2.24 %, AC = 82.29 % +/- 0.63 %, p &lt; 0.05 across all pairwise comparisons with cortex, Mann-Whitney U test, n=5 cross-validation folds).</p><p id="P10">Both in datasets 1 and 2, cortical data are derived only from calcium imaging, raising the possibility that the very important difference of decoder performance could be due to spurious effects of this recording modality. Specifically, temporally deconvoled calcium imaging data are still temporally smeared by the slow rise time of GCAMP6s which is visible for example in the delayed peak of offset responses (<xref ref-type="fig" rid="F2">Fig. 2A</xref>). We have compensated for this effect by delaying the offset analysis window for calcium data (<xref ref-type="fig" rid="F3">Fig. 3</xref>). Nevertheless, it is difficult to rule out <italic>a priori</italic> a transfer of sustained response information into the offset window in calcium imaging data due to this temporal smearing. Three observations allow us to exclude this possibility. First, decoder accuracy was poor for inferior colliculus offsets both for electrophysiology and calcium imaging data (<xref ref-type="fig" rid="F4">Fig. 4C</xref>). Second, decoders trained on auditory cortex sustained responses had poor accuracy when tested on cortical offset responses (<xref ref-type="fig" rid="F4">Fig. 4D</xref>, AC 2P 1: 22.21 % +/- 1.82 %, AC 2P 2: 1.47 % +/- 0.54 %), suggesting that the information used by the decoder during the offset does not simply mirror sustained activity. However, decoders of offset responses displayed an intermediate accuracy level when tested on sustained activity (<xref ref-type="fig" rid="F4">Fig. 4D</xref>, AC 2P 1: 33.68 % +/- 2.30 %, AC 2P 2: 30.71 % +/- 1.67 %) suggesting a degree of overlap between sustained and offset responses. This can have multiple causes including temporal smearing, but also a partially shared representation space between sustained and offset phases in AC.</p><p id="P11">Therefore, our third observation aimed at discriminating between these two alternatives. We decomposed the calcium response on each trial into a linear sum of a set of onset, sustained and offset regressors which modeled the temporal smear based on our data (<xref ref-type="fig" rid="F5">Fig. 5A</xref>). Most importantly, we modeled sustained response with a decaying component that extended into the offset time window (<xref ref-type="fig" rid="F5">Fig. 5A</xref>). The regressors have a fixed time course but three time-dilated regressors were used at the offset to capture the variability of response time constants across neurons (<xref ref-type="fig" rid="F5">Fig. 5A</xref>). This approach allowed us to extract one amplitude value for onset, sustained and offset responses while canceling largely the smearing effect. We verified the latter aspect by plotting the amplitude of sustained against offset components and comparing this with the relation of time-averaged values during sustained and offset periods for calcium imaging data. A clear drop of the correlation between offset and sustained with the linear demixing model confirmed its efficiency to cancel the temporal smearing effect in calcium signals (<xref ref-type="fig" rid="F5">Fig. 5B</xref>). We then measured the accuracy of the decoders trained on the offset component and tested on the sustained component of the demixing model. We observed overall only a modest drop in classification accuracy compared to response averaging, indicating that the smearing effect, largely canceled by demixing, contributes little to the information contained in offset responses in the auditory cortex dataset (<xref ref-type="fig" rid="F5">Fig. 5C</xref>). Likewise, the cross-decoding of sustained activity by offset decoders was little impacted by the demixing model, showing that temporal smearing does not explain this effect, which thus rather corresponds to a genuine overlap between sustained and offset representation spaces in the cortex (<xref ref-type="fig" rid="F5">Fig. 5D</xref>).</p></sec></sec><sec id="S6" sec-type="discussion"><title>Discussion</title><p id="P12">Our results provide a systematic analysis of offset responses across the auditory system based on two large datasets collected in awake mice. They complement a wide range of studies that have reported the presence of offset responses throughout the auditory system and characterized their properties across auditory system stages and animal species (<xref ref-type="bibr" rid="R19">Kopp-Scheinpflug et al., 2018</xref>). The main specificities of our dataset are the large number of neurons recorded especially with calcium imaging and the homogeneity of the stimulus set and recording conditions across the different stages. Also, some recordings (e.g. inferior colliculus or auditory cortex present in dataset 1 and 2, calcium and electrophysiology in inferior colliculus) provide repeats of similar experiments allowing to verify the stability of observed properties across recording modalities, experimental conditions and sampling biases. Our datasets represent a unique collection of mouse auditory system data, but are incomplete to some degree with the absence of recordings in the superior olivary complex and the lack of thalamic data in dataset 1 or of cochlear nucleus in dataset 2.</p><p id="P13">Reassuringly, our broad dataset recapitulates the main observations made in the past about offset responses. First, offset responses are found at all stages (<xref ref-type="fig" rid="F3">Fig. 3</xref>) in a small subset of neurons. Although consistent with observations that offset responses are sparse, our measurement of the fraction of neurons with offset responses may underestimate the real value due to the poor statistical power of our datasets for this type of question (low sound repeat number and large number of sounds). Previous studies with more statistical power indeed reported larger fractions of offset responsive neurons in the inferior colliculus (<xref ref-type="bibr" rid="R1">Akimov et al., 2017</xref>) or in the auditory cortex (<xref ref-type="bibr" rid="R32">Tian et al., 2013</xref>). In the cochlear nucleus, offset responses are thought to be present only in specific subtypes of neurons (<xref ref-type="bibr" rid="R11">Ding et al., 1999</xref>; <xref ref-type="bibr" rid="R37">Young and Brownell, 1976</xref>). It is possible that the large representation of offset neurons in our cochlear nucleus dataset is due to a sampling bias introduced by Neuropixels recordings.</p><p id="P14">Second, offset responses are often, although not systematically, combined with onset and sustained responses (<xref ref-type="fig" rid="F3">Fig. 3</xref>), a property commonly reported at different stages of the auditory system (<xref ref-type="bibr" rid="R19">Kopp-Scheinpflug et al., 2018</xref>). Interestingly, the frequency tuning of on- and offset responses in the same neurons of the auditory cortex is often different (<xref ref-type="bibr" rid="R28">Scholl et al., 2010</xref>; <xref ref-type="bibr" rid="R29">Sollini et al., 2018</xref>) suggesting that on- and offset responses in cortex come from circuit processes that are more complex than a single, shared input channel.</p><p id="P15">Our population decoding analysis demonstrates that cortical offset responses are not only distinct from onset responses but they are also much more informative about the identity of the elapsed sound than subcortical offsets (<xref ref-type="fig" rid="F4">Figs. 4</xref>-<xref ref-type="fig" rid="F5">5</xref>). The classifier accuracy improvement between cortical and subcortical levels is more than 3-fold in our two datasets, indicating a robust and clear effect. This striking difference is not due to the large sample size of auditory cortex recordings. Two-photon calcium imaging data are noisier (<xref ref-type="fig" rid="F1">Fig. 1C</xref>) (<xref ref-type="bibr" rid="R6">Bagur et al., 2025</xref>) and display sparser offset responses than electrophysiology data (<xref ref-type="fig" rid="F3">Fig. 3D</xref>). These two biases are compensated by the larger sample size of the two-photon calcium imaging data. This is shown in our ceiling information analysis (<xref ref-type="fig" rid="F4">Fig. 4B</xref>), which uses population activity decoders based on the full spatio-temporal information available in each neuron to estimate the maximum sound information available in the dataset. This analysis shows that ceiling information is similar across datasets (<xref ref-type="fig" rid="F4">Fig. 4B</xref>). Moreover, decoder accuracies are more similar across auditory system stages for onset and sustained responses (<xref ref-type="fig" rid="F4">Fig. 4B</xref>). These two observations demonstrate that the larger sample size of two-photon calcium imaging does not provide additional information which could explain the highly informative offset in AC. Also, if the sample size of two-photon calcium imaging data would be a factor, offset responses should also be more informative in the two-photon calcium imaging dataset than in the electrophysiology dataset recorded in the inferior colliculus, which we do not observe (<xref ref-type="fig" rid="F4">Fig. 4C</xref>). The boost of offset information is also not due to a spill over of sustained information in cortical recordings as demonstrated with our linear demixing analysis (<xref ref-type="fig" rid="F5">Fig. 5</xref>). Hence, we conclude that auditory cortex response dynamics are such that they generate highly informative offset activity that does not exist upstream.</p><p id="P16">This observation is a clear indication that offset responses do not result from a combination of labelled-line offset inputs from upstream areas. Indeed, if this were the case, as information cannot be created <italic>de novo</italic>, the decoder accuracy would be as poor in the cortex as subcortically. Our results therefore show that offset responses in the auditory cortex are recomputed not only from upstream offsets but also necessarily using information originating in earlier phases of the response, which are much more informative than offset responses at subcortical levels. A previous study reported an absence of offset responses to white noise in the thalamus but not in the auditory cortex (<xref ref-type="bibr" rid="R30">Solyga and Barkat, 2021</xref>), while offset responses were present in both stages for pure tones. This suggested that cortical offset includes new information as compared to subcortical offsets. Our data do not corroborate this observation, as we observe clear offset responses to white noise even in the inferior colliculus (<xref ref-type="fig" rid="F2">Fig. 2C</xref>). Our observations therefore provide a strong argument for the idea of newly computed offset responses in the auditory cortex.</p><p id="P17">What processes could explain our observation of richer offset responses in the auditory cortex? Improved decoder performance in the cortex could result from either an improvement of sound-specific signals or a decrease of offset response variability or both. As response variability was larger in cortical datasets, it is likely that decoder performance was rather improved by an increased sound-specificity of cortical offsets compared to their subcortical counterparts. The mechanisms usually proposed for bottom-up generation of offset responses divided between rebound mechanisms in single neurons and local micro-circuits mechanisms providing for example time- shifted inhibitory and excitatory inputs (<xref ref-type="bibr" rid="R19">Kopp-Scheinpflug et al., 2018</xref>). Because of their spatial locality, these mechanisms are not sufficient to identify the factors underlying the richness of offset responses in complex circuits with multiple inputs. Recently, it was demonstrated that large recurrent neural networks produce complex offset responses that depend on multiple interactions within the network (<xref ref-type="bibr" rid="R7">Bondanelli et al., 2021</xref>). Anatomically, all auditory system networks considered in this study have a recurrent inhibitory and excitatory architecture (<xref ref-type="bibr" rid="R21">Levy and Reyes, 2012</xref>; <xref ref-type="bibr" rid="R24">Oliver, 2005</xref>; <xref ref-type="bibr" rid="R38">Young and Davis, 2002</xref>). It is therefore conceivable that offset responses originate from recurrent network-scale interactions. This hypothesis would generalize local micro-circuit models. It would be highly compatible with the high sensitivity of offset responses to anesthetics that strongly affect network dynamics (<xref ref-type="bibr" rid="R13">Filipchuk et al., 2022</xref>; <xref ref-type="bibr" rid="R15">Gosselin et al., 2024</xref>). In this framework, our results indicate that the collective dynamics generating offset responses are more complex in the auditory cortex than in upstream stages. This complexity could span both the spatial dimension (i.e. the extent to which interactions involve multiple neurons processing multiple sound features) and the temporal dimension (i.e. the temporal span over which information is integrated to produce the offset response). It is already well established that auditory cortex responses have less temporal precision than subcortical responses (<xref ref-type="bibr" rid="R33">Wang et al., 2008</xref>) and are influenced by a longer history time-window (<xref ref-type="bibr" rid="R23">Norman-Haignere et al., 2022</xref>). This could contribute to the higher richness of cortical offset responses, which due to their long duration (<xref ref-type="bibr" rid="R19">Kopp-Scheinpflug et al., 2018</xref>) (<xref ref-type="fig" rid="F2">Fig. 2</xref>) also provide, at the population scale, a transient memory of the elapsed sound.</p></sec><sec id="S7"><title>Resource availability</title><sec id="S8"><title>Lead contact</title><p id="P18"><email>brice.bathellier@cnrs.fr</email></p></sec><sec id="S9" sec-type="materials"><title>Material availability</title><p id="P19">Biological material and technologies used in this study are freely available resources.</p></sec><sec id="S10"><title>Data and code availability</title><p id="P20">All datasets and custom codes will be freely available on Zenodo.</p></sec></sec><sec id="S11" sec-type="materials | methods"><title>Material and Methods</title><sec id="S12"><title>Ethical approval</title><p id="P21">All experimental and surgical procedures were carried out in accordance with the European guidelines for animal experiments and were validated by the French Ethical Committee #89 (authorization APAFIS#27040-2020090316536717 v1).</p></sec><sec id="S13"><title>Datasets</title><p id="P22">All data used in this study are derived from two publicly available datasets summarized in <xref ref-type="table" rid="T1">Table 1</xref>. Dataset 2 was described more extensively in a published article (<xref ref-type="bibr" rid="R6">Bagur et al., 2025</xref>). Dataset 1 is described in a parallel pre-print manuscript (<xref ref-type="bibr" rid="R16">Gosselin et al., 2025</xref>).</p></sec><sec id="S14"><title>Subjects and ethical authorizations</title><p id="P23">All mice used for the production of the datasets were 10 to 16 weeks old male C57Bl6J mice (26 - 30 g) obtained from Janvier labs (Le Genest-Saint-Isle, France) that had not undergone any other procedures. Mice were group-housed (2–4 per cage) before and after surgery, had <italic>ad libitum</italic> access to food and water and enrichment (running wheel, cotton bedding and wooden logs) and were maintained on a 12-hour light-dark cycle in controlled humidity and temperature conditions (21-23 °C, 45-55% humidity). All experiments were performed during the light phase. The terminal procedure was carbon dioxide inhalation.</p></sec><sec id="S15"><title>Surgical procedures</title><p id="P24">Mice were injected with buprenorphine (Vétergesic, 0,05-0,1 mg/kg) 30 min prior to surgery. Surgical procedures were carried out using either intraperitoneal ketamine (Ketasol) and medetomidine (Domitor) which was antagonized with atipamezole (Antisedan, Orion pharma) at the end of the surgery) or 3% isoflurane delivered via a mask. After induction, mice were kept on a thermal blanket during the whole procedure and their eyes were protected with Ocrygel (TVM Lab). Lidocaine was injected under the skin of the skull 5 minutes prior to incision.</p><p id="P25">For electrophysiology recordings, the skull was exposed at the relevant location for ulterior craniotomy: above the IC, above the cortex dorsal to the TH or above the dorsal cerebellum for the CN. A well was formed around it using dental cement in order to retain saline solution during recordings and the head post was fixed to the skull using cyanolit glue and dental cement. To protect the skull, the well was filled with a waterproof silicone elastomer (Kwikcast, WPI) that could be removed prior to recording. The head post was fixed to the skull using cyanolit glue and dental cement (Ortho-Jet, Lang).</p><p id="P26">For calcium imaging, craniotomies of 3 (IC) or 5 (AC) mm were performed above the IC or the AC. Injections of 150nL of AAV1.Syn.GCaMP6s.WPRE (Vector Core, Philadelphia, PA; 10^13 viral particles per ml; used pure for TH and diluted 30x for AC and IC) were made at 30 nL/min with pulled glass pipettes at a depth of 500µm and spaced every 500 µm to cover the large surface of the IC or AC. The craniotomy was sealed with a circular glass coverslip. The coverslip and head post were fixed to the skull using cyanolit glue and dental cement (Ortho-Jet, Lang).</p><p id="P27">After surgery, mice received a subcutaneous injection of 30% glucose and metacam (1 mg/kg). Mice were subsequently housed for one week with metacam delivered via drinking water or dietgel (ClearH20). Mice were given one week to recover from surgery without any manipulation. Then, for four days before recording, mice were habituated to head restraint for increasing periods of time (30 min - 2 hours). For electrophysiological experiments, the day before recording animals were briefly anesthetized using isoflurane anesthesia (2%) in order to perform craniotomy and durectomy for electrode descent.</p></sec><sec id="S16"><title>Electrophysiological recordings</title><p id="P28">Dataset 1 (CN): The awake mouse was head-fixed and Neuropixels 1.0 probes (384 channels) were inserted through the cerebellum at a 38-40° angle in the sagittal plane, targeting the contralateral cochlear nucleus, vertically targeting the inferior colliculus, or both. Electrode angle and entry point were defined relative to the initial head-post placement. Fine tuning of these targeting parameters was progressively obtained through repeated penetrations based on time-locked responses to sounds easily detectable during probe insertion. Data was sampled at 30kHz using a NI-PXI chassis (National Instruments) and the SpikeGLX acquisition software.</p><p id="P29">Dataset 2 (IC, TH): The awake mouse was head-fixed and Neuronexus 1x32 linear probe (IC) or 4x8 comb prove (TH) was inserted. Data was sampled at 20kHz using an Intan RHD2000 amplifier board.</p><p id="P30">Recording was started 15-20 minutes after the electrode position was locked to allow the brain tissue to stabilize and minimize movements of neurons in the first part of the recording. Recordings were performed using warmed saline filling the cyanolit glue well and in contact with the reference electrode. After each recording the well was amply flushed and then refilled with Kwik-Cast.</p><p id="P31">For post-hoc histological verification of the electrode track using fluorescent dye, the electrodes were dipped in diI, diO or diD (Vybrant™ Multicolor Cell-Labeling Kit, Thermofisher) prior to insertion.</p></sec><sec id="S17"><title>Two-photon calcium imaging</title><p id="P32">Dataset 1 (AC): Imaging was performed using an acousto-optic two-photon microscope (Karthala System, Orsay, France) ewith a pulsed laser (Insight, Spectra-Physics, Santa Clara, CA) set at 900 nm. We used a 16x objective (N16XLWD-PF, Nikon) to acquire stacks of four images at 22.9 Hz from four planes interleaved by 50 µm in a field of view of 478x478 µm.</p><p id="P33">Dataset 2 (AC and IC): Imaging was performed using a two-photon microscope (Femtonics, Budapest, Hungary) equipped with an 8kHz resonant scanner combined with a pulsed laser (MaiTai-DS, SpectraPhysics, Santa Clara, CA) set at 900 nm. We used a 10x Olympus objective (XLPLN10XSVMP), which provided a field of view of up to 1x1 mm. For AC, a 1x1mm field of view was used. For IC, the field of view was adjusted to the size of the structure (∼0.5x0.5 mm). Images were acquired at 31.5 Hz.</p></sec><sec id="S18"><title>Sound set and experimental protocol</title><p id="P35">Dataset 1: Sounds were generated with Python (The Python Software Foundation, Wilmington, DE) and were delivered at 192 kHz with Matlab (The Mathworks, Natick, MA), using a NI-PCI-6221 card (National Instruments) driven by a custom protocol using the Matlab Data Acquisition toolbox and feeding an amplified free-field loudspeaker (SA1 and MF1-S, Tucker-Davis Technologies, Alachua, FL) positioned in front of the mouse, 10 to 15 cm from the mouse ear. Sound intensity was cosine-ramped over 10 ms at the onset and offset to avoid spectral splatter. The head fixed mouse was isolated from external noise sources by sound-proof boxes (custom-made by Decibel France, Miribel, France) providing 30 dB attenuation above 1 kHz. Sound pressure levels were computed as Root Mean Square. During a recording session, 307 sounds were repeated 12 times and played in a random order with a 1 s interval between sound onsets in 123 blocks of 30 sounds (total duration ∼80 minutes). The 307 sounds included simple and more complex sounds. Because of the strong time-varying nature of the complex sounds we focused the analysis of offset responses on a set of 152 more simple sounds whose duration was 500ms. These included 28 Pure tones: pure tones at 14 frequencies logarithmically spaced between 2 kHz and 60 kHz at 50 dB SPL and 70 dB SPL. 26 Ramps: linearly ramped sounds, increasing and decreasing in intensity, at the same frequencies as the 13 pure tones between 2 kHz and 50 kHz between 50 dB SPL and 70 dB SPL. 48 Chords: summation of 2-4 70 dB pure tones from low (11 sounds), medium (11 sounds), high (11 sounds) frequency groups, broadly sampled frequencies (10 sounds) and harmonically arranged frequencies (5 sounds). 20 Chirps: up- and down- frequency sweeps of different durations between 25 ms and 400 ms at 6-12 kHz, 50 dB SPL (10 sounds) or different frequency content between 4 kHz and 50 kHz at 50 dB SPL in 500 ms (10 sounds). 30 Coloured noises (WN): broadband noises at 50 dB SPL, 70 dB SPL or up-/down-ramped (6 sounds), filtered noises at different bandwidths between 2 kHz and 80 kHz (14 sounds), and summation of two 1 kHz bandwidth filtered noises up- and down-ramped between 50 dB SPL and 70 dB SPL, matching frequencies of a subset of chords (10 sounds). 48 amplitude-modulated sounds (AM): sinusoidally amplitude modulated sounds at 6 different modulation frequencies between 4 Hz and 160 Hz and 8 carrier frequency contents (2 pure frequencies, 5 sums of frequencies matching chords and 1 broadband noise). Out of the 152 sounds, 33 produced unreliable population responses (mean correlation across time-averaged single trial population vectors &lt; 0.1) in at least one of the three recorded areas. These sounds were excluded from the final analysis, restricted to 119 sounds, to focus on robust responses. We verified that this had no effect on our conclusions.</p><p id="P36">Dataset 2: Sounds were generated with Matlab (The Mathworks, Natick, MA) and were delivered at 192 kHz with a NI-PCI-6221 card (National Instruments) driven by the software Elphy (G. Sadoc, UNIC, France) and feeding an amplified free-field loudspeaker (SA1 and MF1-S, Tucker-Davis Technologies, Alachua, FL) positioned 15 to 20 cm from the mouse ear. Sound intensity was cosine-ramped over 10 ms at the onset and offset to avoid spectral splatter. The head fixed mouse was isolated from external noise sources by sound-proof boxes (custom-made by Femtonics, Budapest, Hungary or Decibel France, Miribel, France) providing 30 dB attenuation above 1 kHz. Sounds were calibrated in intensity at the location of the mouse ear using a probe microphone (Bruel &amp; Kjaer, type 4939-L-002). For two-photon calcium imaging, the resonant scanner generated a harmonic background noise at 8 kHz (intensity at the mouse ear, 45 dB SPL). During a recording session, each sound was presented 15 times in random order.</p><p id="P37">The set of sounds consisted of 112 sounds (<xref ref-type="fig" rid="F1">Fig. 1</xref>) which were all 500 ms long. 26 Pure tones: pure tones at 11 frequencies logarithmically spaced between 4 kHz and 37 kHz at 50, 70 and 80 dB SPL. 42 Ramps: linearly ramped sounds, increasing and decreasing in intensity, at various frequencies and combinations (chords) of frequencies. 44 Chirps: up- and down-frequency sweeps with various start and stop frequencies between 4 and 24 kHz at 50 and 80dB. These sounds were played in pseudo random order together with 28 other sounds (shorter frequency ramps and long amplitude modulated sounds, see (<xref ref-type="bibr" rid="R6">Bagur et al., 2025</xref>)) which were excluded from the present analysis.</p></sec><sec id="S19"><title>Data preprocessing</title><p id="P38">Dataset 1: Motion artifacts, regions of interest selection, and the signal extraction were carried out with the standard pipeline of the Python-based version of Suite2p (<xref ref-type="bibr" rid="R26">Pachitariu et al., 2017</xref>). For each region of interest, the mean fluorescence signal <italic>F(t)</italic> was extracted together with the local neuropil signal <italic>F</italic><sub>np</sub><italic>(t)</italic>. Then 70% of the neuropil signal was subtracted from the neuron signal to limit neuropil contamination. Baseline fluorescence F<sub>0</sub> was calculated with a sliding window computing the 3rd percentile of a Gaussian-filtered trace over the imaging blocks. Fluorescence variations were then computed as <italic>f(t)</italic> = Δ<italic>F/F</italic> = (<italic>F(t)</italic> - <italic>F</italic><sub>0</sub>)/<italic>F</italic><sub>0</sub>. An estimate of firing rate variations r(t) was then obtained by linear temporal deconvolution of f(t): <italic>r(t)</italic> = <italic>f’(t) + f(t)/τ, f’(t)</italic> being the first derivative of <italic>f(t)</italic> and <italic>τ</italic> = 2s, the estimated decay of the GCAMP6s fluorescent transients. This simple method efficiently corrects the strong discrepancy between fluorescence and firing rate time courses due to the slow decay of spike-triggered calcium transients. It does not correct for the rise time of GCAMP6s, leading to remnant low pass filtering of the firing rate estimate and a delay of ∼100ms between the firing rate peaks and the peaks of the deconvolved signal. Finally, response traces were smoothed with a Gaussian filter (σ = 31ms). Single trial sound responses were extracted (0.2 s before up to 0.8 s after sound onset) and the average activity over the prestimulus period (0.2 s - 0.02 s before sound onset) was subtracted for each trial.</p><p id="P39">For electrophysiology, raw data were band-pass filtered (300 - 6 000 Hz) and channels from the electrode tip (corresponding to the cochlear nucleus region) were selected using SpikeInterface (<ext-link ext-link-type="uri" xlink:href="https://github.com/SpikeInterface">https://github.com/SpikeInterface</ext-link>) (<xref ref-type="bibr" rid="R9">Buccino et al., 2020</xref>). Isolated clusters were identified using Kilosort 2.5 (<xref ref-type="bibr" rid="R25">Pachitariu et al., 2024</xref>) followed by manual curation based on the interspike-interval histogram and the inspection of the spike waveform using Phy (<ext-link ext-link-type="uri" xlink:href="https://github.com/cortex-lab/phy">https://github.com/cortex-lab/phy</ext-link>). Canonical spike sorting was first applied with common parameters throughout the whole recording, attempting to optimize the spike detection and assignment to clusters. The measure of drift throughout the recording computed with Kilosort 2.5 showed minimal slow drift throughout the recording, except for some experiments in the first 10 minutes. Due to the high spiking activity in the cochlear nucleus, optimal spike sorting was achieved using lower Kilosort 2.5 parameters (detection threshold = 6, clustering threshold = 6, and matching thresholds = [9,4]) in this region than for the inferior colliculus (detection threshold = 8, clustering threshold = 8, and matching thresholds = [10,4]). After manual curation, single trial sound responses were extracted (0.2 s before up to 0.8 s after sound onset) as a histogram of 1ms time bin and the average activity over the prestimulus period (0.2 s - 0 s before sound onset) was subtracted for each trial. Based on histology, we identified a number of units whose location on the Neuropixel probe was not compatible with a localization in the cochlear nucleus or inferior colliculus.</p><p id="P">Dataset 2:</p><p id="P40">For calcium imaging, regions of interest corresponding to putative neurons (AC 2P and IC) or axons and boutons (TH ephys) were identified by using Autocell (<xref ref-type="bibr" rid="R10">Deneux et al., 2016</xref>) (<ext-link ext-link-type="uri" xlink:href="https://github.com/thomasdeneux/Autocell">https://github.com/thomasdeneux/Autocell</ext-link>). Briefly, each frame of the recording was corrected for horizontal motion using rigid body registration. This step was visually controlled and all sessions with visible z motion were eliminated. A hierarchical clustering algorithm, based on pixel covariance over time, agglomerated pixels up to a user-selected number of clusters corresponding to regions of the size of neurons of axons. Clusters were automatically filtered according to size and shape criteria. This step was controlled by a detailed visual inspection of selected regions of interest (ROIs) during which ROIs without visually identifiable cell body shape were discarded.</p><p id="P41">For each region of interest, the mean fluorescence signal <italic>F(t)</italic> was extracted together with the local neuropil signal <italic>F</italic><sub><italic>np</italic></sub><italic>(t)</italic>. Then 70% of the neuropil signal was subtracted from the neuron signal to limit neuropil contamination. Baseline fluorescence F<sub>0</sub> was calculated with a sliding window computing the 3rd percentile of a Gaussian-filtered trace over the imaging blocks. Fluorescence variations were then computed as <italic>f(t) = ΔF/F = (F(t) - F</italic><sub><italic>0</italic></sub> <italic>)/F</italic><sub><italic>0</italic></sub>. An estimate of firing rate variations <italic>r(t)</italic> was then obtained by linear temporal deconvolution of f(<italic>t</italic>): <italic>r(t) = f’(t) + f(t)/τ, f’(t)</italic> being the first derivative of <italic>f(t)</italic> and <italic>τ</italic> = 2s, the estimated decay of the GCAMP6s fluorescent transients. This simple method efficiently corrects the strong discrepancy between fluorescence and firing rate time courses due to the slow decay of spike-triggered calcium transients. It does not correct for the rise time of GCAMP6s, leading to remnant low pass filtering of the firing rate estimate and a delay of ∼100 ms between the firing rate peaks and the peaks of the deconvolved signal. Finally, response traces were smoothed with a Gaussian filter (<italic>σ</italic> = 31 ms).</p><p id="P42">Electrophysiological signals were high-pass filtered and spike sorting was performed using the CortexLab suite (<ext-link ext-link-type="uri" xlink:href="https://github.com/cortex-lab">https://github.com/cortex-lab</ext-link>, UCL, London, England). Single unit clusters were identified using Kilosort 2.5 (<xref ref-type="bibr" rid="R25">Pachitariu et al., 2024</xref>) followed by manual corrections based on the interspike-interval histogram and the inspection of the spike waveform using Phy (<ext-link ext-link-type="uri" xlink:href="https://github.com/cortex-lab/phy">https://github.com/cortex-lab/phy</ext-link>).</p><p id="P43">Both for imaging and electrophysiology data, single trial sound responses were extracted (0.5s before and 1s after sound onset) and the average activity over the prestimulus period (0.5s - 0s before sound onset) was subtracted for each trial.</p></sec><sec id="S21"><title>Reproducibility index and cell selection</title><p id="P44">To quantify the noise levels in the data, we calculated the mean inter-trial correlation across all pairs of trials. The single neuron reproducibility is then defined for each neuron as the average of the inter-trial correlation for that neuron’s response to all sounds presented in the experiment. Region of interests (ROIs) or single units with reproducibility below 0.12 were classified as non-responsive and were excluded from all analyses. The number of responsive units and the corresponding fraction of the total number of units/ROIs are given in <xref ref-type="table" rid="T1">Table 1</xref>.</p></sec><sec id="S22"><title>Population activity decoding</title><p id="P45">To decode the stimulus identity from neural activity, we evaluated performance across different response windows, including onset, sustained, offset, and full response periods. For each window, neural responses from all neurons in each considered dataset were extracted and concatenated into a virtual population vector. In order to avoid statistical threshold effects, the selection of offset responses based on single neuron responses was not used in the population decoding approach. These vectors were constructed by averaging neural responses across the analysis time bin (onset, sustained, offset) except for the measurement of ceiling information. For the latter analysis, 65 time bins were defined from 0 to 150 ms after stimulus onset (650 ms in total), a population vector was constructed for each time bin and vectors from all time bins were concatenated into a vector summarizing the full spatio-temporal activity time-course of the population.</p><p id="P46">Next, the neural responses from each window were used as input to a stratified 5-fold cross-validation logistic regression decoder. Stratified cross-validation ensured that the class distributions were preserved in each fold, addressing any class imbalances. During each fold, training and test set were normalized by subtracting the training set mean. This approach allowed us to assess the fraction of correct sound identity predictions based on the neural population’s activity during each response window. The decoding performance was evaluated using balanced accuracy.</p></sec><sec id="S23"><title>Response profile identification</title><p id="P47">To identify onset and sustained response for each neuron and sound, we used a non-parametric, paired Wilcoxon signed-rank test comparing baseline activity to onset or sustained activity respectively. The alpha value of the test was 0.05, implying that the proportion of neuron-pairs with significant responses has to be above 5% to exceed the maximum chance level. For offset response detection, we used two non-independent paired Wilcoxon signed-rank tests comparing offset activity to baseline and sustained activity respectively, with an alpha value of 0.05 for each test. Because the single trial measurements of baseline and sustained activity are done at a short time interval, they are not statistically independent. Therefore, the false discovery rate (FDR) is not the product of alpha values as in the case of two independent tests, but is likely higher. To be conservative, we used the alpha value of one signed-rank test (0.05, same for both tests), as an estimate of the false detection rate (FDR, i.e. chance level) for offset responses. Significant responses were classified as positive or negative based on the sign of the time-averaged baseline-substracted activity over the analysis time bin. To estimate the fraction of neurons with at least one offset response (independent of its sign), we used the Benjamin-Hochberg procedure on each neuron to correct FDR for across the 119 (dataset 1) and 112 (dataset 2) signed-rank tests performed on each sound. Therefore the chance level for the fraction of neurons responding with at least one offset is also 5%. The degrees of freedom of the signed-ranked test correspond to the number of sound repetitions: N=12 for dataset 1, N=15 for dataset 2.</p></sec><sec id="S24"><title>Linear decomposition of responses</title><p id="P48">In order to separate the onset, sustained and offset components, we used a linear model to approximate the response function. The linear model is a sum of three regressors (on, off and sustained) with fixed shape but whose amplitude is fit to the neural response. Since we do not know with sufficient precision the underlying biophysical mechanisms resulting in the response shape which are moreover likely to verify between neurons, we empirically designed the shape of the three regressors to resemble the data. <disp-formula id="FD1"><mml:math id="M1"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>O</mml:mi><mml:mi>N</mml:mi></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>t</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mi>t</mml:mi><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mi>t</mml:mi><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
with  <italic>τ</italic><sub><italic>decay</italic></sub> = 0.075<italic>s</italic>     <italic>τ</italic><italic><sub>rise</sub> =</italic> 0.05<italic>s</italic> <disp-formula id="FD2"><mml:math id="M2"><mml:mrow><mml:mtable equalrows="true" equalcolumns="true"><mml:mtr><mml:mtd><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>SUST</mml:mi></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>t</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mi>t</mml:mi><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>y</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mspace width="0.2em"/><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mspace width="13em"/><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mi>t</mml:mi><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>y</mml:mi><mml:mspace width="0.2em"/></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mspace width="0.2em"/><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula> with  <italic>τ</italic><italic><sub>decay</sub> =</italic> 0.075<italic>s</italic>     <italic>τ</italic><italic><sub>rise</sub> =</italic> 0.05<italic>s</italic> <disp-formula id="FD3"><mml:math id="M3"><mml:mrow><mml:mtable equalrows="true" equalcolumns="true"><mml:mtr><mml:mtd><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>O</mml:mi><mml:mi>F</mml:mi><mml:mi>F</mml:mi></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>t</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mspace width="0.2em"/><mml:mspace width="0.2em"/><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mspace width="0.2em"/><mml:mo>&lt;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>=</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mi>t</mml:mi><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mi>t</mml:mi><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mspace width="0.2em"/><mml:mspace width="0.2em"/><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula> with  <italic>τ</italic><sub><italic>decay</italic></sub> = 0.075<italic>/</italic>0.05/0.1<italic>s</italic>     <italic>τ</italic><sub><italic>rise</italic></sub> = 0.1/0.1/0.12<italic>s</italic></p><p id="P55">After defining three regressors, the neural response is defined by this linear equation: <disp-formula id="FD4"><mml:math id="M4"><mml:mrow><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>O</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:mi>O</mml:mi><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>U</mml:mi><mml:mi>S</mml:mi><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:mi>S</mml:mi><mml:mi>U</mml:mi><mml:mi>S</mml:mi><mml:mi>T</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>O</mml:mi><mml:mi>F</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:mi>O</mml:mi><mml:mi>F</mml:mi><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P57">The amplitudes (αON, αSUST, αOFF) can be directly calculated (here, using Matlab’s backslash function). Given the importance of correctly fitting the offset response, we performed the fitting procedure with three different time constants and retained the best for further analysis. This fitting procedure was performed for all neurons, all sounds and every trial and the amplitudes were then used to perform classification as previously described.</p></sec></sec></body><back><ack id="S25"><title>Acknowledgments</title><p>We acknowledge the support of the Fondation pour l’Audition to the Institut de l’Audition.</p><p>We acknowledge the support of the following funding sources: Fondation pour l’Audition, RD-2023-1 (BB), FPA IDA02 (BB) and APA 2016-03 (BB), European Research Council, ERC CoG 770841 DEEPEN (BB) Fondation pour la Recherche Médicale SPF202005011970 (SB) Agence Nationale pour la Recherche, France 2030 program, ANR-23-IAHU-0003 (BB)</p></ack><sec id="S26" sec-type="data-availability"><title>Data availability</title><p id="P77">All data supporting the results in the paper are archived in the public repository Zenodo (access links: doi:<ext-link ext-link-type="uri" xlink:href="https://www.doi.org/10.5281/zenodo.13941450">10.5281/zenodo.13941450</ext-link> and doi:<ext-link ext-link-type="uri" xlink:href="https://www.doi.org/10.5281/zenodo.14421103">10.5281/zenodo.14421103</ext-link>).</p></sec><fn-group><fn fn-type="con" id="FN1"><p id="P58"><bold>Author contributions</bold></p><p id="P59">Conceptualization: CL, EG, BB, SB</p><p id="P60">Methodology: CL, EG, BB, SB</p><p id="P61">Investigation: CL, EG, SB</p><p id="P62">Data curation: CL, EG, SB</p><p id="P63">Formal analysis: CL, EG, SB</p><p id="P64">Supervision: BB, SB</p><p id="P65">Project administration: BB</p><p id="P66">Funding acquisition: BB, SB</p><p id="P67">Software: CL, SB</p><p id="P68">Visualization: CL</p><p id="P69">Validation: BB, SB</p><p id="P70">Writing-original draft: CL, EG, BB, SB</p><p id="P71">Writing-review &amp; editing:</p></fn><fn fn-type="conflict" id="FN2"><p id="P72"><bold>Declaration of interests</bold></p><p id="P73">The authors declare no competing interests.</p></fn><fn id="FN3"><p id="P74"><bold>Declaration of generative AI and AI-assisted technologies</bold></p><p id="P75">The authors did not use generative AI and AI-assisted technologies at any step of the study and in the writing process.</p></fn></fn-group><ref-list><ref id="R1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akimov</surname><given-names>AG</given-names></name><name><surname>Egorova</surname><given-names>MA</given-names></name><name><surname>Ehret</surname><given-names>G</given-names></name></person-group><article-title>Spectral summation and facilitation in on- and off-responses for optimized representation of communication calls in mouse inferior colliculus</article-title><source>Eur J Neurosci</source><year>2017</year><volume>45</volume><fpage>440</fpage><lpage>459</lpage><pub-id pub-id-type="pmid">27891665</pub-id></element-citation></ref><ref id="R2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>LA</given-names></name><name><surname>Linden</surname><given-names>JF</given-names></name></person-group><article-title>Mind the gap: Two dissociable mechanisms of temporal processing in the auditory system</article-title><source>J Neurosci</source><year>2016</year><volume>36</volume><fpage>1977</fpage><lpage>1995</lpage><pub-id pub-id-type="pmcid">PMC4748080</pub-id><pub-id pub-id-type="pmid">26865621</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1652-15.2016</pub-id></element-citation></ref><ref id="R3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Awwad</surname><given-names>B</given-names></name><name><surname>Jankowski</surname><given-names>MM</given-names></name><name><surname>Nelken</surname><given-names>I</given-names></name></person-group><article-title>Synaptic Recruitment Enhances Gap Termination Responses in Auditory Cortex</article-title><source>Cereb Cortex</source><year>2020</year><volume>30</volume><fpage>4465</fpage><lpage>4480</lpage><pub-id pub-id-type="pmcid">PMC7325714</pub-id><pub-id pub-id-type="pmid">32147725</pub-id><pub-id pub-id-type="doi">10.1093/cercor/bhaa044</pub-id></element-citation></ref><ref id="R4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Awwad</surname><given-names>B</given-names></name><name><surname>Jankowski</surname><given-names>MM</given-names></name><name><surname>Polterovich</surname><given-names>A</given-names></name><name><surname>Bashari</surname><given-names>S</given-names></name><name><surname>Nelken</surname><given-names>I</given-names></name></person-group><article-title>Extensive representation of sensory deviance in the responses to auditory gaps in unanesthetized rats</article-title><source>Curr Biol</source><year>2023</year><volume>33</volume><fpage>3024</fpage><lpage>3030</lpage><elocation-id>e3</elocation-id><pub-id pub-id-type="pmid">37385255</pub-id></element-citation></ref><ref id="R5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bagur</surname><given-names>S</given-names></name><name><surname>Bathellier</surname><given-names>B</given-names></name></person-group><article-title>A spatial code for temporal information is necessary for efficient sensory learning</article-title><year>2024</year><pub-id pub-id-type="pmcid">PMC11708902</pub-id><pub-id pub-id-type="pmid">39772691</pub-id><pub-id pub-id-type="doi">10.1126/sciadv.adr6214</pub-id></element-citation></ref><ref id="R6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bagur</surname><given-names>S</given-names></name><name><surname>Bourg</surname><given-names>J</given-names></name><name><surname>Kempf</surname><given-names>A</given-names></name><name><surname>Tarpin</surname><given-names>T</given-names></name><name><surname>Bergaoui</surname><given-names>K</given-names></name><name><surname>Guo</surname><given-names>Y</given-names></name><name><surname>Ceballo</surname><given-names>S</given-names></name><name><surname>Schwenkgrub</surname><given-names>J</given-names></name><name><surname>Verdier</surname><given-names>A</given-names></name><name><surname>Puel</surname><given-names>JL</given-names></name><name><surname>Bourien</surname><given-names>J</given-names></name><etal/></person-group><article-title>A spatial code for temporal information is necessary for efficient sensory learning</article-title><source>Sci Adv</source><year>2025</year><volume>11</volume><elocation-id>eadr6214</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.adr6214</pub-id></element-citation></ref><ref id="R7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bondanelli</surname><given-names>G</given-names></name><name><surname>Deneux</surname><given-names>T</given-names></name><name><surname>Bathellier</surname><given-names>B</given-names></name><name><surname>Ostojic</surname><given-names>S</given-names></name></person-group><article-title>Network dynamics underlying OFF responses in the auditory cortex</article-title><source>eLife</source><year>2021</year><volume>10</volume><elocation-id>e53151</elocation-id><pub-id pub-id-type="pmcid">PMC8057817</pub-id><pub-id pub-id-type="pmid">33759763</pub-id><pub-id pub-id-type="doi">10.7554/eLife.53151</pub-id></element-citation></ref><ref id="R8"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bregman</surname><given-names>AS</given-names></name></person-group><source>Auditory Scene Analysis: The Perceptual Organization of Sound</source><publisher-name>MIT Press</publisher-name><year>1994</year></element-citation></ref><ref id="R9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buccino</surname><given-names>AP</given-names></name><name><surname>Hurwitz</surname><given-names>CL</given-names></name><name><surname>Garcia</surname><given-names>S</given-names></name><name><surname>Magland</surname><given-names>J</given-names></name><name><surname>Siegle</surname><given-names>JH</given-names></name><name><surname>Hurwitz</surname><given-names>R</given-names></name><name><surname>Hennig</surname><given-names>MH</given-names></name></person-group><article-title>SpikeInterface, a unified framework for spike sorting</article-title><source>eLife</source><year>2020</year><volume>9</volume><elocation-id>e61834</elocation-id><pub-id pub-id-type="pmcid">PMC7704107</pub-id><pub-id pub-id-type="pmid">33170122</pub-id><pub-id pub-id-type="doi">10.7554/eLife.61834</pub-id></element-citation></ref><ref id="R10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deneux</surname><given-names>T</given-names></name><name><surname>Kempf</surname><given-names>A</given-names></name><name><surname>Daret</surname><given-names>A</given-names></name><name><surname>Ponsot</surname><given-names>E</given-names></name><name><surname>Bathellier</surname><given-names>B</given-names></name></person-group><article-title>Temporal asymmetries in auditory coding and perception reflect multi-layered nonlinearities</article-title><source>Nat Commun</source><year>2016</year><volume>7</volume><elocation-id>12682</elocation-id><pub-id pub-id-type="pmcid">PMC5025791</pub-id><pub-id pub-id-type="pmid">27580932</pub-id><pub-id pub-id-type="doi">10.1038/ncomms12682</pub-id></element-citation></ref><ref id="R11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname><given-names>J</given-names></name><name><surname>Benson</surname><given-names>TE</given-names></name><name><surname>Voigt</surname><given-names>HF</given-names></name></person-group><article-title>Acoustic and Current-Pulse Responses of Identified Neurons in the Dorsal Cochlear Nucleus of Unanesthetized, Decerebrate Gerbils</article-title><source>J Neurophysiol</source><year>1999</year><volume>82</volume><fpage>3434</fpage><lpage>3457</lpage><pub-id pub-id-type="pmid">10601474</pub-id></element-citation></ref><ref id="R12"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Eggermont</surname><given-names>JJ</given-names></name></person-group><source>Auditory Temporal Processing and its Disorders</source><publisher-name>OUP Oxford</publisher-name><year>2015</year></element-citation></ref><ref id="R13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Filipchuk</surname><given-names>A</given-names></name><name><surname>Schwenkgrub</surname><given-names>J</given-names></name><name><surname>Destexhe</surname><given-names>A</given-names></name><name><surname>Bathellier</surname><given-names>B</given-names></name></person-group><article-title>Awake perception is associated with dedicated neuronal assemblies in the cerebral cortex</article-title><source>Nat Neurosci</source><year>2022</year><volume>25</volume><fpage>1327</fpage><lpage>1338</lpage><pub-id pub-id-type="pmcid">PMC9534770</pub-id><pub-id pub-id-type="pmid">36171431</pub-id><pub-id pub-id-type="doi">10.1038/s41593-022-01168-5</pub-id></element-citation></ref><ref id="R14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gosselin</surname><given-names>E</given-names></name></person-group><article-title>Feature-dependent decorrelation of sound representations across the auditory pathway</article-title><year>2024</year><pub-id pub-id-type="doi">10.5281/zenodo.14421103</pub-id></element-citation></ref><ref id="R15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gosselin</surname><given-names>E</given-names></name><name><surname>Bagur</surname><given-names>S</given-names></name><name><surname>Bathellier</surname><given-names>B</given-names></name></person-group><article-title>Massive perturbation of sound representations by anesthesia in the auditory brainstem</article-title><year>2024</year><pub-id pub-id-type="pmcid">PMC11488538</pub-id><pub-id pub-id-type="pmid">39423272</pub-id><pub-id pub-id-type="doi">10.1126/sciadv.ado2291</pub-id></element-citation></ref><ref id="R16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gosselin</surname><given-names>E</given-names></name><name><surname>Bagur</surname><given-names>S</given-names></name><name><surname>Jamali</surname><given-names>S</given-names></name><name><surname>Puel</surname><given-names>J-L</given-names></name><name><surname>Bourien</surname><given-names>J</given-names></name><name><surname>Bathellier</surname><given-names>B</given-names></name></person-group><article-title>Feature-dependent decorrelation of sound representations across the auditory pathway</article-title><year>2025</year><pub-id pub-id-type="doi">10.1101/2025.04.17.649364</pub-id></element-citation></ref><ref id="R17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grinnell</surname><given-names>AD</given-names></name></person-group><article-title>Rebound excitation (Off-responses) following non-neural suppression in the cochleas of echolocating bats</article-title><source>J Comp Physiol</source><year>1973</year><volume>82</volume><fpage>179</fpage><lpage>194</lpage><pub-id pub-id-type="doi">10.1007/BF00696152</pub-id></element-citation></ref><ref id="R18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kasai</surname><given-names>M</given-names></name><name><surname>Ono</surname><given-names>M</given-names></name><name><surname>Ohmori</surname><given-names>H</given-names></name></person-group><article-title>Distinct neural firing mechanisms to tonal stimuli offset in the inferior colliculus of mice in vivo</article-title><source>Neurosci Res</source><year>2012</year><volume>73</volume><fpage>224</fpage><lpage>237</lpage><pub-id pub-id-type="pmid">22579573</pub-id></element-citation></ref><ref id="R19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kopp-Scheinpflug</surname><given-names>C</given-names></name><name><surname>Sinclair</surname><given-names>JL</given-names></name><name><surname>Linden</surname><given-names>JF</given-names></name></person-group><article-title>When Sound Stops: Offset Responses in the Auditory System</article-title><source>Trends Neurosci</source><year>2018</year><volume>41</volume><fpage>712</fpage><lpage>728</lpage><pub-id pub-id-type="pmid">30274606</pub-id></element-citation></ref><ref id="R20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuwada</surname><given-names>S</given-names></name><name><surname>Batra</surname><given-names>R</given-names></name></person-group><article-title>Coding of Sound Envelopes by Inhibitory Rebound in Neurons of the Superior Olivary Complex in the Unanesthetized Rabbit</article-title><source>J Neurosci</source><year>1999</year><volume>19</volume><fpage>2273</fpage><lpage>2287</lpage><pub-id pub-id-type="pmcid">PMC6782550</pub-id><pub-id pub-id-type="pmid">10066278</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.19-06-02273.1999</pub-id></element-citation></ref><ref id="R21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levy</surname><given-names>RB</given-names></name><name><surname>Reyes</surname><given-names>AD</given-names></name></person-group><article-title>Spatial Profile of Excitatory and Inhibitory Synaptic Connectivity in Mouse Primary Auditory Cortex</article-title><source>J Neurosci</source><year>2012</year><volume>32</volume><fpage>5609</fpage><lpage>5619</lpage><pub-id pub-id-type="pmcid">PMC3359703</pub-id><pub-id pub-id-type="pmid">22514322</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5158-11.2012</pub-id></element-citation></ref><ref id="R22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>H</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Liu</surname><given-names>G</given-names></name><name><surname>Xu</surname><given-names>J</given-names></name><name><surname>Huang</surname><given-names>W</given-names></name><name><surname>Song</surname><given-names>C</given-names></name><name><surname>Wang</surname><given-names>D</given-names></name><name><surname>Tao</surname><given-names>HW</given-names></name><name><surname>Zhang</surname><given-names>LI</given-names></name><name><surname>Liang</surname><given-names>F</given-names></name></person-group><article-title>Phasic Off responses of auditory cortex underlie perception of sound duration</article-title><source>Cell Rep</source><year>2021</year><volume>35</volume><pub-id pub-id-type="pmcid">PMC8154544</pub-id><pub-id pub-id-type="pmid">33882311</pub-id><pub-id pub-id-type="doi">10.1016/j.celrep.2021.109003</pub-id></element-citation></ref><ref id="R23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norman-Haignere</surname><given-names>SV</given-names></name><name><surname>Long</surname><given-names>LK</given-names></name><name><surname>Devinsky</surname><given-names>O</given-names></name><name><surname>Doyle</surname><given-names>W</given-names></name><name><surname>Irobunda</surname><given-names>I</given-names></name><name><surname>Merricks</surname><given-names>EM</given-names></name><name><surname>Feldstein</surname><given-names>NA</given-names></name><name><surname>McKhann</surname><given-names>GM</given-names></name><name><surname>Schevon</surname><given-names>CA</given-names></name><name><surname>Flinker</surname><given-names>A</given-names></name><name><surname>Mesgarani</surname><given-names>N</given-names></name></person-group><article-title>Multiscale temporal integration organizes hierarchical computation in human auditory cortex</article-title><source>Nat Hum Behav</source><year>2022</year><volume>6</volume><fpage>455</fpage><lpage>469</lpage><pub-id pub-id-type="pmcid">PMC8957490</pub-id><pub-id pub-id-type="pmid">35145280</pub-id><pub-id pub-id-type="doi">10.1038/s41562-021-01261-y</pub-id></element-citation></ref><ref id="R24"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Oliver</surname><given-names>DL</given-names></name></person-group><chapter-title>Neuronal Organization in the Inferior Colliculus</chapter-title><person-group person-group-type="editor"><name><surname>Winer</surname><given-names>JA</given-names></name><name><surname>Schreiner</surname><given-names>CE</given-names></name></person-group><source>The Inferior Colliculus</source><publisher-name>Springer New York</publisher-name><publisher-loc>New York, NY</publisher-loc><year>2005</year><fpage>69</fpage><lpage>114</lpage><pub-id pub-id-type="doi">10.1007/0-387-27083-3_2</pub-id></element-citation></ref><ref id="R25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Sridhar</surname><given-names>S</given-names></name><name><surname>Pennington</surname><given-names>J</given-names></name><name><surname>Stringer</surname><given-names>C</given-names></name></person-group><article-title>Spike sorting with Kilosort4</article-title><source>Nat Methods</source><year>2024</year><volume>21</volume><fpage>914</fpage><lpage>921</lpage><pub-id pub-id-type="pmcid">PMC11093732</pub-id><pub-id pub-id-type="pmid">38589517</pub-id><pub-id pub-id-type="doi">10.1038/s41592-024-02232-7</pub-id></element-citation></ref><ref id="R26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Stringer</surname><given-names>C</given-names></name><name><surname>Dipoppa</surname><given-names>M</given-names></name><name><surname>Schröder</surname><given-names>S</given-names></name><name><surname>Rossi</surname><given-names>LF</given-names></name><name><surname>Dalgleish</surname><given-names>H</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><article-title>Suite2p: beyond 10,000 neurons with standard two-photon microscopy</article-title><year>2017</year><pub-id pub-id-type="doi">10.1101/061507</pub-id></element-citation></ref><ref id="R27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scheidt</surname><given-names>RE</given-names></name><name><surname>Kale</surname><given-names>S</given-names></name><name><surname>Heinz</surname><given-names>MG</given-names></name></person-group><article-title>Noise-induced hearing loss alters the temporal dynamics of auditory-nerve responses</article-title><source>Hear Res</source><year>2010</year><volume>269</volume><fpage>23</fpage><lpage>33</lpage><pub-id pub-id-type="pmcid">PMC2934744</pub-id><pub-id pub-id-type="pmid">20696230</pub-id><pub-id pub-id-type="doi">10.1016/j.heares.2010.07.009</pub-id></element-citation></ref><ref id="R28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scholl</surname><given-names>B</given-names></name><name><surname>Gao</surname><given-names>X</given-names></name><name><surname>Wehr</surname><given-names>M</given-names></name></person-group><article-title>Nonoverlapping sets of synapses drive on responses and off responses in auditory cortex</article-title><source>Neuron</source><year>2010</year><volume>65</volume><fpage>412</fpage><lpage>21</lpage><elocation-id>S0896-6273(10)00046-2 [pii]</elocation-id><pub-id pub-id-type="pmcid">PMC3800047</pub-id><pub-id pub-id-type="pmid">20159453</pub-id><pub-id pub-id-type="doi">10.1016/j.neuron.2010.01.020</pub-id></element-citation></ref><ref id="R29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sollini</surname><given-names>J</given-names></name><name><surname>Chapuis</surname><given-names>GA</given-names></name><name><surname>Clopath</surname><given-names>C</given-names></name><name><surname>Chadderton</surname><given-names>P</given-names></name></person-group><article-title>ON-OFF receptive fields in auditory cortex diverge during development and contribute to directional sweep selectivity</article-title><source>Nat Commun</source><year>2018</year><volume>9</volume><pub-id pub-id-type="pmcid">PMC5970219</pub-id><pub-id pub-id-type="pmid">29802383</pub-id><pub-id pub-id-type="doi">10.1038/s41467-018-04548-3</pub-id></element-citation></ref><ref id="R30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Solyga</surname><given-names>M</given-names></name><name><surname>Barkat</surname><given-names>TR</given-names></name></person-group><article-title>Emergence and function of cortical offset responses in sound termination detection</article-title><source>eLife</source><year>2021</year><volume>10</volume><elocation-id>e72240</elocation-id><pub-id pub-id-type="pmcid">PMC8673837</pub-id><pub-id pub-id-type="pmid">34910627</pub-id><pub-id pub-id-type="doi">10.7554/eLife.72240</pub-id></element-citation></ref><ref id="R31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suga</surname><given-names>N</given-names></name></person-group><article-title>Single unit activity in cochlear nucleus and inferior colliculus of echo-locating bats</article-title><source>J Physiol</source><year>1964</year><volume>172</volume><fpage>449</fpage><lpage>474</lpage><pub-id pub-id-type="pmcid">PMC1368861</pub-id><pub-id pub-id-type="pmid">14201578</pub-id><pub-id pub-id-type="doi">10.1113/jphysiol.1964.sp007432</pub-id></element-citation></ref><ref id="R32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tian</surname><given-names>B</given-names></name><name><surname>Kuśmierek</surname><given-names>P</given-names></name><name><surname>Rauschecker</surname><given-names>JP</given-names></name></person-group><article-title>Analogues of simple and complex cells in rhesus monkey auditory cortex</article-title><source>Proc Natl Acad Sci</source><year>2013</year><volume>110</volume><fpage>7892</fpage><lpage>7897</lpage><pub-id pub-id-type="pmcid">PMC3651431</pub-id><pub-id pub-id-type="pmid">23610391</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1221062110</pub-id></element-citation></ref><ref id="R33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Lu</surname><given-names>T</given-names></name><name><surname>Bendor</surname><given-names>D</given-names></name><name><surname>Bartlett</surname><given-names>E</given-names></name></person-group><article-title>Neural coding of temporal information in auditory thalamus and cortex</article-title><source>Neuroscience</source><year>2008</year><volume>157</volume><fpage>484</fpage><lpage>94</lpage><pub-id pub-id-type="pmid">19143093</pub-id></element-citation></ref><ref id="R34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Westerman</surname><given-names>LA</given-names></name><name><surname>Smith</surname><given-names>RL</given-names></name></person-group><article-title>Rapid and short-term adaptation in auditory nerve responses</article-title><source>Hear Res</source><year>1984</year><volume>15</volume><fpage>249</fpage><lpage>260</lpage><pub-id pub-id-type="pmid">6501113</pub-id></element-citation></ref><ref id="R35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xie</surname><given-names>R</given-names></name><name><surname>Gittelman</surname><given-names>JX</given-names></name><name><surname>Pollak</surname><given-names>GD</given-names></name></person-group><article-title>Rethinking Tuning: In Vivo Whole-Cell Recordings of the Inferior Colliculus in Awake Bats</article-title><source>J Neurosci</source><year>2007</year><volume>27</volume><fpage>9469</fpage><lpage>9481</lpage><pub-id pub-id-type="pmcid">PMC6673120</pub-id><pub-id pub-id-type="pmid">17728460</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2865-07.2007</pub-id></element-citation></ref><ref id="R36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yin</surname><given-names>TCT</given-names></name><name><surname>Smith</surname><given-names>PH</given-names></name><name><surname>Joris</surname><given-names>PX</given-names></name></person-group><article-title>Neural Mechanisms of Binaural Processing in the Auditory Brainstem</article-title><source>Compr Physiol</source><year>2019</year><volume>9</volume><fpage>1503</fpage><lpage>1575</lpage><pub-id pub-id-type="pmid">31688966</pub-id></element-citation></ref><ref id="R37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Young</surname><given-names>ED</given-names></name><name><surname>Brownell</surname><given-names>WE</given-names></name></person-group><article-title>Responses to tones and noise of single cells in dorsal cochlear nucleus of unanesthetized cats</article-title><source>J Neurophysiol</source><year>1976</year><volume>39</volume><fpage>282</fpage><lpage>300</lpage><pub-id pub-id-type="pmid">1255224</pub-id></element-citation></ref><ref id="R38"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Young</surname><given-names>ED</given-names></name><name><surname>Davis</surname><given-names>KA</given-names></name></person-group><chapter-title>Circuitry and Function of the Dorsal Cochlear Nucleus</chapter-title><person-group person-group-type="editor"><name><surname>Oertel</surname><given-names>D</given-names></name><name><surname>Fay</surname><given-names>RR</given-names></name><name><surname>Popper</surname><given-names>AN</given-names></name></person-group><source>Integrative Functions in the Mammalian Auditory Pathway</source><publisher-name>Springer</publisher-name><publisher-loc>New York, NY</publisher-loc><year>2002</year><fpage>160</fpage><lpage>206</lpage><pub-id pub-id-type="doi">10.1007/978-1-4757-3654-0_5</pub-id></element-citation></ref></ref-list></back><floats-group><boxed-text id="BX1" position="float" orientation="portrait"><label>Key points summary</label><list list-type="bullet" id="L1"><list-item><p id="P79">Offset responses are found throughout the central auditory system</p></list-item><list-item><p id="P80">Offset responses are often combined to sustained and onset responses at all central auditory system stages</p></list-item><list-item><p id="P81">Offset responses provide richer information about elapsed sounds in the auditory cortex</p></list-item></list></boxed-text><fig id="F1" position="float"><label>Figure 1</label><caption><title>Description of the two multi-area auditory response datasets.</title><p><bold>A</bold>. Schematic summarizing the recording methods (extracellular multi-electrode electrophysiology: “ephys”, and two-photon calcium imaging: “2P”) and the four recorded areas. <bold>B</bold>. Summary of the number of putative neurons recorded in each region for each dataset. <bold>C</bold>. Response reproducibility across datasets. <bold>D</bold>. Sample spectrograms for each sound type played in each of the two datasets.</p></caption><graphic xlink:href="EMS205781-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Offset responses are prominent at all stages of the auditory system.</title><p><bold>A</bold>. Sample responses of three selected neurons in each of the recorded areas for six different sounds. Neurons of the cochlear nucleus (CN) stem from dataset 1 and neurons of the inferior colliculus (IC), medial geniculate nucleus (TH) and auditory cortex (AC) stem from dataset 2. <bold>B</bold>. Heat map of the responses of all recorded neurons for the areas and datasets shown in B for one sound (Pure tone at 16 kHz/70 dB SPL and 24 kHz/80 dB SPL). <bold>C</bold>. (left) Heat map of the responses of responsive neurons to white noise at 70 dB SPL in the cochlear nucleus (CN ephys 1). (right) Heat map of the responses of responsive neurons to 6 different white noise sounds (different intensity profiles) in the inferior colliculus (IC ephys 1).</p></caption><graphic xlink:href="EMS205781-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Offset responses are complex at all stages of the auditory system.</title><p><bold>A</bold>. Schematic of the statistical method used to detect onset, sustained and offset responses. <bold>B</bold>. Fraction of all pairs of sound response and neuron displaying a significant change of firing rate at the offset. Grey dotted line indicates the chance level (FDR, alpha of 0.05). <bold>C</bold>. Fraction of neurons for which at least one significant positive or negative offset response was detected among all tested sounds. Grey dotted line indicates the chance level (FDR, alpha of 0.05). <bold>D</bold>. Distribution of the fraction of responses with a significant change of firing rate (positive or negative) at the offset for each dataset. <bold>E</bold>. Fraction of all pairs of sound response and neuron corresponding to each possible combination of positive (E) or negative (I) onset (ON), sustained and offset (OFF) responses (18 combinations).</p></caption><graphic xlink:href="EMS205781-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Offset responses are more informative in the auditory cortex.</title><p><bold>A</bold>. Schematic of the sound decoders used to predict sound identity based on neural activity. <bold>B</bold>. Accuracy of population activity decoders using the full spatio-temporal activity patterns (black) or only the time-averaged spatial pattern (grey). The accuracy of spatio-temporal decoders is used in C&amp;D as the information ceiling with which the time-restricted decoder accuracy is normalized. Grey dotted line indicates the chance level (1/N sounds). <bold>C</bold>. Normalized accuracy of population decoders based on time-averaged firing rates computed during the onset, sustained and offset phases of the responses respectively for all datasets and recorded brain regions. The normalized accuracy represents the fraction of the ceiling accuracy estimated with the full spatio-temporal decoder (see B). Grey dotted line indicates the chance level. <bold>D</bold>. Normalized accuracies for decoders trained in one response phase but tested on another response phase. Grey dotted line indicates the chance level.</p></caption><graphic xlink:href="EMS205781-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>Offset information is specific to offset responses.</title><p><bold>A</bold>. Schematic of the response demixing algorithm used to separate smeared sustained responses from real offset responses in two-photon calcium imaging. <bold>B</bold>. (left) Scatter plot of all the time averaged deconvolved calcium signals in the offset and sustained time window showing a strong correlation between the two values. (right) Scatter plot of all the fitted offset and sustained coefficients for the demixing models in the offset and sustained time window showing a decorrelation of the offset and sustained component of sound responses. <bold>C</bold>. Decoder accuracies based only on the offset component of the response model compared to accuracies based on raw data (blue and green dotted lines identical to <xref ref-type="fig" rid="F4">Fig. 4</xref>). Grey dotted line indicates the chance level. <bold>D</bold>. Accuracy of the decoder based on the offset component of the response model when tested on the onset and sustained components of the response model. Grey dotted line indicates the chance level.</p></caption><graphic xlink:href="EMS205781-f005"/></fig><table-wrap id="T1" orientation="portrait" position="float"><label>Table 1</label><caption><title>Summary of the datasets</title></caption><table frame="box" rules="groups"><thead><tr><th valign="middle" align="center" colspan="7" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000;background: #d9d9d9">Dataset 1</th></tr><tr><th valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000;background: #d9d9d9"/><th valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000;background: #d9d9d9">Method</th><th valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000;background: #d9d9d9">N animals</th><th valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000;background: #d9d9d9">N session</th><th valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000;background: #d9d9d9">N neurons</th><th valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000;background: #d9d9d9">N good neurons</th><th valign="bottom" align="center" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000;background: #d9d9d9">Soundset</th></tr></thead><tbody><tr><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">CN</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Electrophysiology (1×384)</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">8</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">21</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">2265</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">1421 (63%)</td><td valign="bottom" align="center" rowspan="3" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">119 sounds (pure tones, chords, ramps, frequency sweeps, white noise)</td></tr><tr><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">IC - Central</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Electrophysiology (1×384)</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">9</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">15</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">1197</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">551 (46%)</td></tr><tr><td valign="bottom" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">AC</td><td valign="bottom" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">2 photon calcium imaging</td><td valign="bottom" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">5</td><td valign="bottom" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">15</td><td valign="bottom" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">14055</td><td valign="bottom" align="center" style="border-top:solid 1px #000000;border-left:solid 1px #000000">4217 (30%)</td></tr><tr><td valign="bottom" align="center" colspan="7" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000"/></tr><tr><th valign="bottom" align="center" colspan="7" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000;background: #d9d9d9">Dataset 2</th></tr><tr><th valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000;background: #d9d9d9"/><th valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000;background: #d9d9d9">Method</th><th valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000;background: #d9d9d9">N animals</th><th valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000;background: #d9d9d9">N session</th><th valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000;background: #d9d9d9">N neurons</th><th valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000;background: #d9d9d9">N good neurons</th><th valign="bottom" align="center" style="border-top: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000;background: #d9d9d9">Soundset</th></tr><tr><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">IC - Central</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Electrophysiology (1×32)</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">11</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">30</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">563</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">442 (78%)</td><td valign="bottom" align="center" rowspan="4" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-right: 1px solid #000000;border-left: 1px solid #000000">112 sounds (pure tones, up/down ramps, up/down frequency sweeps)</td></tr><tr><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">IC - Dorsal</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">2 photon calcium imaging</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">30</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">101</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">15312</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">5936 (39%)</td></tr><tr><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">TH</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">Electrophysiology (4×8)</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">10</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">33</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">498</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-left: 1px solid #000000">484 (97%)</td></tr><tr><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid #000000">AC</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid #000000">2 photon calcium imaging</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid #000000">7</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid #000000">60</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid #000000">60822</td><td valign="bottom" align="center" style="border-top: 1px solid #000000;border-bottom: 1px solid #000000;border-left: 1px solid #000000">19414 (32%)</td></tr></tbody></table></table-wrap></floats-group></article>