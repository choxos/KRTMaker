<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS206953</article-id><article-id pub-id-type="doi">10.1101/2025.06.16.658246</article-id><article-id pub-id-type="archive">PPR1037430</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">1</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Developing a Sensory Representation of an Artificial Body Part</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Dowdall</surname><given-names>Lucy</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Molina-Sanchez</surname><given-names>Maria</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Dominijanni</surname><given-names>Giulia</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>da Silva</surname><given-names>Edmund</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Pavalkyte</surname><given-names>Viktorija</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Jugovic</surname><given-names>Ema</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Bianchi</surname><given-names>Matteo</given-names></name><xref ref-type="aff" rid="A4">4</xref></contrib><contrib contrib-type="author"><name><surname>Iida</surname><given-names>Fumiya</given-names></name><xref ref-type="aff" rid="A5">5</xref></contrib><contrib contrib-type="author"><name><surname>Clode</surname><given-names>Dani</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A6">6</xref></contrib><contrib contrib-type="author"><name><surname>Makin</surname><given-names>Tamar R.</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref></contrib></contrib-group><aff id="A1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/055bpw879</institution-id><institution>MRC Cognition and Brain Sciences Unit</institution></institution-wrap>, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/013meh722</institution-id><institution>University of Cambridge</institution></institution-wrap>, <city>Cambridge</city>, <country country="GB">UK</country></aff><aff id="A2"><label>2</label>Institute of Cognitive Neuroscience, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>University College London</institution></institution-wrap>, <city>London</city>, <country country="GB">UK</country></aff><aff id="A3"><label>3</label>Neuro-X Institute, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/02s376052</institution-id><institution>Ecole Polytechnique Fédérale de Lausanne</institution></institution-wrap>, <city>Lausanne</city>, <country country="CH">Switzerland</country></aff><aff id="A4"><label>4</label>Research Center “E. Piaggio” and Department of Information Engineering, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/03ad39j10</institution-id><institution>University of Pisa</institution></institution-wrap>, <city>Pisa</city>, <country country="IT">Italy</country></aff><aff id="A5"><label>5</label>Department of Engineering, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/013meh722</institution-id><institution>University of Cambridge</institution></institution-wrap>, <city>Cambridge</city>, <country country="GB">UK</country></aff><aff id="A6"><label>6</label>Dani Clode Design, Cambridge, UK</aff><pub-date pub-type="nihms-submitted"><day>11</day><month>07</month><year>2025</year></pub-date><pub-date pub-type="preprint"><day>17</day><month>06</month><year>2025</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Somatosensory feedback is essential for motor control, yet artificial limbs are thought to lack such feedback. We investigated how the body and brain gather informative sensory signals from a wearable augmentation interface (a robotic digit for motor augmentation), and whether naturally-mediated feedback can support technological embodiment.</p><p id="P2">Participants intuitively interpreted natural feedback across perceptual tasks, performing comparably to state-of-the-art artificial feedback systems. fMRI revealed an immediate and distinct, topographically-organised representation of the robotic digit. After longitudinal training, this representation was further refined, becoming more similar to the biological digits, which correlated with increased subjective somatosensory embodiment.</p><p id="P3">Our findings demonstrate that wearable devices naturally provide a powerful source of feedback which is immediately integrated with our body. Long-term use can then promote device-embodiment across the sensorimotor hierarchy.</p></abstract></article-meta></front><body><sec id="S1" sec-type="intro"><title>Introduction</title><p id="P4">Motor control is thought to be governed by the sensorimotor loop (<xref ref-type="bibr" rid="R1">1</xref>), where sensory feedback informs about the success of our actions to drive motor learning. Somatosensory feedback (primarily encompassing touch and proprioception) plays a crucial role in both online motor planning and error correction, as well as offline skill acquisition and consolidation (<xref ref-type="bibr" rid="R2">2</xref>–<xref ref-type="bibr" rid="R4">4</xref>). Its importance is strikingly demonstrated in the motor deficits observed in its absence (<xref ref-type="bibr" rid="R5">5</xref>,<xref ref-type="bibr" rid="R6">6</xref>).</p><p id="P5">This reliance on somatosensory feedback poses a challenge for technologies that compliment, replace or expand human movement abilities, such as prosthetic limbs (<xref ref-type="bibr" rid="R7">7</xref>,<xref ref-type="bibr" rid="R8">8</xref>), brain-machine interfaces (<xref ref-type="bibr" rid="R9">9</xref>,<xref ref-type="bibr" rid="R10">10</xref>), and augmentative extra robotic body parts (<xref ref-type="bibr" rid="R11">11</xref>–<xref ref-type="bibr" rid="R15">15</xref>). Such technologies are said to suffer from ‘open-loop’ control (<xref ref-type="bibr" rid="R16">16</xref>–<xref ref-type="bibr" rid="R18">18</xref>), where motor signals are sent out, but no corresponding somatosensory feedback is received. To address this, research has focused on artificial sensory feedback systems, aiming to replace this missing input.</p><p id="P6">Primarily focusing on touch, current efforts to produce artificial feedback include exploration of invasive electrical stimulation at the periphery (<xref ref-type="bibr" rid="R19">19</xref>,<xref ref-type="bibr" rid="R20">20</xref>), spinal cord (<xref ref-type="bibr" rid="R21">21</xref>,<xref ref-type="bibr" rid="R22">22</xref>) and primary somatosensory cortex (S1) (<xref ref-type="bibr" rid="R23">23</xref>,<xref ref-type="bibr" rid="R24">24</xref>), in addition to non-invasive electrotactile (<xref ref-type="bibr" rid="R25">25</xref>,<xref ref-type="bibr" rid="R26">26</xref>), mechanotactile (<xref ref-type="bibr" rid="R27">27</xref>–<xref ref-type="bibr" rid="R30">30</xref>) and vibratory feedback signals (<xref ref-type="bibr" rid="R31">31</xref>–<xref ref-type="bibr" rid="R33">33</xref>) (reviewed in <xref ref-type="bibr" rid="R34">34</xref>). However, unlike the rich, multimodal information conveyed in natural touch, these solutions offer signals with reduced dimensionality that cannot replicate the same diversity of feature extraction, raising questions regarding the fidelity of artificial haptics (<xref ref-type="bibr" rid="R35">35</xref>). Moreover, artificial signals are designed to meet perceptual thresholds, thus risking overriding more subtle yet highly informative existing sensory inputs. This highlights a particular barrier for technologies that extend, rather than replace, motor abilities. We have limited neural capacity that is already fully dedicated to representing our biological body (<xref ref-type="bibr" rid="R36">36</xref>–<xref ref-type="bibr" rid="R38">38</xref>). Consequently, these devices must share existing resources, without disrupting natural motor control (soft embodiment) (<xref ref-type="bibr" rid="R39">39</xref>,<xref ref-type="bibr" rid="R40">40</xref>).</p><p id="P7">Therefore, a key guiding principle is how artificial systems feedback may be best ‘embodied’ into our sensorimotor system. Embodiment is an umbrella term that broadly captures the ability to relate to external objects as if they were a body part (<xref ref-type="bibr" rid="R41">41</xref>). Theoretically, achieving embodiment requires a closed-loop system, making sensory feedback essential (<xref ref-type="bibr" rid="R42">42</xref>). However, how integration into the sensorimotor system manifests at the neural level remains unclear (<xref ref-type="bibr" rid="R43">43</xref>,<xref ref-type="bibr" rid="R44">44</xref>).</p><p id="P8">We aimed to determine how the sensory representation of an extra robotic body part first emerges and is then refined through sensorimotor experience. We used the Third Thumb (Dani Clode Design; <xref ref-type="fig" rid="F1">Figure 1A</xref>; hereafter Digit 6 (D6)), a supernumerary robotic digit designed for collaborative use with the biological fingers to extend hand functionality. We have previously demonstrated that people can successfully perform a proprioceptive task with D6, despite not having any additional artificial feedback (non-sensorised) (<xref ref-type="bibr" rid="R45">45</xref>,<xref ref-type="bibr" rid="R46">46</xref>). Similar results were also replicated with non-sensorised prosthetic devices (<xref ref-type="bibr" rid="R47">47</xref>, see also <xref ref-type="bibr" rid="R48">48</xref>). This suggests that artificial limbs may not be inherently open-loop systems, and naturally-mediated somatosensory cues from how devices directly interact with our somatosensory system may be leveraged to provide somatosensory awareness and help close the sensorimotor loop. Specifically, inputs relating to D6’s movement and interactions travel via the physical connection of D6 with the palm (<xref ref-type="fig" rid="F1">Figure 1B</xref>). Similarly, naturally-mediated somatosensory feedback from the controllers of D6 have been shown to support motor learning (<xref ref-type="bibr" rid="R49">49</xref>).</p><p id="P9">In the current study, we first characterised how “natural” sensory feedback on the hand can support sensory perception of a robotic extra digit in comparison to state-of-the-art artificial sensory feedback. We will refer to this feedback as ‘natural’, even though the source of the input is artificial (e.g. external stimulation delivered to D6 through its interactions with the environment), as the input is mediated from D6 to the hand (and nervous system) without the support of sensors and actuators. We then examined how this natural feedback integrates with the somatosensory representation of the hand at both the perceptual and neural levels. Finally, we explored construction of a sensory representation of D6 in relation to the human hand following extended motor training. We find that the brain rapidly accesses and integrates natural tactile feedback into sensory representations across the sensorimotor hierarchy, offering a potential means to ‘close’ the sensorimotor loop for wearable technology.</p></sec><sec id="S2" sec-type="results"><title>Results</title><sec id="S3"><title>Natural feedback signals can be easily and intuitively interpreted by a novice user</title><p id="P10">To demonstrate the potential utility of natural feedback, we first developed a proof-of-concept test to index natural somatosensory perceptual abilities. We isolated two components that contribute to the tactile and proprioceptive somatosensory awareness of the Third Thumb (Digit 6; D6): skin stretch from D6 movement and vibrotactile input from D6-object contact. Two artificial feedback systems were developed to replicate these aspects, enabling a perceptual comparison of natural and artificial touch.</p><p id="P11">To deliver artificial skin stretch, we developed a feedback system, where deformation received on the tip of D6 produced a proportional amount of linear skin stretch via an actuator worn on the user’s inner wrist (<xref ref-type="fig" rid="F1">Figure 1C</xref>). For the vibrotactile feedback system, any displacement of D6, due to object impact, produced a proportional amount of vibration delivered via an actuator (<xref ref-type="bibr" rid="R50">50</xref>) worn on the user’s ring finger (<xref ref-type="fig" rid="F1">Figure 1D</xref>). We tested each of these systems on a material discrimination task: material deformation for the skin stretch system (<xref ref-type="fig" rid="F1">Figure 1C</xref>), and texture coarseness for the vibrotactile system (<xref ref-type="fig" rid="F1">Figure 1D</xref>). In a within-participant design (<italic>N</italic>=22), performance was compared relative to the wearable D6 device which was originally designed to mediate these sensory components via natural touch (i.e. sensory information that is naturally mediated to the hand without the aid of sensors and actuators; <xref ref-type="fig" rid="F1">Figure 1B</xref>). In each trial, feedback resulting from interactions with two different materials was presented to the (blindfolded) participant (either remotely via the artificial system, or directly via the worn D6). Individual participants’ responses (two-alternative force choice; 2AFC) were fitted to a psychometric curve for each condition, and the slope was extracted as a measure of discrimination ability. Larger values (steeper slope) indicated increased sensitivity for discriminating between materials.</p><p id="P12">We found that, as expected, participants were able to successfully perform each of the tasks using the relevant artificial feedback system (slope significantly above zero, <italic>W</italic>≥171,<italic>p</italic>&lt;.001). Participants were also able to perform the task with just the natural feedback extracted from the worn D6 (<italic>W</italic>≥190,<italic>p</italic>&lt;.001), demonstrating that natural feedback signals can be easily and intuitively interpreted by a novice user. Crucially, participants performed comparably with the natural and artificial systems (skin stretch: <italic>W</italic>(19)=88,<italic>p</italic>=.546,BF<sub>10</sub>=.251), and even outperformed the vibrotactile artificial system (<italic>W</italic>(15)=111,<italic>p</italic>=.025). This set of results demonstrates that natural feedback–when D6 is worn–provides the same level of perceptual detail as the bespoke artificial systems, but also provides the versatility to mediate different sensory components across material demands in an integrated system.</p><p id="P13">As a control, we also indexed perceptual abilities with D6 against natural sensing abilities, where participants performed a variation of both discrimination tasks with the biological thumb (D1) (<italic>N</italic>=10). Participants consistently outperformed the natural D6 feedback (<italic>U</italic>≥154,<italic>p</italic>≤.017). Therefore, despite the impressive abilities of the natural feedback, it is still not comparable to natural sensing abilities.</p></sec><sec id="S4"><title>“Natural” feedback can be integrated with sensory information from the biological hand</title><p id="P14">Given D6 is designed to be used in collaboration with the biological hand, we next aimed to index how the somatosensory system integrates coordinated somatosensory inputs across D6 and the biological digits.</p><p id="P15">In a new set of participants (<italic>N</italic>=50; novice D6 users), we employed a Temporal Order Judgement (TOJ) task to determine if the natural sensory feedback received when wearing D6 is integrated in the same spatiotemporal reference frame as the biological fingers. Motors were worn on the tips of paired digits to deliver vibrotactile stimuli with various interstimulus intervals (four digit-pairs: D6 &amp; biological thumb (D1), D6 &amp; index finger (D2), D6 &amp; little finger (D5), and D5&amp;D1). Responses (2AFC) were fitted to a psychometric curve for each digit-pair, where the just noticeable difference was extracted as a measure of discrimination ability (see <xref ref-type="supplementary-material" rid="SD1">supplementary material</xref> for point of subjective equality as a measure of bias).</p><p id="P16">We compared D6 digit-pairs performance to the biological-pair. Participants could not only perform the task with D6, but performed just as well as with their biological hand (<italic>W</italic>≥506,<italic>p</italic>≥.661,BF<sub>10</sub>≤.194; <xref ref-type="fig" rid="F1">Figure 1E</xref>). This successful integration implies the same spatiotemporal reference frame is being used to extract the relevant features from the stimuli. We then examined whether inputs closer to D6 would be more easily confused (as with the biological fingers (<xref ref-type="bibr" rid="R51">51</xref>,<xref ref-type="bibr" rid="R52">52</xref>)). However, participants performed just as well across all three D6-pairs (<italic>F</italic>(2,92)=.947,<italic>p</italic>=.392,BF<sub>10</sub>=.173; <xref ref-type="fig" rid="F1">Figure 1E</xref>). This absence of topographical organisation demonstrates the distinctiveness of D6’s sensory information. Together, these results suggest the presence of a distinct and accessible sensory representation for D6.</p></sec><sec id="S5"><title>Emergence of a neural representation of a robotic finger in novice users</title><p id="P17">To investigate how a sensory representation of an extra robotic body part may spontaneously emerge, we explored the neural response in the S1 hand area while tactile stimulation was applied to D6 in novice users (<italic>N</italic>=50; <xref ref-type="fig" rid="F2">Figure 2A</xref>).</p><p id="P18">We first visualised the activity elicited in S1 (specifically BA3b) for each of the digits (D1-D6) (<xref ref-type="fig" rid="F2">Figure 2B</xref>). We extracted the average z-values along the hand area (lateral-left to medial-right) and identified the expected somatotopic structure of the five biological fingers (D1–most lateral peak, D5–most medial peak). D6 stimulation also elicited activity within the hand area, peaking near the centre of the hand representation (adjacent to the D3 peak). This indicates that when mediating sensory information from D6, somatosensory cortex receives diffused inputs from across the entire hand.</p><p id="P19">To examine if a more structured topographic organisation underlies this diffused input, we employed multivariate representational similarity analysis (RSA) to compare D6’s neural representation to that of the palm and biological digits. Our findings reveal that the D6 representation is most similar to that of the palm, reflecting a topographic organisation (see comparable dissimilarity matrix for D6 and Palm in <xref ref-type="fig" rid="F2">Figure 2E</xref>). However, the information content associated with D6 is nevertheless distinct from the palm, demonstrated by a significant cross-nobis distance between the D6 and palm representations (<xref ref-type="fig" rid="F2">Figure 2F</xref>; <italic>W</italic>(48)=1166,<italic>p</italic>&lt;.001). These results provide the first evidence towards a topographic signature of D6, and highlight its unique information content in S1.</p></sec><sec id="S6"><title>Longitudinal D6 training to promote experience-based plasticity</title><p id="P20">We next aimed to understand how the somatosensory representation of D6 is refined through sensorimotor experience. We designed a seven-day D6 training regime (<xref ref-type="fig" rid="F3">Figure 3A</xref>), focused on D6-biological hand collaboration (<italic>n</italic>=30). Our control group replicated this week of altered finger usage by training to play the piano keyboard (no D6 involved, <italic>n</italic>=20). The training protocols resulted in extensive improvements in motor performance with D6 during a range of collaboration tasks (main experimental group; as detailed in <xref ref-type="bibr" rid="R46">46</xref>; <xref ref-type="fig" rid="F3">Figure 3B</xref>), as well as extensive improvements in the control group keyboard task (piano day 1 vs day 7 performance: <italic>F</italic>(1,58)=59.79,<italic>p</italic>&lt;.001; <xref ref-type="fig" rid="F3">Figure 3C</xref>).</p><p id="P21">Following D6 training, we examined perceptual and motor integration across individual D6-biological digit-pairs. We found that while perceptual integration remained unchanged (likely due to ceiling effects in TOJ performance; pre vs post-training: BF<sub>10</sub>=.23), motor coordination improvements were equally observed across all digits (<italic>F</italic>(1,166.91=50.68,<italic>p</italic>&lt;.001, <xref ref-type="fig" rid="F3">Figure 3F</xref> index finger untested). This indicates distributed sensorimotor gains across the whole hand.</p></sec><sec id="S7"><title>Refinement of the sensory representation following D6 training</title><p id="P22">We next examined post-training activity within the S1 hand area. During D6 stimulation, we found the activity peak to be qualitatively higher and more defined, relative to the control group (<xref ref-type="fig" rid="F4">Figure 4A</xref>). This hints at differences in the S1 readout of this peripheral stimulation following training.</p><p id="P23">To quantify any refinement of D6’s neural representation induced by training, we assessed its similarity to (1) the palm and (2) the biological digits, using cross-nobis distance, across timepoints (pre/post training) and groups (D6/keyboard training). Relative to the palm, the D6 representation was stable (<italic>F</italic>(1,44)=1.032,<italic>p</italic>=.315; <xref ref-type="fig" rid="F4">Figure 4C</xref>). However, the D6 representation became more associated with the biological digits, specifically following D6 training (group x session interaction: <italic>F</italic>(1,396)=8.08,<italic>p</italic>=.005; <xref ref-type="fig" rid="F4">Figure 4B</xref>). Notably, this was found across all biological fingers, mirroring the behavioural results of similar gains across the whole hand. Put together, these results indicate that while the representation of D6 to the palm is context invariable, the rich interactions between D6 and the biological digits induced during training facilitated greater integration of D6 into the hand representation.</p></sec><sec id="S8"><title>D6-hand coordination training impacts hand kinematics</title><p id="P24">To better understand how D6 training affects this sensory integration, we compared finger kinematics during D6 task performance at the beginning and end of training. We measured biological finger co-use using a markerless tracking setup, during a series of free-choice tasks that required complex coordination patterns (see <xref ref-type="bibr" rid="R46">46</xref> for motor results; <xref ref-type="fig" rid="F3">Figure 3D</xref>). Following longitudinal D6 training, we found decreased co-usage (i.e. increased individuation) of the biological fingers, which was not seen in the control group (group x session interaction: <italic>F</italic>(1,1950.73)=4.777,<italic>p</italic>=.029; <xref ref-type="fig" rid="F4">Figure 4D</xref>). This suggests that prolonged D6 use induces changes in biological finger coordination patterns.</p><p id="P25">To assess whether these changes extend beyond direct D6 use, we also recorded finger kinematics while participants performed the same tasks using only their biological hand (D6 off). Following training, the D6 study group maintained the same co-use patterns whether or not they were using D6, whilst the control group showed a significant decline in finger co-usage (more free individuation) (group x D6 on/D6 off: <italic>F</italic>(1,1885.74)=13.33,<italic>p</italic>&lt;.001; <xref ref-type="fig" rid="F3">Figure 3E</xref>). This indicates that D6 training impacts hand kinematics beyond just the motor demands of D6 use; further implying D6 use may not only trigger changes to the D6 representation, but also of the biological fingers themselves (see <xref ref-type="bibr" rid="R45">45</xref>).</p></sec><sec id="S9"><title>Altered finger coordination impacts sensory hand representation</title><p id="P26">Given this impact on the biological hand, we also explored training-related changes in inter-finger representational relationships in S1 (disregarding D6), using RSA (see <xref ref-type="supplementary-material" rid="SD1">Figure S1</xref> for univariate results). Both groups exhibited a significant reduction in inter-finger dissimilarity, reflecting an altered hand representation following sensorimotor skill learning (<xref ref-type="fig" rid="F5">Figure 5</xref>), as previously reported for both D6 (<xref ref-type="bibr" rid="R45">45</xref>) and piano training (<xref ref-type="bibr" rid="R53">53</xref>,<xref ref-type="bibr" rid="R54">54</xref>). However, the piano control group showed a greater training effect, with a larger reduction in distances (group X session: <italic>F</italic>(1,836)=9.798,<italic>p</italic>=.002). These changes in neural representation compliment the kinematic effects, which demonstrated greater individuation in the biological hand-only free manipulation task (<xref ref-type="fig" rid="F3">Figure 3D-E</xref>).</p></sec><sec id="S10"><title>Neural integration of D6 is reflected by somatosensory embodiment following training</title><p id="P27">Finally, we examined whether D6 perceptual and neural integration was reflected in perceived (phenomenological) sense of embodiment. To assess this, participants completed a questionnaire in both the pre- and post-training sessions, covering multiple embodiment dimensions: Somatosensation, Body Ownership, Body Image, and Agency (latter discussed in <xref ref-type="bibr" rid="R46">46</xref>).</p><p id="P28">Before training, participants responded neutrally, and even negatively to embodiment statements across domains. Although participants could extract and integrate somatosensory cues from D6 (as reported in <xref ref-type="fig" rid="F1">Figures 1C-E</xref>), this did not translate into subjective experience of somatosensory embodiment. Participants responded neutrally in the somatosensation category, with ratings not significantly different from zero (<italic>t</italic>(50)=1.527,<italic>p</italic>=.133,BF<sub>10</sub>=0.452). Responses to Body Ownership and Body Image were negative (significantly below zero, p=.018 and p&lt;.001, respectively). Following D6 training, participants reported greater embodiment across categories compared to controls (group x session: <italic>F</italic>(1,226.85)=9.127,<italic>p</italic>=.003; <xref ref-type="fig" rid="F6">Figure 6A</xref>). However, it was only in the Somatosensation category that D6 participants responded positively (significantly above zero; <italic>t</italic>(27)=3.840,<italic>p</italic>&lt;.001; control group: <italic>t</italic>(18)=0.604,<italic>p</italic>=.553). For Body Ownership and Image, trained participants also responded neutrally (BF<sub>10</sub>=0.318 for both).</p><p id="P29">To establish if changes to experiential embodiment related to neural embodiment of D6, we correlated the change (post-pre-training) in cross-nobis distance between the D6-D1 pair, and in somatosensory embodiment ratings. The D6 training group showed a significant negative correlation (<italic>r</italic>(26)=-.451,<italic>p</italic>=.016; <xref ref-type="fig" rid="F6">Figure 6B</xref>), not seen for the controls (<italic>r</italic>(14)=-.266,<italic>p</italic>=.320; <xref ref-type="fig" rid="F6">Figure 6C</xref>), where decreased distance (increased similarity) between D6 and D1 corresponded to increased feelings of sensory embodiment (although note the two correlations were not significantly different from each other: <italic>Z</italic>=0.63,<italic>p</italic>=0.53).</p><p id="P30">Together, these findings support that extensive training with D6 facilitates somatosensory integration across all levels of the sensorimotor hierarchy-experiential, perceptual, kinematic, and neural.</p></sec></sec><sec id="S11" sec-type="discussion"><title>Discussion</title><p id="P31">Our findings provide a holistic characterisation of how the human sensorimotor system can integrate an artificial limb into its somatosensory body representation, offering insight into the plasticity mechanisms that underly how we perceive and interact with the world around us. We have demonstrated that our somatosensory system can extract detailed information from the natural sensory cues arising from the physical interaction between an artificial limb (the Third Thumb (D6)) and integrate it with our body representation. Our body representation can quickly adapt to D6 across the sensorimotor hierarchy, suggesting we do not even need experience with an artificial limb to see meaningful integration with the body. However, this neural integration at the early stages of usage is not reflected in subjective experience; novice users had not developed a perceived sense of somatosensory embodied connection. Following training however, we observe multiple experience-dependent changes to hand-D6 integration. Not only do people successfully learn to use D6, but this experience also modulates adaptation of the body across both kinematic and neural matrices. These quantitative experience-driven changes in sensory integration appears to reflect a categorical shift in the subjective experience of the users, who now report feelings of somatosensory embodiment towards D6. These embodiment gains were asssociated with increased similarity between the way the biological hand and D6 are being represented in S1.</p><p id="P32">The fact that both the body and D6 representations are changing following extensive experience to use D6 calls for caution while considering the mechanism underlying this integration of D6 with the body. It remains an open question if this is a manifestation of sensory embodiment (<xref ref-type="bibr" rid="R45">45</xref>,<xref ref-type="bibr" rid="R55">55</xref>,<xref ref-type="bibr" rid="R56">56</xref>), or if this is simply reflecting the signatures of well-established adaptive plasticity mechanisms (<xref ref-type="bibr" rid="R57">57</xref>,<xref ref-type="bibr" rid="R58">58</xref>). When training to incorporate D6 into the motor repertoire, the body is undergoing two simultaneous changes – altered hand use, while also gaining a new somatosensory input (via D6). To disassociate the respective roles of these two changes, we can gain insight from our control group, who also trained to alter their hand use, but did not experience an additional somatosensory input. Indeed, while control participants show greater changes to the biological hand representation following training, the D6 training group showed increased changes to the integration of D6 into the hand representation. These results, which were also mirrored in the kinematics results, illustrates the unique role of sensorimotor experience in shaping the representation of an artificial body part into our body representation.</p><p id="P33">Nevertheless, it is important to highlight that the representation of D6 is inherently rooted in the biological hand representation – S1 does not reallocate neural resources of the body to develop an emerging representation of D6 (<xref ref-type="bibr" rid="R39">39</xref>,<xref ref-type="bibr" rid="R40">40</xref>). Instead, it integrates the inputs from D6 into our body representation. This observation distinguishes our findings from previous studies examining representation and embodiment of hand-held tools (<xref ref-type="bibr" rid="R44">44</xref>,<xref ref-type="bibr" rid="R59">59</xref>–<xref ref-type="bibr" rid="R61">61</xref>), and artificial limbs for substitution (<xref ref-type="bibr" rid="R43">43</xref>,<xref ref-type="bibr" rid="R62">62</xref>–<xref ref-type="bibr" rid="R65">65</xref>). Indeed, unlike tools, D6 is used <italic>with</italic> the hand, rather than <italic>by the hand</italic>. Therefore, the simultaneous changes to the representations of D6 and the biological digits result in a novel form of integration into the body representation, which sidesteps the issue of the limited neural resources that are available in S1 (<xref ref-type="bibr" rid="R39">39</xref>).</p><p id="P34">While our findings highlight the brain's capacity for novel sensory integration, important questions remain regarding the purpose and longevity of these adaptations. A limit to our interpretation is that we do not know if the neural changes to the represenation of D6 observed in S1 are stable, and whether they serve a functional role. We previously demonstarted rapid learning with D6 (successful task performance within the first minutes of use (<xref ref-type="bibr" rid="R66">66</xref>)). Combined with the impressive performance of sensory tasks using D6 by naïve and novice participants shown here, it is possible that functional sensorimotor integration does not require an adapted D6 representation relative to the hand. Conversely, it is possible that further training could have evolved other differences to the S1 body and D6 representation. As augmentation technology becomes more embedded in everyday life, researchers must carefully consider its long-term implications for our bodies.</p><p id="P35">To conclude, we demonstrate the emergence of a distinct representation of an artificial body part within our body representation, and that this emerging representation is further integrated with the hand representation following sensorimotor experience. Understanding this malleability of our sensory body representation is crucial as we look to the future of technology, with successful sensory integration of a device being possible by the simple means of wearing it. By demonstrating the power of our somatosensory system to mediate and integrate such information, we have shown that you cannot change the body without changing the brain. This bidirectional relationship needs to be better harnessed when considering future technologies that interface with the human body and brain.</p></sec><sec id="S12" sec-type="materials | methods"><title>Materials and Methods</title><sec id="S13"><title>The Third Thumb</title><p id="P36">The Third Thumb (Dani Clode Design, London, UK) (Digit 6; D6) is a robotic extra digit that attaches to the ulnar side of the right hand (<xref ref-type="fig" rid="F1">Figure 1A</xref>) and is operated through pressure sensors strapped underneath the big toes. D6 has two degrees of freedom that allow a corresponding proportional control: applying pressure to left big toe sensor causes an adduction/abduction movement, whilst pressure on the right one causes a flexion/extension movement (see further details in <xref ref-type="bibr" rid="R45">45</xref> and <xref ref-type="bibr" rid="R67">67</xref>).</p></sec><sec id="S14"><title>Feedback systems</title><sec id="S15"><title>Skin Stretch system</title><p id="P37">The skin stretch feedback system conveyed pressure information from D6’s tip to the user via a device worn on the inner wrist. The system comprised of three components: (1) a flexible pneumatic deformation sensor, integrated into D6’s tip, (2) an external control unit, and (3) a linear skin stretch device worn on the wrist (<xref ref-type="fig" rid="F1">Figure 1C</xref>; <xref ref-type="supplementary-material" rid="SD1">Figure S2A</xref>).</p><p id="P38">A pneumatic deformation sensor was chosen for its compatibility with D6’s soft, flexible design. A silicone air chamber which deforms upon contact was integrated into D6’s tip, generating pressure changes measurable by the air pressure sensor. This tip was optimised using silicone moulding for improved sensitivity and durability. A custom circuit in the control unit processed the pressure signal, filtering noise before driving the skin stretch device. This device was positioned on the wrist for optimal sensitivity and used a high-torque servomotor to apply precise linear skin stretch, proportional to the pressure input. To enhance comfort and grip, the skin-contacting surface was lined with ethylene-vinyl acetate foam.</p><p id="P39">The system underwent multiple validation tests, where the pneumatic deformation sensor demonstrated 92% accuracy in classifying materials of varying deformability in a model hand test. The skin stretch device achieved 89% accuracy in a human material deformability 2AFC discrimination task involving three materials (full details available in <xref ref-type="supplementary-material" rid="SD1">supplementary materials</xref>).</p></sec><sec id="S16"><title>Vibrotactile system</title><p id="P40">The vibrotactile feedback system conveyed information to the user about any displacement of the D6 tip caused by interactions with the external environment (predominantly object interactions), via high-frequency vibrations to the user’s ring finger. The system comprised of three components: (1) an inertial measurement unit (IMU) attached to the nail area of D6 for sensing, (2) a control unit mounted on the user’s wrist for processing signals, and (3) a vibrotactile actuator positioned on the back of the user’s ring finger to provide feedback (<xref ref-type="fig" rid="F1">Figure 1D</xref>; <xref ref-type="supplementary-material" rid="SD1">Figure S2B</xref>).</p><p id="P41">The custom IMU mounted to D6’s ‘nail’ detected accelerations and vibrations caused by contact events at D6’s tip. The sensor was housed in a lightweight, 3D-printed protective casing. A custom electronic board processed the IMU data and generated control signals for the vibrotactile actuator. Signal noise was mitigated using a fourth-order Chebyshev Type I bandpass filter (120–230 Hz) which removed unwanted artifacts caused by free hand motion, and vibrations caused by D6’s servo and cable driven actuation system. The processed signal was mapped to a pulse-width modulation output, controlling the actuator’s frequency and amplitude. A linear voice coil actuator provided vibrotactile feedback proportional to the IMU output, encased in a custom 3D-printed housing. Elastic fabric within the housing ensured consistent vibrations by returning the actuator to its resting position after each pulse. The actuator was placed on the back of the ring finger, chosen for its high sensitivity to vibrations and minimal interference with hand function.</p><p id="P42">The vibrotactile system was validated using texture discrimination performance. Participants achieved 80% accuracy in a 2AFC task, demonstrating the delivery of interpretable and differentiable tactile information (see <xref ref-type="supplementary-material" rid="SD1">supplementary materials</xref> for full validation task details).</p></sec></sec><sec id="S17" sec-type="subjects"><title>Participants</title><p id="P43">In total, 102 participants took part in the study, see <xref ref-type="supplementary-material" rid="SD1">supplementary table S1</xref> for breakdown of participants per sub-study. The study was approved by the Cambridge Psychology Research Ethics Committee (PREC: 2022.068) and the UCL Research Ethics Committee (project ID number 12921/001). Participants were recruited via online advertisements on the MRC Cognition and Brain Sciences Unit and University of Cambridge SONA participant pools.</p></sec><sec id="S18"><title>Material Discrimination Tasks</title><p id="P44">Using a within-subjects design, the same set of participants performed the material deformation and texture coarseness discrimination tasks across the three feedback systems, using a between-participant counter-balanced order. Due to the artificial feedback design requirements, we restricted the skin stretch system to the deformation task and the vibrotactile system to the coarseness task, whereas the wearable D6 system was used for both tasks.</p><sec id="S19"><title>General Task Design</title><p id="P45">Both material discrimination tasks were 2AFC. For the artificial feedback tasks, feedback was collected with a physically remote sensorised D6 and delivered via a worn actuator. For the natural feedback task, D6 was worn on the user’s hand during the tasks, and feedback provided via the intrinsic wearable interface. For the biological hand only task, the left biological thumb was used (left chosen due to task setup constraints).</p><p id="P46">In each trial, participants received a set reference stimulus first, followed by a comparison stimulus. In the deformation task, participants needed to determine if two deformable foam pieces were the same or different, and in the coarseness task, participants compared between two texture samples, based on the feedback cues available (natural or artificial feedback, in different blocks). Participants responded via a two-key keypad in their left hand.</p><p id="P47">Participants performed the task with their eyes closed, and with white noise playing through over-ear headphones. Volume was adjusted individually to mask the sound of a knock on the table. In addition to the white noise, participants were given a series of beeps to alert them prior to trial onset (t=-1.5sec), trial start time (t=0) and prompt to respond (t=5/3.5 for deformation/coarseness, respectively).</p><p id="P48">Participants were first familiarised with each task. They were asked to feel the various materials with their biological hand, and were then walked through an example trial to ensure task demands were clear. Participants were then given 10 pre-set practice trials with verbal reinforcement for correct performance. Each main experimental block included 50 trials with no verbal reinforcement.</p><p id="P49">In each trial, the comparison stimulus (the second stimulus delivered) was determined online using the adaptive psi method (<xref ref-type="bibr" rid="R67">67</xref>) implemented using the MATLAB Palamedes toolbox (<xref ref-type="bibr" rid="R68">68</xref>). The method estimates parameters of interest based on Bayes theorem, that are continuously updated after each trial response (<xref ref-type="bibr" rid="R69">69</xref>). We set broad prior estimates for both parameters of interest - slope and threshold (50%) based on pilot data. Psychometrics parameters were preset as follows: Deformation discrimination: threshold (-20 – 20; 0.01 steps); slope: -2 – 2; 0.1 steps); Coarseness discrimination: threshold (-10 – 10; 0.01 steps); slope: -2 – 2; 0.1 steps) Offline analysis involved fitting the responses for each task/system block to a psychometric logit curve and calculating the Akaike information criterion (AIC) as a measure of goodness of fit. We compared this to the AIC of the intercept-only (no predictor) model and excluded any datasets showing a difference &lt;2 (<xref ref-type="bibr" rid="R70">70</xref>). In total 8.05% of the data was excluded due to fit issues (see <xref ref-type="supplementary-material" rid="SD1">supplementary table S1</xref> for breakdown per block). We next extracted the slope of the fitted curve for each block/participant, as a measure of sensitivity while discriminating between the different samples, with a larger value indicating better discrimination ability. We also replicated the analysis with the values of the intercept, informing us about the bias people have in responding (see <xref ref-type="supplementary-material" rid="SD1">supplementary materials</xref>).</p></sec><sec id="S20"><title>Material Deformation Task</title><p id="P50">Each material piece was cut to the approximate size of 8.5 cm x 6 cm x 4 cm. Eight out of the nine materials were foams varying in deformability, the ninth was a solid block. Deformability was initially quantified using the average signal peak when a deformation sensor embedded into the D6 tip sampled each foam piece three times. The most deformable material had a measure of 0.7 and used as reference, whilst the firmest material had a measure of 29 (full range: 0.7, 2.2, 5.2, 8.9, 10.8, 11.8, 15.1, 19.1, 29). The smaller the value, the less force was received in response when the deformation sensor sampled the material. Deformability order was later corroborated by quantification in cm through an in-house system that delievered 850g of weight to each foam (amount of deformation: 2.6cm, 2.4cm, 1.5cm, 0.8cm, 0.75cm, 0.65cm, 0.45cm, 0.2cm, 0)</p><p id="P51">Task setup is presented in <xref ref-type="fig" rid="F1">Figures 1C</xref> and <xref ref-type="supplementary-material" rid="SD1">S4</xref>. The hand (wearable device) or model hand (skin stretch) was secured underneath a table that allowed full flexing of D6 to sample the materials, while minimising contact with the hand. D6 was triggered to automatically move to sample the material (never controlled by the participant), hold for one seconds, and then release. In the biological thumb-only control task, the participant timed the sampling themselves, practicing beforehand.</p></sec><sec id="S21"><title>Texture Coarseness Task</title><p id="P52">All the texture pieces were 79 mm long and 35 mm wide and made from silicone, ensuring compatibility with the D6 tip. Each texture had a series of pyramid shaped peaks, creating finer or coarser ridges. The nine textures were quantified by the distance between peaks. The finest texture had a 5mm distance between peaks (used as reference), whilst the coarsest had a 15mm distance between peaks (total range: 5mm, 6mm, 7mm, 8mm, 9mm, 10mm, 11mm, 13mm, and 15mm).</p><p id="P53">Task setup can be seen in <xref ref-type="fig" rid="F1">Figures 1D</xref> and <xref ref-type="supplementary-material" rid="SD1">S5</xref>. The hand (wearable device) or model hand (vibrotactile) was secured on a mount off the table to allow sampling of the texture pieces by D6, while minimizing contact with the hand. D6 was always passive in this task (never connected to power so could not move), it was simply worn on the hand/hand model whilst the texture pieces were applied to the tip, using a custom rail controlled by the experimenter.</p></sec></sec><sec id="S22"><title>Temporal Order Judgement</title><sec id="S23"><title>Hardware</title><p id="P54">To deliver the vibrotactile stimulations, encapsulated DC vibration motors (3 VDC) were attached to the glabrous skin on the fingertips of the biological thumb (D1), index finger (D2), little finger (D5) and the silicone pad of D6 (<xref ref-type="fig" rid="F1">Figure 1D</xref>; <xref ref-type="supplementary-material" rid="SD1">Figure S6</xref>). Each stimulation lasted 15 ms, with a frequency of 235Hz and vibration amplitude of 7G.</p></sec><sec id="S24"><title>Task Design</title><p id="P55">The task comprised of four digit-pair blocks, delivered in a randomised order – D6&amp;D1, D6&amp;D2, D6&amp;D5 and D5&amp;D1. Each block had 40 trials; in each trial participants received vibrotactile stimulation to one digit and then another in quick succession (interstimulus interval (ISI): -400ms to 400ms, possible steps of 10ms between). Participants verbally reported which digit they felt was stimulated first (the digit to the left of the digit-pair (respond “0”) or the digit to the right (respond “1”) and were reminded of the response mapping at the beginning of each block.</p><p id="P56">Before the task began, participants completed six practice trials for each digit-pair at pre-determined ISIs. Here participants had full vision and audition and received verbal reinforcement for correct performance.</p><p id="P57">In the experimental run, participants had their eyes closed and listened to white noise through over-ear headphones; The white noise was initially set to 75% of the maximum volume, with adjustments made to ensure comfort. They received no verbal reinforcement.</p><p id="P58">The interstimulus interval between stimulations was determined using the adaptive psi method (described above). The threshold estimate was set to -0.1 to 0.1; steps of 0.01, with a slope estimate of -1.5 to 1.5; steps of 0.1.</p><p id="P59">We replicated the curve fitting and goodness of fit checks described above for each digit-pair block, leading to removal of 1% of the data. We calculated the JND as a measure of discrimination ability by finding the difference between the 75% point and 25% point on the psychometric curve and dividing by two. Smaller values imply better temporal discrimination ability. We also extracted the point of subjective equality as a measure of bias by finding the 50% point of the psychometric curve, to explore spatial biases (<xref ref-type="supplementary-material" rid="SD1">supplementary materials</xref>).</p></sec></sec><sec id="S25"><title>Training</title><p id="P60">The full protocol for both training groups is available in the general protocol at <italic>osf</italic>.<italic>io/c76xd</italic>.</p><sec id="S26"><title>Third Thumb (D6) Training</title><p id="P61">Participants in our experimental group underwent seven days of D6 training, designed to allow acquisition of different motor skills with D6, particularly focused on D6-biological hand collaboration. The first and last day of training was supervised in-person, whilst the middle five days were completed remotely and semi-supervised (approximately two hours of training per day). Full details available in <italic>46</italic>.</p><p id="P62">On the first and last day of training participants performed a D6-biological digit coordination task. Per one-minute block, participants had to make tip-to-tip movements between D6 and a randomised digit (cues: ‘thumb’, ‘middle’, ‘ring’, ‘little’ – four blocks). Participants were given the audio cue ‘go’ to begin a trial, and ‘stop’ to end the trial when the experimenter determined the coordinated movement was successful.</p></sec><sec id="S27"><title>Keyboard Training</title><p id="P63">Our active control group underwent a similar training regime (two days in-person, five remote, with approximately two hours of training per day). Participants trained to play the piano keyboard over seven days of training, guided by the app ‘Yousician’ (<xref ref-type="bibr" rid="R71">71</xref>), using only their right hand and a right foot pedal to maintain the notes.</p><p id="P64">Participants completed one set of songs in the app at the beginning of every session, and a different set at the end of every session. In between, participants completed different training tasks working on technique, major scales, minor scales and blues scales. Each training task was repeated 10 times each, replicating the D6 training schedule (both schedules available at <italic>osf</italic>.<italic>io/c76xd</italic>). Yousician calculated a score for each task based on note-accuracy and timing information. Participants were given a different chord to practice in between each session.</p></sec></sec><sec id="S28"><title>Functional Magnetic Resonance Imaging (fMRI)</title><sec id="S29"><title>Acquisition</title><p id="P65">Details of all MRI images acquired are available at <italic>osf</italic>.<italic>io/c76xd</italic>. MRI images were acquired using a 3T Prisma Fit MRI scanner (Siemens, Munich, Germany) using a 32-channel head coil. For functional image acquisition, we used a multiband T2* - weighted pulse sequence with a between-slice acceleration factor of 4 and no in-slice acceleration. A voxel size of 2mm isotropic was used, and a repetition time (TR) of 1500 ms. Acquisition sequence parameters consisted of an echo time (TE) of 35 ms, flip angle of 70° with 72 transversal slices per volume. For our T1-weighted image acquisition sequence to acquire our structural image we used a voxel size of 1mm isotropic and TR of 2250 ms, with sequence parameters consisting of a 3ms TE, flip angle of 9°.</p></sec><sec id="S30"><title>Task and tactile stimulation</title><p id="P66">Silicon vibrotactors were used to deliver vibrotactile stimulations via a pneumatic system to the glabrous skin of the five biological fingertips, to the silicon tip of D6, and to the side of the hand where D6 is worn (the ‘Palm’) (<xref ref-type="fig" rid="F2">Figure 2A</xref>). We used an in-house system inspired by the design of <xref ref-type="bibr" rid="R72">72</xref> (validated in <xref ref-type="bibr" rid="R73">73</xref>). The digit vibrotactors were held in place with elasticated sports tape, whilst the Palm vibrotactor was fitted under the D6 hand piece.</p><p id="P67">During the scan, each body part was stimulated individually in a pseudo-randomised order. Each tactile stimulation event was delivered over a nine second block – a one second preparation period for system pressure stabilisation, 7.5 seconds of stimulation, then a 0.5 second rest of no stimulation. To avoid peripheral or central adaptation (<xref ref-type="bibr" rid="R73">73</xref>–<xref ref-type="bibr" rid="R76">76</xref>), each stimulation varied frequency every 400 milliseconds, following a pattern of 5 Hz, 15 Hz, and 30 Hz, with 100 millisecond gaps between frequencies; this pattern occurred five times per block. Interweaved within the stimulation blocks were six, nine second ‘rest’ blocks with no stimulation, to allow for BOLD signal relaxation. Rest blocks could be on their own or grouped in two consecutive blocks, but between rest block groups there was always at least two stimulation blocks. In addition, two 16 second rest blocks were at the beginning and end of each run.</p><p id="P68">Participants completed three runs of the task, each 472 seconds long (323 volumes). There was no active task, but to ensure participant engagement they were told (a) to ensure the name of the digit on the screen matched the digit being stimulated and (b) to inform the experimenter if any vibrations in the run felt different to the others. When available, an eye tracker was used for a subset of participants to ensure attention was maintained throughout the task.</p></sec><sec id="S31"><title>Pre-processing and first-level analysis</title><p id="P69">All MRI data pre-processing and analyses were carried out using FMRIB Software Library ((<xref ref-type="bibr" rid="R77">77</xref>); FSL, version 6.0.5), as well as in-house scripts written in MATLAB (version R2020b), Python (3.13.0), and R (4.2.2). For multivariate analyses, we used the MATLAB RSA Toolbox (<xref ref-type="bibr" rid="R78">78</xref>) in addition to within-lab toolbox extensions (<xref ref-type="bibr" rid="R79">79</xref>). The decoding analyses were carried out using python library scikit-learn (v.1.5.2).</p><p id="P70">To ensure that the functional scans were well aligned for each participant, we calculated a midspace between the six runs (three pre-training runs, three post-training runs). This represents the average space where the images are minimally reoriented. Each scan was aligned to this midspace using FLIRT (<xref ref-type="bibr" rid="R80">80</xref>,<xref ref-type="bibr" rid="R81">81</xref>), with structural image alignment optimised using Boundary-Based Registration.</p><p id="P71">Functional data was primarily pre-processed using FSL-FEAT. We first performed motion correction using FMRIB’s Linear Image Registration Tool (MCFLIRT (<xref ref-type="bibr" rid="R81">81</xref>), followed by brain extraction using the Brain Extraction Tool (BET (<xref ref-type="bibr" rid="R82">82</xref>)). We then used temporal high-pass filtering, with a cutoff of 100 seconds, and lastly spatial smoothing with a 3 mm full width at half maximum (FWHM) Gaussian kernel. Field maps were also used for field unwarping.</p><p id="P72">We used a voxel-based general linear model (GLM) implemented in FSL-FEAT to identify activity patterns related to each tactile stimulation condition. For each run, seven regressors were created, one for each body part condition (D1-D6, Palm). Regressors were convoluted with a double-gamma function to account for the delayed BOLD response. Additional first derivative regressors were included to capture temporal variations in the BOLD signal, along with six motion parameters to estimate head movements. Additionally, we used motion scrubbing, adding regressors of no interest to exclude any volumes with excessive motion (framewise displacement larger than 0.9 (<xref ref-type="bibr" rid="R83">83</xref>)). In the model, 14 contrasts were set up; each body part vs rest, each biological digit vs all the other biological digits, D6 vs Palm, and the average of the biological digits vs rest. For each participant, the contrast images obtained for each of the three runs per session were then averaged voxel-wise using a fixed-effects model in FSL. This image was normalised to the standard Montreal Neurological Institute (MNI) space and used for the <italic>Line Analysis</italic>. For the Line Analysis, we focused on the selectivity in each condition by contrasting the biological digits and D6 relative to their respective controls - the average of the other digits, and the palm of the hand.</p></sec><sec id="S32"><title>Region of Interest (ROI) Definition</title><p id="P73">We focused all analyses in S1, specifically Broadmann Area 3b (BA3b). For each participant, their structural T1 image was used to estimate the cortical surface, reconstructing the pial and white-grey matter surfaces using FreeSurfer’s recon-all (Freesurfer, 7.4.0 (<xref ref-type="bibr" rid="R84">84</xref>)).</p><p id="P74">To initially explore selectivity across the BA3b strip, we took the standard flat map (FS_LR 32K) of the Human Connectome Project (HCP) and performed a 15° clockwise rotation so that the central sulcus was perpendicular to the horizontal axis. We then created a mask of BA3b as defined by the Glasser Atlas (<xref ref-type="bibr" rid="R85">85</xref>), and constructed 50 equally spaced lines from the top to bottom of the mask (anterior to posterior axis), creating 49 ROI ‘bands’. These were then transformed into volumetric ROIs. We constrained then visualisation to the estimated hand area, bands 13-29.</p><p id="P75">To localise the hand representation for further analyses, we took the Glasser BA3b ROI and a pre-defined ROI taking all surface S1 nodes on the standard flat map 2cm proximal/distal of the anatomical hand knob (<xref ref-type="bibr" rid="R86">86</xref>). We transformed this into volumetric standard MNI space and took the intersection of the two ROIs. We further refined the ROI by taking the top 100 most active voxels for each biological condition contrasted to rest (each biological digit vs rest, and palm vs rest) from the activity of an independent group (<italic>N</italic>=20) that completed the paradigm. We took the additive sum of these voxels as our final ROI. These were then mapped to the individual’s volumetric functional space (via the individual’s volumetric high-resolution anatomy). An important consideration is that this ROI may not precisely reflect BA3b and may contain relevant activity from neighboring S1 areas due to the nature of our data and processing (3T fMRI, smoothing FWHM 3mm) and the probabilistic nature of the atlas. As such, we take this as definitively S1, and indicatively BA3b, as such as refer to this as S1 throughout.</p></sec><sec id="S33"><title>Representational Similarity Analysis (RSA)</title><p id="P76">To explore the informational content available in the hand representation, we used multivariate representational similarity analysis (RSA (<xref ref-type="bibr" rid="R87">87</xref>)). For each participant and each session, we extracted the beta weights estimates from the first-level analyses for each condition vs rest within our BA3b hand area ROI. These were prewhitened using the GLM residuals, and the cross-validated mahalanobis (crossnobis) distance (<xref ref-type="bibr" rid="R88">88</xref>) was calculated between the patterns for each of the conditions. We calculated the distances using each possible imaging run pair combination within a session (pre- and post-training) and then averaged the distances across all run pairs. This distance provides us with a measure of dissimilarity in the activity patterns elicited in each stimulation condition. The expected distance is zero if two patterns are not significantly different from each other. The crossnobis distance between D6 and D1 was taken to correlate with embodiment scores due to being the D6-biological digit pair most commonly used in collaboration (<xref ref-type="bibr" rid="R46">46</xref>) and the pair that would intuitively have the largest distance based on hand topography.</p></sec></sec><sec id="S34"><title>Markerless Tracking</title><p id="P77">We extracted the hand use kinematics during a set of free-choice tasks that engaged complex digit coordination patterns (see task details in <xref ref-type="bibr" rid="R46">46</xref>) using a markerless tracking setup. We recorded performance using three Logitech Brio 4k Stream Webcams (<xref ref-type="bibr" rid="R89">89</xref>). During offline analyses, we tracked the 2D joint coordinates of the five biological digits using Google Mediapipe (<xref ref-type="bibr" rid="R90">90</xref>) for each of the three camera recordings. We then filtered and triangulated using Anipose to obtain the 3D joint angles (<xref ref-type="bibr" rid="R91">91</xref>). The intrinsic parameters of the cameras and the relative location were obtained during calibration using a ChArUco board (Size 21.0 x 29.7 cm; 10 x 7 squares, with 4 bit markers and a dictionary size of 50 markers).</p><p id="P78">For each participant, session and task, the joint angles were extracted and smoothed using third-order Savitzky-Golay filter with a window length of 151 samples. Angular velocities were then calculated from the first difference of the filtered joint angle data divided by the time step (<xref ref-type="bibr" rid="R45">45</xref>). We then z-normalized across the tasks within a session (<xref ref-type="bibr" rid="R92">92</xref>). Separately for the distal interphalangeal joint (DIP) and proximal interphalangeal (PIP) joint angles (using the interphalangeal joint (IP) for D1), we used linear regression to fit the angular velocity data of a given digit as a function of the angular velocity of each of the other digits individually. This produced a coefficient of determination (R<sup>2</sup>) for each digit pair, informing about the proportion of total variance of each digit’s angular velocity that could be explained by a linear reconstruction, based on the paired regression with each of the other digits. We took this as a measure of co-usage.</p></sec><sec id="S35"><title>Embodiment Questionnaire</title><p id="P79">Participants completed an Embodiment questionnaire at the end of their pre-training and post-training behavioural sessions to assess phenomenological experience with D6. The questionnaire contained 20 statements (adapted from <xref ref-type="bibr" rid="R45">45</xref>; based on <xref ref-type="bibr" rid="R93">93</xref>), which participants rated along a seven-point Likert scale, ranging from −3 (strongly disagree) to 3 (strongly agree).</p><p id="P80">Statements formed four categories – somatosensation, body ownership, body image, as well as agency (reported in <xref ref-type="bibr" rid="R46">46</xref>). There were additional four ‘catch’ statements, designed to confirm the participant was paying attention to their ratings. For each participant and session, questionnaire scores were averaged within each category. If a participant’s average rating in the catch category exceeded zero, their data for that session was excluded, resulting in the removal of one participant.</p></sec><sec id="S36"><title>General Analysis</title><p id="P81">All statistical analyses were performed in JASP (version 0.19.1). Throughout, parametric statistics were used when there were no violations of test assumptions (normality assessed by Shapiro-Wilk values and visual inspection, homoscedasticity assessed by Levene test values). If there were violations, when possible, the equivalent non-parametric test was used. All null results of interest were followed up using Bayesian statistics (Cauchy prior width r=0.707) to obtain a Bayesian factor (BF<sub>10</sub>) to allow interpretation based on the strength of support for the null hypothesis. We used a threshold of BF&lt;1/3 as sufficient evidence in support of the null hypothesis, BF&gt;3 as sufficient evidence in support of the alternative hypothesis, and 1/3&lt;BF&lt;3 as inconclusive evidence (<xref ref-type="bibr" rid="R94">94</xref>).</p><p id="P82">Wherever possible, we employed linear mixed models (LMM), with a random intercept for participant. We used the Satterthwaite testing method and Satterthwaite degrees of freedom approximation for all follow-up tests. Models accounted for testing session, group and digit-pair (fMRI multivariate analyses and kinematics) or category (embodiment questionnaire) as fixed effects. Our fMRI models additionally accounted for days between sessions using a continuous covariate, and our kinematics models accounted for joint (PIP or DIP).</p><p id="P83">For any simple comparisons where a LMM would not be appropriate, we used one-sample t-tests to assess if values were significantly different from zero (including the material discrimination tasks, fMRI multivariate analyses, and embodiment questionnaire) and paired samples t-tests and repeated measures ANOVAs for within-subjects comparisons (including material discrimination tasks and TOJ performance). For both, a Wilcoxon signed-rank test was used if assumptions were violated. For the between-groups comparison when comparing material discrimination task performance with our biological hand to the wearable D6 performance, a Mann-Whitney test was used due to assumption violations. A Pearson correlation was used to correlate embodiment and Crossnobis distance.</p></sec></sec><sec sec-type="supplementary-material" id="SM"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>Supplementary Materials</label><media xlink:href="EMS206953-supplement-Supplementary_Materials.pdf" mimetype="application" mime-subtype="pdf" id="d20aAcEbB" position="anchor"/></supplementary-material></sec></body><back><ack id="S39"><title>Acknowledgements</title><p>We thank all of our participants for their time and effort. We thank Raffaele Tucciarelli for support with experimental setup and analysis; Ilana Nisky for helpful advice during development of the feedback systems; Silvestro Micera and Solaiman Shokur for helpful advice throughout the study; Yousician for providing us with a preminum version of their application for this research; Hristo Dimitrov for support with setting up the kinematics analysis; Mabel Ziman &amp; Clara Gallay for data collection; and Roderick Spender, Klara Selén, Katarina Krajnovic, Hannah Browning, Yuval Amichay, Karan Salvi and Alexandra Williams for additional support with data collection. We thank Yon Visell and Calogero Oddo for their helpful feedback on the initial manuscript.</p><sec id="S37"><title>Funding</title><p>The study was funded by UKRI’s Frontier Research Guarantee (EP/X040372/1), the Engineering and Physical Sciences Research Council (EP/W004062/1), the Medical Research Council (MC_uu_00030/10) and the Observatory for Human Machine Collaboration. TRM was partially funded by a Wellcome Trust Senior Research Fellowship (215575/Z/19/Z). MB was supported by the Italian Ministry of University and Research (MUR) - Fondo Italiano per la Scienza (FIS), with the grant PERCEIVING (no. FIS00001153). GD was funded by European Union's Horizon 2020 MSCA Programme under Grant Agreement No 813713.</p></sec></ack><sec id="S38" sec-type="data-availability"><title>Data and materials availability</title><p id="P84">The data that support the findings of this study will be available from the Open Science Framework upon publication (osf.io/c76xd). For the purpose of open access, the authors have applied a Creative Commons Attribution (CC BY) licence to any Author Accepted Manuscript version arising from this submission.</p></sec><fn-group><fn fn-type="con" id="FN1"><p id="P85"><bold>Author Contributions</bold>: L.D and T.R.M led all conceptualisation and experimental design development. M.M and G.D supported experimental design for the longitudinal training participants. D.C designed and constructed the Third Thumb. E.d.S led design and construction of the artificial feedback systems. M.B, F.I, D.C. L.D and T.R.M supported artificial feedback system development. M.B and F.I were also available for consulation throughout. L.D contributed to data collection for all the datasets included in this manuscript. M.M, G.D, E.d.S, E.J and V.P also contributed to data collection on subsets of the data included in this manuscript. L.D and T.R.M led all data analysis. G.D and V.P. contributed to organisation and processing of the kinematics data. E.J. contributed to processing and analysis of the keyboard training data. M.M and V.P. contributed to organsiation and processing of the Third Thumb training data. L.D and T.R.M wrote the paper. L.D and D.C prepared the figures. M.M, G.D, E.d.S, V.P, E.J, M.B, F.I, and D.C. provided feedback on the paper. T.R.M provided funding for the paper.</p></fn><fn fn-type="conflict" id="FN2"><p id="P86"><bold>Competing interests</bold>: The authors declare that they have no competing interests.</p></fn></fn-group><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miall</surname><given-names>RC</given-names></name><name><surname>Wolpert</surname><given-names>DM</given-names></name></person-group><article-title>Forward Models for Physiological Motor Control</article-title><source>Neural Networks</source><year>1996</year><volume>9</volume><fpage>1265</fpage><lpage>1279</lpage><pub-id pub-id-type="pmid">12662535</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Umeda</surname><given-names>T</given-names></name><name><surname>Isa</surname><given-names>T</given-names></name><name><surname>Nishimura</surname><given-names>Y</given-names></name></person-group><article-title>The somatosensory cortex receives information about motor output</article-title><source>Sci Adv</source><year>2019</year><volume>5</volume><pub-id pub-id-type="doi">10.1126/sciadv.aaw5388</pub-id><pub-id pub-id-type="pmcid">PMC6620090</pub-id><pub-id pub-id-type="pmid">31309153</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ariani</surname><given-names>G</given-names></name><name><surname>Pruszynski</surname><given-names>JA</given-names></name><name><surname>Diedrichsen</surname><given-names>J</given-names></name></person-group><article-title>Motor planning brings human primary somatosensory cortex into action-specific preparatory states</article-title><source>Elife</source><year>2022</year><volume>11</volume><pub-id pub-id-type="doi">10.7554/eLife.69517</pub-id><pub-id pub-id-type="pmcid">PMC8786310</pub-id><pub-id pub-id-type="pmid">35018886</pub-id></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ebrahimi</surname><given-names>S</given-names></name><name><surname>Ostry</surname><given-names>DJ</given-names></name></person-group><article-title>The human somatosensory cortex contributes to the encoding of newly learned movements</article-title><source>Proc Natl Acad Sci U S A</source><year>2024</year><volume>121</volume><pub-id pub-id-type="doi">10.1073/pnas.2316294121</pub-id><pub-id pub-id-type="pmcid">PMC10861869</pub-id><pub-id pub-id-type="pmid">38285945</pub-id></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carteron</surname><given-names>A</given-names></name><name><surname>McPartlan</surname><given-names>K</given-names></name><name><surname>Gioeli</surname><given-names>C</given-names></name><name><surname>Reid</surname><given-names>E</given-names></name><name><surname>Turturro</surname><given-names>M</given-names></name><name><surname>Hahn</surname><given-names>B</given-names></name><name><surname>Benson</surname><given-names>C</given-names></name><name><surname>Zhang</surname><given-names>W</given-names></name><name><surname>Li</surname><given-names>S</given-names></name><name><surname>Gao</surname><given-names>F</given-names></name><name><surname>Cole</surname><given-names>KJ</given-names></name></person-group><article-title>Temporary nerve block at selected digits revealed hand motor deficits in grasping tasks</article-title><source>Front Hum Neurosci</source><year>2016</year><volume>10</volume><elocation-id>234766</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2016.00596</pub-id><pub-id pub-id-type="pmcid">PMC5122577</pub-id><pub-id pub-id-type="pmid">27932964</pub-id></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Richardson</surname><given-names>AG</given-names></name><name><surname>Attiah</surname><given-names>MA</given-names></name><name><surname>Berman</surname><given-names>JI</given-names></name><name><surname>Chen</surname><given-names>HI</given-names></name><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Zhang</surname><given-names>M</given-names></name><name><surname>Van der Spiegel</surname><given-names>J</given-names></name><name><surname>Lucas</surname><given-names>TH</given-names></name></person-group><article-title>The effects of acute cortical somatosensory deafferentation on grip force control</article-title><source>Cortex</source><year>2016</year><volume>74</volume><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2015.10.007</pub-id><pub-id pub-id-type="pmcid">PMC4724548</pub-id><pub-id pub-id-type="pmid">26587914</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sensinger</surname><given-names>JW</given-names></name><name><surname>Dosen</surname><given-names>S</given-names></name></person-group><article-title>A Review of Sensory Feedback in Upper-Limb Prostheses From the Perspective of Human Motor Control</article-title><source>Front Neurosci</source><year>2020</year><volume>14</volume><fpage>345</fpage><pub-id pub-id-type="doi">10.3389/fnins.2020.00345</pub-id><pub-id pub-id-type="pmcid">PMC7324654</pub-id><pub-id pub-id-type="pmid">32655344</pub-id></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Farina</surname><given-names>D</given-names></name><name><surname>Aszmann</surname><given-names>O</given-names></name></person-group><article-title>Bionic limbs: clinical reality and academic promises</article-title><source>Sci Transl Med</source><year>2014</year><volume>6</volume><pub-id pub-id-type="pmid">25298319</pub-id></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lebedev</surname><given-names>MA</given-names></name><name><surname>Nicolelis</surname><given-names>MAL</given-names></name></person-group><article-title>Brain-machine interfaces: From basic science to neuroprostheses and neurorehabilitation</article-title><source>Physiol Rev</source><year>2017</year><volume>97</volume><fpage>767</fpage><lpage>837</lpage><pub-id pub-id-type="pmid">28275048</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bensmaia</surname><given-names>SJ</given-names></name><name><surname>Miller</surname><given-names>LE</given-names></name></person-group><article-title>Restoring sensorimotor function through intracortical interfaces: progress and looming challenges</article-title><source>Nature Reviews Neuroscience</source><year>2014</year><volume>15</volume><issue>5</issue><fpage>313</fpage><lpage>325</lpage><comment>2014 15</comment><pub-id pub-id-type="pmid">24739786</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prattichizzo</surname><given-names>D</given-names></name><name><surname>Pozzi</surname><given-names>M</given-names></name><name><surname>Baldi</surname><given-names>TL</given-names></name><name><surname>Malvezzi</surname><given-names>M</given-names></name><name><surname>Hussain</surname><given-names>I</given-names></name><name><surname>Rossi</surname><given-names>S</given-names></name><name><surname>Salvietti</surname><given-names>G</given-names></name></person-group><article-title>Human augmentation by wearable supernumerary robotic limbs: review and perspectives</article-title><source>Progress in Biomedical Engineering</source><year>2021</year><volume>3</volume><elocation-id>042005</elocation-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>B</given-names></name><name><surname>Huang</surname><given-names>J</given-names></name><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Xiong</surname><given-names>C</given-names></name><name><surname>Hasegawa</surname><given-names>Y</given-names></name></person-group><article-title>Supernumerary Robotic Limbs: A Review and Future Outlook</article-title><source>IEEE Trans Med Robot Bionics</source><year>2021</year><volume>3</volume><fpage>623</fpage><lpage>639</lpage></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bardi</surname><given-names>E</given-names></name><name><surname>Gandolla</surname><given-names>M</given-names></name><name><surname>Braghin</surname><given-names>F</given-names></name><name><surname>Resta</surname><given-names>F</given-names></name><name><surname>Pedrocchi</surname><given-names>ALG</given-names></name><name><surname>Ambrosini</surname><given-names>E</given-names></name></person-group><article-title>Upper limb soft robotic wearable devices: a systematic review</article-title><source>J Neuroeng Rehabil</source><year>2022</year><volume>19</volume><fpage>1</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.1186/s12984-022-01065-9</pub-id><pub-id pub-id-type="pmcid">PMC9367113</pub-id><pub-id pub-id-type="pmid">35948915</pub-id></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walsh</surname><given-names>C</given-names></name></person-group><article-title>Human-in-the-loop development of soft wearable robots</article-title><source>Nature Reviews Materials</source><year>2018</year><volume>3</volume><issue>6</issue><fpage>78</fpage><lpage>80</lpage><comment>2018 3</comment></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eden</surname><given-names>J</given-names></name><name><surname>Bräcklein</surname><given-names>M</given-names></name><name><surname>Ibáñez</surname><given-names>J</given-names></name><name><surname>Barsakcioglu</surname><given-names>DY</given-names></name><name><surname>Di Pino</surname><given-names>G</given-names></name><name><surname>Farina</surname><given-names>D</given-names></name><name><surname>Burdet</surname><given-names>E</given-names></name><name><surname>Mehring</surname><given-names>C</given-names></name></person-group><article-title>Principles of human movement augmentation and the challenges in making it a reality</article-title><source>Nat Commun</source><year>2022</year><volume>13</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1038/s41467-022-28725-7</pub-id><pub-id pub-id-type="pmcid">PMC8924218</pub-id><pub-id pub-id-type="pmid">35292665</pub-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cordella</surname><given-names>F</given-names></name><name><surname>Ciancio</surname><given-names>AL</given-names></name><name><surname>Sacchetti</surname><given-names>R</given-names></name><name><surname>Davalli</surname><given-names>A</given-names></name><name><surname>Cutti</surname><given-names>AG</given-names></name><name><surname>Guglielmelli</surname><given-names>E</given-names></name><name><surname>Zollo</surname><given-names>L</given-names></name></person-group><article-title>Literature review on needs of upper limb prosthesis users</article-title><source>Front Neurosci</source><year>2016</year><volume>10</volume><elocation-id>175438</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2016.00209</pub-id><pub-id pub-id-type="pmcid">PMC4864250</pub-id><pub-id pub-id-type="pmid">27242413</pub-id></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raspopovic</surname><given-names>S</given-names></name><name><surname>Valle</surname><given-names>G</given-names></name><name><surname>Petrini</surname><given-names>FM</given-names></name></person-group><article-title>Sensory feedback for limb prostheses in amputees</article-title><source>Nature Materials</source><year>2021</year><volume>20</volume><issue>7</issue><fpage>925</fpage><lpage>939</lpage><comment>2021 20</comment><pub-id pub-id-type="pmid">33859381</pub-id></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seminara</surname><given-names>L</given-names></name><name><surname>Dosen</surname><given-names>S</given-names></name><name><surname>Mastrogiovanni</surname><given-names>F</given-names></name><name><surname>Bianchi</surname><given-names>M</given-names></name><name><surname>Watt</surname><given-names>S</given-names></name><name><surname>Beckerle</surname><given-names>P</given-names></name><name><surname>Nanayakkara</surname><given-names>T</given-names></name><name><surname>Drewing</surname><given-names>K</given-names></name><name><surname>Moscatelli</surname><given-names>A</given-names></name><name><surname>Klatzky</surname><given-names>RL</given-names></name><name><surname>Loeb</surname><given-names>GE</given-names></name></person-group><article-title>A hierarchical sensorimotor control framework for human-in-the-loop robotic hands</article-title><source>Sci Robot</source><year>2023</year><volume>8</volume><pub-id pub-id-type="pmid">37196072</pub-id></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raspopovic</surname><given-names>S</given-names></name><name><surname>Capogrosso</surname><given-names>M</given-names></name><name><surname>Petrini</surname><given-names>FM</given-names></name><name><surname>Bonizzato</surname><given-names>M</given-names></name><name><surname>Rigosa</surname><given-names>J</given-names></name><name><surname>Di Pino</surname><given-names>G</given-names></name><name><surname>Carpaneto</surname><given-names>J</given-names></name><name><surname>Controzzi</surname><given-names>M</given-names></name><name><surname>Boretius</surname><given-names>T</given-names></name><name><surname>Fernandez</surname><given-names>E</given-names></name><name><surname>Granata</surname><given-names>G</given-names></name><etal/></person-group><article-title>Bioengineering: Restoring natural sensory feedback in real-time bidirectional hand prostheses</article-title><source>Sci Transl Med</source><year>2014</year><volume>6</volume><pub-id pub-id-type="pmid">24500407</pub-id></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vargas</surname><given-names>L</given-names></name><name><surname>Huang</surname><given-names>H</given-names></name><name><surname>Zhu</surname><given-names>Y</given-names></name><name><surname>Hu</surname><given-names>X</given-names></name></person-group><article-title>Object Shape and Surface Topology Recognition Using Tactile Feedback Evoked through Transcutaneous Nerve Stimulation</article-title><source>IEEE Trans Haptics</source><year>2020</year><volume>13</volume><fpage>152</fpage><lpage>158</lpage><pub-id pub-id-type="doi">10.1109/TOH.2020.2967366</pub-id><pub-id pub-id-type="pmcid">PMC7237381</pub-id><pub-id pub-id-type="pmid">31976905</pub-id></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chandrasekaran</surname><given-names>S</given-names></name><name><surname>Nanivadekar</surname><given-names>AC</given-names></name><name><surname>McKernan</surname><given-names>G</given-names></name><name><surname>Helm</surname><given-names>ER</given-names></name><name><surname>Boninger</surname><given-names>ML</given-names></name><name><surname>Collinger</surname><given-names>JL</given-names></name><name><surname>Gaunt</surname><given-names>RA</given-names></name><name><surname>Fisher</surname><given-names>LE</given-names></name></person-group><article-title>Sensory restoration by epidural stimulation of the lateral spinal cord in upper-limb amputees</article-title><source>Elife</source><year>2020</year><volume>9</volume><fpage>1</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.7554/eLife.54349</pub-id><pub-id pub-id-type="pmcid">PMC7373432</pub-id><pub-id pub-id-type="pmid">32691733</pub-id></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nanivadekar</surname><given-names>AC</given-names></name><name><surname>Chandrasekaran</surname><given-names>S</given-names></name><name><surname>Helm</surname><given-names>ER</given-names></name><name><surname>Boninger</surname><given-names>ML</given-names></name><name><surname>Collinger</surname><given-names>JL</given-names></name><name><surname>Gaunt</surname><given-names>RA</given-names></name><name><surname>Fisher</surname><given-names>LE</given-names></name></person-group><article-title>Closed-loop stimulation of lateral cervical spinal cord in upper-limb amputees to enable sensory discrimination: a case study</article-title><source>Scientific Reports</source><year>2022</year><volume>12</volume><issue>1</issue><fpage>1</fpage><lpage>11</lpage><comment>2022 12</comment><pub-id pub-id-type="doi">10.1038/s41598-022-21264-7</pub-id><pub-id pub-id-type="pmcid">PMC9553970</pub-id><pub-id pub-id-type="pmid">36220864</pub-id></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flesher</surname><given-names>SN</given-names></name><name><surname>Collinger</surname><given-names>JL</given-names></name><name><surname>Foldes</surname><given-names>ST</given-names></name><name><surname>Weiss</surname><given-names>JM</given-names></name><name><surname>Downey</surname><given-names>JE</given-names></name><name><surname>Tyler-Kabara</surname><given-names>EC</given-names></name><name><surname>Bensmaia</surname><given-names>SJ</given-names></name><name><surname>Schwartz</surname><given-names>AB</given-names></name><name><surname>Boninger</surname><given-names>ML</given-names></name><name><surname>Gaunt</surname><given-names>RA</given-names></name></person-group><article-title>Intracortical microstimulation of human somatosensory cortex</article-title><source>Sci Transl Med</source><year>2016</year><volume>8</volume><pub-id pub-id-type="pmid">27738096</pub-id></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greenspon</surname><given-names>CM</given-names></name><name><surname>Valle</surname><given-names>G</given-names></name><name><surname>Shelchkova</surname><given-names>ND</given-names></name><name><surname>Hobbs</surname><given-names>TG</given-names></name><name><surname>Verbaarschot</surname><given-names>C</given-names></name><name><surname>Callier</surname><given-names>T</given-names></name><name><surname>Berger-Wolf</surname><given-names>EI</given-names></name><name><surname>Okorokova</surname><given-names>EV</given-names></name><name><surname>Hutchison</surname><given-names>BC</given-names></name><name><surname>Dogruoz</surname><given-names>E</given-names></name><name><surname>Sobinov</surname><given-names>AR</given-names></name><etal/></person-group><article-title>Evoking stable and precise tactile sensations via multi-electrode intracortical microstimulation of the somatosensory cortex</article-title><source>Nature Biomedical Engineering</source><year>2024</year><volume>2024</volume><fpage>1</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.1038/s41551-024-01299-z</pub-id><pub-id pub-id-type="pmcid">PMC12176618</pub-id><pub-id pub-id-type="pmid">39643730</pub-id></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dosen</surname><given-names>S</given-names></name><name><surname>Markovic</surname><given-names>M</given-names></name><name><surname>Strbac</surname><given-names>M</given-names></name><name><surname>Belic</surname><given-names>M</given-names></name><name><surname>Kojic</surname><given-names>V</given-names></name><name><surname>Bijelic</surname><given-names>G</given-names></name><name><surname>Keller</surname><given-names>T</given-names></name><name><surname>Farina</surname><given-names>D</given-names></name></person-group><article-title>Multichannel electrotactile feedback with spatial and mixed coding for closed-loop control of grasping force in hand prostheses</article-title><source>IEEE Transactions on Neural Systems and Rehabilitation Engineering</source><year>2017</year><volume>25</volume><fpage>183</fpage><lpage>195</lpage><pub-id pub-id-type="pmid">27071179</pub-id></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arakeri</surname><given-names>TJ</given-names></name><name><surname>Hasse</surname><given-names>BA</given-names></name><name><surname>Fuglevand</surname><given-names>AJ</given-names></name></person-group><article-title>Object Discrimination Using Electrotactile Feedback</article-title><source>J Neural Eng</source><year>2018</year><volume>15</volume><elocation-id>046007</elocation-id><pub-id pub-id-type="doi">10.1088/1741-2552/aabc9a</pub-id><pub-id pub-id-type="pmcid">PMC6331001</pub-id><pub-id pub-id-type="pmid">29629874</pub-id></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Antfolk</surname><given-names>C</given-names></name><name><surname>Björkman</surname><given-names>A</given-names></name><name><surname>Frank</surname><given-names>SO</given-names></name><name><surname>Sebelius</surname><given-names>F</given-names></name><name><surname>Lundborg</surname><given-names>G</given-names></name><name><surname>Rosen</surname><given-names>B</given-names></name></person-group><article-title>Sensory feedback from a prosthetic hand based on air-mediated pressure from the hand to the forearm skin</article-title><source>J Rehabil Med</source><year>2012</year><volume>44</volume><fpage>702</fpage><lpage>707</lpage><pub-id pub-id-type="pmid">22729800</pub-id></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wheeler</surname><given-names>J</given-names></name><name><surname>Bark</surname><given-names>K</given-names></name><name><surname>Savall</surname><given-names>J</given-names></name><name><surname>Cutkosky</surname><given-names>M</given-names></name></person-group><article-title>Investigation of rotational skin stretch for proprioceptive feedback with application to myoelectric systems</article-title><source>IEEE Transactions on Neural Systems and Rehabilitation Engineering</source><year>2010</year><volume>18</volume><fpage>58</fpage><lpage>66</lpage><pub-id pub-id-type="pmid">20071271</pub-id></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Clark</surname><given-names>JP</given-names></name><name><surname>Kim</surname><given-names>SY</given-names></name><name><surname>O’Malley</surname><given-names>MK</given-names></name></person-group><source>The rice haptic rocker: Altering the perception of skin stretch through mapping and geometric design</source><conf-name>IEEE Haptics Symposium, HAPTICS 2018-March</conf-name><year>2018</year><fpage>192</fpage><lpage>197</lpage></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Godfrey</surname><given-names>SB</given-names></name><name><surname>Bianchi</surname><given-names>M</given-names></name><name><surname>Bicchi</surname><given-names>A</given-names></name><name><surname>Santello</surname><given-names>M</given-names></name></person-group><source>Influence of Force Feedback on Grasp Force Modulation in Prosthetic Applications: a Preliminary Study</source><conf-name>Conf Proc IEEE Eng Med Biol Soc</conf-name><year>2016</year><volume>2016</volume><elocation-id>5439</elocation-id></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gathmann</surname><given-names>T</given-names></name><name><surname>Atashzar</surname><given-names>SF</given-names></name><name><surname>Alva</surname><given-names>PGS</given-names></name><name><surname>Farina</surname><given-names>D</given-names></name></person-group><article-title>Wearable Dual-Frequency Vibrotactile System for Restoring Force and Stiffness Perception</article-title><source>IEEE Trans Haptics</source><year>2020</year><volume>13</volume><fpage>191</fpage><lpage>196</lpage><pub-id pub-id-type="pmid">31985443</pub-id></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aboseria</surname><given-names>M</given-names></name><name><surname>Clemente</surname><given-names>F</given-names></name><name><surname>Engels</surname><given-names>LF</given-names></name><name><surname>Cipriani</surname><given-names>C</given-names></name></person-group><article-title>Discrete Vibro-Tactile Feedback Prevents Object Slippage in Hand Prostheses More Intuitively Than Other Modalities</article-title><source>IEEE Trans Neural Syst Rehabil Eng</source><year>2018</year><volume>26</volume><fpage>1577</fpage><lpage>1584</lpage><pub-id pub-id-type="pmid">29994712</pub-id></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marasco</surname><given-names>PD</given-names></name><name><surname>Kim</surname><given-names>K</given-names></name><name><surname>Colgate</surname><given-names>JE</given-names></name><name><surname>Peshkin</surname><given-names>MA</given-names></name><name><surname>Kuiken</surname><given-names>TA</given-names></name></person-group><article-title>Robotic touch shifts perception of embodiment to a prosthesis in targeted reinnervation amputees</article-title><source>Brain</source><year>2011</year><volume>134</volume><fpage>747</fpage><lpage>758</lpage><pub-id pub-id-type="doi">10.1093/brain/awq361</pub-id><pub-id pub-id-type="pmcid">PMC3044830</pub-id><pub-id pub-id-type="pmid">21252109</pub-id></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bensmaia</surname><given-names>SJ</given-names></name><name><surname>Tyler</surname><given-names>DJ</given-names></name><name><surname>Micera</surname><given-names>S</given-names></name></person-group><article-title>Restoration of sensory information via bionic hands</article-title><source>Nature Biomedical Engineering</source><year>2020</year><volume>7</volume><issue>4</issue><fpage>443</fpage><lpage>455</lpage><comment>2020 7</comment><pub-id pub-id-type="doi">10.1038/s41551-020-00630-8</pub-id><pub-id pub-id-type="pmcid">PMC10233657</pub-id><pub-id pub-id-type="pmid">33230305</pub-id></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nisky</surname><given-names>I</given-names></name><name><surname>Makin</surname><given-names>TR</given-names></name></person-group><article-title>A neurocognitive pathway for engineering artificial touch</article-title><source>Sci Adv</source><year>2024</year><volume>10</volume><elocation-id>eadq6290</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.adq6290</pub-id><pub-id pub-id-type="pmcid">PMC11654688</pub-id><pub-id pub-id-type="pmid">39693427</pub-id></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Penfield</surname><given-names>W</given-names></name><name><surname>Rasmussen</surname><given-names>T</given-names></name></person-group><source>The Cerebral Cortex of Man; a Clinical Study of Localization of Function</source><year>1950</year><publisher-name>Macmillan</publisher-name><publisher-loc>Oxford, England</publisher-loc></element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sato</surname><given-names>K</given-names></name><name><surname>Nariai</surname><given-names>T</given-names></name><name><surname>Tanaka</surname><given-names>Y</given-names></name><name><surname>Maehara</surname><given-names>T</given-names></name><name><surname>Miyakawa</surname><given-names>N</given-names></name><name><surname>Sasaki</surname><given-names>S</given-names></name><name><surname>Momose-Sato</surname><given-names>Y</given-names></name><name><surname>Ohno</surname><given-names>K</given-names></name></person-group><article-title>Functional representation of the finger and face in the human somatosensory cortex: intraoperative intrinsic optical imaging</article-title><source>Neuroimage</source><year>2005</year><volume>25</volume><fpage>1292</fpage><lpage>1301</lpage><pub-id pub-id-type="pmid">15850747</pub-id></element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roux</surname><given-names>FE</given-names></name><name><surname>Djidjeli</surname><given-names>I</given-names></name><name><surname>Durand</surname><given-names>JB</given-names></name></person-group><article-title>Functional architecture of the somatosensory homunculus detected by electrostimulation</article-title><source>Journal of Physiology</source><year>2018</year><volume>596</volume><fpage>941</fpage><lpage>956</lpage><pub-id pub-id-type="doi">10.1113/JP275243</pub-id><pub-id pub-id-type="pmcid">PMC5830421</pub-id><pub-id pub-id-type="pmid">29285773</pub-id></element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dominijanni</surname><given-names>G</given-names></name><name><surname>Shokur</surname><given-names>S</given-names></name><name><surname>Salvietti</surname><given-names>G</given-names></name><name><surname>Buehler</surname><given-names>S</given-names></name><name><surname>Palmerini</surname><given-names>E</given-names></name><name><surname>Rossi</surname><given-names>S</given-names></name><name><surname>De Vignemont</surname><given-names>F</given-names></name><name><surname>d’Avella</surname><given-names>A</given-names></name><name><surname>Makin</surname><given-names>TR</given-names></name><name><surname>Prattichizzo</surname><given-names>D</given-names></name><name><surname>Micera</surname><given-names>S</given-names></name></person-group><article-title>The neural resource allocation problem when enhancing human bodies with extra robotic limbs</article-title><source>Nature Machine Intelligence</source><year>2021</year><volume>3</volume><issue>10</issue><fpage>850</fpage><lpage>860</lpage><comment>2021 3</comment></element-citation></ref><ref id="R40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Makin</surname><given-names>TR</given-names></name><name><surname>de Vignemont</surname><given-names>F</given-names></name><name><surname>Micera</surname><given-names>S</given-names></name></person-group><article-title>Soft Embodiment for Engineering Artificial Limbs</article-title><source>Trends Cogn Sci</source><year>2020</year><volume>24</volume><fpage>965</fpage><lpage>968</lpage><pub-id pub-id-type="pmid">33129721</pub-id></element-citation></ref><ref id="R41"><label>41</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Vignemont</surname><given-names>F</given-names></name></person-group><article-title>Embodiment, ownership and disownership</article-title><source>Conscious Cogn</source><year>2011</year><volume>20</volume><fpage>82</fpage><lpage>93</lpage><pub-id pub-id-type="pmid">20943417</pub-id></element-citation></ref><ref id="R42"><label>42</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shu</surname><given-names>T</given-names></name><name><surname>Herrera-Arcos</surname><given-names>G</given-names></name><name><surname>Taylor</surname><given-names>CR</given-names></name><name><surname>Herr</surname><given-names>HM</given-names></name></person-group><article-title>Mechanoneural interfaces for bionic integration</article-title><source>Nature Reviews Bioengineering</source><year>2024</year><volume>2</volume><issue>5</issue><fpage>374</fpage><lpage>391</lpage><comment>2024 2</comment></element-citation></ref><ref id="R43"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maimon-Mor</surname><given-names>RO</given-names></name><name><surname>Makin</surname><given-names>TR</given-names></name></person-group><article-title>Is an artificial limb embodied as a hand? Brain decoding in prosthetic limb users</article-title><source>PLoS Biol</source><year>2020</year><volume>18</volume><elocation-id>e3000729</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.3000729</pub-id><pub-id pub-id-type="pmcid">PMC7302856</pub-id><pub-id pub-id-type="pmid">32511238</pub-id></element-citation></ref><ref id="R44"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schone</surname><given-names>HR</given-names></name><name><surname>Maimon-Mor</surname><given-names>RO</given-names></name><name><surname>Baker</surname><given-names>CI</given-names></name><name><surname>Makin</surname><given-names>TR</given-names></name></person-group><article-title>Expert Tool Users Show Increased Differentiation between Visual Representations of Hands and Tools</article-title><source>Journal of Neuroscience</source><year>2021</year><volume>41</volume><fpage>2980</fpage><lpage>2989</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2489-20.2020</pub-id><pub-id pub-id-type="pmcid">PMC8018880</pub-id><pub-id pub-id-type="pmid">33563728</pub-id></element-citation></ref><ref id="R45"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kieliba</surname><given-names>P</given-names></name><name><surname>Clode</surname><given-names>D</given-names></name><name><surname>Maimon-Mor</surname><given-names>RO</given-names></name><name><surname>Makin</surname><given-names>TR</given-names></name></person-group><article-title>Robotic hand augmentation drives changes in neural body representation</article-title><source>Sci Robot</source><year>2021</year><volume>6</volume><pub-id pub-id-type="doi">10.1126/scirobotics.abd7935</pub-id><pub-id pub-id-type="pmcid">PMC7612043</pub-id><pub-id pub-id-type="pmid">34043536</pub-id></element-citation></ref><ref id="R46"><label>46</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Molina-Sanchez</surname><given-names>M</given-names></name><name><surname>Dowdall</surname><given-names>L</given-names></name><name><surname>Dominijanni</surname><given-names>G</given-names></name><name><surname>Pavalkyte</surname><given-names>V</given-names></name><name><surname>Gallay</surname><given-names>C</given-names></name><name><surname>da Silva</surname><given-names>E</given-names></name><name><surname>Clode</surname><given-names>D</given-names></name><name><surname>Makin</surname><given-names>Tamar R</given-names></name></person-group><article-title>Motor learning outside the body: broad skill generalisation with a new body part</article-title><source>In Prep</source><year>2025</year></element-citation></ref><ref id="R47"><label>47</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ivani</surname><given-names>AS</given-names></name><name><surname>Catalano</surname><given-names>MG</given-names></name><name><surname>Grioli</surname><given-names>G</given-names></name><name><surname>Bianchi</surname><given-names>M</given-names></name><name><surname>Visell</surname><given-names>Y</given-names></name><name><surname>Bicchi</surname><given-names>A</given-names></name></person-group><article-title>Tactile Perception in Upper Limb Prostheses: Mechanical Characterization, Human Experiments, and Computational Findings</article-title><source>IEEE Trans Haptics</source><year>2024</year><pub-id pub-id-type="pmid">39093675</pub-id></element-citation></ref><ref id="R48"><label>48</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doubler</surname><given-names>JA</given-names></name><name><surname>Childress</surname><given-names>DS</given-names></name></person-group><article-title>Design and evaluation of a prosthesis control system based on the concept of extended physiological proprioception</article-title><source>J Rehabil Res Dev</source><year>1984</year><volume>21</volume><fpage>19</fpage><lpage>31</lpage><pub-id pub-id-type="pmid">6527287</pub-id></element-citation></ref><ref id="R49"><label>49</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amoruso</surname><given-names>E</given-names></name><name><surname>Dowdall</surname><given-names>L</given-names></name><name><surname>Kollamkulam</surname><given-names>MT</given-names></name><name><surname>Ukaegbu</surname><given-names>O</given-names></name><name><surname>Kieliba</surname><given-names>P</given-names></name><name><surname>Ng</surname><given-names>T</given-names></name><name><surname>Dempsey-Jones</surname><given-names>H</given-names></name><name><surname>Clode</surname><given-names>D</given-names></name><name><surname>Makin</surname><given-names>TR</given-names></name></person-group><article-title>Intrinsic somatosensory feedback supports motor control and learning to operate artificial body parts</article-title><source>J Neural Eng</source><year>2022</year><volume>19</volume><elocation-id>016006</elocation-id><pub-id pub-id-type="doi">10.1088/1741-2552/ac47d9</pub-id><pub-id pub-id-type="pmcid">PMC10431236</pub-id><pub-id pub-id-type="pmid">34983040</pub-id></element-citation></ref><ref id="R50"><label>50</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fani</surname><given-names>S</given-names></name><name><surname>Di Blasio</surname><given-names>K</given-names></name><name><surname>Bianchi</surname><given-names>M</given-names></name><name><surname>Catalano</surname><given-names>MG</given-names></name><name><surname>Grioli</surname><given-names>G</given-names></name><name><surname>Bicchi</surname><given-names>A</given-names></name></person-group><article-title>Relaying the High-Frequency Contents of Tactile Feedback to Robotic Prosthesis Users: Design, Filtering, Implementation, and Validation</article-title><source>IEEE Robot Autom Lett</source><year>2019</year><volume>4</volume><fpage>926</fpage><lpage>933</lpage></element-citation></ref><ref id="R51"><label>51</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Haan</surname><given-names>AM</given-names></name><name><surname>Anema</surname><given-names>HA</given-names></name><name><surname>Dijkerman</surname><given-names>HC</given-names></name></person-group><article-title>Fingers Crossed! An Investigation of Somatotopic Representations Using Spatial Directional Judgements</article-title><source>PLoS One</source><year>2012</year><volume>7</volume><elocation-id>e45408</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0045408</pub-id><pub-id pub-id-type="pmcid">PMC3454417</pub-id><pub-id pub-id-type="pmid">23028989</pub-id></element-citation></ref><ref id="R52"><label>52</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kolasinski</surname><given-names>J</given-names></name><name><surname>Makin</surname><given-names>TR</given-names></name><name><surname>Logan</surname><given-names>JP</given-names></name><name><surname>Jbabdi</surname><given-names>S</given-names></name><name><surname>Clare</surname><given-names>S</given-names></name><name><surname>Stagg</surname><given-names>CJ</given-names></name><name><surname>Johansen-Berg</surname><given-names>H</given-names></name></person-group><article-title>Perceptually relevant remapping of human somatotopy in 24 hours</article-title><source>Elife</source><year>2016</year><volume>5</volume><pub-id pub-id-type="doi">10.7554/eLife.17280</pub-id><pub-id pub-id-type="pmcid">PMC5241114</pub-id><pub-id pub-id-type="pmid">28035900</pub-id></element-citation></ref><ref id="R53"><label>53</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ogawa</surname><given-names>K</given-names></name><name><surname>Mitsui</surname><given-names>K</given-names></name><name><surname>Imai</surname><given-names>F</given-names></name><name><surname>Nishida</surname><given-names>S</given-names></name></person-group><article-title>Long-term training-dependent representation of individual finger movements in the primary motor cortex</article-title><source>Neuroimage</source><year>2019</year><volume>202</volume><elocation-id>116051</elocation-id><pub-id pub-id-type="pmid">31351164</pub-id></element-citation></ref><ref id="R54"><label>54</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hirano</surname><given-names>M</given-names></name><name><surname>Kimoto</surname><given-names>Y</given-names></name><name><surname>Shiotani</surname><given-names>S</given-names></name><name><surname>Furuya</surname><given-names>S</given-names></name></person-group><article-title>Enhanced Somatosensory Inhibition Sharpens Hand Representation and Sensorimotor Skills in Pianists</article-title><source>Journal of Neuroscience</source><year>2025</year><volume>45</volume><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1486-24.2024</pub-id><pub-id pub-id-type="pmcid">PMC11841757</pub-id><pub-id pub-id-type="pmid">39746821</pub-id></element-citation></ref><ref id="R55"><label>55</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Umezawa</surname><given-names>K</given-names></name><name><surname>Suzuki</surname><given-names>Y</given-names></name><name><surname>Ganesh</surname><given-names>G</given-names></name><name><surname>Miyawaki</surname><given-names>Y</given-names></name></person-group><article-title>Bodily ownership of an independent supernumerary limb: an exploratory study</article-title><source>Scientific Reports</source><year>2022</year><volume>12</volume><issue>1</issue><fpage>1</fpage><lpage>11</lpage><comment>2022 12</comment><pub-id pub-id-type="doi">10.1038/s41598-022-06040-x</pub-id><pub-id pub-id-type="pmcid">PMC8844351</pub-id><pub-id pub-id-type="pmid">35165309</pub-id></element-citation></ref><ref id="R56"><label>56</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pinardi</surname><given-names>M</given-names></name><name><surname>Longo</surname><given-names>MR</given-names></name><name><surname>Formica</surname><given-names>D</given-names></name><name><surname>Strbac</surname><given-names>M</given-names></name><name><surname>Mehring</surname><given-names>C</given-names></name><name><surname>Burdet</surname><given-names>E</given-names></name><name><surname>Di Pino</surname><given-names>G</given-names></name></person-group><article-title>Impact of supplementary sensory feedback on the control and embodiment in human movement augmentation</article-title><source>Communications Engineering</source><year>2023</year><volume>2</volume><issue>1</issue><fpage>1</fpage><lpage>15</lpage><comment>2023 2</comment></element-citation></ref><ref id="R57"><label>57</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muret</surname><given-names>D</given-names></name><name><surname>Makin</surname><given-names>TR</given-names></name></person-group><article-title>The homeostatic homunculus: rethinking deprivation-triggered reorganisation</article-title><source>Curr Opin Neurobiol</source><year>2021</year><volume>67</volume><fpage>115</fpage><lpage>122</lpage><pub-id pub-id-type="pmid">33248404</pub-id></element-citation></ref><ref id="R58"><label>58</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Makin</surname><given-names>TR</given-names></name><name><surname>Krakauer</surname><given-names>JW</given-names></name></person-group><article-title>Against cortical reorganisation</article-title><source>Elife</source><year>2023</year><volume>12</volume><pub-id pub-id-type="doi">10.7554/eLife.84716</pub-id><pub-id pub-id-type="pmcid">PMC10662956</pub-id><pub-id pub-id-type="pmid">37986628</pub-id></element-citation></ref><ref id="R59"><label>59</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>LE</given-names></name><name><surname>Longo</surname><given-names>MR</given-names></name><name><surname>Saygin</surname><given-names>AP</given-names></name></person-group><article-title>Tool Use Modulates Somatosensory Cortical Processing in Humans</article-title><source>J Cogn Neurosci</source><year>2019</year><volume>31</volume><fpage>1782</fpage><lpage>1795</lpage><pub-id pub-id-type="pmid">31368823</pub-id></element-citation></ref><ref id="R60"><label>60</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cardinali</surname><given-names>L</given-names></name><name><surname>Zanini</surname><given-names>A</given-names></name><name><surname>Yanofsky</surname><given-names>R</given-names></name><name><surname>Roy</surname><given-names>AC</given-names></name><name><surname>de Vignemont</surname><given-names>F</given-names></name><name><surname>Culham</surname><given-names>JC</given-names></name><name><surname>Farnè</surname><given-names>A</given-names></name></person-group><article-title>The toolish hand illusion: embodiment of a tool based on similarity with the hand</article-title><source>Scientific Reports</source><year>2021</year><volume>11</volume><issue>1</issue><fpage>1</fpage><lpage>9</lpage><comment>2021 11</comment><pub-id pub-id-type="doi">10.1038/s41598-021-81706-6</pub-id><pub-id pub-id-type="pmcid">PMC7820319</pub-id><pub-id pub-id-type="pmid">33479395</pub-id></element-citation></ref><ref id="R61"><label>61</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fabio</surname><given-names>C</given-names></name><name><surname>Salemme</surname><given-names>R</given-names></name><name><surname>Farnè</surname><given-names>A</given-names></name><name><surname>Miller</surname><given-names>LE</given-names></name></person-group><article-title>Alpha oscillations reflect similar mapping mechanisms for localizing touch on hands and tools</article-title><source>iScience</source><year>2024</year><volume>27</volume><pub-id pub-id-type="doi">10.1016/j.isci.2024.109092</pub-id><pub-id pub-id-type="pmcid">PMC10884914</pub-id><pub-id pub-id-type="pmid">38405611</pub-id></element-citation></ref><ref id="R62"><label>62</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maimon-Mor</surname><given-names>RO</given-names></name><name><surname>Obasi</surname><given-names>E</given-names></name><name><surname>Lu</surname><given-names>J</given-names></name><name><surname>Odeh</surname><given-names>N</given-names></name><name><surname>Kirker</surname><given-names>S</given-names></name><name><surname>MacSweeney</surname><given-names>M</given-names></name><name><surname>Goldin-Meadow</surname><given-names>S</given-names></name><name><surname>Makin</surname><given-names>TR</given-names></name></person-group><article-title>Talking with Your (Artificial) Hands: Communicative Hand Gestures as an Implicit Measure of Embodiment</article-title><source>iScience</source><year>2020</year><volume>23</volume><pub-id pub-id-type="doi">10.1016/j.isci.2020.101650</pub-id><pub-id pub-id-type="pmcid">PMC7578755</pub-id><pub-id pub-id-type="pmid">33103087</pub-id></element-citation></ref><ref id="R63"><label>63</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Castañeda</surname><given-names>TS</given-names></name><name><surname>Connan</surname><given-names>M</given-names></name><name><surname>Capsi-Morales</surname><given-names>P</given-names></name><name><surname>Beckerle</surname><given-names>P</given-names></name><name><surname>Castellini</surname><given-names>C</given-names></name><name><surname>Piazza</surname><given-names>C</given-names></name></person-group><article-title>Experimental evaluation of the impact of sEMG interfaces in enhancing embodiment of virtual myoelectric prostheses</article-title><source>J Neuroeng Rehabil</source><year>2024</year><volume>21</volume><fpage>1</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.1186/s12984-024-01352-7</pub-id><pub-id pub-id-type="pmcid">PMC11020298</pub-id><pub-id pub-id-type="pmid">38627772</pub-id></element-citation></ref><ref id="R64"><label>64</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Graczyk</surname><given-names>EL</given-names></name><name><surname>Resnik</surname><given-names>L</given-names></name><name><surname>Schiefer</surname><given-names>MA</given-names></name><name><surname>Schmitt</surname><given-names>MS</given-names></name><name><surname>Tyler</surname><given-names>DJ</given-names></name></person-group><article-title>Home Use of a Neural-connected Sensory Prosthesis Provides the Functional and Psychosocial Experience of Having a Hand Again</article-title><source>Scientific Reports</source><year>2018</year><volume>8</volume><issue>1</issue><fpage>1</fpage><lpage>17</lpage><comment>2018 8</comment><pub-id pub-id-type="doi">10.1038/s41598-018-26952-x</pub-id><pub-id pub-id-type="pmcid">PMC6026118</pub-id><pub-id pub-id-type="pmid">29959334</pub-id></element-citation></ref><ref id="R65"><label>65</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zbinden</surname><given-names>J</given-names></name><name><surname>Lendaro</surname><given-names>E</given-names></name><name><surname>Ortiz-Catalan</surname><given-names>M</given-names></name></person-group><article-title>Prosthetic embodiment: systematic review on definitions, measures, and experimental paradigms</article-title><source>Journal of NeuroEngineering and Rehabilitation</source><year>2022</year><volume>19</volume><issue>1</issue><fpage>1</fpage><lpage>16</lpage><comment>2022 19</comment><pub-id pub-id-type="doi">10.1186/s12984-022-01006-6</pub-id><pub-id pub-id-type="pmcid">PMC8962549</pub-id><pub-id pub-id-type="pmid">35346251</pub-id></element-citation></ref><ref id="R66"><label>66</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clode</surname><given-names>D</given-names></name><name><surname>Dowdall</surname><given-names>L</given-names></name><name><surname>da Silva</surname><given-names>E</given-names></name><name><surname>Selén</surname><given-names>K</given-names></name><name><surname>Cowie</surname><given-names>D</given-names></name><name><surname>Dominijanni</surname><given-names>G</given-names></name><name><surname>Makin</surname><given-names>TR</given-names></name></person-group><article-title>Evaluating initial usability of a hand augmentation device across a large and diverse sample</article-title><source>Sci Robot</source><year>2024</year><volume>9</volume><pub-id pub-id-type="doi">10.1126/scirobotics.adk5183</pub-id><pub-id pub-id-type="pmcid">PMC7616312</pub-id><pub-id pub-id-type="pmid">38809995</pub-id></element-citation></ref><ref id="R67"><label>67</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kontsevich</surname><given-names>LL</given-names></name><name><surname>Tyler</surname><given-names>CW</given-names></name></person-group><article-title>Bayesian adaptive estimation of psychometric slope and threshold</article-title><source>Vision Res</source><year>1999</year><volume>39</volume><fpage>2729</fpage><lpage>2737</lpage><pub-id pub-id-type="pmid">10492833</pub-id></element-citation></ref><ref id="R68"><label>68</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prins</surname><given-names>N</given-names></name><name><surname>Kingdom</surname><given-names>FAA</given-names></name></person-group><article-title>Applying the model-comparison approach to test specific research hypotheses in psychophysical research using the Palamedes toolbox</article-title><source>Front Psychol</source><year>2018</year><volume>9</volume><pub-id pub-id-type="doi">10.3389/fpsyg.2018.01250</pub-id><pub-id pub-id-type="pmcid">PMC6064978</pub-id><pub-id pub-id-type="pmid">30083122</pub-id></element-citation></ref><ref id="R69"><label>69</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prins</surname><given-names>N</given-names></name></person-group><article-title>The psi-marginal adaptive method: How to give nuisance parameters the attention they deserve (no more, no less)</article-title><source>J Vis</source><year>2013</year><volume>13</volume><fpage>3</fpage><pub-id pub-id-type="pmid">23750016</pub-id></element-citation></ref><ref id="R70"><label>70</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burnham</surname><given-names>KP</given-names></name><name><surname>Anderson</surname><given-names>DR</given-names></name></person-group><article-title>Model Selection and Multimodel Inference</article-title><source>Model Selection and Multimodel Inference</source><year>2004</year><pub-id pub-id-type="doi">10.1007/B97636</pub-id></element-citation></ref><ref id="R71"><label>71</label><element-citation publication-type="others"><collab>Yousician</collab><year>2010</year><comment>[Preprint]</comment></element-citation></ref><ref id="R72"><label>72</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sonar</surname><given-names>HA</given-names></name><name><surname>Gerratt</surname><given-names>AP</given-names></name><name><surname>Lacour</surname><given-names>SP</given-names></name><name><surname>Paik</surname><given-names>J</given-names></name></person-group><article-title>Closed-Loop Haptic Feedback Control Using a Self-Sensing Soft Pneumatic Actuator Skin</article-title><source>Soft Robot</source><year>2020</year><volume>7</volume><fpage>22</fpage><lpage>29</lpage><pub-id pub-id-type="pmid">31549908</pub-id></element-citation></ref><ref id="R73"><label>73</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kikkert</surname><given-names>S</given-names></name><name><surname>Sonar</surname><given-names>HA</given-names></name><name><surname>Freund</surname><given-names>P</given-names></name><name><surname>Paik</surname><given-names>J</given-names></name><name><surname>Wenderoth</surname><given-names>N</given-names></name></person-group><article-title>Hand and face somatotopy shown using MRI-safe vibrotactile stimulation with a novel soft pneumatic actuator (SPA)-skin interface</article-title><source>Neuroimage</source><year>2023</year><volume>269</volume><elocation-id>119932</elocation-id><pub-id pub-id-type="pmid">36750151</pub-id></element-citation></ref><ref id="R74"><label>74</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tommerdahl</surname><given-names>M</given-names></name><name><surname>Hester</surname><given-names>KD</given-names></name><name><surname>Felix</surname><given-names>ER</given-names></name><name><surname>Hollins</surname><given-names>M</given-names></name><name><surname>Favorov</surname><given-names>OV</given-names></name><name><surname>Quibrera</surname><given-names>PM</given-names></name><name><surname>Whitsel</surname><given-names>BL</given-names></name></person-group><article-title>Human vibrotactile frequency discriminative capacity after adaptation to 25 Hz or 200 Hz stimulation</article-title><source>Brain Res</source><year>2005</year><volume>1057</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="pmid">16140284</pub-id></element-citation></ref><ref id="R75"><label>75</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leung</surname><given-names>YY</given-names></name><name><surname>Bensmaïa</surname><given-names>SJ</given-names></name><name><surname>Hsiao</surname><given-names>SS</given-names></name><name><surname>Johnson</surname><given-names>KO</given-names></name></person-group><article-title>Time-course of vibratory adaptation and recovery in cutaneous mechanoreceptive afferents</article-title><source>J Neurophysiol</source><year>2005</year><volume>94</volume><fpage>3037</fpage><lpage>3045</lpage><pub-id pub-id-type="doi">10.1152/jn.00001.2005</pub-id><pub-id pub-id-type="pmcid">PMC1839047</pub-id><pub-id pub-id-type="pmid">16222071</pub-id></element-citation></ref><ref id="R76"><label>76</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanchez-Panchuelo</surname><given-names>RM</given-names></name><name><surname>Besle</surname><given-names>J</given-names></name><name><surname>Beckett</surname><given-names>A</given-names></name><name><surname>Bowtell</surname><given-names>R</given-names></name><name><surname>Schluppeck</surname><given-names>D</given-names></name><name><surname>Francis</surname><given-names>S</given-names></name></person-group><article-title>Within-Digit Functional Parcellation of Brodmann Areas of the Human Primary Somatosensory Cortex Using Functional Magnetic Resonance Imaging at 7 Tesla</article-title><source>Journal of Neuroscience</source><year>2012</year><volume>32</volume><fpage>15815</fpage><lpage>15822</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2501-12.2012</pub-id><pub-id pub-id-type="pmcid">PMC6621625</pub-id><pub-id pub-id-type="pmid">23136420</pub-id></element-citation></ref><ref id="R77"><label>77</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Beckmann</surname><given-names>CF</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name></person-group><article-title>FSL</article-title><source>Neuroimage</source><year>2012</year><volume>62</volume><fpage>782</fpage><lpage>790</lpage><pub-id pub-id-type="pmid">21979382</pub-id></element-citation></ref><ref id="R78"><label>78</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nili</surname><given-names>H</given-names></name><name><surname>Wingfield</surname><given-names>C</given-names></name><name><surname>Walther</surname><given-names>A</given-names></name><name><surname>Su</surname><given-names>L</given-names></name><name><surname>Marslen-Wilson</surname><given-names>W</given-names></name><name><surname>Kriegeskorte</surname><given-names>N</given-names></name></person-group><article-title>A Toolbox for Representational Similarity Analysis</article-title><source>PLoS Comput Biol</source><year>2014</year><volume>10</volume><elocation-id>e1003553</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003553</pub-id><pub-id pub-id-type="pmcid">PMC3990488</pub-id><pub-id pub-id-type="pmid">24743308</pub-id></element-citation></ref><ref id="R79"><label>79</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wesselink</surname><given-names>D</given-names></name><name><surname>Maimon-Mor</surname><given-names>R</given-names></name></person-group><article-title>rsatoolbox, version 20fbe05</article-title><source>github</source><year>2017</year><comment>[Preprint]</comment></element-citation></ref><ref id="R80"><label>80</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Smith</surname><given-names>S</given-names></name></person-group><article-title>A global optimisation method for robust affine registration of brain images</article-title><source>Med Image Anal</source><year>2001</year><volume>5</volume><fpage>143</fpage><lpage>156</lpage><pub-id pub-id-type="pmid">11516708</pub-id></element-citation></ref><ref id="R81"><label>81</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Bannister</surname><given-names>P</given-names></name><name><surname>Brady</surname><given-names>M</given-names></name><name><surname>Smith</surname><given-names>S</given-names></name></person-group><article-title>Improved optimization for the robust and accurate linear registration and motion correction of brain images</article-title><source>Neuroimage</source><year>2002</year><volume>17</volume><fpage>825</fpage><lpage>841</lpage><pub-id pub-id-type="pmid">12377157</pub-id></element-citation></ref><ref id="R82"><label>82</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>SM</given-names></name></person-group><article-title>Fast robust automated brain extraction</article-title><source>Hum Brain Mapp</source><year>2002</year><volume>17</volume><fpage>143</fpage><lpage>155</lpage><pub-id pub-id-type="doi">10.1002/hbm.10062</pub-id><pub-id pub-id-type="pmcid">PMC6871816</pub-id><pub-id pub-id-type="pmid">12391568</pub-id></element-citation></ref><ref id="R83"><label>83</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Power</surname><given-names>JD</given-names></name><name><surname>Mitra</surname><given-names>A</given-names></name><name><surname>Laumann</surname><given-names>TO</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Schlaggar</surname><given-names>BL</given-names></name><name><surname>Petersen</surname><given-names>SE</given-names></name></person-group><article-title>Methods to detect, characterize, and remove motion artifact in resting state fMRI</article-title><source>Neuroimage</source><year>2013</year><volume>84</volume><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.08.048</pub-id><pub-id pub-id-type="pmcid">PMC3849338</pub-id><pub-id pub-id-type="pmid">23994314</pub-id></element-citation></ref><ref id="R84"><label>84</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischl</surname><given-names>B</given-names></name></person-group><article-title>FreeSurfer</article-title><source>Neuroimage</source><year>2012</year><volume>62</volume><fpage>774</fpage><lpage>781</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.01.021</pub-id><pub-id pub-id-type="pmcid">PMC3685476</pub-id><pub-id pub-id-type="pmid">22248573</pub-id></element-citation></ref><ref id="R85"><label>85</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glasser</surname><given-names>MF</given-names></name><name><surname>Coalson</surname><given-names>TS</given-names></name><name><surname>Robinson</surname><given-names>EC</given-names></name><name><surname>Hacker</surname><given-names>CD</given-names></name><name><surname>Harwell</surname><given-names>J</given-names></name><name><surname>Yacoub</surname><given-names>E</given-names></name><name><surname>Ugurbil</surname><given-names>K</given-names></name><name><surname>Andersson</surname><given-names>J</given-names></name><name><surname>Beckmann</surname><given-names>CF</given-names></name><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name><etal/></person-group><article-title>A multi-modal parcellation of human cerebral cortex</article-title><source>Nature</source><year>2016</year><volume>536</volume><issue>7615</issue><fpage>171</fpage><lpage>178</lpage><comment>2016 536</comment><pub-id pub-id-type="doi">10.1038/nature18933</pub-id><pub-id pub-id-type="pmcid">PMC4990127</pub-id><pub-id pub-id-type="pmid">27437579</pub-id></element-citation></ref><ref id="R86"><label>86</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiestler</surname><given-names>T</given-names></name><name><surname>Diedrichsen</surname><given-names>J</given-names></name></person-group><article-title>Skill learning strengthens cortical representations of motor sequences</article-title><source>Elife</source><year>2013</year><volume>2</volume><pub-id pub-id-type="doi">10.7554/eLife.00801</pub-id><pub-id pub-id-type="pmcid">PMC3707182</pub-id><pub-id pub-id-type="pmid">23853714</pub-id></element-citation></ref><ref id="R87"><label>87</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name><name><surname>Mur</surname><given-names>M</given-names></name><name><surname>Bandettini</surname><given-names>P</given-names></name></person-group><article-title>Representational similarity analysis - connecting the branches of systems neuroscience</article-title><source>Front Syst Neurosci</source><year>2008</year><volume>2</volume><fpage>249</fpage><pub-id pub-id-type="doi">10.3389/neuro.06.004.2008</pub-id><pub-id pub-id-type="pmcid">PMC2605405</pub-id><pub-id pub-id-type="pmid">19104670</pub-id></element-citation></ref><ref id="R88"><label>88</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nili</surname><given-names>H</given-names></name><name><surname>Wingfield</surname><given-names>C</given-names></name><name><surname>Walther</surname><given-names>A</given-names></name><name><surname>Su</surname><given-names>L</given-names></name><name><surname>Marslen-Wilson</surname><given-names>W</given-names></name><name><surname>Kriegeskorte</surname><given-names>N</given-names></name></person-group><article-title>A toolbox for representational similarity analysis</article-title><source>PLoS Comput Biol</source><year>2014</year><volume>10</volume></element-citation></ref><ref id="R89"><label>89</label><element-citation publication-type="others"><collab>Logitech</collab><year>2021</year><comment>[Preprint]</comment></element-citation></ref><ref id="R90"><label>90</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>F</given-names></name><name><surname>Bazarevsky</surname><given-names>V</given-names></name><name><surname>Vakunov</surname><given-names>A</given-names></name><name><surname>Tkachenka</surname><given-names>A</given-names></name><name><surname>Sung</surname><given-names>G</given-names></name><name><surname>Chang</surname><given-names>C-L</given-names></name><name><surname>Grundmann</surname><given-names>M</given-names></name></person-group><source>MediaPipe Hands: On-device Real-time Hand Tracking</source><year>2020</year></element-citation></ref><ref id="R91"><label>91</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karashchuk</surname><given-names>P</given-names></name><name><surname>Rupp</surname><given-names>KL</given-names></name><name><surname>Dickinson</surname><given-names>ES</given-names></name><name><surname>Walling-Bell</surname><given-names>S</given-names></name><name><surname>Sanders</surname><given-names>E</given-names></name><name><surname>Azim</surname><given-names>E</given-names></name><name><surname>Brunton</surname><given-names>BW</given-names></name><name><surname>Tuthill</surname><given-names>JC</given-names></name></person-group><article-title>Anipose: A toolkit for robust markerless 3D pose estimation</article-title><source>Cell Rep</source><year>2021</year><volume>36</volume><pub-id pub-id-type="doi">10.1016/j.celrep.2021.109730</pub-id><pub-id pub-id-type="pmcid">PMC8498918</pub-id><pub-id pub-id-type="pmid">34592148</pub-id></element-citation></ref><ref id="R92"><label>92</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jarque-Bou</surname><given-names>NJ</given-names></name><name><surname>Scano</surname><given-names>A</given-names></name><name><surname>Atzori</surname><given-names>M</given-names></name><name><surname>Müller</surname><given-names>H</given-names></name></person-group><article-title>Kinematic synergies of hand grasps: a comprehensive study on a large publicly available dataset</article-title><source>J Neuroeng Rehabil</source><year>2019</year><volume>16</volume><pub-id pub-id-type="doi">10.1186/s12984-019-0536-6</pub-id><pub-id pub-id-type="pmcid">PMC6540541</pub-id><pub-id pub-id-type="pmid">31138257</pub-id></element-citation></ref><ref id="R93"><label>93</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Longo</surname><given-names>MR</given-names></name><name><surname>Schüür</surname><given-names>F</given-names></name><name><surname>Kammers</surname><given-names>MPM</given-names></name><name><surname>Tsakiris</surname><given-names>M</given-names></name><name><surname>Haggard</surname><given-names>P</given-names></name></person-group><article-title>What is embodiment? A psychometric approach</article-title><source>Cognition</source><year>2008</year><volume>107</volume><fpage>978</fpage><lpage>998</lpage><pub-id pub-id-type="pmid">18262508</pub-id></element-citation></ref><ref id="R94"><label>94</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wetzels</surname><given-names>R</given-names></name><name><surname>Matzke</surname><given-names>D</given-names></name><name><surname>Lee</surname><given-names>MD</given-names></name><name><surname>Rouder</surname><given-names>JN</given-names></name><name><surname>Iverson</surname><given-names>GJ</given-names></name><name><surname>Wagenmakers</surname><given-names>EJ</given-names></name></person-group><article-title>Statistical Evidence in Experimental Psychology: An Empirical Comparison Using 855 t Tests</article-title><source>Perspect Psychol Sci</source><year>2011</year><volume>6</volume><fpage>291</fpage><lpage>298</lpage><pub-id pub-id-type="pmid">26168519</pub-id></element-citation></ref><ref id="R95"><label>95</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Corniani</surname><given-names>G</given-names></name><name><surname>Saal</surname><given-names>HP</given-names></name></person-group><article-title>Tactile innervation densities across the whole body</article-title><source>J Neurophysiol</source><year>2020</year><volume>124</volume><fpage>1229</fpage><lpage>1240</lpage><pub-id pub-id-type="pmid">32965159</pub-id></element-citation></ref><ref id="R96"><label>96</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deflorio</surname><given-names>D</given-names></name><name><surname>Di Luca</surname><given-names>M</given-names></name><name><surname>Wing</surname><given-names>AM</given-names></name></person-group><article-title>Skin and Mechanoreceptor Contribution to Tactile Input for Perception: A Review of Simulation Models</article-title><source>Front Hum Neurosci</source><year>2022</year><volume>16</volume><elocation-id>862344</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2022.862344</pub-id><pub-id pub-id-type="pmcid">PMC9201416</pub-id><pub-id pub-id-type="pmid">35721353</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><title>Users can easily extract detailed sensory information to inform perceptual judgements with an artificial body part.</title><p>(A) The Third Thumb (Dani Clode Design; Digit 6 (D6)) is a 3D-printed extra robotic digit, worn on the ulnar side of the hand and controlled by force sensors fixed underneath the big toes. (B) Sensory feedback is passively received on the side of the hand and distributed across the hand from how D6 is worn and moves on the hand, even without the active mediation of sensors and actuators; hereafter “natural” feedback. (C) Incorporation of Skin Stretch artificial feedback into the D6 design, where deformation of a pressure sensor in the D6 tip produced a proportional amount of linear skin stretch in the inner wrist (left). Participants performed just as well in a material deformation task (middle) with the Skin Stretch feedback as with the Natural feedback (BF<sub>10</sub> =.251, right). (D) Incorporation of Vibrotactile artificial feedback into the D6 design, where non-intentional displacement of the D6 tip produced a proportional amount of Vibrotactile feedback delivered to the ring finger (left). The Natural Feedback outperformed the Vibrotactile Feedback (right) in a texture discrimination task (middle). (E) In a temporal order judgement (TOJ) task, motors were attached to the biological thumb (D1), index finger (D2), little finger (D5) and (non-sensorised) D6 and were used to stimulate digit-pairs in quick succession (left). Participants could successfully make spatiotemporal judgements about the D6 digit-pairs, performing similarly to when performing the task with only their biological fingers (right). Participants also performed similarly across all D6 digit-pairs, regardless of distance between D6 and the biological digit (middle). * denotes p &lt; .05.</p></caption><graphic xlink:href="EMS206953-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><title>Emergence of a sensory representation of D6 in novice users.</title><p>(A) Silicone vibrotactors used to deliver stimulations to each of the biological digits, D6 (the Third Thumb), and the side of the hand where the natural feedback is received (the ‘palm’) (left) during the fMRI scan (right). (B) Averaged activity (zstat) elicited along the S1 hand area (lateral (left) to medial (right) for the biological digits and D6 (selectivity; relative to their respective controls - the average of the other biological digits, and the palm of the hand;). (C) S1 (BA3b) hand area region of interest, segmented into 17 equally-spaced bands for line analysis. (D) S1 (BA3b) region of interest for RSA, approximately 2cm proximal/distal to the hand knob. (E) Multidimensional Scaling (MDS) plot (left) and representational dissimilarity matrix (RDM) showing the crossnobis distances between the stimulation conditions, demonstrating the topographical organisation of the hand, and the integration of D6 into this topographical structure. Error bands in MDS represent variability when projecting into 2D space. (F) Crossnobis distance between D6 and the palm is significantly above zero, implying unique information content within the D6 representation even at baseline.</p></caption><graphic xlink:href="EMS206953-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>D6 Training.</title><p>(A) Longitudinal training study design. Participants all underwent a short familiarisation session with D6, followed by the TOJ psychophysics task and passive fMRI scan described above. Participants were then allocated to the D6 Training (experimental group) or Keyboard Training (control group). After their seven days of training, participants returned for another fMRI scan (replicating the first) and performed the TOJ task. (B) D6 training focused on D6-biological hand collaboration-based tasks, exploring different aspects of this motor skill. Participants show large improvements in motor task performance over their week of training. (C) Control group trained to play the piano keyboard over the week of training. Participants showed large improvements in task performance over the week. (D) View from each of the three cameras used to track participants’ hand during the free-choice tasks, with projections of the 2D joint coordinates of the five biological digits, and 3D reconstructed joint angles. (E) When looking at patterns of finger co-usage following training using 3D kinematics (through a markerless tracking setup), Keyboard participants show significantly more individuation when performing ecological tasks without wearing D6 (whilst the D6 training group saw no difference). Averaged over joint and digit-pair for visualisation purposes only. (F) D6 training participants performed a coordination task involving opposing D6 with an individual digit over the course of one minute. Regardless of distance between D6 and the biological digit, similar improvements in coordination were seen across the whole hand. *** denotes p &lt; .001.</p></caption><graphic xlink:href="EMS206953-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><title>Refinement of the D6 sensory representation following D6 training</title><p>(A) Peak of activity for D6 within the S1 hand representation (versus palm). Following D6 training (right), we see a large and more distinct peak for D6, compared to the Keyboard control group (left). (B) We see reduced distances between D6 and the biological fingers for the D6 training group, relative to the Keyboard group, demonstrating that D6 is becoming more similar to the biological hand (C) The crossnobis distance between D6 and the palm does not change based on training experience (D) Co-usage measure of the biological fingers when wearing D6 and performing a series of free-choice tasks on the first and last day of training. We see the D6 group show increased finger individuation following training, not seen for the control group.</p></caption><graphic xlink:href="EMS206953-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><title>Effects of training on biological hand representation.</title><p>Crossnobis distance for each group, before and after their respective training regimes (Keyboard left, D6 right). All participants demonstrated reduced inter-finger information content following their altered finger-coordination training, but we see a greater training effect for the Keyboard group.</p></caption><graphic xlink:href="EMS206953-f005"/></fig><fig id="F6" position="float"><label>Figure 6</label><caption><title>D6 training led to increased sensory embodiment.</title><p>(A) Following training, D6 participants showed an increase in phenomenological embodiment compared to controls. Participants only experienced positive embodiment in the somatosensory category (consisting of questions such as “it seems like I can distinguish between different textures with the robotic finger” and “it seems like I can feel the touch of an object in the location with the robotic finger is touching the object”). (B) Significant negative correlation between decreases in cross-nobis distance (increased similarity) and increases in somatosensory embodiment scores (increased embodiment) D6 training, (C) Non-significant correlation between changes in cross-nobis distance and somatosensory embodiment for the Keyboard training control group. * denotes p &lt; .05.</p></caption><graphic xlink:href="EMS206953-f006"/></fig></floats-group></article>