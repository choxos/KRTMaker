<!DOCTYPE article
 PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="preprint"><?all-math-mml yes?><?use-mml?><?origin ukpmcpa?><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-title-group><journal-title>bioRxiv : the preprint server for biology</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn></journal-meta><article-meta><article-id pub-id-type="manuscript">EMS205733</article-id><article-id pub-id-type="doi">10.1101/2025.05.16.654560</article-id><article-id pub-id-type="archive">PPR1023197</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">1</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>GEM-pRF: GPU-Empowered Mapping of Population Receptive Fields for Large-Scale fMRI Analysis</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Mittal</surname><given-names>Siddharth</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Woletz</surname><given-names>Michael</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Linhardt</surname><given-names>David</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Windischberger</surname><given-names>Christian</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib></contrib-group><aff id="A1"><label>1</label>High Field MR Center, Center for Medical Physics and Biomedical Engineering, <institution-wrap><institution-id institution-id-type="ror">https://ror.org/05n3x4p02</institution-id><institution>Medical University of Vienna</institution></institution-wrap>, <country country="AT">Austria</country></aff><pub-date pub-type="nihms-submitted"><day>22</day><month>05</month><year>2025</year></pub-date><pub-date pub-type="preprint"><day>21</day><month>05</month><year>2025</year></pub-date><permissions><ali:free_to_read/><license><ali:license_ref>https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0 International license</ext-link>.</license-p></license></permissions><abstract><p id="P1">Population receptive field (pRF) mapping is a fundamental technique for understanding retinotopic organization of the human visual system. Since its introduction in 2008, however, its scalability has been severely hindered by the computational bottleneck of iterative parameter refinement. Current state-of-the-art implementations either sacrifice precision for speed or rely on slow iterative parameter updates, limiting their applicability to large-scale datasets. Here, we present a novel mathematical reformulation of the General Linear Model (GLM), wrapped in a GPU-Empowered Mapping of population Receptive Fields (GEM-pRF) software implementation. By orthogonalizing the design matrix, our approach enables the direct and fast computation of the objective function‚Äôs derivatives, which are used to eliminate the iterative refinement process. This approach dramatically accelerates pRF estimation while maintaining full accuracy. Validation using empirical and simulated data confirms GEM-pRF‚Äôs accuracy, and benchmarking against established tools demonstrates an order-of-magnitude reduction in computation time. With its modular and extensible design, GEM-pRF provides a critical advancement for large-scale fMRI retinotopic mapping. Furthermore, our reformulated GLM approach in combination with GPU-based implementation offer a broadly applicable solution that may extend beyond visual neuroscience, accelerating computational modelling across various domains in neuroimaging and beyond.</p></abstract><kwd-group><kwd>Retinotopy</kwd><kwd>Population receptive fields</kwd><kwd>fMRI</kwd><kwd>General Linear Model</kwd><kwd>GPU-empowered pRF mapping</kwd></kwd-group></article-meta></front><body><sec id="S1" sec-type="intro"><label>1</label><title>Introduction</title><p id="P2">Within neuroscience, the research domain of retinotopic mapping is dedicated to unravelling the relationship between the visual field and the visual cortex. Since early observations in the 1900s suggested a direct mapping between the visual field and visual cortex (<xref ref-type="bibr" rid="R21">Holmes, 1918</xref>; <xref ref-type="bibr" rid="R42">Tatsuji, 1909</xref>), many researchers have engaged in the development of techniques for assessing the retinotopic features of the visual system (for a review see (<xref ref-type="bibr" rid="R44">Wandell &amp; Winawer, 2011</xref>)). Notably, functional magnetic resonance imaging (fMRI)-based techniques have become pivotal for non-invasive retinotopic experiments based on travelling waves stimuli (<xref ref-type="bibr" rid="R9">DeYoe et al., 1994</xref>; <xref ref-type="bibr" rid="R12">Engel et al., 1994</xref>). Numerous studies have established a functional topographic mapping of the human visual system using Positron-Emission Tomography (PET) (<xref ref-type="bibr" rid="R13">Fox et al., 1987</xref>; <xref ref-type="bibr" rid="R46">Zeki et al., 1991</xref>) and fMRI (<xref ref-type="bibr" rid="R38">Schneider et al., 1993</xref>). In particular, (<xref ref-type="bibr" rid="R40">Sereno et al., 1995</xref>) proposed mapping the retinotopic organization of multiple visual areas on the cortical surface based on phase information in fMRI data using periodic visual stimulation. Taking into consideration the eccentricities and polar angles of the corresponding receptive fields, they were able to functionally segment visual area regions such as V1, V2, VP, V3, and V4.</p><p id="P3">At the beginning of the twenty-first century, a new mathematical model for retinotopic analysis was proposed, referred to as population receptive field (pRF) mapping (<xref ref-type="bibr" rid="R10">Dumoulin &amp; Wandell, 2008</xref>). Unlike previous methods, this approach is no longer limited to periodic stimulus designs and thus allows the use of arbitrary visual stimuli.</p><p id="P4">Numerous studies have used the pRF approach for visual field mapping (<xref ref-type="bibr" rid="R3">Benson et al., 2022</xref>; <xref ref-type="bibr" rid="R5">Bridge et al., 2023</xref>; <xref ref-type="bibr" rid="R11">Elul &amp; Levin, 2024</xref>; <xref ref-type="bibr" rid="R16">Groen et al., 2022</xref>). In addition, applications in healthy participants with simulated visual field deficits (<xref ref-type="bibr" rid="R17">Haak et al., 2012</xref>; <xref ref-type="bibr" rid="R22">Hummer et al., 2018</xref>; <xref ref-type="bibr" rid="R25">Linhardt et al., 2022</xref>) and in clinical populations have demonstrated the potential of pRF mapping for staging retinal pathologies and tracking retinal disease progression (<xref ref-type="bibr" rid="R30">Molz et al., 2023</xref>; <xref ref-type="bibr" rid="R33">Prabhakaran et al., 2021</xref>; <xref ref-type="bibr" rid="R36">Ritter et al., 2019</xref>, <xref ref-type="bibr" rid="R37">2024</xref>). These studies collectively enhance our understanding of visual field mapping in both simulated and actual vision loss. Another application of retinotopic mapping is the decoding of visual information, which is crucial for developing brain-computer interface (BCI) devices. These devices could one day reliably reconstruct cortical activity to the visual field, from reconstructing perceived or imagined letters (<xref ref-type="bibr" rid="R39">Senden et al., 2019</xref>) to complex visual scenes (<xref ref-type="bibr" rid="R41">Takagi &amp; Nishimoto, 2023</xref>).</p><p id="P5">As pRF applications evolve, algorithms are needed that can provide swift retinotopic estimation results from even larger datasets. In the current implementations, pRF mapping techniques involve computing predicted time courses for each pRF position in the visual field. These time courses ultimately depend on the visual stimulus used in the experiment and the chosen pRF model, such as the isotropic 2D Gaussian (<xref ref-type="bibr" rid="R10">Dumoulin &amp; Wandell, 2008</xref>) or the difference of Gaussians (<xref ref-type="bibr" rid="R47">Zuiderbaan et al., 2012</xref>). The algorithm then identifies the best-fit model signal for the measured fMRI time course in every voxel to estimate the pRF parameters spatial position (¬µ<sub>x</sub>, ¬µ<sub>y</sub>) and other chosen model‚Äôs parameters (such as size (œÉ) in case of 2D isotropic Gaussian model). This fitting procedure uses optimization algorithms to minimize the difference between the predicted and measured fMRI time courses. It typically involves a two-stage process where initial coarse fitting is followed by refined fitting. Notably, the refined fitting procedure is commonly built as an iterative, computationally demanding optimization process.</p><p id="P6">Several implementations for such pRF mapping-based approaches are currently used by researchers such as mrVista (<xref ref-type="bibr" rid="R10">Dumoulin &amp; Wandell, 2008</xref>) and SamSrf (<xref ref-type="bibr" rid="R7">D. Sam Schwarzkopf, 2018</xref>). These tools perform all computations on the CPU. There are other pRF mapping implementations such as DeepRF (<xref ref-type="bibr" rid="R43">Thielen et al., 2019</xref>), fast-pRF (<xref ref-type="bibr" rid="R4">Bhat et al., 2021</xref>) and qPRF (<xref ref-type="bibr" rid="R45">Waz et al., 2025</xref>), which specifically aim to minimise computational times. The DeepRF method is a deep learning-based approach and requires model training to predict the pRF parameters estimation for the measured fMRI data. Training the deep learning model for the DeepRF approach takes several hours and each specific experiment setup requires a model trained with the same setup. Given the long training time and the necessity for identical experimental setups between test and training data, this pRF mapping implementation might not be optimal for scenarios requiring frequent configuration changes. On the other hand, the fast-pRF method makes the pRF mapping procedure extremely fast on the CPU, however, it suffers from a loss in fitting precision. Therefore, it is only suitable for applications where accuracy can be sacrificed in favour of faster execution times, as e.g. real-time applications. Lastly, the qPRF method uses a searchable similarity-based tree to refine pRF parameters efficiently. By storing neighbor relationships, it enables rapid refinement. However, tree construction takes several hours, which may be a consideration for studies requiring frequent reconfiguration, such as comparative analyses with varying stimuli.</p><p id="P7">Considering the currently available toolboxes, we have identified a gap in pRF mapping implementations for applications that require highly accurate estimations combined with minimal computation times. To address this gap, we developed a novel pRF analysis software from scratch that (1) takes full advantage of the computational capabilities of current Graphics Processing Units (GPUs) and (2) optimises the mathematical procedure for time course fitting by reformulating the algorithm.</p><p id="P8">The utilisation of GPUs began in the late 1990s but was mostly limited to graphics applications. Their usage for high-performance computing in the framework of General-Purpose GPU (GPGPU) programming emerged with the introduction of the Compute Unified Device Architecture (CUDA) libraries, released in the mid-2000s. This marked a substantial milestone in facilitating GPGPU programming and sparked widespread adoption of the use of GPGPU hardware. Since then, numerous research fields have benefited from the unique computational capabilities of GPU accelerated software (<xref ref-type="bibr" rid="R8">Dally et al., 2021</xref>; <xref ref-type="bibr" rid="R28">Mi≈°iƒá et al., 2012</xref>), particularly in machine learning (<xref ref-type="bibr" rid="R43">Thielen et al., 2019</xref>).</p><p id="P9">For pRF analysis, however, the most commonly used software packages do not take full advantage of the computational power provided by GPUs. This is partly because the mathematics involved in pRF mapping are not easily transferred to the parallel processing paradigm of GPUs. Typically, the fMRI data processing steps utilise a general multivariate regression model, also known as General Linear Model (GLM) (<xref ref-type="bibr" rid="R32">Poline &amp; Brett, 2012</xref>). In the case of pRF mapping, as proposed by (<xref ref-type="bibr" rid="R10">Dumoulin &amp; Wandell, 2008</xref>), the application of GLM is required in both coarse as well as refine-fitting steps. However, during the refine-fitting process, the GLM needs to be applied iteratively to find the pRF parameter estimations. These requirements have made it challenging to implement a GPU-based pRF analysis application as GPUs are best suited for applications involving Single Instruction, Multiple Data (SIMD) processing.</p><p id="P10">In this study, we propose a novel implementation of pRF analysis based on a modified linear regression method, which can organise the data operations to follow a SIMD pattern. Our approach of GPU-Empowered Mapping of pRF (GEM-pRF) is encapsulated within a Python-based software package using CUDA libraries. To optimise efficiency and enable easy exploration of various setups, our methodology specifically employs the CuPy package- an open-source Python wrapper for CUDA (<xref ref-type="bibr" rid="R31">Okuta et al., 2017</xref>). Specifically designed for GPU operations, it follows NumPy‚Äôs API structure and includes the CUDA C++ runtime library NVRTC (<xref ref-type="bibr" rid="R34">Raschka et al., 2020</xref>), providing a Python API for compiling and executing CUDA kernels at runtime. This key feature enables the integration of native CUDA kernels (implemented in C/C++) to accommodate diverse pRF modelling approaches. We demonstrate the accuracy and applicability of GEM-pRF on both simulated and empirical data to show how GEM-pRF enables high-accuracy pRF analyses with greatly reduced processing time.</p></sec><sec id="S2" sec-type="methods"><label>2</label><title>Methods</title><sec id="S3"><label>2.1</label><title>pRF modelling and fitting</title><p id="P11">The general idea behind pRF mapping is to compute expected time courses for the BOLD (blood-oxygen-level-dependent) signal based on a pRF model, a stimulus aperture, and a hemodynamic response function (HRF). The stimulus data depends on the experimental paradigm and must be provided as input for the analysis. As the HRF reflects a neurophysiological phenomenon, it varies between subjects. While some software implementations allow the computation of a subject-specific HRF, our software is designed to use either user-defined HRF values or a standard HRF as input. Consequently, while the stimulus and the HRF are typically assumed constant across voxels for a given experiment and subject, the pRF model depends on several parameters that must be estimated on a voxel-by-voxel basis. Following a similar methodology to the pRF fitting procedure outlined by (<xref ref-type="bibr" rid="R10">Dumoulin &amp; Wandell, 2008</xref>), our implementation adopts a coarse-to-fine fitting strategy to estimate the pRF parameters for each measured fMRI time course. However, our approach introduces a novel streamlined linear regression method, optimised for high performance through GPU acceleration.</p><p id="P12">In classical pRF modeling, a pRF is represented as a function of spatial position in the visual field, denoted by <italic>¬µ</italic><sub><italic>x</italic></sub> and <italic>¬µ</italic><sub><italic>y</italic></sub>, which corresponds to the center coordinates of the receptive field. Additional parameters, such as the receptive field size œÉ, may also be included depending on the chosen pRF model. For instance, a commonly used model is based on a 2D Gaussian function, where œÉ defines the isotropic standard deviation of the Gaussian receptive field.</p><p id="P13">Mathematically, a pRF can be expressed as a function <italic>f</italic><sub><italic>ij</italic></sub>(<bold>Œ∏</bold>) that depends on a set of <italic>K</italic> parameters, where <bold>Œ∏</bold> ‚àà ‚Ñù<sup><italic>K</italic></sup>, while the indices <italic>i</italic> and <italic>j</italic> represent the spatial positions in the visual field. In this paper, we focus on the 2D Gaussian pRF model with <italic>K</italic> = 3 parameters, which leads to <bold>Œ∏</bold> = (<italic>¬µ</italic><sub><italic>x</italic></sub>, <italic>¬µ</italic><sub><italic>y</italic></sub>, <italic>œÉ</italic>). However, more complex models incorporating additional parameters can also be implemented in the GEM-pRF framework.</p><p id="P14">Another essential aspect in computing predicted time courses is the stimulus aperture, which determines the neuronal response patterns elicited during a pRF mapping experiment. The stimulus aperture can be mathematically defined as a three-dimensional matrix: <disp-formula id="FD1"><mml:math id="M1"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo>‚àà</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mrow><mml:mi>U</mml:mi><mml:mo>√ó</mml:mo><mml:mi>V</mml:mi><mml:mo>√ó</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula> where: <list list-type="bullet" id="L1"><list-item><p id="P15"><italic>U</italic> √ó <italic>V</italic> represents the spatial dimensions of the stimulus grid,</p></list-item><list-item><p id="P16"><italic>T</italic> is the number of time points in the experiment,</p></list-item><list-item><p id="P17">Each element of <bold>S</bold> takes a value between either 0 (no stimulus) or 1 (stimulus present).</p></list-item></list></p><p id="P18">When a visual stimulus appears at a particular location and time, it triggers neural responses. These responses are typically modeled using the HRF, denoted as <italic>h</italic>(<italic>t</italic>), which describes the linear response of the BOLD signal to a neural event. Given this, a pRF model time course <bold>p</bold>(<bold>Œ∏</bold>) corresponding to a particular parameter combination <bold>Œ∏</bold> can be computed as follows: <disp-formula id="FD2"><mml:math id="M2"><mml:mrow><mml:mrow><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>p</mml:mi></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>‚àó</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mi>‚àë</mml:mi><mml:mi>i</mml:mi><mml:mi>U</mml:mi></mml:munderover><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mi>‚àë</mml:mi><mml:mi>j</mml:mi><mml:mi>V</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mtext>s</mml:mtext><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p id="P19">However, considering the linearity of convolution operation, we can first convolve the given stimulus <bold>S</bold> with <italic>h</italic>(<italic>t</italic>) and then use the HRF-convolved stimulus <inline-formula><mml:math id="M3"><mml:mrow><mml:mover accent="true"><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi></mml:mstyle><mml:mo stretchy="true">Àú</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> version to compute the model time courses. This can be represented as: <disp-formula id="FD3"><label>(1)</label><mml:math id="M4"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mtext>S</mml:mtext><mml:mo stretchy="true">Àú</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>‚àó</mml:mo><mml:msub><mml:mtext>S</mml:mtext><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>p</mml:mi></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mi>‚àë</mml:mi><mml:mi>j</mml:mi><mml:mi>U</mml:mi></mml:munderover><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mi>‚àë</mml:mi><mml:mi>j</mml:mi><mml:mi>V</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>Àú</mml:mo></mml:mover></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p id="P20">For pRF mapping analysis, the general linear model (<xref ref-type="bibr" rid="R14">Friston et al., 1995</xref>) is used. This model uses linear least squares optimization with a design matrix including effects of interest and additional confounds to model the task-based BOLD effect. The design matrix <bold>X</bold>, with a model time course <bold>p</bold>(<bold>Œ∏</bold>) (i.e. p(<bold>Œ∏</bold>, t) from <xref ref-type="disp-formula" rid="FD3">equation (1)</xref>) for a particular modelling parameter combination <bold>Œ∏</bold>, and the additional regressor matrix <bold>R</bold> can therefore be represented as: <disp-formula id="FD4"><label>(2)</label><mml:math id="M5"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>X</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>p</mml:mi></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mspace width="1em"/><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>R</mml:mi></mml:mstyle></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p id="P21">The regressor matrix <bold>R</bold> may contain different nuisance regressors and low-frequency functions, but, for the purpose of this work, must at least contain a constant term. Based on ordinary least square fitting, the residuals <bold>√™</bold> between a measured time course <bold>y</bold> and a prediction <bold>≈∑</bold> can be represented as: <disp-formula id="FD5"><label>(3)</label><mml:math id="M6"><mml:mrow><mml:mover accent="true"><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>e</mml:mi></mml:mstyle><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>I</mml:mi></mml:mstyle><mml:mo>‚àí</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>X</mml:mi></mml:mstyle><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>X</mml:mi></mml:mstyle><mml:mtext>T</mml:mtext></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>X</mml:mi></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>‚àí</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mn>1</mml:mn></mml:mstyle></mml:mrow></mml:msup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>X</mml:mi></mml:mstyle><mml:mtext mathvariant="bold">T</mml:mtext></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle></mml:mrow></mml:math></disp-formula> where <bold>I</bold> represents an identity matrix.</p><p id="P22">Since the prediction is invariant with respect to a change of basis in the column space of the design matrix, we can replace the design matrix with an orthonormal version. We are assuming the regressor matrix <bold>R</bold> to be already orthogonalized (e.g. by using Gram-Schmidt or QR decomposition) and then explicitly orthogonalizing each pRF model time course <bold>p</bold>(<bold>Œ∏</bold>) with respect to <bold>R</bold>. The result is then normalised and denoted as <bold>p</bold>‚Ä≤(<bold>Œ∏</bold>), which represents a prediction time course. This results in an orthonormalized regressor matrix <bold>X</bold>‚Ä≤, given as: <disp-formula id="FD6"><label>(4)</label><mml:math id="M7"><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>X</mml:mi></mml:mstyle><mml:mo>‚Ä≤</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>p</mml:mi></mml:mstyle><mml:mo>‚Ä≤</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Œ∏</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mspace width="1em"/><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>R</mml:mi></mml:mstyle></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p id="P23">Upon substituting the modified regressor matrix <bold>X'</bold> in the equation (3) for residual errors, and solving it for the residual sum of squares (RSS), we obtain: <disp-formula id="FD7"><label>(5)</label><mml:math id="M8"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>e</mml:mi></mml:mstyle><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mtext mathvariant="bold">T</mml:mtext></mml:msup><mml:mover accent="true"><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>e</mml:mi></mml:mstyle><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mtext mathvariant="bold">T</mml:mtext></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>‚àí</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mtext mathvariant="bold">T</mml:mtext></mml:msup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>p</mml:mi></mml:mstyle><mml:mo>‚Ä≤</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">Œ∏</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>p</mml:mi></mml:mstyle><mml:mo>‚Ä≤</mml:mo></mml:msup><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">Œ∏</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mtext mathvariant="bold">T</mml:mtext></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>‚àí</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mtext mathvariant="bold">T</mml:mtext></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>R</mml:mi></mml:mstyle><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>R</mml:mi></mml:mstyle><mml:mtext mathvariant="bold">T</mml:mtext></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mtext mathvariant="bold">T</mml:mtext></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>‚àí</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mtext mathvariant="bold">T</mml:mtext></mml:msup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>p</mml:mi></mml:mstyle><mml:mo>‚Ä≤</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">Œ∏</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>‚àí</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mtext mathvariant="bold">T</mml:mtext></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>R</mml:mi></mml:mstyle><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>R</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p id="P24">In pRF mapping, the ultimate goal is to compute the parameter <bold>Œ∏</bold> that minimises the residual sum of squares (RSS). Upon careful examination of the new RSS equation (5), it becomes evident that both <bold>y</bold><sup><bold><italic>T</italic></bold></sup><bold>y</bold> and <bold>y</bold><sup><bold><italic>T</italic></bold></sup><bold>RR</bold><sup><bold><italic>T</italic></bold></sup><bold>y</bold> are independent of any modelling parameters <bold>Œ∏</bold>. Therefore, the RSS is dependent on a prediction time course solely through the term (<bold>y</bold><sup><bold><italic>T</italic></bold></sup><bold>p</bold>‚Ä≤(<bold>Œ∏</bold>) <sup><bold>2</bold></sup>.</p><p id="P25">Since (<bold>y</bold><sup><bold><italic>T</italic></bold></sup><bold>p</bold>‚Ä≤(<bold>Œ∏</bold>))<sup><bold>2</bold></sup> directly affects the RSS, maximizing this value corresponds to finding the prediction time course that minimizes the residual error. This term represents the square of the dot product between <bold>y</bold> and <bold>p</bold>‚Ä≤(<bold>Œ∏</bold>), and its value is maximized when both the time courses are either correlated or anti-correlated. In the case of anti-correlation, the dot product would yield negative values.</p><p id="P26">However, the goal is to find a prediction time course <bold>p</bold>‚Ä≤(<bold>Œ∏</bold>) that correlates highly with the fMRI time course <bold>y</bold> (indicating a strong positive correlation). Thus, to focus on maximizing the correlation (and avoiding negative values due to anti-correlation), we can safely drop the square. With this observation, we can define the objective function ùíû(<bold>Œ∏</bold>) as the dot product between <bold>y</bold> and the prediction time course <bold>p</bold>‚Ä≤(<bold>Œ∏</bold>), as shown below: <disp-formula id="FD8"><label>(6)</label><mml:math id="M9"><mml:mrow><mml:mi mathvariant="script">C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">Œ∏</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>p</mml:mi></mml:mstyle><mml:mo>‚Ä≤</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p id="P27">With the above-defined objective function, the coarse fitting step tries to maximize the objective function value. <disp-formula id="FD9"><label>(7)</label><mml:math id="M10"><mml:mrow><mml:mover accent="true"><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>arg</mml:mi><mml:munder><mml:mrow><mml:mi>max</mml:mi></mml:mrow><mml:mo mathvariant="bold">Œ∏</mml:mo></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>p</mml:mi></mml:mstyle><mml:mo>‚Ä≤</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><sec id="S4"><label>2.1.1</label><title>Coarse fitting</title><p id="P28">The above reformulation of the objective function (<xref ref-type="disp-formula" rid="FD8">equation (6)</xref>) especially simplifies the process of determining the best-fitting parameter combination from a given set of parameter combinations. This is crucial for determining an initial combination in the vicinity of the global optimum, here denoted as coarse fitting, which is then refined in a subsequent optimisation routine.</p><p id="P29">Given a set <bold>Œò</bold> of <italic>N</italic> parameter combinations <bold>Œ∏</bold>, the best fitting parameter coarse parameter combination <inline-formula><mml:math id="M11"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mtext>c</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula> for a measured time course <bold>y</bold> in the coarse fitting step is therefore: <disp-formula id="FD10"><label>(8)</label><mml:math id="M12"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mtext>c</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mi>arg</mml:mi><mml:munder><mml:mrow><mml:mi>max</mml:mi></mml:mrow><mml:mo mathvariant="bold">Œ∏</mml:mo></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>p</mml:mi></mml:mstyle><mml:mo>‚Ä≤</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo>‚àà</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>Œò</mml:mi></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p id="P30">This can be efficiently implemented on a GPU, or in other parallelized systems, by constructing matrices from the prediction, as well as the measured time courses and performing a matrix multiplication, followed by an argmax operation. In GEM-pRF, this is implemented on the GPU using custom CUDA kernels in C/C++ alongside Python‚Äôs CuPy library.</p><p id="P31">It is worth noting that similar to the pRF mapping method proposed by (<xref ref-type="bibr" rid="R10">Dumoulin &amp; Wandell, 2008</xref>), our method also uses a linear least square approach. However, our proposed method of using an orthogonalized design matrix eliminates the need for computing beta weights explicitly. This effectively reduces the computational load and enables the explicit computation of derivatives of the RSS objective function which is used for improving the initial coarse-fitting solution.</p></sec><sec id="S5"><label>2.1.2</label><title>Refine fitting</title><p id="P32">After the initial coarse fitting, where the optimal pRF parameters are selected from a discrete sampling space <bold>Œò</bold>, a fine-fitting step is performed to refine these estimates. Given a sufficiently dense sampling space <bold>Œò</bold> and a smooth objective function ùíû(<bold>Œ∏</bold>), the global maximum is expected to be in the vicinity of the coarse-fit solution. In our implementation, the refinement step efficiently determines this maximum without requiring iterative optimization.</p><sec id="S6"><title>Quadratic Approximation for Refinement</title><p id="P33">Traditional pRF mapping methods are based on iterative refinement of coarse estimates for each measured fMRI signal <bold>y</bold>, which is computationally expensive. Instead, GEM-pRF takes advantage of prediction time courses and their derivatives available on GPU side to compute the derivatives of the objective function directly, thus reducing overall computation times. This enables a non-iterative refinement based on a quadratic approximation of the residual sum of squares (RSS) values in the local neighbourhood of the coarse-fit parameters as illustrated in <xref ref-type="fig" rid="F2">Figure 2</xref>.</p><p id="P34">Denoting the estimated coarse-fit parameters as <inline-formula><mml:math id="M13"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mtext>c</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>, we consider the objective function values in their local neighborhood <bold>Œò</bold><sub><italic>N</italic></sub> <italic>‚äÜ</italic> <bold>Œò</bold>. Here, <italic>N</italic> represents the set of neighbours around <inline-formula><mml:math id="M14"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mtext>c</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula> in the multidimensional discrete sampling space <bold>Œò</bold>. These objective function values can be approximated using a multidimensional quadratic function: <disp-formula id="FD11"><label>(9)</label><mml:math id="M15"><mml:mrow><mml:mi mathvariant="script">C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>‚âà</mml:mo><mml:mi>Œµ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mi>T</mml:mi></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mtext>A</mml:mtext></mml:mstyle><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>b</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo>+</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:math></disp-formula> where: <list list-type="bullet" id="L2"><list-item><p id="P35"><bold>A</bold> is a symmetric square matrix</p></list-item><list-item><p id="P36"><bold>b</bold> is a vector,</p></list-item><list-item><p id="P37"><italic>c</italic> is a scalar value.</p></list-item></list></p><p id="P38"><bold>A, b</bold> and <italic>c</italic> coefficients in the above <xref ref-type="disp-formula" rid="FD11">equation (9)</xref> are estimated using a linear least-squares fit to the function values ùíû(<bold>Œ∏</bold>) and their partial derivatives in the neighborhood of <inline-formula><mml:math id="M16"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mtext>c</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula> for each parameter combination <bold>Œ∏</bold> using, <disp-formula id="FD12"><label>(10)</label><mml:math id="M17"><mml:mrow><mml:mfrac><mml:mrow><mml:mo>‚àÇ</mml:mo><mml:mi mathvariant="script">C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>‚àÇ</mml:mo><mml:msub><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mfrac><mml:mrow><mml:mo>‚àÇ</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>p</mml:mi></mml:mstyle><mml:mo>‚Ä≤</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>‚àÇ</mml:mo><mml:msub><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p id="P39">The first-order derivative of <italic>Œµ</italic> from <xref ref-type="disp-formula" rid="FD11">equation (9)</xref> with respect to <bold>Œ∏</bold> is given by: <disp-formula id="FD13"><label>(11)</label><mml:math id="M18"><mml:mrow><mml:mo>‚àá</mml:mo><mml:mtext>Œµ</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo>+</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>b</mml:mi></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p id="P40">And by equating the above <xref ref-type="disp-formula" rid="FD13">equation (11)</xref> to zero (i.e. ‚àáŒµ(<bold>Œ∏</bold>) = 0), we obtain the following equation that can be solved to obtain refined-fitting parameters <inline-formula><mml:math id="M19"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mtext mathvariant="bold-italic">r</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>: <disp-formula id="FD14"><label>(12)</label><mml:math id="M20"><mml:mrow><mml:mn>2</mml:mn><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi mathvariant="bold">A</mml:mi></mml:mstyle><mml:msub><mml:mrow><mml:mover accent="true"><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mtext mathvariant="bold-italic">r</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mo>‚àí</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>b</mml:mi></mml:mstyle></mml:mrow></mml:math></disp-formula>
</p><p id="P41">This refined solution <inline-formula><mml:math id="M21"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mtext mathvariant="bold-italic">r</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula> is accepted if its function value <inline-formula><mml:math id="M22"><mml:mrow><mml:mi mathvariant="script">C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mtext mathvariant="bold-italic">r</mml:mtext></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (from <xref ref-type="disp-formula" rid="FD8">equation (6)</xref>) is greater than that at the coarse-fit estimate <inline-formula><mml:math id="M23"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mtext>c</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>.</p><p id="P42">Refinement relies only on a local neighbourhood, and the neighbours for each pRF parameter remain static. As a result, the neighbours and their corresponding design matrix for quadratic approximation are either precomputed or can be computed in parallel with the prediction signal computation. Furthermore, the neighbourhood data consists of only a few values, depending on the selected pRF modelling approach. This allows for quick processing on the CPU. Therefore, our overall refined fitting step efficiently takes place on the CPU side, as illustrated in <xref ref-type="fig" rid="F1">Figure 1</xref>.</p><p id="P43">By employing this non-iterative, quadratic approximation approach, GEM-pRF significantly reduces computation time while maintaining accurate parameter estimations.</p></sec></sec><sec id="S7"><label>2.1.3</label><title>Variance explained</title><p id="P44">Similar to the original pRF mapping procedure proposed by (<xref ref-type="bibr" rid="R10">Dumoulin &amp; Wandell, 2008</xref>), we incorporate a goodness-of-fit criterion to assess the quality of our predictions. This criterion quantifies how a prediction time series, generated using refined estimations of pRF parameters, aligns with a given measured fMRI time course, where all nuisance regressors were already removed. For this, we can compute the nuisance regressed time course <bold>y</bold><sup>‚àó</sup> by using the equation, <disp-formula id="FD15"><label>(13)</label><mml:math id="M24"><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>‚àó</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>I</mml:mi></mml:mstyle><mml:mo>‚àí</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>R</mml:mi></mml:mstyle><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>R</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle></mml:mrow></mml:math></disp-formula> to compute the variance explained <italic>œÅ</italic><sup>2</sup> as our measure of goodness-of-fit, calculated using the equation: <disp-formula id="FD16"><label>(14)</label><mml:math id="M25"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mi>œÅ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>‚àí</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:mtext mathvariant="bold">e</mml:mtext><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mover accent="true"><mml:mtext mathvariant="bold">e</mml:mtext><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi mathvariant="bold">y</mml:mi></mml:mstyle><mml:mrow><mml:mo>‚àó</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi mathvariant="bold">y</mml:mi></mml:mstyle><mml:mo>‚àó</mml:mo></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>‚àí</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi mathvariant="bold">y</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi mathvariant="bold">y</mml:mi></mml:mstyle></mml:mrow><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi mathvariant="bold">y</mml:mi></mml:mstyle><mml:mrow><mml:mo>‚àó</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi mathvariant="bold">y</mml:mi></mml:mstyle><mml:mo>‚àó</mml:mo></mml:msup></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>Œµ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi mathvariant="bold">y</mml:mi></mml:mstyle><mml:mrow><mml:mo>‚àó</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi mathvariant="bold">y</mml:mi></mml:mstyle><mml:mo>‚àó</mml:mo></mml:msup></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi mathvariant="bold">y</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>R</mml:mi></mml:mstyle><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>R</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi mathvariant="bold">y</mml:mi></mml:mstyle></mml:mrow><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi mathvariant="bold">y</mml:mi></mml:mstyle><mml:mrow><mml:mo>‚àó</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi mathvariant="bold">y</mml:mi></mml:mstyle><mml:mo>‚àó</mml:mo></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p></sec></sec><sec id="S8"><label>2.2</label><title>Multiple runs</title><p id="P45">The GEM-pRF implementation uses an approach equivalent to averaging for the joint analysis of multiple runs. To derive results for multiple runs, we continue to use our reformulated linear regression approach and extend it to the sum of the vector projections of the measured signals against the modelled signals for individual runs. Our approach can also jointly analyze the runs that are measured with different stimulus paradigms. For instance, if <italic>M</italic> numbers of distinct runs need to be jointly analysed, and <inline-formula><mml:math id="M26"><mml:mrow><mml:msubsup><mml:mtext mathvariant="bold">p</mml:mtext><mml:mi>m</mml:mi><mml:mo>/</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mtext mathvariant="bold">y</mml:mtext><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> denote the orthonormal time courses and the measured fMRI time course for the <italic>m</italic>-th run respectively, then the pRF parameters for the joint analysis are obtained by identifying the parameter combination <bold>Œ∏</bold> that maximises the sum of the products <inline-formula><mml:math id="M27"><mml:mrow><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mi>m</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>p</mml:mi></mml:mstyle><mml:mi>m</mml:mi><mml:mo>‚Ä≤</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> overall <italic>m</italic> with the objective function <disp-formula id="FD17"><label>(15)</label><mml:math id="M28"><mml:mrow><mml:mi mathvariant="script">C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mstyle displaystyle="true"><mml:mi>‚àë</mml:mi></mml:mstyle></mml:mrow><mml:mi>m</mml:mi></mml:munder><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mi>m</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>p</mml:mi></mml:mstyle><mml:mi>m</mml:mi><mml:mo>‚Ä≤</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mo mathvariant="bold">Œ∏</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p></sec><sec id="S9"><label>2.3</label><title>Sampling space</title><p id="P46">As mentioned above, the coarse-fitting step involves the definition of a parameter set <bold>Œò</bold>, which is used both for the coarse and the refined fitting process. Therefore, it is of utmost importance to choose a dense sampling for the pRF model‚Äôs parameters to create a set of representative parameter combinations. In the case of a 2D Gaussian pRF mode, the three parameters are the pRF spatial position <italic>¬µ</italic><sub><italic>x</italic></sub>, <italic>¬µ</italic><sub><italic>y</italic></sub> and size <italic>œÉ</italic>. While in its simplest form the combination of these spatial parameters can be formed by defining a uniform grid, some studies may employ more complex spatial distributions of the pRFs, such as hexagonal, circular, or other intricate shapes. The GEM-pRF program therefore provides the possibility to use complex distributions of the spatial parameters (<italic>¬µ</italic><sub><italic>x</italic></sub> and <italic>¬µ</italic><sub><italic>y</italic></sub>). Such custom spatial distributions can be provided as an input parameter. These combinations are then duplicated in other dimensions to generate the prediction time courses with all parameter combinations. Currently, for the isotropic 2D Gaussian model for pRF mapping, the default sampling space configuration of GEM-pRF is 151x151x16, corresponding to the parameters <italic>¬µ</italic><sub><italic>x</italic></sub>, <italic>¬µ</italic><sub><italic>y</italic></sub> and <italic>œÉ</italic>. Notably, the sampling space extends beyond the actually stimulated visual field. For instance, if the experimental stimulus aperture has a radius of 9¬∞, the sampling space is defined for an extended visual field of 13.5¬∞.</p></sec><sec id="S10"><label>2.5</label><title>Data transfer considerations</title><p id="P47">The total number of model signals depends upon the defined pRF sampling space and commonly spans several thousand, entailing memory necessities ranging from several hundred megabytes to a few gigabytes (with 64-bit precision). To process the data on the GPU (referred to as device), the data must be present on the device. Such transfers of data from the CPU (referred to as the host) to the GPU device and vice-versa are predominantly facilitated by the Peripheral Component Interconnect-Express (PCIe) high-speed bus standard (<xref ref-type="bibr" rid="R15">Gorelick &amp; Ozsvald, 2020</xref>), especially on the low-end consumer computing systems. The bandwidth provided by PCIe is critical for the performance of GPUs, especially in scenarios where large amounts of data need to be transferred between the CPU and GPU. Therefore, GEM-pRF tries to minimise such transfers, for example, the model signals are directly computed on the GPU side and kept there until the analysis finishes. <xref ref-type="fig" rid="F1">Figure 1</xref> provides an overview of various computation steps and the requirement of data availability on either the CPU or GPU side.</p></sec><sec id="S11"><label>2.6</label><title>Multi-GPU environment</title><p id="P48">In a multi-GPU environment, GEM-pRF distributes the various computationally expensive and GPU memory-demanding execution steps onto different GPUs. This capability makes it possible to run the pRF analysis with a much larger number of model signals and therefore specifying denser pRF sampling space. For a multi-GPU cluster, the GPUs that are available for processing can be specified so that the program can automatically distribute memory requirements uniformly on all the specified GPUs. Therefore, all specified GPUs must have enough memory available for processing.</p></sec><sec id="S12"><label>2.7</label><title>Data</title><p id="P49">To evaluate the results of pRF parameter estimation obtained using GEM-pRF, we employed both simulated and empirical data. For assessing computational time, we furthermore utilised a public dataset acquired at 7T and a locally acquired dataset on 3T scanner.</p><sec id="S13"><label>2.7.1</label><title>Simulated data</title><p id="P50">Simulated fMRI time series data was generated using the prfsynth docker image (version d9b64480cf1e) provided by a publicly available validation framework (<xref ref-type="bibr" rid="R23">Lerma-Usabiaga et al., 2020</xref>). To assess the accuracy of our implementation, we generated simulated fMRI time courses for three spatial locations (P, Q, and R) in the visual field. As shown in <xref ref-type="fig" rid="F3">Figure 3(a)</xref>, the parameters for the simulated pRF were set as follows: (<italic>¬µ</italic><sub><italic>x</italic></sub> = 0, <italic>¬µ</italic><sub><italic>y</italic></sub> = 0, <italic>œÉ</italic> = 1) for location P, (<italic>¬µ</italic><sub><italic>x</italic></sub> = 3, <italic>¬µ</italic><sub><italic>y</italic></sub> = 3, <italic>œÉ</italic> = 1) for location Q, and (<italic>¬µ</italic><sub><italic>x</italic></sub> = 6, <italic>¬µ</italic><sub><italic>y</italic></sub> = 6, <italic>œÉ</italic> = 1) for location R. The stimulus is considered to be extending from -10 to +10 degree visual angle. The pRF positions are chosen at different eccentricities to assess the accuracy of pRF parameter estimations between the fixation centre and the periphery close to the stimulation border. The simulated data was generated at two different white Gaussian noise levels to evaluate the accuracy and robustness of our implementation. These noise levels were specified in the configuration file provided by the validation framework for the prfsynth docker image. In the low-noise condition, the data achieved an average variance explained value of 88%, while in the high-noise condition, the average variance explained was 47%. Using the validation framework (<xref ref-type="bibr" rid="R23">Lerma-Usabiaga et al., 2020</xref>), we generated 5000 simulated time courses for each position. The average estimated position and pRF size were calculated by averaging the estimation results from all 5,000 simulations. However, for clearer visualization of the distribution of the results, the panels (c) and (d) in <xref ref-type="fig" rid="F3">Figure 3</xref> only displays 50 randomly selected individual estimations for each case, represented by grey circles.</p><p id="P51">To compute the pRF parameter estimation using GEM-pRF, we sampled the visual field across 151x151 spatial positions, spanning from -15.0 to +15.0 degrees, and duplicated these positions for 16 different pRF sizes linearly ranging from 0.1 to 5. This resulted in a total of 151x151x16 predicted time courses. And, to compare our estimation results with those of mrVista, we computed the mrVista pRF parameter estimations using the prfanalyze-vista Docker container (version 2.3.1_3.1.2) by (<xref ref-type="bibr" rid="R23">Lerma-Usabiaga et al., 2020</xref>), with its default configuration. This container is publicly available at GitHub (github.com/vistalab/prfmodel).</p></sec><sec id="S14"><label>2.7.2</label><title>Empirical data</title><p id="P52">For evaluation with empirical data, a healthy participant (25 yrs, female) was measured in a single session and 5 pRF runs were acquired using a 64-channel head coil on a 3T PrismaFit scanner (Siemens Healthineers, Erlangen, Germany). The study framework was approved by the local ethics board and adhered to the Helsinki Declaration. The full coil was used for anatomical measurements, while for the functional measurement, only the head coil‚Äôs lower part was used. Functional data was acquired using the CMRR EPI sequence (<xref ref-type="bibr" rid="R29">Moeller et al., 2010</xref>) with a spatial resolution of 1.5 mm isotropic and the following parameters: TE = 38 ms, TR = 1000 ms, multiband factor = 3, partial Fourier = 6/7, matrix size = 80x80, field of view (FoV) = 120x120 mm, phase encoding direction = left to right, flip angle = 55¬∞, and slice spacing = 10%. Each run lasted 5 minutes, yielding 300 volumes, each consisting of 32 slices. The slices were aligned parallel to the calcarine sulcus, covering the participant‚Äôs occipital cortex. Anatomical imaging was performed using the MP2RAGE sequence (<xref ref-type="bibr" rid="R27">Marques et al., 2010</xref>) with a 1 mm isotropic resolution (TE = 2.98 ms; TR = 4000 ms, TI = 700/2500 ms, FoV = 256 x 216 mm, 160 slices and flip angle 4/5¬∞).</p><p id="P53">For the fMRI runs, we employed a moving bar stimulus displaying a reversing checkerboard pattern, which was organized as a rectangular grid. The bar had a width of 1.2¬∞ visual angle, with a step size of 0.6¬∞ visual angle. The bar began moving from left to right, taking 36 steps for one crossing. The bar and the underlying checkerboard pattern rotated clockwise by 45¬∞ after each crossing. A single fMRI run consisted of eight different screen-crossing directions. Following each diagonal crossing, a grey background image was displayed for 12 seconds as a baseline. The stimulus aperture had a diameter of 18¬∞.</p><p id="P54">Data were preprocessed using fMRIPrep (version 23.1.4), which included slice-time correction, motion correction, and distortion correction. The pRF analyses were performed on data averaged over all five runs and masked for visual areas using prfprepare (<xref ref-type="bibr" rid="R26">Linhardt et al., 2025</xref>). For the empirical data analysis, the visual field was sampled in 151x151 spatial positions, ranging from -13.5¬∞ to +13.5¬∞ in the visual field, and duplicating these positions for 16 pRF sizes ranging from 0.5 to 5. The pRF estimation results were utilised to generate retinotopy maps (eccentricity, polar angle, and pRF size maps) for visual inspection using a custom in-house mapping software.</p></sec></sec><sec id="S15"><label>2.8</label><title>Performance analysis</title><p id="P55">To evaluate the computational times of the GEM-pRF implementation, we conducted performance tests on two platforms: a consumer laptop (ASUS ROG x13, AMD Ryzen 9, 8 cores, 3.30 GHz, 32 GB RAM, RTX 3050 Ti, 4 GB GPU Memory) and a High-Performance Computing (HPC) system (Intel Xeon E5-2698 v4, 40 cores, 2.20 GHz, 4x NVIDIA Tesla V100 DGX, 32 GB per GPU Memory). This setup provides a significant contrast for evaluating computational times on low-end and high-end systems.</p><p id="P56">To provide a comparison of computational times with respect to the size of an fMRI dataset, we created simulated fMRI datasets of different sizes (ranging up to 100,000 voxels) using the validation framework provided by (<xref ref-type="bibr" rid="R23">Lerma-Usabiaga et al., 2020</xref>). The ground truth parameters for all synthesized time courses were set to <italic>¬µ</italic><sub><italic>x</italic></sub> = 0, <italic>¬µ</italic><sub><italic>y</italic></sub> = 0 and <italic>œÉ</italic> = 1. Additionally, the white noise level in the validation framework was adjusted to achieve an overall variance explained of approximately 70%. To analyse the effect of the chosen configuration for the sampling space, we computed the pRF parameters estimation results with the following setups: <list list-type="bullet" id="L3"><list-item><p id="P57">GEM-pRF with sampling space 151x151x16 with refine-fitting enabled (our default configuration) on the HPC system</p></list-item><list-item><p id="P58">GEM-pRF with sampling space 151x151x16 without refine-fitting on HPC system</p></list-item><list-item><p id="P59">GEM-pRF with sampling space 151x151x16 without refine-fitting on consumer laptop</p></list-item><list-item><p id="P60">mrVista, using its default configuration of the prfanalyze-vista container (version-2.3.1_3.1.2)</p></list-item></list></p><p id="P61">The above analyses allowed us to evaluate the computational performance across various dataset sizes and on systems with strong differences in their computing capabilities.</p></sec></sec><sec id="S16" sec-type="results"><label>3</label><title>Results</title><p id="P62">All analyses were computed on either a standard laptop with a GPU or a high-performance computing system with multiple GPUs clusters (please refer to the <xref ref-type="sec" rid="S2">Method</xref> section for details).</p><sec id="S17"><label>3.1</label><title>Simulated data analysis</title><p id="P63">The analysis of pRF parameter estimation by GEM-pRF accuracy relies on simulated fMRI data with added noise. This simulated dataset comprises 5000 fMRI time series for three distinct spatial positions. Since we possess the ground truth pRF parameters in this scenario, assessing the accuracy of our estimation becomes more straightforward.</p><p id="P64">In <xref ref-type="fig" rid="F3">Figure 3(a)</xref>, we illustrate the selected spatial positions (P, Q, and R) for which both low-noise and high-noise (as examples depicted in <xref ref-type="fig" rid="F3">Figure 3(b)</xref>) simulated fMRI data were generated. <xref ref-type="fig" rid="F3">Figure 3(c) &amp; (d)</xref> present a comparison between the pRF parameters estimated by GEM-pRF, which are depicted by black dots, representing the average of individual estimations (grey circles, 50 randomly chosen samples). In the same plots, the ground truth values are represented by blue dots for spatial position and dashed blue circles for pRF size. The Figure also provides a comparison of the estimated parameters by GEM-pRF and the widely used tool mrVista. Analysing <xref ref-type="fig" rid="F3">Figure 3(c)</xref>, it becomes apparent that under the low noise scenario, the pRF parameters estimated by GEM-pRF and mrVista align closely with the ground truth for spatial positions P and Q. For the low noise scenario, minor deviations from the ground truth parameters can be observed for the peripheral position R. As further depicted in <xref ref-type="fig" rid="F3">Figure 3(d)</xref>, in the high noise scenario, on average both GEM-pRF and mrVista seem to reliably estimate the pRF parameters for positions P and Q. However, in this case, for both methods, notable deviations from the ground truth parameters can be observed for the peripheral spatial position R.</p><p id="P65">A closer examination of <xref ref-type="fig" rid="F3">Figure 3(d)</xref>, showing the estimation results, reveals several small grey circles by both GEM-pRF and mrVista. Since all the simulated fMRI time courses were generated with a ground truth pRF size of 1 (indicated by the black dashed circle), these small circles therefore suggest that the pRF sizes were underestimated by both implementations in the high noise scenario. This can also be observed in the high noise case shown in <xref ref-type="fig" rid="F4">Figure 4</xref>. The <xref ref-type="fig" rid="F3">Figure 3(d)</xref> further reveals that the GEM-pRF results show several fixed size small circles and mrVista show even smaller circles.</p><p id="P66"><xref ref-type="fig" rid="F4">Figure 4</xref> provides a further analysis to compare the estimation results from the GEM-pRF and mrVista implementations. The boxenplots (<xref ref-type="bibr" rid="R18">Heike et al., 2017</xref>) illustrate the deviations (Œî) of the estimated parameter values from the ground truth. In the low-noise condition, both implementations showed minimal bias for position estimates (<italic>¬µ</italic><sub><italic>x</italic></sub>, <italic>¬µ</italic><sub><italic>y</italic></sub>), with small deviations centered around zero. However, mrVista exhibited greater variability in the size parameter (<italic>œÉ</italic>), particularly at higher eccentricities. In the high-noise condition, estimation errors increased across both software implementations. Additionally, at higher eccentricities, the variance of positional errors (Œî<italic>¬µ</italic><sub><italic>x</italic></sub>, Œî<italic>¬µ</italic><sub><italic>y</italic></sub>) was asymmetrically larger on the positive Œî side, suggesting a systematic bias towards the periphery. This pattern was more pronounced in the high-noise condition.</p></sec><sec id="S18"><label>3.2</label><title>In vivo data analysis</title><p id="P67">We computed retinotopy maps using the default configuration of GEM-pRF, with 151√ó151√ó16 prediction signals for coarse fitting. The cortex overlays of the eccentricity, polar angle and pRF size maps are presented in <xref ref-type="fig" rid="F5">Figure 5</xref>. Additionally, the coverage map, also shown in <xref ref-type="fig" rid="F5">Figure 5</xref>, depicts a higher density of mapped pRFs near the foveal region compared to the parafoveal region. It further highlights a disparity in the number of mapped pRFs between the upper and lower vertical meridians.</p></sec><sec id="S19"><label>3.3</label><title>Performance analysis</title><p id="P68"><xref ref-type="fig" rid="F6">Figure 6</xref> presents a comparative analysis of the overall execution durations of GEM-pRF using two different pRF parameter estimation configurations: (1) using only coarse fitting and (2) using both coarse and refine-fitting. The total execution times include various stages of the analysis process, such as coarse fitting, refine-fitting (if enabled), calculation of variance explained, and writing results to a file. Additionally, depending on the specified sampling space and stimulus used, the software incurs some initialization time at the beginning, which involves the computation of prediction signals, the determination of neighbors for each pRF parameter set, and the generation of the corresponding design matrix for quadratic approximation.</p><p id="P69">In the current comparison scenario with the default sampling space of 151x151x16 and a bar visual stimulus of duration 300 seconds and size 101x101, the total initialization time was approximately 320 seconds on our HPC system. This initialization time is not included in the computational times shown in <xref ref-type="fig" rid="F6">Figure 6</xref> for two reasons. First, it is independent of the size of the fMRI dataset being analyzed. Second, the calculations performed during this initialization phase are required only once when analyzing multiple datasets. For instance, <xref ref-type="fig" rid="F6">Figure 6</xref> depicts the computational times required for datasets containing varying numbers of vertices (ranging from 5,000 to 100,000). In this case, the initialization computations were performed once and subsequently reused across all datasets. Furthermore, since the calculations that are part of the initialization times are static, they can be cached and can be loaded from cache to further reduce the initialization times.</p><p id="P70">A closer examination of <xref ref-type="fig" rid="F6">Figure 6</xref> reveals an almost linear increase in computational time with the size of the fMRI dataset. To evaluate the performance improvements achieved with GEM-pRF, we compared its computational efficiency against the widely used tool, mrVista. We conducted pRF analyses on simulated data using mrVista on our HPC system. As shown in <xref ref-type="fig" rid="F6">Figure 6</xref>, mrVista‚Äôs default implementation required slightly less than 3 hours to perform pRF estimations on a dataset containing 100,000 voxels. In contrast, GEM-pRF demonstrated significantly faster processing times, completing the same task in approximately 6 minutes on the HPC system and around 7 minutes on a consumer laptop using only the coarse-fitting configuration (151√ó151√ó16 sampling space) and about 20 minutes on the HPC system when both coarse and refine-fitting were applied with the same sampling space.</p></sec></sec><sec id="S20" sec-type="discussion"><label>4</label><title>Discussion</title><p id="P71">The proposed GEM-pRF implementation presents a novel approach to pRF mapping by utilising GPU acceleration for efficient processing of large fMRI datasets. Our implementation reformulates the GLM approach into projections on prediction time courses <bold>p</bold>‚Ä≤(<bold>Œò</bold>) which can be computed and evaluated on the GPU, enabling accelerated execution of the coarse-fitting stage of pRF estimation. We achieve this acceleration through a modified linear regression approach, facilitating SIMD data processing. Additionally, we introduce a novel method for refining coarse pRF estimated parameters as illustrated in <xref ref-type="fig" rid="F2">Figure 2</xref>. For our refinement step, we assume that our objective function can be approximated by a quadratic function in the neighbourhood of the coarse fitting pRF estimation parameters. The maximum of the quadratic approximation is then used as the refined pRF parameters. These mathematical concepts are encapsulated within our GEM-pRF software implementation. <xref ref-type="fig" rid="F1">Figure 1</xref> outlines the core computation steps of the GEM-pRF software and illustrates the execution of these steps on the CPU and GPU. Furthermore, the GEM-pRF implementation provides an extensive configuration file, enabling researchers to specify input datasets in BIDS format and conduct pRF analysis with different settings for comparative analysis.</p><sec id="S21"><title>Accuracy</title><p id="P72">The evaluation of pRF parameter accuracy utilising GEM-pRF was conducted through a dual approach involving empirical and simulated data. The cortex overlays of eccentricity, polar angle, and pRF size maps (<xref ref-type="fig" rid="F5">Figure 5</xref>) exhibit expected retinotopic organization (<xref ref-type="bibr" rid="R19">M. M. Himmelberg et al., 2023</xref>; <xref ref-type="bibr" rid="R44">Wandell &amp; Winawer, 2011</xref>) in an in vivo dataset. Eccentricity values increase from red to blue as we move from the posterior to the anterior end of the primary visual cortex (V1), aligning with known retinotopic organization. The polar angle maps follow the expected visual field representation, with the left hemisphere corresponding to the right visual field and vice versa. Furthermore, the coverage map shown in <xref ref-type="fig" rid="F5">Figure 5</xref> reveals more coverage along the lower vertical meridian as compared to the upper vertical meridian, which is also consistent with the previous studies (<xref ref-type="bibr" rid="R20">M. Himmelberg et al., 2021</xref>; <xref ref-type="bibr" rid="R19">M. M. Himmelberg et al., 2023</xref>). This empirical analysis validates the accuracy of our implementation for pRF analysis with the default sampling space configuration 151x151x16 with refine-fitting.</p><p id="P73">Additionally, quantitative analysis using simulated data demonstrated GEM-pRF‚Äôs ability to estimate pRF parameters for noisy fMRI data. However, estimations for peripherally situated receptive fields (e.g. Position R in <xref ref-type="fig" rid="F3">Figure 3</xref>) showed larger deviations from ground truth, particularly under high-noise conditions, aligning prior research findings (<xref ref-type="bibr" rid="R23">Lerma-Usabiaga et al., 2020</xref>).</p><p id="P74">The high-noise case, as shown in <xref ref-type="fig" rid="F3">Figure 3(d)</xref> and <xref ref-type="fig" rid="F4">Figure 4</xref>, highlights an underestimation of pRF sizes by both implementations. At first glance, <xref ref-type="fig" rid="F4">Figure 4</xref> suggests that mrVista underestimates pRF sizes more than GEM-pRF. However, a closer look at <xref ref-type="fig" rid="F3">Figure 3(d)</xref> reveals that while GEM-pRF estimates several small pRF sizes at a fixed lower bound, mrVista produces even smaller estimates. The small, fixed pRF sizes in GEM-pRF correspond to the lower bound of our specified sigma size for the given sampling space <bold>Œò</bold>, which was set to 0.1, as described in the methods section. Further analysis of these small pRF estimates showed that both implementations achieved similar average variance-explained (<italic>œÅ</italic><sup>2</sup>) values, which serves as a key goodness-of-fit metric for both methods, when applied to these simulated voxels. These findings suggest that while both GEM-pRF and mrVista exhibit large deviations in pRF size estimates for voxels with low-SNR time courses, they still produce equivalent <italic>œÅ</italic><sup>2</sup> values, confirming their methodological consistency as expected.</p><p id="P75">Furthermore, the observed directional bias in position estimates at higher eccentricities suggests a systematic deviation in pRF localization, which may reflect an inherent limitation either in visual stimulation pattern or the fitting procedures of both methods. This effect warrants further investigation in future studies to determine whether it stems from methodological constraints or the choice of visual stimulation pattern. Understanding these biases will be crucial for improving pRF modelling, particularly in studies examining peripheral visual field representations.</p></sec><sec id="S22"><title>Speed</title><p id="P76">The GEM-pRF implementation provides a significant speedup, as depicted in <xref ref-type="fig" rid="F6">Figure 6</xref>. The total computational time required for pRF parameter estimation analysis using our implementation on a large dataset comprising 100,000 voxels shows a speedup of one order of magnitude.</p><p id="P77"><xref ref-type="fig" rid="F6">Figure 6</xref> further demonstrates that the computational times on the consumer laptop system are higher than those on the HPC system for a sampling space of 151x151x16 without refined fitting. This discrepancy can be attributed to the fact that a significant portion of the computation involves matrix operations and objective function term evaluations, which are handled more efficiently by the DGX V100, likely due to its overall architectural optimizations for computational workloads. Furthermore, data transfer between the GPU and CPU contributes more to the overall runtime on the consumer laptop system, likely due to differences in PCIe bandwidth and memory access speeds. These factors collectively explain the increased processing time observed on the consumer laptop system equipped with the RTX 3050 GPU.</p><p id="P78">It is worth noting that the underlying mathematics for GEM-pRF implementation is a reformulated version of the originally proposed pRF mapping methodology by (<xref ref-type="bibr" rid="R10">Dumoulin &amp; Wandell, 2008</xref>). Therefore, the pRF parameters and the retinotopic maps calculated with GEM-pRF are similar to those obtained by the mrVista gold-standard approach. This contrasts with some other previous implementations, which provide alternate methodologies for fast pRF mapping. For example, f-pRF (<xref ref-type="bibr" rid="R4">Bhat et al., 2021</xref>) provides the possibility for fast computation of pRF parameters estimation on a CPU. However, to favour speed over accuracy, they use tile coding and hashing based encoding of stimulus, without using typical GLM approach for parameter estimations. While this approach provides significant speed, it often leads to the mapping of parameters on the discrete grid values with significant deviations. Another technique that has also tried to address the speed issue for pRF mapping is the DeepRF implementation (<xref ref-type="bibr" rid="R43">Thielen et al., 2019</xref>). Deep learning-based methods hold great potential to reliably predict pRF parameters from measured fMRI data. However, their accuracy requires further independent validation. Additionally, the substantial training time needed for these models limits their suitability for research studies where it becomes necessary to train different models (e.g. for the comparison of pRF mapping results using different stimuli). There are also some other methods that have altogether tried to address the speed issue from a different perspective. For example, the deep learning-based implementation by (<xref ref-type="bibr" rid="R35">Ribeiro et al., 2021</xref>) returns estimated pRF parameters of the early visual areas without requiring functional scans. Their method predicts retinotopy maps using brain segmentation from anatomical scans using a geometric deep learning model trained on the Human Connectome Project (HCP) dataset (<xref ref-type="bibr" rid="R2">Benson et al., 2018</xref>). While this method significantly accelerates the mapping process, it comes with certain limitations. First, its accuracy is influenced by the reliability of the pRF estimations used for training, meaning biases introduced by biases introduced by stimulus selection in the experimental setup (<xref ref-type="bibr" rid="R1">Alvarez et al., 2015</xref>; <xref ref-type="bibr" rid="R6">Chang et al., 2025</xref>; <xref ref-type="bibr" rid="R24">Linhardt et al., 2021</xref>) could be learned by the deep learning model, potentially affecting the generalizability of its pRF estimations. Additionally, since the method relies solely on anatomical data to predict pRF parameters, it may not account for functional alterations due to visual pathway pathologies. Condensing these facts, our proposed GEM-pRF implementation provides the possibility for quick estimation of pRF parameters for large datasets (such as the HCP dataset), while maintaining high accuracy.</p></sec><sec id="S23"><title>Sampling space</title><p id="P79">As previously outlined, the refinement stage aims to enhance the accuracy of pRF parameter estimation achieved during the coarse fitting phase. This refinement process involves exploring parameter combinations within the vicinity of the initially computed coarse-fitting pRF parameters. These parameters, along with their neighbouring values, form a discrete set of combinations. The objective of refinement is to identify optimal parameter combinations lying between these discrete points, thereby better capturing the measured fMRI time course, <bold>y</bold>.</p><p id="P80">Given this rationale, selecting an adequately dense sampling space for pRF parameters is crucial for computing prediction time courses. Our default sampling space is set at 151x151x16, corresponding to the pRF parameters (<italic>¬µ</italic><sub><italic>x</italic></sub>, <italic>¬µ</italic><sub><italic>y</italic></sub> and <italic>œÉ</italic>). Additionally, the GEM-pRF implementation provides flexibility in utilizing various custom sampling configurations. It also accommodates complex, irregular spatial distributions of receptive fields. This adaptability enables the analysis and comparison of pRF estimation results across various spatial arrangements of receptive fields in the visual field.</p></sec><sec id="S24"><title>Joint analysis</title><p id="P81">It is customary in pRF analysis applications to perform a joint analysis of multiple datasets, obtained during different runs, sessions, or with different visual stimuli for a subject. The GEM-pRF package provides an out-of-the-box software implementation possibility to conduct such joint analyses.</p></sec><sec id="S25"><title>Scalability</title><p id="P82">In terms of scalability, our software program employs a batching procedure to handle the memory-intensive execution steps on GPUs. Since the estimation of pRF parameters for each voxel‚Äôs fMRI time series, <bold>y</bold>, is independent of others, the minimum batch size for processing measured fMRI data can even be reduced to a single voxel‚Äôs time series.</p><p id="P83">However, during the computation of coarse fitting, the vector projection of a voxel‚Äôs fMRI time series, <bold>y</bold>, is computed with respect to all the prediction time courses. Thus, in our current implementation, it‚Äôs required to hold all the prediction time series data in GPU memory. This necessitates a constraint wherein the user must select a sampling space <bold>Œò</bold> configuration such that the prediction time courses can be stored in the available GPU memory. Our tests have indicated that a sampling space of 151x151x16, corresponding to the pRF parameters (<italic>¬µ</italic><sub><italic>x</italic></sub>, <italic>¬µ</italic><sub><italic>y</italic></sub> and <italic>œÉ</italic>), achieves satisfactory accuracy and can be executed on consumer-grade GPU systems by disabling refine-fitting.</p></sec><sec id="S26"><title>Future scope of work</title><p id="P84">The chosen modular and generic development approach for the GEM-pRF implementation paves the way for future advancements. The software currently uses a 2D Gaussian model for pRF mapping, with the potential to incorporate alternative models, such as the Difference of Gaussian (<xref ref-type="bibr" rid="R47">Zuiderbaan et al., 2012</xref>), into the GEM-pRF open-source implementation. The GEM-pRF implementation already provides a framework of abstract classes, making it easy to integrate a new pRF mapping modelling approach.</p><p id="P85">Moreover, to enhance performance, further improvements can be explored, such as leveraging CUDA streams to achieve additional parallelization in CPU-GPU data transfer and processing. This optimization can lead to faster execution times and more efficient utilisation of computational resources, ultimately enhancing the scalability and usability of the GEM-pRF software.</p></sec></sec><sec id="S27" sec-type="conclusions"><label>5</label><title>Conclusion</title><p id="P86">We herein introduced a breakthrough solution that reworks the design matrix using orthogonalization, allowing us to compute the objective function and its derivatives directly on the GPU. This eliminates the need for iterative refinement, making the process significantly faster while keeping the accuracy unchanged. Our novel GEM-pRF analysis approach yielded accurate pRF mapping results in a fraction of the computation time required with the gold-standard mrVista software package. This increase in computational speed is due to a modified fitting procedure combined with GPU-powered acceleration and offers a modular and flexible approach for efficiently analysing even large fMRI datasets with varying configurations. Our evaluation demonstrated GEM-pRF‚Äôs accuracy in estimating pRF parameters, validated through both empirical and simulated data analyses. Notably, the software‚Äôs scalability allows for effective handling of memory-intensive computations, while its performance surpasses that of widely used tools, significantly reducing computation times without sacrificing accuracy. Looking ahead, GEM-pRF‚Äôs modular design provides possibilities for future enhancements, such as incorporating additional pRF mapping models and optimising CPU-GPU data processing. As the first GPU-accelerated implementation utilizing the traditional GLM-based fitting approach for visual field mapping, GEM-pRF offers a significant step forward in computational neuroimaging, enhancing the efficiency and accessibility of large-scale retinotopic mapping.</p></sec></body><back><ack id="S28"><title>Acknowledgements</title><p>This work was supported by the Austrian Science Fund (FWF; grant number: P35583).</p></ack><fn-group><fn fn-type="conflict" id="FN1"><p id="P87"><bold>Declaration of Competing Interest</bold></p><p id="P88">The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p></fn><fn id="FN2" fn-type="con"><p id="P89"><bold>CRediT authorship contribution statement</bold></p><p id="P90"><bold>Siddharth Mittal</bold>: Data curation, Conceptualization, Methodology, Software, Validation, Visualization, Writing ‚Äì original draft, Writing ‚Äì review &amp; editing. <bold>Michael Woletz</bold>: Conceptualization, Methodology, Validation, Visualization, Writing ‚Äì review &amp; editing. <bold>David Linhardt</bold>: Data curation, Conceptualization, Methodology, Validation, Visualization, Writing ‚Äì review &amp; editing. <bold>Christian Windischberger</bold>: Conceptualization, Methodology, Validation, Visualization, Writing ‚Äì review &amp; editing, Supervision, Project administration, Funding acquisition.</p></fn><fn id="FN3"><p id="P91"><bold>Declaration of generative AI and AI-assisted technologies in the writing process</bold></p><p id="P92">During the preparation of this work the author(s) used Grammarly and ChatGPT in order to improve the readability of our manuscript. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the publication.</p></fn></fn-group><ref-list><ref id="R1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alvarez</surname><given-names>I</given-names></name><name><surname>De Haas</surname><given-names>B</given-names></name><name><surname>Clark</surname><given-names>CA</given-names></name><name><surname>Rees</surname><given-names>G</given-names></name><name><surname>Schwarzkopf</surname><given-names>DS</given-names></name></person-group><article-title>Comparing different stimulus configurations for population receptive field mapping in human fMRI</article-title><source>Frontiers in Human Neuroscience</source><year>2015</year><volume>9</volume><pub-id pub-id-type="pmcid">PMC4335485</pub-id><pub-id pub-id-type="pmid">25750620</pub-id><pub-id pub-id-type="doi">10.3389/fnhum.2015.00096</pub-id></element-citation></ref><ref id="R2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benson</surname><given-names>NC</given-names></name><name><surname>Jamison</surname><given-names>KW</given-names></name><name><surname>Arcaro</surname><given-names>MJ</given-names></name><name><surname>Vu</surname><given-names>AT</given-names></name><name><surname>Glasser</surname><given-names>MF</given-names></name><name><surname>Coalson</surname><given-names>TS</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Yacoub</surname><given-names>E</given-names></name><name><surname>Ugurbil</surname><given-names>K</given-names></name><name><surname>Winawer</surname><given-names>J</given-names></name><name><surname>Kay</surname><given-names>K</given-names></name></person-group><article-title>The Human Connectome Project 7 Tesla retinotopy dataset: Description and population receptive field analysis</article-title><source>Journal of Vision</source><year>2018</year><volume>18</volume><issue>13</issue><fpage>23</fpage><pub-id pub-id-type="pmcid">PMC6314247</pub-id><pub-id pub-id-type="pmid">30593068</pub-id><pub-id pub-id-type="doi">10.1167/18.13.23</pub-id></element-citation></ref><ref id="R3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benson</surname><given-names>NC</given-names></name><name><surname>Yoon</surname><given-names>JMD</given-names></name><name><surname>Forenzo</surname><given-names>D</given-names></name><name><surname>Engel</surname><given-names>SA</given-names></name><name><surname>Kay</surname><given-names>KN</given-names></name><name><surname>Winawer</surname><given-names>J</given-names></name></person-group><article-title>Variability of the Surface Area of the V1, V2, and V3 Maps in a Large Sample of Human Observers</article-title><source>The Journal of Neuroscience</source><year>2022</year><volume>42</volume><issue>46</issue><fpage>8629</fpage><lpage>8646</lpage><pub-id pub-id-type="pmcid">PMC9671582</pub-id><pub-id pub-id-type="pmid">36180226</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0690-21.2022</pub-id></element-citation></ref><ref id="R4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bhat</surname><given-names>S</given-names></name><name><surname>L√ºhrs</surname><given-names>M</given-names></name><name><surname>Goebel</surname><given-names>R</given-names></name><name><surname>Senden</surname><given-names>M</given-names></name></person-group><article-title>Extremely fast pRF mapping for real-time applications</article-title><source>NeuroImage</source><year>2021</year><volume>245</volume><elocation-id>118671</elocation-id><pub-id pub-id-type="pmid">34710584</pub-id></element-citation></ref><ref id="R5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bridge</surname><given-names>H</given-names></name><name><surname>Ip</surname><given-names>IB</given-names></name><name><surname>Parker</surname><given-names>AJ</given-names></name></person-group><article-title>Investigating the human binocular visual system using multi-modal magnetic resonance imaging</article-title><source>Perception</source><year>2023</year><volume>52</volume><issue>7</issue><fpage>441</fpage><lpage>458</lpage><pub-id pub-id-type="pmid">37272064</pub-id></element-citation></ref><ref id="R6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>K</given-names></name><name><surname>Fine</surname><given-names>I</given-names></name><name><surname>Boynton</surname><given-names>GM</given-names></name></person-group><article-title>Improving the reliability and accuracy of population receptive field measures using a logarithmically warped stimulus</article-title><source>Journal of Vision</source><year>2025</year><volume>25</volume><issue>1</issue><fpage>5</fpage><pub-id pub-id-type="pmcid">PMC11702787</pub-id><pub-id pub-id-type="pmid">39752175</pub-id><pub-id pub-id-type="doi">10.1167/jov.25.1.5</pub-id></element-citation></ref><ref id="R7"><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Sam Schwarzkopf</surname><given-names>D</given-names></name></person-group><source>SamSrf 98‚ÄîMatlab toolbox for pRF analysis</source><year>2018</year><pub-id pub-id-type="doi">10.17605/OSF.IO/2RGSM</pub-id></element-citation></ref><ref id="R8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dally</surname><given-names>WJ</given-names></name><name><surname>Keckler</surname><given-names>SW</given-names></name><name><surname>Kirk</surname><given-names>DB</given-names></name></person-group><article-title>Evolution of the Graphics Processing Unit (GPU)</article-title><source>IEEE Micro</source><year>2021</year><volume>41</volume><issue>6</issue><fpage>42</fpage><lpage>51</lpage><pub-id pub-id-type="doi">10.1109/MM.2021.3113475</pub-id></element-citation></ref><ref id="R9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeYoe</surname><given-names>EA</given-names></name><name><surname>Bandettini</surname><given-names>P</given-names></name><name><surname>Neitz</surname><given-names>J</given-names></name><name><surname>Miller</surname><given-names>D</given-names></name><name><surname>Winans</surname><given-names>P</given-names></name></person-group><article-title>Functional magnetic resonance imaging (FMRI) of the human brain</article-title><source>Journal of Neuroscience Methods</source><year>1994</year><volume>54</volume><issue>2</issue><fpage>171</fpage><lpage>187</lpage><pub-id pub-id-type="pmid">7869750</pub-id></element-citation></ref><ref id="R10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dumoulin</surname><given-names>SO</given-names></name><name><surname>Wandell</surname><given-names>BA</given-names></name></person-group><article-title>Population receptive field estimates in human visual cortex</article-title><source>NeuroImage</source><year>2008</year><volume>39</volume><issue>2</issue><fpage>647</fpage><lpage>660</lpage><pub-id pub-id-type="pmcid">PMC3073038</pub-id><pub-id pub-id-type="pmid">17977024</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.09.034</pub-id></element-citation></ref><ref id="R11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elul</surname><given-names>D</given-names></name><name><surname>Levin</surname><given-names>N</given-names></name></person-group><article-title>The Role of Population Receptive Field Sizes in Higher-Order Visual Dysfunction</article-title><source>Current Neurology and Neuroscience Reports</source><year>2024</year><volume>24</volume><issue>12</issue><fpage>611</fpage><lpage>620</lpage><pub-id pub-id-type="pmcid">PMC11538192</pub-id><pub-id pub-id-type="pmid">39266871</pub-id><pub-id pub-id-type="doi">10.1007/s11910-024-01375-6</pub-id></element-citation></ref><ref id="R12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engel</surname><given-names>SA</given-names></name><name><surname>Rumelhart</surname><given-names>DE</given-names></name><name><surname>Wandell</surname><given-names>BA</given-names></name><name><surname>Lee</surname><given-names>AT</given-names></name><name><surname>Glover</surname><given-names>GH</given-names></name><name><surname>Chichilnisky</surname><given-names>E-J</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><article-title>fMRI of human visual cortex</article-title><source>Nature</source><year>1994</year><volume>369</volume><issue>6481</issue><fpage>525</fpage><pub-id pub-id-type="pmid">8031403</pub-id></element-citation></ref><ref id="R13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fox</surname><given-names>P</given-names></name><name><surname>Miezin</surname><given-names>F</given-names></name><name><surname>Allman</surname><given-names>J</given-names></name><name><surname>Van Essen</surname><given-names>D</given-names></name><name><surname>Raichle</surname><given-names>M</given-names></name></person-group><article-title>Retinotopic organization of human visual cortex mapped with positron-emission tomography</article-title><source>The Journal of Neuroscience</source><year>1987</year><volume>7</volume><issue>3</issue><fpage>913</fpage><lpage>922</lpage><pub-id pub-id-type="pmcid">PMC6569058</pub-id><pub-id pub-id-type="pmid">3494107</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.07-03-00913.1987</pub-id></element-citation></ref><ref id="R14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Holmes</surname><given-names>AP</given-names></name><name><surname>Poline</surname><given-names>J-B</given-names></name><name><surname>Grasby</surname><given-names>PJ</given-names></name><name><surname>Williams</surname><given-names>SCR</given-names></name><name><surname>Frackowiak</surname><given-names>RSJ</given-names></name><name><surname>Turner</surname><given-names>R</given-names></name></person-group><article-title>Analysis of fMRI Time-Series Revisited</article-title><source>NeuroImage</source><year>1995</year><volume>2</volume><issue>1</issue><fpage>45</fpage><lpage>53</lpage><pub-id pub-id-type="pmid">9343589</pub-id></element-citation></ref><ref id="R15"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gorelick</surname><given-names>M</given-names></name><name><surname>Ozsvald</surname><given-names>I</given-names></name></person-group><source>High performance Python: Practical performance programming for humans</source><edition>Second edition</edition><publisher-name>O‚ÄôReilly</publisher-name><year>2020</year><comment>second release</comment></element-citation></ref><ref id="R16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Groen</surname><given-names>IIA</given-names></name><name><surname>Dekker</surname><given-names>TM</given-names></name><name><surname>Knapen</surname><given-names>T</given-names></name><name><surname>Silson</surname><given-names>EH</given-names></name></person-group><article-title>Visuospatial coding as ubiquitous scaffolding for human cognition</article-title><source>Trends in Cognitive Sciences</source><year>2022</year><volume>26</volume><issue>1</issue><fpage>81</fpage><lpage>96</lpage><pub-id pub-id-type="pmid">34799253</pub-id></element-citation></ref><ref id="R17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haak</surname><given-names>KV</given-names></name><name><surname>Cornelissen</surname><given-names>FW</given-names></name><name><surname>Morland</surname><given-names>AB</given-names></name></person-group><article-title>Population Receptive Field Dynamics in Human Visual Cortex</article-title><source>PLoS ONE</source><year>2012</year><volume>7</volume><issue>5</issue><elocation-id>e37686</elocation-id><pub-id pub-id-type="pmcid">PMC3359387</pub-id><pub-id pub-id-type="pmid">22649551</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0037686</pub-id></element-citation></ref><ref id="R18"><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Heike</surname><given-names>H</given-names></name><name><surname>Hadley</surname><given-names>W</given-names></name><name><surname>Karen</surname><given-names>K</given-names></name></person-group><source>Letter-value plots: Boxplots for large data</source><year>2017</year><volume>26</volume><fpage>469</fpage><lpage>477</lpage></element-citation></ref><ref id="R19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Himmelberg</surname><given-names>MM</given-names></name><name><surname>T√ºn√ßok</surname><given-names>E</given-names></name><name><surname>Gomez</surname><given-names>J</given-names></name><name><surname>Grill-Spector</surname><given-names>K</given-names></name><name><surname>Carrasco</surname><given-names>M</given-names></name><name><surname>Winawer</surname><given-names>J</given-names></name></person-group><article-title>Comparing retinotopic maps of children and adults reveals a late-stage change in how V1 samples the visual field</article-title><source>Nature Communications</source><year>2023</year><volume>14</volume><issue>1</issue><fpage>1561</fpage><pub-id pub-id-type="pmcid">PMC10030632</pub-id><pub-id pub-id-type="pmid">36944643</pub-id><pub-id pub-id-type="doi">10.1038/s41467-023-37280-8</pub-id></element-citation></ref><ref id="R20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Himmelberg</surname><given-names>M</given-names></name><name><surname>Winawer</surname><given-names>J</given-names></name><name><surname>Carrasco</surname><given-names>M</given-names></name></person-group><source>Linking individual differences in human V1 to perception around the visual field</source><year>2021</year><pub-id pub-id-type="pmcid">PMC9192713</pub-id><pub-id pub-id-type="pmid">35697680</pub-id><pub-id pub-id-type="doi">10.1038/s41467-022-31041-9</pub-id></element-citation></ref><ref id="R21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holmes</surname><given-names>G</given-names></name></person-group><article-title>DISTURBANCES OF VISION BY CEREBRAL LESIONS</article-title><source>British Journal of Ophthalmology</source><year>1918</year><volume>2</volume><issue>7</issue><fpage>353</fpage><lpage>384</lpage><pub-id pub-id-type="pmcid">PMC513514</pub-id><pub-id pub-id-type="pmid">18167806</pub-id><pub-id pub-id-type="doi">10.1136/bjo.2.7.353</pub-id></element-citation></ref><ref id="R22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hummer</surname><given-names>A</given-names></name><name><surname>Ritter</surname><given-names>M</given-names></name><name><surname>Woletz</surname><given-names>M</given-names></name><name><surname>Ledolter</surname><given-names>AA</given-names></name><name><surname>Tik</surname><given-names>M</given-names></name><name><surname>Dumoulin</surname><given-names>SO</given-names></name><name><surname>Holder</surname><given-names>GE</given-names></name><name><surname>Schmidt-Erfurth</surname><given-names>U</given-names></name><name><surname>Windischberger</surname><given-names>C</given-names></name></person-group><article-title>Artificial scotoma estimation based on population receptive field mapping</article-title><source>NeuroImage</source><year>2018</year><volume>169</volume><fpage>342</fpage><lpage>351</lpage><pub-id pub-id-type="pmid">29253656</pub-id></element-citation></ref><ref id="R23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lerma-Usabiaga</surname><given-names>G</given-names></name><name><surname>Benson</surname><given-names>N</given-names></name><name><surname>Winawer</surname><given-names>J</given-names></name><name><surname>Wandell</surname><given-names>BA</given-names></name></person-group><article-title>A validation framework for neuroimaging software: The case of population receptive fields</article-title><source>PLOS Computational Biology</source><year>2020</year><volume>16</volume><issue>6</issue><elocation-id>e1007924</elocation-id><pub-id pub-id-type="pmcid">PMC7343185</pub-id><pub-id pub-id-type="pmid">32584808</pub-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007924</pub-id></element-citation></ref><ref id="R24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Linhardt</surname><given-names>D</given-names></name><name><surname>Pawloff</surname><given-names>M</given-names></name><name><surname>Hummer</surname><given-names>A</given-names></name><name><surname>Woletz</surname><given-names>M</given-names></name><name><surname>Tik</surname><given-names>M</given-names></name><name><surname>Ritter</surname><given-names>M</given-names></name><name><surname>Schmidt-Erfurth</surname><given-names>U</given-names></name><name><surname>Windischberger</surname><given-names>C</given-names></name></person-group><article-title>Combining stimulus types for improved coverage in population receptive field mapping</article-title><source>NeuroImage</source><year>2021</year><volume>238</volume><elocation-id>118240</elocation-id><pub-id pub-id-type="pmid">34116157</pub-id></element-citation></ref><ref id="R25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Linhardt</surname><given-names>D</given-names></name><name><surname>Pawloff</surname><given-names>M</given-names></name><name><surname>Woletz</surname><given-names>M</given-names></name><name><surname>Hummer</surname><given-names>A</given-names></name><name><surname>Tik</surname><given-names>M</given-names></name><name><surname>Vasileiadi</surname><given-names>M</given-names></name><name><surname>Ritter</surname><given-names>M</given-names></name><name><surname>Lerma-Usabiaga</surname><given-names>G</given-names></name><name><surname>Schmidt-Erfurth</surname><given-names>U</given-names></name><name><surname>Windischberger</surname><given-names>C</given-names></name></person-group><article-title>Intrasession and Intersession Reproducibility of Artificial Scotoma pRF Mapping Results at Ultra-High Fields</article-title><source>Eneuro</source><year>2022</year><volume>9</volume><issue>5</issue><elocation-id>ENEURO.0087-22.2022</elocation-id><pub-id pub-id-type="pmcid">PMC9512620</pub-id><pub-id pub-id-type="pmid">36635900</pub-id><pub-id pub-id-type="doi">10.1523/ENEURO.0087-22.2022</pub-id></element-citation></ref><ref id="R26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Linhardt</surname><given-names>D</given-names></name><name><surname>Woletz</surname><given-names>M</given-names></name><name><surname>Paz-Alonso</surname><given-names>PM</given-names></name><name><surname>Windischberger</surname><given-names>C</given-names></name><name><surname>Lerma-Usabiaga</surname><given-names>G</given-names></name></person-group><article-title>Biases in Volumetric Versus Surface Analyses in Population Receptive Field Mapping</article-title><source>Human Brain Mapping</source><year>2025</year><volume>46</volume><issue>2</issue><elocation-id>e70140</elocation-id><pub-id pub-id-type="pmcid">PMC11758450</pub-id><pub-id pub-id-type="pmid">39854138</pub-id><pub-id pub-id-type="doi">10.1002/hbm.70140</pub-id></element-citation></ref><ref id="R27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marques</surname><given-names>JP</given-names></name><name><surname>Kober</surname><given-names>T</given-names></name><name><surname>Krueger</surname><given-names>G</given-names></name><name><surname>Van Der Zwaag</surname><given-names>W</given-names></name><name><surname>Van De Moortele</surname><given-names>P-F</given-names></name><name><surname>Gruetter</surname><given-names>R</given-names></name></person-group><article-title>MP2RAGE, a self bias-field corrected sequence for improved segmentation and T1-mapping at high field</article-title><source>NeuroImage</source><year>2010</year><volume>49</volume><issue>2</issue><fpage>1271</fpage><lpage>1281</lpage><pub-id pub-id-type="pmid">19819338</pub-id></element-citation></ref><ref id="R28"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Mi≈°iƒá</surname><given-names>MJ</given-names></name><name><surname>ƒêurƒëeviƒá</surname><given-names>ƒêM</given-names></name><name><surname>Toma≈°eviƒá</surname><given-names>MV</given-names></name></person-group><source>Evolution and Trends in GPU Computing</source><conf-name>2012 Proceedings of the 35th International Convention MIPRO</conf-name><year>2012</year><fpage>289</fpage><lpage>294</lpage><comment><ext-link ext-link-type="uri" xlink:href="https://ieeexplore.ieee.org/abstract/document/6240658">https://ieeexplore.ieee.org/abstract/document/6240658</ext-link></comment></element-citation></ref><ref id="R29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moeller</surname><given-names>S</given-names></name><name><surname>Yacoub</surname><given-names>E</given-names></name><name><surname>Olman</surname><given-names>CA</given-names></name><name><surname>Auerbach</surname><given-names>E</given-names></name><name><surname>Strupp</surname><given-names>J</given-names></name><name><surname>Harel</surname><given-names>N</given-names></name><name><surname>Uƒüurbil</surname><given-names>K</given-names></name></person-group><article-title>Multiband multislice GE-EPI at 7 tesla, with 16-fold acceleration using partial parallel imaging with application to high spatial and temporal whole-brain fMRI</article-title><source>Magnetic Resonance in Medicine</source><year>2010</year><volume>63</volume><issue>5</issue><fpage>1144</fpage><lpage>1153</lpage><pub-id pub-id-type="pmcid">PMC2906244</pub-id><pub-id pub-id-type="pmid">20432285</pub-id><pub-id pub-id-type="doi">10.1002/mrm.22361</pub-id></element-citation></ref><ref id="R30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Molz</surname><given-names>B</given-names></name><name><surname>Herbik</surname><given-names>A</given-names></name><name><surname>Baseler</surname><given-names>HA</given-names></name><name><surname>De Best</surname><given-names>P</given-names></name><name><surname>Raz</surname><given-names>N</given-names></name><name><surname>Gouws</surname><given-names>A</given-names></name><name><surname>Ahmadi</surname><given-names>K</given-names></name><name><surname>Lowndes</surname><given-names>R</given-names></name><name><surname>McLean</surname><given-names>RJ</given-names></name><name><surname>Gottlob</surname><given-names>I</given-names></name><name><surname>Kohl</surname><given-names>S</given-names></name><etal/></person-group><article-title>Achromatopsia‚ÄîVisual Cortex Stability and Plasticity in the Absence of Functional Cones</article-title><source>Investigative Opthalmology &amp; Visual Science</source><year>2023</year><volume>64</volume><issue>13</issue><fpage>23</fpage><pub-id pub-id-type="pmcid">PMC10584018</pub-id><pub-id pub-id-type="pmid">37847226</pub-id><pub-id pub-id-type="doi">10.1167/iovs.64.13.23</pub-id></element-citation></ref><ref id="R31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Okuta</surname><given-names>R</given-names></name><name><surname>Unno</surname><given-names>Y</given-names></name><name><surname>Nishino</surname><given-names>D</given-names></name><name><surname>Hido</surname><given-names>S</given-names></name><name><surname>Loomis</surname><given-names>C</given-names></name></person-group><source>CuPy: A NumPy-Compatible Library for NVIDIA GPU Calculations</source><year>2017</year></element-citation></ref><ref id="R32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poline</surname><given-names>J-B</given-names></name><name><surname>Brett</surname><given-names>M</given-names></name></person-group><article-title>The general linear model and fMRI: Does love last forever?</article-title><source>NeuroImage</source><year>2012</year><volume>62</volume><issue>2</issue><fpage>871</fpage><lpage>880</lpage><pub-id pub-id-type="pmid">22343127</pub-id></element-citation></ref><ref id="R33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prabhakaran</surname><given-names>GT</given-names></name><name><surname>Al-Nosairy</surname><given-names>KO</given-names></name><name><surname>Tempelmann</surname><given-names>C</given-names></name><name><surname>Thieme</surname><given-names>H</given-names></name><name><surname>Hoffmann</surname><given-names>MB</given-names></name></person-group><article-title>Mapping Visual Field Defects With fMRI ‚Äì Impact of Approach and Experimental Conditions</article-title><source>Frontiers in Neuroscience</source><year>2021</year><volume>15</volume><elocation-id>745886</elocation-id><pub-id pub-id-type="pmcid">PMC8455880</pub-id><pub-id pub-id-type="pmid">34566575</pub-id><pub-id pub-id-type="doi">10.3389/fnins.2021.745886</pub-id></element-citation></ref><ref id="R34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raschka</surname><given-names>S</given-names></name><name><surname>Patterson</surname><given-names>J</given-names></name><name><surname>Nolet</surname><given-names>C</given-names></name></person-group><article-title>Machine Learning in Python: Main Developments and Technology Trends in Data Science, Machine Learning, and Artificial Intelligence</article-title><source>Information</source><year>2020</year><volume>11</volume><issue>4</issue><fpage>193</fpage><pub-id pub-id-type="doi">10.3390/info11040193</pub-id></element-citation></ref><ref id="R35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ribeiro</surname><given-names>FL</given-names></name><name><surname>Bollmann</surname><given-names>S</given-names></name><name><surname>Puckett</surname><given-names>AM</given-names></name></person-group><article-title>Predicting the retinotopic organization of human visual cortex from anatomy using geometric deep learning</article-title><source>NeuroImage</source><year>2021</year><volume>244</volume><elocation-id>118624</elocation-id><pub-id pub-id-type="pmid">34607019</pub-id></element-citation></ref><ref id="R36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ritter</surname><given-names>M</given-names></name><name><surname>Hummer</surname><given-names>A</given-names></name><name><surname>Ledolter</surname><given-names>AA</given-names></name><name><surname>Holder</surname><given-names>GE</given-names></name><name><surname>Windischberger</surname><given-names>C</given-names></name><name><surname>Schmidt-Erfurth</surname><given-names>UM</given-names></name></person-group><article-title>Correspondence between retinotopic cortical mapping and conventional functional and morphological assessment of retinal disease</article-title><source>British Journal of Ophthalmology</source><year>2019</year><volume>103</volume><issue>2</issue><fpage>208</fpage><lpage>215</lpage><pub-id pub-id-type="pmid">29699983</pub-id></element-citation></ref><ref id="R37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ritter</surname><given-names>M</given-names></name><name><surname>Hummer</surname><given-names>A</given-names></name><name><surname>Pawloff</surname><given-names>M</given-names></name><name><surname>Ledolter</surname><given-names>AA</given-names></name><name><surname>Linhardt</surname><given-names>D</given-names></name><name><surname>Woletz</surname><given-names>M</given-names></name><name><surname>Deak</surname><given-names>GG</given-names></name><name><surname>Sacu</surname><given-names>S</given-names></name><name><surname>Ristl</surname><given-names>R</given-names></name><name><surname>Ramazanova</surname><given-names>D</given-names></name><name><surname>Holder</surname><given-names>GE</given-names></name><etal/></person-group><article-title>Retinotopic cortical mapping in objective functional monitoring of macular therapy</article-title><source>British Journal of Ophthalmology</source><year>2024</year><elocation-id>bjophthalmol-2021-320723</elocation-id><pub-id pub-id-type="pmid">38811051</pub-id></element-citation></ref><ref id="R38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneider</surname><given-names>W</given-names></name><name><surname>Noll</surname><given-names>DC</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><article-title>Functional topographic mapping of the cortical ribbon in human vision with conventional MRI scanners</article-title><source>Nature</source><year>1993</year><volume>365</volume><issue>6442</issue><fpage>150</fpage><lpage>153</lpage><pub-id pub-id-type="pmid">8371756</pub-id></element-citation></ref><ref id="R39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Senden</surname><given-names>M</given-names></name><name><surname>Emmerling</surname><given-names>TC</given-names></name><name><surname>Van Hoof</surname><given-names>R</given-names></name><name><surname>Frost</surname><given-names>MA</given-names></name><name><surname>Goebel</surname><given-names>R</given-names></name></person-group><article-title>Reconstructing imagined letters from early visual cortex reveals tight topographic correspondence between visual mental imagery and perception</article-title><source>Brain Structure and Function</source><year>2019</year><volume>224</volume><issue>3</issue><fpage>1167</fpage><lpage>1183</lpage><pub-id pub-id-type="pmcid">PMC6499877</pub-id><pub-id pub-id-type="pmid">30637491</pub-id><pub-id pub-id-type="doi">10.1007/s00429-019-01828-6</pub-id></element-citation></ref><ref id="R40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sereno</surname><given-names>MI</given-names></name><name><surname>Dale</surname><given-names>AM</given-names></name><name><surname>Reppas</surname><given-names>JB</given-names></name><name><surname>Kwong</surname><given-names>KK</given-names></name><name><surname>Belliveau</surname><given-names>JW</given-names></name><name><surname>Brady</surname><given-names>TJ</given-names></name><name><surname>Rosen</surname><given-names>BR</given-names></name><name><surname>Tootell</surname><given-names>RBH</given-names></name></person-group><article-title>Borders of Multiple Visual Areas in Humans Revealed by Functional Magnetic Resonance Imaging</article-title><source>Science</source><year>1995</year><volume>268</volume><issue>5212</issue><fpage>889</fpage><lpage>893</lpage><pub-id pub-id-type="pmid">7754376</pub-id></element-citation></ref><ref id="R41"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Takagi</surname><given-names>Y</given-names></name><name><surname>Nishimoto</surname><given-names>S</given-names></name></person-group><source>High-resolution image reconstruction with latent diffusion models from human brain activity</source><conf-name>2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</conf-name><year>2023</year><fpage>14453</fpage><lpage>14463</lpage><pub-id pub-id-type="doi">10.1109/CVPR52729.2023.01389</pub-id></element-citation></ref><ref id="R42"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Tatsuji</surname><given-names>I</given-names></name></person-group><source>Die Sehst√∂rungen bei Schu√üverletzungen der kortikalen Sehsph√§re: Nach Beobachtungen an Verwundeten der letzten japanischen Kriege</source><publisher-name>Engelmann</publisher-name><year>1909</year></element-citation></ref><ref id="R43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thielen</surname><given-names>J</given-names></name><name><surname>G√º√ßl√º</surname><given-names>U</given-names></name><name><surname>G√º√ßl√ºt√ºrk</surname><given-names>Y</given-names></name><name><surname>Ambrogioni</surname><given-names>L</given-names></name><name><surname>Bosch</surname><given-names>SE</given-names></name><name><surname>Van Gerven</surname><given-names>MAJ</given-names></name></person-group><article-title>DeepRF: Ultrafast population receptive field mapping with deep learning</article-title><source>Neuroscience</source><year>2019</year><comment>[Preprint]</comment><pub-id pub-id-type="doi">10.1101/732990</pub-id></element-citation></ref><ref id="R44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wandell</surname><given-names>BA</given-names></name><name><surname>Winawer</surname><given-names>J</given-names></name></person-group><article-title>Imaging retinotopic maps in the human brain</article-title><source>Vision Research</source><year>2011</year><volume>51</volume><issue>7</issue><fpage>718</fpage><lpage>737</lpage><pub-id pub-id-type="pmcid">PMC3030662</pub-id><pub-id pub-id-type="pmid">20692278</pub-id><pub-id pub-id-type="doi">10.1016/j.visres.2010.08.004</pub-id></element-citation></ref><ref id="R45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Waz</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Lu</surname><given-names>ZL</given-names></name></person-group><article-title>qPRF: A system to accelerate population receptive field modeling</article-title><source>NeuroImage</source><year>2025</year><volume>306</volume><elocation-id>120994</elocation-id><pub-id pub-id-type="pmcid">PMC11877312</pub-id><pub-id pub-id-type="pmid">39761863</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2024.120994</pub-id></element-citation></ref><ref id="R46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeki</surname><given-names>S</given-names></name><name><surname>Watson</surname><given-names>J</given-names></name><name><surname>Lueck</surname><given-names>C</given-names></name><name><surname>Friston</surname><given-names>K</given-names></name><name><surname>Kennard</surname><given-names>C</given-names></name><name><surname>Frackowiak</surname><given-names>R</given-names></name></person-group><article-title>A direct demonstration of functional specialization in human visual cortex</article-title><source>The Journal of Neuroscience</source><year>1991</year><volume>11</volume><issue>3</issue><fpage>641</fpage><lpage>649</lpage><pub-id pub-id-type="pmcid">PMC6575357</pub-id><pub-id pub-id-type="pmid">2002358</pub-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.11-03-00641.1991</pub-id></element-citation></ref><ref id="R47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zuiderbaan</surname><given-names>W</given-names></name><name><surname>Harvey</surname><given-names>BM</given-names></name><name><surname>Dumoulin</surname><given-names>SO</given-names></name></person-group><article-title>Modeling center-surround configurations in population receptive fields using fMRI</article-title><source>Journal of Vision</source><year>2012</year><volume>12</volume><issue>3</issue><fpage>10</fpage><pub-id pub-id-type="pmid">22408041</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Figure 1</label><caption><p>An illustrative flow chart representing the matrix dot product-based coarse-fitting step and a non-iterative refinement step. The green highlighted colours represent that the computation takes place on GPU for performance gain.</p></caption><graphic xlink:href="EMS205733-f001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><p>Illustration of quadratic surface approximation Œµ(<bold>Œ∏</bold>) of the objective function ùíû(<bold>Œ∏</bold>) (<xref ref-type="disp-formula" rid="FD8">equation (6)</xref>). The blue dot marks the spatial position of the coarse-fit result parameters (<italic>¬µ</italic><sub><italic>x</italic></sub>, <italic>¬µ</italic><sub><italic>y</italic></sub>, for a given <italic>œÉ</italic>). The red dots represent the immediate neighbours of the coarse-fit point in the sampling space. The red wireframe depicts the objective function values in an extended neighborhood around the coarse-fit parameters. The 3D translucent blue surface shows the refined quadratic approximation Œµ(<bold>Œ∏</bold>) (<xref ref-type="disp-formula" rid="FD11">equation (9)</xref>) near the coarse-fit (blue dot). The black arrows on the blue and red dots represent the gradients, where the arrow directions point towards the refined-fitting point. The green point represents the optimal parameters computed using non-linear iterative optimization function, while the yellow point represents the refined parameters obtained through our quadratic surface approximation. Notably, this example demonstrates an extreme case of a small pRF (small <italic>œÉ</italic>), leading to non-smooth objective function values in the extended neighborhood.</p></caption><graphic xlink:href="EMS205733-f002"/></fig><fig id="F3" position="float"><label>Figure 3</label><caption><title>Comparison of population receptive field (pRF) estimation results at different eccentricities for ground truth data under low and high noise conditions.</title><p>(a): Illustration depicting the spatial positions (P, Q, and R) of selected receptive fields used to generate simulated data. (b): Visualization of noise levels for low and high noise scenarios. (c, d): Comparison of estimation results using GEM-pRF and mrVista for low noise (Panel c) and high noise (Panel d) scenarios, generated for the selected spatial positions using pRF parameters P: (<italic>¬µ</italic><sub><italic>x</italic></sub> = 0, <italic>¬µ</italic><sub><italic>y</italic></sub> = 0, <italic>œÉ</italic> = 1), Q: (<italic>¬µ</italic><sub><italic>x</italic></sub> = 3, <italic>¬µ</italic><sub><italic>y</italic></sub> = 3, <italic>œÉ</italic> = 1), and R: (<italic>¬µ</italic><sub><italic>x</italic></sub> = 6, <italic>¬µ</italic><sub><italic>y</italic></sub> = 6, <italic>œÉ</italic> = 1). In Panels c and d, the blue dot and blue dashed circle indicate the ground truth pRF center and its size, respectively, while the black dot and black dashed circles represent the averaged estimated pRF center and its size.</p></caption><graphic xlink:href="EMS205733-f003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><p>Comparison of GEM-pRF and mrVista for pRF parameter estimations using the simulated data across low- and high-noise scenarios. The Figure shows the differences between the estimated value and the ground truth for a given pRF parameter (i.e. <italic>¬µ</italic><sub><italic>x</italic></sub>, <italic>¬µ</italic><sub><italic>y</italic></sub> or <italic>œÉ</italic>). As indicated in <xref ref-type="fig" rid="F3">Figure 3</xref>, the comparisons are conducted at the same spatial positions (P, Q, R) corresponding to eccentricity values of <inline-formula><mml:math id="M29"><mml:mrow><mml:mn>3</mml:mn><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt><mml:mspace width="0.2em"/><mml:mtext>and</mml:mtext><mml:mspace width="0.2em"/><mml:mn>6</mml:mn><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula></p></caption><graphic xlink:href="EMS205733-f004"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><p>Visualization of estimated population receptive field (pRF) parameters overlaid onto an inflated cortical surface, delineating the left and right hemispheres of the brain. The bottom row displays an aggregate coverage map spanning both hemispheres. The pRF parameters were estimated utilizing the default settings of GEM-pRF, employing a grid of 151x151 pRF positions across the visual field (total diameter 18¬∞), each replicated for 8 sigma values.</p></caption><graphic xlink:href="EMS205733-f005"/></fig><fig id="F6" position="float"><label>Figure 6</label><caption><p>Comparison of mrVista vs. GEM-pRF computational times as well as the comparison of two GEM fitting configurations i.e. coarse fitting only and coarse fitting plus refine-fitting. The default parameter-sampling configuration is used i.e. a regular grid of 151x151x16. The computational times are depicted on a log scale.</p></caption><graphic xlink:href="EMS205733-f006"/></fig></floats-group></article>